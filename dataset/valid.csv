id,article,abstract,created_at,exemplar,similarity
elastic_elasticsearch/72156,"compatible testing key in match and length transformations . <nl> additional transformations to modify a key in a match and a key in a <nl> length assertions <para-sep> a transformation to replace the key in a length assertion . <nl> a transformation to replace the key in a match assertion . <nl> replaces all the values of a is_true assertion for all project rest tests . for example ' is_true ' : ' value_to_replace ' to ' is_true ' : ' value_replaced ' <nl> replaces all the values of a is_false assertion for all project rest tests . for example ' is_false ' : ' value_to_replace ' to ' is_false ' : ' value_replaced ' <nl> replaces all the values of a is_false assertion for given rest test . for example ' is_false ' : ' value_to_replace ' to ' is_false ' : ' value_replaced ' <nl> an abstract common class to handle replacing key and values under a parent object this class can be subclass to transform the ' getkeytofind ' : { ' requiredchildkey ' : ' foo ' } into ' getkeytofind ' : { ' newchildkey ' : ' getreplacementnode ' } a getkeytofind and transformtest would have to be implemented in a subclass <nl> a transformation to replace the key in a length assertion . for example , change from ' length ' : { ' index._type ' : 0 } to ' length ' : { ' index._doc ' : 0 } <nl> a transformation to replace the key in a match . for example , change from ' match ' : { ' index._type ' : ' foo ' } to ' match ' : { ' index._doc ' : ' foo ' } <nl> a transformation to replace the value of a match . for example , change from ' match ' : { ' _type ' : ' foo ' } to ' match ' : { ' _type ' : ' bar ' }",additional yml tests transformations to modify a key in a match assertion and a key in a <nl> length assertion . <nl> the testing is done with the original and expected transformed files . this should make it a little more easy to write new tests and add new transformations .,1619181080,"this code change achieves witching from using and extraction to using the api . it helps simplify the ql code , but does also come with a small drawback which will become visible in where some tests are not needed anymore . any query ( especially sql ) on fields that have disabled , but are indexed ( accessible through ) , will not be possible anymore . <nl> this pr , also , improves bwc checks when it comes to running queries in a mixed-versions cluster ( a rolling upgrade scenario ) by using a minimum compatibility version when",0.9705777168273926
quarkusio_quarkus/14975,"fix undertow http/0 issue . <nl> ( cherry picked from commit sha ) <cm-sep> exclude jboss-logging-jdk . <nl> ( cherry picked from commit sha ) <cm-sep> make sure getdefferredidentity does not return null . <nl> ( cherry picked from commit sha ) <cm-sep> fix the native httproot & nonapproot issue . <nl> made the code more consistent between the 0 uis <nl> signed-off-by : phillip kruger . <nl> ( cherry picked from commit sha ) <cm-sep> mark resteasy qute with code starter . <nl> ( cherry picked from commit sha ) <cm-sep> remove field that can cause graalvm to fail . <nl> ( cherry picked from commit sha ) <cm-sep> do not produce kubernetesclient if we have openshiftclient available . <nl> ( cherry picked from commit sha ) <cm-sep> document capabilities as a tool for conditional build steps . <nl> ( cherry picked from commit sha ) <para-sep> wire up the config bean support <nl> do not register our client producer if the openshift client is present , because it provides it too <nl> wire up the kubernetesclient bean support <nl> make sure we can inject both aspects of it","please do n't merge , i will merge it myself .",1612972527,"please do not merge , i will merge it myself .",0.9284788966178894
apache_incubator-pinot/5639,"initial commit for controller side change . <cm-sep> revised based on email discussion and add more tests . <para-sep> modifies the segment location in committingsegmentdescriptor to the uri which the segment is moved to unless committingsegmentdescriptor has a peer download uri scheme in segment location . <nl> if the download url set by the server is a peer download url format with peer scheme , put metadata_uri_for_peer_download in zk ; otherwise just use the location in the descriptor . <nl> the committingsegmentdescriptor is then updated with the permanent segment location to be saved in metadata store . convert to a controller uri if the segment location uses local file scheme . <nl> set up a new table with 0 replicas , 0 instances , 0 partition <nl> test case 0 : segment location with vip format . commit a segment for partition 0 <nl> test case 0 : segment location with peer format : peer : //segment1 , verify that an empty string is stored in zk .","for such peer segment location , during the commit phase of the llc protocol , we modify the controller behavior such that ( 0 ) controller does need to move segments during commitend ( ) phase of split commit ( 0 ) controller will store an empty string ' in the zk . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1593500384,check alert 's lasttaskruntime . if there is no success run within 0 days then disable it .,0.9522421360015869
elastic_elasticsearch/71931,"use the remaining scroll response documents on update by query bulk requests . <nl> in update by query requests where max_docs < size and conflicts=proceed <nl> we were n't using the remaining documents from the scroll response in <nl> cases where there were conflicts and in the first bulk request the <nl> successful updates < max_docs . this commit address that problem and <nl> use the remaining documents from the scroll response instead of <nl> requesting a new page . <para-sep> use a single thread pool for writes so we can enforce a consistent ordering <nl> force match_delete version so we get reindex conflicts <nl> force that the first maxdocs are transformed into a noop <nl> add a marker on the document to signal that this document should return a noop in the script <nl> block the write thread pool <nl> ensure that the write thread blocking task is currently executing <nl> modify a subset of the target documents concurrently <nl> the bulk request is enqueued before the update by query <nl> ensure that the concurrent writes are enqueued before the update by query request is sent <nl> allow tasks from the write thread to make progress <nl> when scripts are enabled , the first maxdocs are a noop <nl> use explicit mappings so we do n't have to create those on demands and the task ordering can change to wait for mapping updates <nl> keeps track of the total number of bulk operations performed from a single scroll response . it is possible that multiple bulk requests are performed from a single scroll response , meaning that we have to take into account the total in order to compute a correct scroll keep alive time . <nl> unable to consume more than remaining hits",in update by query requests where max_docs < size and conflicts=proceed <nl> we were n't using the remaining documents from the scroll response in <nl> cases where there were conflicts and in the first bulk request the <nl> successful updates < max_docs . this commit address that problem and <nl> use the remaining documents from the scroll response instead of <nl> requesting a new page .,1618924011,this pr removes the blocking call to insert ingest documents into a queue in the coordinator . it replaces it with an offer call which will throw a rejection exception in the event that the queue is full . this prevents deadlocks of the write threads when the queue fills to capacity and there are more than one enrich processors in a pipeline . <nl> we are weighing options and will be fixing that problem soon .,0.9665900468826294
apache_pulsar/9877,"support get persistent topics or non-persistent topics for pulsar admin client . <para-sep> get the both persistent and non-persistent topics under a namespace . get the list of topics under a namespace . response example : [ ' topic : //my-tenant/my-namespace/ ' , ' topic : //my-tenant/my-namespace/ ' ] <nl> get both persistent and non-persistent topics under a namespace asynchronously . get the list of topics under a namespace asynchronously . response example : [ ' topic : //my-tenant/my-namespace/ ' , ' topic : //my-tenant/my-namespace/ ' ]","currently , we can only get all topics by the admin client . this pr supports to get persistent topic or non-persistent topic by add or . <nl> for pulsar sql , is should only get fetch the persistent topics when list tables . i will push the next pr to fix the pulsar sql . <nl> unit test and integration test added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl>",1615429385,org.apache.pulsar.admin.cli.pulsaradmintooltest # topics <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivetopicapi <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivepolicyupdateandclean <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testdeletewhennosubscriptionswithtopiclevelpolicies,0.9782124161720276
apache_flink/14534,"do n't check whether a function is generic in hive catalog <para-sep> prefix used to distinguish scala/python functions <nl> check if function exists <nl> to be compatible with old behavior <nl> thus , use a prefix in class name to distinguish java/scala and python functions <nl> create a function with old prefix 'flink : ' and make sure we can properly retrieve it <nl> to make sure hive catalog does n't check function class <nl> alter the function","do n't check whether a function is generic in hive catalog . <nl> do n't check whether a function is generic in hivecatalog . <nl> - stop calling in hivecatalog . <nl> - add test case to verify . <nl> new test case . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or",1609401297,"this pr adds a method to instantiate a streamexecutionenvironment with a given . it is a shortcut for . <nl> added tests in : <nl> * <nl> * changed the way environment is instantiated in . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) :",0.9544855356216431
jenkinsci_jenkins/4909,ga extended and system read permissions,", graduate overall/systemread to ga status .",1597351562,"like mentioned in the previous comment in code , the method should be used in the other project , like authorize-project that require a field to be set as critical . <nl> as discussed with jesse and oleg on oct. 0 , i can un-restrict the call to this method by plugins . <nl> you can see the workaround used in authorize-project at the moment : pr . <nl> * un-restrict the use of the addcriticalfield in xstream2 to be used in plugins .",0.7834786176681519
confluentinc_ksql/6266,wire up the key format . <nl> update the physical plan to pass around the key format . <para-sep> when : <nl> given : <nl> given : <nl> when : <nl> given : <nl> when :,update the physical plan to pass around the key format . <nl> usual .,1600687448,no functional change . <nl> also rename the source files of several udfs which look to have been previously converted to remove the 'kudf ' from their class names . <nl> a new unit test added to internalfunctionregistry which should fail if any new kudfs get sneaked back in by mistake .,0.9305773377418518
elastic_elasticsearch/71031,allow closing a write index of a data stream . <nl> prior to this commit when attempting to close a data stream a validation error is returned indicating that it is forbidden to close a write index of a data stream . the idea behind that is to ensure that a data stream always can accept writes . for the same reason deleting a write index is not allowed ( the write index can only be deleted when deleting the entire data stream ) . <nl> however closing an index is n't as destructive as deleting an index ( an open index request makes the write index available again ) and there are other cases where a data stream ca n't accept writes . for example when primary shards of the write index are not available . so the original reasoning for not allowing to close a write index is n't that strong . <nl> on top of this is that this also avoids certain administrative operations from being performed . for example restoring a snapshot containing data streams that already exist in the cluster ( in place restore ) . <para-sep> close all indices : <nl> a rollover after taking snapshot . the new backing index should be a standalone index after restoring and not part of the data stream : <nl> close all backing indices of ds data stream : <nl> the backing index created as part of rollover should still exist ( but just not part of the data stream ) <nl> an additional rollover should create a new backing index ( 3th generation ) and leave .ds-ds- ... 0 index as is :,prior to this commit when attempting to close a data stream a validation error is returned indicating that it is forbidden to close a write index of a data stream . the idea behind that is to ensure that a data stream always can accept writes . for the same reason deleting a write index is not allowed ( the write index can only be deleted when deleting the entire data stream ) . <nl> however closing an index is n't as destructive as deleting an index ( an open index request makes the write index available again ) and,1617093299,"this adds validation to make sure alias operations ( add , remove , remove index ) <nl> do n't target data streams or the backing indices .",0.9504532217979431
vespa-engine_vespa/16449,sleep in end of iteration <cm-sep> speedup flusher unit test . <nl> finish test as soon as flush is invoked on mock handler,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1612876420,"this fixes . <nl> most of this code is to generate a helpful error message by printing ( the start of ) of the offending document . <nl> also removed a case where could be : i 'm not quite sure how this is possible , as long as we find a document id , should be ?",0.9350004196166992
eclipse-openj9_openj9/10909,"cull stack depth in dumpallthreads later on . <nl> we need the full stacktrace from getthreadinfo function since later in the <nl> createthreadinfoarray , we copy over monitorinfo objects which may refer to <nl> stack frames beyond the max depth argument passed into dumpallthreads .","we need the full stacktrace from getthreadinfo function since later in the <nl> createthreadinfoarray , we copy over monitorinfo objects which may refer to <nl> stack frames beyond the max depth argument passed into dumpallthreads .",1602867495,"add access checks for parameter and return types . <nl> though methods are public and there is no need for access check , the parameter and return classes require access check by access class . <nl> throw instead of when an application attempts ( not refectively ) to access or modify a field , or to invoke a method that it does n't have access to . this is to satisfy java spec requirements .",0.8343267440795898
apache_incubator-pinot/6141,add query option of disabling upsert during query,add a query option for skipping upsert ( mostly for debugging purpose ) . <nl> displays : .,1602651355,"currently you can specify a readerconfig when creating segments using pinot-admin.sh , but this argument is not available when creating segments using the hadoop jar command . i added code so that you can specify a readerconfig filepath in job.properties . not sure why the spacing ended up off within getreaderconfig . <nl> it may be a good idea to also allow job.properties to specify the expected file format . the current way that hadoop segmentcreation reads file formats gives problems e.g . when uploading a .tsv file ; this pr now allows reading files with any delimiter , but",0.9436235427856445
elastic_elasticsearch/70514,"allow unicode escape sequences in strings . <nl> occationally , it 's useful to be able to use non-printable , <nl> rtl ( right-to-left ) or other non-standard unicode characters <nl> in an eql query . <nl> introducing the standard \uxxxx escape sequence as well as <nl> the variable 0-0 char escape sequence \u { xxxxxxxx } , e.g . : . <para-sep> old style quoting of string , handled as errors in abstractbuilder <nl> antlr4 grammar guarantees there is always a character after the <nl> will be interpreted as regex , so we have to escape it <nl> unknown escape sequence , pass through as-is , e.g : <nl> u+d800—u+dfff can only be used as surrogate pairs and therefore are not valid character codes","occasionally , it 's useful to be able to use non-printable , <nl> rtl ( right-to-left ) or other non-standard unicode characters <nl> in an eql query . <nl> introducing the standard escape sequence as well as <nl> the variable 0-0 char escape sequence , e.g . : .",1616005906,"when a data stream is being auto followed then a rollover in a local cluster can break auto following , <nl> if the local cluster performs a rollover then it creates a new write index and if then later the remote <nl> cluster rolls over as well then that new write index ca n't be replicated , because it has the same name <nl> as in the write index in the local cluster , which was created earlier . <nl> if a data stream is managed by ccr , then the local cluster should not do a rollover for those",0.9520280361175537
OpenAPITools_openapi-generator/7833,add net47 support to the csharp generator <para-sep> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .plg <nl> .opt <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> to test special tags <nl> anotherfakeapi | call123testspecialtags | patch /another-fake/dummy | to test special tags defaultapi | fooget | get /foo | fakeapi | fakehealthget | get /fake/health | health check endpoint fakeapi | fakeouterbooleanserialize | post /fake/outer/boolean | fakeapi | fakeoutercompositeserialize | post /fake/outer/composite | fakeapi | fakeouternumberserialize | post /fake/outer/number | fakeapi | fakeouterstringserialize | post /fake/outer/string | fakeapi | getarrayofenums | get /fake/array-of-enums | array of enums fakeapi | testbodywithfileschema | put /fake/body-with-file-schema | fakeapi | testbodywithqueryparams | put /fake/body-with-query-params | fakeapi | testclientmodel | patch /fake | to test \ ' client\ ' model fakeapi | testendpointparameters | post /fake | fake endpoint for testing various parameters 假端點 偽のエンドポイント 가짜 엔드 포인트 fakeapi | testenumparameters | get /fake | to test enum parameters fakeapi | testgroupparameters | delete /fake | fake endpoint to test group parameters ( optional ) fakeapi | testinlineadditionalproperties | post /fake/inline-additionalproperties | test inline additionalproperties fakeapi | testjsonformdata | get /fake/jsonformdata | test json serialization of form data fakeapi | testqueryparametercollectionformat | put /fake/test-query-paramters | fakeclassnametags123api | testclassname | patch /fake_classname_test | to test class name in snake case petapi | addpet | post /pet | add a new pet to the store petapi | deletepet | delete /pet/ { petid } | deletes a,add ' net47 ' ( .net framework version ) support to the client generator .,1603949090,description of the original pr <nl> > we want to able to unit test our code that uses the generated api code . <nl> in order to do that we need a virtual interface to mock away the <nl> generated api code . <nl> > <nl> > this pr introduces two new config options for the cpprest generator : <nl> > <nl> > ' generateinterfacesforapis ' will generate an abstract base class <nl> ( interface ) for all apis . <nl> > ' generategmocksforapis ' will additionally generate google mock classes <nl> for the apis . this config option of,0.786641001701355
elastic_elasticsearch/71602,remove loop counting in foreach loops <cm-sep> add tests,not loop counting for each loops should be relatively safe as they have a natural ending point . we can consider adding the check back in once we have configurable loop counters .,1618267364,"this adds support for v2 index templates to the cat templates api . it uses the field as <nl> priority in order not to break compatibility , while adding the field to show component <nl> templates that are used from an index template .",0.9251682162284851
apache_flink/15029,whitelist non-critical debug messages <cm-sep> increase resource timeout,"yarn tends to be rather slot when it comes to starting task executors , so we increase the resource timeout to 0 seconds to increase the test stability .",1614328487,"fixes an instability in the where the shutdown of the dispatcher caused a slot allocation to fail , resulting in the job failing , reaching a terminal state and afterwards being removed from zookeeper . <nl> we now prevent the job from reaching a terminal state by enabling a fixed-delay restart strategy . should the allocation fail the jm will retry until the jm itself is being shut down . on shutdown the jm will suspend the job , allowing it to be recovered by other dispatchers . <nl> i verified the fix by re-running the test until i ran",0.9062365293502808
apache_kafka/9850,"; move envelope request parsing out of socketserver <para-sep> : apiversionsrequest is intercepted here to catch the client software name and version . it is done here to avoid wiring things up to the api layer . <nl> until we are ready to integrate the raft layer , these apis are treated as unexpected and we just close the connection . <nl> if forwarding is not yet enabled or this request has been received on an invalid endpoint , then we treat the request as unparsable and close the connection . <nl> we use unsupported_version if the embedded request can not be parsed . the purpose is to disambiguate structural errors in the envelope request itself , such as an invalid client address . <nl> we use unsupported_version if the embedded request can not be parsed . the purpose is to disambiguate structural errors in the envelope request itself , such as an invalid client address .","prior to this patch , envelope handling was a shared responsibility between and . the former was responsible for parsing and validation , while the latter was responsible for authorization . this patch consolidates logic in so that envelope requests follow the normal request flow .",1610143052,"fixed a critical bug where replica followers would inadequately use the leader epoch cache for truncating their logs upon becoming a follower . the root of the issue was that a regression in caused the leader epoch cache to be populated upon becoming a leader , even if the message format was older and did not support epoch caches . this resulted in very sparsely populated caches which the brokers would make use of when becoming a follower , resulting in huge log truncations . <nl> fixed that problem by not updating the leader epoch cache if the message format",0.8439034223556519
apache_ignite/8822,"milti-cell transaction changes may be not visible ( during some time ) after the cellular switch <para-sep> skipping iteration when local node is one of tx 's primary . this future finished with 'cluster is fully rebalanced ' state . * / <nl> this tx was rolled back on recovery because of primary node fail , other backups may be not aware of it . <nl> skipping counters update to keep them the same everywhere without any sync . tx counters will be finalized ( gaps removed ) on local txs recovery finish . each node will have counters equals to latest successful transactions counters . <nl> failed . * / <nl> broken cell . * / <nl> alive cell . * / <nl> originating node . * / <nl> failed node . * / <nl> broken cell 's nodes . * / <nl> alive cell 's nodes . * / <nl> test checks that txs will be recovered on cellular switch if prepared , regardless of their content , as well as upcoming txs will be committed . <nl> tests checks that switch finished only when all transactions required recovery are recovered . based on corner case found at teamcity runs : we have 0 cells , the first contains partitions for k1 , second for k2 . tx with put ( k1 , v1 ) and put ( k2 , v2 ) started and prepared . then node from the first cell , which is the primary for k1 , failed . the second cell ( with key2 ) should not finish the cellular switch before tx recovered , otherwice stale data read is possible . <nl> puts 0 entries , each on it 's own cell . <nl> should be null white tx is uncommitted/unrecovered . <nl> should be available for reading only after recovery happen ( should be not null ) . <nl> get should not happen while tx is not recovered . <nl> allowing recovery . <nl> allowing commit . <nl> awaiting for get on alive cell . <nl> making sure get finished with recovered value . <nl> final check that any transactions are absent . <nl> test checks than non-affected nodes ( alive cells ) finishes the switch asap , that they wait only for the recovery related to these nodes ( eg . replicated caches recovery that affects every node ) . <nl>",milti-cell transaction changes may be not visible ( during some time ) after the cellular switch .,1614091583,this pr contains system views for several sql objects : <nl> * schemas <nl> * tables <nl> * views <nl> * indexes <nl> * table columns <nl> * view columns,0.9802295565605164
hazelcast_hazelcast/18033,"remove the deadlock between clientstatemutex and clusterviewmutex . <nl> we have captured a deadlock in a failing test : . <nl> these two threads are waiting for each other because they are trying to lock same mutexes in reverse order . <nl> in the first stacktrace , a member removed event could cause closing of a member under which will require <nl> the responsibility of closing of the connection is taken from clientclusterservice and given to tcpclientconnectiomanager . <nl> in the second stacktrace , someone closing the connection could potentially couse a reregistration listener under which will requre <nl> fireconenctionremovedevent is offloaded to an executor so that it will not held the mutex when fired . <para-sep> rejectedexecutionexception thrown when the client is shutting down","we have captured a deadlock in a failing test : . <nl> these two threads are waiting for each other because they are trying to lock same mutexes in reverse order . <nl> in the first stacktrace , a member removed event could cause closing of a member under which will require <nl> fix : the responsibility of closing of the connection is taken from clientclusterservice and given to tcpclientconnectiomanager . <nl> in the second stacktrace , someone closing the connection could potentially cause a reregistration listener under which will requre <nl> fix : fireconenctionremovedevent is offloaded to an executor",1609775206,this is so factories have their tenant environment set .,0.8820996284484863
apache_flink/14689,fix temporal join test <para-sep> keep the timestamp in the records are in the ascending order . it will keep the records in the kafka partition are in the order . it has the same effects by adjusting the watermark strategy .,"the reason why the test fails is the records in the same partition are out-of-order . i print the partition-id and offset in the partition . <nl> in the test , the expected record is ` <nl> ` . <nl> it may be the left stream record arrives before the record ` <nl> 0-0-16t01:0:0-0-16t01:0:0 ` have arrived and emits itself . <nl> therefore , we should adjust the order in the partition or watermark strategy . here we just adjust order for convenience . the new order in the partition follows . <nl> - reorder the records in the partition",1611029633,"fix npe when left input is a query ( e.g . a filter/project/temporal join ) in temporal table function join . <nl> - get the reloptschema from the leaf relnode which holds the non-null reloptschema . <nl> - add a plan test that left input is a filter query <nl> - add a it case that left input is a temporal join . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no",0.691373348236084
apache_pulsar/9853,fix schema not added when subscribe a topic without schema <para-sep> bytes schema is treated as no schema <nl> topic1 's schema becomes string now <nl> bytes schema is treated as no schema <nl> topic2 's schema becomes string now .,"when a consumer with a schema subscribes an empty topic without schema , the current check uses , which only checks if the topic can be deleted . however , it should check if there 's any connected producer or consumer of this topic . for current implementation , even if a topic has no active producers of consumers , the topic 's subscription list may be not empty and will return true . then the schema of consumer wo n't be attached to the topic and it will throw an . <nl> - check if the topic has active",1615309614,"when using a multi-broker service url to create a producer , if the connection to the first broker failed , the creation will fail . <nl> add backoff retries when getting partitioned metadata from brokers .",0.9175977110862732
netty_netty/10989,"revert httppostmultipartrequestdecoder and httppoststandardrequestdecoder to sha . <nl> motivation : . <nl> the changes introduced in sha did cause various issues while the fix itself is not considered critical . for now it is considered the best to just rollback and investigate more . <nl> modifications : . <nl> revert changes done in sha ( and later ) for <nl> the post decoders . <nl> result : . <para-sep> it 's safe to call discardbytes ( ) as we are the only owner of the buffer . <nl> there seems to be multiple references of the buffer . let 's copy the data and release the buffer to ensure we can give back memory to the system . <nl> check but do not changed readerindex <nl> force read <nl> write cr ( not followed by lf ) <nl> read one line up to the crlf or lf <nl> write cr ( not followed by lf ) <nl> now check if either opening delimiter or closing delimiter <nl> first check for opening delimiter <nl> error since cr must be followed by lf delimiter not found so break here ! <nl> second check for closing delimiter <nl> now try to find if crlf or lf there <nl> error cr without lf delimiter not found so break here ! <nl> no crlf but ok however ( adobe flash uploader ) minus 0 since we read one char ahead but should not <nl> fixme what do we do here ? either considering it is fine , either waiting for more data to come ? lets try considering it is fine ... <nl> only one '- ' = > not enough whatever now = > error since incomplete read one line up to -- delimiter or -- delimiter -- and if existing the crlf or lf . note that crlf or lf are mandatory for opening delimiter ( -- delimiter ) but not for closing delimiter ( -- delimiter -- ) since some clients does not include crlf in this case . <nl> check conformity with delimiter <nl> delimiter not found so break here ! <nl> now check if either opening delimiter or closing delimiter <nl> first check for opening delimiter <nl> error cr without lf delimiter not found so break here ! <nl> error since cr must be followed by lf delimiter not found so break here ! <nl> same first check for opening",revert httppostmultipartrequestdecoder and httppoststandardrequestdecoder to sha . <nl> motivation : . <nl> the changes introduced in sha did cause various issues while the fix itself is not considered critical . for now it is considered the best to just rollback and investigate more . <nl> modifications : . <nl> revert changes done in sha ( and later ) for <nl> the post decoders . <nl> result : .,1612359719,motivation : . <nl> how we did manage the memory of writev was quite wasteful and could <nl> produce a lot of memory overhead . we can just keep it simple by using <nl> one iovarray . once it is full we can just submit and clear it as at this <nl> point the kernel did take over a copy and its safe to reuse . <nl> modifications : . <nl> use one iovarray and submit once it is full . <nl> result : . <nl> less memory overhead and less code duplication,0.9485388994216919
jenkinsci_jenkins/4835,"extracts tab , panes , tables styles to a module <cm-sep> extract tab & table variables <cm-sep> unwraps view and plugin tables from .pane-frame <cm-sep> update table styles . <nl> - styles are applied to the .bigtable class . there are some changes to .pane-frame <nl> - some styles are inherited from .pane-frame <cm-sep> fix widget styles conflicting with tables . <nl> - differentiates the side-panel widget pane borders from .pane-frame elements <nl> - fix padding spaces on project view header . the functions # nbspindent function was changed to return 0 less spaces <nl> - restored missing border on filtered plugins management table <nl> - fixed the alignment of some tables <cm-sep> restyles the tab baseline and new item button . <nl> - the tabbar.jelly now has a prop to show a baseline . the default display of the baseline can also be themed <para-sep> tabbar links <nl> tabbar baseline <nl> padding : 7px 0px ; <nl> add this fallback because tables with hidden rows will not have a bottom border <nl> pane * / <nl> bigtable * / <nl> for non-full screen table * / <nl> keep this for tables still wrapped by .pane-frame <nl> ========================= sortable table ========================= * / <nl> baseline is hidden by default . see next rule fo adding visibility . * /",this pr revamps the tables and tab styles according to the design briefs provided on the jira ticket . the scope of this pr is limited to tables implementing the class . <nl> screenshots . <nl> - the tables and tabs have updated colors that are consistent with the new jenkins color palette . they are consistent with sidebar and footer . they also have improved in-cell spacing . <nl> - the components are fully themeable . <nl> - tables are no longer supposed to be wrapped in a class . this generated some inconsistencies . tables inside a will,1594194591,"currently : . <nl> for each of the three times that i hit this edge , the difference between and was ' 0 ' . here 's an example : . <nl> i 'm making two changes : <nl> 0. getting the time first instead of second because time ticks forward which means that the later we get it , the more likely it is to be negative and thus ' confusing ' . <nl> 0. including 0,0 milliseconds ( 0 seconds ) of tolerance . <nl> for my system , 0,0 milliseconds ( 0 seconds ) would be enough",0.9229161739349365
apache_pulsar/8842,enable spotbugs for pulsar-io-aws and pulsar-io-aerospike,"* this is a start , enable spotbugs for the pulsar-io module . <nl> * enable spotbugs for pulsar-io-aws and pulsar-io-aerospike . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api : ( yes / no ) <nl> - the schema : ( yes / no / do n't know ) <nl> - the default values of configurations : ( yes / no ) <nl> - the wire protocol : ( yes / no ) <nl>",1607313638,debezium has released the major version v1.version.final . <nl> * upgrade version of debezium from version to version.final . <nl> local integration test,0.8282352685928345
jenkinsci_jenkins/4609,set httponly and secure on cookies to fix spotbugs issue,"after a break from spotbugs , a small one with setting the httponly and secure flags on cookies . <nl> * set httponly header on cookie for iconsize storage",1585390860,add headers x-hudson-job and x-hudson-result to e-mail notification for filtering purposes .,0.9112398028373718
apache_druid/10377,"include sequence-building time in cpu time metric . <nl> meaningful work can be done while building sequences , and we should <nl> count this work . on the broker , this includes subquery processing <nl> work done by the mergeresults call of the groupbyqueryquerytoolchest .","meaningful work can be done while building sequences , and we should <nl> count this work . on the broker , this includes subquery processing <nl> work done by the mergeresults call of the groupbyqueryquerytoolchest .",1599705207,incremental index storage adapter incorrectly returns done for single row indexes,0.9418631792068481
elastic_elasticsearch/70674,fix test to not run as a newer jdbc than server . <nl> fix test simulating running an newer jdbc driver against an older <nl> server . this scenario 's no longer supported .,fix test simulating running an newer jdbc driver against an older <nl> server . this scenario 's no longer supported ( bug fix ) .,1616431778,"an ignore parameter was originally added to the validatejsonagainstschematask <nl> to allow the build to pass for rest specs that did not properly validate <nl> against the schema . <nl> since the introduction of this task , all schemas that did not validate have <nl> been fixed to now validate properly . <nl> this commit removes the ability to ignore specific files for validation . this <nl> allows any consumers the assurance that all rest specs validate against the schema .",0.8947739601135254
elastic_elasticsearch/71548,"simplify mvt end point <para-sep> todo : validation <nl> todo : validation <nl> todo : validation <nl> todo : validation <nl> specific for vector tiles <nl> even if there is no hits , we return a tile with the meta layer <nl> todo : should be expose the total number of buckets on internalgeotilegrid ? <nl> todo : i wonder if we can leverage field and format so what we get in the result is already the mvt commands . <nl> todo : it would be great if we can add the centroid information for polygons . that information can be used to place labels inside those geometries <nl> todo : see comment on field formats . <nl> add geometry <nl> todo : it should be the centroid of the data <nl> add count as key value pair <nl> add aggregations results as key value pair <nl> top term and percentile should be supported <nl> add keys <nl> add values <nl> rest test for _mvt end point . the test only check that the structure of the vector tiles is sound in respect to the number of layers returned and the number of features abd tags in each layer .","this change unifies the mvt end point into one unique call . <nl> the rest interface allow a body with the following optional parameters : . <nl> the generated vector tile will contain up to three layers : . <nl> : always generated , it contains <nl> : one feature per matched document . if is equal to 0 , the layer is not generated . <nl> : each feature represents a buckets on a geo tile aggregation . if s equal to 0 , the layer is not generated .",1618215029,currently we duplicate our specialized cors logic in all transport <nl> plugins . this is unnecessary as it could be implemented in a single <nl> place . this commit moves the logic to server . additionally it fixes a <nl> but where we are incorrectly closing http channels on early cors <nl> responses .,0.9654526710510254
ballerina-platform_ballerina-lang/24284,improve diagnostic reporting to logic to capture additional args <cm-sep> make syntaxerror constructor private <cm-sep> introduce a genric syntax error enum member . <nl> this member should only be used in situations where you can not figure out the exact error <cm-sep> remove unused method <cm-sep> update javadoc in utility methods <cm-sep> improve invalid node reporting logic to capture message args <cm-sep> update remaining invalid node reporting cases in the parser <cm-sep> remove unused classes and method after diagnostic related changes <para-sep> the member represents a generic syntax error we should use this only when we ca n't figure out the exact error <nl> adds the invalid node as minutiae to the next consumed token . this method pushes this invalid node into a stack and attach it as invalid node minutiae to the next token when it is consumed . <nl> adds the invalid node as minutiae to the next consumed token . this method pushes this invalid node into a stack and attach it as invalid node minutiae to the next token when it is consumed . <nl> holds invalid node diagnostic information until the next token is consumed .,"i 've updated methods to capture additional message args . <nl> in addition to the above changes , i 've also fixed the remaining diagnostic related improvements in the new parser .",1592434543,removed the google gson dependency and added fasterxml.jackson for better streaming support . <nl> -contributor : anjana fernando,0.9741048216819763
jenkinsci_jenkins/4597,hide message re disabling implied dependencies when no dependents exist,"i got sick of this warning being shown for mailer plugin , which was detached around version , when all other plugins are on a newer core and would need an explicit dependency . <nl> ( too minor )",1584912637,"the recursive behavior only activates if you access cc.xml with a query parameter named , in case anyone relies on the current behavior . if that seems unlikely , i can make the recursive behavior the default . <nl> * enable cc.xml to export jobs in folders recursively when accessed with a query parameter named recursive . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8971167802810669
Alluxio_alluxio/10892,use source instead of hostname and client id <para-sep> the pattern is instance.name [ .tagname : tagvalue ] * [ .source ] .,use source instead of hostname and client id to identify metrics source,1581471253,"this pr decouples the journal api from its ufs implementation . in particular , it creates , , , and interfaces and hides the ufs implementation behind these interfaces . <nl> in the context of the journal api , we no longer talk about files , directories , and paths . we talk about checkpoints , completed logs , and the current log . the api uses uris to identify these objects and provides methods for working with these objects .",0.9721994996070862
elastic_elasticsearch/71999,add null-field checks to shape field mappers,this commit fixes <nl> that regression and adds a method to mappertestcase <nl> to ensure that all field mappers correctly handle nulls .,1618999701,"currently we always call reduce even when we only have one internalaggregation . in some cases this is necessary but in others the reduce method is just making a copy of itself . this is normally not too expensive excepts for aggregations that hold expensive objects , for example cardinality or percentile aggregations . <nl> in order to prevent this necessary step this pr adds a new abstract method in internalaggregation that flags the framework if it needs to reduce on a single internalaggregation .",0.9304317831993103
Alluxio_alluxio/12172,"fix cp with wildcard and special characters . <nl> previously if we try to use wildcard to copy files in path with special <nl> characters like ' . ' , '+ ' , '^ ' , ' $ ' , ' * ' , the cp will fail . <nl> this test fix the escape function to escape special characters used in <nl> regrex pattern matching . <cm-sep> cherry pick cp with wildcard and special characters <para-sep> tests copying a list of files with special characters in folder name specified through a wildcard expression .","previously if we try to use wildcard to copy files in path with special characters like ' . ' , '+ ' , '^ ' , ' $ ' , ' * ' , the cp will fail . <nl> this test fix the escape function to escape special characters used in regrex pattern matching .",1601595599,fix infinite retries when a directory can not be created in ufs due to permission issue .,0.932841956615448
vespa-engine_vespa/16801,remove allocation on expiry from dirty in dynamically provisioned zones <para-sep> do not keep allocation in dynamically provisioned zones so that the hosts can be deprovisioned,"the condition to remove a dynamically provisioned host is that it has no nodes with allocation . <nl> we want to give the host enough time to clean up and upload node logs to s3 , but if the host is unable to do so , we should just give up after dirty expiry time , clear the allocation , and let it be deprovisioned .",1614867142,"emit metrics on job starts and ends , with status as name and job id as dim .",0.9341796040534973
neo4j_neo4j/11034,always attach cors headers in rest . <nl> previously cors headers were only added to requests that passed auth . <nl> this made js requests from browser unable to receive the actual error <nl> because cors is not allowed with missing headers . <nl> this commit moves the relevant filter to the top of the filter chain so <nl> that every response has cors headers attached . <para-sep> this filter adds the header ' access-control-allow-origin : * ' to all responses that goes through it . this allows modern browsers to do cross-site requests to us via javascript .,previously cors headers were only added to requests that passed auth . this made js requests from browser unable to receive the actual error because cors is not allowed with missing headers . <nl> this pr moves the relevant filter to the top of the filter chain so that every response has cors headers attached .,1518786286,"introducing labelindex.auto which is intended to be used for tooling <nl> where it 's convenient to not have a say in which label index to use , <nl> but let database select which ever label index is present already . <nl> this was driven by a backup scenario where the backup client would <nl> select a different label index than the source . this would work <nl> conceptually ( because it would have been rebuilt ) , but proved to be <nl> troublesome by means of page cache actions for moving files after <nl> temporary store had been started and",0.9614614248275757
grpc_grpc-java/7751,remove some of the static imports in codegen <cm-sep> regenerate code,it 's less readable using static import than using full-qualified method name in-place .,1608688130,in this pr we still only send v2 requests to xds server ( no v3 bootstrap or env flag support ) .,0.9112077951431274
Alluxio_alluxio/10919,alloq super user to stopsync w/o a lock <cm-sep> cleanup logging <cm-sep> remove newline <para-sep> todo ( am ) : remove once we do n't require a write lock on the sync point during a full sync stop sync w/o acquiring an inode lock to terminate an initial full scan ( if running ) <nl> stop sync here only if not terminated w/o holding the inode lock <nl> collects user and groups <nl> checks whether the user is a super user or in super group .,a full scan for active sync acquires a write lock on the syncpoint which prevents the permission check for stopsync to proceed . this pr skips the read lock needed on the inode for the permission check if the user is a super user . this allows us to terminate a long-running full scan early .,1581708895,web ui might fail to load if anything given under prefix is required to load the under file system . <nl> this fix makes the web ui to use which takes properties with prefix when initializing the ufs . <nl> will port to version branch once approved .,0.9187052845954895
neo4j_neo4j/10948,"adding temporal array types . <nl> refactoring all arrayvalue classes to not have single implementation <nl> ' direct ' , but be concrete themselves . <nl> create class nonprimitivearray to capture common behavior of pointarrays , <nl> date/time-arrays and durationarrays . <cm-sep> adding default implementations to values.equals methods . <nl> the equals methods now return false by default . they are still <nl> overridden ( with the exact same implementation ) to be final in <nl> abstract subclasses , where equality can be ruled out for certain values . <nl> this makes the concrete classes shorter , since they only need to <nl> implement the equals method ( s ) which can return true . <cm-sep> fixing some remaining cypherland stuff around temporal values . <cm-sep> adding equality tests to temporal values . <nl> implementing computehash in datetimevalue <para-sep> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> average nbr of seconds on a month does n't imply equality <nl> not the same due to leap seconds <nl> average nbr of days in 0 years does n't imply equality",also fix some remainders around temporal values in some other classes .,1517572479,"the rotation done in physicallogfile only flushed the channel , <nl> i.e . bytes already written to it . it did n't tell the writer to <nl> empty its buffer into the channel first . this could sometimes <nl> result in rotation happening in the middle of a transaction . <nl> all the bytes would be there , just split across files and be <nl> more difficult to read later on if not using proper log version <nl> bridging and would eventually cause problems when first part of <nl> split transaction would be pruned . <nl> this change will have",0.9698165059089661
keycloak_keycloak/6579,support for the wildcard character in sc 's authrole ( spring-boot keycloak adpater with undertow ) <para-sep> support for ' * ' as all roles allowed we clear out the role in the securityconstraints and set the emptyrolesemantic to authenticate but we will set emptyrolesemantic to deny ( default ) if roles are non existing or left empty,"i propose this change to support the wildcard character ( ' * ' ) in the definition of the securityconstraint 's authrole property of the ' spring-boot keycloak adapter ' so that an authentication-only flow can be implemented . at the moment it 's not possible due to the way undertow manages the wildcard character ( securitypatchmatches 's expandrolesallowed ( ) ) . <nl> notice that the change was tested against the version version because the version version-snapshot currently returns an invalid bearer token error . the logs showed an access token value of ' .signature ' , and i",1575828922,rewritten getjsonvalue using oidcattributemapperhelper.splitclaimpath and removed recursion .,0.8472481369972229
ballerina-platform_ballerina-lang/25410,configure and add unit test setup to compiler api module <cm-sep> add api for getting position info of a symbol <cm-sep> add a predefined position for builtin symbols <cm-sep> add position info to let symbol <cm-sep> refactor btypesymbol to add position info <cm-sep> refactor usages createtypesymbol ( ) method <cm-sep> refactor var symbols to include position info <cm-sep> add position info to derivatives of var symbol <cm-sep> refactor usages of createfunctionsymbol ( ) <cm-sep> refactor ns symbol usages <cm-sep> remove unused code <para-sep> test cases for the semantic api . <nl> throw new assertionerror ( ' error ' ) ; <nl> import ballerina/io ;,> - refactor the usages of the symbols to provide the diagnostic position at the time of creation .,1598362155,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9652690887451172
ballerina-platform_ballerina-lang/26688,"allow dependently-typed function declarations <cm-sep> update error message for invalid dependently-typed function <cm-sep> fix compile-time subtyping and add tests <cm-sep> update subtyping rules <cm-sep> disallow non-dependently-typed functions as dependently-typed functions <cm-sep> consider param position for dependently-typed return type subtyping <cm-sep> add referred param index to bparameterizedtype <cm-sep> introduce the bparameterizedtype for the runtime <cm-sep> resolve conflicts and merge master <cm-sep> update bir.ksy for parameterized type param index <para-sep> this is ok , referencing classes/object constructors should have 'external ' implementations . <nl> outparameter ; <nl> this is ok , referencing classes/object constructors should have 'external ' implementations . <nl> outparameter ;",any class or object constructor that references/includes the type has to have an implementation . <nl> - fixes subtyping for objects with dependently-typed methods . <nl> the following is now allowed .,1604076834,"from this pr , first proto will be created and then taking that proto as input a sample bal file will be created . <nl> bal files will vary according to the rpc concepts ( unary , bidirectional streaming , client streaming ) .",0.9760395884513855
elastic_elasticsearch/71575,fix profiled global agg . <nl> this fixes the aggregator when is enabled . it does so <nl> by removing all of the special case handling for aggs in <nl> and having the global aggregator itself perform the <nl> scoped collection using the same trick that we use in filter-by-filter <nl> mode of the aggregation . <para-sep> run sub-aggregations on child documents <nl> add filters from slice or filtered aliases .,this fixes the aggregator when is enabled . it does so <nl> by removing all of the special case handling for aggs in <nl> and having the global aggregator itself perform the <nl> scoped collection using the same trick that we use in filter-by-filter <nl> mode of the aggregation .,1618245443,merges the remaining implementation of into <nl> so that we can more easilly make them work properly without <nl> which should save memory and speed them up .,0.9792081117630005
jenkinsci_jenkins/4710,"upgrade to version version of remoting for lts release . <cm-sep> * websockets : use abstractbytebuffercommandtransport to transport messages . <nl> * depend on timestamped snapshot since incrementals is broken . <nl> * fix reviews . <nl> * update snapshot dep . <nl> * print directly <cm-sep> do not print random binary data during websocketagentstest <cm-sep> * fix git not in path for git plugin global config <nl> git client plugin global configuration allows addition of git implementations using gittool <nl> the field path was not able to identify git executable . the fix involves changing prefix with <nl> file.seperator instead of file.pathseperator . this allows jenkins to find the git exec at the <nl> already existing path . <nl> * tests added to validate fix . <nl> * improve hamcrest comparison in formvalidationtest . <nl> * import matchers for . <cm-sep> - update groovy init hooks to run after all job configurations are adapted . <nl> ( cherry picked from commit sha ) <cm-sep> * websockets : use abstractbytebuffercommandtransport to transport messages . <nl> * depend on timestamped snapshot since incrementals is broken . <nl> * fix reviews . <nl> * update snapshot dep . <nl> * print directly . <nl> ( cherry picked from commit sha ) <cm-sep> use remoting version <cm-sep> - fix spacing between error messages in setup wizard ( regression in version ) . <nl> ( cherry picked from commit sha ) <cm-sep> * read-only extended read view . <nl> * namespace css , add selector for when read-only . <nl> remove select changes . <nl> * revert change that is no longer in use . <nl> * format radioblock . <nl> * disable select . <nl> * reduce diff and rename to read only . <nl> * more whitespace revert . <nl> * add possiblereadonlyfield to wrap content . <nl> * less diff . <nl> * fix missing tag close . <nl> * new line . <nl> * fix another if . <nl> * change if statement to bail out early . <nl> * remove drag and drop re-order when read only . <nl> ( cherry picked from commit sha ) <cm-sep> fix permission check . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> * fix read only password . <nl> * do n't call getpasswordvalue until later . <nl> ( cherry picked from commit","backporting has started and the rc is scheduled for 0-0-0 . <nl> please have look at the changes proposed and rejected so we have a consensus of what goes in by 0-0-0 . <nl> at large , i propose to get the read-only config page changes backported , but to leave the banner rework out .",1588662443,"* rfe : jenkins defines a minimum remoting version and prints warnings when an older version is connected . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9578496813774109
OpenAPITools_openapi-generator/8111,"configure and use import mapping . <nl> this prevents models from being generated which would clash with exisiting dart types , e.g . list . <cm-sep> fix decimal format not supported <cm-sep> remove redundant modeltoignore & ignore dart : core import . <nl> * modeltoignore is now handled via importmappings the same way other generators do this <nl> * choose not to import dart : core as this is available by default <cm-sep> enumclass is a reserved word in built_value <para-sep> these are needed as they prevent models from being generated which would clash with existing types , e.g . list importing dart : core does n't hurt but a subclass may choose to skip dart : core imports . <nl> decimal | double * | | [ default to null ] <nl> / optionally , enum_class can generate a mixin to go with your enum for use / with angular . it exposes your enum constants as getters . so , if you mix it / in to your dart component class , the values become available to the / corresponding angular template . / / trigger mixin generation by writing a line like this one next to your enum . <nl> tests for modelenumclass <nl> decimal | double * | |",* configure and use import mapping <nl> * cleanup import usage in dart-dio <nl> * add decimal support <nl> * handle reserved keywords in dart-dio .,1607349008,"summary <nl> - generators without runtime models conversion use ' original ' property naming by default . it 's still possible to change it via cli options - might be helpful when used together with customized templates . the cli option description has been modified to provide some more context . <nl> - generators with runtime conversion ( typescript-fetch , typescript-node , typescript-reduxquery ) keep using ' camelcase ' . <nl> implementation notes <nl> - i decoupled from . former respects the , while latter keeps always using camelcase . <nl> - refactoring : use an enum instead of string",0.9378836154937744
Alluxio_alluxio/11519,change hms tool version to version <para-sep> the validation tool interface . <nl> runs validation tests . <nl> the validation tool factory interface . <nl> creation must not interact with external services . <nl> the registry of validation tool implementations . <nl> refreshes the registry by service loading classes . <nl> load the validation tool factory from libraries <nl> load the hive metastore validation tool from the default classloader <nl> use the extension class loader of the factory . <nl> catching throwable rather than exception to catch service loading errors <nl> utilities to run the validation tests . <nl> task state . <nl> represents the result of a given task . <nl> output stores stdout if test passed or stderr if error thrown <nl> sets task state . <nl> sets task name . <nl> sets task output . <nl> sets task advice .,hms validation tool depends on hive metastore jar which internally has many dependencies that are conflicts with alluxio dependencies . <nl> shade the whole hms validation tool and put it in alluxio/lib directory . <nl> load the hms validation tool when running hms tests .,1591298461,"0. in fuse openfile , a getstatus rpc is issued , but openfile will also issue a getstatus rpc internally , this redundant rcp is reduced in this pr . <nl> 0. when getting status of a file , or listing status of a directory , cache the status results so that future getstatus and liststatus calls do not need to issue rpcs to master . <nl> this pr introduces a new class to cache path metadata .",0.9772304892539978
elastic_elasticsearch/72487,"[ ml ] increase the default value of xpack.ml.max_open_jobs from 0 to 0 <para-sep> note : this will return here if ismemorytrackerrecentlyrefreshed is false , we do n't allow assignment with stale memory <nl> if this will be the first job assigned to the node then it will need to load the native code shared libraries , so add the overhead for this <nl> note : this will return here if ismemorytrackerrecentlyrefreshed is false , we do n't allow assignment with stale memory use the job_task_name for the appropriate job size <nl> note : this will return here if ismemorytrackerrecentlyrefreshed is false , we do n't allow assignment with stale memory","this commit increases the from 0 to 0. additionally , it ignores nodes that can not provide an accurate view into their native memory . <nl> if a node does not have a view into its native memory , we ignore it for assignment . <nl> this effectively fixes a bug with autoscaling . autoscaling relies on jobs with adequate memory to assign jobs to nodes . if that is hampered by the scaling decisions are hampered .",1619708895,fieldtypelookup implements iterable which is currently only used in indexwarmer to iterate through all field types that have eager global ordinals set to true . implementing iterable makes it hard to track who iterates through all the field types . <nl> this commit exposes a new method that allows to provide a predicate and returns an iterable of all the field types that match the predicate .,0.9382623434066772
Graylog2_graylog2-server/9493,"rename authservicerealm - > usernamepasswordrealm <cm-sep> add skeleton for bearer token realm <cm-sep> add bearer token suitable for auditing <cm-sep> add generic support for token-based auth . <nl> added respective methods to interfaces and classes but did n't yet <nl> implement an actual auth service supporting token-based auth <cm-sep> add default implementation for auth by username/pw <cm-sep> remove obsolete method <cm-sep> move auth service backend binder to pluginmodule <cm-sep> remove wrongly added tostring ( ) method <para-sep> tries to authenticate the user with the given token . <nl> a token to be used for token-based authentication . <nl> type of the token . <nl> credentials will be matched via the authentication service itself so we do n't need shiro to do it <nl> credentials will be matched via the authentication service itself so we do n't need shiro to do it <nl> we encrypt the password before passing it on to reduce the chance of exposing it somewhere by accident . <nl> extract additional session attributes out of a subject 's principal collection . we assume that if there is a second principal , that this would be a map of session attributes .","* adds a shiro realm capable of authenticating users by accepting tokens as input . <nl> * allows authentication service backends to set session attributes . <nl> * includes some minor changes to make writing auth services in plugins easier . <nl> not every authentication scheme involves credentials comprised of a username and a password . in order to provide authentication service backends which operate on opaque tokens , the authentication service framework needs to be extended . <nl> smoke test that ldap authentication is still functional .",1605523768,for the search types there are now entities so we can easily <nl> map the streams during creation and installation of the <nl> content pack . <nl> for the query we needed to add a generic builder access <nl> for the filter so we could change the stream id for <nl> a streamfilter and rebuild the filter refered in the <nl> queryentity and query . <nl> this id needs to be used in all references of the stream . <nl> therefore also in the viewentity where a streamid is persisted . <nl> also when installing this content pack the installed,0.9766988158226013
elastic_elasticsearch/71611,add value ranges for bucket metrics in meta layer <para-sep> top term and percentile should be supported <nl> should not have pipeline aggregations <nl> creates a vector layer builder with the provided name and extent . adds the flatten elements of toxcontent into the feature as tags . <nl> adds the provided key / value pair into the feature as tags . <nl> add keys <nl> add values,"in order to support automatic styling , the consumers of vector tiles need to know the range of values added to the aggs layer . therefore this pr adds this values ranges on the meta later . values are computed using min / max pipeline aggregations . <nl> so for example , there is the document counts range in the form : . <nl> in addition , for any metric aggregation there will be two entries :",1618301562,"this commit reworks the internalclusterinfoservice run asynchronously , <nl> using timeouts on the stats requests instead of implementing its own <nl> blocking timeouts . it also improves the logging of failures by <nl> identifying the nodes that failed or timed out . finally it ensures that <nl> only a single refresh is running at once , enqueueing later refresh <nl> requests to run immediately after the current refresh is finished rather <nl> than racing them against each other .",0.9572531580924988
elastic_elasticsearch/71929,fieldnamesfieldmapper is resposible for building its own metadata document fields <para-sep> return the collection of fields to be added to the _field_names field,"the fieldnamesfieldmapper is a metadata mapper defining a field that <nl> can be used for exists queries if a mapper does not use doc values or <nl> norms . currently , data is added to it via a special method on fieldmapper <nl> that pulls the metadata mapper from a mapping lookup , checks to see <nl> if it is enabled , and then adds the relevant value to a lucene document . <nl> this is one of only two places that pulls a metadata mapper from the <nl> mappinglookup , and it would be nice to remove this method",1618923051,"the 0.x branch has usages of that revolve around types , which can be replaced by adding a couple of specific methods to . <nl> this commit takes care of those as well as a couple of other usages that can be removed .",0.9248467087745667
apache_pulsar/8886,add cmd flag of retain key ordering . <cm-sep> add docs for retain key ordering .,"in this pull request , we expose this cmd flag of and add the docs for this . <nl> the original test can cover this option , so , in this change , no relevant code is added . <nl> - does this pull request introduce a new feature ? ( yes ) <nl> - if yes , how is the feature documented ? ( docs ) <nl> - if a feature is not applicable for documentation , explain why ? <nl> - if a feature is not documented yet in this pr , please create a followup issue for",1607570545,"as a user , we need to add sub-name for the function . adding support to attach custom sub-name .",0.8997297883033752
Graylog2_graylog2-server/9294,return correct paginatedlist results . <nl> - 'total ' should contain the count of all filtered results ( ignoring pagination ) <nl> - 'grand_total ' should contain the count of all results ( also ignoring filters ) . <cm-sep> add documentation for paginatedlist and a simple test <para-sep> creates a paginatedlist,- 'total ' should contain the count of all filtered results ( ignoring pagination ) <nl> - 'grand_total ' should contain the count of all results ( also ignoring filters ) .,1603884887,"the only populated the field of the generated elasticsearch document if the field was filled , but not if the field in the map was being used . <nl> this lead to inconsistent ' exports ' of the internal representation .",0.9293330907821655
hazelcast_hazelcast/18056,<para-sep> get the first page through the ' execute ' request <nl> get the second page through the ' execute ' request <nl> make sure that we cached the plan to avoid failures on automatic schema inference . <nl> no-op <nl> no-op <nl> no-op <nl> no-op <nl> target that is deserialized lazily . the object is unlinked <nl> no-op . <nl> helper interface to deserialize the laze target . reduces coupling between the row and the sql service .,"this pr ensures that top-level key/value objects are not deserialized unless it is absolutely necessary . these objects must be deserialized in one of the following cases : <nl> 0. when the object participates in some expression ( e.g . ) . <nl> 0. when we need an object 's field , and the object is not . <nl> 0. when requested by a user from the . <nl> in all other cases , we just transfer the object in the original form ( or the object itself ) between nodes .",1610617839,added support for executing jet sql statements .,0.9788100719451904
OpenAPITools_openapi-generator/8127,revise wordings for options <cm-sep> update,revise wordings for options to make the explanation a bit shorter .,1607445158,escape special variables with ' var ' .,0.8078059554100037
Graylog2_graylog2-server/9333,"add userservice # loadbyids to get all users for the given ids <para-sep> it makes only a few assumptions , which are common to many graylog entities :",this is required for an upcoming change . <nl> other changes : . <nl> - add <nl> - make protected,1604333942,"on version we added the possibility to repeat alert notifications , allowing users to keep the old behaviour in their alerts while still having some features of the new stateful alerts . <nl> this pr checks the alert history to see when was the last time notifications were send for the alert , and verify that the defined grace period has elapsed before notifying again . <nl> i 'm also adding some tests to ensure that all cases ( or all i though of ) are covered and we do n't break any other case by mistake .",0.9176695346832275
OpenAPITools_openapi-generator/7569,move java specific import mappers to java specific code gen <para-sep> file <nl> file,# # # pr checklist .,1601574963,packagename : specify the prefix to the erl file that generate by openapi-generator . <nl> openapispecname : specify the json file name generated by yaml file,0.7853238582611084
ballerina-platform_ballerina-lang/26836,"migrate bitwise expression evaluation support with tests <cm-sep> migrate logical expression evaluation support with tests <cm-sep> add unary expression evaluation support <cm-sep> add integration tests for unary expression evaluation <cm-sep> fix checkstyle <cm-sep> sync with master <para-sep> unary expression <nl> unary expression evaluator implementation . <nl> todo - add proper syntax for for int and float , after fixing runtime exception . <nl> left shift <nl> signed right shift <nl> unsigned right shift <nl> bitwise and <nl> bitwise or <nl> bitwise xor <nl> logical and <nl> logical or <nl> unary plus operator int <nl> float <nl> decimal <nl> unary minus operator int <nl> float <nl> decimal <nl> unary invert operator int <nl> unary negation operator boolean <nl> bitwise and <nl> bitwise or <nl> bitwise xor <nl> logical and <nl> logical or",- adds ballerina debug expression evaluation support for . <nl> - refactor binary expression evaluation implementation to use new runtime helper methods <nl> - adds integrations tests .,1604999933,fix intermittence integration test failures .,0.9605145454406738
runelite_runelite/12544,"xp tracker : goal time formatting options . <nl> add option to display xp goal times in hours rather than days , since some people find it easier to visualize goals that way . this means hours can go above 0 in xp goals . in addition , add an option for showing the current percentage of an xp goal in the progress bar tooltip . <para-sep> durationdays = 0 or durationhourstotal = 0 or goaltimetype = short if we got here . return time remaining in hh : mm : ss or mm : ss format where hh can be > 0 <nl> minutes and seconds will always be present","add option to display xp goal times in hours rather than days , since some people find it easier to visualize goals that way . this means hours can go above 0 in xp goals . in addition , add an option for showing the current percentage of an xp goal in the progress bar tooltip .",1600892549,this allows players to select from a number of positions where they <nl> would like highlighted player 's names to be drawn relative to the <nl> player 's model .,0.924429714679718
ballerina-platform_ballerina-lang/26169,set statement returns if even one nested returns <cm-sep> add nested retry return tests <cm-sep> add nested transaction return tests <cm-sep> add nested retry transaction return tests,"this is because retry , transaction and retry transaction statements are wrapped inside a lambda function and the result of its invocation is only returned if its body has returns .",1601529876,and fix reference equality of empty xml sequences so that all empty xml sequences are equal to each other .,0.91538405418396
elastic_elasticsearch/70709,add searchable snapshots integration tests for url repositories <para-sep> these directories are shared between the url repository and the fs repository in integration tests <nl> tests expect to have an empty repo <nl> these directories are shared between the url repository and the fs repository in integration tests <nl> it is used in repository-url integration tests to expose a directory created by a regular fs repository .,this commit also increases the max number of pooled http connections,1616491219,"when running ml , sometimes it is best to automatically adjust the <nl> memory allotted for machine learning based on the nodesize <nl> and how much space is given to the jvm . <nl> this commit adds a new static setting for <nl> allowing this dynamic calculation . the old setting remains as a backup <nl> just in case the limit can not be automatically determined due to <nl> lack of information .",0.9590456485748291
apache_pulsar/9514,"expire message by position . <cm-sep> remove debug msg . <para-sep> since we ca n't read the message from the storage layer , it might be an already delete message id or an invalid message id we should fall back to non batch index seek . <nl> if the topic name is a partition name , no need to get partition topic metadata again <nl> if it 's beyond last position of this topic , do nothing . <nl> if given position larger than entry position . <nl> do n't do anything for almost caught-up connected subscriptions <nl> wait at most 0 seconds for sub1 's message to expire . <nl> wait at most 0 seconds for sub2 's message to expire . <nl> wait at most 0 seconds for sub3 's message to expire . <nl> wait at most 0 seconds for rest of sub2 's message to expire . <nl> force to create a topic <nl> create consumer and subscription <nl> expire by position and verify mark delete position of cursor . <nl> expire by position beyond last position and nothing should happen . <nl> expire by position again and verify mark delete position of cursor did n't change . <nl> expire by position before current mark delete position and verify mark delete position of cursor did n't change . <nl> expire by position after current mark delete position and verify mark delete position of cursor move to new position . <nl> expire all messages older than given n ( expiretimeinseconds ) seconds for a given subscription . <nl> expire all messages older than given n ( expiretimeinseconds ) seconds for a given subscription asynchronously . <nl> cmd with option can not be executed repeatedly .","- added test for expire message by position in admin client/admin rest api . <nl> - does this pull request introduce a new feature ? yes <nl> - if yes , how is the feature documented ? docs / javadocs",1612678449,org.apache.pulsar.admin.cli.pulsaradmintooltest # topics <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivetopicapi <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivepolicyupdateandclean <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testdeletewhennosubscriptionswithtopiclevelpolicies,0.9860881567001343
confluentinc_ksql/6558,"add back configs for setting tls protocols and cipher suites <para-sep> vert.x does not yet support a method for setting cipher suites , so we use the following workaround instead . <nl> given <nl> when <nl> then","functionality of the configs and were lost in the jetty - > vert.x migration . this pr adds back the functionality . <nl> there were also some other configs that were n't migrated : <nl> - : i 'm not entirely clear on the expected behavior of this config , particularly because it 's a client config , not a server config . if configured , ksqldb properly passes the config to outgoing clients such as kafka admin clients , producers , consumers , etc . this pr adds support for the config in the ksqldb cli , for use",1604368550,"this new functionality is only available on new kafka brokers and so would unnecessarily restrict compatible ksql - kafka versions . <nl> instead , we use the new api and if its not available we fallback to the older api . <nl> the older api has issues with race conditions and overwriting secret properties . <nl> unit and integration tests are expected for any behavior changes._ .",0.9334211945533752
Alluxio_alluxio/12120,truncate long proto lines <para-sep> the truncated length for a message line . * / <nl> truncates each line of a message to a certain length . <nl> truncates each line of a message to a certain length . <nl> generate lines both short and long <nl> check each line,"when printing a request proto as a log message or exception message , some requests contain large payloads . those large payloads make it difficult to inspect the message . this change truncates individual lines of message .",1600721140,added some options for selecting which timestamp should be displayed when running command .,0.9490171074867249
apache_pulsar/9229,"transaction buffer stable position and lowwatermark implementation . <cm-sep> fix some test <cm-sep> fix some comments <cm-sep> fix some comments <cm-sep> fix the checkstyle <cm-sep> transaction time out implementation . <para-sep> the timeout may wait time longer than the new transaction timeout time , so we should cancel the current timeout and create a timeout wait time is the new transaction timeout time . <nl> no operation <nl> no operation <nl> no operation <nl> no operation <nl> no operation <nl> this because of the transaction commit marker have't delete delete commit marker after ack position when delete commit marker operation is processing , next delete operation will not do again when delete commit marker operation finish , it can run next delete commit marker operation so this test may not delete all the position in this manageledger . <nl> marker is the lastconfirmedentry , after commit the marker will only be write in","when aborting and committing finish we should change the status in transaction coordinator . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options :",1610961467,"add mechanisms to limit the subscribe per consumer to avoid high network bandwidth usage . <nl> by default , the limit mechanisms is close . can enable by broker.conf and namespaces policy . <nl> add mechanisms to limit consumer subscribe times in a period . <nl> if enable the subscribe rate limiter , broker will refuse a consumer subscribe which subscribe times is over more than max subscribe times in a period .",0.9822814464569092
apache_camel/5263,camel-kafka - decouple kafka.partition_key from kafka.key,"i removed the if-else block altogether , as each field may be null during producerrecord instantiation . i also noticed that the original / not-converted key was passed to the constructor , which looks like a bug to me . i changed it accordingly .",1616674279,"] make sure there is a [ jira issue filed for the change ( usually before you start working on it ) . trivial changes like typos do not require a jira issue . your pull request should address just this issue , without pulling in other changes . <nl> [ ] each commit in the pull request should have a meaningful subject line and body . <nl> [ ] if you 're unsure , you can format the pull request title like , where you replace with the appropriate jira issue . <nl> [ ] write a pull request",0.9073376655578613
apache_pulsar/9785,pulsar client : allow to print genericrecord contents,"add two new options to the ' pulsar-client consume ' tool : <nl> - ' -- schema-type ' option , that can be ' bytes ' and ' auto_consume ' in order to select the schema ( in particular you are interested in auto_consume if you are dealing with genericrecords ) <nl> - ' -- hide-content ' boolean option , that shuts down the printing of the contents of the messages , in case they are in binary form or that you are using the tool only to test if any message is coming from the topic . <nl> in",1614782268,"it also provides option to switch back to existing rangeset so , user can flip back to original behavior to avoid any rollback . we will remove option in future release once it will not be experimental . <nl> broker will not face gc-pauses in case client generates large number of unack messages into broker . <nl> i performed perf and functional test on the changes : . <nl> 0. with existing guava range data-structure and large unack msg usecase : <nl> - we can see high gc-pause <nl> - and over 9m objects <nl> - cpu usage around 0",0.9298195242881775
apache_beam/12718,more logging for missing next work index .,this should catch issues earlier and help diagnose the issue,1598631661,"- the state and message streams got a little messy , as they 're <nl> treated as if they 're independent , but at least in this implementation <nl> the message stream is just a superset of the state stream ( assuming that states last long enough to be picked up by both streams ) . to untangle <nl> things a bit , i decided to a ) allow duplicate messages and b ) store <nl> message history , in addition to state history . <nl> - for unit testing , i added library to freeze time at 0 ,",0.8354626297950745
elastic_elasticsearch/71630,fix up backport merge <para-sep> should never occur during processor execution,"the uri parts processor uses the class to parse the input string which is fairly strict in its interpretation of the uri spec and it rejects such characters as non-uri-encoded spaces . in the interest of handling as broad a range of input data as possible , this change attempts to parse the input string using the class which is more lenient if the first attempt to parse with fails .",1618318588,"this removes the deprecated wrapper from <nl> . unlike most other such removals , this is n't likely to <nl> save much memory . but it does make the internals of the aggregator <nl> slightly less twisted .",0.9532861113548279
eclipse-openj9_openj9/9485,"java 0 bufferpool class has moved to a different package . <nl> [ ci skip ] . <cm-sep> update java 0 jvm_ module functions parameters . <nl> related to 0 : during module definition , move conversion of <nl> packages from native to vm . <nl> the signature of jvm_definemodule has been modified from ` ... , const <nl> char const packages , jsize numpackages ... , jobjectarray <nl> packages ` . <nl> also the package parameter of following has been modified from char * to <nl> jstring . <nl> jvm_addmoduleexports <nl> jvm_addmoduleexportstoallunnamed <nl> jvm_addmoduleexportstoall . <cm-sep> java 0 - stub in hidden class support . <nl> [ ci skip ] . <para-sep> [ if java15 ] * / <nl> java15 / [ if java15 ] / todo : implement support for hidden classes . <nl> java15 * /",add implementation of new hidden class apis to unblock the jdk15 builds .,1588867550,apply trusted domaincombiner.combine ( ) from closest doprivileged frame <nl> to protectiondomain instances to be checked later including those <nl> context from embedded accesscontrolcontext such as <nl> accesscontrolcontext.doprivilegedacc and <nl> accesscontrolcontext.nextstackacc . <nl> added a testcase which caused stackoverflowerror without this pr .,0.9419857859611511
apache_flink/14377,the jdbc-connector 's 'lookup.max-retries ' option initial value is 0 in jdbclookupfunction <para-sep> lookup max-retries property less than zero,"…es ' option initial value is 0 in jdbclookupfunction . <nl> the jdbc-connector 's 'lookup.max-retries ' option implementation is different from the meaning . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that",1607936630,"disallow embedded metastore in hivecatalog production code . <nl> embedded metastore can cause weird problems for hivecatalog , e.g . missing dn dependencies . since embedded mode is rarely used in production , we should ban it in hivecatalog production code . this can give users a clearer message when something goes wrong , and makes it easier for dependency management . <nl> - add a boolean parameter to constructor to indicate whether embedded mode is allowed . <nl> - add test . <nl> existing and added test cases . <nl> - dependencies ( does it add or upgrade a",0.9165913462638855
apache_shardingsphere/9202,rename jobconfiguration to handleconfiguration <cm-sep> rename scalingconfiguration to jobconfiguration <cm-sep> rename scalingconfiguration to jobconfiguration <para-sep> scaling server configuration initializer . init server configuration . <nl> handle configuration . <nl> scaling job configuration .,changes proposed in this pull request : <nl> - rename scalingconfiguration to jobconfiguration <nl> - rename jobconfiguration to handleconfiguration,1611822060,changes proposed in this pull request : <nl> - use executioncontext instead of routeresult <nl> - decouple routeresult and routeunit .,0.9751798510551453
hazelcast_hazelcast/18187,"fixes map config parsing . <nl> when overlapping wildcard configs are defined <nl> in declarative config , then it can be the <nl> case that the most specific one inherits <nl> attributes from more generic one during <nl> parsing .","when overlapping wildcard configs are defined <nl> in declarative config , then it can be the <nl> case that the most specific one inherits <nl> attributes from more generic one during <nl> parsing . <nl> the fix in this pr looks for <nl> an exact match instead and creates a new <nl> if none is found .",1613042452,see the original pr for details .,0.8539074659347534
netty_netty/10983,clarify whom is responsible closing the inputstream once sslcontext was build . <nl> motivation : . <nl> it was not 0 % clear whom is responsible calling close ( ) on the inputstream . <nl> modifications : . <nl> clarify javadocs . <nl> result : .,clarify who is responsible closing the inputstream once sslcontext was build . <nl> motivation : . <nl> it was not 0 % clear who is responsible calling close ( ) on the inputstream . <nl> modifications : . <nl> clarify javadocs . <nl> result : .,1612105866,"added comments to linebasedframedecoder , jsonobjectdecoder and xmlframedecoder that they are only compatible with encoded streams . <nl> no code changes , therefore no tests .",0.8679987192153931
runelite_runelite/12506,add new gu'tanoth agility shortcut highlight,"add gu'tanoth agility shortcut highlight . <nl> note that there are two objects you can interact with ( rocks to go up and crumbling wall to leave ) . since the shortcut was a qol update to help people get here , i used rocks for the map text .",1600368863,clue text : . <nl> ' a general who sets a 'shining ' example . ',0.9212098717689514
apache_beam/12957,upgrade version of pubsublite to version . <nl> also change to use pullsubscriber version from lite instead of using an external copy . <para-sep> subscriptionpath.newbuilder ( ) .setlocation ( zone ) .setname ( subscriptionname ) topicpath.newbuilder ( ) .setlocation ( zone ) .setname ( topicname ),also change to use pullsubscriber version from lite instead of using an external copy,1601325138,as discussed in the jira ticket . this can be achieved by using valueproviders . so not worth to clutter the api for this .,0.9430195093154907
crate_crate/10589,"avoid wrapping exceptions in runtimeexception . <nl> changes a few places where we did the runtimeexception dance manually to <nl> re-use and others where we did n't to use <nl> it , to avoid wrapping if not necessary .","changes a few places where we did the runtimeexception dance manually to <nl> re-use and others where we did n't to use <nl> it , to avoid wrapping if not necessary . <nl> motivated by a flaky that sometimes failed because <nl> of a wrapped into a .",1600957783,before on an error only the exception message was printed without the <nl> stacktrace : . <nl> now the the stacktraces are printed as well . this should make it easier <nl> to investigate failures happening on travis or jenkins : .,0.8131972551345825
elastic_elasticsearch/71909,"fix networkutilstests # testnonexistinginterface . <nl> in linux it 's possible that different virtual network interfaces appear <nl> and dissapear during the test execution . networkinterface # isvirtual <nl> only detects interfaces that are created as a child of a physical <nl> interface , veth network interfaces appear as non-virtual interfaces .","in linux it 's possible that different virtual network interfaces appear <nl> and disappear during the test execution . networkinterface # isvirtual <nl> only detects interfaces that are created as a child of a physical <nl> interface , veth network interfaces appear as non-virtual interfaces . <nl> this commit deletes the assertion that checks that all the interfaces <nl> are listed in the exception message , since there 's no way to get <nl> a snapshot of the network interfaces that were available when the exception <nl> message was generated .",1618912540,"testhealthonmasterfailover could timeout on some of the health requests <nl> in the case where an index is added , since the recovery leads to <nl> extended test run time .",0.8067100048065186
apache_shardingsphere/10117,add oracle alter session statement <para-sep> oracle alter session statement . <nl> alter session statement assert . <nl> assert alter session statement is correct with expected parser result . <nl> alter session statement test case .,please check it . i 'll change based on your feedback . <nl> changes proposed in this pull request : <nl> - added sql definition for <nl> - added test cases for,1618584129,"changes proposed in this pull request : <nl> - support mysql store procedure create , alter , drop , call statement parse",0.953029990196228
apache_pulsar/9841,sql add protobuf_native support <para-sep> protobuf have not yet supported cyclic objects . <nl> parse by proto javatype <nl> map <nl> row <nl> list <nl> testutil for protobufnativedecoder . <nl> protobuf3 keytype only support integral or string type <nl> check value <nl> shared = 0 ; <nl> failover = 0 ; <nl> shared = 0 ; <nl> failover = 0 ;,"pulsar sql support for protobuf . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no ) <nl> - anything that affects deployment : ( no )",1615261456,,0.0
apache_pulsar/9107,fix master broker while subscribe to non-persistent partitioned topic without topic auto-creation .,"this looks like a concurrent merge related issue , but i 'm not able to find another pr related to this issue . <nl> this pr is fixing the test that wants to subscribe to a partitioned non-persistent topic but disabled the topic auto-creation . currently , the fix is enabling the topic auto-creation for the test . for non-persistent topics , we do n't persist any metadata for it in the metadata server , so for users who want to use the non-persistent topic , they must enable the topic auto-creation . <nl> if was chosen , please highlight",1609557579,"this issue happens due to stale data into loadbalancer and it tries to split already split bundle . so , it does n't have any functional issue and it would be resolved after a minute as soon as load-manager will get latest data . so , to fix it : load-balancer should get latest data after bundle-split . after reproducing , i am seeing below logs . <nl> generate load-report forcefully if load-manager already derived generation is needed . <nl> load-manager will not try to split bundle based on old load-report which will prevent split-bundle failure .",0.8743759989738464
vespa-engine_vespa/16147,"use the same activation transaction to write lbs <cm-sep> make it possible to wait for resources in resources <para-sep> call to activate to make sure that everything is ready , but do not commit the transaction",": node-repository maintainers assume that once a goes through , the will not fail , but in dynamically provisioned zones will throw s until node 's hosts are . to avoid that , we should instead wait in until the parent hosts are ready , at least for internal deployments ( for external deployments , the transient failures are retried by the controller and each failure provides live feedback to the user in the deployment log about the progress ) .",1611240234,"next step is to run entire node-admin locally , which requires some changes due to maintainer , so will do it in separate pr .",0.9654113054275513
prestodb_presto/15262,"revert ' enable nullifying iterator for broadcast join ' . <nl> this reverts commit sha . <cm-sep> make sure pagesserde is not used in a non thread safe manner <cm-sep> compress broadcast pages in presto on spark to save memory <cm-sep> enforce broadcast memory limits in presto on spark <para-sep> todo : the driver might still oom on a very large broadcast , think of how to prevent that from happening","nullifying iterator does not work if the executor containers are reused , as the broadcast variables persistent between tasks . nullifying a broadcast variable will make it invalid for the next task run on the same executor . <nl> as a workaround for increased broadcast memory on executors compression has been added and additional check for broadcast size is added .",1601667056,canonicalize valuesnode as it may contain correlated symbols .,0.7815068364143372
vespa-engine_vespa/16645,"simplify <cm-sep> shuffle node moves <para-sep> shuffle nodes so we did not get stuck if the chosen move is consistently discarded . node moves happen through a soft request to retire ( prefertoretire ) , which node allocation can disregard <nl> returns whether this can be replaced by any of the reserved candidates * /","since we switched to soft request to retire ( ) , node allocation <nl> may choose to ignore the request . this combined with suggesting node <nl> moves in the same order on every iteration may result the getting <nl> stuck . <nl> example case where this can happen : . <nl> 0. a cluster has _nodea_ and _nodeb_ on the same switch . <nl> suggests moving , because that is the first suggestion and it does not <nl> consider any other constraints . <nl> 0. decides that is the best node on its switch because <nl> of some other",1614092177,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9022520184516907
keycloak_keycloak/7214,add userinfo check fix and associated tests .,this very small edit adjusts the the way the oidc userinfo endpoint is accessed to make sure it 's always accessed if the ui checkbox is not disabled . previously it would be skipped in many cases due the third portion of the check on line 0 .,1593417850,"moved all the heavy lifting , which is mostly db-related , to the dedicated method . this can be optionally deferred by providing a implementation . on quarkus , this is essential since many critical subsystems ( e.g logging , agroal ) are not yet ready when you 're inside the application constructor .",0.8129936456680298
netty_netty/10943,"ignore priority frames for non existing streams and so prevent a npe . <nl> motivation : . <nl> unfortunally it didnt correctly guard against the possibility to receive a priority frame for an non-existing stream , which resulted in a npe . <nl> modifications : . <nl> - ignore priority frame for non existing stream <nl> - correctly implement equals / hashcode for defaulthttp2priorityframe <nl> - add unit tests . <nl> result : . <para-sep> the stream was not opened yet , let 's just ignore this for now .","motivation : . <nl> unfortunally it didnt correctly guard against the possibility to receive a priority frame for an non-existing stream , which resulted in a npe . <nl> modifications : . <nl> - ignore priority frame for non existing stream <nl> - correctly implement equals / hashcode for defaulthttp2priorityframe <nl> - add unit tests . <nl> result : .",1610709848,"motivation : . <nl> when decoding , if the record contains compression pointers , and not all compression pointers are decompressed , but part of the pointers are decompressed . then when encoding the record , the compressed pointer will point to the wrong location , resulting in bad label problem . <nl> modification : . <nl> pre-decompressed record rdata that may contain compression pointers . <nl> result : .",0.9560969471931458
ballerina-platform_ballerina-lang/24780,create extended language server services spi . <cm-sep> move extendedlanguageclient into lang-server-commons . <para-sep> extended language client interface . <nl> extended languageclientaware interface . <nl> represents the data model for semantic highlighting information . <nl> represents the data model for semantic highlighting params . <nl> represents extended language server service interface . <nl> initialize callback for the service . <nl> callback when client connected . <nl> callback for shutdown . <nl> callback for exit . <nl> returns remote interface for the extended service . <nl> model class for trace log . <nl> provides capabilities for the extended language server services .,"currently , this is done with adding annotation for the extendedlanguageserver interface of the ballerina language server . this approach has several issues including all the extending services needing to be added as dependencies to the language-server-core module . <nl> > <nl> > new approach is to provide an spi interface called where extending service developers can provide extended services from anywhere as long as it is available to the lang-server java classpath . <nl> > . <nl> main/src/java/demo/ifooservice.java . <nl> main/src/java/demo/fooservice.java . <nl> meta-inf/services/org.ballerinalang.langserver.commons.service.spi.extendedlanguageserverservice .",1594880916,"we should able to create a channel without initiating any structs . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why .",0.9558327198028564
apache_kafka/9727,initial changes to cogrouped processor <cm-sep> adding view <cm-sep> adding testing <para-sep> aggregation requires materialization so we will always enable sending old values,changes the cogrouped processor from to to allow for sending old values . extends instead of to implement sending old values and the method .,1607617238,"as of version , producer.inittransactions may throw a timeoutexception , which is retriable . streams should retry instead of crashing when we encounter this exception . <nl> reviewers : guozhang wang , matthias j. sax , bill bejeck .",0.9615158438682556
elastic_elasticsearch/70573,"this aims at making the shrink action retryable . every step is <nl> retryable , but in order to provide an experience where ilm tries <nl> to achieve a successful shrink even when the target node goes <nl> missing permanently or the shrunk index can not recover , this also <nl> introduces a retryable shrink cycle within the shrink action . <nl> the shrink action will generate a unique index name that 'll be the <nl> shrunk index name . the generated index name is stored in the lifecycle <nl> state . <nl> if the shrink action ends up waiting for the source shards to <nl> colocate or for the shrunk index to recover for more than the configured <nl> setting , it will move back <nl> to clean up the attempted ( and failed ) shrunk index and will retry <nl> generating a new index name and attempting to shrink the source <nl> to the newly generated index name . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan <para-sep> a node is removed during the action . no node has enough disk space to host the source index 's shards . { es } can not reallocate the shrunken index due to conflicting allocation rules . <nl> deletes the index identified by the shrink index name stored in the lifecycle state of the managed index ( if any was generated ) <nl> the current managed index is a shrunk index <nl> if the source index does not exist , we 'll skip deleting the ( managed ) shrunk index as that will cause data loss <nl> if the shrink index was not generated there is nothing to delete so we move on <nl> even if not all nodes acked the delete request yet we can consider this operation as successful as we 'll generate a new index name and attempt to shrink into the newly generated name <nl> we can move on if the index was deleted in the meantime <nl> failures encountered whilst executing the wrapped action will be propagated directly . <nl> index must have been since deleted , ignore it <nl> checking the threshold after we execute the step to make sure we execute the wrapped step at least once ( because time is a wonderful thing ) <nl> return true if the threshold was surpassed and false otherwise <nl> generates","this aims at making the shrink action retryable . every step is <nl> retryable , but in order to provide an experience where ilm tries <nl> to achieve a successful shrink even when the target node goes <nl> missing permanently or the shrunk index can not recover , this also <nl> introduces a retryable shrink cycle within the shrink action . <nl> the shrink action will generate a unique index name that 'll be the <nl> shrunk index name . the generated index name is stored in the lifecycle <nl> state . <nl> if the shrink action ends up waiting",1616085122,"this commit allows coordinating node to account the memory used to perform partial and final reduce of <nl> aggregations in the request circuit breaker . the search coordinator adds the memory that it used to save <nl> and reduce the results of shard aggregations in the request circuit breaker . before any partial or final <nl> reduce , the memory needed to reduce the aggregations is estimated and a circuitbreakingexception is thrown <nl> if exceeds the maximum memory allowed in this breaker . <nl> this size is estimated as roughly version times the size of the serialized aggregations that need",0.9835973978042603
apache_druid/10479,"fix compaction task slot computation in auto compaction <para-sep> returns true if this task can run in the parallel mode with the given inputsource and tuningconfig . this method should be synchronized with compactsegments.isparallelmode ( clientcompactiontaskquerytuningconfig ) . <nl> returns the maximum number of task slots used by one compaction task at any time when the task is issued with the given tuningconfig . <nl> max number of task slots used in parallel mode = maxnumconcurrentsubtasks + 0 ( supervisor task ) <nl> returns true if the compaction task can run in the parallel mode with the given tuningconfig . this method should be synchronized with parallelindexsupervisortask.isparallelmode ( inputsource , parallelindextuningconfig ) . <nl> dynamic partitionsspec will be used if getpartitionsspec ( ) returns null","the auto compaction does n't currently consider whether or not compaction tasks run in a parallel mode . this leads to an inaccurate task slot computation , so that the auto compaction use more or less task slots than configured",1601921416,this patch properly applies the requested extractionfn to missing columns . <nl> it 's important when the extractionfn maps null to something other than null .,0.9615334272384644
neo4j_neo4j/11347,make extract ( ) eager <cm-sep> move test to better home <cm-sep> make filter ( ) eager <para-sep> given <nl> when <nl> then <nl> extract <nl> filter,"stop and being lazy , which could cause problems in bolt serialization when the cypher-help statement had been closed on the last result . their lazyness could also yield incorrect results , if part of the mapping of filter was modified by a later clause . <nl> changelog : under some circumstances cypher queries using would hang indefinitely when accessed over bolt , if the result of extract was returned . this issue has been fixed .",1521723637,"the problem is that if the <nl> latter is used in a static context can not see single test failures , <nl> hence it will effectively delete the files on disk . this is <nl> problematic when there are failures in ci and we need logs to <nl> understand what happened for debugging purposes .",0.9440420866012573
apache_beam/13151,upgrade gax-java version and grpc version,grpc version has two important changes ; <nl> - conscrypt-related optimization in the alts protocol <nl> - bdp-estimator fix,1603212993,"this change modifies the bigquerytornadoes cookbook example to use the <nl> new bigquery storage api when reading from bigquery , including the use <nl> of column selection . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9203509092330933
apache_kafka/9736,"add a timestamp payload generator and record processor . <para-sep> this is the spec to pass in to be able to run the workload . this allows for customized and even variable configurations in terms of messages per second , message size , batch size , key size , and even the ability to target a specific partition out of a topic . this has several notable differences from the producebench classes , namely the ability to dynamically control flushing and throughput through configurable classes , but also the ability to run against specific partitions within a topic directly . this workload can only run against one topic at a time , unlike the producebench workload . the parameters that differ from producebenchspec : - used to instruct the kafkaproducer when to issue flushes . this allows us to simulate variable batching since batch flushing is not currently exposed within the kafkaproducer class . see the interface for more information . - used to throttle the configurableproducerworker based on a calculated number of messages within a window . see the interface for more information . - this class only supports execution against a single topic at a time . if more than one topic is specified , the configurableproducerworker will throw an error . - specify a specific partition number within the activetopic to run load against , or specify to allow use of all partitions . here is an example spec : { ' startms ' : 0 , ' durationms ' : 0 , ' producernode ' : ' trogdor- ' , ' bootstrapservers ' : ' some.example.kafka.server:0 ' , ' flushgenerator ' : { ' type ' : ' gaussian ' , ' messagesperflushaverage ' : 0 , ' messagesperflushdeviation ' : 0 } , ' throughputgenerator ' : { ' type ' : ' gaussian ' , ' messagespersecondaverage ' : 0 , ' messagesperseconddeviation ' : 0 , ' windowsuntilratechange ' : 0 , ' windowsizems ' : 0 } , ' keygenerator ' : { ' type ' : ' constant ' , ' size ' : 0 } , ' valuegenerator ' : { ' type ' : ' gaussiantimestamprandom ' , ' messagesizeaverage ' : 0 , ' messagesizedeviation ' : 0 , ' messagesuntilsizechange ' : 0 } , ' producerconf ' : { ' acks ' : ' all '",this allows us to run highly granular and configurable workloads to directly simulate customer scenarios and measure the end to end latency all within trogdor . <nl> this creates a new workload that can be used to tune many parts of the workload better than the workload . <nl> this also creates all the helper classes for the workload . <nl> this adds a new parameter to the workload to allow for processing of records after polling them . <nl> this also adds a new e2e latency test utilizing the new record processor within the workload . <nl> the configurableproducer,1607716396,* added pluginstest file which did not exist before <nl> * removed converter : :configure test case <nl> * removed headerconverter test plugin and test cases <nl> * removed converter types test cases <nl> * removed classloader control test cases .,0.9803855419158936
prestodb_presto/15288,bump aws-sdk to version <nl> needed for eks presto deployments - eks feature to grant iam to k8s service account <cm-sep> allow prestos3filesystem and gluehivemetastore to assume an aws role . <para-sep> instance credentials are disabled by default,"if release note is not required , use : .",1602147803,useragent can be used to store spark application id .,0.85066157579422
vespa-engine_vespa/16778,nonfunctional changes <cm-sep> let the system settle before maintenance starts <para-sep> necessary guarantees for this being invoked from only a single thread .,delay initial maintenance by 0 seconds . <nl> if we 're starting an entire system it 's not helpful to start maintenance while things are still coming up .,1614844934,make sure to merge with other pr .,0.8166006803512573
elastic_elasticsearch/70689,"manage fleet system indices within elasticsearch . <nl> this commit moves the management of seven system indices that are used <nl> by fleet to an elasticsearch plugin . the mappings were taken largely <nl> untouched from the fleet server project , with the exception of adding <nl> a _meta field with a version key to enable the system indices <nl> infrastructure to manage these indices .","this commit moves the management of seven system indices that are used <nl> by fleet to an elasticsearch plugin . the mappings were taken largely <nl> untouched from the fleet server project , with the exception of adding <nl> a _meta field with a version key to enable the system indices <nl> infrastructure to manage these indices .",1616443201,"this adds support to expand data streams when resolving , or missing ' include all ' wildcards <nl> and resolve the backing indices according to the configured wildcard expansion options ( ie . if some <nl> backing indices are closed they will not be resolved if closed indices are not desired ) .",0.949288547039032
ballerina-platform_ballerina-lang/26121,"add several node implementations . <nl> importdeclarationnode , servicedeclarationnode , explicitnewexpressionnode , parenthesizedarglist , servicebodynode , qualifiednamereferencenode , returntypedescriptornode , optionaltypedescriptornode , expressionstatementnode , checkexpressionnode , remotemethodcallactionnode , simplenamereferencenode , typedefinitionnode , singletontypedescriptornode <cm-sep> add some more nodes . <nl> whilestatementnode , bracedexpressionnode , assignmentstatementnode , compoundassignmentstatementnode , dostatementnode , foreachstatementnode , binaryexpressionnode , onfailclausenode , returnstatementnode , functioncallexpressionnode <cm-sep> fix formatting issues",* importdeclarationnode <nl> * servicedeclarationnode <nl> * explicitnewexpressionnode <nl> * parenthesizedarglist <nl> * servicebodynode <nl> * qualifiednamereferencenode <nl> * returntypedescriptornode <nl> * optionaltypedescriptornode <nl> * expressionstatementnode <nl> * checkexpressionnode <nl> * remotemethodcallactionnode <nl> * simplenamereferencenode <nl> * typedefinitionnode <nl> * singletontypedescriptornode <nl> * whilestatementnode <nl> * bracedexpressionnode <nl> * assignmentstatementnode <nl> * compoundassignmentstatementnode <nl> * dostatementnode <nl> * foreachstatementnode <nl> * binaryexpressionnode <nl> * onfailclausenode <nl> * returnstatementnode <nl> * functioncallexpressionnode .,1601266226,"this is supported only in contract first approach . <nl> and generate ballerina source code using ballerina inbuild proto compiler tool . generated source code looks like , .",0.9233323931694031
apache_kafka/10185,": wait for mm2 auto-created the topic <para-sep> make sure the topic is auto-created in the other cluster <nl> make sure the topic is auto-created in the other cluster <nl> retrieve the consumer group offset from backup cluster <nl> pinpoint the offset of the last partition which does not receive records <nl> offset of the last partition should exist , but its value should be 0 <nl> make sure the topic is created in the other cluster <nl> make sure the topic is created in backup cluster <nl> wait for the topic created on the cluster <nl> make sure the consumer group offsets are synced to expected number","the reason why the test sometimes failed with : is because we tried to create the topic that the mm2 already help us created . that is , . <nl> note : after mm2 replicate the topic , the topic partition number will also get increased to the in the end . so , we should just let mm2 help us create topic . also fix 0 issues in the tests : <nl> 0. we had resource leak due to no close the adminclient .",1614048266,"while working on consolidating the various store unit tests i uncovered some minor ' bugs ' in the in-memory stores ( inconsistencies with the behavior as established by the rocksdb stores ) . <nl> - open iterators should be properly closed in the case the store is closed <nl> - fetch/findsessions should always throw npe if key is null <nl> - window end time should be truncated at long.max_value rather than throw exception . <nl> ( verified in-memory stores pass all applicable rocksdb tests now , unified unit tests coming in another pr ) .",0.9272239804267883
confluentinc_ksql/6312,update integration tests to work with non-kafka keys <cm-sep> update tests <cm-sep> update client integration test to use json keys,"this pr updates integration tests to work with non-kafka keys and updates clientintegrationtest to use json keys , which validates that the new api endpoints behave as expected with non-kafka keys . <nl> three commits : <nl> - remove hard-coding of kafka serdes from integrationtestharness , and update testdataproviders accordingly <nl> - update integration tests in light of changes above <nl> - update clientintegrationtest to use json keys . <nl> test-only change .",1601401349,"this is preparatory work to make it easier to add support for elements later . <nl> the new class holds an ordered list of s that make up the value fields . <nl> it checks for duplicate field names . later it will be enhanced to hold key fields too . <nl> has been beefed up to check for reserved field names . <nl> some small refactoring to remove unnecessary code from these types . <nl> added more tests around tableelement + new key-schemas.json qtt test , which will be enhanced in the new pr .",0.9853289723396301
apache_pulsar/9400,"op.cmd may be null , cause npe","check msg = op.cms == null , so use op.cmd . readablebytes ( ) may throw npe",1612181251,"we take the first row in the extracted table for example . <nl> when call , cursor.readposisition is 0:0 , however , when using cursor.readpostition to construct opreadentry , it use the cursor.readposition to construct op.readpostition . due to cursor.readposition not exist in managedledger ledgers map , return the earliest available ledger position , and set op.readposition to 0:0 , but the cursor.readposition still 0:0 . <nl> when call according to the constructed opreadentry , it call . the key variables as follow . <nl> thus , it will go into the following branch . <nl> finally , it call",0.8289274573326111
apache_pulsar/8821,make module gradually conform checkstyle . <cm-sep> make module gradually conform checkstyle . <cm-sep> make module gradually conform checkstyle . <cm-sep> make module gradually conform checkstyle . <para-sep> get the domain of the topic ( whether it 's persistent or non-persistent ) . get the list of namespaces ( on every cluster ) for a given property . <nl> redirect the call to the specified broker .,this pr changes code style related things only,1607055335,there are several connectors ( sources/sinks ) related admin apis and rest endpoints that reside within functions admin api and rest endpoints which is n't necessary any more since sources and sinks having their own separate admin api and rest api now . <nl> also move getting a complete list of connectors ( sources and sinks ) for a worker from functions rest api to worker api since that more sense .,0.878699541091919
Alluxio_alluxio/11159,"make parallel sync threads configurable <para-sep> : number of parallel threads to use to sync with the udb . if too large , <nl> keep track of the status of each syncing table . synchronization is necessary if accessed concurrently from multiple threads keeps track of how many tables have been synced <nl> only log at regular intervals , or when complete <nl> compute percentage , cap at 0 % <nl> create a thread pool to parallelize the sync <nl> if invalid , set to the default <nl> shutdown the thread pool <nl> this should be larger than numthreads , to guarantee all threads are utilized",this adds a configuration parameter to specify the number of threads to use for syncing a database .,1584032747,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9821704030036926
ballerina-platform_ballerina-lang/24784,"allow redirection for non-safe methods <para-sep> when performing redirect operation for non-safe method , message needs to be built before sending out the to keep the request message to subsequent redirect . <nl> build message for for multipart requests <nl> get the http method that should be used for redirection based on the status code .","> existing implementation serves auto redirection only for get and head methods as there was a requirement of getting user consent before performing redirection for non-safe http methods in rfc2616 . but that requirement has been dropped in rfc7231 and if the user enables redirect config in the client configuration , then it also implies the consent as the redirection is disabled in http client by default . <nl> > also , rfc7231 and rfc7538 specify that 0 and 0 should not allow changing the request method from post to get . that means a post request should be repeated",1594884025,this would make both the following valid : .,0.9067665338516235
elastic_elasticsearch/71044,cleanup and optimise code . <nl> cleanup unused code and minor code optimisations .,cleanup unused code and minor code optimisations .,1617100344,this is simpler to reason about <nl> because the mapping snapshot is immutable .,0.9531431198120117
apache_druid/10463,"adjustments to kafka integration tests to allow running against azure event hubs in kafka mode <para-sep> there is probably a better way to do this ... <nl> given some config input , such as druid.test.config.properites.a.b.c=d calling jsonparser.readvalueas ( map.class ) here results in a map that has both nested objects and also flattened string pairs , so the map looks something like this ( in json form ) : { ' a ' : { ' b ' : { ' c ' : ' d ' } } } , ' a.b.c ' : ' d ' } the string pairs are the values we want to populate this map with , so filtering out the top level keys which do not have string values leaves us with { ' a.b.c ' : ' d ' } from the given example , which is what we want <nl> do nothing","additionally , an option to disable transaction tests ( azure event hubs does not support kafka transactions ) in . note that this pr does not actually add any new integration tests , it just allows more configurability making this stuff possible . <nl> with these adjustments i was able to run and with all tests passing by overriding the kafka configs with something like this : . <nl> for , i encountered an exception in the test itself with the admin client api trying to change the partition count for : . <nl> so it can not be run",1601618885,turning immutabledruiddatasource into a data container . immutabledruiddatasource 's equals ( ) and hashcode ( ) should throw unsupportedoperationexception as well as druiddatasource 's methods do .,0.9494006633758545
Alluxio_alluxio/11158,"add option to disable web ui pages <cm-sep> checkstyle <para-sep> if the web ui is disabled , disable the resources and servlet together . <nl> todo ( william ) : consider a rewrite rule instead of an error handler <nl> if the web ui is disabled , disable the resources and servlet together . <nl> todo ( william ) : consider a rewrite rule instead of an error handler","this change adds a property to disable web ui for master and worker . some users , for security reasons , need to disable the ui . <nl> the restful endpoints like will still be available . <nl> the metric endpoints like will still be available . <nl> only the web ui pages ( together with the servlet that serves them ) are disabled by this option .",1584023836,setting ' alluxio.underfs.object.breadcrumbs.enabled ' to false will disable breadcrumb creation when doing a ' list ' operation .,0.9215003848075867
eclipse-openj9_openj9/10754,"clean up . <cm-sep> detect incomplete elf core files . <nl> * validate segments are within the bounds of a core file . <para-sep> list to keep track of all the files that have been opened by this dump reader <nl> store it to throw later <nl> close the handle to the dump now close any open module handles <nl> close any tracked open files <nl> release any resources acquired for library resolution <nl> the executable into _modules . file looking for which are libraries and iterating through the debug information within the executable . we may find the executable either on disk , within the core file as one of the loaded segments , or appended to the core file by library collections . consolidate the list of libraries that we find from the debug information with the list from the core file to build the best list possible . when constructing the module objects , use the best available data . this means using the section header information from the collected libraries if present since this is always more reliable than that in the core file . appended to the core file . in this case all that is really wanted is a list of the names of the libraries to guide the collection but this method does not discriminate and constructs everything possible , reading section header tables and symbol tables and so on . in this case the aim is to return the most complete list of modules , examining both the modules within the core file and the list that can be found from the debug data in the executable . each module - as for example when called from jdmpview . in this case the collected libraries may or may not be appended to the core file but if they are then the section header information is always better when taken from the collected library so the modules should be constructed from the them . depends on whether it was found and returned in circumstance 0. todo refactor so that the code paths for the two circumstances are not so entwined . separate out the the best possible image of each library , using core and collected library , only needed for the second circumstance . there are three sorts of module , too . libraries e.g . ld-linux.so.0 . these only have the",* validate segments are within the bounds of a core file . <nl> first commit includes significant cleanup : <nl> * format <nl> * remove trailing whitespace <nl> * use only leading tabs <nl> * add missing annotations <nl> * remove redundant initializations <nl> * remove redundant type parameters <nl> * remove unused local variables <nl> * make fields and classes where appropriate <nl> * remove redundant throws clauses <nl> * use,1601489054,* provide object names ( as strings ) to <nl> * defer creation of objects <nl> * refactor notifications through <nl> * remove useless class <nl> * defer loading of the <nl> * replace lambdas with anonymous classes <nl> * do n't force loading unnecessarily <nl> * do n't start prematurely <nl> * use where appropriate <nl> * do n't pre-allocate a memoryusage instance in .,0.9747922420501709
apache_pulsar/9782,add npe check for pulsarservice # getadminclient,"if user set incorrect config , the would throw npe and the error logs is not clear . for example , start a standalone pulsar with , some admin apis that do n't involve work well , however some admin apis like will throw npe with following logs : . <nl> after this pr , the logs became : . <nl> - check if is null in and give a human readable error message . <nl> this change is a trivial rework / code cleanup without any test coverage .",1614762225,"when i use oracle jdk version，the broker metrics will export as follow : . <nl> and then prometheus will failed when parsing . <nl> the reason is when using to collect jvm info , it returns jvm vendor with , and in the pulsar source code , it adds in both sides , so it comming with , and prometheus parse failed .",0.8243559002876282
apache_druid/10650,"load segments with segment files check <cm-sep> add more java docs <cm-sep> done <cm-sep> add java docs <cm-sep> revert misc <para-sep> check data intact . <nl> if there is 'downloadstartmarker ' existed in localstoragedir , the segments files might be damaged . because each time , druid will delete the 'downloadstartmarker ' file after pulling and unzip the segments from deepstorage . downloadstartmarker existed here may mean something error during download segments and the segment files may be damaged . <nl> make sure segments files in loc is intact , otherwise function like loadsegments will failed because of segment files is damaged . <nl> if last load/drop request status is failed , here can try that again","there are two minor shortcomings in druid historical loading , which can be enhancement to improve the robustness . <nl> fitst : <nl> when historical start up or do compact action , druid will check segments are loaded or not . <nl> the existing logic is based on whether the directory exists . when directory exists but segment files are damaged during download and unzip from deepstorage , like crashed , this simple check will pass . what 's worse is that any action using this segments like segment loading or datasource compaction will fail unexpectedly . <nl> if last",1607334570,"was not actually testing sync behavior disabled , and had the incorrect url specified in the mock expect , causing it to just spin forever in retry utils instead of test the behavior . <nl> was doing the correct thing , but a hard coded 0 second timeout in was causing it to spin for an extra minute each retry loop . i refactored the hard coded value to be a property on that defaults to 0 seconds ( mainly so that tests could override , but also just to not be hard coded ) .",0.9300104379653931
apache_flink/14469,"remove unused code <cm-sep> move logging of resource declaration to slot pool <cm-sep> centralize skipping declaration of unchanged requirements . <nl> there are multiple events where resource requirements might not actually change , and so far the user of the slot pool was responsible for checking that the requirements have actually changed to prevent unnecessary rpc calls . <nl> since this is something that every user should check , we might as well always do this automatically . <cm-sep> extend slot pool logging . <nl> - log total acquired resources when declaring requirements , or after accepting new / releasing idle slots <nl> - log if an offer could not be matched to any requirement <cm-sep> do not rematch freed slots . <nl> when a slot was freed the slot pool was trying to find another requirement it could potentially fulfill , using the same code paths as for newly offered slots , which also includes an increase in acquired resources . <nl> as a result we were potentially counting a single slot as multiple resources , causing an inconsistent state . the slot pool hence believed it had enough slots to fulfill the requirements , causing it to reject slots , while the scheduler was waiting for enough slots to arrive and the rm repeatedly trying to provide the actually required slots . <nl> while it is not necessarily a bad thing to try an find another matching requirement , it is currently not necessary to do so , since the scheduler will use slots however it sees fit anyway . in the worst case we go through another slot allocation cycle . <nl> as such freed slots now remain assigned to the originally matched requirement , and this mapping will only change whe the slot is explicitly reserved for a different requirement . <nl> in the long-term it would be desirable for the slot pool to automatically adjust the matching if a slot was freed . this could prevent cases where we request new slots although we still have idling slots around that we could use , or release slots as idle although there are still outstanding requirements . <nl> however this needs a more sophisticated approach , it has to account for cases where : <nl> - a freed slot could not be matched to another requirement ( i.e. , it is truly an excess resource )","when a slot was freed the slot pool was trying to find another requirement it could potentially fulfill , using the same code paths as for newly offered slots , which also includes an increase in acquired resources . <nl> as a result we were potentially counting a single slot as multiple resources , causing an inconsistent state . the slot pool hence believed it had enough slots to fulfill the requirements , causing it to reject slots , while the scheduler was waiting for enough slots to arrive and the rm repeatedly trying to provide the actually required slots",1608666988,"this pull request set to be false if was not specified . <nl> add unit case to cover . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos , zookeeper : ( no",0.9103639721870422
vespa-engine_vespa/15979,"revert ' revert ' remove unnecessary component ' ' <cm-sep> component is not used anymore <para-sep> verifies that given hosts are available for use by tenant . <nl> delete app , add tenant again and deploy","now also uses just 0 host registry , with application id as key , whereas we earlier used 0 ( one with application id as key and one with tenant name as key ) .",1610310283,"this is the first in series of prs to fix . <nl> currently , we have is a wrapper for the 's , which is the source of . this connection is removed with this pr . in is now a simple data class which stores the metrics in memory ( same as before ) , without forwarding them to . the reasoning being that <nl> 0. there is no easy way to feed metrics directly from to any metrics collection service due to need for format conversion . <nl> 0. even if we could get metrics in the format",0.9710646271705627
ballerina-platform_ballerina-lang/23966,enable tests after new type migration of stdlibs <cm-sep> fix langlib tesst cases <para-sep> represent ballerina distinct type id . <nl> represent ballerina type id . <nl> todo : using reason type as string is just a hack to get the code compile after removing error reason type .,and fixes failing langlib test cases and checkstyle issues . <nl> fixes # .,1591892634,> merge inresponse and outresponse to a single response struct,0.9069811105728149
apache_kafka/10137,"this reverts commit sha . <cm-sep> : implement task idling semantics via currentlag api . <nl> implements . <nl> reverts a previous behavior change to consumer.poll and replaces <nl> it with a new consumer.currentlag api , which returns the client 's <nl> currently cached lag . <nl> uses this new api to implement the desired task idling semantics <nl> improvement from .","* adds . <nl> * updates the streams task idling feature to use the new api . <nl> * implements <nl> * reverts a previous behavior change to consumer.poll and replaces <nl> it with a new consumer.currentlag api , which returns the client 's <nl> currently cached lag . the reverted jira is . <nl> the version pr had to revert both and <nl> , but this pr needed to revert and adapt .",1613538467,"now that we have augmented windowserde with non-arg parameters , extract it out as part of the public apis so that users who want to i/o windowed streams can use it . <nl> this pr grows out to be a much larger one , as i found a few tech debts and bugs while working on it . here is a summary of the pr : . <nl> 0. public api changes ( i will propose a kip after a first round of reviews ) : . <nl> * add timewindowedserializer , timewindoweddeserializer , sessionwindowedserializer , sessionwindoweddeserializer into o.a.k.streams.kstream .",0.9626341462135315
apache_incubator-pinot/5869,"roundup decimal points when compressing anomlaytimelinesview <para-sep> round up timelines view to save space in storage . * / <nl> first try rounding up <nl> max rounding will be up to 0 decimals for values > = version , use 0 decimals ( eg . 0 , version , version , version , version ) for values < version , use 0 decimals ( eg . version , version , version ) <nl> get rounded double value , according to the value of the double . <nl> create 0-min granularity test data * / <nl> compression test case 0 : anomaly view could satisfy requirement after rounding up the decimals . * / <nl> compression test case 0 : the anomaly view is still too large after rounding up , and needed to be further compressed * / <nl> compression test case 0 : compressed 0 times * /",this is a waste of storage with little added information on the values . this pr first round up the time series to 0 decimal points before compressing .,1597450558,"we 've changed the detector interface to pass predicted time series from detector to detection pipeline . this pr updates each stage of the detection pipeline to pass the time series . this makes the time series available in preview endpoints . also , this makes the evaluation metrics calculation possible .",0.9567146897315979
elastic_elasticsearch/70987,fix unit tests <para-sep> visible for testing,"if a naming conflict for a new write index is detected when a data stream rolls over , it will now increment its own generation until the new write index 's name does not conflict with any other indices , aliases , or data streams . this allows us to remove the trappy validation around name conflicts for the backing indices of data streams .",1617024135,"* removed custom data stream timestamp field validation and reuse the validation from and <nl> instead only check that the _timestamp field mapping has been defined on a backing index of a data stream . <nl> * moved code that injects _timestamp meta field mapping from method <nl> to method . <nl> * only apply _timestamp meta field if index is created as part of a data stream or data stream rollover , <nl> this fixes a docs test , where a regular index creation matches ( logs- * ) with a template with a data stream definition .",0.9411913156509399
apache_druid/10307,add support for all partitioing schemes for auto compaction <cm-sep> annotate last compaction state for multi phase parallel indexing <para-sep> hash partitioning is not supported with segment lock yet <nl> range partitioning is not supported with segment lock yet <nl> hash partitioning is not supported with segment lock yet <nl> should be always true for non-dynamic partitionsspec for now .,"this pr allows using all supported partitioning schemes in auto compaction . in addition to that , all tuningconfigs in are now available for auto compaction except for and configurations related to parse exceptions . can be computed based on the type of and the configurations related to parse exceptions are not supported by parallel index task yet . these changes can be found in . <nl> is now modified to allow all partitioning schemes . before , it always triggered compactions if it finds a segment compacted with non-dynamic partitioning . <nl> is also now able to annotate the",1598037623,"is similar to that of automatic compaction and means the size of the result segments after compaction . this is especially useful to compact a large interval partition into a few segments of the optimal size . a large interval partition means that the total size of segments in that partition is larger than no matter what the number of segments is . <nl> since indextask does n't support a sort configuration for target segment size , compactiontask assumes that the segment size is proportional to the number of rows in the segment and automatically computes based on the given",0.982430636882782
elastic_elasticsearch/71374,add rt fields to painless execute action <cm-sep> add some tests <cm-sep> finish single node tests <cm-sep> add yaml tests,this change adds support for the 0 different runtime fields contexts to the painless execute api . each context can accept the standard script input ( source and params ) along with a user-defined document and an index name to pull mappings from . the results depend on the output of the runtime field type .,1617743382,"the current implicit behaviour is that when an api keys is used to create another api key , <nl> the child key is created without any privilege . this implicit behaviour is surprising and is <nl> a source of confusion for users . this change makes that behaviour explicit .",0.9353113174438477
vespa-engine_vespa/16962,handle client port that is configured to tls only . <nl> the client port can no longer be distributed through the zk dynamic <nl> reconfiguration as the protocol does not support ssl client port . <nl> the port must be configured through the static config section instead . <cm-sep> remove unused parameter,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1615819207,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9255126118659973
Alluxio_alluxio/11114,add client side debug logging <para-sep> todo ( binfan ) : create rpc context so we could get rpc duration from metrics timer directly,"with this pr , after setting in , one can find debug logs on client operation in client-side log : .",1583280114,this change moves the creation of filesystem/context out of <nl> the job definitions and into the respective master/worker <nl> processes . the processes should aim to create clients as few <nl> times as possible because of all the underlying threadpools <nl> and resources that are needed to instantiate a client . <nl> the jobmaster and jobworkers now pass in a single instance <nl> of a filesystem client+context when selecting executors and <nl> running tasks . this greatly reduces the amount of resources <nl> that the job master and workers consume when there are lots <nl> of jobs being executed .,0.9247496128082275
jenkinsci_jenkins/4957,"omit stacktraces on classnotfoundexception in pluginstrategy classloading <para-sep> default and fallback strategy the default plugin manager implementation does not propagate/log stacktraces for classnotfoundexceptions , hence stacktraces are omitted by default for better performance . <nl> it improves classloading performance when the stacktrace is ignored , e.g .","the default plugin manager implementation suppresses in s thrown by and . such exceptions are a part of the normal jenkins classloading behavior , there are thousands of them on normal jenkins startup with plugins . each exception construction is a cpu/memory-heavy operation due to stacktrace initialized in the constructor . such behavior decreases startup performance , especially on instances with low memory limits . and the data is not really needed 🤷‍♂️ . <nl> this pull request .. . <nl> * adds api in and which allows disabling stacktrace generation in plugin manager implementations <nl> * disables stacktraces in",1601634789,"during plugin installs , particularly noticed when upgrading to jenkins 0 , required dependencies which are disabled are left as such , causing issues running newly installed plugins or worse .",0.9630114436149597
vespa-engine_vespa/16671,make the secret store a field on the tenant object <para-sep> put in a new secret store for the tenant <nl> get a tenant with secret stores configured,* add rendering of the secret stores to the tenant object <nl> * update to include writing and reading secret stores .,1614248681,"adds a ' steps ' field to the <nl> /application/v4/tenant/ { tenant } /application/ { application } /instance/ { instance } /job/ { jobtype } /run/ { number } <nl> rest api with the following structure : . <nl> ' steps ' : { <nl> ' deploytester ' : { <nl> ' status ' : ' succeeded ' , <nl> ' startmillis ' : 0 <nl> } , <nl> ' deployreal ' : { <nl> ' status ' : ' succeeded ' , <nl> ' startmillis ' : 0 <nl> } , <nl> ... <nl> }",0.9262492656707764
elastic_elasticsearch/71658,"first cut of a node shutdown allocation decider <para-sep> an allocation decider that prevents shards from being allocated to a node that is in the process of shutting down . in short : no shards can be allocated to , or remain on , a node which is shutting down for removal . primary shards can not be allocated to , or remain on , a node which is shutting down for restart . <nl> determines if a shard can be allocated to a particular node , based on whether that node is shutting down or not . <nl> there 's no shutdown metadata for this node , return yes . <nl> prevents indices from being auto-expanded to nodes which are in the process of shutting down , regardless of whether they 're shutting down for restart or removal . <nl> there are no nodes in the process of shutting down , return null . <nl> a very basic smoke test to make sure the allocation decider is working . <nl> put a shutdown request <nl> create an index with 1s/2r <nl> watch to ensure no shards gets allocated to the node that 's shutting down <nl> now that we know all shards of the test index are assigned except one , make sure it 's unassigned because of the allocation decider .","this pr adds an allocation decider which uses the metadata managed by the node shutdown api to prevent shards from being allocated to nodes which are preparing to be removed from the cluster . <nl> additionally , shards will not be auto-expanded to nodes which are preparing to restart , instead waiting until after the restart is complete to expand the shard replication .",1618349895,this creates an auto update service . the first automatic update is rewriting datafeed aggregations if they exist .,0.982922375202179
grpc_grpc-java/7441,"logging lrs raw response should be together ( run by the same thread ) withlogging the parsed data . <cm-sep> logging xds response should be together ( run by the same thread ) with logging the parsed data . <cm-sep> use implementation types for debug log messages . <cm-sep> improve method names . <para-sep> must run in synccontext . <nl> must run in synccontext . <nl> must run in synccontext . <nl> must run in synccontext . <nl> nonce in each response is echoed back in the following ack/nack request . it is used for management server to identify which response the client is acking/nacking . to avoid confusion , client-initiated requests will always use the nonce in most recently received responses of each resource type . <nl> must run in synccontext . <nl> must run in synccontext .","logging raw response messages should be run in the same synchronization context as other response handling logics . otherwise , logs for the same response message will be interleaved . <nl> including minor cosmetic improvements .",1600468681,"when deadline expires , both the client and the server try to cancel the stream . there is a race between server receiving the cancellation from the client and the server cancelling the stream , which changes the final status of the stream from the server 's perspective . if the former wins , server sees cancelled . if the latter wins , server sees deadline_exceeded . <nl> because does n't pass the final status to the server-side application , this ambiguity is n't a problem in most cases . however , the status is passed to , and thus",0.9191136956214905
apache_flink/14951,"hide terminal executiongraph outside finished <para-sep> if the state is overridden with a non-globally-terminal state then we need to erase traces of globally-terminal states for consistency <nl> ideally we 'd delay the async call to # ongloballyterminalstate instead , but the context does not support that <nl> this is just a sanity check for the test <nl> ideally we 'd delay the async call to # ongloballyterminalstate instead , but the context does not support that <nl> this is just a sanity check for the test <nl> ideally we 'd delay the async call to # ongloballyterminalstate instead , but the context does not support that <nl> this is just a sanity check for the test <nl> ideally we 'd just delay the state transitions , but the context does not support that <nl> this is just a sanity check for the test","hides the fact that the executiongraph can reach a globally-terminal state while the declarativescheduler is in a restarting/canceling/failing/executing state . <nl> this can happen because the transition into a globally-terminal state in the eg and the scheduler transition to waitingforresources/finished does not happen atomically ( mainthread-wise ) . <nl> this should not happen during restarting because it would break the contract that a globally-terminal job never transitions into another state . <nl> as for restarting/canceling/failing/executing , this is mostly for consistency ; we should ensure that the scheduler has a chance to cleanup whatever it wants before we communicate to",1613569279,"implement insert for hive dialect . <nl> to implement insert for hive dialect . <nl> - implement syntax . <nl> - add test cases . <nl> existing and added tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos ,",0.9453394412994385
neo4j_neo4j/10868,"do n't check dynamic processor assignment that often <cm-sep> increased page cache size <cm-sep> prints seed in quickimport <cm-sep> checks bounds in offheapbytearray <cm-sep> warn about heap size too big <cm-sep> defaults sequential bg flushing on ! highio <cm-sep> dumpstore can dump id ranges <para-sep> why test a silly thing like this ? this implementation contains some printf calls that needs to get arguments correct or will otherwise throw exception . it 's surprisingly easy to get those wrong . <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> at this point in time the store has n't started so it wo n't show up in free memory reported from os , i.e . we have to include it here in the calculations . <nl> check if there 's enough memory for the import <nl> check if the heap is big enough to handle the import <nl> check if heap size could be tweaked <nl> sanity checking against estimates <nl> the reason why we 're trying so hard to calculate these things is that for large imports ... getting the balance between heap and off-heap memory just right will allow the importer to use available memory and can mean difference between a failed and successful import . the calculated numbers are a bit on the defensive side , generally adding 0 % to the numbers . <nl> calculates optimal and minimal heap size for an import . a minimal heap for an import has enough room for some amount of working memory and the part of the page cache meta data living in the heap . at the time of writing this the heap size is really only a function of store size , where parts of the page cache meta data lives in the heap . for reference page cache meta data of a store of ~18tib takes up ~10gib of heap , so pagecacheheapusage ~= storesize / 0. on top of that there must be some good old working memory of ~0-0 gib for handling objects created and operating during the import . <nl> page cache meta data , see outline of this number above <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl>",found to improve various small things while working on importing really large data sets .,1516649378,to make sure it is possible to specify as well as in <nl> setting . <nl> changelog : made possible to allow node id reuse using 'dbms.ids.reuse.types.override ' setting .,0.9743813872337341
apache_druid/10441,"vectorized group by support for numeric null columns <cm-sep> revert unintended change <para-sep> sometimes doubles can become floats making the round trip from serde , make sure to coerce them both to double timestamp is not present in fieldtypes since it only includes the dimensions . sort of hacky , but if timestamp is included , dimstart will be 0 , so subtract from ' i ' to get correct index <nl> sometimes doubles can become floats making the round trip from serde , make sure to coerce them both to double","i modified the signature of the methods on to include for the selector , so that methods could check to continue to use the existing processors , and only use the newly added null handling processors when there are actually null values to deal with . <nl> in the process of adding tests for this , i also uncovered another issue with the when grouping on double values , where sometimes when making the round trip through serde they end up as floats , resulting in a cast exception when run through the comparator . to fix this issue i",1601203515,syntax is the same as hive/presto 's .,0.976391613483429
vespa-engine_vespa/15575,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> move config instance building into configserver <cm-sep> fallback to old method <para-sep> returns true if this instance should be applied on restart , false if it should be applied immediately * /","i remembered wrongly - it 's building a configinstance from a configinstance.builder i moved out of the config model and into configinstance.builder . i tried to put it in configserver instead now to see if this makes it work . otherwise i think i 'll embark on a major cleanup , but would rather not couple that with this as it is enough here as it is .",1606845184,"this changes node allocation to prefer nodes on network switches distinct within <nl> a cluster . we do this to avoid allocating multiple nodes in the same cluster on <nl> the same top-of-rack switch , thereby reducing the impact of an entire rack <nl> dying . <nl> behaviour : <nl> - deployment prefers nodes on exclusive switches . <nl> - deployment reuses switches instead of failing if exclusive allocation is n't <nl> possible . <nl> - node lacking switch information are exclusive by default to avoid unnecessary <nl> reallocation . this is currently the case for all nodes as none",0.9711017608642578
jenkinsci_jenkins/4636,use standard java base64 class . <cm-sep> update commons-codec to version,also includes some refactoring to remove need to use from commons-codec . <nl> internal : * upgrade commons-codec to version,1586383992,"* reduce usage of . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8901950120925903
OpenAPITools_openapi-generator/7719,"- fix the identification of path parameters <nl> - fix the model and client to support freeformobject <cm-sep> update doc <cm-sep> fix errors , update samples <para-sep> for symbol , e.g . $ , # <nl> number <nl> string",- fix the identification of path parameters <nl> - fix the model and client to support freeformobject .,1602747755,- replace powershell generator with powershell-experimental generator .,0.9477757215499878
jenkinsci_jenkins/5010,a step towards removing more 'slave ' terminology . <nl> overload the mechanisms for obtaining the jenkins-agent.jnlp ( formerly slave-agent.jnlp ) file for launching inbound tcp agents . <nl> serve the file at either of the two locations . <nl> change the ui ( etc . ) documentation to reference the correct term / file . <cm-sep> convert test to correct terminology . <para-sep> launches the inbound tcp agent and asserts its basic operations . <nl> adds an inbound tcp agent to the system and returns it . <nl> adds an inbound tcp agent to the system and returns it .,"overload the mechanisms for obtaining the jenkins-agent.jnlp ( formerly slave-agent.jnlp ) file for launching inbound tcp agents . <nl> serve the file at either of the two locations . <nl> change the ui ( etc . ) documentation to reference the correct term / file . <nl> this does n't allow us to remove the old , incorrect term , but allows us a path forward . existing agents and configurations continue to work . new ones are suggested to use the new terms and locations . this obsoletes the old . at some point we can remove the old",1602886359,"* rfe : jenkins defines a minimum remoting version and prints warnings when an older version is connected . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9254742860794067
Alluxio_alluxio/10933,small fix <para-sep> todo ( lu ) aggregate the per ufs per op from master + worker + client metrics <nl> divide into two lines so uptime is always zero or positive <nl> the value is bytes per minute,change the throughput calculation to be per minute value instead of per second and use clock for easy testing,1582054652,this should fix the hdfs build . <nl> this pr also includes minor cleanup of logging ( following our logging style guideline ) .,0.9340561628341675
elastic_elasticsearch/72274,"fix defaultrestchannel corrupting shared buffers on serialialization issues . <nl> we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects . <para-sep> not supported , close and create a new instance instead <nl> this method should only be called once per request . <nl> fallback in case of encountering a bug , release the existing buffer if any ( to avoid leaking memory ) and acquire a new one to send out an error response <nl> releases the current output buffer for this channel . <nl> the production implementation in defaultrestchannel always releases the output buffer , so we must too","we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects . <nl> note to reviewers : . <nl> i 'm aware that the existing code is extremely hard to follow in terms of the buffer lifecycle and this change does n't necessarily help things . then again , the bug fixed here is potentially very",1619466699,"almost every outbound message is serialized to buffers of 16k pagesize . <nl> we were serializing these messages off the io loop ( and retaining the concrete message <nl> instance as well ) and would then enqueue it on the io loop to be dealt with as soon as the <nl> channel is ready . <nl> 0. this would cause buffers to be held onto for longer than necessary , causing less reuse on average . <nl> 0. if a channel was slow for some reason , not only would concrete message instances queue up for it , but also",0.9519848823547363
elastic_elasticsearch/72206,"introduce a new class which uses a text file , <nl> to read and assert translation of planned and optimised queries similar to <nl> the approach already used in eql . <nl> furthermore : . <nl> - move the reading/parsing of that file to the common <nl> module , to avoid repeating code between eql & sql . <nl> - rename test names to remove _ and words like translate , <nl> or painless which are superfluous . <nl> - rename eql tests from to . <para-sep> test query term <nl> test common term <nl> test field source extraction <nl> querytranslation tests a test is made up of a name ( one line ) , a query that can span multiple lines and ends with ; and one or multiple assertions ( one per line ) that end with ; ; ... ; notes : - the eql query could span multiple lines and should be terminated with semicolon ( ; ) - the currently supported matchers : ( the default one ) , - to ignore a test , add the -ignore to the end of the name - matchers can be skipped , if you just want to test that a query is optimized/plan without errors - do not use whitespaces in the relevant parts of the query itself , as they will be removed . for example 'process where process_name : ' system idle process ' ' the whitespaces between system idle process will be removed and the assertion will fail . <nl> like and regex <nl> add and zero out for the next spec <nl> matcher which extends the functionality of org.hamcrest.matchers.matchespattern ( string ) } by allowing to match detected regex groups later on in the pattern , e.g . : ' ( ? .+ ? ) ' ....... \k ..... ' } <nl> miscellaneous /////////////// <nl> these two should be semantically different reference attributes <nl> datetime ///////// <nl> like/rlike/startswith ////////////////////// <nl> histograms /////////// count ///////// stats/extended stats ///////////////////// <nl> query translator tests . format : [ ... eol eol ... ] ; notes : - the sql query could span multiple lines and should be terminated with semicolon ( ; ) - the currently supported matchers : ( the default one ) , - to ignore a test , add the -ignore to the end of the name - matchers can be skipped ,","introduce a new class which uses a text file , <nl> to read and assert translation of planned and optimised queries similar to <nl> the approach already used in eql . <nl> furthermore : . <nl> - move the reading/parsing of that file to the common <nl> module , to avoid repeating code between eql & sql . <nl> - rename test names to remove _ and words like translate , <nl> or painless which are superfluous . <nl> - rename eql tests from to .",1619425145,"was originally not written as a parametrized field mapper . <nl> this pr refactors to extend . <nl> also , refactored to extend instead of",0.9225818514823914
apache_druid/10359,add shuffle metrics for parallel indexing <para-sep> emit metrics using the given emitter .,"this pr adds these metrics for middlemanagers . these metrics have the as their dimension . <nl> - : number of bytes shuffled per emissionperiod . <nl> - : number of shuffle requests per emissionperiod . <nl> i have n't updated document yet , will add them with missing shuffle configurations together in a follow-up pr",1599262353,"includes : . <nl> - foundational classes rowbasedsegment , rowbasedstorageadapter , <nl> rowbasedcursor provide a queryable interface on top of a <nl> rowbasedcolumnselectorfactory . <nl> - add lookupsegment : a rowbasedsegment that is built on lookup data . <nl> - improve capability reporting in rowbasedcolumnselectorfactory .",0.9807607531547546
elastic_elasticsearch/71580,avoid forking in abstractsearchasyncaction <para-sep> ensure that the current code has the following stacktrace : abstractsearchasyncaction # start - > abstractsearchasyncaction # executephase - > abstractsearchasyncaction # performphaseonshard,we do n't need to fork when handling unassigned shard failures in abstractsearchasyncaction as we never call it recursively .,1618250956,"since the index name pattern resolves to ' no indices ' , it makes a normally destructive action into a non-destructive one . rather than throwing a wildcards-not-allowed exception , we can allow this pattern to pass without triggering an exception . this allows the security layer to safely use a pattern to indicate a ' no indices ' result for its index resolution step , which is important because otherwise we get wildcards-not-allowed exceptions when trying to delete nonexistent concrete indices , e.g . : . <nl> i do n't have the domain knowledge to know if there is",0.8210554122924805
apache_flink/15120,"set output type for transformations from sourceprovider and datastreamscanprovider in commonexectablesourcescan <para-sep> for scantablesource , the output type is determined by the planner , and the result of this method will not be used . the purpose of returning null is to verify that the planner can handle the output type correctly .","this pull request set output type for transformations from sourceprovider and datastreamscanprovider in commonexectablesourcescan . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",1615262691,"thank you very much for contributing to apache flink - we are happy that you want to help us improve flink . to help the community review your contribution in the best possible way , please go through the checklist below , which will get the contribution into a shape in which it can be best reviewed . <nl> please understand that we do not do this to make contributions to flink a hassle . in order to uphold a high standard of quality for code contributions , while at the same time managing a large number of contributions ,",0.8721153140068054
apache_druid/10128,mask secrets in mm task command log,mm logs the java task command and does not mask the secrets so this pr fixes that and respects the masked properties config,1593707694,"fix stack overflow with infinite loop in reduceexpressionsrule of hepprogram . <nl> due to calcite bug ( ) , reduceexpressionsrule can considered expression which is the same as the previous input expression as reduced . basically , the expression is actually not reduced but is still considered as reduced . hence , this resulted in an infinite loop of calcite trying to reducing the same expression over and over in reduceexpressionsrule . calcite version fixes this issue by not consider expression as reduced if this case happens . however , while we are still using calcite version , a workaround",0.947136402130127
grpc_grpc-java/7403,accept all forms of gkeclusterurl and fix the ' x-goog-request-params ' value,also the location metadata header value should be,1599620314,"if initial response was received during the previous rpc , the retry will be immediate , and the back-off will be reset . otherwise , will use the current back-off sequence to schedule the next retry . <nl> classes are made public visibility for grpclb to use . they are still internal api though . <nl> reviewers , please ignore the individual commits .",0.9072653651237488
apache_incubator-pinot/5403,fixing template argument if not specify values,"0. fixing the npe issue that if is not specified , then a null array is parsed instead of empty array . so need to check null for array . <nl> thanks to manoj singh for reporting this . <nl> 0. fixing script .",1589617546,this pr adds an endpoint that allows manually refresh the holiday events within a specific time range . also improves the error handling of holiday events loader .,0.9371707439422607
grpc_grpc-java/7443,cds lb policy hardcode the eds lb policy config it generates with weighted-target policy . <cm-sep> deleted workaround code . <cm-sep> fix the legacy eds lb policy tests ( deprecated ) . <para-sep> fixme ( chengyuanzhang ) : handle error correctly to avoid being unnecessarily fragile .,this cleans up the temporary workaround code that implicitly includes the locality picking policy internally inside the eds lb config creation .,1600713048,"this adds a method on grpchttp2connectionhandler which , when called , indicates that the channel associated with the handler is no longer needed . <nl> notes : . <nl> * the handler may not be on the channel , but will either a. need to be added or will never be added . <nl> * the channel will only be ' unused ' on the server side . <nl> * it is expected that after calling , the channel will be deregistered from the loop without being properly shut down . this allows the channel to be handed off to",0.9218748211860657
Alluxio_alluxio/12149,add worker master periodical connect timeout,"in a cluster with multiple masters using embedded journal , when network partitioned the original leading master , leadership changes to a new leading master . the workers hang in grpc connections with the previous leading master and do n't register with the new leading master . <nl> this pr adds the timeout to periodical connections ( operations ) between workers and leading masters to prevent workers from hanging forever .",1601229757,"this pr introduces a new property to enable using the worker id as domain socket address . <nl> in k8s , where a compute framework may run with virtual networking , the client hostname may not match worker hostname . in such a scenario , this new property is used to enable short circuit by inspecting the filesystem instead of comparing the network address .",0.9385093450546265
Alluxio_alluxio/11962,"bump the version <cm-sep> implement a compatibility layer for hive metastore client <para-sep> compatibility worked but threw non tapplicationexception , re-throwing cause . <nl> implements a shim layer for hive metastore client . * / <nl> constructor for hmsshim . <nl> because retryingmetastoreclient is itself a proxy , we need to get to the base class <nl> other handlers can be added here <nl> hive compatibility . <nl> get table operation . <nl> test if a table exists .","version version of hive metastore client worked with a wide range of server versions , but we have to upgrade it for java 0 support . hence we add a compatibility library which proxies a number of calls to achieve compatibility with older versions .",1597115802,"created an alluxio shell command that does a bunch of environment checks to ensure alluxio can start correctly . it includes the following checks : . <nl> - check alluxio master port is open and available <nl> - check alluxio worker port is open and available <nl> - check nodes specified in conf/worker can be reached through ssh . <nl> user can run a specific set of commands by giving the check name or prefix . if no argument is given , it will run all checks . the command runs without requiring alluxio being started .",0.9849581122398376
hazelcast_hazelcast/18406,fix comments regarding a client 's disconnection from cluster,this only changes comments in code . <nl> * fixes another usage grammatically .,1615816527,"wrap into equal connections in firewallingserver . <nl> each call to wraps the <nl> connection into a new instance of . jet , to <nl> guarantee exactly-once and in-order delivery , checks , that the <nl> connection did n't change and restarts the job , if it did . this pr adds <nl> an method so that even though the connection instance is <nl> different , it 's equal if the delegate is the same . <nl> also contains some unrelated grammar fixes .",0.847469687461853
elastic_elasticsearch/71293,"[ ml ] shore up the ml feature reset code and potential bugs <para-sep> ignore <nl> ignore <nl> ignore <nl> ignore <nl> the extra work of the original native clean up causes the indices to be recreated it can complicate the logging and make it difficult to determine if the reset feature api cleaned up all the indices appropriately <nl> if we have succeeded , clear the jobs and datafeeds so that the delete api does n't recreate the notifications index <nl> first attempt to kill all anomaly jobs <nl> if successful , close and wait for jobs <nl> create a valid index routing so persistence will occur <nl> can not mock originsettingclient as it is final so mock the client <nl> test with reset mode turned on <nl> now set the upgrade mode <nl> queue some stats to be persisted <nl> this time turn off reset mode","the ml feature reset code was originally force closing all datafeeds , anomaly jobs , and analytics jobs . <nl> this does not allow the caller to wait for the persistent tasks to complete . it is possible for a persistent task <nl> to not exist in cluster state , but the individual node task is still executing . but , there is no visibility . <nl> to prevent this from causing issues and more complexity in the feature reset code , this commit <nl> attempts to close/stop all datafeeds , jobs , and data frame jobs without force first",1617641770,"this fixes a long outstanding issue with the resume behaviour <nl> of a datafeed that has been reassigned on a node . <nl> when we resume a datafeed , we start from the latest result time <nl> or the latest record time , whichever is greater . this makes sense <nl> when a job had been closed gracefully previously . <nl> in the scenario when a job is being reassigned , it is highly likely <nl> that the job has seen data after the latest snapshot was persisted . <nl> this means that with the current behaviour , we load",0.9772924184799194
grpc_grpc-java/7710,add channelz to xdstestserver in secure_mode=false,server-side channelz checks will be used in non-secure ( baseline ) interop tests as well .,1607450049,"embeddedchannel now runs all pending tasks when the channel is closed . <nl> this caused the http2connectionhandler to clear deframer references ( on <nl> channelinactive ) on errors when it previously did n't . now that the <nl> errors were handled more fully , it exposed bugs in tests .",0.8469351530075073
pentaho_pentaho-kettle/7546,"backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <para-sep> one or more steps failed on initialization . transformation is now stopped . <nl> halt the other threads as well , signal end-of-the line to the outside world ... also explicitly call dispose ( ) to clean up resources opened during init ( ) ; we will not pass this exception up to prepareexecution ( ) entry point . <nl> scenario : step not stopped <nl> scenario : step stopped <nl> common base for testsetinternalentrycurrentdirectory 's ' tests . <nl> a step that is already disposed <nl> a step not yet disposed <nl> only 'stepdatamock2 ' is to be disposed <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'stopped ' <nl> all cases should result in status being 'stopped ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'finished ' <nl> all cases , except where stopped is set , should result in status being 'end ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'paused ' <nl> it ca n't be 'finished ' nor 'stopped ' <nl> all cases should result in status being 'end ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> it ca n't be 'finished ' , 'paused ' nor 'stopped ' <nl> all cases should result in status being 'running ' . <nl> :","backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) <nl> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <nl> this pull request refers to two issues because the original prs were done along some time and have some",1596057289,"converting integer to timestamp type using select values step results in incorrect date . <nl> the kettle property is now called 'kettle_timestamp_number_conversion_mode ' and controls how timestamp should be converted to a number and vice-versa . <nl> there 're three possible values : <nl> - 'legacy ' : ( the default , the behaviour that existed until now ) timestamp to number uses milliseconds but number to timestamp uses nanoseconds <nl> - 'milliseconds ' : both conversions use milliseconds <nl> - 'nanoseconds ' : both conversions use nanoseconds . <nl> added several unit tests to guarantee all three scenarios (",0.946310818195343
Alluxio_alluxio/11612,"make hdfs mount check and io test do n't die on invalid paths <para-sep> checks if a path is hdfs . <nl> if the directory does not exist , there 's no point proceeding <nl> if the ufs path is not valid , abort the test <nl> if the ufs path is not valid , abort the test","the hdfs mount validation tool and io speed test tool will throw uncaught exceptions instead of returning a parsable json string , if the given path is not accessible . <nl> this change enables them to return parsable json results enclosing the invalid path exceptions , to whatever is consuming the results .",1592826197,"due to eventual consistency , open stream may fail with key does not exist exception .",0.9310342073440552
apache_kafka/10123,": remove methodhandle usage in compressiontype . <nl> we do n't really need it and it causes problems in older android versions <nl> and graalvm usage . <nl> move the logic to separate classes that are only invoked when the <nl> relevant compression library is actually used . place such classes <nl> in their own package and enforce via checkstyle that only these <nl> classes refer to compression library packages . <para-sep> a partial implementation of the v1.version lz4 frame format . <nl> and are effectively final , they are initialised in the method that is only invoked from the constructor <nl> if a block is compressed , this is the same as . if a block is not compressed , this is a slice of to avoid unnecessary copies . <nl> check whether kafkalz4blockinputstream is configured to ignore the frame descriptor checksum , which is useful for compatibility with old client implementations that use incorrect checksum calculations . <nl> reads the magic number and frame descriptor from input buffer . <nl> read first 0 bytes into buffer to check magic and flg/bd descriptor flags <nl> mark start of data to checksum <nl> final byte of frame descriptor is hc checksum <nl> old implementations produced incorrect hc checksums <nl> decompresses ( if necessary ) buffered data , optionally computes and validates a xxhash32 checksum , and writes the result to a buffer . <nl> check for endmark <nl> verify checksum <nl> a partial implementation of the v1.version lz4 frame format . <nl> check whether kafkalz4blockinputstream is configured to write an incorrect frame descriptor checksum , which is useful for compatibility with old client implementations . <nl> todo write uncompressed content size , update flg.validate ( ) <nl> compute checksum on all descriptor fields <nl> write out frame descriptor <nl> store block uncompressed if compressed length is greater ( incompressible ) <nl> write content <nl> calculate and write block checksum <nl> writes a 0-length block ( without block checksum ) to signal the end of the block stream . <nl> todo implement content checksum , update flg.validate ( ) <nl> while b will fill the buffer <nl> fill remaining space in buffer <nl> compute new offset and length <nl> a simple state check to ensure the stream is still open . <nl> basically flush the buffer writing the last block <nl> write the end block <nl> 0^ ( 2n+0 ) <nl>","we do n't really need it and it causes problems in older android versions <nl> and graalvm native image usage ( there are workarounds for the latter ) . <nl> move the logic to separate classes that are only invoked when the <nl> relevant compression library is actually used . place such classes <nl> in their own package and enforce via checkstyle that only these <nl> classes refer to compression library packages . <nl> to avoid cyclic dependencies , moved to the <nl> package .",1613231691,the log context is useful when debugging applications which have multiple clients . this patch propagates the context to the channel builders and the sasl authenticator .,0.9046128392219543
confluentinc_ksql/6647,"propagate null-valued records in repartition <cm-sep> historic plans <para-sep> remove all non-key columns from the value , and copy all key columns into the value . <nl> given : <nl> when <nl> then : <nl> extracts column references from expressions <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","the current mapper used in repartitions builds the new key by evaluating the generated expression on the value . if the value is null , the mapper returns an empty key rather than the original key . more intuitive behavior is to detect when the partition by expression depends only on key column ( s ) and evaluate the new key on the key columns in these cases , allowing null values to be propagated . <nl> unit + qtt .",1605826019,"introduces a new that can be used to specify a url that the node can be contacted on by other nodes . this can be different to the listeners defined in . this can be required if is set to a wildcard address , i.e . ipv4 or ipv6 , or if the node sits behind network infrastructure that requires other nodes to reach it using a different url . <nl> if is not set it still defaults to the first listener in config . however , it now replaces an wildcard address with . this means inter-node comms is",0.9723111987113953
apache_incubator-pinot/5320,"use time column from table config <para-sep> construct the segmentgeneratorconfig using schema and table config . if table config is passed , it will be used to initialize the time column details and the indexing config this constructor is used during offline data generation . <nl> star-tree v2 configs <nl> set time column details using the given time column . if not found , use schema <nl> set time column details using the given field spec <nl> time format : 'epoch ' <nl> time format : 'simple_date_format : ' <nl> date time columns should be dictionary encoded . <nl> fixme : make table config available here , and pass it to the segmentgeneratorconfig <nl> compute group by columns for roll-up preparation ( all dimensions + date time columns + time column ) <nl> table config provided <nl> table config not provided <nl> table config provided <nl> table config not provided <nl> name of the time column . <nl> optional . once we move to datetimefieldspec , check that table config ( w/ valid timecolumnname ) is provided if multiple datetimefieldspecs are configured <nl> once we move to datetimefieldspec , check that table config ( w/ valid timecolumnname ) is provided if multiple datetimefieldspecs are configured <nl> todo : get field spec of _timecolumnname from schema for the timetype","then use the timecolumnname to fetch the fieldspec from schema . <nl> major changes : <nl> 0 ) removing segmentgeneratorconfig ( schema schema ) constructor . enforcing the usage of segmentgeneratorconfig ( tableconfig tableconfig , schema schema ) instead . this allows us to read time from table config . <nl> 0 ) if table config is not available , reading timespec . this will change to reading 1st datetimefieldspec soon . this will fail if we have multiple datetimefieldspecs and no table config defined . <nl> pending : <nl> ~0 ) have n't figured out how to bring table",1588210155,"this migration does n't take care rolling up data . for instance , roll up data point from 0-minutes to 0-days granularity . therefore , we revert the change until the roll up functionality is implemented using data frame . <nl> after the migration to data frame , the timestamp shifting issue should be resolved .",0.971836268901825
ballerina-platform_ballerina-lang/23599,add error cause destructuring support <cm-sep> add temporary fixes for ballerina-io module <cm-sep> rename .reason ( ) to .message in unit test files <cm-sep> fix few more unit tests <para-sep> todo : detail type need to be a union representing all details of members of <nl> boolean erroneinitsuccesful = e1.message ( ) == error_reason_one & & e1.detail ( ) .length ( ) == 0 ; boolean errtwoinitsuccesful = e2.message ( ) == error_reason_two & & e2.detail ( ) .length ( ) == 0 & & e2.detail ( ) .err.message ( ) == error_reason_one & & e2.detail ( ) .err.detail ( ) .length ( ) == 0 ;,temporary fix io-module <nl> fix failing unit tests . <nl> fixes # .,1590733198,,0.0
netty_netty/10747,"fix explicitly little-endian accessors in swappedbytebuf . <nl> motivation : <nl> some buffers implement bytebuf # order ( order ) by wrapping themselves in a swappedbytebuf . <nl> the swappedbytebuf is then responsible for swapping the byte order on accesses . <nl> the explicitly little-endian accessor methods , however , should not be swapped to big-endian , but instead remain explicitly little-endian . <nl> modification : <nl> the swappedbytebuf was passing through calls to e.g . writeintle , to the big-endian equivalent , e.g . writeint . <nl> this has been changed so that these calls delegate to their explicitly little-endian counterpart . <nl> result : <nl> this makes all buffers that make use of swappedbytebuf for their endian-ness configuration , consistent with all the buffers that use other implementation strategies . <nl> in the end , all buffers now behave exactly the same , when using their explicitly little-endian accessor methods .","motivation : <nl> some buffers implement bytebuf # order ( order ) by wrapping themselves in a swappedbytebuf . <nl> the swappedbytebuf is then responsible for swapping the byte order on accesses . <nl> the explicitly little-endian accessor methods , however , should not be swapped to big-endian , but instead remain explicitly little-endian . <nl> modification : <nl> the swappedbytebuf was passing through calls to e.g . writeintle , to the big-endian equivalent , e.g . writeint . <nl> this has been changed so that these calls delegate to their explicitly little-endian counterpart . <nl> result : <nl> this",1603920552,"i use netty4.version . <nl> souce code : . <nl> in my opinion , the buffer.isreadable ( ) method should not be used here to judge , but the available ( ) method should be used . because bytebufinputstream is passed in length when constructing , so if the buffer.isreadable ( ) method is used here if judged , it may exceed the limit of length , which is unreasonable .",0.8712153434753418
netty_netty/10819,"let http2connectionhandler close stream with voidpromise . <nl> motivation : . <nl> http2connectionhandler tries to addlistener to the future without checking if it 's void . if it is void , this will fail and generate an exception . <nl> modifications : . <nl> get a new promise from the future 's channel if the future is void . <nl> result : .","motivation : . <nl> http2connectionhandler tries to addlistener to the future without checking if it 's void . if it is void , this will fail and generate an exception . <nl> modifications : . <nl> unvoid the promise before attempting to write <nl> result : .",1606215787,"motivation : . <nl> if the encoded value of a form element happens to exactly hit the chunk limit ( 0 bytes ) , the post request encoder will throw a nullpointerexception . <nl> modification : . <nl> catch the null case and return . <nl> result : .",0.8635562658309937
ballerina-platform_ballerina-lang/26825,update xml iterator to return xml <cm-sep> update concat logic <para-sep> xml iterator return type <nl> there are no 'xml elements ' in x1,"inconsistencies found in the method and enabling , and to be iterable is also done in this pr .",1604921010,"e.g. , . <nl> additionally it will also <nl> - allow passing args for the rest param as both individual args and a vararg . <nl> - remove adding parameter defaults when there 's a rest param . <nl> the following will result in a compilation error now . <nl> if the vararg list provided as the first member a type compatible with the defaultable parameter , that member would be used as the arg for the relevant defaultable parameter . <nl> - this pr also fixes two bugs .",0.9626495838165283
apache_shardingsphere/9408,"merge untracked file <cm-sep> refactor the integration test case executor <nl> based on the mac os version to adapt to the embedded mysql version <nl> new embedded postgresql support <nl> adjust the postgresql initialization script <cm-sep> refactor the integration test case executor <nl> adapt the embedded database default version <nl> added embedded postgresql support <nl> fixed postgresql dropping index npe <nl> refactor integration test parameterization parameters <nl> refactor database sql initialization <nl> mark some test cases to ignore postgresql tests <cm-sep> refactor the integration test case executor <nl> adapt the embedded database default version <nl> added embedded postgresql support <nl> fixed postgresql dropping index npe <nl> refactor integration test parameterization parameters <nl> refactor database sql initialization <nl> mark some test cases to ignore postgresql tests <nl> enhanced embedded database startup failure retry <cm-sep> restore the configuration <para-sep> it runner executor . <nl> a child statement to run . <nl> override to implement any behavior that must occur after all children have been scheduled ( for example , waiting for them all to finish ) . <nl> it runner parallel executor . <nl> it runner scenarios executor . <nl> case entry event . <nl> it runner serial executor . <nl> checkstyle : off <nl> ignored checkstyle : on <nl> get identify the individual test cases in a parameterized test . <nl> parameterized wrapper based integration test . <nl> execute sql script . <nl> todo this can be a single instance if the github action port has been adjusted <nl> checkstyle : off <nl> checkstyle : on <nl> embedded database for postgresql . <nl> database sql initialization . <nl> execute init sqls . <nl> database sql initialization for default . <nl> execute init sqls . <nl> todo use multiple threads to improve performance <nl> database sql initialization for h2 . <nl> todo use multiple threads to improve performance <nl> database sql initialization for mariadb . <nl> database sql initialization for mysql . <nl> database sql initialization for oracle . <nl> database sql initialization for postgresql . <nl> todo use multiple threads to improve performance <nl> database sql initialization for sqlserver .",changes proposed in this pull request : <nl> - refactor the integration test case executor <nl> - adapt the embedded database default version <nl> - added embedded postgresql support <nl> - fixed postgresql dropping index npe <nl> - refactor integration test parameters <nl> - refactor database sql initialization <nl> - mark some test cases to ignore postgresql tests <nl> - enhanced embedded database startup failure retry,1612872321,changes proposed in this pull request : <nl> - 将测试拆分dql、ddlanddml，对于dql只需执行一次测试初始化，提升运行速度 <nl> - 测试类运行结束后关闭连接池，避免占用连接资源 <nl> - 调整连接池连接数量为1，修改temporary table 表名为t_temp_log <nl> - 其他测试数据修正,0.9750143885612488
elastic_elasticsearch/71517,this pr adds a new api to delete service account tokens that are backed <nl> by the security index . it also fixes a few oversights from previous prs . <para-sep> cache is populated after authenticate <nl> cache is cleared after token deletion <nl> todo : wildcard support ? <nl> non-exist token name <nl> invalid service account <nl> index not exists <nl> index exists but not available,this pr adds a new api to delete service account tokens that are backed <nl> by the security index .,1617933866,"custom geoip databases can be provided via the config/ingest-geoip directory , <nl> which are loaded at node startup time . this change adds the functionality <nl> that reloads custom databases at runtime . <nl> - extracted logic that loads builtin and custom databases into a separate class . <nl> - the builtin databases serve always as a fallback for when no database can be found in config dir . <nl> - added qa module that tests reloading of databases at runtime .",0.9750284552574158
pentaho_pentaho-kettle/7540,missing alert message in ubuntu version,"the particular message being show is about the absence of _libwebkitgtk_ in ubuntu . it does not relate with any version in particular of ubuntu . <nl> we were only verifying for the supported versions at the time ( 0 and 0 ) . as soon as users start to use newer versions the message would not appear ( although we would still face the problems of not having _libwebkitgtk_ installed ) . <nl> a possible correction could be to update the versions to the current supported ones ( which now are 0 and 0 ) but , <nl> since",1595607633,cleanup for the following files : <nl> - zipcompressioninputstream <nl> - fileutil <nl> - javascriptutils <nl> - pluginpropertyhandler <nl> - jobhopmeta,0.8851778507232666
apache_pulsar/9565,"fix race condition in brokerservice topic cache <cm-sep> add test that reproduces the topic cache race condition <para-sep> a non-existing topic in the cache should n't prevent creating a topic <nl> retry and create topic <nl> in-progress future completed successfully <nl> method for resetting state explicitly this is required since setup & cleanup are using beforeclass & afterclass <nl> this test might fail if there are stats from other tests <nl> this test might fail if there are stats from other tests <nl> this test fails if there is state from other tests <nl> run multiple iterations to increase the chance of reproducing a race condition in the topic cache <nl> create race condition with a short delay the bug might not reproduce in all environments , this works at least on i7-10750h cpu <nl> expected exception","there 's a concurrency bug in method . <nl> when the topic has been retried with , for example by getting the statistics , for the topic , the pending future for this call will be in the cache and it 's result will be returned for the call which currently calls this method with . <nl> address the race condition and if , retry calling when the current result is .",1613053291,"rawreader # readnextasync returns a future to the user , which includes a <nl> retained bytebuf . if the user is no longer interested in the result of <nl> the read call , it should be able to cancel to ensure that the bytebuf <nl> is released . <nl> cancellation messes up the state of a stream ( if you cancel a read , should the subsequent read get the message that read would have received , or the message after it ? ) , so it should only occur when a you are about to close a reader or",0.9268479943275452
confluentinc_ksql/6476,"fix ksqlversion so it supports new version format . <nl> pom now has version set to , which could n't handle . this causes any attempt to generate new historical qtt test cases to fail . <nl> - updated ksqlversion to be able to handle new format . <nl> - added unit test for new format . <nl> - added unit test to test against latest version in pom , so we pick this up earlier next time . <para-sep> when : <nl> then : <nl> when : <nl> then : ( did not throw )","pom now has version set to , which could n't handle . this causes any attempt to generate new historical qtt test cases to fail . <nl> - updated to be able to handle new format . <nl> - added unit test for new format . <nl> - added unit test to test against latest version in pom , so we pick this up earlier next time . <nl> usual .",1603218168,"that the session window written as part of the record key will now contain the start _and_ end time , where previously it was just the start time . <nl> this pr addresses this by adding a new setting . users can set this to to use the legacy key format . more importantly , this setting will automatically be for all existing queries , ensuring backwards compatibility . <nl> answers on a postcard .. .",0.9183216691017151
apache_camel/4719,: map java.io.file to swagger response schema type 'file ' <para-sep> file is a special type in oas2 / oas3 ( no model ),fixes by setting schema type to 'file ' if responsemessage class is 'java.io.file ' .,1607013648,-check empty base path before adding '/ ' ( ftpconsumer ) . <nl> -add a new test .,0.9691996574401855
vespa-engine_vespa/16090,move sslhandshakefailure to separate class <cm-sep> add 'type ' to sslhandshakefailure <cm-sep> add ssl handshake failure to connection log <cm-sep> simplify handling of nested json fields during serialization <cm-sep> only include http counters if non-zero <cm-sep> add duration to access log <cm-sep> add remote address to connection log <cm-sep> add getters to connectionlogentry <cm-sep> verify content of connection log in httpservertest . <nl> also extend existing test methods for proxy-protocol and ssl handshake failure metrics to test content of connection log . <para-sep> note : this pattern will match certificates with too late notbefore as well <nl> retry when the server closes the connection before the tls handshake is completed . this have been observed in ci . we have been unable to reproduce this locally . the cause is therefor currently unknown .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610991888,"adds shared-host flag to enable and define resources of shared hosts . this pr <nl> is a no-op until that flag is set , but there remains some integration with <nl> exclusiveto ( tbd in this pr or follow-up ) .",0.9804769158363342
ballerina-platform_ballerina-lang/25919,fix the class syntax change <cm-sep> fix the issue with alias arrays,* fix an issue related to returning of arrays from classes with alias names .,1600413991,pr adds httpversion field to http client options where user can config the version .,0.8583341836929321
apache_pulsar/9694,"support get topic applied policy for maxunackedmessagesonconsumer <cm-sep> fix disabled can not take effect <cm-sep> add unit test <cm-sep> merge master <cm-sep> add unit test <para-sep> disable topic-level limiter <nl> remove topic-level policy , namespace-level should take effect <nl> disable namespace-level limiter <nl> remove namespace-level policy , broker-level should take effect <nl> remove maxunackedmessagesperconsumer for a namespace . <nl> remove maxunackedmessagesperconsumer for a namespace asynchronously . <nl> get applied max unacked messages on consumer of a topic . <nl> get applied max unacked messages on consumer of a topic asynchronously .","therefore , the namespace-level policy needs to add delete api",1614159466,"for some usecase , we do n't want to consume the reset position again , so it 's better to provide a way to reset the cursor to a specific position and exclude this position . so that the consumers under the subscription can start consume messages from the next position of the reset position .",0.9761318564414978
elastic_elasticsearch/71800,this pr ensure existing auditing tests cover service account authentication . <nl> it makes sure compatible existing fields also work for service accounts . <cm-sep> fix for 0.x quirks,this pr ensure existing auditing tests cover service account authentication . <nl> it makes sure compatible existing fields also work for service accounts .,1618789133,generating certificates with the sub-command now requires either : 0 ) a ca to be provided with or ; or 0 ) make them self-signed with the option . generating a ca on the fly is no longer supported . the option is removed and the tool throws an error if it is specified .,0.9458041787147522
apache_pulsar/9776,[ pulsar transaction ] pulsar client check transaction state . <cm-sep> move logic to transactionimpl <para-sep> we need to issue the request to tc to register the produced topic <nl> we need to issue the request to tc to register the acked topic,"it should be prevented . <nl> when open we can do transaction operation , it is close we ca n't do transaction operation . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( yes ) <nl> the rest endpoints",1614690727,"currently , pulsar support delete inactive topic which has no active producers and no subscriptions . this pull request is support to delete inactive topics that all subscriptions of the topic are caught up and no active producers/consumer . <nl> expose inactive topic delete mode in broker.conf , future more we can support namespace level configuration for the inactive topic delete mode . <nl> new unit tests added for each inactive topic delete mode . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no",0.9605369567871094
apache_druid/10208,cluster wide default query context setting <cm-sep> cluster wide default query context setting <cm-sep> cluster wide default query context setting <para-sep> a user configuration holder for all query types . any query-specific configurations should go to their own configuration . <nl> this field contains context configs from runtime property which is then merged with configs passed in query context . the result of the merge is subsequently stored in the query context . the order of precedence in merging of the configs is as follow : runtime property values ( store in this class ) override by query context parameter passed in with the query <nl> simple_timeseries_query_low_priority context has overrideconfigkey with value of 0,"cluster wide default query context setting . <nl> sometimes when external solutions such as looker connect to druid , users can not easily specify query context parameters . <nl> this pr allows user to use runtime properties ( druid.query.override.default.context . * ) to override any default value in querycontext . the order of precedence is as follow : hard_coded_default_value < - runtime_properties < - query_context_parameter . <nl> note that this changes the key for setting vectorize and vectorsize in the runtime property from druid.query.vectorize and druid.query.vectorsize to druid.query.override.default.context.vectorize and druid.query.override.default.context.vectorsize respectively <nl> queryconfig.java <nl> querylifecycle.java <nl> querylifecyclefactory.java",1595579190,"enables joins where the right-hand side is a lookup . includes an <nl> integration test . <nl> also , includes changes to lookupextractorfactorycontainerprovider : . <nl> 0 ) add ' getalllookupnames ' , which will be needed to eventually connect <nl> lookups to druid 's sql catalog . <nl> 0 ) convert ' get ' from nullable to optional return . <nl> 0 ) swap out most usages of lookupreferencesmanager in favor of the <nl> simpler lookupextractorfactorycontainerprovider interface .",0.9722424149513245
confluentinc_ksql/6694,expose avro and json_sr as key formats <cm-sep> historic plans,"this pr un-hides avro and json_sr from behind the feature flag , and cleans up a bunch of feature flag appearances in tests accordingly . review the first commit to avoid scrolling through the new qtt historic plans . <nl> qtt .",1606800418,throw an exception with the config documentation rather than getting an,0.8643917441368103
apache_shardingsphere/9765,refactor encryptcreatetabletoken <cm-sep> refactor encryptaltertabletoken <cm-sep> merge encryptcreatetablecolumntoken and substitutablecolumnnametoken <cm-sep> adjust rewrite order for create table with encrypt <cm-sep> for code format,- always remove logic column from create table for encrypt <nl> - merge encryptcreatetablecolumntoken and substitutablecolumnnametoken <nl> - adjust rewrite order for create table with encrypt,1616392262,- inline xid broadcast <nl> - clear xid of sub thread when sql executed <nl> - revise unit test,0.9456995129585266
ballerina-platform_ballerina-lang/23862,"update sttreemodifier to handle stnodelist instances <cm-sep> implement internal syntax node replace capability . <nl> this is required to support invalid node scenarios <cm-sep> add methoda to clone nodes with invalid node minutiae <cm-sep> update invalid node reporting in function parameter parsing <para-sep> continue ; <nl> clones the last parameter in list with the invalid node as minutiae and update the list . <nl> parse byte array literal . <nl> in this iteration , i am marking all the items as invalid <nl> replaces the given target node with the replacement . <nl> replaces internal tree nodes with the given replacements . it descends to a subtree only if the target node is there in the subtree . the transformation happens during the ascend . <nl> todo can we check whether to descend ? <nl> replaces the given target node with the replacement node and return new root node .",- invalid node diagnostics related to parsing byte array literal .,1591749666,map-binding-pattern and functional-binding-pattern will be added separately .,0.9835471510887146
apache_druid/10183,"fix sys.servers table to not throw npe and handle brokers/indexers/peons properly for broadcast segments <para-sep> other metadata associated with the node e.g . if it 's a historical node then lookup information , segment loading capacity etc . <nl> this is used for maxsize and currentsize when they are unknown . the unknown size does n't have to be 0 , it 's better to be null . however , this table is returning 0 for them for some reason and we keep the behavior for backwards compatibility . maybe we can remove this and return nulls instead when we remove the bindable query path which is currently used to query system tables . <nl> noinspection constantconditions <nl> build a row for the data server if that server is in the server view , or the node type is historical . the historicals are usually supposed to be found in the server view . if some historicals are missing , it could mean that there are some problems in them to announce themselves . we just fill their status with nulls in this case . <nl> returns a row for all node types which do n't serve data . the returned row contains only static information . <nl> returns a row for discoverable data server . <nl> if server is missing in serverinventoryview , the currentsize should be unknown","the servers table can throw npe if you have a historical that announced its node role , but not itself in the server view ( can be null at here ) . this pr fixes this npe and cleans up some unnecessary method calls . it also fixes the servers table to handle optional data servers which can serve broadcast segments . ~after this pr , the servers table will return all fields properly if they are found in the server view . otherwise , some fields such as , , and will be filled with nulls.~ i reverted the",1594693444,"- use druid float for sql float , and druid double for sql double , real , <nl> and decimal . <nl> - use float * aggregators when appropriate . <nl> - add tests involving both float and double columns . <nl> - adjust documentation accordingly .",0.9676610827445984
apache_druid/10445,fix the task id creation in compactiontask <para-sep> expect compaction state to exist as store compaction state by default <nl> expect compaction state to exist as store compaction state by default <nl> expect compaction state to exist as store compaction state by default <nl> range partitioning is not supported with segment lock yet <nl> expect compaction state to exist as store compaction state by default expect compaction state to exist as store compaction state by default,fixes a corner scenario in compaction when is of type and is set to 0. compaction fails since subtasks are created with a that is not the task id of the compaction task and they fail to find the supervisor task,1601310853,"document unsupported join on multi-value column . <nl> moreover , we should fail query that tries to join on multi-value column rather than silently ignoring multi-valued column and returning results back to user . this is because user may not be aware that druid actually do not support join on multi-value column and thinking that the result is because nothing match join condition",0.9624528288841248
apache_shardingsphere/10245,fix readyforquery may be missing when simple query <cm-sep> fix testcases,i 've tested it by sysbench and simplily tested it by psql . i do n't think some fatal about transaction is related to this pr .,1619981934,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.8692452907562256
elastic_elasticsearch/72057,designate reporting_user as a deprecated role,"the built-in role is used by kibana to grant report-generation privileges to a user that has that role assigned . that is deprecated in kibana , as the kibana admin can now migrate to using the kibana application privileges apis for reporting . <nl> it updates the built-in role to be marked as ' deprecated ' in the metadata . this change will allow kibana to show notices to the admin user in the ui that migrating to kibana application privileges is the preferred option .",1619048280,adds an optional column with support for x_opaque_id to _cat/tasks api .,0.8658574819564819
elastic_elasticsearch/71416,"centralize lucene files extensions <para-sep> compound files are tricky because they store all the information for the segment . benchmarks suggested that not mapping them hurts performance . <nl> dim files only apply up to lucene 0.x indices . it can be removed once we are in lucene 0 <nl> mmapdirectory has special logic to read long [ ] arrays in little-endian order that helps speed up the decoding of postings . the same logic applies to positions ( .pos ) of offsets ( .pay ) but we are not mmaping them as queries that leverage positions are more costly and the decoding of postings tends to be less a bottleneck . <nl> doc values are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> old extension <nl> old extension <nl> lucene version point format metadata file <nl> norms are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> term dictionaries are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> we want to open the terms index and kd-tree index off-heap to save memory , but this only performs well if using mmap . <nl> lucene version terms metadata file <nl> temporary lucene file <nl> lucene version indexed vectors metadata <nl> lucene file 's extension . <nl> short description of the lucene file <nl> some lucene files should be memory-mapped when applicable . <nl> some lucene files are considered as ' metadata ' files and should therefore be fully cached when applicable . those files are usually fully read by lucene when a directory is opened . for non-metadata files lucene usually only reads the header and footer checksums .","today elasticsearch enumerates lucene files extensions for various purposes : grouping files in segment stats under a description , mapping files in memory through or adjusting the caching strategy for lucene files in searchable snapshots . <nl> but when a new extension is handled somewhere ( let 's say , added to the list of files to mmap ) it is easy to forget to add it in other places . this pull request is an attempt to centralize in a single place all known lucene files extensions in elasticsearch .",1617808729,"could actually call the internal method more than once on contention . <nl> if i read the javadocs , it says : . <nl> so , it could be getting multiple updates on contention , thus having a race condition where stats are double counted . <nl> to fix , i am going to use a . the objects allows fast thread safe writes in high contention environments . these can be protected by the . <nl> when stats are persisted , i need to call reset on all these adders . this is not thread safe if additions are",0.9463692903518677
confluentinc_ksql/6393,"joins on sources with different key formats . <nl> joins prefer the format of the left source and will repartition the right source if needed , unless : <nl> * the right source is a table <nl> * the right source is not already being repartitioned to facilitate the join and the left source is being repartitioned already . <cm-sep> historical plans <para-sep> determines the key format of the join . avoids repartitioning tables for now . instead choosing to repartition the stream side . this is different to what is proposed in . for now , the left key format is the preferred join key format unless either : the right source is not already being repartitioned and the left source is . the right source is a table . in which case , the right key format it used . an exception is currently thrown if both sides are tables and their key formats differ . <nl> at least one table : <nl> a node that collaborates in joins . <nl> get any required key format . table 's , which do n't yet support changing key format , require the join key format to be their key format . <nl> get any preferred key format . any side that is already being repartitioned has no preferred key format . <nl> set the key format . <nl> node is repartitioning already : <nl> parent node can handle any key format change : <nl> only safe to call this if joiningnode is empty . <nl> util class around repartitioning . <nl> determine if a repartition is needed . a repartition is only not required if partitioning by the existing key columns . <nl> no current key , so repartition needed : <nl> different number of expressions to keys means it must be a repartition : <nl> if expression is not a column reference then the key will be changing <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then ( did not throw ) : <nl> given : <nl> when : <nl> then ( did not throw ) :","where the left and right source 's key formats differ , a joins prefer the format of the left source and will force a repartition of the right source if needed , unless : <nl> * the right source is a table <nl> * the right source is not already being repartitioned to facilitate the join and the left source is being repartitioned already . <nl> ... in which case it will force a repartition of the left source , unless : <nl> * the left source is a table <nl> ... in which case the query will be rejected",1602251391,"this change moves the validation done to ensure columns referenced in the projection for a query out of the / and into the logical model . <nl> at this point , only the validation of select expressions has moved . the rest will move in follow up prs . <nl> to achieve this , the needs to not take a logical schema as a parameter , but instead build it once the select items have been validated . this means logical plan nodes are no longer immutable . <nl> this is necessary work to enable the removal of joinkey udf",0.9843450784683228
vespa-engine_vespa/16363,clean up unused metricspresentationconfig <cm-sep> throw if no snapshot provider is given . <nl> + rename field and parameter to 'snapshotprovider ',"cleanup after removing the statemetricsconsumer . <nl> edit : i originally forgot to fix the actual todos , done in the third commit .",1612347179,use config server spec instead of calling external program,0.9209962487220764
apache_incubator-pinot/5794,[ te ] make rca insights in email resilient to issues in rca response <para-sep> alert notification should n't fail if rca insights are not available <nl> email template should not break even if cuberesults are null or empty <nl> email template should not break even if dimension field under cuberesults are null or empty <nl> email template should not break even if dimension field under cuberesults are null or empty,* added a version 0 of cube api that returns a map rather than a string . <nl> * added a safeguard in the notification pipeline that does n't fail the anomaly notification if the rca api has errors .,1596483559,"in commitsegmentmetadata in pinotllcrealtimesegmentmanager , we update zookeeper in 0 steps . <nl> step 0 : update propertystore to change the old segment metadata status to done <nl> step 0 : update propertystore to create the new segment metadata with status in_progress <nl> step 0 : update idealstates to include new segment in consuming state , and change old segment to online state . <nl> the controller may fail between these three steps . <nl> we have 0 chances to correct the state created by these failures . one is when a new controller takes over as leader . other",0.9606890082359314
quarkusio_quarkus/16478,"replace multivalueheaders with normal headers to match aws apigateway v2 . <nl> ( cherry picked from commit sha ) <cm-sep> change assignability check for interfaces . <nl> ( cherry picked from commit sha ) <cm-sep> fix oidc web auth docs . <nl> correction of property name quarkus.oidc.state-session-manager.strategy to quarkus.oidc.token-state-manager.strategy in oidc web authentication documentation . <nl> ( cherry picked from commit sha ) <cm-sep> fix websockets class loading issue . <nl> ( cherry picked from commit sha ) <cm-sep> make sure class is only processed once . <nl> note that at present we are processing more <nl> classes than are strictly nessesary , however <nl> the proper fix for this requires some changes <nl> that are part of my continous testing branch . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> js for all-config guide page . <nl> ( cherry picked from commit sha ) <cm-sep> handle rejectedoperationexception in the mutiny executor to avoid printing stack traces when the application is terminated . <nl> ( cherry picked from commit sha ) <cm-sep> detect native image build with com.oracle.graalvm.isaot . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> avoid unnecessary exception wrapping in nativetestextension.throwbootfailureexception . <nl> ( cherry picked from commit sha ) <cm-sep> bump gizmo in resteasy-reactive to version.final . <nl> the same version used in quarkus core . <nl> ( cherry picked from commit sha ) <cm-sep> fix issue with hang detection . <nl> ( cherry picked from commit sha ) <cm-sep> http/0 + bodyhandler fix . <nl> ( cherry picked from commit sha ) <cm-sep> fix race condition on reactive client with streaming and sse responses . <cm-sep> apply minor polish to reactive client classes . <nl> ( cherry picked from commit sha ) <para-sep> ignore the failure - the application has been shutdown . <nl> do nothing in case there is already a transaction ( e.g . self-intercepted non-private non-test method in test class ) w/o this check usertransaction.begin ( ) would fail because there is already a tx associated with the current thread <nl> an exception from proceed ( ) has to be captured to avoid shadowing it in finally ( ) with a exception from rollback ( ) <nl> note this property overrides the property which may be set in openid connect provider 's well-known configuration .","please do n't merge , i will merge it myself .",1618323844,"please do n't merge , i 'll merge it myself .",0.9801563620567322
ballerina-platform_ballerina-lang/26725,support bal env for object and receiver interops <cm-sep> support getting current module from bal env <cm-sep> add tests for getting current module for interops <para-sep> load the current module <nl> this is for object interop functions when both balenv and self is passed as parameters . <nl> validate receiver type <nl> calling overloaded method using self as a parameter . <nl> test get current module,this will support an api to get current module for given interop function environment . <nl> also fixes the ballerina environment passing issue with instance methods ( receivers ) and ballerina object methods . <nl> added test cases for each scenario .,1604422418,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.969887912273407
ballerina-platform_ballerina-lang/25161,fix object instruction gen interface issue <cm-sep> fix typeparamtest.testboundtypeascet issue <para-sep> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration of the reduce <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration <nl> accessing the parent strand here to use it with each iteration,fixes # . <nl> > todo : other langlib related test case failures are to be fixed .,1596717027,also skip running source gen tests on ballerina test files .,0.8774863481521606
elastic_elasticsearch/71379,"support fetching _tier values . <cm-sep> reorganize metadata fields docs . <para-sep> retrieve the first tier preference from the index setting . if the setting is not present , then return null . <nl> tier preference can be a comma-delimited list of tiers , ordered by preference it was decided we should only test the first of these potentially multiple preferences .","now that the option allows fetching metadata fields , we can support <nl> loading the new metadata field .",1617747864,"elasticsearch plugins can add a java security policy file to grant <nl> additional permissions . these policy files can contain permission grants <nl> for specific jar files , which are specified through system properties . <nl> unfortunately the java policy parser is lenient when a system property <nl> is missing , meaning we ca n't know if there is a typo or grant for a no <nl> longer relevant jar file . <nl> this commit adds validation to the policy parsing by overriding the <nl> system properties and tracking when a missing system property is used .",0.9552685618400574
apache_pulsar/9356,reduce rabbitmq fail rate . <para-sep> rabbitmq service may need time to initialize,"the rabbitmq service in tests startup asynchronously , so connect sometimes failed because the service is not prepared yet , try multiple times to reduce the failure rate .",1611822864,"by the way , i found a way to set idea to optimize imports to automatically conform checkstyle , just set like the picture below .",0.830313503742218
grpc_grpc-java/7750,"delayedstream should start ( ) real stream immediately . <nl> delayedclienttransport needs to avoid becoming terminated while it owns <nl> rpcs . previously delayedclienttransport could terminate when some of its <nl> rpcs had their realstream but realstream.start ( ) had n't yet been called . <nl> to avoid that , we now make sure to call realstream.start ( ) <nl> synchronously with setting realstream . since start ( ) and the method <nl> calls before start execute quickly , we can run it in-line . but it does <nl> mean we now need to split the stream methods into ' before start ' and <nl> ' after start ' categories for queuing . <para-sep> drain in-line instead of using an executor as failing stream just throws everything away . this is essentially the same behavior as delayedstream.cancel ( ) but can be done before stream.start ( ) . <nl> runnable may be null . * / <nl> no need to synchronize ; start ( ) synchronization provides a happens-before <nl> transfers all pending and future requests and mutations to the given stream . method will return quickly , but if the returned runnable is non-null it must be called to complete the process . the runnable may take a while to execute . when this method returns , start ( ) has been called on realstream or passthrough is guaranteed to be true <nl> starts stream without synchronization . <nl> note that listener is a delayedstreamlistener <nl> todo ( ejona ) : run this on a separate thread <nl> make sure that streams are created and started immediately , not in any executor . this is necessary during shut down to guarantee that when delayedclienttransport terminates , all streams are now owned by a real transport ( which should prevent the channel from terminating ) . <nl> but also verify that non-start ( ) -related calls are run within the executor , since they may be slow . <nl> if there is an executor in the calloptions , it will be used to create the real stream .","delayedclienttransport needs to avoid becoming terminated while it owns <nl> rpcs . previously delayedclienttransport could terminate when some of its <nl> rpcs had their realstream but realstream.start ( ) had n't yet been called . <nl> to avoid that , we now make sure to call realstream.start ( ) <nl> synchronously with setting realstream . since start ( ) and the method <nl> calls before start execute quickly , we can run it in-line . but it does <nl> mean we now need to split the stream methods into ' before start ' and <nl> ' after start ' categories",1608670847,"uses that ticker to create incoming s. this feature is specifically restricted to in-process , as it can also customize , and them together can fake out the clock which is useful in tests . on the other hand , a fake wo n't work with netty 's . <nl> also improved mismatch detection , documentation and tests in .",0.9548353552818298
apache_druid/10651,"fixed input source sampler buildreader exp <para-sep> add all rows to response <nl> no data parsed , add one response row <nl> inputrowlistplusrawvalues guarantees the size of rawcolumnslist and inputrows are the same <nl> keep the index of the row to be added to responserows for further use <nl> store the raw value ; will be merged with the data from the incrementalindex later <nl> make sure size of responserows meets the input",the change is simple - moving inputsourcereader creation in try-catch-block,1607359044,"would plan into . <nl> the test added to was just for fun , and passed prior to updating avatica",0.8565945029258728
vespa-engine_vespa/16983,add initial implementation - start with dummy test <cm-sep> implement first assessor functionality <cm-sep> clean up imports <para-sep> get all active nodes running on the impacted hosts <nl> group nodes pr cluster <nl> report assessment pr cluster <nl> todo check upgrade policy <nl> todo do some heuristic on suggestion action <nl> todo do some heuristic on impact <nl> the structure here should be { zone : string hosts : string [ ] switches : string [ ] switchinsequence : boolean } only zone and host are supported right now <nl> for now ; mandatory fields <nl> the impacted hostnames <nl> updated gives clue to if the assessment is old <nl> assessment on the host level - todo <nl> a separate/alternative list of noderepositorynode nodes . methods operating with node and noderepositorynode lives separate lives . <nl> both zone and hostnames are empty <nl> add an not impacted hosts <nl> make assessment <nl> assess the assessment : -o <nl> two impacted nodes on host1 <nl> one impacted nodes on host2 <nl> another group on hosts not impacted <nl> another cluster on hosts not impacted - this one also with three different groups ( should all be ignored here ) <nl> make assessment <nl> assess the assessment : -o,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1615904323,"this implements feature flags for the node repository . a feature flag can be <nl> toggled on/off for the following dimensions : . <nl> 0 ) the node repository ( entire zone ) <nl> 0 ) a specific node <nl> 0 ) a specific application . <nl> flags must be declared in the enum , this is typically done when <nl> implementing the feature that should be guarded by a flag . <nl> flag status is stored in zookeeper . inspecting and toggling flag status is done <nl> through a rest api , see .",0.9819164276123047
elastic_elasticsearch/71156,fix setup code in geoipclitests <cm-sep> unmute test,instead of creating directories manually under temp dir we should simply use twice . this should make windows be able to delete directories correctly . <nl> this pr also removes unused method .,1617227467,"an ignore parameter was originally added to the validatejsonagainstschematask <nl> to allow the build to pass for rest specs that did not properly validate <nl> against the schema . <nl> since the introduction of this task , all schemas that did not validate have <nl> been fixed to now validate properly . <nl> this commit removes the ability to ignore specific files for validation . this <nl> allows any consumers the assurance that all rest specs validate against the schema .",0.9139070510864258
netty_netty/11074,return correct result for futures that are returned from unorderedthreadpoolexecutor . <nl> motivation : . <nl> due a regression in sha we did not correctly set the result for the returned future if it was build for a callable . <nl> modifications : . <nl> - adjust code to call get ( ) to retrive the correct result for notification of the future . <nl> - add unit test . <nl> result : . <para-sep> if this runnablescheduledfuturetask wraps a runnablescheduledfuture that wraps a callable we need to ensure that we return the correct result by calling future.get ( ) . <nl> unwrap exception .,return correct result for futures that are returned from unorderedthreadpoolexecutor . <nl> motivation : . <nl> due a regression in sha we did not correctly set the result for the returned future if it was build for a callable . <nl> modifications : . <nl> - adjust code to call get ( ) to retrieve the correct result for notification of the future . <nl> - add unit test . <nl> result : .,1615382966,"motivation : . <nl> if two requests from the same ip are reached at the same time , may return false in both threads . <nl> modifications : . <nl> check if there is already a connection with the same ip using return values . <nl> result : . <nl> become thread safe .",0.9256530404090881
confluentinc_ksql/6279,"fix error handling in qtt . <nl> i 've noticed that the qtt tests are n't failing on the statement that caused the error . rather it was executing the next statement , which generally failed with some 'unknown source ' error . very misleading . <nl> the issue was that if a statement fails , the code calls on the iterator of test statements to ensure its the last statement that failed . ( this is needed to ensure we do n't have misleading tests with statements after an invalid one that are never executed ) . however , the call was evaluating the next statement , which would likely fail due to the previous statement failing . <nl> the fix is to make _not_ parse and prepare the statement . this is delayed until is called . this required moving the insert values execution code , but that 's a good thing anyway - that should never had been executed as part of ! <para-sep> when : <nl> then : <nl> given : <nl> when : <nl> then ( did not throw ) : <nl> given : <nl> when : <nl> then :","i 've noticed that the qtt tests are n't failing on the statement that caused the error . rather it was executing the next statement , which generally failed with some 'unknown source ' error . very misleading . <nl> the issue was that if a statement fails , the code calls on the iterator of test statements to ensure its the last statement that failed . ( this is needed to ensure we do n't have misleading tests with statements after an invalid one that are never executed ) . however , the call was evaluating the next statement",1600814967,not review required . <nl> usual .,0.9749197959899902
elastic_elasticsearch/71642,"more fixes to deprecation log indexing so that the data stream name and document <nl> contents are more ecs-compatible . <para-sep> tests that deprecation message are returned via response headers , and can be indexed into a data stream . same as deprecationindexingappender # deprecation_messages_data_stream , but that class is n't visible from here . <nl> check that log messages about rest api compatibility are recorded to an index <nl> it can take a moment for the index to be created . if it does n't exist then the client throws an exception . translate it into an assertion error so that assertbusy ( ) will continue trying .",more fixes to deprecation log indexing so that the data stream name and document <nl> contents are more ecs-compatible .,1618327297,"our handling for concurrent refresh of access tokens suffered from <nl> a race condition where : . <nl> 0. thread a has just finished with updating the existing token <nl> document , but has n't stored the new tokens in a new document <nl> yet <nl> 0. thread b attempts to refresh the same token and since the <nl> original token document is marked as refreshed , it decrypts and <nl> gets the new access token and refresh token and returns that to <nl> the caller of the api . <nl> 0. the caller attempts to use the newly refreshed",0.9025221467018127
apache_incubator-pinot/5705,add error message to broker response in case of broker send error,"on pinot broker , the incoming request gets written into socket channels of the target servers . this happens on function . if any exception occurs during submitquery for any reason like connection refused to one of the servers , sending requests to the remaining servers are abandoned and the partial responses from already successful sent requests are returned in brokerresponse with no indication of the exception . <nl> although partial response is acceptable , there should be an indication of such problem in broker response to make life easier for ppl debugging this issue . recently there was an",1594772490,"realtime data gets displayed by default , and we are n't fully equipped to handle it yet . this is resulting in undesirable results in certain datasets . adding realtime as a mode to the dataset , disabled by default , so that we only consider realtime if explicitly set",0.9414092898368835
vespa-engine_vespa/15366,add curator config and populate it for config servers and cluster controllers,add curator config and populate it for config servers and cluster controllers,1605618753,this adds a new config which includes all <nl> document type to bucket space mappings across all configured content <nl> clusters . inject this config into to ensure all changes <nl> to the mapping is observed . this also removes the remaining per-request <nl> config fetching during document v1 visit ops .,0.9512287974357605
eclipse-openj9_openj9/10735,"jdk15 load native libraries via jdk.internal.loader.nativelibraries . <nl> * jdk15 bindnative ( ) first search the nativelibrary associated with the <nl> classloader ( like pre-jdk15 levels ) for systemclassloader ; if that <nl> did n't succeed or the classloader is not systemclassloader , <nl> lookupnativeaddress ( ) is invoked with a null nativelibrary ; <nl> * when the incoming nativelibrary is null , lookupnativeaddress ( ) call <nl> into java.lang.classloader.findnative ( ) to get native method <nl> functionaddress ; <nl> * after a successful binding , classloaderregisterlibrary ( ) skips <nl> jni_onload ( ) which is going to be invoked by nativelibraries.load ( ) <nl> instead ; <nl> * jvm_loadlibrary ( ) invokes registerbootstraplibrary ( ) for early <nl> bootstrap , and j9sl_open_shared_library for later class loading ; <nl> * change system.load/loadlibrary to classloader.loadlibrary ( caller , <nl> filename ) ; <nl> * added jvm_unloadlibrary ( ) implementation ; <nl> * added a few tracepoints ; . <cm-sep> jdk15 jvmti library loading via jdk.internal.loader.nativelibraries . <nl> added callback ( currentthread , nativemethod , null , longjni , shortjni , <nl> functionargcount , true ) in which the nativelibrary is null ; <nl> added a few tracepoints . <para-sep> [ if java15 ] * / <nl> java15 * / <nl> [ if java15 ] * / <nl> java15 * / <nl> [ if java15 ] * / <nl> java15 / [ if java15 ] / <nl> java15 / [ if java15 ] / <nl> java15 / [ msg ' k0649 ' , ' { 0 } ( { 0 } ) ' ] / <nl> [ msg ' k0647 ' , ' ca n't load { 0 } ' ] * / <nl> [ msg ' k0647 ' , ' ca n't load { 0 } ' ] * / <nl> [ msg ' k0648 ' , ' not an absolute path : { 0 } ' ] * / <nl> [ msg ' k0647 ' , ' ca n't load { 0 } ' ] * / <nl> [ msg ' k0647 ' , ' ca n't load { 0 } ' ] * / <nl> [ if java15 ] * / <nl> [ msg ' k0648 ' , ' not an absolute path : { 0 } ' ] * / <nl> java15 / [ if java15 ] / <nl> / java15 / note this is required by jdk15+","* jdk15 first search the nativelibrary associated with the classloader ( like pre-jdk15 levels ) for ; if that did n't succeed or the is not , is invoked with a nativelibrary ; <nl> * when the incoming nativelibrary is , calls into to get native method functionaddress ; <nl> * after a successful binding , skips which is going to be invoked by instead ; <nl> * invokes for early bootstrap , and for later class loading ; <nl> * changed to invoke ; <nl> * added implementation ; .",1601334491,apply trusted domaincombiner.combine ( ) from closest doprivileged frame <nl> to protectiondomain instances to be checked later including those <nl> context from embedded accesscontrolcontext such as <nl> accesscontrolcontext.doprivilegedacc and <nl> accesscontrolcontext.nextstackacc . <nl> added a testcase which caused stackoverflowerror without this pr .,0.9442103505134583
netty_netty/11068,"introduce httpmessagedecoderresult to expose decoded header size . <nl> motivation . <nl> the httpobjectdecoder accepts input parameters for maxinitiallinelength <nl> and maxheadersize . these are important variables since both message <nl> components must be buffered in memory . as such , many decoders ( like <nl> netty and others ) introduce constraints . due to their importance , many <nl> users may wish to add instrumentation on the values of successful <nl> decoder results , or otherwise be able to access these values to enforce <nl> their own supplemental constraints . <nl> while users can perhaps estimate the sizes today , they will not be <nl> exact , due to the decoder being responsible for consuming optional <nl> whitespace and the like . <nl> modifications . <nl> * add httpmessagedecoderresult class . this class extends decoderresult <nl> and is intended for httpmessage objects successfully decoded by the <nl> httpobjectdecoder . it exposes attributes for the decoded <nl> initiallinelength and headersize . <nl> * modify httpobjectdecoder to produce httpmessagedecoderresults upon <nl> successfully decoding the last http header . <nl> * add corresponding tests to httprequestdecodertest & <nl> httpresponsedecodertest . <para-sep> the decoded initial line length plus the decoded header size ( in bytes ) . <nl> done parsing initial line and headers . set decoder result .","the accepts input parameters for and . these are important variables since both message components must be buffered in memory . as such , many decoders ( like netty and others ) introduce constraints . due to their importance , many users may wish to add instrumentation on the values of successful decoder results , or otherwise be able to access these values to enforce their own supplemental constraints . <nl> while users can perhaps estimate the sizes today , they will not be exact , due to the decoder being responsible for consuming optional whitespace and the like .",1615262358,"this tests the following classes more : . <nl> 0 : internalloggerfactorytest <nl> tests internalloggerfactory.getinstance ( class ) . <nl> 0 : defaultattributemap / defaultattribute ( 0 % ) <nl> 0 : networkconstants ( version % , functionally 0 % ) <nl> 0 : stringutil ( 0 % , functionally 0 % )",0.945967972278595
confluentinc_ksql/6295,"json format should correct scale of decimals when deserializing . <nl> it is the responsibility of the format to ensure the data returned matches the required schema . this includes the scale of decimals . the json format was not correctly setting the scale of decimals when deserializing . for example , give : . <nl> the above creates a stream with a single value column which should have a scale of , i.e . two decimal places . <nl> if the data in tbe kafka record 's value was to have the incorrect , e.g . <nl> or . <nl> then the deserializer was returning the decimal as provided , i.e . or . however , this is incorrect as the schema of the column states is has a scale of two . so all values for the column should have the scale set to two , i.e . the above examples should deserialize to and . with this change they no do . <cm-sep> updated qtt <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","it is the responsibility of the format to ensure the data returned matches the required schema . this includes the scale of decimals . the json format was not correctly setting the scale of decimals when deserializing . for example , give : . <nl> the above creates a stream with a single value column which should have a scale of , i.e . two decimal places . <nl> if the data in tbe kafka record 's value was to have too small a scale , e.g . <nl> or . <nl> then the deserializer was returning the decimal as",1600960846,"the api is a new method added in kafka version . if ksql runs on kafka version or lower , this api will return null causing a npe in ksql and denying any operation executed on a kafka version environment . <nl> to avoid the npe issue , ksql avoids enabling the topic validator instead . look at the which checks if the from the cluster is null . <nl> run local tests with kafka version . warning message is printed : . <nl> [ 0-0-0 0:0:0,0 ] warn the kafka broker has an authorization service enabled , but the",0.9109518527984619
ballerina-platform_ballerina-lang/26008,"fix the union type issue <cm-sep> fix the issue in the while statement <cm-sep> disable the if else issue <cm-sep> fix issues in method calls and panic statements <cm-sep> fix the new line endings issue <cm-sep> add test cases for query expressions <cm-sep> disable the query expression formatting <cm-sep> fix the streaming node <para-sep> as a syntax tree . <nl> todo : enable the nested if else statements <nl> todo : enable the queryexpressionnode if ( ! isinlinerange ( queryexpressionnode , linerange ) ) { } queryconstructtypenode queryconstructtype = this.modifynode ( queryexpressionnode.queryconstructtype ( ) .orelse ( null ) ) ; querypipelinenode querypipeline = this.modifynode ( queryexpressionnode.querypipeline ( ) ) ; selectclausenode selectclause = this.modifynode ( queryexpressionnode.selectclause ( ) ) ; onconflictclausenode onconflictclause = this.modifynode ( queryexpressionnode.onconflictclause ( ) .orelse ( null ) ) ; if ( queryconstructtype ! = null ) { queryexpressionnode = queryexpressionnode.modify ( ) .withqueryconstructtype ( queryconstructtype ) .apply ( ) ; } if ( onconflictclause ! = null ) { queryexpressionnode = queryexpressionnode.modify ( ) .withonconflictclause ( onconflictclause ) .apply ( ) ; } return queryexpressionnode.modify ( ) .withquerypipeline ( querypipeline ) .withselectclause ( selectclause ) .apply ( ) ; <nl> the works similar to a statement . it can be used to iterate through any iterable value . the result of the is the termination value of the iterable value . it can be either an error or . <nl> the block inside the clause is executed in each iteration . <nl> the clause works similarly to a statement . it can be used to iterate any iterable value . the is the result of the . <nl> an inner equijoin is performed here . the clause iterates any iterable value similarly to the clause . <nl> the condition is used to match the with the based on the . the iteration is skipped when the condition is not satisfied . <nl> the clause limits the number of output items . <nl> the clause is evaluated in each iteration when the condition is satisfied . <nl> the works similar to a statement . it can be used to iterate through any iterable value . the result of the is the termination value of the iterable value . it can be either an error or . <nl> the block inside the clause is executed in each iteration . <nl> the clause works similarly to a statement",disables the formatting of nested if statements and query expressions in order to reduce the priority levels of the following issues .,1600771822,- fix calling init multiple times when services are used <nl> - refactor suite initializing logic and update bal files <nl> - update tests and fix broken tests .,0.9706268310546875
apache_incubator-pinot/5398,"[ te ] data sla yaml parser & translator <cm-sep> refactor <cm-sep> clean up <para-sep> verify if this detection has data quality checks enabled <nl> the data quality job submitted to the scheduler . this job creates data quality tasks which the runners will later pick and execute . <nl> if a task is pending and not time out yet , do n't schedule more <nl> ths class is responsible for running the data quality tasks <nl> default constructor for thirdeye task execution framework . loads dependencies from daoregitry and cacheregistry <nl> a small hack to reuse the properties field to run the data quality pipeline ; this is reverted after the run . <nl> revert the properties field back to detection properties <nl> save all the data quality anomalies <nl> performs data sla checks for the window and generates data_sla anomalies . data sla is verified based on the following information . a. the dataset refresh timestamp updated by the event based data availability pipeline ( if applicable ) . b. otherwise , we will query the data source and run sla checks . <nl> runs the data sla check for the window on the given metric . <nl> fetches the latest timestamp for the dataset . it relies on 0 sources : a. data-trigger/availability based refresh timestamp b. if not available , check by directly querying the data-source . <nl> note that we only measure the overall dataset availability . filters are not considered as the data availability events fire at the dataset level . <nl> fetch dataset refresh time based on the data availability events <nl> no availability event - > assume we have processed data till the current detection start <nl> if the data availability event indicates no data or partial data , we will confirm with the data source . <nl> double check with data source . this can happen if , 0. this dataset/source does n't not support data trigger/availability events 0. the data trigger event did n't arrive due to some upstream issue . <nl> we say the data is partial if we do not have all the data points in the sla detection window . or more specifically if we have at least 0 data-point missing in the sla detection window . for example : assume that the data is delayed and our current sla detection window is [ 1st feb to","overall updates : <nl> * added ability to configure data quality ( dq ) alerts from yaml . see a sample below . <nl> * dq pipeline leverages and extends on the existing detection merging logic pattern . <nl> * refactored code to modularize & reuse the detection translators and extend them to data quality translators . <nl> * updated the data_quality task and pipeline runner . <nl> * added following metrics to track - # dq tasks , # dq success tasks & # dq fail tasks . <nl> note that this pr supports data quality checks only when",1589585682,"this will enable us to hook in event data providers for say deployment events , a/b testing events , to the eventresource and the eventdataprovidermanager . <nl> this will also help us achieve an abstraction between the eventdataprovider and the pipeline , allowing us to operate on eventdataprovider independent of the pipelines",0.9615123271942139
apache_incubator-pinot/5347,"remove some unused timefieldspec related methods from schema <para-sep> time columns should be dictionary encoded . <nl> mode all - use all columns mode non_metric - use all dimensions and time columns mode time - use only time columns <nl> intentionally falling through to next case <nl> constructs a transformfunction string for the time column , based on incoming and outgoing timegranularityspec","as i was making changes to schema to treat time as date_time , found a subset of changes that can go prior to the bigger change . <nl> removing 0 methods from the schema which are related to timefieldspec <nl> 0. getincomingtimeunit - was unused <nl> 0. getoutgoingtimeunit - was unused <nl> 0. gettimecolumnname - was able to remove the 0 usages",1588813135,"the refactoring has two purpose : <nl> 0. users do not need to update anomaly result manually : the classify method now returns only the issue type for the given anomaly . the update is performed by classification pipeline . <nl> 0. simplify the implementation of classify method because it takes one main anomaly at at time . therefore , users do not need to manually go through the list of main anomaly . <nl> test on local controllers .",0.9506853818893433
elastic_elasticsearch/72518,service account tokens should work when tokenservice is disabled . <nl> add a test to ensure that service account tokens always work with basic <nl> license for which oauth2 token service is disabled . <para-sep> service account token works independently to oauth2 token service,add a test to ensure that service account tokens always work with basic <nl> license for which oauth2 token service is disabled .,1619763643,"we were caching serialized in the newest <nl> metadata format . this lead to a confusing situation where <nl> numeric shard generations would be cached in <nl> that were not written to the repository because the repository <nl> or cluster did not yet support . <nl> in the case where shard generations are not actually supported yet , <nl> these cached numeric generations are not safe and there 's multiple <nl> scenarios where they would be incorrect , leading to the repository <nl> trying to read shard level metadata from index-n that do n't exist . <nl> this commit makes",0.9317014813423157
apache_camel/4900,"camel component for huaweicloud simple notification services ( smn ) services . <nl> smn is one among the cloud product offering within huaweicloud ecosystem which enables cloud application users to broadcast/send out notifications to subscribers . it provides a single unified endpoint aka . topic for the application to push data . <nl> multiple subscribers can be associated with a given topic . simple message notification ( smn ) enables you to broadcast messages to subscribers who can chose to receive the notifications via an email addresses , phone numbers , serverless functions and http/https servers and connect cloud services through notifications , reducing system complexity and developmental efforts to the publishing app . <para-sep> since camel { since } * <nl> { component-header } * <nl> component options : start <nl> component options : end <nl> endpoint options : start <nl> endpoint options : end <nl> huawei cloud component to integrate with simplenotification services <nl> todo : delete me when you implemented your custom component <nl> publish message service operations <nl> maps api response parameters as exchange property <nl> validation and initialization of smnclient object <nl> checking for cloud sk ( secret key ) <nl> checking for cloud ak ( auth key ) <nl> checking for project id <nl> checking for region <nl> checking for ignore ssl verification <nl> checking if http proxy authentication is used <nl> initialization of smn client . this is lazily initialized on the first message <nl> building smn client object <nl> validation of all user inputs before attempting to invoke a service operation <nl> verifying if exchange has valid body content . this is mandatory for 'publish as text ' operation <nl> checking for mandatory field 'operation name ' <nl> checking for mandatory field 'topic name ' <nl> checking for optional field 'message subject ' <nl> checking for optional field 'message ttl ' <nl> utility functions for the component <nl> resolves endpoint url for the given region <nl> request properties <nl> response properties <nl> cloud service authentication key ( ak ) <nl> cloud service secret key ( sk ) <nl> populating tag values . user has to adjust the map entries according to the structure of their respective templates","camel component for huaweicloud simple notification services ( smn ) services . <nl> smn is one among the cloud product offering within huaweicloud ecosystem which enables cloud application users to broadcast/send out notifications to subscribers . it provides a single unified endpoint aka . topic for the application to push data . <nl> multiple subscribers can be associated with a given topic . simple message notification ( smn ) enables you to broadcast messages to subscribers who can chose to receive the notifications via an email addresses , phone numbers , serverless functions and http/https servers and connect cloud services",1610992947,this adds azure eventhubs component .,0.9845970869064331
elastic_elasticsearch/71863,change context names for run time fields to type_field <para-sep> disable runtime fields scripts from being allowed to be stored as part of the script meta data . <nl> determines if the script can be stored as part of the cluster state . * / <nl> maxcompilationratedefault and allow scripts of this context to be stored scripts * /,this change disallows stored scripts using a runtime field context . this adds a constructor parameter to script context as to whether or not a context is allowed to be a stored script .,1618850324,this fixes to properly parse string formatted dates that <nl> have nanosecond resolution .,0.8765931725502014
apache_flink/14480,properly respect max-failures-per-interval <cm-sep> cleanup simplerecoveryitcasebase,fixes an issue where the was allowing 0 less restart than configured . the strategy should remember one more exception in it 's history ( maxfailuresperinterval+0 ) .,1608725638,"removes and refactors existing usages . <nl> the method did not achieve the desired effect of running the action in the te main thread . given that the test has not shown instabilities despite this we can conclude that these actions can just be executed in the tests main thread instead . <nl> additionally , this test removes/replaces accesses to the jobmanagertable of the taskexecutor . <nl> the first access was removed since it is not really necessary since it effectively verified the test setup . <nl> the second access was replaced with a check for whether the disconnect-from-jm future",0.9137480854988098
ballerina-platform_ballerina-lang/23573,add exclude tags and operations filter <para-sep> checking both tags and excludetags include same tags and operations <nl> else if proceed to check exclude operation filter is enable else check tag filtering or excludetag filtering enable . else if exclude tag filtering available validate only the operations that are not include exclude tags . <nl> if exclude tags filtering available validate only the filtered exclude operations grouped by given exclude tags . else if tags filtering available validate only the operations that filtered by exclude operations . else proceed only to validate filtered exclude operations . <nl> if exclude tag filtering available proceed to validate all the operations grouped by tags which are not included in list . else if validate the operations group by tag filtering else proceed without any filtering . <nl> if tag filtering available proceed to validate all the operations grouped by given tags . else proceed only to validate filtered operations . <nl> for tag filter <nl> for operation filter,add the extra fields excludetags and excludeoperations to opeanapi annotation . this use to filter the tags and operations that exclude validating .,1590653720,"from this pr , first proto will be created and then taking that proto as input a sample bal file will be created . <nl> bal files will vary according to the rpc concepts ( unary , bidirectional streaming , client streaming ) .",0.9734370708465576
ballerina-platform_ballerina-lang/25837,"change the dataflow <cm-sep> add tests <para-sep> if the flow was terminated within the block , then that branch should not be considered for analyzing the data-flow for the downstream code . <nl> only if last pattern is present , uninitializedvars should be updated",changed the dataflowanalyser in order to fix the issue .,1600234404,"generate bir for . <nl> note : this will fail at jvm gen , since that part is not covered by this pr",0.9672297239303589
elastic_elasticsearch/72297,"we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects . <para-sep> not supported , close and create a new instance instead <nl> release whatever output we already buffered and write error response to fresh buffer <nl> this method should only be called once per request . <nl> fallback in case of encountering a bug , release the existing buffer if any ( to avoid leaking memory ) and acquire a new one to send out an error response <nl> releases the current output buffer for this channel . <nl> the production implementation in defaultrestchannel always releases the output buffer , so we must too",we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects .,1619514087,* faster and for which is nice since with this change we use it for the search cache <nl> * lighter for that should save memory and some indirection relative to the one on the abstract bytes reference <nl> * lighter implementation <nl> * build a instead of a whenever possible to save indirection and memory,0.9528781175613403
apache_incubator-pinot/5758,stashing avro bug fixe <cm-sep> only add known ssl configs,"add ability to pass ssl certs info to schema registry . <nl> example config to pass ssl certs to schema registry in the table config follows : <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.truststore.location ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.keystore.location ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.truststore.password ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.keystore.password ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.keystore.type ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.truststore.type ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.key.password ' : ' ' , <nl> ' stream.kafka.decoder.prop.schema.registry.ssl.protocol ' : ' ssl ' ,",1595788453,an unknown exception is thrown when trying to initiate anomaly function that shows special baseline . we only show week-over-week values for now until we find the problem .,0.9291198253631592
confluentinc_ksql/6722,"additional qtt <cm-sep> integration tests <cm-sep> expose support for array and struct keys <cm-sep> historic plans <para-sep> ca n't use expectedrow.add ( ( bigdecimal ) value ) directly since client serializes bigdecimal as string , whereas this method builds up the expected result ( unrelated to serialization )","four commits for ease of reviewing : <nl> - additional qtt test coverage <nl> - adds integration test coverage , via the http2 api and java client tests <nl> - removes the feature flag <nl> - adds qtt historic plans . <nl> see above -- lots of new tests !",1607115802,"has a couple of methods that find columns : . <nl> * finds a column in the schema that 'matches ' the supplied <nl> * as above , but only searching value columns <nl> * returns the index of the column in the value columns that 'matches ' the supplied . <nl> the reason 'matches ' in the list above is in quotes is because it does n't do what you might think . the matching logic only takes the of a column into account if both the schema column and the supplied have a source name . if either",0.9399119019508362
jenkinsci_jenkins/4754,capture stacktrace from the original thread when slavecomputer # _connect fails,print stack trace from the originating thread if fails,1590671058,"[ fix ] : use english as default-locale , so the resourcebundleutiltest runs also on systems with other default os locales .",0.8076463341712952
vespa-engine_vespa/15199,revert ' revert ' add collection method enumerations - change default ' ',this re-applies the changes i merged too early,1604650881,"we have seen 0 deployments running at the same time , which is more than the config servers can handle .",0.9460210204124451
apache_kafka/9645,update build and test dependencies <cm-sep> fix bug in scrammechanism.frommechanismname where it did n't handle an unknown mechanism name correctly <cm-sep> remove redundant null check <cm-sep> upgrade to spotbugs version and adjust exclusion to be more specific <cm-sep> introduce scrammechanismtest,"the spotbugs upgrade means we can re-enable <nl> rcn_redundant_nullcheck_of_nonnull_value and rcn_redundant_nullcheck_would_have_been_a_npe . <nl> these uncovered one bug , one unnecessary null check and one <nl> false positive . addressed them all , including a test for the bug . <nl> * gradle ( version - > version ) : minor fixes . <nl> * gradle versions plugin ( version - > version ) : minor fixes . <nl> * grgit ( version - > version ) : a few small fixes and dependency bumps . <nl> * owasp dependency checker plugin ( version - > version ) : improved db",1606159923,"the fetchsession ( ) method of sessionstore searches for a ( single ) specific session and returns null if none are found . this is analogous to fetch ( key , time ) in windowstore or get ( key ) in keyvaluestore . meteredwindowstore and meteredkeyvaluestore both check for a null result before attempting to deserialize , however meteredsessionstore just blindly deserializes and as a result npe is thrown when we search for a record that does not exist . <nl> also piggyback on this : fetch ( ) in the metered layer currently delegates to findsessions with time range",0.8801808953285217
OpenAPITools_openapi-generator/7963,more fixes to go doc generation <cm-sep> regenerate samples <para-sep> maparrayinteger | pointer to map ] int32 | | maparrayanytype | pointer to map [ ] mapinterface { } | | mapmapstring | pointer to mapmapstring | | mapmapanytype | pointer to mapmapmapinterface { } | | arrayarraynumber | pointer to [ ] [ ] float32 | | arrayarrayofinteger | pointer to [ ] [ ] int64 | | arrayarrayofmodel | pointer to [ [ ] [ ] readonlyfirst | | binary | pointer to os.file | | datetime | pointer to time.time | | mapmapofstring | pointer to mapmapstring | | datetime | pointer to time.time | | shipdate | pointer to time.time | | mapofmapproperty | pointer to mapmapstring | | arrayarraynumber | pointer to ] [ ] float32 | | arrayarrayofinteger | pointer to [ ] [ ] int64 | | arrayarrayofmodel | pointer to [ [ ] [ ] readonlyfirst | | binary | pointer to os.file | | datetime | pointer to time.time | | file | pointer to os.file | file to upload | binary | pointer to os.file | none | datetime | pointer to time.time | none | requiredfile | os.file | file to upload | mapmapofstring | pointer to mapmapstring | | datetime | pointer to time.time | | datetimeprop | pointer to nullabletime | | * shipdate | pointer to time.time | |,"this fixes some issues in go doc generation , like links to unexisting models .",1605613522,this addition to the rust-server generator enables the use of text/html responses as plaintext . <nl> i 've added an html endpoint to the sample to demonstrate that this works ( and fixed the problem that that uncovered ) .,0.89356529712677
trinodb_trino/7236,"fix queries with very large limit with redshift . <nl> redshift does not support limit 0 or more . <cm-sep> simplify phoenix limitfunction . <nl> now that limit exceeding is filtered out in <nl> , the can be simplified .",redshift does not support limit 0 or more .,1615371759,"this is just a refactor . no longer provides default <nl> implementation of and . instead , it <nl> provides these as a separate function that a connector may or may not <nl> call . notably , does not use these methods , because the <nl> oracle connector covers all its mappings explicitly . same should be <nl> applied to all other connectors .",0.812174916267395
apache_druid/10419,"automatically determine numshards for parallel ingestion hash partitioning <para-sep> we choose logk=0 because the following link shows that hllsketch with k=0 has roughly the same serialized size as hyperloglogcollector . <nl> the hllsketch objects should be created with the hll_sketch_log_k constant defined in this class . the collector is used to determine cardinality estimates for each interval . <nl> only range and hash partitioning is supported for multiphase parallel ingestion , see runmultiphaseparallel ( ) <nl> 0. need to determine numshards by scanning the data <nl> 0. partial segment generation phase <nl> aggregate all the sub-reports <nl> determine the highest cardinality in any interval <nl> determine numshards based on maxrowspersegment and the highest per-interval cardinality <nl> if there 's a remainder add 0 so we stay under maxrowspersegment <nl> id should n't be null except when this task is created by parallelindexsupervisortask <nl> noinspection constantconditions ( null rows are filtered out by filteringcloseableinputrowiterator <nl> noinspection optionalgetwithoutispresent ( inputrowiterator returns rows with present intervals ) <nl> serialize the collectors for sending to the supervisor task <nl> separate interval with only 0 value <nl> first interval in test has cardinality 0 <nl> we do n't specify maxrowspersegment so it defaults to default_max_rows_per_segment , which is 0 million , so assume that there will only be 0 shard if numshards is not set . <nl> segment granularity is day , query granularity is hour","this pr allows parallel batch ingestion to automatically determine when is used with hash partitioning . <nl> this is accomplished with a new phase of subtasks ( ) . these subtasks build a map of where the hll collector records the cardinality of the partitioning dimensions for each segment granularity interval in the input data . <nl> the supervisor task aggregates the hll collectors by interval , and determines the highest cardinality across all the intervals . this max cardinality is divided by to determine automatically",1600771016,initializing a is not cheap ; it includes parsing an expression . the should be reused in stream indexing rather than recreating it for every stream chunk . batch ingestion does n't have this issue since it decorates an with a which is a reader for the entire input data . <nl> also fixed json serde of,0.9835101962089539
elastic_elasticsearch/70640,geoipdownloaderit should be able to reuse test clusters and <nl> run tests against a test cluster with multiple nodes . <para-sep> all nodes share the same geoip base dir in the shared tmp dir :,run tests against a test cluster with multiple nodes .,1616420934,"bcjsse uses different exception messages than sun jsse , so we needed <nl> to update <nl> restrictedtrustmanagertests.testthatdelegatetrustmanagerisrespected <nl> to reflect the fact that sometimes we might receive bcjsse error <nl> messages on a java8 jvm .",0.8868304491043091
elastic_elasticsearch/70769,"fix flakiness in testretrypolicy . <nl> retrying a retryable step when the ilm loop is configured to ( as we do in <nl> the integration tests ) is a recipe for flakiness - as ilm keeps moving a failed <nl> step from back into the failed step for it to be retried , and the retry <nl> step api fails if executed when ilm is not in the step . <nl> this makes the documentation integration test more lenient . <para-sep> tag : :ilm-retry-lifecycle-policy-execute <nl> end : :ilm-retry-lifecycle-policy-execute tag : :ilm-retry-lifecycle-policy-response <nl> end : :ilm-retry-lifecycle-policy-response <nl> the retry api might fail as the shrink action steps are retryable ( so if the retry api reaches es when ilm is retrying the failed step , the retry api will fail ) assert that 's the exception we encountered ( we want to test to fail if there is an actual error with the retry api )","retrying a retryable step when the ilm loop is configured to ( as we do in <nl> the integration tests ) is a recipe for flakiness - as ilm keeps moving a failed <nl> step from back into the failed step for it to be retried , and the retry <nl> step api fails if executed when ilm is not in the step . <nl> this makes the documentation integration test more lenient .",1616517404,"when the jvm is configured to be in fips mode , the reload security settings api returns a different error message that is specific to fips when given an empty password . this pr adjust the assertions so that they are matched correspondingly .",0.8858574032783508
vespa-engine_vespa/15768,"0 hacks to be able to use zookeeper server version . <nl> explicitly depend on io.dropwizard.metrics and org.xerial.snappy since <nl> they are used by metrics provider ( even nullmetricsprovider ) when <nl> bootstrapping servermetrics in zookeeper code and can not be found <nl> when runnin in a container . <nl> do some class loadin trick to circumvent zookeeper itself loading a class <nl> with the threads current class loader , which does not work well in <nl> a container <para-sep> note : hack to make this work in zookeeper version , where metrics provider class is loaded by using thread.currentthread ( ) .getcontextclassloader ( ) which does not work well in the container","explicitly depend on io.dropwizard.metrics and org.xerial.snappy since <nl> they are used by metrics provider ( even nullmetricsprovider ) when <nl> bootstrapping servermetrics in zookeeper code and can not be found <nl> when running in a container . <nl> do some class loading trick to circumvent zookeeper itself loading a class <nl> with the threads current class loader , which does not work well in <nl> a container . <nl> there might be better ways of doing this , but this makes the zookeeper server start and work in a cluster with <nl> version and version servers . also tested that",1607551655,"if docker image is set for a node type , use that image when preloading docker image by host-admin for the corresponding host type . avoids unnecessarily downloading an image that will not be used .",0.8922600746154785
apache_beam/12578,initial draft for java worker changes <cm-sep> resolve merge conflicts <cm-sep> fix merge conflicts and format <cm-sep> minor fixes <para-sep> mark the given shardedkey and work as active . * / <nl> marks the work for a the given shardedkey as complete . schedules queued work for the key if any . <nl> make sure computationid is part of the cache key <nl> make sure sharding key is part of the cache key <nl> also add work for a different shard of the same key . <nl> verify work queues . <nl> verify a different shard of key is a separate queue . <nl> verify duplicate work dropped <nl> ensure that the this work item processes . <nl> verifies that caches are kept independently per shard of key . * / <nl> invalidation of key 0 shard 0 does not affect another shard of key 0 or other keys . <nl> invalidation of an non-existing key affects nothing .,"this is to support groupintobatches transform with runner determined sharding in dataflow . to mitigate the limited parallelism introduced by an implicit grouping on keys , we allow the states/timers associated with each input key to be shardable . <nl> this pr modifies the state and work caching in the dataflow java runner such that the states of different shards of keys are tracked separately , to prepare it for shardable groupintobatches",1597363627,"support stable id in stateful transforms . also in this pr : <nl> - use same implementation of getoffsetafter for both bounded and unbounded system <nl> - added gettable to portable translation context <nl> - change timer state to mapstate <nl> - make hashidgenerator accept longer hashes . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.965143620967865
ballerina-platform_ballerina-lang/25939,update observe lib module functions which are currently used by ballerina/http module to isolated . <nl> ideally we should make all the function in observe lib isolated .,the relevant java level implementations were updated as well to ensure thread safety .,1600426826,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.827155351638794
confluentinc_ksql/6405,"fix master build . <nl> this means the sink topic now only receives the records for the two rows that pass the filter , not the other three rows . hence the call now only waits for the two records to be produced before running the test . <nl> additionally , the name of the test was actually misleading as the logic in to filter any records not passing the having clause is actually installed as part of running the sql in the test case , so those records are filtered from any pull request anyway . <para-sep> note : having clause are handled centrally by ksqlmaterialization . this logic will have been installed as part of building the below statement : <nl> rows passing the having clause : <nl> rows filtered by the having clause : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","ksqldb now benefits from this . tombstones are no longer emitted to the sink topic when a having clause excludes a row from the result _that has never been in the result table_ . <nl> breaking change : this change fixes a _bug_ where unnecessary tombstones where being emitted when a clause filtered out a row from the source that is not in the output table . <nl> for example , given : . <nl> where previously the contents of the sink topic would have contained records : . <nl> | null . | spurious tombstone : the table does",1602504164,this format is used by kafka connect to represent date objects with no time or time zone component . <nl> in a separate commit on the same pr i also updated and to use the new udf api and to support dynamically supplied format patterns . <nl> generated and views updated docs locally .,0.960571825504303
confluentinc_ksql/6603,"check for index before removing value in undo of collect_list <para-sep> a more ideal solution would remove the value which corresponded to the original insertion but keeping track of that is more complex so we just remove the last value for now . <nl> if we can not find the value , that means that we hit the limit and never inserted it , so just return .",adds a check for the index of the last value and does nothing if it 's not found .,1605209888,"currently , if you execute a run script where the script contains a persistent query , then try to restart the ksql server , the server will fail to restart . this happens because recent changes we introduced to the recovery logic result in the server attempting to start the persistent query created by the run script twice , resulting in the following error : . <nl> the fix is simple : only start run script queries once when recovering . <nl> manual testing done . added unit test .",0.90259850025177
elastic_elasticsearch/71599,add a utility method to return runtime field values in doc value order,this adds utility methods to each type of runtime field to return the results of a document in an ordered array based on the same order that doc values are ordered in .,1618264839,"this pr would begin to issue a deprecation warning when running a date range , date histogram , or auto date histogram over a boolean field . this is currently permitted , but is unlikely to be what the user intended to do , as a histogram over the values [ 0 , 0 ] is not terribly useful . one possible way users could encounter this situation would be an index pattern that includes indexes with different mappings .",0.9047015309333801
apache_camel/4698,": camel-salesforce : streaming replayid default . <nl> salesforce now requires a value for replayid , so defaulting to 0 . <para-sep> default : 0 default : 0 default : 0 default : 0 default : 0 default : 0 default : 0","salesforce now requires a value for replayid , so defaulting to 0 .",1606585922,allows to start/stop routes based on cnames,0.8764938712120056
apache_shardingsphere/9749,revert commit <para-sep> substitutable column . <nl> get quotecharacter . <nl> substitutable column name token . <nl> add substitutablecolumn . <nl> return column.getstopindex ( ) ;,"-refactor substitutablecolumnnametoken to substitutablecolumnstoken , support rewrite sql correctly when using sharding and encrypt together .",1616159472,changes proposed in this pull request : <nl> - add parser support for sql_mode=ansi_quotes <nl> - fix parser of .,0.9637462496757507
jenkinsci_jenkins/4826,parameterdefinition check for validity . <nl> add a simple api to parameterdefinition by which a caller can validate a parametervalue for that specific definition . <para-sep> checks whether a given value is valid for this definition . <nl> the base implementation just accepts the value .,"add an api to parameterdefinition by which a caller can validate a parametervalue for that specific definition . this provides a mechanism to ensure that users can not inject unrecognized values . this is particularly useful for things like choiceparameterdefinition , which process a value as a string , but should only allow a specific set of choices . <nl> this new api is optional in two different ways : . <nl> 0. a subclass of parameterdefinition has to optionally add implementation to participate in the api . the base implementation just accepts everything as valid because it does n't",1593550876,"reduces cpu usage from the setup wizard when installing a batch of plugins . not so dramatic an improvement in oss jenkins since the time is dominated by downloading plugins from a public update center ; for cloudbees jenkins variants , where the available plugins are bundled ( ) , this speeds up installation by about 0× . <nl> most of the time in the unpatched installation is spent inside , which is apparently pretty expensive . it does not suffice to just defer this call to the end , though : a plugin ’ s generally expects its own",0.956753134727478
neo4j_neo4j/10925,"add pagecache.listexistingmappings . <cm-sep> fix an exception message spelling error in muninnpagecache . <para-sep> note : the calling code is responsible for closing the returned paged file , if any . list a snapshot of the current file mappings . the mappings can change as soon as this method returns . note : the calling code is responsible for closing all the returned paged files . <nl> flush all dirty pages .",looks like a nice thing to have .,1517310172,"individual commits tells the story , but generally this is about various issues with concurrent schema changes , such that the loaded representation of the schema may end up in state of permanently missing some updates , and also temporary reading temporarily broken schema . <nl> some of these issues has existed since the introduction of schema , but the more severe ones was introduced with the global schema lock split . <nl> the test could previously run into all these issues in one or two runs , consistently , so could reproduce very reliably . for that reason i",0.9599097371101379
Alluxio_alluxio/10878,"fix unauthenticated exception during relogin <para-sep> if there has been a failure in opening grpcchannel , it 's possible because the authentication credential has expired . relogin . <nl> disable authentication in the channel since version service does not require authentication","we recently moved relogin early before the retry loop to fix polling master client authentication . now we start to see random unauthenticated exception during the relogin time . since the polling master client does not really need the authentication , disabling it and move the relogin back inside the retry . the unauthenticated exception can no longer be observed after this change .",1581376782,"- packet writing failure is bad , so it should be error but not warning . and the stacktrace is necessary to show in the log <nl> - to prevent too much logging from the write request validation on misbehaving client , we only validate the write request when the context does not have error .",0.8409008383750916
apache_incubator-pinot/5733,[ te ] deprecate the yaml/list endpoint <para-sep> note : it is limited to list and filter the most recent 0 alerts only due to possible oom issues .,"this pr marks the ' yaml/list ' endpoint as deprecated because it is not scalable . the new endpoint '/alerts ' has been built to search the alerts more efficiently . also , this pr limits the query to 0 alerts at most to avoid possible out of memory issues .",1595455718,"currently , we emit a metric at broker level . this change makes it so that its emitted at the server level to make correlation/debugging easy . <nl> testing done : none",0.8563396334648132
Alluxio_alluxio/11466,return a report from each management task,this pr lays out the essential infrastructure for each management task to return stats in terms of how many block operations are executed/failed/backed-off .,1590140762,"0. in fuse openfile , a getstatus rpc is issued , but openfile will also issue a getstatus rpc internally , this redundant rcp is reduced in this pr . <nl> 0. when getting status of a file , or listing status of a directory , cache the status results so that future getstatus and liststatus calls do not need to issue rpcs to master . <nl> this pr introduces a new class to cache path metadata .",0.9738688468933105
pentaho_pentaho-kettle/7649,"metadata injection , save injected transformation - missing info like database logging . <para-sep> do n't clear all of the clone 's data before copying from the source object <nl> do n't clear all of the clone 's data before copying from the source object <nl> make sure realclone ( false ) is called and no other , so that the resulting ktr keeps all the info <nl> delete temporary file created by the test","metadata injection , save injected transformation - missing info like database logging .",1598635782,note : i can not squash the commits or i would lose some of the i18n file history .,0.8559800982475281
vespa-engine_vespa/16368,enable connection log for hosted configserver/controller <cm-sep> make queue size of log file handler configurable . <nl> add new config parameter for connection log and request log . <nl> scale queue size on vcpu in config model . <nl> use linkedblockingqueue instead of arrayblockingqueue .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1612358391,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9541221857070923
hazelcast_hazelcast/18231,"respect flag while computing member state . <nl> before this change , member state was considered safe once all migrations <nl> are committed . technically , after that point a member can safely execute <nl> queries . but some queries might be executed using full scans ( instead of <nl> index scans ) since global indexes are populated during the migration <nl> finalization phase which goes after the migration commit phase . <nl> tests verifying indexing behavior expect indexes to be fully populated <nl> once member state reported as safe . <nl> this fix also considers a member to be safe only after the finalization <nl> phase is finished on it , but does it in a different way without changing <nl> the migration logic .","before this change , member state was considered safe once all migrations <nl> are committed . technically , after that point a member can safely execute <nl> queries . but some queries might be executed using full scans ( instead of <nl> index scans ) since global indexes are populated during the migration <nl> finalization phase which goes after the migration commit phase . <nl> tests verifying indexing behavior expect indexes to be fully populated <nl> once member state reported as safe . <nl> this fix also considers a member to be safe only after the finalization <nl> phase is",1613637107,"field is added to . it is used to <nl> distinguish stopping from pausing ( if it 's true , wan replication is <nl> stopped , if it 's false , it 's paused ) . <nl> hardcode version that 's sent to mc as version-c1 , as memberversion <nl> does n't have qualifier and adding it is out of scope for this release .",0.8679662942886353
ballerina-platform_ballerina-lang/26821,"add utility classes to work with a collection of diagnostics <cm-sep> delete unwanted classes <cm-sep> add the default impl of the diagnosticresult class <cm-sep> introduce an enum for all project kinds <cm-sep> remove unwanted tasks from build and run commands <cm-sep> update project implements to include projectkind <cm-sep> remove unused code segments <cm-sep> improve compilation cache api to accept a bytearrayoutputstream <cm-sep> introduce various impls of compilationcache <cm-sep> cache bir and jar files during the compilation . <nl> this commit contains many related changes to the above features . it is hard to break these changes to multiple commits <cm-sep> fix checkstyle issues introduced earlier <cm-sep> remove unused task <cm-sep> fix spotbug failure in cli module <cm-sep> fix failing build related tests <cm-sep> disable some run command tests <cm-sep> add a utility to get jars and classloader from the backend <cm-sep> refactor jballerinabackend with jarresolver class <para-sep> returns a collection of platform-specific library dependencies of a given package . typically these library dependencies are specified in ballerina.toml file . <nl> returns the generated platform library of the specified module . <nl> returns the generated platform library of the specified module required to run tests . <nl> returns the platform-specific runtime library . <nl> returns the supported target platform of this compiler backend . <nl> todo this method should be moved to some other class owned by the compilerbackend <nl> represent the unique name of a supported compiler backed target . <nl> represents a collection of diagnostics generated typically by the compiler . <nl> todo this method should be moved to some other class owned by the jballerinabackend <nl> todo check whether the tests have been skipped use the compilationoptions if ( skiptests ) { return ; } <nl> todo can we move this method to module.displayname ( ) <nl> used to prevent adding duplicated entries during the final jar creation . <nl> used to process spi related metadata entries separately . the reason is unlike the other entry types , service loader related information should be merged together in the final executable jar creation . <nl> copy all the jars <nl> copy merged spi services . <nl> getting the jarfilename of the root module of this executable <nl> copies a given jar file into the executable fat jar . <nl> its not required to copy spi entries in here as we 'll be adding merged spi related entries separately .",this pr contains many changes related to the above summary .,1604912646,"this pr brings slight changes to how trace logs are used following the introduction of the config api . now , to enable http trace logs , users need to set the flag . <nl> this also introduces log level configuring to ballerina user level logging through the config api . there are several aspects to this : log api config vs. package level configs and vs. dynamic parameters . <nl> if we consider dynamic parameters , log level can be set to the entire log api through the flag . to set the log level to a specific package",0.9699885845184326
apache_pulsar/9283,issue 0 : pulsar admin : add command to list bookies <nl> - add bookies/all api <nl> - add list-bookies command <nl> - add relevant test cases <para-sep> gets discovery information for all the bookies in the cluster . <nl> gets discovery information for all the bookies in the cluster asynchronously . <nl> raw bookies information . <nl> bookie information .,"this change added tests . <nl> - does this pull request introduce a new feature ? yes <nl> - if yes , how is the feature documented ? not documented - self explaining when using pulsar-admin help <nl> - if a feature is not applicable for documentation , explain why ? it is explained in pulsar-admin help",1611321438,in some cases it 's desirable to throttle the number of http requests made against brokers to avoid impact from either malign attacks or misconfigured clients . <nl> this add a very simple servlet filter and could be later expanded with more sophisticated logic .,0.9680578708648682
apache_incubator-pinot/5376,"fix segmentcompletionprotocol to ignore unknown json fields . <nl> our compatibility guarantees are around upgrading the controller first <nl> and then the broker and then the server . so , it is possible that the <nl> controller sends a new field in the response ( in segmentcompletionprotocol ) <nl> the server should ignore new fields that it does not understand","our compatibility guarantees are around upgrading the controller first <nl> and then the broker and then the server . so , it is possible that the <nl> controller sends a new field in the response ( in segmentcompletionprotocol ) <nl> the server should ignore new fields that it does not understand",1589317262,"* currently , in retention manager ( and i am sure other places in the future ) , we have switched to deep storage . as a result , we have to construct uris out of path strings , and we do not expect for these paths to already end with slashes . so that users can still declare whatever data directory they desire , we will clean this data directory before using it .",0.8148279786109924
apache_incubator-pinot/5920,[ te ] only merge same trend in childkeepingmerge,"this pr is to fix the issue that childkeepmergewrapper merges anomalies with different trend . after this pr , the wrapper will only merge anomalies with same trend , e.g anomalies with up trend , meaning current value higher than predicted value .",1598380176,- moving monitoring window <nl> - moving window aligned to dataset granularity,0.9326238632202148
apache_shardingsphere/8929,"add unit test for agent core <para-sep> have to redefine this class dynamic , so never add modifier . <nl> have to redefine this class dynamic , so never add modifier . <nl> mock method for testing . <nl> mock method for testing with exception . <nl> have to redefine this class dynamic , so never add modifier . <nl> mock method for testing . <nl> mock method for testing with exception . <nl> mock static method for testing . <nl> mock static method for testing with exception . <nl> have to redefine this class dynamic , so never add modifier . <nl> mock static method for testing . <nl> mock static method for testing with exception .",fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,1610001837,changes proposed in this pull request : <nl> -add module sharding-orchestration-config-center <nl> -add module sharding-orchestration-config-center-api <nl> -add module sharding-orchestration-config-center -- zookeeper-curator,0.9945230484008789
elastic_elasticsearch/72442,simplify outboundhandler . <nl> the whole serializer class adds nothing but complexity . simplified it away <nl> to make this code easier to read while saving some objects as well and making <nl> the slow warning serialize slightly nicer .,the whole serializer class adds nothing but complexity . simplified it away <nl> to make this code easier to read while saving some objects as well and making <nl> the slow warning serialize slightly cleaner to read .,1619676925,"this makes keywordfieldmapper extend parametrizedfieldmapper , with explicitly <nl> defined parameters . <nl> in addition , we add a new option to parameter , , which <nl> accepts a restricted set of string options .",0.9442125558853149
apache_druid/10211,"fix minor formatting in docs . <cm-sep> add nullhandling initialization for test to run from ide . <cm-sep> vectorize longmin aggregator . <nl> - a new vectorized class for the vectorized long min aggregator . <nl> - changes to aggregatorfactory to support vectorize functionality . <nl> - few changes to schema evolution test to add longminaggregatorfactory . <cm-sep> add longsum to the supported vectorized aggregator implementations . <cm-sep> add min ( ) long min to calcite query test that can vectorize . <cm-sep> add simple long aggregations test . <para-sep> aggregatorfactory is a strategy ( in the terms of design patterns ) that represents column aggregation , e.g . min , had value [ ' 0 ' , ' 0 ' , ' 0 ' ] , doublesum aggregation would take each of them and sum them to 0 . <nl> nothing to close . <nl> index2 : c1 is a long , c2 is a string , ' uniques ' is uniques on c2 , ' longmin ' is min on c1 <nl> only long ( 0 ) -- which we can filter and aggregate <nl> some sanity . <nl> groupby handles timestamps differently when granularity is all","this patch adds vectorization support for the aggregator to speed up queries that use the aggregator . <nl> summary of changes : <nl> - added a new class that implements the interface . <nl> - modified some existing test cases to include this vectorized in . <nl> - added a new simple test case to each and . modified some test cases in and , to demonstrate that vectorization _does_ work for the aggregator . <nl> - enabled null handling in the to test both null-compatibility and non null-compatibility code paths . <nl> - query context documentation update . <nl>",1595608862,this pr modifies the input sources to skip empty files except for the http input source . this pr additionally fixes the two bugs :,0.974697470664978
ballerina-platform_ballerina-lang/24621,fix npe at certificate retrieving with invalid alias <cm-sep> generalize assertion for crypto tests,suspect the issue is due to the jdk version mismatch . the objective of the test cases are still valid .,1594102060,also updated the ast models .,0.8521032929420471
apache_camel/4844,": upgrade debezium to version.final <cm-sep> : upgrade debezium to version.final <para-sep> this property contains a comma-separated list of . , for which the initial snapshot may be a subset of data present in the data source . the subset would be defined by mongodb filter query specified as value for property snapshot.collection.filter.override .. <nl> maximum size of the queue for change events read from the database log but not yet recorded or forwarded . defaults to 0 , and should always be larger than the maximum batch size . <nl> a comma-separated list of regular expressions that match the collection names for which changes are to be captured <nl> time to wait before restarting connector after retriable exception occurs . defaults to 10000ms . <nl> the number of milliseconds to delay before a snapshot will begin . <nl> enables transaction metadata extraction together with event counting <nl> whether delete operations should be represented by a delete event and a subsquenttombstone event ( true ) or only by a delete event ( false ) . emitting the tombstone event ( the default behavior ) allows kafka to completely delete all events pertaining to the given key once the source record got deleted . <nl> database containing user credentials . <nl> the initial delay when trying to reconnect to a primary after a connection can not be made or when no primary is available . defaults to 0 second ( 0 ms ) . <nl> a comma-separated list of regular expressions that match the collection names for which changes are to be excluded <nl> this setting must be set to specify a list of tables/collections whose snapshot must be taken on creating or restarting the connector . <nl> the path to the file that will be used to record the database history <nl> maximum number of failed connection attempts to a replica set primary before an exception occurs and task is aborted . defaults to 0 , which with the defaults for 'connect.backoff.initial.delay.ms ' and 'connect.backoff.max.delay.ms ' results in just over 0 minutes of attempts before failing . <nl> maximum size of the queue in bytes for change events read from the database log but not yet recorded or forwarded . defaults to 0. mean the feature is not enabled <nl> the socket timeout in milliseconds <nl> specify how failures during processing of events ( i.e . when encountering a corrupted",note debezium version.final depends on kafka version which is our current kafka version in camel,1610098043,- fix ( ) : propagate inline count in camel-olingo2 component . <nl> add result count ( coming from system query option $ inlinecount ) to odata entries when using splitresults . <nl> - fix ( ) : configure entity provider properties on camel-olingo2 . <nl> add uri param configuration settings for read/write entity provider properties . the entity provider properties are used for each read/write operation and specify the way to serialize odata entries as json/xml/atom data . <nl> - fix ( ) : fix merge operation in camel-olingo2 . <nl> merge operation must enable isdatabasedpropertyserialization setting in the,0.9453179836273193
apache_incubator-pinot/5744,add geo aggregate function <para-sep> geo aggregation functions <nl> constructor for the class . <nl> queries test for st_union queries . <nl> inner segment <nl> inter segments <nl> inner segment <nl> inter segments <nl> inner segment <nl> inter segments <nl> size of this array will be equal to number of aggregation functions since we return each aggregation function separately,"does this pr otherwise need attention when creating release notes ? things to consider : <nl> - yes , new user-facing aggregation function .",1595531174,implements the runner that generates data sla anomalies . data_missing anomalies are created if the data is not available for the sla detection window within the configured sla . <nl> also inclues : <nl> * logic to merge sla anomaly with existing and mark them as parent-child . <nl> * unit tests covering various data missing use-cases,0.9738572239875793
ballerina-platform_ballerina-lang/23950,fix potential npes when mapping jvm types to ballerina variables . <nl> ( cherry picked from commit sha ) <cm-sep> add support for bstrings and jvm integer types . <nl> ( cherry picked from commit sha ) <cm-sep> fix nested variables of bstring type . <nl> ( cherry picked from commit sha ) <cm-sep> update spotbugs-exclude.xml . <nl> ( cherry picked from commit sha ) <cm-sep> fix breakpoint path issue due to new module versioning <para-sep> extracts relative path of the source file location from jdi class-reference mappings . <nl> removes module version part from the jdi reference source path . <nl> removes module version part from the jdi reference source path .,- adds support for bstrings and jvm integer types .,1591871327,now there are child buckets with values in both internal and external syntax tree nodes . but the public api does not expose those null values due to the usage of optional .,0.9705268740653992
apache_ignite/8946,"refactor pdsconsistentidprocessor for reusage <para-sep> here deprecated method is used to get compatible version of consistentid <nl> database subfolders constant prefix . * / <nl> node index and uid separator in subfolders name . * / <nl> constant node subfolder prefix and node index pattern ( nodeii , where ii - node index as decimal integer ) * / <nl> uuid as string pattern . * / <nl> subdir ( nodeii-uid , where ii - node index as decimal integer , uid - string representation of consistent id ) pattern . <nl> database subfolders for new style filter . * / <nl> database subfolders for old style filter . * / <nl> database default folder . * / <nl> * / <nl> * / <nl> * / <nl> * /",this pr extracts logic for finding pds folders in . <nl> this new class intended to be reused in ignite-related applications which do n't have available,1617090564,* add affinitycall and affinityrun overloads that take multiple cache names and partition <nl> * fix existing affinitycall and affinityrun : use proper java apis that reserve the partition instead of custom task-based implementation,0.9688882231712341
trinodb_trino/7262,"simplify exception message asserts in testrowfilter . <nl> no need to use regular expressions when the entire thing is quoted . <cm-sep> add testrowfilter # testdelete . <nl> the similar testcolumnmask has tests for and , but this <nl> one was missing them . only makes sense here , though , because <nl> you can freely rows when row filtering is enabled . <cm-sep> simplify exception message asserts in testcolumnmask . <nl> no need to use regular expressions when the entire thing is quoted . <cm-sep> add update tests to testcolumnmask and testrowfilter . <nl> this is for completeness : there are already tests for and <nl> , and needs to be tested too .","the tests for access control with row filtering and column masking were incomplete with regards to update statements : the already had tests for and , but missed them , and both missed tests for . this pr adds the missing pieces . <nl> includes a side-refactoring of exception message asserts .",1615476913,add test coverage for show create view,0.8387715816497803
Graylog2_graylog2-server/8929,add unique index for grantee and entity . <nl> there should be only one grant per grantee and entity . <nl> having multiple will even break some of our code . <nl> better fail early .,there should be only one grant per grantee and entity . <nl> having multiple will even break some of our code . <nl> better fail early .,1599493797,"currently , the gelf http input does n't work without specifying . clients will report a timeout when attempting to submit data . this is due to the fact that , when in keep-alive mode , it must respond with a content-length so the client knows when the data is finished sending . there are some cases where specifying a header is not possible . some load balancers strip or change this header when proxying the request . <nl> this pr adds a content-length header to the response . since we never send any data back , the content-length is",0.8148439526557922
confluentinc_ksql/6200,"register correct unwrapped schema . <nl> this commit fixes several issues and refactors a lot of the serde code around wrapping and unwrapping single values . <nl> the main issues being fixed are : <nl> 0. allow each format to define if it supported wrapping and/or unwrapping . ( not possible with current design ) <nl> 0. pass the correct wrapping / unwrapping flags are passed to key vs value formats when creating serde . ( bug in code passes same serdeoptions to key and value ) . <nl> 0. register the correct wrapped / unwrapped schema with the sr. ( bug in existing code meant registered format is always wrapped ) . <nl> at the same time , the way wrapping / unwrapping was handled in the code was n't great . formats like needed to be able to handle both wrapped and unwrapped schemas and values , depending on whether the user _explicitly_ set wrapping or unwrapping , vs the default behaviour of the format . this commit refactors the code such that the format will always be passed the a consistent schema and the set of serde features the format should use when creating the serde . this simplifies things and paves the way to user-define-serde . <cm-sep> historic plans <cm-sep> almog 's requested changes <cm-sep> push connectschema down . <nl> higher levels of the code now deal with , or just a . <nl> this moves us closer to removing the connect schema from the code base , except in the serde code that deals with connect formats . <nl> and no longer know about the connect schema type . calls to retrieve the connect schema from these types have been replaced with a util function that can convert a list of columns into a struct connect schema . as more code moves away from the connect schema these util function calls will slowly be removed . <para-sep> there are a lot of different schema types in ksql . it is a schema that represents how parts of a row should be serialized , or are serialized , e.g . the kafka message 's value or key .","higher levels of the code now deal with , or just a . <nl> this moves us closer to removing the connect schema from the code base , except in the serde code that deals with connect formats . <nl> and no longer know about the connect schema type . calls to retrieve the connect schema from these types have been replaced with a util function that can convert a list of columns into a struct connect schema . as more code moves away from the connect schema these util function calls will slowly be removed . <nl> a good",1600125263,"first part of supporting key column names other than . <nl> with this initial pass you can now name your key columns anything you want in your and statements , e.g . <nl> any group by , partition by or join on the key column results any created data source having a key column with a matching name , e.g . <nl> pull and push queries work as expected and quoted identifiers work too . <nl> however , this functionality is not complete yet . hence it is guarded by the feature flag , which defaults to off . the",0.9862687587738037
apache_druid/10272,"fix router jdbc prepared statement connectionid issue <cm-sep> column metadata too <cm-sep> style <para-sep> ensure that wikipedia segments are loaded completely <nl> maybe more schemas than this , but at least should have these <nl> maybe more tables than this , but at least should have these <nl> a lot more columns than this , but at least should have these <nl> avatica commands always have a 'connectionid ' . if commands are not part of a prepared statement , this appears at the top level of the request , but if it is part of a statement , then it will be nested in the 'statementhandle ' .","per the docs , all requests either have a top level , or , if part of a prepared statement , the might be nested in a , so the router will now check for this case . there are probably more magical ways to do this , but this was the most straightforward . <nl> integration tests have been added to test jdbc metadata , statements , and prepared statements to make sure things work on both brokers and routers . the prepared statement query test fails prior to the changes in this patch",1597288805,"currently , the index_parallel supervisor task kills sub tasks when one of them fails , but it does n't if someone kills itself . this pr is to kill sub tasks in of the supervisor task .",0.9629334807395935
keycloak_keycloak/6612,fix export/import for users that have custom credential algorithms with no salt,fix export/import for users that have custom credential algorithms with no salt .,1576769674,only checked master and realm admin roles when roles are specified in imported realm to speed up realm creation,0.8644837141036987
apache_flink/14802,introduce a new interface for catalog to listen on temporary object operations,"introduce a new interface for catalog to listen on temporary object operations . <nl> add an interface for a catalog to listen on temporary object operations . <nl> - add interface which will be invoked when a temporary table/view/function is created or dropped . <nl> - if a catalog implements the above interface , will inform it when a temporary table/view is created or dropped in that catalog . <nl> - if a catalog implements the above interface , will inform it when a temporary function is created or dropped in that catalog . <nl> - add a test case",1611906182,"splits into and . the latter should use indices of input and field within input as a reference rather than simply always looking up field by name . <nl> proper use of the fieldreferenceexpression is not part of this pr . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : (",0.9588971138000488
runelite_runelite/12828,update grandexchangeconfig.java . <nl> provides more descriptive text hints . <cm-sep> update grandexchangeconfig.java . <nl> add more descriptive hint text to the grand exchange plugin settings .,updates the hint text for the settings to be more descriptive,1606020749,change ' plate skirt ' to ' plateskirt ' for dance clue in party room issue 0 comment <nl> change ' plate skirt ' to ' plateskirt ' for cheer clue at port sarim issue 0 comment <nl> change location for wave clue on mudskipper point to be next to stash hole issue 0 comment <nl> change ' iron med helm ' to ' iron medium helmet ' for clap on the causeway to the wizards ' tower clue . issue 0 comment .,0.9084694385528564
ballerina-platform_ballerina-lang/25184,skip type narrowed symbols for arrow function scope . <nl> we should skip type narrowed symbols in the scope for arrow expr <nl> and the same it is done for lambda functions as well . <cm-sep> add test cases covering arrow expr type narrowing <para-sep> should fail operator '+ ' not defined for 'string ' and ' ( string|int ) ',"however , for any lambda , it was deciede not to type narrow and use the original symbol as it it . <nl> the follwing will now fail with compilation error . <nl> this pr fixes the issue with arrow expresions . lambda functions are working as expected .",1597032012,"grpc blocking client call , does n't handle error responses properly . so return value to ballerina becomes null . so we set error type as return value . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9117996096611023
elastic_elasticsearch/71262,whitespace <cm-sep> extract common setup <cm-sep> add a failing test <cm-sep> explicitly check for a zero-length source . <nl> not just for an absent content-type,"there 's explicit validation with nice error messages if you do n't submit a watcher body , but it looks to me like there 's an error in the logic such that the validation and nice error messages do n't actually hit if you specify a content-type but not a body . this fixes that ( and adds a test ) . <nl> just a minor thing , but i ran into it with the rest compatibility api work , because in those tests we always send a content-type , so the test was suddenly blowing up on me because",1617400576,"take into account messy scenarios of 0 node clusters elections <nl> where multiple nodes can trigger an election concurrently , meaning <nl> that it takes longer to stabilize the cluster and elect a leader .",0.8356451988220215
ballerina-platform_ballerina-lang/23560,fix tag filter issue <cm-sep> add exclude attribute <cm-sep> fix suggestions <cm-sep> remove comments <para-sep> checking both tags and excludetags include same tags and operations,add the extra fields excludetags and excludeoperations to opeanapi annotation . this use to filter the tags and operations that exclude validating .,1590640725,"with this phase of the auto-imports feature , we allow auto importing of packages available in the ballerina sdk .",0.9726207256317139
apache_kafka/9942,": reset to original class loader after connector stop <cm-sep> : remove unneeded change <para-sep> we should keep the original class loader and set it back after connector stopped since the connector will change the class loader , and then , the mockito will use the unexpected class loader to generate the wrong proxy instance , which makes mock failed","after days of investigation , i finally found the root cause of the test failure reason : class loader . <nl> the issue is quite weird , we mocked the method , but still call the real method , and cause the npe . digging into the mockito , found it 's not about junit 0 , it 's because of the class loader . <nl> so , there 's an interference of integration tests with unit tests when connect integration tests run before the mm2 unit tests , and that will cause the mockito used in unit tests not",1611195479,"securitytest.test_client_ssl_endpoint_validation_failure is failing because it greps for 'sslhandshakeexception in the consumer and producer log files . with the fix for , the test uses the verifiableconsumer instead of the consoleconsumer , which does not log the exception stack trace to the service log . this patch catches exceptions in the verifiableconsumer and logs them in order to fix the test . tested by running the test locally .",0.8894219398498535
elastic_elasticsearch/70952,this change moves the implementation of point in time to the server package . <para-sep> all shards are still search-idle as we did not acquire new searchers,this change moves the implementation of point in time to the server package .,1616950273,"this field mapper only lived in its own module so it could be licensed as x-pack <nl> basic . now it can be moved to core , which matches its status as a core type . <nl> this commit does n't bring major code simplification yet , but it does improve <nl> how the tests are factored .",0.9433194398880005
apache_pulsar/9985,fix npe caused by null value of schema properties <para-sep> null key will be skipped by gson when serializing json to string,"if there exists a null value of 's properties , npe will be thrown in or . <nl> - add null checks before 's constructor , and . <nl> - add related tests . <nl> this change added tests and can be verified as follows : and .",1616224041,"if consumer acks batch-messages concurrently , then client-consumer is not acking the message to broker even if consumer acks all batch-index-msg with in that batch-message . which tracks unack-batch-message is not thread-safe and it accessed by multiple thread while acking and therefore , it fails to conclude that all messages have been acked . <nl> make access of thread-safe . <nl> batch-msg ack will be thread-safe .",0.9378714561462402
elastic_elasticsearch/71861,broekn <cm-sep> add index-time scripts to geo_point field mapper,"this commit adds the ability to define an index-time geo_point field <nl> with a parameter , allowing you to calculate points from other <nl> values within the indexed document .",1618848886,"adds a setting that , when enabled , directs any currently running exporters in monitoring will treat any cluster alert definition as excluded from the list of allowed cluster alert watches . this is the first step to adding a migration path away from using cluster alerts configured by the monitoring plugin and toward those managed by the stack monitoring solutions on the new alerting feature .",0.9766439199447632
confluentinc_ksql/6353,add an endpoint for returning the query limit configuration <cm-sep> fix merge conflict <para-sep> when : <nl> then : <nl> when : <nl> then :,"currently , only the persistent query limit can be requested .",1601674675,"this allows us to make known backwards-compatible changes to ksql that would previously have caused an existing test to fail , e.g . changing the name of the internal topics . with this commit we can mark the old test as only valid up to the last version and create a new version of the test for , with a min version , to test versions going forward . <nl> e.g . <nl> 0. now accepts an optional . <nl> 0. , which is built from , now expects a <nl> 0. no longer takes the param , as it",0.9808019995689392
apache_kafka/9904,: do n't change perm for base/state dir when no persistent store,"but we forgot to consider one situation : if user does n't have persistent stores , we wo n't create base dir and state dir . and if there 's no such dir , and when we tried to set permission to them , we 'll have .",1610701818,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.897082507610321
grpc_grpc-java/7337,"fix a bug for hedging with throttling <para-sep> the invariant is whether or not # ( potential hedge + active hedges ) > 0. once haspotentialhedging ( state ) is false , it will always be false , and then # ( state.activehedges ) will be decreasing . this guarantees that even there may be multiple concurrent hedges , one of the hedges will end up committed . <nl> else , no activehedges , no new hedges possible , try to commit <nl> the check state.winningsubstream == null , checking if is not already committed , is racy , but is still safe b/c the retry will also handle committed/cancellation <nl> retry",refactored to two separate classes and .,1597772839,"roll-forward of sha . <nl> the added unit test does n't really reveal the issue being fixed , as the breakage happens only on android . just leave it for coverage .",0.9481850862503052
Graylog2_graylog2-server/9567,<para-sep> user fields <nl> to be removed <nl> to be removed <nl> user fields,the main purpose of backporting this change to is to fix the value .,1605889959,this change adds the following metrics for extractors : . <nl> * conditionhits ( number of times the condition succeeded ) <nl> * conditionmisses ( number of times the condition failed ) <nl> * conditiontime ( time spent in evaluating the condition ) <nl> * completeexecutiontime ( total time spent in the extractor ) .,0.8833686113357544
Graylog2_graylog2-server/9171,"checking if a url is whitelisted should not require permissions . <nl> otherwise users which posess the new creator roles <nl> can not create objects that perform a url whitelist check . <nl> ( e.g . creating a httpeventnotification ) . <nl> thus , we should allow any authenticated user to check if urls are whitelisted . <cm-sep> avoid calling _setdefaultwhiteliststate ( null ) . <nl> this happens if the user has no read access for the urlwhitelists <para-sep> checking can be done without any special permission .","otherwise users which possess the new creator roles <nl> can not create objects that perform a url whitelist check . <nl> ( e.g . creating a httpeventnotification ) . <nl> thus , we should allow any authenticated user to check if urls are whitelisted .",1602765229,"when introducing the messageprocessor interface , the processing threads accidentally shared the instances ( and by induction the messagefilter instances as well ) . <nl> that posed no problem for most of the filters , because they do not rely on shared state , but the drools filter does and could skip messages ( because of drools itself returning early ) . <nl> this change uses a provider to get the orderedmessageprocessor instances explicitly and those do not get shared across threads .",0.6499444842338562
elastic_elasticsearch/71146,[ ml ] waiting for no initialization shards + for stats index,"in the high level rest client tests , we should clean up trained models , same as we do for datafeeds , jobs , etc . <nl> but , to delete a trained model , it needs to not be used in a pipeline , so we grab the model stats . <nl> this commit does : <nl> - waiting for no more initializing shards when ml integration tests are cleaning up before attempting to delete things <nl> - the specific inference stats test now waits for the index to exist before continuing <nl> - and we make sure that",1617221799,this pr will update the current role so that the role allows both the old direct access to indexes as well as the use of the new plugin .,0.8817287683486938
apache_kafka/10073,: fix handling of null values by flatten smt <para-sep> use a linkedhashmap to ensure the smt sees entries in a specific order,"using instead of when encountering null fields causes the remainder of the fields to be skipped . this pr addresses that , and adds a lightweight unit test that is able to reproduce the error on current versions of connect , and verify the accuracy of the fix .",1612579526,* fix dataexception thrown when handling tombstone events with null value <nl> * passes through original record when finding a tombstone record <nl> * add tests for schema and schemaless data .,0.9498586058616638
apache_druid/10240,"support redis cluster <cm-sep> add 'password ' , 'database ' properties <cm-sep> test cases passed <cm-sep> update doc <cm-sep> some improvements <para-sep> both get、put and getbulk will increase request count by 0 <nl> no resources to cleanup <nl> cluster <nl> support for long-format and period style format <nl> before version , only long-format is support , try to parse it as long <nl> try to parse it as a period string <nl> kept for test cases only <nl> host of a standalone mode redis port of a standalone mode redis <nl> max connections of redis connection pool max idle connections of redis connection pool min idle connections of redis connection pool <nl> orginal mockjediscluster does not provide full support for all public get/set interfaces some methods must be overriden for test cases <nl> test put and get <nl> test multi get <nl> orginal mockjedis do not support 'milliseconds ' in long type , for test we override to support it","the orignal redis cache extension is designed for standalone redis only , and does not support a couple of redis features which are widely used in production . so this pr updates the redis cache extension to : . <nl> 0. add support for redis cluster <nl> 0. allow users to customize which database of a redis they want to use through new property <nl> 0. add support for password protected redis servers through new property <nl> 0. allow period style configuration for the existing and properties . <nl> 0. orignal is splitted into and , the first provides a",1596598291,"as was used only for pooling memcache clients , it is specialized as .",0.9785871505737305
apache_kafka/10170,"set timestamp <para-sep> when punctuating , we need to preserve the timestamp ( this can be either system time or event time ) while other record context are set as dummy : null topic , 0 partition , 0 offset and empty header <nl> assign single partition",# # # committer checklist ( excluded from commit message ) .,1613891847,unit tests <nl> - <nl> - <nl> - <nl> verify that bug is fixed with the new . <nl> ensures that tasks are evenly assigned over clients when all overprovisioned clients join <nl> simultaneously . <nl> ensures that warm-up tasks are assigned to two new clients that join the group <nl> although the assignment is already balanced over stream threads . <nl> ensures that stateful active tasks are balanced over previous and warmed-up client <nl> although it the previous assignment is balanced over stream threads .,0.9513457417488098
pentaho_pentaho-kettle/7529,modified javascript value : bignumber value incorrect in non-compatability mode - unit tests <cm-sep> optimizations,modified javascript value : bignumber value incorrect in non-compatability mode .,1594836305,addding scale.java ; passing hardcoded strings to const.java ; adding a few more tests on panit .,0.9058091640472412
apache_pulsar/8871,export prometheus metric for messagettl <para-sep> let the message expire <nl> wait for checkmessageexpiry <nl> there should be 0 metrics with different tags for each topic <nl> check value <nl> check value <nl> check value <nl> total messages expired on this subscription . * /,"currently , these metrics are too few , so that ttl looks like a black box , unobservable .",1607493390,"currently we do n't have a way to unset offload policies for namespaces , we may need one . <nl> add a rest api . <nl> ( please pick either of the following options ) . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> ( or ) . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> ( or ) . <nl> this change added tests and can be verified as follows : . <nl> ( example : ) <nl> - added",0.9691925048828125
apache_shardingsphere/10217,update sqlserverdatabasetype.java . <nl> modify sqlserver database type condition,modify sqlserver database type condition . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,1619682191,"fixes apollo debug & warn log , control log out by slf4j xml file .",0.8643556833267212
apache_incubator-pinot/5312,"inbuiltfunctionevaluator implements functionevaluator interface <cm-sep> add some tests <cm-sep> add test case to extractsourcefields <para-sep> inbuilt date time related transform functions todo : exhaustively add all time conversion functions <nl> convert epoch millis to epoch hours <nl> convert epoch millis to epoch minutes , bucketed by given bucket granularity <nl> evaluates a function expression . this is optimized for evaluating the an expression multiple times with different inputs . overall idea parse the function expression into an expression tree convert each node in the expression tree into and executablenode an executablenode can be a functionnode - executes another function columnnode - fetches the value of the column from the input genericrow constantnode - returns the same value typically constant function arguments are represented using a constantnode <nl> root of the execution tree <nl> interface for evaluators of transform function expressions of schema field specs <nl> get the arguments of the function <nl> evaluate the function on the generic row and return the result <nl> if transform function expression present , use it to generate function evaluator <nl> for backward compatible handling of time field conversion <nl> for backward compatible handling of map type ( currently only in avro ) <nl> for backward compatible handling of map type in avro ( currently only in avro ) <nl> registry for inbuilt pinot functions <nl> groovyshell is used to execute expressions . the transform expression must follow the convention groovy ( { expression } , arguments1 , argument2 ... ) for example : ' dimensionfieldspecs ' : [ { ' name ' : ' fullname ' , ' datatype ' : ' string ' , ' transformfunction ' : ' groovy ( { firstname+ ' '+lastname } , firstname , lastname ) ' } ] <nl> fixme : if any param is null a ) exit or b ) assume function handles it ? <nl> performs time transformation <nl> toepochhours <nl> toepochminutes w/ bucketing fixed <nl> tests groovy functions for transforming schema columns <nl> inbuilt functions <nl> inbuilt functions with literal <nl> tests the recordreader for schema with transform functions",wiring the functionexpressionevaluator with the expressionevaluatorfactory to be able to execute inbuilt transform functions . <nl> added 0 simple time transformation examples . <nl> immediate next steps : <nl> 0 ) exhaustively add a lot of time transformation functions . can be a good beginner/first task . <nl> future steps : <nl> 0 ) ability to plug in user defined custom functions - annotation based function registering <nl> 0 ) ability to use these simple transform functions as query time udfs - introduce a udf wrapper that can call these simple transform functions on every row during query,1588035599,separated data and anomaly reports modules,0.9769646525382996
jenkinsci_jenkins/5015,separate security / non-security admin monitors . <nl> + improve performance by calling them only once per page ( instead of 0 ) <para-sep> returns true if this monitor is security related . this will be used to determine which icon will be used in the navigation bar . <nl> show notifications and popups for active administrative monitors on all pages . used by jelly <nl> used by jelly <nl> compute the administrative monitors that are active and should be shown . this is done only when the instance is currently running and the user has the permission to read them . <nl> hide non-security monitors on mobile view to avoid messing up the heading * / <nl> non-security monitor / bell-alert new colors <nl> security monitor / shield new colors,"+ improve performance by calling them only once per page ( instead of 0 ) <nl> + adding a new icon for the ' security warnings ' ( see screenshots ) . <nl> screenshots . <nl> ℹ️ if you want to change small things ( color , wording , contrast , etc . ) , you 're welcome to directly commit in this pr . that could prevent ping-pong discussion and if something is terribly ' wrong ' it could be reverted , so no worries . <nl> separation of notifications into security and non-security categories with their associated icons",1603052873,"reduces cpu usage from the setup wizard when installing a batch of plugins . not so dramatic an improvement in oss jenkins since the time is dominated by downloading plugins from a public update center ; for cloudbees jenkins variants , where the available plugins are bundled ( ) , this speeds up installation by about 0× . <nl> most of the time in the unpatched installation is spent inside , which is apparently pretty expensive . it does not suffice to just defer this call to the end , though : a plugin ’ s generally expects its own",0.9293280839920044
confluentinc_ksql/6345,"wire up key_format in c * as statements <para-sep> overwrite any inheritable properties if they were explicitly specified in the statement <nl> statement wo n't parse : this will be detected/handled later . <nl> catch block allows negative tests to fail in the correct place , i.e . later . <nl> current none .... coming soon .",wire up and explicitly provided in c * as statements . <nl> usual .,1601561022,"as it 's horrible ! synthetic join columns now have system generated column names in the form . <nl> commits : . <nl> 0. prod code changes . <nl> 0. doc changes to bring the klip inline with the implementation . <nl> 0. test code changes . <nl> 0. historical plans - including removal of any historic plans that use the joinkey udf , which has never been released . <nl> usual .",0.9552214741706848
neo4j_neo4j/11356,"remove eagerization of index seeks . <cm-sep> use two bounding boxes for circles touching the date line . <nl> index seeks with distance queries where the circle touches the date line <nl> are now planned with two small bounding boxes at either side of the <nl> date line and concatenating the results , instead of having one <nl> than bounding box extending over all longitudes . <para-sep> large rectangle covering all longitudes <nl> two small rectangles east and west of dateline <nl> two small rectangles east and west of dateline <nl> given <nl> create enough points so that an index seek gets planned <nl> then","index seeks with distance queries where the circle touches the date line <nl> are now planned with two small bounding boxes at either side of the <nl> date line and concatenating the results , instead of having one <nl> than bounding box extending over all longitudes .",1521731877,lets try to duplicate property value holder instead of reference it twice .,0.900232195854187
elastic_elasticsearch/71503,"tests for runtime field queries with fbf aggs . <nl> this adds a few tests for runtime field queries applied to <nl> ' filter-by-filter ' style aggregations . we expect to still be able to <nl> use filter-by-filter aggregations to speed up collection when the top <nl> level query is a runtime field . you 'd think that filter-by-filter would <nl> be slow when the top level query is slow , like it is with runtime <nl> fields , but we only run filter-by-filter when we can translate each <nl> aggregation bucket into a quick query . so long as the results of those <nl> queries do n't ' overlap ' we should n't end up running the slower top level <nl> query more times than we would during regular collection . <nl> this also adds some javadoc to that effect to the two places where we <nl> chose between filter-by-filter and a ' native ' aggregation <nl> implementation . <cm-sep> drop method we do n't need <cm-sep> fix bug <para-sep> it 's totally possible that there might be a top level query that was generated by a runtime field . that query might indeed be slow , but we wo n't execute it any more times doing filter-by-filter then we would doing regular collection . <nl> the thing is , we wo n't be executing the script more times than we would if it were just at the top level . <nl> the thing is , we wo n't be executing the script more times than we would if it were just at the top level . <nl> we do n't estimate the cost here so these should n't show up <nl> do n't use searchandreduce because we only want a single aggregator .","this adds a few tests for runtime field queries applied to <nl> ' filter-by-filter ' style aggregations . we expect to still be able to <nl> use filter-by-filter aggregations to speed up collection when the top <nl> level query is a runtime field . you 'd think that filter-by-filter would <nl> be slow when the top level query is slow , like it is with runtime <nl> fields , but we only run filter-by-filter when we can translate each <nl> aggregation bucket into a quick query . so long as the results of those <nl> queries do n't ' overlap",1617915375,"this commit adds validation that when a composable index template is updated , that the number <nl> of unreferenced data streams does not increase . while it is still possible to have data streams <nl> without a backing template ( through snapshot restoration ) , this reduces the chance of getting <nl> in to that scenario .",0.9600971937179565
hazelcast_hazelcast/18347,do n't shift expiry time when scanning over index <para-sep> free memory of expired record <nl> check that evaluating the predicate did n't update the last access time of the returned records,modifications : <nl> - removed usage and related delegates,1614784410,- replaced with <nl> - removed unused and,0.9569894075393677
OpenAPITools_openapi-generator/7465,option to clean files before generation <para-sep> hack : disallow directory traversal outside of output directory . we do n't want to delete wrong files .,"this provides a means to fully remove files which were previously generated . this adds a option to the cli 's batch command . this is not done by default in the ensures script , but can be enabled via : . <nl> functionally , this loops over each line in the target directory 's file , verifies that the file is below the target directory , and deletes it . <nl> this is implemented only in the command for now , and we can include elsewhere if people would like .",1600658202,"…rializable , by adding the config option serializablemodel= ( true|false ) . <nl> if kotlin data classes implement the interface java.io.serializable , they should have a companion object defining a serialversionuid of type long . <nl> therefore , these templates have been changed accordingly : . <nl> * kotlin-server/data_class.mustache <nl> * kotlin-client/data_class.mustache",0.9208381175994873
apache_shardingsphere/10015,refactor shardingsphereauthority to authoritycheckalgorithm <cm-sep> remove privilegeloadalgorithm <cm-sep> remove authorityengine <cm-sep> move storageauthoritycheckalgorithm <cm-sep> refactor authoritycontext <cm-sep> move storage loader package <para-sep> authority check algorithm . <nl> initialize authority . <nl> find privileges . <nl> authority context . <nl> get instance . <nl> initial authority checker . <nl> storage authority check algorithm . <nl> storage privilege load engine . <nl> load privileges . <nl> storage privilege loader . <nl> load privilege . <nl> storage privilege builder . <nl> build privileges . <nl> build default privileges . <nl> storage privilege merger . <nl> merge privileges . <nl> mysql privilege loader . <nl> oracle privilege loader . <nl> todo other privilege <nl> postgresql privilege loader . <nl> todo consider about merge userrulechangedevent and privilegechangedevent <nl> todo reload authoritycheckalgorithm from spi,the yaml to config authority changed to : .,1617983265,changes proposed in this pull request : <nl> - refactor rdbmsconfiguraton <nl> - refactor syncconfiguration <nl> - refactor inventorydatatasksplitter <nl> - refactor synctaskfactory,0.970397412776947
elastic_elasticsearch/72032,"add integration test for nodes caches stats api <para-sep> here to ensure no shard relocations after the snapshot is mounted , since this test verifies the cache stats on specific nodes","nb : i tried to make better assertions for the various stats reported but it complicates the test a lot with poor value , i think .",1619018624,currently the transportbulkaction detects whether an index is missing and <nl> then decides whether it should be auto created . the coordination of the <nl> index creation also happens in the transportbulkaction on the coordinating node . <nl> this change adds a new transport action that the transportbulkaction delegates to <nl> if missing indices need to be created . the reasons for this change : . <nl> * auto creation of data streams ca n't occur on the coordinating node . <nl> based on the index template ( v2 ) either a regular index or a data stream should be,0.9374544620513916
elastic_elasticsearch/71552,"[ ml ] use feature reset api in ml rest test cleanup . <nl> now that we have a feature reset api , we should use <nl> this for cleaning up in between tests instead of running <nl> lots of bespoke cleanup code . <para-sep> cleans up ml resources created during tests <nl> this resets all features , not just ml , but they should have been getting reset between tests anyway so it should n't matter <nl> this resets all features , not just ml , but they should have been getting reset between tests anyway so it should n't matter <nl> the feature reset api touches transform custom cluster state so we need this plugin to understand it <nl> there is a complication that the feature reset api knows nothing about ml upgrade mode . if the feature reset api is called while ml upgrade mode is enabled then it takes precedence and resets the ml state . this means that all ml entities will be deleted and upgrade mode will be disabled if the reset completes successfully . <nl> at the time the action filter is installed no cluster state is available , so initialise to false/false and let the first change event set the real values <nl> ensure the same object is used for both tests <nl> if we are in upgrade mode but a reset is being done then allow the destructive actions that reset mode uses <nl> class to allow both upgrade and reset flags to be recorded atomically so that code that checks both one after the other does n't see inconsistent values . <nl> if we are waiting for an upgrade or reset to complete , we should not assign to a node <nl> after a successful reset we completely remove the transform metadata <nl> do n't do this if a reset is in progress , because the feature reset api touches all features even if they have never been used .","now that we have a feature reset api , we should use <nl> this for cleaning up in between tests instead of running <nl> lots of bespoke cleanup code . <nl> during testing of this change we found we need to <nl> delete custom cluster state as part of the reset process , <nl> so this pr also implements that . <nl> additionally we no longer assign persistent tasks <nl> during feature reset .",1618221011,"this commit makes datefieldmapper extend parametrizedfieldmapper , <nl> declaring its parameters explicitly . as well as changes to datefieldmapper <nl> itself , there are some changes to dynamic mapping code to ensure that <nl> dynamically detected date formats are passed through to new date mapper <nl> builders .",0.9722306132316589
apache_incubator-pinot/5972,"[ te ] add threshold-based anomaly labeler <para-sep> the severity of anomaly . <nl> the order of definition follows the severity from highest to lowest <nl> flag to be set when severity changes but not to be persisted <nl> default severity level is debug <nl> helper to initialize and run the next level wrapper <nl> threshold-based severity labeler , which labels anomalies with severity based on deviation from baseline and duration of the anomalies . it tries to label anomalies from highest to lowest if deviation or duration exceeds the threshold <nl> severity map ordered by priority from top to bottom <nl> find the severity from highest to lowest <nl> only set renotify if the anomaly exists and its severity gets higher <nl> add or modify labels of anomalies in place <nl> this anomaly labeler wrapper runs the anomaly labeler component to label anomalies generated by detector based on the labeler implementation .",this pr is the first part of adding anomaly labeler for better alerting thirdeye users . it adds a labeling phase and a threshold-based labeler . the next pr is to add logic of translating yaml to json config .,1599174645,"* added rootcauseevententity , which holds additional info for event rca page . <nl> * added rootcauseevententityformatter as specialized formatter interface . <nl> * adapt existing event formatters to new rootcauseevententityformatter interface . <nl> * refactor rca handling of evententities . <nl> * add time-based scoring for holiday event pipeline to conform to other event ranking pipelines",0.9708758592605591
apache_druid/10700,"refactor noderole so extensions can participate in disco and announcement <para-sep> ) echo $ cluster_conf_base/misc/ $ 0 ; ; <nl> ) echo $ cluster_conf_base/misc/ $ 0 ; ; <nl> ugly mimic of other jetty initializers <nl> perform no-op authorization for these resources <nl> check that requests were authorized before sending responses <nl> do not change the order of the handlers that have already been added <nl> add gzip handler at the very end <nl> defines the 'role ' of a druid service , utilized to strongly type announcement and service discovery . originally , this was an enum to add type safety for discovery and announcement purposes , but was expanded into a class to allow for extensibility while retaining the type safety of using defined types instead of raw strings . as such , this class tries to mimic the interface provided by the previous enum . these abstractions can all potentially be merged when druid updates to jackson version that supports jsonaliases , <nl> for built-in roles , to preserve backwards compatibility when this was an enum , this provides compatibility for usages of the enum name as a string , ( e.g . <nl> for built-in roles , to preserve backwards compatibility when this was an enum , allow built-in node roles to specify the 'name ' which is used by 'tostring ' to be separate from the jsonname , which is the value which the node role will be serialized as and deserialized from <nl> for built-in roles , to preserve backwards compatibility when this was an enum <nl> built-in node roles","extensions are able to create entire new standalone tools and even full services , and they can be quite powerful because they have access to the wealth of facilities provided by the druid codebase . however , they are not currently able to announce or discover themselves because we use a enumeration which limits participation to known service types . <nl> this pr modifies to instead be a class , mimicking the contract the enum provided so that there is no apparent change , and allowing custom to be used alongside the built-in service types . i 've added an",1608587022,"add support for using hdfs as an input source . in this version , commas or globs are not supported in hdfs paths",0.9787279367446899
neo4j_neo4j/10955,"treenodedynamicsize cleanup . <nl> we used put- and readkeyoffset and size when we was in <nl> fact talking about deadspace and allocoffset . <nl> we now use pagecursorutil directly instead . <para-sep> this first value size byte can fit value size one byte key , no value [ 0,0,0 , k , k , k , k , k ] one byte key , one byte value [ 0,0,0 , k , k , k , k , k ] [ 0 , v , v , v , v , v , v , v ] one byte key , two byte value [ 0,0,0 , k , k , k , k , k ] [ 0 , v , v , v , v , v , v , v ] [ v , v , v , v , v , v , v , v ] two byte key , no value [ 0,0,0 , k , k , k , k , k ] [ k , k , k , k , k , k , k , k ] two byte key , one byte value [ 0,0,0 , k , k , k , k , k ] [ k , k , k , k , k , k , k , k ] [ 0 , v , v , v , v , v , v , v ] two byte key , two byte value [ 0,0,0 , k , k , k , k , k ] [ k , k , k , k , k , k , k , k ] [ 0 , v , v , v , v , v , v , v ] [ v , v , v , v , v , v , v , v ] this key/value size format is used , both for leaves and internal nodes even though internal nodes can never have values . key entry - [ keyvaluesize 1b|actualkey ] key_value entry - [ keyvaluesize 1b|actualkey|actualvalue ] first bit in keyvaluesize is used as a tombstone , set to 0 if key is dead . <nl> key size <nl> assuming no key size larger than 4k <nl> value size <nl> assuming no value size larger than 16k <nl> key size | value size | expected bytes <nl> key size","the dynamic tree node has an offset array , which is 0 bytes per entry . it also had 0 bytes key size and 0 bytes value size . these key/value sizes is what this pr reduces , from 0 down to a minimum of 0 byte .",1517587268,"which is stored in the selected state page , after the other state information . <nl> checkpoint/close methods come in two variants , one with header writer and one w/o . <nl> the one with header writer will replace the header data with new data , <nl> whereas the variants w/o will keep/carry over the previous header data to <nl> the new state page . <nl> when opening a gbptree the ( newly introduced ) supplied header reader can access <nl> the header data .",0.965993344783783
apache_druid/10373,adding more dimensions to the audit log entry,adding more dimensions to the service metric for audit log,1599679217,fix npe in remotetaskrunner event handler causes jvm shutdown . <nl> an overlord can encountered the following npe and subsequently triggered a jvm shutdown : . <nl> this is in the following code reproduced below : . <nl> also updated the version of curator to version,0.9122894406318665
vespa-engine_vespa/15472,"rewrite config convergence checker to use async http client <cm-sep> do n't reuse clients . <nl> the unit tests never closes the config convergence checker , causing stale connections to eventually exhaust the limit for max open files . <cm-sep> specify that connection manager is not shared",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606317936,"first commit makes the unit tests work , but breaks unit tests in node-repository ( restapitest ) .",0.979850172996521
netty_netty/11001,"add some tests to check consistency in http codec multipart . <nl> motivation : <nl> underlying buffer usages might be erroneous when releasing them internaly <nl> in httppostmultipartrequestdecoder . <nl> 0 bugs occurs : <nl> 0 ) final file upload seems not to be of the right size <nl> 0 ) memory , even in disk mode , is increasing continuously , while it should n't . <nl> modification : <nl> add some tests to check consistency for httppostmultipartrequestdecoder . <nl> add a package protected method for testing purpose only . <cm-sep> fix httppostmultipartrequestdecoder buffer usages and allocations . <nl> motivation : . <nl> method is too often called within the current implementation <nl> of the httppostmultipartrequestdecoder . <nl> this implies too much activities which is visible when paranoid mode is active . <nl> this is also true in standard mode . <nl> apply the same fix on buffer from httppostmultipartrequestdecoder to httppoststandardrequestdecoder <nl> made previously . <nl> finally in order to ensure we do not rewrite already decoded httpdata when decoding <nl> next ones within multipart , we must ensure the buffers are copied and not a retained slice . <nl> modifications : . <nl> use the method instead of in order to limit the external <nl> access to the underlying buffer by retrieving iteratively the beginning of a correct start <nl> position . <nl> it is used to find both lf/crlf and delimiter . <nl> 0 methods in httppostbodyutil were created for that . <nl> the undecodedchunk is copied when adding a chunk to a datamultipart is loaded . <nl> the same buffer is also rewritten in order to release the copied memory part . <nl> result : . <nl> just for note , for both memory or disk or mixed mode factories , the release has to be done as : . <nl> for ( interfacehttpdata httpdata : decoder.getbodyhttpdatas ( ) ) { <nl> httpdata.release ( ) ; <nl> factory.removehttpdatafromclean ( request , httpdata ) ; <nl> } <nl> factory.cleanallhttpdata ( ) ; <nl> decoder.destroy ( ) ; . <nl> the memory used is minimal in disk or mixed mode . in memory mode , a big file is still <nl> in memory but not more in the undecodedchunk but its own buffer ( copied ) . <nl> in terms of benchmarking , the results are : . <nl> original code benchmark mode cnt score error units","method is too often called within the current implementation <nl> of the httppostmultipartrequestdecoder . <nl> this implies too much activities which is visible when paranoid mode is active . <nl> this is also true in standard mode . <nl> apply the same fix on buffer from httppostmultipartrequestdecoder to httppoststandardrequestdecoder <nl> made previously . <nl> finally in order to ensure we do not rewrite already decoded httpdata when decoding <nl> next ones within multipart , we must ensure the buffers are copied and not a retained slice . <nl> use the method instead of in order to limit the external <nl>",1612712383,"review pooledbytebufallocator in respect of jemalloc 0.x changes and <nl> update allocate algorithm . <nl> motivation : <nl> for size from 0 bytes to chunksize , we use a buddy algorithm . the drawback is that it has a large internal fragmentation . <nl> modifications : <nl> 0. add sizeclassesmetric and sizeclasses <nl> 0. remove tiny size , now we have small , normal and huge size <nl> 0. rewrite the structure of poolchunk <nl> 0. rewrite pooled allocate algorithm in poolchunk <nl> 0. when allocate subpage , using lowest common multiple of pagesize and elemsize instead of pagesize .",0.9598435163497925
elastic_elasticsearch/71712,revamps the integration tests for the agg to be more clear and <nl> builds integration tests for the agg . both of these <nl> integration tests are fairly basic but they do assert that the aggs <nl> work .,revamps the integration tests for the agg to be more clear and <nl> builds integration tests for the agg . both of these <nl> integration tests are fairly basic but they do assert that the aggs <nl> work .,1618435432,this pr changes the readonly action to also be allowed in the hot phase after a rollover .,0.922687292098999
hazelcast_hazelcast/18246,set client connection timeout to prevent test timeouts . <nl> some tests are failing because they hit test timeouts . <nl> the reason is that the clients are trying to connect in impossible <nl> conditions since the test checks these impossible <nl> conditions . the clients continuosly try to establish connections <nl> which leads to test timeouts .,some tests are failing because they hit test timeouts . <nl> the reason is that the clients are trying to connect in impossible <nl> conditions since the test checks these impossible <nl> conditions . the clients continuously try to establish connections <nl> which leads to test timeouts .,1613748588,"the test occasionally fails but the attempt limit is set to the default <nl> number of 0. since a lot of tests increase this limit , we are increasing <nl> it here as well .",0.8801162838935852
elastic_elasticsearch/72282,"convert path.data to string setting instead of list . <nl> since multiple data path support has been removed , the setting no longer <nl> needs to support multiple values . this commit converts the <nl> path_data_setting to a string setting from list .","since multiple data path support has been removed , the setting no longer <nl> needs to support multiple values . this commit converts the <nl> path_data_setting to a string setting from list .",1619482039,"this change will not be backported , though this functionality is deprecated as of version .",0.9411154985427856
trinodb_trino/7133,remove unused method <cm-sep> simplify conditions in pushpredicatethroughprojectintowindow . <nl> this also avoids using a deprecated api .,this also avoids using a deprecated api .,1614758708,"includes two changes : . <nl> - and appears to be the same as queuedtime and elapsedtime respectively , if the split actually ran . populate them from the same fields for simplification and prepare for deprecation . <nl> - elapsedtime being populated in drivercontext returns 0 for running splits . changing that to reflect actual elapsed time .",0.843244194984436
quarkusio_quarkus/16236,"introduce the ability to skip native tests if graalvm version is too old . <cm-sep> disable kafka-snappy tests for versions of graalvm older than version . <para-sep> used to signal that a test class should be disabled if the version of graalvm used to build the native binary under test was older than the supplied version . <nl> compares this version with a tuple of major and minor parts representing another graalvm version <nl> we need to guess where the artifact properties file is based on the location of the test class <nl> we have the maven test classes dir <nl> we have the gradle test classes dir , build/classes/java/test <nl> this will make mvn failsafe : integration-test work",this is done by introducing the ability to skip native tests if graalvm version is too old . <nl> essentially the test is skipped if the graalvm version used to build the <nl> native binary was older than the version specified in the new <nl> annotation . <nl> this is accomplished by recording the graalvm version in the <nl> file ( this file was introduced to support ) and reading <nl> the necessary data in a new junit 0 implementation .,1617607741,"and move jaeger into its own module to enable other opentracing compliant tracers to be used . <nl> have tested with the example , by adding the opentracing deployment dependency : . <nl> note : if the is added with dependency excluded , then it will use the opentracing . <nl> then starting a local jaeger standalone instance : . <nl> and running the app : . <nl> and then send requests to the app using : . <nl> then view the trace in the jaeger ui . <nl> once this pr is closer to being merged , i will",0.966774046421051
apache_pulsar/9580,allow to build pulsar with jdk11 and -dmaven.compiler.release=0 <cm-sep> fix style <para-sep> try to use the methods,if you try to build pulsar on jdk11 and add the -- release flag to javac ( that is -dmaven.compiler.release=0 in maven terms ) you see errors due to some internal apis that have been hidden to the user at build time . <nl> - fix usages of internal jre apis that are still accessible at runtime even on jdk11 but they are not visible at build time in jdk8 <nl> - add tests,1613146873,motivation . <nl> this is the first set of changes to better integration with state storage . <nl> changes . <nl> - pulsarclustermetadatasetup should initialize the metadata for bookkeeper table service <nl> - move the common util functions to <nl> - delete state table on deleting functions .,0.9535048604011536
elastic_elasticsearch/71686,"<para-sep> commons-logging <nl> this limitation of liability shall not apply to liability for death or personal injury resulting from such party 's negligence to the extent applicable law prohibits such limitation . some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages , so this exclusion and limitation may not apply to you . * * * * * <nl> we have domain with no matching public suffix , but ' . ' in it","this pr adds support for a processor that looks up the registered domain , etld from the public suffix list , and uses those to split out the subdomain as well . it 's essentially a port of the beats processor . <nl> produces : .",1618403378,"similar to what the moving function aggregation does , except merging windows of percentiles sketches together instead of cumulatively merging final metrics .",0.9796193838119507
apache_druid/10689,"multiphase merge for indexmergerv9 <para-sep> use the given outdir on the final merge phase <nl> we 're done , we made a single file output <nl> convert files to queryableindexindexableadapter and do another merge phase <nl> always merge at least two segments regardless of column limit <nl> always merge at least two segments regardless of column limit <nl> +0 for the __time column <nl> no column limit <nl> column limit is greater than total # of columns <nl> column limit is greater than 0 segments worth of columns <nl> column limit is between 0 and 0 segments worth of columns ( merge two segments at once ) <nl> column limit is less than 0 segment <nl> column limit is exactly 0 segment 's worth of columns <nl> column limit is exactly 0 segment 's worth of columns <nl> column limit is exactly the total number of columns","this pr introduces a new tuning config parameter , . <nl> this functions as a limit on how many segments can be merged at the same time by the indexmerger , to limit memory usage during the merge . when the column limit is exceeded across a set of segments , the indexmerger will break the segments to be merged into smaller phases , and merge the smaller phases in a tree . <nl> a minimum of 0 segments will be merged at once , regardless of the limit . if there is only 0 segment being merged , the",1608237718,"with this pr , users can simply skip head rows rather than guessing the schema from the head rows . the is effective for only non-hadoop index tasks .",0.9717684984207153
confluentinc_ksql/6400,add support for alter stream|table <cm-sep> merge with master <cm-sep> remove serdeoptions <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"add new syntax , . it works as follows : . <nl> it only works on data sources that are created using ddl statements .",1602290546,"udfs are loaded from the jars by searching for the anotations and . each method ( in a class with ) marked with is compiled into a class that can be called via the existing function call code . each udf gets it 's own child first classloader so that they are free to include versions of jars that are different than those provided by ksql . <nl> classes can be ' blacklisted ' from being called from a udf , i.e. , so they ca n't call , for example . <nl> have also changed the to this new",0.9876875877380371
grpc_grpc-java/7508,fix the transport-socket-name to match what control plane sends,the comment in envoy/src/api/envoy/config/cluster/v3/cluster.proto line 0 mentions using ' tls ' as the name but the actual string is ' envoy.transport_sockets.tls ' as per the example on line 0 in the same file .,1602536859,fix lints for import . <nl> remove unused vars . make path and package match so tests run <nl> successfully internally .,0.8378742933273315
apache_druid/10149,"add availability and consistency docs . <nl> describes transactional ingestion and atomic replacement . also , this patch <nl> deletes some bad advice from the javadocs for segmenttransactionalinsertaction .","describes transactional ingestion and atomic replacement . also , this patch <nl> deletes some bad advice from the javadocs for segmenttransactionalinsertaction .",1594148845,"while not all indexspec properties are explained , it does explain how roaring bitmaps can be turned on .",0.8401604890823364
Alluxio_alluxio/10869,refactor stop sync <para-sep> gets the lock protecting the syncmanager .,"when stopsync is called , the thread performing the initial scan handles interrupt to return early . a full sync on a very large directory can take a long time to finish , this change enables us to cancel a full sync after partial completion .",1581121985,updates the load ufs script to use load metadata and changes some implementation in s3 client to handle load metadata .,0.9664316773414612
OpenAPITools_openapi-generator/8076,"updated eiffel code generator . <nl> added missing language reserved words . <nl> updated mustache templates to use the latest eiffel rules to avoid obsolte <nl> feature calls and cat-calls . <nl> updated eiffel configuration files ( ecf 's ) <nl> updated comments styles . <nl> updated travis ci file to use the latest eiffel compiler . <cm-sep> added missing mapping decimal to real_64 <nl> added eiffel kernel classes to importmapping to avoid generate models for <nl> them . <nl> fixed issue with eiffel feature name generation , updated tooperationid ( string ) method . <nl> simplified toinstantiationtype method implementaetion . <nl> improved model.mustache to generate eiffel models . <cm-sep> updated eiffel sample . <para-sep> we need to check if import-mapping has a different model for this class , so we use it instead of the auto-generated one . <nl> model name starts with _ <nl> ( after camelize ) <nl> throw exception if method name is empty <nl> operationid starts with a number <nl> if ( modelutils.ismapschema ( p ) ) { schema additionalproperties2 = getadditionalproperties ( p ) ; string type = additionalproperties2.gettype ( ) ; if ( null == type ) { logger.error ( ' no type defined for additional schema ' + additionalproperties2 + ' \n ' // + ' \tin schema : ' + p ) ; } string inner = tomodelname ( getschematype ( additionalproperties2 ) ) ; return instantiationtypes.get ( ' map ' ) + ' [ ' + inner + ' ] ' ; } else if ( modelutils.isarrayschema ( p ) ) { arrayschema ap = ( arrayschema ) p ; string inner = tomodelname ( getschematype ( ap.getitems ( ) ) ) ; return instantiationtypes.get ( ' array ' ) + ' [ ' + inner + ' ] ' ; } else { return null ; } <nl> anotherfake_api | call123test_special_tags | patch /another-fake/dummy | to test special tags fake_api | create_xml_item | post /fake/create_xml_item | creates an xmlitem fake_api | test_body_with_file_schema | put /fake/body-with-file-schema | fake_api | test_endpoint_parameters | post /fake | fake endpoint for testing various parameters 假端點 偽のエンドポイント 가짜 엔드 포인트 fake_api | test_group_parameters | delete /fake | fake endpoint to test group parameters ( optional ) fake_api | test_query_parameter_collection_format | put /fake/test-query-paramters | pet_api * | upload_file_with_required_file | post /fake/ { petid } /uploadimagewithrequiredfile | uploads an image ( required ) <nl> name | string_32",updated eiffel code generator . <nl> added missing language reserved words . <nl> updated mustache templates to use the latest eiffel rules to avoid obsolte feature calls and cat-calls . <nl> updated eiffel configuration files ( ecf 's ) <nl> updated comments styles . <nl> updated travis ci file to use the latest eiffel compiler . <nl> updated mustache model template to simplify the generated code . <nl> updated eiffel sample . <nl> - [ x } pull request title clearly describes the work in the pull request and pull request description provides details about how to validate the work,1606925047,- parameter names now as is from openapi spec ( 0 ) <nl> - include failures now without visibile markup <nl> - header level corrected <nl> - 0 minor markup corrections .,0.8875858783721924
neo4j_neo4j/11293,remove causeless direct byte buffers usages . <nl> replace usages of direct byte buffers with their on heap twin .,replace usages of direct byte buffers with their on heap twin .,1521227927,remove setting initial heapsize using heap_size environment variable . <nl> note : it does not affect the initial heapsize set by neo4j config during neo4j startup .,0.8499456644058228
elastic_elasticsearch/71221,"[ ml ] fixes bug with composite agg datafeed extraction <para-sep> we want to stop processing once a timestamp enters the next time bucket . this could occur in any page . one benefit we have is that even though the paging order is not sorted by max timestamp , our iteration of the page results is . so , once we cross over to the next bucket within a given page , we know the previous bucket has been exhausted . this simple equation handles two unique scenarios : if the timestamp is the current floor , this means we need to keep processing until the next timebucket if we are not matching the current bucket floor , then this simply aligns to the next bucket","if a value in a given composite aggregation bucket is the same as the current after page floor , the datafeed could cancel processing composite aggregation pages too early . <nl> it will see that timestamp aligned with the interval and stop processing . this is a bug . there may be still other terms <nl> to process within that bucket in subsequent pages as the order of the buckets are done by term not by max timestamp . <nl> this commit corrects this to verify that if the process is canceled , the datafeed continues to finish out the",1617366484,a search request should not be required to extend the keep_alive of a point in time . this change makes that parameter optional .,0.8887800574302673
ballerina-platform_ballerina-lang/26427,bug fixes and improvements <cm-sep> fix formatting in parser source files <cm-sep> modify parser test assert files <para-sep> flag indicating whether the annotations should be inline . <nl> set indentation for braces . <nl> set the indentation for statements starting with explicit anonymous function expression nodes . <nl> cache the current node and parent before format . because reference to the nodes will change after modifying . <nl> set the flag for setting inline annotations . <nl> builddirectory.resolve ( ' resources ' ) .resolve ( ' test ' ) .tostring ( ) ) .orelse ( null ) },* fix formatting issues in the formatter core .,1603192881,fixes # . <nl> bir will keep referance to that function .,0.9185837507247925
Alluxio_alluxio/10895,debug root mount issue <cm-sep> propagate readonly and shared field <para-sep> write operation under a readonly path is not permitted,correctly propagate root mount options to mounttable . <nl> after the change :,1581508494,add integration tests for using uris with connect details in authorities to connect to <nl> alluxio cluster through hadoop filesystem,0.9365300536155701
ballerina-platform_ballerina-lang/23889,undeprecated jdbc module <cm-sep> fix testcase failures due to undeprecation,undeprecated jdbc module in version.x .,1591794288,"fix byte value , tuple mutability tests",0.8885642886161804
ballerina-platform_ballerina-lang/25473,"fix join spec deviations <cm-sep> merge upstream <cm-sep> fix parser error recovery <cm-sep> fix formatter for join spec deviation changes <cm-sep> fix key function type issue in codegen <cm-sep> fix tests for join spec deviations <para-sep> desugar joinclauses to below and return a reference to created join _streamfunction . <nl> creates a lambda key function for a given expression . function ( _frame _frame ) returns any { returns keyexpr ; } <nl> defines a _frame with nil value fields for given symbols . <nl> adds nil value fields to a given _frame . <nl> adds _frame value fields to a given _frame . <nl> creates _frame $ frame $ = new ; variable definition and return a reference to the created frame . <nl> lhsexprenv should only contain scope entries before join condition . <nl> rhsexprenv should only contain scope entries after join condition . <nl> parse equals keyword . <nl> move to next lhs frame <nl> reset the state of lhsframe <nl> move to next lhs frame in next iteration . <nl> rhscandidates is nil , move to next lhs frame in next iteration . <nl> reset the state of lhsframe <nl> function testonclausewithoutequals ( ) returns boolean { person p1 = { id : 0 , fname : ' alex ' , lname : ' george ' } ; person p2 = { id : 0 , fname : ' ranjan ' , lname : ' fonseka ' } ; department d1 = { id : 0 , name : ' hr ' } ; department d2 = { id : 0 , name : ' operations ' } ; person [ ] personlist = [ p1 , p2 ] ; department [ ] deptlist = [ d1 , d2 ] ; deptperson [ ] deptpersonlist = from var person in personlist outer join department dept in deptlist on person.id == dept.id select { fname : person.fname , lname : person.lname , dept : dept.name } ; }",ref [ 0 ] & [ 0 ] .,1598530175,"within those angle brackets , you can specify a package qualified identifier , ( empty means current package ) <nl> above * * means that this annotation is only applicable in services which uses , http protocol package ( ' ' empty brackets means , current package , so in this case , it is ballerina.net.htttp ) <nl> second attachment point which is means that , it is applicable for ' ballerina.net.ws ' protocol package . <nl> apart from above , this pull include the new http configuration annotation change , as well as all the related test changes and",0.9874928593635559
elastic_elasticsearch/71042,"frozen tier autoscaling decider based on shards . <nl> the frozen tier only holds shared cache searchable snapshots . this <nl> commit adds an autoscaling decider that scales the total memory on <nl> the tier adequately to hold the shards . a frozen shard is assigned <nl> a memory size of 64gb/0 , i.e. , each 64gb node can hold 0 shards <nl> before scaling further . <para-sep> randomly set the setting to verify it can be set . <nl> this decider enforces that on a 64gb memory node ( 31gb heap ) we can max have 0 shards . we arrive at 0 because our current limit is 0 but frozen tier uses the ' frozen engine ' , which is much more efficient . we scale the total tier memory accordingly . the decider relies on frozen tier being used exclusively for frozen shards . <nl> we assume that nodes do not grow beyond 64gb here . <nl> pass setting validator .","the frozen tier only holds shared cache searchable snapshots . this <nl> commit adds an autoscaling decider that scales the total memory on <nl> the tier adequately to hold the shards . a frozen shard is assigned <nl> a memory size of 64gb/0 , i.e. , each 64gb node can hold 0 shards <nl> before scaling further . <nl> the max shards validation limit will be relaxed in a separate pr .",1617098080,the primary shards of follower indices during the bootstrap need to be <nl> on nodes with the remote cluster client role as those nodes reach out to <nl> the corresponding leader shards on the remote cluster to copy lucene <nl> segment files and renew the retention leases . this commit introduces a <nl> new allocation decider that ensures bootstrapping follower primaries are <nl> allocated to nodes with the remote cluster client role .,0.9870629906654358
elastic_elasticsearch/71671,"nodeindicesstats # statsbyshard is never null . <nl> today we support serializing with a null <nl> field , but in practice it is always present ( since at <nl> least version ) . if it were absent , we either throw npes or treat it as an <nl> empty map . this commit removes the option for this field to be null on <nl> the wire .","today we support serializing with a null <nl> field , but in practice it is always present ( since at <nl> least version ) . if it were absent , we either throw npes or treat it as an <nl> empty map . this commit removes the option for this field to be null on <nl> the wire .",1618384818,* stop redundantly creating a length that is never used <nl> * add efficient way to get a minimal size copy of the bytes in a <nl> * avoid multiple redundant copies in search cache key creation,0.8748994469642639
elastic_elasticsearch/72534,"while looking at the test i noticed that <nl> - autofollowit extends esccrresttestcase which does not wipe <nl> clusters between tests ; <nl> - multiple tests use the same auto-follow pattern logs- * ; <nl> - tests do not always clean up indices/datastreams/auto-follow patterns <nl> on all test clusters , specially when the test fails and leaves existing <nl> resources that can conflict with subsequent tests . <nl> therefore i am <nl> committing some changes to add clean up logic for tests in <nl> blocks . it also changes the logs- * patterns for data streams tests <nl> so that they are not conflicting anymore . <para-sep> create auto follow pattern <nl> create data stream and ensure that is is auto followed first rollover and ensure second backing index is replicated : second rollover and ensure third backing index is replicated : <nl> initialize data stream prior to auto following <nl> create auto follow pattern <nl> rollover and ensure only second backing index is replicated : <nl> explicitly follow the first backing index and check that the data stream in follow cluster is updated correctly : <nl> create auto follow pattern <nl> create data stream and ensure that is is auto followed rollover in leader cluster and ensure second backing index is replicated : try rollover in follow cluster <nl> unfollow .ds-logs-tomcat- <nl> try again <nl> promote local data stream <nl> try again and now the rollover should be successful because local data stream is now : <nl> todo : verify that following a backing index for logs-tomcat-prod data stream in remote cluster fails , because local data stream is n't a replicated data stream anymore . unfollow .ds-logs-tomcat- , which is now possible because this index can now be closed as it is no longer the write index . <nl> create auto follow pattern <nl> create leader index and write alias : rollover in leader cluster and ensure second backing index is replicated : try rollover in follow cluster , this should fail , because is_write_index property of an alias is n't replicated to follow cluster . <nl> create auto follow pattern in follow cluster <nl> create auto follow pattern in leader cluster : <nl> first add remote cluster to leader cluster : <nl> then create the actual auto follow pattern : <nl> create data stream in leader cluster and ensure it is followed in follow cluster todo :","while looking at the test i noticed that <nl> - autofollowit extends esccrresttestcase which does not wipe <nl> clusters between tests ; <nl> - multiple tests use the same auto-follow pattern logs- * ; <nl> - tests do not always clean up indices/datastreams/auto-follow patterns <nl> on all test clusters , specially when the test fails and leaves existing <nl> resources that can conflict with subsequent tests . <nl> therefore i am <nl> committing some changes to add clean up logic for tests in <nl> blocks . it also changes the logs- * patterns for data streams tests <nl> so that",1619775843,= > removed it and made the test use other primitives as a replacement .,0.9077004790306091
neo4j_neo4j/11071,fix default value lookup in config to return the original string,previously we returned the setting with type and called to get the original value out . this does not work for settings that uses java lang types such as where the can not be overridden .,1519209259,lets try to duplicate property value holder instead of reference it twice .,0.9057044982910156
apache_beam/12919,"moved gettableschema method from expand to setup in clickhouseio <para-sep> set tableschema . if not set , then tableschema will be fetched from clickhouse server itself",have moved gettableschema method from expand to setup in clickhouseio so that gettableschema method is executed only when pipeline starts not at the time of deployment,1600885673,"i 've added the needed string parameter to the bigqueryio.write ( ) function , and passed it through to the underlying class . wanted to get some feedback before trying to write a test . <nl> 0. should i also add a valueprovider interface ? <nl> 0. i 've modified the constructor for writetables , which is public . should i instead add a setter for that function or overload the constructor ? <nl> 0. should i validate the this parameter is not set unless the method is file_loads ? it is n't harmful to set it otherwise , it",0.8949151635169983
elastic_elasticsearch/71346,"transform docker log4j properties at build time . <nl> for the docker distribution , we transform the archive distribution 's <nl> log4j2 config so that all messages are logged to the console by default . <nl> however this transformation step happens when the docker image is built , <nl> which means that the source for the transformation must be included in <nl> the docker context . <nl> improve this by transforming the config when the docker context is <nl> built . the downside is that build context task now has dependencies . <para-sep> squeeze multiple empty lines into a single line . * / <nl> this flag provides a way to handle properties whose values are split over multiple lines and we need to omit those properties . <nl> skip lines with this comment - we remove the relevant config <nl> we do n't need to explicitly define a console appender because the ' rolling ' appender will become a console appender . we also do n't carry over ' * _old ' appenders <nl> no longer applicable . omit it . <nl> the root logger only needs this appender <nl> check that the transformer does n't explode when given an empty file . <nl> check that the transformer leaves non-appender lines alone . <nl> check that the root logger appenders are filtered to just the ' rolling ' appender <nl> check that any explicit 'console ' or 'rolling_old ' appenders are removed . <nl> check that rolling file appenders are converted to console appenders . <nl> check that rolling file appenders have redundant properties removed . <nl> check that rolling file appenders have redundant properties removed . <nl> check that as well as skipping old appenders , logger references to them are also skipped . <nl> check that multiple blank lines are reduced to a single line . <nl> this artifact makes it possible for other projects to pull in the final log4j2.properties configuration , as it appears in the archive distribution .","for the docker distribution , we transform the archive distribution 's <nl> log4j2 config so that all messages are logged to the console by default . <nl> however this transformation step happens when the docker image is built , <nl> which means that the source for the transformation must be included in <nl> the docker context . <nl> improve this by transforming the config when the docker context is <nl> built . the downside is that build context task now has dependencies . <nl> also tweak the checkstyle config to stop complaining about missing docs <nl> on the method .",1617718394,"in order to iterate through remote connections , the remote connection <nl> manager maintains a local cache of connected nodes . unfortunately this <nl> is difficult in relationship with testing as it is inherently racy in <nl> comparison to the parent connection manager map of connections . <nl> this commit improves the relationship by only returning a cached <nl> connection if it is still registered with the parent . if the connection <nl> is not open , we will go to the slow path of allocating a iterator <nl> directly from the parent .",0.914232075214386
Alluxio_alluxio/11019,add additional metrics for client cache . <para-sep> cache hit rate = cache hits / ( cache hits + cache misses ) . <nl> pages evicted from the cache . * / <nl> errors when deleting pages . * / <nl> errors when getting pages . * / <nl> errors when adding pages . * / <nl> client cache metrics,"adds page eviction rate , cache hit rate , space utilization , and error counts .",1582675177,warn : . <nl> failed : .,0.9228329062461853
elastic_elasticsearch/72137,"expose api key metadata to setsecurityuser ingest processor . <nl> this pr ensures setsecurityuserprocessor adds the api key metadata <nl> inside the existing api_key object if the metadata is not null or empty . <para-sep> tbd : it 's unclear why we 're putting users in an index here . <nl> this qa project tests the security plugin when security is explicitly disabled . if the authentication has type of api_key , returns the metadata associated to the api key .",this pr ensures setsecurityuserprocessor adds the api key metadata <nl> inside the existing api_key object if the metadata is not null or empty .,1619151747,"today searchable snapshot shards can be restored from a snapshot , recovered from a peer or force-allocated as stale primary on data node without copying any files on disk . it works because does not rely on local files on disk and because every time such a is instantiated an empty translog is associated to it through a new lucene commit ( holds in memory ) . <nl> the translog/lucene commit association is done within a cluster state update when the 's directory is created and requires to open an and to create the translog and translog checkpoint files on",0.9653505682945251
Graylog2_graylog2-server/9746,"do not allow users to see or copy old tokens . <nl> since tokens can be used to impersonate a user , only display tokens <nl> once after creation , and remove the functionality to display or <nl> copy them afterwards . <cm-sep> remove token from token list resource . <nl> do not transmit plaintext tokens when listing tokens for a user , making <nl> it only possible to see ( and copy ) tokens immediately after creation .","remove tokens from the list tokens resource and the token list page . this means that users will only be able to see ( and copy ) tokens when they are created . if a token is lost , the user will need to create another one . <nl> please note that this only fixes the issue for cloud . we will need to port it to other branches along with other cloud-specific changes .",1607530796,the original metrics name did n't contain any information about the stream which the stream rule was part of . <nl> this made it very hard to identify the stream which included the stream rule and was only possible by either querying mongodb directly or take a look into each stream ( brute force ) . <nl> this change set changes the metrics name from . <nl> org.graylog2.plugin.streams.streamrule. $ { stream-rule-id } .executiontime . <nl> to . <nl> org.graylog2.plugin.streams.stream. $ { stream-id } .streamrule. $ { stream-rule-id } .executiontime . <nl> - breaking change ( fix or feature that would,0.9149520993232727
confluentinc_ksql/6712,attempt to make clitest more robust,"we were getting failures like : . <nl> i have no idea why those are happening , but i hope that this change ( which just removes the parts which terminate queries ) will make this better . note that all queries are terminated after the class is done because is an which gets cleaned up by junit . <nl> test only change .",1606945683,"dropping as its currently incorrect and there 's no easy way to capture it at the moment . the main benefit of adding the post conditions was to capture all the topic names anyway . <nl> the previous pr updated the historical plans by tracking all the topics produced to during the test run as post conditions , such that subsequent runs will fail if the topic names , or config , changes . as part of this work i tracked the topics schema , however , the code doing this was buggy and the wrong schema was being tracked",0.8892750144004822
quarkusio_quarkus/15541,"create /tmp/vertx-cache and configure it to be world-readable and writable . <nl> under that directory , another random directory is created that is only readable and writable from the current user . <nl> the vertx-cache directory creation is disabled if : . <nl> * the user specifies a cache directory <nl> * the vertx-cache directory already exists . <para-sep> recursively delete the created directory and all the files <nl> we do not delete the vertx-cache directory on purpose , as it could be used concurrently by another application . in the worse case , it 's just an empty directory . <nl> do not reuse an existing directory .","create /tmp/vertx-cache and configure it to be world-readable and writable . <nl> under that directory , another random directory is created that is only readable and writable from the current user ( which is used by the application ) ) . <nl> the vertx-cache directory creation is disabled if : . <nl> * the user specifies a cache directory <nl> * the vertx-cache directory already exists .",1615213600,the pr introduces indexing for and the root directory of the jars on the classpath . <nl> i only added those 0 as those are the ones i saw being used by all applications .,0.9456987380981445
elastic_elasticsearch/71171,"reduce size of management threadpool on small node . <nl> today by default the threadpool always permits 0 threads <nl> even if the node has a single cpu , which unfairly prioritises management <nl> activities on small nodes . with this commit we limit the size of this <nl> threadpool to the number of processors if less than 0 . <para-sep> fire off the delete-by-query first <nl> then refresh the cluster info which checks the disk threshold and releases the block on the index <nl> the delete by query request will be executed successfully because it retries after the block is released <nl> cancellation is usually lightweight , and runs on the transport thread if the task did n't even start yet , but some implementations of cancellabletask # oncancelled ( ) are nontrivial so we use generic here . todo could it be same ?","today by default the threadpool always permits 0 threads <nl> even if the node has a single cpu , which unfairly prioritises management <nl> activities on small nodes . with this commit we limit the size of this <nl> threadpool to the number of processors if less than 0 .",1617266631,"adds assertions to netty to make sure that its threads are not polluted by thread contexts ( and also that thread contexts are not leaked ) . moves the to use the system context ( same as we do for ) , which allows to remove a hack from and makes it clearer that applying cs updates is fully executing under system context .",0.8873276710510254
elastic_elasticsearch/72135,fix painless execute api output <para-sep> convert geo points to the standard format of the fields api <nl> consumers must copy the emitted geopoint ( s ) if stored .,"this fixes the output for the date type , geo point type , and ip type to match as if it was coming from the fields api . this also ensures it 's in a nicely , human-readable format .",1619130429,"the administrative actions for data streams , create , delete , and get , are now index-level actions . in keeping with the decision that privileges should be granted on data streams and indices in the same namespace , the create , delete , and get ( aka view metadata ) actions have been added to the existing , , and privileges , respectively . <nl> because the requests for all index-level actions must implement , that change was included in this pr . it was minor except for the fact that the get data stream request must accept multiple",0.9293025732040405
apache_druid/10318,"fix handling of 'join ' on top of 'union ' datasources . <nl> the problem is that unions are typically rewritten into a series of <nl> individual queries on the underlying tables , but this is n't done when <nl> the union is wrapped in a join . <nl> the main changes are in unionqueryrunner : . <nl> 0 ) replace an instanceof unionqueryrunner check with datasourceanalysis . <nl> 0 ) replace a ' query.withdatasource ' call with a new function , ' queries.withbasedatasource ' . <nl> together , these enable unionqueryrunner to ' see through ' a join . <para-sep> create a join datasource from a string condition . <nl> sanity check : query must be based on a single table . <nl> rewrite ' query ' to refer to some specific base datasource , instead of the one it currently refers to . <nl> verify postconditions , just in case . <nl> union of tables . <nl> should n't happen , because uniondatasource does n't allow empty unions . <nl> single table . run as a normal query . <nl> split up the tables and merge their results . <nl> assign the subqueryid . this will be used to validate that every query servers have responded per subquery in retryqueryrunner <nl> not a union of tables . do nothing special . returns the base ( bottom-leftmost ) datasource . otherwise , returns an empty optional . otherwise , returns an empty optional . <nl> this is an important property , because it corresponds to datasources that can be handled by druid 's distributed query stack . <nl> noinspection resultofobjectallocationignored <nl> sanity check : make sure the query is based on the table we 're meant to handle . <nl> note : this should really be 0 , but in the interim queries that are composed of multiple queries count each invocation of either the cluster or local walker in clientquerysegmentwalker","the problem is that unions are typically rewritten into a series of individual queries on the underlying tables , but this is n't done when the union is wrapped in a join . <nl> the main changes are in unionqueryrunner : . <nl> 0 ) replace an check with datasourceanalysis . <nl> 0 ) replace a call with a new function , . <nl> together , these enable unionqueryrunner to ' see through ' a join .",1598293724,"the main changes are the removal of query-result-to-array code from , and the addition of these two methods to querytoolchest : . <nl> i think this improves the design of the code a little bit , but the main benefit is really to support joins on subqueries . <nl> > allow joining on to ' query ' datasources as well . to make this work , we ’ ll need to add a sense of a ‘ standard translation ’ of results from certain query types into flat schemas that we can offer column selectors on top of . there",0.9547566771507263
elastic_elasticsearch/71868,"add force single data path option for integ tests . <nl> some functionality will no longer work with multiple data paths and in <nl> order to run integration tests for that , we need the capability to <nl> force a single data path for those tests . <para-sep> override to return true in tests that can not handle multiple data paths . <nl> use 0 data path if we are forced to , or 0 % of the time that we are not , otherwise use between 0 and 0 data paths","some functionality will no longer work with multiple data paths and in <nl> order to run integration tests for that , we need the capability to <nl> force a single data path for those tests . <nl> opt'ed for a method on over adding to the annotation , since this felt less intrusive and mdp is going away anyway .",1618853912,"constructing the timout checker first and then registering the watcher allows the test to have a race condition . <nl> the timeout value could be reached before the matcher is added . to prevent the matcher never being interrupted , a new value is added to the watcher thread entry . then when a new matcher is registered , if the thread was previously timedout , we interrupt the matcher immediately .",0.8543602228164673
apache_beam/12601,"generate query execution summary table after finishing jobs <para-sep> print the summary table after all jobs are finished . <nl> query execution <nl> transform the result from pcollection into pcollection , and write it to the location where results are stored . <nl> print the summary table after all jobs are finished . <nl> if the job is not successful , leave the run time related field blank <nl> this is the default method in beamtpcds.main method . run job using sqltranform.query ( ) method . <nl> generate the tpcds queries execution summary on the command line after finishing all jobs . <nl> add a rowline at the beginning , the middle between headerslist and rowlists , the end of the summary table . * / <nl> get the width of the summary table . * / <nl> use space to fill a single cell with optimum cell padding size . * / <nl> make sure to set the job status to be successful only when pipelineresult 's final state is done . <nl> if the pipeline execution failed , return a result with failed status but do n't interrupt other threads .",generate a query runtime summary table on the command line after finishing all jobs . <nl> jobs with ' failed ' status will leave runtime fields blank,1597687176,- create a class <nl> - update method <nl> - add method <nl> - update push-down rule,0.9676401615142822
apache_ignite/8898,: fix node failure on receiving data of unknown class via distributed metastorage . <nl> original author of this patch is sam vimes,: fix node failure on receiving data of unknown class via distributed metastorage . <nl> original author of this patch is sam vimes,1616131691,fix memory leak on unstable topology caused by partition reservation,0.9671818614006042
runelite_runelite/11934,added support for crystal axe in enchanted valley clue step,added support for the crystal axe for enchanted valley clue step,1592534050,shows crystal pickaxe as usable for the soul altar master clue step . <nl> i used the crystal pickaxe when doing this step and it worked,0.8588844537734985
jenkinsci_jenkins/4657,forward groovy view permission errors to login,"* some views showed an error screen instead of forwarding to the login form when necessary permissions were missing . <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs",1586908904,"extract region/country and variant from the language parameter in case it is bigger then 0 letters . add tests for both cases . <nl> > the basic rule here is that if your language preference list contains a language tag containing a hyphen , such as fr-ch ( french as spoken in switzerland ) , you should consider adding an additional language tag without the hyphen , ie . fr ( french ) in this case , immediately after . <nl> > this is because if a server follows the http/version specification literally , it is unable to match fr-ch",0.9169101715087891
apache_kafka/9887,"fix synchronization issue happening in kafkastreams ( related to flaky adjuststreamthreadcounttest ) <para-sep> creating thread should hold the lock in order to avoid duplicate thread index . if the duplicate index happen , the metadata of thread may be duplicate too . <nl> make a copy of threads to avoid holding lock <nl> handle each stream thread in a snapshot of threads . noted : iteration over synchronizedlist is not thread safe so it must be manually synchronized . however , we may require other locks when looping threads and it could cause deadlock . hence , we create a copy to avoid holding threads lock when looping threads . <nl> count the snapshot of threads . noted : iteration over synchronizedlist is not thread safe so it must be manually synchronized . however , we may require other locks when looping threads and it could cause deadlock . hence , we create a copy to avoid holding threads lock when looping threads .",the synchronization list requires us to manually synchronize the iterator . non-synchronizing the list results in inconsistent results and consequently unstabilize the adjuststreamthreadcounttest . <nl> is not called with holding so it is possible that we create two threads with same thread index . it makes different threads have same metadata and then returns incorrect number of metadata . <nl> looped the test 0 times on my local . all pass .,1610614511,* add a normal windowed suppress with short windows and a short grace <nl> period <nl> * improve the smoke test so that it actually verifies the intended <nl> conditions .,0.9402371644973755
vespa-engine_vespa/15586,add helper for combining multiple completable futures <cm-sep> add helper method to rethrow checked as unchecked <cm-sep> move serialized value definition to state enum,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606900257,adding docker allocation metrics . most of the metrics will only makes sense once we start to dynamically allocate docker containers .,0.9860411286354065
apache_pulsar/9787,"ensure read-lock is not continuously held on a section while iterating over concurrent maps <para-sep> we need to make sure that we read these 0 variables in a consistent way validate no rehashing <nl> fallback to read lock <nl> go through all the buckets for this section . we try to renew the stamp only after a validation error , otherwise we keep going with the same . <nl> fallback to acquiring read lock <nl> go through all the buckets for this section . we try to renew the stamp only after a validation error , otherwise we keep going with the same . <nl> fallback to acquiring read lock <nl> take a reference to the data table , if there is a rehashing event , we 'll be simply iterating over a snapshot of the data . go through all the buckets for this section . we try to renew the stamp only after a validation error , otherwise we keep going with the same . <nl> fallback to acquiring read lock <nl> go through all the buckets for this section . we try to renew the stamp only after a validation error , otherwise we keep going with the same . <nl> fallback to acquiring read lock","0. if the process functions is taking a long time ( eg : making a blocking request to zk that might even timeout ) , the writes operations on that section of the map are stalled during that time . <nl> 0. it 's deadlock prone : <nl> 0. if a thread tries to use the map while scanning through it can deadlock itself <nl> 0. if the processing operation waits for the completion of some operation from a different thread and that thread tries to use the same map , it can create a deadlock . <nl> instead of",1614800161,"the futures returned by , and methods <nl> return a that contains a ' whencomplete ' callback which handles . the callback action will remove the registered futures from the internal ' pendingreceives ' and ' pendingbatchreceives ' futures . <nl> the changes attempt to also against possible race conditions that could happen when cancellation and a message get received at the exactly same moment and the future removed from the queue has already been cancelled . <nl> while adding unit tests , some minor refactoring was made to start adding a clienttestfixtures class that would make it easier to",0.9482054710388184
confluentinc_ksql/6663,"fix leaked executor service in pull query handling . <nl> this fixes a leaked executor service with 0 threads that is being created once-per-request for pull queries . <cm-sep> enhance test to catch leaked threads next time <para-sep> groups all of the partition locations by the round-th entry in their prioritized list of host nodes . <nl> only set once one full run completed to ensure all persistent threads created : <nl> there is a pool of ksql worker threads that grows over time , but is capped . <nl> give threads a chance to die ...","this fixes a leaked executor service with 0 threads that is being created once-per-request for pull queries . <nl> 0. the first commit fixes the leaked executor . <nl> 0. the second enhances rqtt to ( hopefully ) catch such errors in the future ( this is the second such bug in quick succession ) . <nl> this bug was stopping rqtt running locally for me , because the jvm was running out of resources . <nl> important : it looks to my untrained eye that the current pull query code is creating an executor with 0 threads _on each",1606174541,adds support for listing queries to the java client . <nl> docs will come in a follow-up pr . javadocs on the new method and interface are included in this one . <nl> added unit and integration tests .,0.9556542038917542
elastic_elasticsearch/71172,adapt frozen write buffer and thread pool <para-sep> reduce the buffer size per cache-fetch thread to keep direct memory usage under control .,"increases the write buffer size to 2mb , which has shown in benchmarks to provide better throughput on the frozen tier . also makes the corresponding cache fetch thread pool size adaptive , as we 're otherwise consuming too much memory on smaller instance nodes . for the instance types ( e.g . i3en.2xl ) considered on cloud ( 0 cpu ) , the number of cache_fetch threads stay roughly the same .",1617273595,this commit migrates the esintegtestcase tests in x-pack to the <nl> internalclustertest source set .,0.9071046113967896
quarkusio_quarkus/15309,ignore config_ordinal for default values source . <nl> ( cherry picked from commit sha ) <cm-sep> kubernetesdeployer now always deletes existing resources . <nl> ( cherry picked from commit sha ) <cm-sep> group all raw service binding properties under quarkus.service-binding . <nl> this is done in order to avoid accidental collision of properties <nl> when only quarkus was used as a prefix . <nl> ( cherry picked from commit sha ),"please do n't merge , i will merge it myself .",1614186667,"this is a pre-requisite for a sequence of fixes i 'll be sending later ; they all need the version upgraded first , so it would be simpler to first merge this and then send individual prs for each fix .",0.9439923167228699
ballerina-platform_ballerina-lang/23545,infer error type from rhs <cm-sep> add test cases for error detail inferring,this is handled the same way the compiler handles .,1590579556,"this is expected to prevent infinite loops when analyzing invocation outcomes . <nl> during the block resolution , taint analyzer will ignore recursive invocations and analyze the rest of the function to determine the tainted outcome of the function . however , as soon as the blocking invocation get ignored , taint analyzer will change into a mode where it will not skip any proceeding booking invocations . this is done to prevent invalid taint outcomes . <nl> when there are multiple recursive invocations , the following recursive invocations will not get skipped causing a stack-overflow . <nl> due to",0.8986369967460632
runelite_runelite/12552,added mapping for unidentified minerals . <nl> unidentified minerals recently became sellable to an npc in the mining guild in the same way gold nuggets are sellable . <cm-sep> corrected comment <para-sep> 0 unidentified minerals = 0 soft clay,unidentified minerals recently became sellable to an npc in the mining guild in the same way gold nuggets are sellable .,1601069723,"adds the blighted food/pots introduced with the bounty hunter update to the itemstats plugin . <nl> blighted anglerfish , manta ray , karambwan , and super restore ( 0 ) - ( 0 ) .",0.8377078175544739
grpc_grpc-java/7618,clarify the actual semantics of num_failures . <para-sep> the number of rpcs succeeded for each peer . the number of rpcs that failed . the number of rpcs succeeded for each peer . the number of rpcs succeeded for each type ( unarycall or emptycall ) .,this is something i found very confusing and error-prone . <nl> the proto field is named as but its comment is saying it is for number of rpcs that failed to record a remote peer . <nl> rpc failed == rpc failed to record a remote peer was true previously ( so no existing tests should be affected by this changed ) as server completed rpcs immediately . it is no longer true with server capability to keep the call open/delayed . <nl> no change needed for implemented the circuit breaking test as it uses accumulated stats for test logic,1605173384,unused variables in tests were deleted . the unused variable in netty <nl> was a future that needed completing ; that was a bug .,0.8670645356178284
elastic_elasticsearch/71092,lower memory usage of snapshotretentiontask . <nl> sometimes can be non-trivial in size when containing <nl> a number of exceptions . this commit makes it so we do n't retain these <nl> objects all the way until the deletion finishes . <para-sep> snapshotinfo instances can be quite large in case they contain e.g . a large collection of exceptions so we extract the only two things ( id + policy id ) here so they can be gced,sometimes can be non-trivial in size when containing <nl> a number of exceptions . this commit makes it so we do n't retain these <nl> objects all the way until the deletion finishes .,1617166483,"a technical limitation in the stack made it necessary to use this workaround . <nl> it is now possible to find out , if a node is a <nl> transform node without using the node attribute . this pr deprecates the node attribute and bases <nl> the placement decision on the node role . the attribute gets unused for placement , however we can <nl> not remove the node attribute yet , because in a mixed version cluster the attribute might still <nl> be used , especially when master gets updated last . the node attribute will be completely removed",0.9046202301979065
vespa-engine_vespa/16984,"retire all wanttoretire nodes with typenodespec <para-sep> all nodes marked with wanttoretire get marked as retired just before this function is called <nl> the orchestrator will allow only 0 to be removed , say cfg1 <nl> there are now 0 retired config servers left <nl> the retiring nodes should be the nodes we marked for retirement <nl> let all retired nodes expire <nl> all currently active proxy nodes are not marked with wanttoretire or as retired <nl> all the nodes that were marked with wanttoretire earlier are now dirty","when wanttoretire is set on a set of infra nodes ( any non-tenant application ) , at most 0 node is allowed to retire . <nl> this causes a problem when wanting to reprovision all config servers : say cfg1 and cfghost2 is allowed to retire . cfghost2 will not be allowed to exit retirement because cfg2 is not parked , which it can not be because it is n't even retired yet . <nl> capping the number of retiring nodes seems unnecessary . for instance retiredexpirer ensures only one config server is allowed to complete retirement ( be removed",1615906182,"this should fix most of the issues with . <nl> this pr simplifies/makes tests more accurate by using to perform application activation ( thereby always setting last deploy time ) . this makes it possible to simplify the actual maintainers by always using last deploy time , f.ex . in . this should also fix a minor bug where an operator has performed a change , but the redeployment failed - in that case it would not be retried until picked it up . <nl> the rest is just logging a nicer stack trace on transient errors . <nl> what",0.9330377578735352
apache_kafka/9639,"; complete fetches in purgatory immediately after raft leader resigns <para-sep> send fetch request when become leader <nl> append some record , but the fetch in purgatory will still fail <nl> when transition to resign , all request in fetchpurgatory will fail <nl> shutting down finished","more detailed description of your change . <nl> if the condition of fetch is satisfied , or is returned when the leader is shutting down . so we just return with a message . <nl> summary of testing strategy <nl> a simple unit test to verify fetches in purgatory is completed after resigning .",1606055780,"when the log contains out of order message formats ( for example v2 message followed by v1 message ) and consists of compressed batches typically greater than 1kb in size , it is possible for down-conversion to fail . with compressed batches , we estimate the size of down-converted batches using : . <nl> this almost always underestimates size of down-converted records if the batch is between 1kb in size . in general , this means we may under estimate the total size required for compressed batches . <nl> because of an implicit assumption in the code that messages with",0.9376019239425659
apache_kafka/10215,"dont remove thread until dead , trim later <cm-sep> dont remove from threads until shut down <para-sep> do n't remove from threads until shutdown is complete . we will trim it from the list once it reaches dead , and if for some reason it 's hanging indefinitely in the shutdown then we should just consider this thread.id to be burned <nl> returns the number of threads that are not in the dead state -- use this over threads.size ( ) <nl> trim any dead threads from the list so we can reuse the thread.id this is only safe to do once the thread has fully completed shutdown <nl> assume threads are always named with the ' -streamthread- ' suffix <nl> it 's safe to use threads.size ( ) rather than getnumlivestreamthreads ( ) to infer the number of threads here since we trimmed any dead threads earlier in this method while holding the lock","basically any id that is n't actively being used by a non-dead thread in the list is fair game . this is relevant in two scenarios : . <nl> : when choosing to replace a thread after a recoverable error , we should just grab a new ( and free ) thread.id rather than reusing the id of the dying thread , to avoid a race condition between the old thread shutting down and the new thread starting up . <nl> : in this case , if we have n't explicitly waited for the thread to complete the shutdown ,",1614310385,"re-validate and make sure the topic either exists or it 's gone by using a delay . <nl> there is a bug in the internaltopicmanager that makes the client believe that a topic exists even though it does n't , it occurs mostly in those few seconds between when a topic is marked for deletion and when it is actually deleted . in that timespan , the broker gives inconsistent information , first it hides the topic but then it refuses to create a new one therefore the client believes the topic was existing already and it starts polling for",0.9179227948188782
elastic_elasticsearch/71555,add scripts to keyword field mapper,"this commit adds and parameters to <nl> keyword field mappers , allowing you to define index-time scripts <nl> for keyword fields .",1618229254,"adds a setting that , when enabled , directs any currently running exporters in monitoring will treat any cluster alert definition as excluded from the list of allowed cluster alert watches . this is the first step to adding a migration path away from using cluster alerts configured by the monitoring plugin and toward those managed by the stack monitoring solutions on the new alerting feature .",0.9768015742301941
apache_incubator-pinot/5892,expose response stats in the pinot client 's brokerresponse . <nl> this would let the client application to observe and print response stats selectively <nl> for queries and avoid reproducing slow queries . <para-sep> simple pojo to hold query execution statistics for a request . these stats come in every query that 's executed and can be used for debugging pinot slow queries . please note that objects of this class will hold a reference to the given jsonnode object and that will only be released when the object is gc'ed . <nl> lazily load the field from the jsonnode to avoid reading the stats when not needed . <nl> verify the execution stats .,"* no <nl> * no . <nl> yes . the java client of pinot now exposes brokerresponse object , which has responsestats in the api .",1597770506,"in order to allocate memory efficiently for dictionary for a column , we can attempt to use <nl> the statistics gathered from previously completed segments . <nl> added a class to keep track of statistics for n previously completed segments for a table on local disk <nl> of each server . for now , we have code to store average size ( in case of a string column ) and cardinality <nl> ( for all columns ) . these can be used when initializing a dictionary for the next segment . <nl> some methods are synchronized since we expect that",0.9698471426963806
elastic_elasticsearch/72080,"remove mapperservice # parse method . <nl> we have recently split documentmapper creation from parsing mapping . there was one method leftover that exposed parsing mapping into documentmapper , which is generally not needed . either you only need to parse into a mapping instance , which is more lightweight , or like in some tests you need to apply a mapping update for which you merge new mappings and get the resulting document mapper . this commit addresses this and removes the method . <cm-sep> iter","we have recently split documentmapper creation from parsing mapping . there was one method leftover that exposed parsing mapping into documentmapper , which is generally not needed . either you only need to parse into a mapping instance , which is more lightweight , or like in some tests you need to apply a mapping update for which you merge new mappings and get the resulting document mapper . this commit addresses this and removes the method .",1619092788,"almost every outbound message is serialized to buffers of 16k pagesize . <nl> we were serializing these messages off the io loop ( and retaining the concrete message <nl> instance as well ) and would then enqueue it on the io loop to be dealt with as soon as the <nl> channel is ready . <nl> 0. this would cause buffers to be held onto for longer than necessary , causing less reuse on average . <nl> 0. if a channel was slow for some reason , not only would concrete message instances queue up for it , but also",0.9545298218727112
elastic_elasticsearch/71067,"[ ml ] make ml memory tracker more robust to flipping on/off master . <nl> testing has shown that during cluster formation it is possible for <nl> a node to flip backwards and forwards between being master/not <nl> being master a couple of times . the ml memory tracker is not <nl> completely robust to this . <nl> this change improves the situation in a low-risk way , by aborting <nl> refreshes if the node ceases to be master during the refresh , and <nl> not updating the last update time when this happens . this helps <nl> because then the ' is recently refreshed ? ' question will return <nl> false if the node briefly became master , then ceased to be master <nl> before the refresh was complete , then later became master again . <nl> there is still a race condition after this change : it is possible <nl> that the ' is recently refreshed ? ' question is asked after a <nl> refresh is complete and while the node is still master , but then <nl> the node ceases to be master before the memory information is used . <nl> fixing this is a much more major change , so too dangerous for a <nl> patch . since the refresh is a longer operation than a simple <nl> boolean accessor , the change in this pr should still help a lot .","testing has shown that during cluster formation it is possible for <nl> a node to flip backwards and forwards between being master/not <nl> being master a couple of times . the ml memory tracker is not <nl> completely robust to this . <nl> this change improves the situation in a low-risk way , by aborting <nl> refreshes if the node ceases to be master during the refresh , and <nl> not updating the last update time when this happens . this helps <nl> because then the ' is recently refreshed ? ' question will return <nl> false if the node",1617118604,"shouldstopatcheckpoint tells transform to stop at the next checkpoint , if <nl> this api is called while a checkpoint is finishing , it can cause a race condition <nl> in state persistence . <nl> with this change does not call dosavestate <nl> if indexer is shutting down . still it ensures the job stops after the indexer has <nl> shutdown . apart from that the change fixes : a logging problem , it adds error <nl> handling in case of a timeout during . some <nl> logic has been moved from the task to the indexer .",0.9337881803512573
apache_pulsar/9767,"fix topic ownership is not checked <cm-sep> merge master <para-sep> setup cluster with 0 broker <nl> for partitioned topic , we can get topic policies from every broker <nl> for non-partitioned topic , we can get topic policies from every broker","in the case of multiple brokers , a will appear . <nl> 0. the parameter validation of the read and write api should not be the same , and the read api should not verify . if is set , the read api will also be abnormal . <nl> 0. general api should not use .",1614601385,"consumer subscriptions are not cleanup when functions/sinks are terminated which can be a headache for admins to do this manually . because subscriptions are left over , topics never get cleaned up . <nl> in this pr , i created a flag ' cleanupsubscription ' that indicates whether the subscriptions created by the function should be removed on terminate . the flag is set to true by default , since i think that is probably going to be the normal use case . <nl> i also fixed the shutdown process of function processes .",0.9509158730506897
Alluxio_alluxio/11596,fix glue udb fetch partition <para-sep> todo ( shouwei ) : make getpartition multi-thread to accelerate the large table fetching,glue fetches a random number of partition from glue service without setting the and . add the and to fix the partition fetching for glue udb .,1592519892,before : . <nl> after : .,0.9339385032653809
apache_pulsar/9255,fix peek message metadata broker while enable broker entry metadata . <para-sep> test for the broker entry metadata .,"fix peek message metadata broker while enable broker entry metadata . <nl> when enabled the broker entry metadata , following error occurs : . <nl> the root cause is peeking message metadata does not skip the broker entry metadata . <nl> skip the broker entry metadata if exists when peek message metadata . <nl> tests added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no )",1611213671,"currently , if we pass an invalid source configuration to instantiate we will get no log even there is an exception thrown . and after called , the background thread may still alive unless we caught an if returns . so i would like to add a flag to indicate if the connector is stopped . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9583798050880432
apache_pulsar/8973,motivation . <nl> we have a new package management service which can manage all <nl> the packages . we can use that in the pulsar function which will <nl> make the function packages are easier to manage . <nl> modifications . <nl> - support new package type url <para-sep> add auth plugin and parameters if necessary <nl> expected exception <nl> expected exception,motivation . <nl> we have a new package management service which can manage all <nl> the packages . we can use that in the pulsar function will make the <nl> function packages are easier to manage . <nl> i reuse the 'packageurl ' for downloading the package from the packages <nl> management service . so user can use the package name as the 'packageurl ' <nl> to download it . <nl> modifications . <nl> - support new package type url for creating and updating functions <nl> - support to use package download command for kubernetes runtime <nl> - add tests,1608128310,"recently , multiple times we have seen that for a specific topic , all repl clusters reached to backlog quota in below scenario . <nl> 0. initially client had non-partitioned topic in one of the colo ( eg : topic1 ) and then client had made it partitioned-topic with partition 0 . <nl> 0. now when broker tires to load bundle it tries to load non-partition topic ( topic1 ) which starts replication-producer which internally creates producer on partitioned-topic ( topic1- and topic1- ) because topic has been converted to partitioned-topic in global-zk . <nl> 0. now , when broker",0.9696552753448486
OpenAPITools_openapi-generator/8159,add .t in spec generation of object types,i 'm unable to run the due to an error when generating the jar file : .,1607683740,"the validate command now uses parseoptions # setresolve ( true ) to match how <nl> we parse in codegenconfigurator and online 's generate . without this <nl> option , the openapi 0 parser skips the ' resolve ' block , which made lead <nl> to validations in the command not matching validations during <nl> generation . <nl> and : .",0.8045267462730408
elastic_elasticsearch/71833,"unify supported runtime fields script contexts . <nl> there 's a few places where we need to access all of the supported runtime fields script contexts . up until now we have listed them in all those places , but a better way would be to have them listed in one place and access that same list from all consumers . this is what this commit introduces . <nl> along with the introduction of runtime fields contexts in scriptmodule , we rename the whitelist files so that they contain their corresponding context name to simplify looking them up .","there 's a few places where we need to access all of the supported runtime fields script contexts . up until now we have listed them in all those places , but a better way would be to have them listed in one place and access that same list from all consumers . this is what this commit introduces . <nl> along with the introduction of runtime fields contexts in scriptmodule , we rename the whitelist files so that they contain their corresponding context name to simplify looking them up .",1618836355,"i added the enumsetting option to as suggested in the issue . additionally , i changed the settings mentioned in the issue into s . <nl> this is my first elasticsearch contribution , so no doubt i missed some details or forgot to do something while following the contribution guide . please let me know ! <nl> i was n't certain of some impl . details . i have added comments at file level illustrating this .",0.9378108978271484
apache_druid/10645,two fixes related to encoding of % symbols . <nl> 0 ) taskresourcefilter : do n't double-decode task ids . request.getpathsegments ( ) <nl> returns already-decoded strings . applying stringutils.urldecode on <nl> top of that causes erroneous behavior with ' % ' characters . <nl> 0 ) update various threadfactorybuilder name formats to escape ' % ' <nl> characters . this fixes situations where substrings starting with ' % ' <nl> are erroneously treated as format specifiers . <nl> its are updated to include a ' % ' in extra.datasource.name.suffix . <para-sep> encodes a string ' s ' for insertion into a format string . returns null if the input is null .,0 ) taskresourcefilter : do n't double-decode task ids . request.getpathsegments ( ) <nl> returns already-decoded strings . applying stringutils.urldecode on <nl> top of that causes erroneous behavior with ' % ' characters . <nl> 0 ) update various threadfactorybuilder name formats to escape ' % ' <nl> characters . this fixes situations where substrings starting with ' % ' <nl> are erroneously treated as format specifiers . <nl> its are updated to include a ' % ' in extra.datasource.name.suffix .,1607205067,"also changes the built-in allowed property prefixes so they are always added . i think that makes more sense , otherwise a user-provided list might break something built-in ( like a pusher 's list ) . also changes the prefixes from looking like ' druid.xxx . ' to looking like ' druid.xxx ' . this is useful for stuff like ' druid.emitter ' , where ' druid.emitter ' is a property but so is ' druid.emitter.foo ' . <nl> i think these behavior changes are all fine for a minor release since allowedhadoopprefix was n't documented yet .",0.9300750494003296
elastic_elasticsearch/70875,fix infinite loop when polygonizing a circle <para-sep> it throws an illegalargumentexception if the circle contains a pole . <nl> make sure we do not start at angle 0 or we have issues at the poles,"when transforming a circle with centre on one of the poles into a polygon on the geo case , the code enters in an infinite loop . this is because we are trying to find a point at a distance from the pole by just changing the value of the longitude . this point is always itself . <nl> this pr changes the logic so we fail whenever we try to polygonize a circle that contains a pole .",1616680490,"today search responses do not report failures for shard that were not available <nl> for the search . <nl> so if one shard is not assigned on a search over 0 shards , the <nl> search response will report : . <nl> if all shards are unassigned , we report a generic search phase exception with no cause . <nl> it 's easy to spot that is less than in the response but not reporting <nl> the failure is misleading for users . <nl> this change removes the special handling of not available shards exception in search responses <nl> and",0.9177147746086121
apache_incubator-pinot/5894,add a separate table for storing online data <cm-sep> add crud endpoints for online detection data <para-sep> delete expired online detection data <nl> todo : refactor code to resolve request configurations in one place ( e.g . default/customized config names ) <nl> create & save dataset <nl> create & save metric <nl> save online data <nl> data is already registered and dataset/metric config should also have been created <nl> check if time & metric columns exist in adhoc data <nl> check if time & metric columns exist in adhoc data <nl> save online data <nl> registered online data should not be cleaned <nl> suffix format : __ <nl> customized metric name <nl> register the online detection ad-hoc data with optional customized dataset and metric configurations . <nl> create & save dataset <nl> create & save metric <nl> save online data <nl> update the online detection ad-hoc data with optional customized dataset and metric configurations . <nl> find existing dataset config <nl> find existing metric config <nl> update dataset config <nl> update metric config <nl> delete the online detection ad-hoc data with optional customized dataset and metric configurations . <nl> query the online detection ad-hoc data with optional customized dataset and metric configurations . <nl> test customized metric and time column names - good <nl> pass <nl> test customized metric and time column names - bad <nl> pass <nl> default config names . <nl> customized config names . <nl> test1 : update adhoc data and dataset config <nl> test2 : update adhoc data and metric config <nl> test3 : update adhoc data and dataset config and metric config <nl> pre : build and store an online data <nl> update based on input,phase 0 is separated into two parts . this pr is for the 2nd part . please note that this pr has a dependency . <nl> the main change is that several crud endpoints are created for managing online detection data . those endpoints are listed as follows : . <nl> * post /anomaly-detection/data - register data . the data should be provided in the request . the dataset and metric configurations can optionally be provided to customize configurations . a will be returned . <nl> * get /anomaly-detection/data/ { data-id } - retrieve registered data with the corresponding dataset,1597777490,"created new bean , dto , index , manager , resource for ingraphdashboardconfig",0.9849315881729126
ballerina-platform_ballerina-lang/24652,"avoid logging incompatible types error for constructor exprs with invalid cets <cm-sep> fix anon type name getting printed for immutable records/objects <cm-sep> avoid logging errors for errored constrs/union cets and add tests <para-sep> ignore the return value , we only need to visit the expressions .",need to merge that first .,1594203984,"> * fix the issue of functions not invoking in function , and enable the tests .",0.9372884631156921
elastic_elasticsearch/71163,"remove legacy role settings . <nl> this commit removes the previously deprecated legacy role <nl> settings . these settings have been replaced by node.roles . <para-sep> details * + <nl> impact * + <nl> do n't use discoverynode # isdatanode ( settings ) here , as it is called before all plugins are initialized",this commit removes the previously deprecated legacy role settings . these settings have been replaced by node.roles .,1617238032,"removed the autoscaling feature flags , autoscaling is now on by default <nl> ( though it requires an external system to handle the autoscaling <nl> events ) . added experimental notice to all autoscaling related <nl> documentation pages .",0.9346061944961548
quarkusio_quarkus/15818,"the default for orm is false , but when we create the sessionfactory <nl> for hibernate reactive this value has to be true . <para-sep> injecting a vert.x pool is not required , it 's used to independently validate the contents of the database for the test",fetch of lazy associations after a find .,1616002081,"* verifies all valid signatures <nl> * added hot reload tests for config and code , as well as recovery after an error <nl> * verifies that profiles are supported",0.9868292808532715
apache_shardingsphere/10195,fix exception message missing format in jdbclockengine,changes proposed in this pull request : <nl> - fix exception message missing format in jdbclockengine .,1619415544,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - fix for mysql tcl <nl> - ref mysql dml,0.7586804628372192
apache_druid/10660,"fix race condition with druidschema tables and datasourcesneedingrebuild <para-sep> remove broadcast rule <nl> prepare for broadcast by adding forever broadcast load rule <nl> query metadata until druid schema is refreshed and datasource is no longer available <nl> someday we could hypothetically remove broker special casing , whenever brokerserverview supports tracking broker served segments in the timeline , to ensure that removesegment the event is triggered accurately <nl> someday we could hypothetically remove broker special casing , whenever brokerserverview supports tracking broker served segments in the timeline , to ensure that removesegment the event is triggered accurately for brokers , if the segment drops from all historicals before the broker this could be null . <nl> a segment on a broker means a broadcast datasource , skip metadata because we 'll also see this segment on the historical , however mark the datasource for refresh because it might no longer be broadcast or something","the underlying issue was caused by a race condition between being populated upon rebuilding the tables , segment removal handlers removing segments from when no other segments were left ( but not ) , and not considering if the table had been removed from due to all the segments being dropped in the time between being added to the refresh list and actually doing the refresh . <nl> the added an additional step to the integration test that would fail prior to the changes in , and chose this test in particular to cover the most surface area since there",1607483339,but i would like to suppose that there may be rare possibility someone has a dependency on this field . the restful should be the priority option to retrieve segment metadata,0.9020900130271912
jenkinsci_jenkins/4658,"restyles the buttons . <nl> - disables default yahooui button styles <nl> - use yui classes for backwards compatibility : <nl> - button element <nl> - styles are applied by default for the following input types : <nl> - <nl> - add a large button variant <nl> - the variant is set adding the .large-button class <nl> - f : apply and f : submit jelly templates now have a islarge property that allows toggling large buttons on <nl> - job configuration has large buttons <cm-sep> adds styles for hyperlinks as buttons <cm-sep> adds styles for icons within buttons <cm-sep> add icon buttons and update button styles <cm-sep> removed button nested within an anchor link . <nl> - now that the anchor tags with a .yui-button class are styled like buttons , it is unnecessary to add a button within . <para-sep> state colors <nl> buttons <nl> button variant mixins <nl> button styles <nl> vertical padding : versionrem == 6px == 32px ( target height ) - 4px ( borders ) - 0 ( line ) / 0 <nl> vertical padding versionrem == 8px == 40px ( target height ) - 4px ( borders ) - 0 ( line ) / 0 <nl> dropdown buttons <nl> these buttons have a caret as the : after element <nl> icon buttons","this pr can be tested using the following docker image : . <nl> this pr restyles the buttons . the css api is described in detail in the jira issue . <nl> to summarize : <nl> - buttons are restyled from scratch . removed references to yahooui css code that dealt with buttons in order to avoid overriding styles . <nl> - use the same css api that yui buttons used . no breaking changes here . <nl> - created styles for 0 button variants : primary , secondary ( default ) , danger and link ( transparent ) .",1586950679,"… and when rewriting jenkins.exe . <nl> ' jenkins.copies ' should be written to the folder containing the service wrapper executable ( jenkins.exe ) . currently , jenkins_home is used . using a custom jenkins_home will cause the file to be written to a wrong directory . the service wrapper is setting the environment variable base which is the correct directory to use . <nl> * entry 0 : , fixing problem with auto upgrade when using custom jenkins_home on windows .",0.8691079020500183
jenkinsci_jenkins/4730,"make computer # getlogdir thread-safe . <nl> when called by concurrent threads , the call to ioutils.mkdirs could <nl> fail with filealreadyexistexception","when called by concurrent threads , the call to could <nl> fail with . <nl> * fix a thread safety issue in",1589803977,"remove xml string writer from ioexception2 message when xpath error <nl> occurs in /api/xml request . <nl> the xml string writer has the potential to be very large ( many <nl> megabytes or even gigabytes ) and these exceptions will be logged to <nl> the default jenkins logfile by winstone . this has the potential to <nl> quickly use all available disk space if , for example , a jenkins poller <nl> ( i.e . a chrome extension ) makes frequent calls to the api that causes <nl> errors . <nl> this is a quick fix to address a specific",0.8046078681945801
netty_netty/11031,less noisy logging in . <nl> motivation : . <nl> it is not uncommon to run netty on os x without the specific <nl> . the current log message is too <nl> verbose because it prints a full stack trace on the console while a <nl> simple logging message would have been enough . <nl> modifications : . <nl> - print a message when <nl> class is not found ; <nl> - print a message with a stack trace when the class was found <nl> but could not be loaded due to some other reasons ; . <nl> result : . <nl> less noise in logs .,motivation : . <nl> it is not uncommon to run netty on os x without the specific <nl> . the current log message is too <nl> verbose because it prints a full stack trace on the console while a <nl> simple logging message would have been enough . <nl> modifications : . <nl> - print a message when <nl> class is not found ; <nl> - print a message with a stack trace when the class was found <nl> but could not be loaded due to some other reasons ; . <nl> result : . <nl> less noise in logs,1613719969,unlogged throwable . <nl> motivation : . <nl> besides an error caused by closing socket in windows a bunch of other errors may happen at this place which wo n't be somehow logged . for instance any as will be simply ignored . the library should at least log the problem . <nl> modification : . <nl> added logging of the throwable object . <nl> result : .,0.8243331909179688
Alluxio_alluxio/10897,improve error handling for attach db and sync <para-sep> todo ( gpang ) : remove in favor of status <nl> todo ( gpang ) : remove in favor of status <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> optional bool ignore_sync_errors = 0 ; <nl> todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus sync_status = 0 ; <nl> todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status todo ( gpang ) : remove in favor of status <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl> optional .alluxio.grpc.table.syncstatus status = 0 ; <nl>,this change adds an option to keep the database attached even if a sync failure occurred .,1581535918,"if new partitions are synced to a table , and the table is transformed with the same definition , then only the newly added partitions will be transformed .",0.9852070212364197
vespa-engine_vespa/15970,add more fields to tenant metadata,starting adding more tenant metadata information : . <nl> * last deployment to dev <nl> * last submission to prod . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610104362,"this fixes a corner case where we compute versions to run in system and staging tests , where the first production deployment used to compute the versions has a newer platform that what we are deploying — this confused the algorithm into believing it needed both a run which was a success both on the deploying change , and on the newer version , which is obviously impossible . when a newer version exists in the production deployment , this is now used instead of , not in addition to , the deploying change .",0.8929728865623474
hazelcast_hazelcast/18337,report java classpath in phone homes .,"with this change , we add reporting of the java classpath that the members run on . since we pass the info as <nl> part of the request uri , the header section might become very large depending on the classpath of the project . <nl> for this reason , we will need to increase maximum size of the http message header in phone home server application . <nl> in the <nl> future , we should change to scanning the classpath for libraries that we 're interested of . <nl> the classpath is not cleaned up on the member side",1614759310,"- fixes hazelcasttestsupport.assertjoinable , expects milliseconds timeout , not nanoseconds . <nl> - threadleaktestutils initializes logger factory . log4j2 creates its own shutdown hook threads , by initializing logger initially we force them to be created beforehand . this is required to be able to detect thread leaks . <nl> - add explicit thread names to test connection managers .",0.9235783815383911
elastic_elasticsearch/71085,exclude invalid url-encoded strings from randomized tests <para-sep> some random strings produced by the randomized test framework contain invalid url encodings,the randomized testing framework produces some input strings that are not valid url-encoded strings so the urldecodeprocessor correctly throws an exception . this change retries any tests that use a string that can not be url decoded .,1617144498,"as requestoptions add requestconfig , users can set some request config per request , e.g sockettimeout . <nl> without requestconfig , sockettimeout can only set in restclient init . <nl> as different kind of request maybe have different request options , users can set requestconfig optional .",0.9282833933830261
apache_shardingsphere/9752,fixed 0 <cm-sep> update <cm-sep> add token generator for creating table <cm-sep> add token generator for creating table <cm-sep> add token generator for creating table <cm-sep> add token generator for creating table <cm-sep> add token generator for creating table <para-sep> create table token generator for encrypt . <nl> create table token generator for encrypt . <nl> create table token for encrypt . <nl> create table token for encrypt .,changes proposed in this pull request : <nl> - <nl> - <nl> -,1616219558,- fix get data source for shadow <nl> - add shadow insert values token generator <nl> - add remove shadow column token generator <nl> - add the executeupdate,0.9646218419075012
vespa-engine_vespa/15463,invoice methods needed to support csv generation . <nl> - create methods to summarize values in the line items up to the invoice level . <nl> - make tenant id part of the invoice . <cm-sep> method to access all invoices in database <cm-sep> export all bills/invoices as csv <para-sep> anything that is not covered by the cost for resources is ' additional ' costs,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606307371,"( the second commit , the first is just unrelated functional changes . )",0.9715842604637146
apache_beam/13448,address flake in loadbalancesbundles <para-sep> this call should block until closingfuture has finished closing b2 ( 100ms ) ensure the previous call waited for close <nl> join closingfuture and check if an exception occurred,"see my comment on for an explanation of what seems to have caused the flakes : . <nl> however since we left the forked thread , it never got out of the b2.close ( ) call and set the boolean . <nl> this pr addresses it by replacing the and with a . we then make an assertion on the result of the scheduled future , including a small delay to make sure the main thread will block and give the forked thread a chance to run . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all",1606787790,consolidate on one parser and drop . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .,0.9028522372245789
ballerina-platform_ballerina-lang/24001,add match pattern support for transformer,add match pattern support for transformer .,1591950873,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.8789732456207275
vespa-engine_vespa/16552,log active and new config before reconfiguring,"wait a minute , need to format config",1613567922,this fixes possibly two build breakages .,0.8264962434768677
Alluxio_alluxio/12261,update one deprecated call <cm-sep> checkstyle,constructor is deprecated . replaced with recommended call .,1602594535,"in most of the objectunderfilesystem operations , we will strip prefix if exist . prefix here refers to the specific object ufs root key ( s3 : //bucket_name for example ) . <nl> however , in our objectunderfilesystem.isroot check , we still check if the stripped path ( ' / ' for example ) equals to the full root key ( s3 : //bucket_name ) . <nl> this fix consider the isroot case for both stripped path and original full url .",0.8589287400245667
grpc_grpc-java/7588,introduce an interface for providing per-clusuter request counters . <para-sep> provides the counter for aggregating outstanding requests per cluster : eds_service_name . introduced for testing . <nl> the global map for holding circuit breaker atomic counters .,"use weakreference to hold atomics . circuit breaking will always be enabled , with the limit of per-cluster concurrent requests default to 0. each eds lb policy will get or create the counter for aggregating outstanding requests sent through it at the time it is instantiated . this holds a strong reference to the counter ( as well as the picker instance spawned ) . when the eds lb policy and the picker instance are destroyed , strong references will be gone . atomics will be gced when strong references are gone and the global map will be cleaned up",1604439123,"this is part 0 of a larger change to simplify channel initialization . part two will be to let protocol negotiators install themselves in a deterministic manner and delegate error handling to the exception handler . <nl> changes : . <nl> 0. copied most of abstractbufferinghandler to writebufferingandexceptionhandler . wbaeh does not handle adding more than one handler . eventually , pipeline initialization will happen in the protocol negotiator rather than in each handler . <nl> 0. added tests for error handling . <nl> 0. the wbaeh is always added to the nettyclienttransport . this means for a brief period",0.9851288199424744
elastic_elasticsearch/70625,"local size in stats . <nl> with shared cache searchable snapshots we have shards that have a size <nl> in s3 that differs from the locally occupied disk space . this commit <nl> introduces to node and indices stats , allowing to <nl> differ between the two . <para-sep> if this shard has no disk footprint then its local size is reported as 0","with shared cache searchable snapshots we have shards that have a size <nl> in s3 that differs from the locally occupied disk space . this commit <nl> introduces to node and indices stats , allowing to <nl> differ between the two .",1616410449,"today searchable snapshots implementations use the _blob store cache_ to cache the first bytes of every lucene files . after some experiments we think that we could adjust the length of the cached data depending of the lucene file that is read , caching up to 64kb for lucene _metadata_ files ( ie files that are fully read when a directory is opened ) and only 1kb for other files . <nl> the files that are cached up to 64kb are the files with the following extensions : . <nl> > ' cfe ' , // compound file 's entry",0.9603462219238281
ballerina-platform_ballerina-lang/25820,"change objects to class , add abstract objects <para-sep> generates the page bclasses for bal packages . check for class definitions in the package <nl> get field documentation from bclass/record def documentation <nl> iterate through the functions <nl> create pages for bclasses <nl> create pages for abstract objects <nl> page context for the abstract object page . <nl> represent documentation for an abstract object . <nl> represent documentation for an bclass . <nl> page context for the bclass page . <nl> check whether the symbol is a listener bclass . <nl> test deprecated bclass member methods <nl> test non-deprecated bclass member methods <nl> test class to check record/bclass field-level documentation in docerina . bclass with module-level documentation <nl> bclass with field-level documentation <nl> bclass with both module-level & field-level documentation <nl> test cases to check default value initialization for bclasses in docs .",> - anonymous objects are now shown inline .,1600170976,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9784567952156067
Alluxio_alluxio/12105,add loadmetadata command <para-sep> loads metadata about a path in the ufs to alluxio . no data will be transferred . <nl> loads the metadata of a file from the under file system . <nl> constructs a new instance to load metadata for the given alluxio path from ufs .,"we used to have a command <nl> this pr restores loadmetadata command , but as a client-side optimization without storing all returned results , preventing oom for massive amount of small files . <nl> this optimization is experimental , going to .0-fuse only for now .",1599950661,"this pr : <nl> 0. adds to and implement it in . <nl> 0. when calling from alluxio master , if acl is supported and enabled in under file system , loads the acl to alluxio inode tree . <nl> this pr extends the to include acl entries , so when creating an inode in , the acl entries retrieved from ufs are set into the inode 's acl . <nl> another design option is to extend the to include acl entries , then create inode without acl , after the creation is completed , use to set the acl",0.9619825482368469
runelite_runelite/11825,item charges : update amulet of chemistry charges when creating less than 0 dose potions,updated the regex for amulet of chemistry to update the amulet 's charge count when creating less than 0-dose potions,1591391303,"- on screen marker renaming , enter to save , esc to cancel <nl> - on screen marker title hover , preview that screen marker ingame . <nl> ( this last one is useful when you have a bunch of hidden markers and you want to look for a specific one , faster than toggling one at a time )",0.8652536273002625
confluentinc_ksql/6583,bump ak version to version-beta201006024150- <cm-sep> use correct artifacts <cm-sep> change again kafka version <cm-sep> bump command version number,unit and integration tests are expected for any behavior changes._ .,1604632059,also minor other doc fixes i encountered while making this patch . <nl> note : i wo n't merge this until i have the embedded connect pr merged ( which is about to come out ) .,0.5774824619293213
apache_incubator-pinot/5370,"schema method to fetch field spec of time column <para-sep> test method which fetches the datetimefieldspec given the timecolumnname test is on time <nl> test it on date_time <nl> fetches the datetimefieldspec for the given time column name . if the columnname is a date_time column , returns the datetimefieldspec if the columnname is a time column , converts to datetimefieldspec before returning","introducing method in . if , fieldtype for time columnname is <nl> 0 ) date_time - return the datetimefieldspec <nl> 0 ) time - convert to datetimefieldspec before returning <nl> as per recent discussions , we will not be changing the ser/deser of timefieldspec in schema , so as to not mess with external integrations . as a result , we decided that schema can have timefieldspec/datetimefieldspecs/both/none . the timecolumn is anyway decided by the table config . <nl> this means , the callers of getfieldspecfor ( time ) can get either datetimefieldspec or timefieldspec , and the caller should",1589249055,updated the unit test to include both versions,0.9163376688957214
apache_druid/10499,"support for vectorizing expressions with non-existent inputs , more consistent type handling for non-vectorized expressions <cm-sep> inspector","this pr also makes non-vectorized expression type handling a bit more consistent across different types of expressions . major changes here include operator expressions will now try to preserve the type when one of the arguments is null instead of always producing double values , and math functions now follow logic similar to the operators . <nl> tagging pr as release notes/incompatible because the changes cause some expressions to output slightly different results ( typically longs instead of doubles ) . examples : <nl> instead of . <nl> and math functions will produce output from non-existent inputs in default mode",1602274011,"added endpoint . it returns a json map of the form , indicating whether the node has recieved a confirmation <nl> from the central node discovery mechanism ( currently zookeeper ) of the druid cluster that the node has been added to the <nl> cluster . it is recommended to not consider a druid node ' healthy ' or ' ready ' in automated deployment/container <nl> management systems until it returns from this endpoint . <nl> also added endpoint which does the same as but responses in the form of 0/0 return code depending on whether the node has discovered",0.9300737380981445
OpenAPITools_openapi-generator/7806,replace islistcontainer with isarray <cm-sep> update serviceformparams.mustache,- replace islistcontainer with isarray <nl> - reenable the test case .,1603678153,"this modifies the golang client to use the http constants for method types as defined by rfc 0 section version . these are documented on : . <nl> this does not require any new dependencies , as net/http is already imported .",0.8064089417457581
apache_kafka/9669,": prevent source task shutdown from blocking herder thread <para-sep> if we try to start the task at all by invoking initialize , then count this as ' started ' and expect a subsequent call to the task 's stop ( ) method to properly clean up any resources allocated by its initialize ( ) or start ( ) methods . if the task throws an exception during stop ( ) , the worst thing that happens is another exception gets logged for an already- failed task <nl> note that there is only ever at most one global block latch at a time , which makes tests that use blocks in multiple places impossible . if necessary , this can be addressed in the future by adding support for multiple block latches at a time , possibly identifiable by a connector/task id , the location of the expected block , or both . <nl> used to test blocks in connector ( as opposed to task ) methods <nl> no-args constructor required by the framework <nl> used to test blocks in sourcetask methods <nl> no-args constructor required by the framework <nl> no-args constructor required by the framework <nl> used to test blocks in sinktask methods <nl> no-args constructor required by the framework <nl> no-args constructor required by the framework","the functional changes are simple : change the class to only call from one location , during task shutdown , and only if an attempt has been made to start the task ( which will not be the case if it was created in the paused state and then shut down before being started ) . this is important in order to prevent from being indirectly invoked on the herder 's thread , which can have adverse effects if the task is unable to shut down promptly . <nl> the existing integration tests for blocking connectors are expanded to also",1606852795,subtask jira <nl> main changes of this pr <nl> * deprecate old consumer.internal.partitionassignor and add public consumer.consumerpartitionassignor with all ootb assignors migrated to new interface <nl> * refactor assignor 's assignment/subscription related classes for easier to evolve api <nl> * removed version number from classes as it is only needed for serialization/deserialization . <nl> other previously-discussed cleanup included in this pr : <nl> * remove assignment.error added in pt 0 <nl> * remove consumercoordinator # adjustassignment added in pt 0,0.9399517774581909
prestodb_presto/15348,refactor accesscontrolmanager to load properties map,- the default value for config is true . need to configure presto-on-spark after this is merged . <nl> - is removed .,1603474679,"* add support for 'insert into select ' <nl> * add support for ctas <nl> * add support for native batch ( parallel ) ingestion <nl> * ingest data from a local holder . <nl> ingest by ctas . <nl> ingest by insert : . <nl> or even more . <nl> limitation : <nl> currently only supports limited data types such as timestamp , varchar , bigint , double and float .",0.9275663495063782
apache_pulsar/9836,fix maven surefire default exclude . <nl> - fix : use single quotes for the exclude parameter <para-sep> * /adminapioffloadtest.java ' <nl> * /antiaffinitynamespacegrouptest.java ' <nl> * /simpleproducerconsumertest.java ' <nl> * /messagepublishbufferthrottletest.java ' \,this makes the test run skip most tests for the groups that use excludes . <nl> - fix : use single quotes for the exclude parameter in script,1615183786,"if writes to bk are failing we can not update the cursor . if the writes are failing because the disk is full , we have a circular problem , since we can not easily delete old data by moving the cursors forward . <nl> in case of bk write errors , try to update the cursor in zk as a fallback strategy . if that fails as well , give up .",0.8412718176841736
OpenAPITools_openapi-generator/7438,add gitignore template file <cm-sep> update samples <para-sep> .log <nl> .pid .seed <nl> .log <nl> .pid .seed,"hello there , . <nl> i added the already existing gitignore template to the javascript client generator , because it was missing : d .",1600328384,"this pr fixes a runtimeexception when the http signature parameters are not configured : . <nl> also , add some code comments .",0.7614473700523376
apache_ignite/8911,wip <cm-sep> data structures system views .,this pr contains new system views for a ignite data structures such as . <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> *,1616388810,provide the ability to manage the process from cli : . <nl> starts master key rotation . <nl> displays cluster 's current master key name .,0.9409559965133667
apache_flink/15050,introduce pluggable parser <para-sep> a parser that uses hive 's planner to parse a statement . * / <nl> * / <nl> hive dialect should use hiveparser <nl> execute some sql and verify the parser instance is reused <nl> switching dialect will result in a new parser <nl> * / <nl> this factory is used with java 's service provider interfaces ( spi ) for discovering . a factory is called with a set of normalized properties that describe the desired configuration . those properties may include table configurations like sql dialect .,"introduce pluggable and add simple implementation for hive . <nl> - add interface <nl> - add to create <nl> - create parser instance according to dialect in <nl> - do n't hold a constant parser instance in <nl> - add to create <nl> - add test case . <nl> existing and added test cases . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance",1614584132,"with this pr the can detect and reconcile deployments that are missing or unknown . <nl> the is periodically informing the about the set of deployed executions , submitted with the heartbeat . <nl> the tracks the set of expected deployments with a new component . the tracker is updated of deployed/terminated deployments by 0 new listeners in the . <nl> the reconciles deployments with a new component . <nl> if the is hosting an unexpected execution , then that execution will be canceled . <nl> if the is unexpectedly not hosting an execution , then the execution is failed",0.9639116525650024
elastic_elasticsearch/71057,"with shared cache searchable snapshots we have shards that have a size <nl> in s3 that differs from the locally occupied disk space . this commit <nl> introduces to node and indices stats , allowing to <nl> differ between the two . <para-sep> if this shard has no disk footprint then its local size is reported as 0","with shared cache searchable snapshots we have shards that have a size <nl> in s3 that differs from the locally occupied disk space . this commit <nl> introduces to node and indices stats , allowing to <nl> differ between the two .",1617111575,"today searchable snapshots implementations use the _blob store cache_ to cache the first bytes of every lucene files . after some experiments we think that we could adjust the length of the cached data depending of the lucene file that is read , caching up to 64kb for lucene _metadata_ files ( ie files that are fully read when a directory is opened ) and only 1kb for other files . <nl> the files that are cached up to 64kb are the files with the following extensions : . <nl> > ' cfe ' , // compound file 's entry",0.9603461027145386
apache_druid/10165,switch to apache version of ambari-metrics-common <para-sep> ignoring zk fallback .,prev version is available in only hortonworks repo . <nl> this pr upgrades to ambari-metrics-common version and also remove dependency on hortonworks repo,1594299558,"problem statement : need to get the topn page hit count from the set of filtered user accessed the page . <nl> solution : to solve this use case need to intersect two datasets , one with filtered data set and other topn page count . <nl> hence i will execute two queries , one with finalize = false and get the theta and pass the same as a constant to second query .",0.9582448601722717
ballerina-platform_ballerina-lang/26643,add context aware else and else if block suggestions,remove the pre declared langlib suggestions with auto import .,1603866880,therefore this pr remove this field from the codebase .,0.9651342034339905
elastic_elasticsearch/70647,"this pr moves field related rollup metadata from the index metadata to the field mapping metadata . <nl> - date_histogram fields is moved to the timestamp field <nl> ( fields are fixed_interval or calendar_interval , time_zone ) <nl> - histogram fields are moved to the numeric field on which the the histogram is computed <nl> ( the field is named interval ) . <nl> also , the index uuid has been added to the index rollup settings as index.rollup.source.uuid <nl> and index.rollup.source.name . <nl> the rest of the rollupmetadata has been removed and no rollup metadata exists in the global <nl> cluster state . <cm-sep> implemented changes to backport code <para-sep> add the source index name and uuid to the rollup index metadata . if the original index is a rollup index itself , we will add the name and uuid of the raw index that we initially rolled up . <nl> using the createindexrequest class only to produce the transformation to the mappings map . alternatively , we would have to copy-paste that part of the code . <nl> index created <nl> update rollup metadata to include this index <nl> if rolling up a backing index of a data stream , add rolled up index to backing data stream <nl> adding rollup indices to the beginning of the list will prevent rollup indices from ever being considered a write index <nl> use integers to ensure that avg is comparable between rollup and original <nl> assert rollup metadata are set in index settings <nl> assert field mappings <nl> assert that temporary index was removed","> this pr moves field related rollup metadata from the index metadata to the field mapping metadata . <nl> > <nl> > fields is moved to the timestamp field ( fields are or , ) <nl> > fields are moved to the numeric field on which the the histogram is computed ( the field is named interval ) <nl> > <nl> > also , the index uuid has been added to the index rollup settings as index.rollup.source.uuid and index.rollup.source.name <nl> > <nl> > the rest of the rollupmetadata has been removed . finally , no rollup metadata exists in the",1616424423,"this pr moves field related rollup metadata from the index metadata to the field mapping metadata . <nl> - fields is moved to the timestamp field ( fields are or , ) <nl> - fields are moved to the numeric field on which the the histogram is computed ( the field is named ) . <nl> also , the index uuid has been added to the index rollup settings as and . <nl> the rest of the has been removed . finally , no rollup metadata exists in the global cluster state",0.9978114366531372
grpc_grpc-java/7635,"added documentation for onclose hanging problem <para-sep> this method should not throw . if this method throws , there is no way to be notified of the exception . implementations should therefore be careful of exceptions which can accidentally leak resources .","if a clientinterceptor implementation throws from , the call will hang forever . this is a known issue , but issue appears unresolvable given the current api . so i 'm adding guidance here for implementing",1605664263,"the dns scheme is only the default scheme with grpc-java . other <nl> libraries could add more nameresolvers and thus change the default . for <nl> compatibility reasons , the schema should therefore be specified <nl> explicitly . <nl> the current javadocs conflict with those of , which allow setting a priority higher than dns . <nl> users of grpc-spring-boot-starter who want to use a service discovery have the problem that many libraries do n't provide a schema for dns addresses and therefore do n't work anymore without additional configuration .",0.9190858602523804
apache_flink/14634,"improve create hiveconf instance <para-sep> utils to create hiveconf , see for more information . * / <nl> create hiveconf instance via hadoop configuration . <nl> to make sure hive configuration properties in conf not be overridden <nl> * / <nl> will override configurations from with hive default values which default value is null or empty string","this pull request improves hiveconf creation . <nl> this change is already covered by existing tests , such as ( hivetablesourceitcase ) . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos ,",1610553307,"currently , format only support deserialization , but not support serialization , which is not convenient for users to writing changelogs to an message queue . the serialization for could follow the json strcuture of debezium , but should consider currently flink ca n't combine and into a single message . this could encode and as and debezium messages . therefore , this could support serialization for format . <nl> - add which serialization schema from flink table/sql internal data structure to debezium json . <nl> - supports with creating encodingformat for . <nl> - add test cases for to",0.9261660575866699
elastic_elasticsearch/71975,"this adds a bunch of javadocs for aggregation 's , mostly <nl> trying to say why you 'd use the things we already have . i 've tried to <nl> explain why you 'd use ' orindals ' for byte array valued fields . and to <nl> explain the tradeoffs between ' global ' and ' segment ' ordinals . <para-sep> second level subclasses are then specialized based on where they read values from , e.g . script or field cases . get a byte array like view into the values . get a ' has any values ' view into the values . aggregations that are aware of these lookup tables can operate directly on the value 's position in the table , know as the ' ordinal ' . each leaf may have a different ordinal for the same byte array . if you have to compare the ordinals of values from different segments then you 'd need to somehow merge them . <nl> get a ' global ' view into the leaf 's ordinals . they are ordinals into a lookup table containing all values on the shard . this makes comparing the values from different segments much simpler . but it comes with a fairly high memory cost and a substantial performance hit when this method is first called after modifying the index . if the global ordinals lookup has n't been built then this method 's runtime is roughly proportional to the number of distinct values on the field . if there are very few distinct values then the runtime 'll be dominated by factors related to the number of segments . but in that case it 'll be fast enough that you wo n't usually care . <nl> returns a mapping from segment ordinals to global ordinals . this allows you to post process segment ordinals into global ordinals which could save you a few lookups . also , operating on segment ordinals is likely to produce a more ' dense ' list of , say , counts . anyone looking to use this strategy rather than looking up on the fly should benchmark well and update this documentation with what they learn . <nl> get the maximum global ordinal . they 'll do normal ' number stuff ' to those values like add , multiply , and compare them to other numbers .","this adds a bunch of javadocs for aggregation 's , mostly <nl> trying to say why you 'd use the things we already have . i 've tried to <nl> explain why you 'd use ' orindals ' for byte array valued fields . and to <nl> explain the tradeoffs between ' global ' and ' segment ' ordinals .",1618942123,"this commit tightens certain dependency license checks in our build . <nl> firstly , the build will not fail if it can not accurately identify the <nl> type of license in one of our license.txt files . secondly , dependencies <nl> for licenses identified as requiring source redistribution will fail if <nl> a corresponding sources.txt file does not exist . this file should <nl> include a hyperlink to a source artifact for the given dependency to be <nl> used for redistribution during the release process . <nl> we also add source distribution urls ( if applicable ) to the generated",0.951647162437439
apache_druid/10642,handle null case <cm-sep> test this case,i 've added a check to see if the value for a field we 're returning is null . i 've considered the behaviour of this change in two cases : . <nl> in this pr the value returned from aggregation will get formatted as a timestamp . <nl> 0 ) : in this case the value will be null and we pass it along to the output instead of attempting to format it,1607143666,"in sql , postaggregations such as are missing in the query plan , thereby resulting in nulls . see the newly added unit tests in the patch for example queries .",0.8999220728874207
apache_pulsar/9061,make netty acceptor thread can config <cm-sep> make netty acceptor thread can config,"when the consumer application which serves ten thousands of consumers start , the default netty acceptor config opens slow . make the consumer bootstrap costs long time . <nl> make netty acceptor threads can config , so people can tuning . <nl> ( please pick either of the following options ) . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> ( or ) . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> ( or ) . <nl> this change added tests",1608886418,"currently the default ledger rollover size is hardcode to when initializing broker in . <nl> if the user sets in , then the setting value will be used .",0.935158371925354
elastic_elasticsearch/71179,handle all metadata fields in documentandfieldlevelsecuritytests . <nl> this change ensures that we do n't break the existing tests when adding <nl> a new metadata field in the distribution . we can not rely on the list of <nl> builtin metadata fields in an it tests that loads extra modules in x-pack . <para-sep> best effort to remove metadata fields,this change ensures that we do n't break the existing tests when adding <nl> a new metadata field in the distribution . we can not rely on the list of <nl> builtin metadata fields in an it tests that loads extra modules in x-pack .,1617279590,"if the constructor internalorder.compoundorder was called with an empty <nl> compoundorder , then comparator ( ) returned a comparator that would crash . <nl> ( an alternative fix could be to ensure that is always <nl> nonempty . however , checks such as ( orders.size ( ) > = 0 ) on line 0 and <nl> the lack of any comment to the contrary suggest that it might be better <nl> to have code that works in the empty case too . )",0.9007211923599243
elastic_elasticsearch/71134,make searchable snapshot cache size effectively zero on non-frozen nodes . <nl> this commits makes the shared_cache searchable snapshot cache size setting resolve to 0 for nodes <nl> that to do have the data_frozen node role .,this commits makes the shared_cache searchable snapshot cache size setting resolve to 0 for nodes <nl> that to do have the data_frozen node role .,1617212386,this setting was recently deprecated in favor of node.remote_cluster_client . this commit adds this setting to the deprecation info api .,0.9197835326194763
apache_incubator-pinot/5314,add a new best effort segment uploader with bounded upload time and default segment location when upload fails . <para-sep> a segment uploader which does segment upload to a segment store ( with store root dir configured as _segmentstoreuristr ) using pinotfs within a configurable timeout period . the final segment location would be in the uri _segmentstoreuristr/_tablenamewithtype/segmentname if successful . <nl> check and delete any existing segment file . <nl> make sure the sleep time > the timeout threshold of uploader .,add a segment uploader which does segment upload to a segment store ( with store root dir configured as _segmentstoreuristr ) using pinotfs within a configurable timeout period . it is designed to enable by-passing the deep store requirement in llc split commit . <nl> twig the segmentuploader interface to add table name and segment name . the reason is to make the pinotfssegmentuploader as a singleton for sharing in a pinot server .,1588094883,this pr will handle remove the restriction that table names and column names in the query must match what is defined in tableconfig and schema . <nl> the idea is to fix the broker request object in the beginning so that the rest of the code does not require any change .,0.9858428835868835
apache_shardingsphere/9469,merge untracked file <cm-sep> simplify test class constructors <nl> tuning an embedded database singleton instance <nl> add case run time policy <nl> lazy load case executors <para-sep> case runtime parallel level . <nl> case runtime strategy . <nl> set/get parallel level . <nl> it parameterized . <nl> checkstyle : off <nl> checkstyle : on <nl> runner executor key . <nl> scenario key . <nl> scenario executor queue . <nl> get database port .,changes proposed in this pull request : <nl> - simplify test class constructors <nl> - tuning an embedded database singleton instance <nl> - add case run time policy <nl> - lazy load case executors,1613979858,add data consistency check function .,0.9745867252349854
vespa-engine_vespa/16248,reduce log entry queue size <cm-sep> create symbolic link using files api instead of 'ln ' <cm-sep> simplify unit tests,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1611744401,last commit is the interesting one .,0.933174192905426
grpc_grpc-java/7271,add server features support to bootstrapper,in preparation for xds-v3 support .,1596144777,"when deadline expires , both the client and the server try to cancel the stream . there is a race between server receiving the cancellation from the client and the server cancelling the stream , which changes the final status of the stream from the server 's perspective . if the former wins , server sees cancelled . if the latter wins , server sees deadline_exceeded . <nl> because does n't pass the final status to the server-side application , this ambiguity is n't a problem in most cases . however , the status is passed to , and thus",0.9602319002151489
ballerina-platform_ballerina-lang/25732,"fix do-stmt and on-fail-clause error recovery <cm-sep> add on-fail-clause recovery test cases <cm-sep> fix merging issues <para-sep> fail-stmt : = fail expression ; <nl> lock-stmt : = lock block-stmt <nl> transaction-stmt : = block-stmt <nl> retry-stmt : = retry-spec block-stmt retry-spec : = [ arg-list ] context is closed inside the the method . <nl> parse optional on fail clause . <nl> statements starts other than var-decl <nl> action-statements <nl> even-though worker is not a statement , we parse it as statements . then validates it based on the context . this is done to provide better error messages <nl> var-decl-stmt start <nl> expression-stmt start <nl> parse on fail clause . on-fail-clause : = on fail typed-binding-pattern statement-block <nl> valid source test recovery source test <nl> recovery test",- fix do-stmt recovery <nl> - implement on-fail-clause recovery rules <nl> - add test cases for on-fail-clause recovery <nl> - remove optional limit-clause of query-action in error handler .,1599804372,additionally this will add worker formatting and assignment formatting for record literals and add fixes went only with next-release branch,0.969688892364502
OpenAPITools_openapi-generator/7808,"rename bigdecimal to decimal <cm-sep> add isdecimal <cm-sep> fix tests <para-sep> check if any validation rule defined exclusive * are noop without corresponding min/max <nl> enum case : $ ref case : decimal ( type : string , format : decimal ) <nl> decimal | decimal * | | / _decimal . <nl> / gets or sets decimal / <nl> / <nl> decimal | decimal * | | / _decimal . <nl> / gets or sets decimal / <nl> / <nl> decimal | decimal * | | / _decimal . <nl> / gets or sets decimal / <nl> / <nl> decimal | decimal * | | / _decimal . <nl> / gets or sets decimal / <nl> / <nl> decimal | number * | |","add ' decimal ' ( type : string , format : number ) support .",1603709166,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) . <nl> the problem : <nl> api generation for c # , java and ruby creates a class based on the tag and then adds ' api ' after it . <nl> ideally though we have a class like ' study ' or ' study { { suffix } } ' not ' studyapi ' . <nl> i introduced a apinamesuffix parameter in order to add suffixes to the generated api class/file/document names . added the option '",0.9255998730659485
confluentinc_ksql/6145,"avoid noise in apitest . <nl> tests derived from can generate multiple exceptions in the logs unnecessarily , making it harder to debug issues , because they attempt to close and multiple times . this change resolves this .","tests derived from can generate multiple exceptions in the logs unnecessarily , making it harder to debug issues , because they attempt to close and multiple times . this change resolves this . <nl> additionally , our test logs are full of log lines about unknown configs being passed to classes . this warning can be safely ignored ( and is ) , so we should n't need to see it in the logs . <nl> usual .",1599083029,previously there was no back pressure on writes from the legacy streaming api to the response . this could mean that writes buffered in memory if the client was slow which could lead to unbounded memory usage . <nl> this pr blocks the writer thread if the response is full and unblocks it when it is drained to provide some synchronous back pressure to the caller . <nl> manually tested .,0.8117982745170593
apache_druid/10544,"honor zk enablement config in more places in druid code <para-sep> annotation for suppressing spotbugs checks when necessary . <nl> the set of findbugs warnings that are to be suppressed in annotated element . the value can be a bug category , kind or pattern . <nl> optional documentation of the reason why the warning is suppressed <nl> k8s no longer has history that we need <nl> interface to abstract pod read/update with k8s api server to allow unit tests with mock impl .","this patch has been tested to successfully run a small druid test cluster with k8s and without zookeeper . <nl> most of the code introduced here goes in a new extension . at a high level , it introduces a new druid kubernetes extension that implements 0 druid discovery and leader election related interfaces ... ' druidnodediscoveryprovider ' , ' druidleaderselector ' , ' druidnodeannouncer ' and provides necessary plumbing to use those when configured . <nl> see for how to use it . it can support multiple druid clusters running on same k8s cluster [ in same namespace ]",1604077332,"the config is an option to specify classes of user/role managers , caches and notifiers . <nl> if a config field is specified then the corresponding class is instantiated regardless of what type of druid component runs it .",0.98307865858078
apache_camel/5350,": kamelet eip <cm-sep> : kamelet eip <cm-sep> : kamelet eip <cm-sep> : kamelet eip <para-sep> lookup the route template with the given id ( i.e . foo ) from the camel context create a new route based on the route template <nl> eip options : start <nl> eip options : end <nl> * xref : eips : kamelet-eip.adoc <nl> there must be at least one sink <nl> active kamelet eips <nl> kamelet eip implementation . <nl> we use the kamelet component ( producer ) to call the kamelet and to receive the reply we register ourselves to the kamelet component with our child processor it should call <nl> the kamelet producer has multiple purposes at this point it is capable of linking the kamelet component with the kamelet eip to ensure the eip and the component are wired together with their kamelet : source and kamelet : sink endpoints so when calling the sink then we continue processing the eip child processors <nl> if no eip is in use , then its _just_ a regular camel component with producer and consumers linked together via the component <nl> when calling a kamelet : sink then lookup any waiting processor from the kamelet eip to continue routing <nl> if the current route is from a kamelet source then we should break out as otherwise we would end up calling ourselves again <nl> kamelet producer that calls its kamelet consumer to process the incoming exchange <nl> * * * test set-up * * * <nl> this is not possible , you must use kamelet eip instead <nl> * * * test set-up * * * <nl> * * * test set-up * * * <nl> * * * test set-up * * * <nl> to call kamelets to call kamelets to call kamelets <nl> * xref : eips : kamelet-eip.adoc <nl> lookup the route template with the given id ( i.e . foo ) from the camel context create a new route based on the route template <nl> eip options : start <nl> eip options : end <nl> to call kamelets <nl> name of the kamelet ( templateid/routeid ) to call . options for the kamelet can be specified using uri syntax , eg myname ? count=0 & type=gold . <nl> creates a kamelet eip . this requires having camel-kamelet on the classpath . <nl> to call kamelets to call kamelets to","with the kamelet eip you can now do the aggregate example . <nl> however to do this without the eip its harder - even if we try to do this correlation thingy . however i may go back and try that too . <nl> but with the eip we can better illustrate in the flow , that the output from the kamelet is the sub-flow . this means you can do the 0 - > 0 message example with the aggregator .",1618314981,: camel-main - add logic for automatic routebuilder class detection ala camel-spring-boot has,0.9781912565231323
vespa-engine_vespa/15565,"move code in clustercontroller-apputils into clustercontroller-apps . <nl> code in clustercontroller-apputils is now only used from clustercontroller-apps , <nl> so those two modules can be merged <para-sep> note . this class is tested through apache http instance test , using this as other endpoint . <nl> the handler is mostly tested through the apache tests , using it as endpoint here .. this test class is just to test some special cases .","code in clustercontroller-apputils is now only used from clustercontroller-apps , <nl> so those two modules can be merged .",1606828465,reapply with zookeeper-server as a preinstalled bundle,0.9095020294189453
vespa-engine_vespa/15207,rewrite configconvergencechecker to use apache instead of jersey client . <nl> the effective exception handling for some confiserver apis may have changed as webapplicationexception leaked out with old jersey-based implementation . <nl> connections will now be reused for a short duration . <cm-sep> do n't use private inner class in return type of public methods <cm-sep> deprecate vespaclientbuilderfactory + vespajerseyjaxrsclientfactory,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1604659494,"disables secret-agent , core-dump reporting and storage maintenance in local zone test .",0.9721859097480774
confluentinc_ksql/6270,"format interface . <nl> in prep for user-defined-formats and just to tidy up the interface and fix some bugs .. . <nl> refactored the interface so that the functions used during schema inference , i.e . and , are moved onto a new interface . the is obtained from the by calling , passing in the format properties . <nl> this removes the strange requirement of having to pass a , which contains the name of the format , to the method . <nl> and ensures consistent properties are used for both and . ( though at the moment properties are only needed in , that may not be the case once user-definfed-formats are supported . <nl> for example , if was , but the schema returned by the schema registry was , then the statement would succeed ... and would later generate lots of deserialisation errors if used . the statement will now fail . <cm-sep> move avro specific constants into avro package <cm-sep> switch schema inference to a serdefeature <para-sep> the format supports interaction with the confluent schema registry . indicates whether or not a format can support create statements that omit the table elements and instead determine the schema from a confluent schema registry query .","in prep for user-defined-formats and just to tidy up the interface and fix some bugs while i had a spare moment .. . <nl> refactored the interface so that the functions used during schema inference , i.e . and , are moved onto a new interface . the is obtained from the by calling , passing in the format properties . <nl> this removes the strange requirement of having to pass a , which contains the name of the format , to the method . <nl> and ensures consistent properties are used for both and . ( though at the",1600789773,"a couple of the implementations have a field that has a non- sql type , but the sql type of was still . <nl> this is not incorrect : the with-key field must have the same sql type as the actual key , i.e . <nl> this change fixes the s and any associated tests . it also refactors the providers and the code tests use to produce and consume messages to clean this up and remove duplicate functionality . <nl> unit and integration tests are expected for any behavior changes._ .",0.9808952212333679
vespa-engine_vespa/15812,"stop depending on zookeeperprovider . <nl> vespazookeeperserver is enough , zookeeperprovider is just an <nl> unnecessary extra layer . in addition neither provides any guarantee <nl> that the the server has started and is working . clustercontroller has <nl> code that verifies that connecting to zookeeper works , that should <nl> be sufficient .","vespazookeeperserver is enough , zookeeperprovider is just an <nl> unnecessary extra layer . in addition neither provides any guarantee <nl> that the the server has started and is working . clustercontroller has <nl> code that verifies that connecting to zookeeper works , that should <nl> be sufficient . <nl> please review only",1608020444,"added a object structure for groupingrequest objects , accessable from query.getselect ( ) .getgrouping ( ) . i believe i have done what you described .",0.9259734749794006
confluentinc_ksql/6397,recovery hangs when using terminate all,"this pr now properly handles . i checked to see if i could do this without ' hacking ' the fact that the is but it would require parsing the statement , which would require quite a few changes ( like passing the engine into the compactor , which does n't sound right ) . anything else ( changing the ) is not backwards compatible . <nl> unit test .",1602264617,adds a flag to make sure that allows servers to disable ad-hoc pull queries . <nl> - unit testing <nl> - e2e testing : .,0.8852403163909912
Graylog2_graylog2-server/9886,adding test cases for bug . <cm-sep> adjusting regex for query string parser .,"before this change , a user could write or generate a query string that contains two characters in unrelated places ( e.g . because a field name or value contains it ) , leading to an undeclared parameter being incorrectly identified . an example for this is a query string of . <nl> this pr is fixing the regex used to identify parameters in query strings . the regex is now checking for two enclosing a group of alphanumerical ( , , & ) characters instead of a group of _any_ characters . this also matches the description in the",1610448329,"this commit adds a factory method to which can be used by jackson to deserialize an instance of from json . <nl> additionally , the derived field ' empty ' ( via ) is being ignored and thus not part of the serialized or deserialized representation of .",0.8348250389099121
runelite_runelite/11993,add identification option for tablets <para-sep> tablets,"based on a request from discord , adds item identification for all tablets ( i.e. , teleports , enchants , bones to peaches , etc . )",1593200896,"the itemidentification plugin supports items that are hard to tell apart , such as seeds and herbs . i 've added potions as well , since many potions are difficult to tell apart for colorblind individuals . <nl> i 've added short and medium identification to all of the most commonly commonly used potions and all unfinished potions . i have not added identification to skill potions , barbarian mixes , or some one-off potions like blamish oil . although adding them later would be trivial . <nl> potions ( normal vision ) . <nl> potions ( deuteranopia vision )",0.9737313985824585
apache_beam/12720,"linked schemaioprovider development guide in javadoc <para-sep> for a detailed walkthrough of implementation , see s.apache.org/schemaio-development-guide for a detailed walkthrough of implementation , see s.apache.org/schemaio-development-guide","linked schemaioprovider development guide in javadoc . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1598641424,"these are very minor edits to the documentation , to the pcollection javadoc and the java examples . in pcollection , there 's a javadoc link to a nonexistent method , and in the java word count examples , the code and comments disagree , and javadoc conventions are not followed .",0.8629911541938782
apache_druid/10430,"add specialized index types for long keys . <nl> two new index types are added : . <nl> 0 ) use an int-array-based index in cases where the difference between <nl> the min and max values is n't too large , and keys are unique . <nl> 0 ) use a long2objectopenhashmap ( instead of the prior java hashmap ) in <nl> all other cases . <nl> in addition : . <nl> 0 ) rowbasedindexbuilder , a new class , is responsible for picking which <nl> index implementation to use . <nl> 0 ) the indexedtable.index interface is extended to support using <nl> unboxed primitives in the unique-long-keys case , and callers are <nl> updated to use the new functionality . <nl> other key types continue to use indexes backed by java hashmaps . <para-sep> initialize keycolumn index builders <nl> returns the natural key type for the index . <nl> returns whether keys are unique in this index . <nl> returns the list of row numbers corresponding to ' key ' in this index . <nl> only used by ' matchcondition ' , and only in the multi-row-matching case . <nl> returns an iterator for the row numbers that match the current cursor position . <nl> creates a new instance based on a particular map . <nl> its main role is to decide which kind of implementation to use . <nl> long2objectopenhashmap is ( very ) roughly 15x bigger than int [ ] per entry . <nl> a number that is small enough that we should n't worry about making a full array for it . ( yields a 1mb array . ) <nl> we 're specializing the type even though we do n't specialize usage in this class , for two reasons : ( 0 ) it 's still useful to reduce overall memory footprint . ( 0 ) mapindex specifically checks for long2objectmap instances and does specialize usage . <nl> add a key to the index . this must be called exactly once per row , even for null values or values that are the wrong type , because the builder keeps an internal row-number counter . the builder will handle both nulls and mismatched types , so callers do not need to worry about this . <nl> track min , max long value so we can decide later on if it 's appropriate to use an array-backed","two new index types are added : . <nl> 0 ) use an int-array-based index in cases where the difference between <nl> the min and max values is n't too large , and keys are unique . <nl> 0 ) use a long2objectopenhashmap ( instead of the prior java hashmap ) in <nl> all other cases . <nl> in addition : . <nl> 0 ) rowbasedindexbuilder , a new class , is responsible for picking which <nl> index implementation to use . <nl> 0 ) the indexedtable.index interface is extended to support using <nl> unboxed primitives in the unique-long-keys case",1600902038,this pr modifies the input sources to skip empty files except for the http input source . this pr additionally fixes the two bugs :,0.9782721400260925
hazelcast_hazelcast/18128,"wip <cm-sep> clean closed cursors on timeout . <para-sep> send ' close ' <nl> make sure that we observed the cancel request . <nl> wait for it to disappear . <nl> close cursors that were opened by disconnected clients . <nl> close cursors created for the ' cancel ' operation , that are too old . this is needed to avoid a race condition between the query cancellation on a client and the query completion on a server . <nl> for testing only .","note that eventually , we will allow for the async execution , therefore all the infrastructure is left intact . i only added the to make the call synchronous . <nl> 0. fixed a bug when we do not close the server-side if the query is already canceled by the client . <nl> 0. fixed a race when the client request may arrive after the server-side cursor had been closed , causing a slow memory leak . now , we clear the canceled cursors once in 0 seconds ( this should be sufficient for a concurrent to arrive ) .",1612262214,a new test is added as well .,0.9388245940208435
elastic_elasticsearch/71391,"include node roles in cluster state json response . <nl> today the response to does not include the roles of <nl> the nodes in the cluster . in the past this made sense , roles were <nl> relatively unchanging things that could be determined from elsewhere . <nl> these days we have an increasingly rich collection of roles , with <nl> nontrivial bwc implications , so it is important for debugging to be able <nl> to see the specific roles as viewed by the master . this commit adds the <nl> role names to the cluster state api output . <para-sep> testresponse [ s/ ' roles ' : \ [ [ ^ ] ] * \ ] / ' roles ' : $ body. $ _path/ ]","today the response to does not include the roles of <nl> the nodes in the cluster . in the past this made sense , roles were <nl> relatively unchanging things that could be determined from elsewhere . <nl> these days we have an increasingly rich collection of roles , with <nl> nontrivial bwc implications , so it is important for debugging to be able <nl> to see the specific roles as viewed by the master . this commit adds the <nl> role names to the cluster state api output .",1617789171,report anonymous roles in response to ' get _security/_authenticate ' api call when : . <nl> * anonymous role is enabled <nl> * user is not the anonymous user <nl> * credentials is not an api key,0.9562650918960571
ballerina-platform_ballerina-lang/23511,"unify assert file formatting <cm-sep> add typed-binding patterns to var-decl <cm-sep> add typed-binding-pattern support for var-decl <cm-sep> update foreach with new typed-binding-impl <cm-sep> cleanup unused methods <cm-sep> add typed binding patterns for var-decl test <cm-sep> update nodelistapitest <para-sep> parse the component after the type-desc , of a typed-binding-pattern . <nl> t [ .. ] .. <nl> if the parser recovered by inserting a token , then try to re-parse the same rule with the inserted token . this is done to pick the correct branch to continue the parsing . <nl> parse typed-binding pattern with list , array-type-desc , or member-access-expr . <nl> if the bracketed list is empty , i.e : t [ ] then t is an array-type-desc , and [ ] could be anything . <nl> parse first member <nl> if the member type was figured out as a binding pattern , then parse the remaining members as binding patterns and be done with it . <nl> ideally we would reach here , only if the parsed member was a name-reference . i.e : t [ a <nl> parse separator <nl> if there are more than one member , then its definitely a binding pattern . <nl> we reach here if it is still ambiguous , even after parsing the full list . that is : t [ a ] . this could be : 0 ) array type desc 0 ) member access on lhs 0 ) typed-binding-pattern <nl> parse a member of an ambiguous bracketed list . this member could be : 0 ) array length 0 ) key expression of a member-access-expr 0 ) a member-binding pattern of a list-binding-pattern . <nl> case open_brace_token : // mapping-binding-pattern <nl> error|t ( args ) -- > functional-binding-pattern <nl> if the parser recovered by inserting a token , then try to re-parse the same rule with the inserted token . this is done to pick the correct branch to continue the parsing . <nl> error|t ( args ) -- > functional-binding-pattern <nl> we do n't know which one <nl> treat the current node as an array , and parse the remainder of the binding pattern . <nl> in ambiguous scenarios typdesc : t [ a ] may have parsed as an indexed expression . therefore make an array-type-desc out of it . <nl> if the parser recovered by inserting a token , then try to re-parse the","$ subject . <nl> supports capture binding pattern , wildcard binding pattern , and list binding pattern .",1590494182,this pr is to support passing custom headers with grpc message and handle in both client and server side . following changes are done to support custom headers . following will be supported from this fix . <nl> server side header support <nl> ` . <nl> client side header support <nl> `,0.9892762899398804
neo4j_neo4j/10984,"removed the cipher filter enforced by new jetty version . <nl> if a user configures cipher suites and protocols via configuration ssl policy , then jetty server should pick up whatever the user configured . <cm-sep> enforce tlsv1.0 by default both for https server and bolt server . <nl> for users who would like to have other protocols or cipher suites , they need to migrate their old configuration to use new <nl> for users whose jdk does not have tlsv1.0 enabled by default such as ibm-jdk8 , if they would like to use tlsv1.0 , they should run the server with jvm option","https server and bolt server use legacy ssl policy . this policy does not expose any configuration option for allowed security protocols or cipher suites . as a result , the rest and bolt server were running with protocol and cipher suites provided by jvm by default . however to provide more secured neo4j service , from this version , we will enforce tlsv1.0 as default for legacy ssl policy . <nl> for users who would like to have their own customized protocols or cipher suites , they could migrate their ssl policy for bolt and https to new to",1518105910,- an issue with store file locks not getting released when shutting down sometimes . <nl> - fixes a wait issue where a join of a cluster could end up waiting indefinitely .,0.9269447326660156
jenkinsci_jenkins/4655,limit the number of exceptions stored by compositeioexception <para-sep> the number of exceptions is limited to avoid pathological cases where a huge number of exceptions could lead to excessive memory usage .,"this pr truncates the list of exceptions passed to to only contain the first 0 exceptions . i expect that the only callers of that will be affected by this limit in practice are and , but could potentially run into this issue as well , so i thought it made sense to perform the truncation in itself . 0 was my rough guess for the point where additional exceptions are probably going to contain mostly redundant information . right now , this value is not configurable by users , but i am happy to make it configurable as a",1586901235,"during plugin installs , particularly noticed when upgrading to jenkins 0 , required dependencies which are disabled are left as such , causing issues running newly installed plugins or worse .",0.9520278573036194
apache_kafka/9776,testreadwhenoptionaldatamissingattheendisnottolerated/testreadwithmissingnonoptionalextradataattheend should check the error message,use assert to check failed message . <nl> - testreadwhenoptionaldatamissingattheendisnottolerated <nl> - testreadwithmissingnonoptionalextradataattheend,1608617447,"reading the configuration field names from producerconfig class and taking the key and value serializer names from class name directly instead of hardcoding . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger",0.8049437999725342
quarkusio_quarkus/15067,delay the executor shutdown . <nl> the executor should be one of the last <nl> services to be shutdown . <cm-sep> do n't lookup the request context each time . <nl> this improves performance and avoid issues <nl> during shutdown after the container has been <nl> shutdown .,also includes a fix for a shutdown problem if anything with context propagation is still running after the container is shutdown .,1613366628,"some typos , and reduce logging .",0.7973539233207703
apache_kafka/9785,migrate log4j-appender module to junit 0,migrate log4j-appender module to junit 0,1608794034,"in the unit test for jdk 0 , we spotted a case where a global stream thread startup would stall if it fails immediately upon the first poll . the reason is that function only checks whether the thread is not running , as it needs to block until it finishes the initialization . however , if the thread transits to immediately , the call would block forever . <nl> use the failed unit test to verify it works .",0.8826934695243835
ballerina-platform_ballerina-lang/24101,fixed onerror listener request flow in client and bidi streaming <para-sep> extract the response status from trailers .,this fix contains server-side changes to catch client errors and dispatch to the onerror function .,1592130863,"need to revisit test cases after h2 , sql packages are working .",0.9100921154022217
confluentinc_ksql/6250,"force unwrap_single_keys serde option . <nl> for the serde option to be included for new plans where the key format supports both wrapping and unwrapping , as we 're only writing unwrapped single key columns at the moment . this should hopefully stop us painting ourselves into a corner . <para-sep> when : <nl> then : <nl> given : <nl> when : <nl> then :","for the serde option to be included for new plans where the key format supports both wrapping and unwrapping , as we 're only writing unwrapped single key columns at the moment . this should hopefully stop us painting ourselves into a corner . <nl> usual .",1600375759,"the exception is thrown when shutting down the command runner because the command runner thread is still active and can be using the consumer . attempting to / the consumer results in a concurrent mod exception if it is being used from the command runner thread . <nl> reviewing notes : . <nl> - the command runner thread is now managed by the command runner , so that it can ensure things shutdown in the right order to avoid concurrent mod exceptions . <nl> - to allow things to shutdown i 've changed the to take a timeout . this",0.9740829467773438
Alluxio_alluxio/10935,close previous input stream before opening the next one when compacting files,previous implementation of compactdefinition opened an arbitrary number of input files to be fed through the sequentialcompactor . this is very wasteful because only one input file needs to be open at a time to compact files sequentially .,1582063943,"the fault-tolerance related tests leak tons of threads when they kill the test alluxio cluster to see what happens . this destabilizes the rest of the build . <nl> after ignoring these two tests , the time it took to run the integration tests locally for me went from 0:0 to 0:0 , and the number of threads existing at the end of the last integration test went from 0 to 0 .",0.9160923957824707
vespa-engine_vespa/15800,refactor code and document code to verify that zookeeper is working <para-sep> block until we are connected to zookeeper server,"based on non-working system tests when removing this code , document why it is needed/useful . <nl> also add annotation for unused constructor and a non-functional change in",1607933277,"i think the second commit here should get out quickly , and the first will let us spot problematic zone-application nodes earlier .",0.886668860912323
Alluxio_alluxio/11764,fix issue where a custom property key containing awsaccesskey is not displayed as credential <cm-sep> tests <para-sep> check reference equality,we occasionally create custom property keys containing strings like ' accesskeyid ' or ' secretkey ' ( or other combinations ) that should be treated as displaytype credentials and thus not be sent back to the client .,1594698532,"in the getdirectorystatus javadoc : <nl> - if a path is a file , this method should throw an exception . <nl> in the getfilestatus javadoc : <nl> - if a path is a directory , this method should throw an <nl> exception . <nl> unit tests added for behavior verification .",0.9171214699745178
elastic_elasticsearch/70932,"first cut at deprecation warning for changed default <cm-sep> simplify deprecation warning <para-sep> test that we get a deprecation warning if we try a wildcard deletion and action.destructive_requires_name is unset . <nl> no warning <nl> test that applying settings enables and disables the deprecation warning . <nl> empty settings gives us a warning <nl> setting to ' true ' removes the deprecation warning and fails the operation <nl> restoring the empty setting restores the warning <nl> explicitly set to false : no warning , no failure","we 're not deprecating the setting as a whole , just the old default value , but since we do n't want anyone to be caught by surprise with this change , it seems appropriate to use the deprecation logger .",1616785942,"today , a follow task will fail if the master node of the follower cluster is temporarily overloaded and unable to process master node requests ( such as update mapping , setting , or alias ) from a follow-task within the default timeout . this error is transient , and follow-tasks should not abort . we can avoid this problem by setting the timeout of master node requests on the follower cluster to unbounded .",0.9381482005119324
apache_incubator-pinot/5966,"validate timecolumnname when adding/updating schema/tableconfig <para-sep> find schema with same name as rawtablename . if not found , find schema using schemaname in validationconfig . for offline table , it is possible that schema was not uploaded before creating the table . hence for offline , this method can return null . <nl> get all tableconfigs ( offline and realtime ) using this schema . if tables have not been created , this will return empty list . if table config raw name does n't match schema , they will not be fetched . <nl> validates the schema . first checks that the schema is compatible with any provided table configs associated with it . <nl> validates that the schema is compatible with the given table config <nl> todo : add more validations for each section ( e.g . verify column names used in the indexing , validate conditions are met for aggregatemetrics etc ) <nl> validates the following in the validationconfig of the table 0. for realtime table - checks for non-null timecolumnname - checks for valid field spec for timecolumnname in schema 0. for offline table - checks for valid field spec for timecolumnname in schema , if timecolumnname and schema re non-null 0. checks peerdownloadschema <nl> for realtime table , must have a non-null timecolumnname <nl> timecolumnname can be null in offline table <nl> filter config <nl> transform configs <nl> empty list <nl> offline table null timecolumnname <nl> schema does n't have timecolumnname <nl> expected <nl> schema does n't have timecolumnname as time spec <nl> expected <nl> schema has timecolumnname <nl> schema does n't have destination columns from transformconfigs <nl> expected <nl> realtime table schema does n't have timecolumnname <nl> expected <nl> schema does n't have timecolumnname as time spec <nl> expected <nl> schema has timecolumnname <nl> schema does n't have destination columns from transformconfigs <nl> expected <nl> realtime table <nl> null timecolumnname and schema <nl> expected <nl> null schema only <nl> expected <nl> null timecolumnname only <nl> expected <nl> timecolumnname not present in schema <nl> expected <nl> timecolumnname not present as valid time spec schema <nl> expected <nl> valid <nl> offline table null timecolumnname and schema - allowed in offline <nl> null schema only - allowed in offline <nl> null timecolumnname only - allowed in offline <nl> non-null schema and timecolumnname , but timecolumnname not present in schema <nl> expected <nl> non-null schema nd timecolumnname ,","cases <nl> - adding/updating tableconfig - find associated schema ( using rawtablename or from validationconfig.getschemaname ) . check that timecolumnname is present in schema . for offline , it is possible that timecolumnname/schema is null . <nl> - adding/updating schema - find associated table configs ( schemaname_offline and schemaname_realtime ) check timecolumnname used in all associated tableconfigs also exists in schema . <nl> corner case <nl> if tableconfig has been created with a schemaname ! = rawtablename , then we will not be able to validate during schema add/upload .",1599101344,reusing the code path from offline side entirely,0.9607208967208862
pentaho_pentaho-kettle/7508,fixed issue with creating report using streaming html output and updated copyright data . <nl> this commit is a cherry-pick from master sha,fixed issue with creating report using streaming html output and updated copyright data . <nl> this commit is a cherry-pick from master sha,1593199397,new implementation of and for apache vfs 's would load resource of type .,0.8546914458274841
apache_druid/10351,"fix incorrect ' combine ' method . <nl> there was a test , but it was wrong .","there was a test , but it was wrong .",1599170775,"should be immutable , but is exposed by and can be modified .",0.9163956046104431
apache_beam/13598,update testpubsubsignal to use gcp client <cm-sep> minor cleanup in testpubsub <para-sep> set this after successful creation ; it signals that the topic needs teardown <nl> ignore empty messages,"see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1608670737,"more improvements for samzarunner : . <nl> - life cycle methods for the pipeline runtime <nl> - hook up samza externalcontext for linkediin use cases <nl> - support metrics reporters in pipeline options <nl> - some bug fixes for the state key in samza . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9448888301849365
vespa-engine_vespa/16842,"better handling of zk connectivity issues concurrent with elections . <nl> adds the following safeguards/improvements : <nl> - do not clear pending ( non-persisted ) writes over a edge . <nl> avoids having the controller eternally wait for a doomed pending <nl> write to be completed when it has no other events that can trigger <nl> a new write . <nl> - trigger whenever zk is reconfigured to <nl> ensure we reload the newest state before trying to compute/publish <nl> any new states . <nl> - explicitly drop leadership in to immediately <nl> prevent controller from trying any funny leader-related business <nl> since it no longer can depend on zk watches triggering . <nl> - when falling back to default state/cluster bundle , ensure that any <nl> subsequent dependent znode write is predicated on the pre-existing <nl> znode version being 0 , i.e . did not previously exist . <para-sep> enforce that we re-fetch all state information from zookeeper upon the next tick if we 're still master . <nl> todo : require non-null , not possible now since at least clusterfeedblocktest uses null address <nl> if we have pending cluster state writes we can not drop these on the floor , as otherwise the core cc logic may keep thinking it has persisted writes it really has not . clearing pending state writes would also prevent the controller from detecting itself being out of sync by triggering cas violations upon znode writes . <nl> do n't clear pending state writes in case they were attempted prior to connect ( ) being called , but after receiving a database loss event . <nl> reset ( ) will handle both session clearing and trigger a database loss callback into the cc . <nl> if we return a default , empty version , writes dependent on this bundle should only succeed if the previous znode version is 0 , i.e . not yet created . <nl> if we return a default , empty bundle , writes dependent on this bundle should only succeed if the previous znode version is 0 , i.e . not yet created .",these are predominantly racing edge cases dependent on zk behavior and therefore tricky to test explicitly . <nl> adds the following safeguards/improvements : <nl> - do not clear pending ( non-persisted ) writes over a edge . <nl> avoids having the controller eternally wait for a doomed pending <nl> write to be completed when it has no other events that can trigger <nl> a new write . <nl> - trigger whenever zk is reconfigured to <nl> ensure we reload the newest state before trying to compute/publish <nl> any new states . <nl> - explicitly drop leadership in to immediately <nl>,1615213200,the load balancer hostname is not distinct in the shared routing layer and this <nl> prevented removal of routing policies for removed clusters .,0.9348902702331543
apache_incubator-pinot/6038,"adding dependency validation check between inverted index , bloom filter and no dictionary column config <para-sep> ensures that every referred column name exists in the corresponding schema . also ensures proper dependency between index types ( eg : inverted index columns can not be present in no-dictionary columns ) . <nl> expected <nl> expected",no <nl> no . <nl> no .,1600492160,"we are working on re-design the alert pipeline , removing the notified flag from anomaly results . one problem is that we need to distinguish anomalies from scheduled detection from others . users are not expect to receive any backfill anomalies in their alerts . to achieve that , a label should be applied to distinguish the difference . <nl> - add anomalyresultsource to distinguish the default anomaly detection from others . <nl> - update the anomaly result source in detection task runner",0.9066615700721741
elastic_elasticsearch/72129,add enroll node api . <nl> enroll node api can be used by new nodes in order to join an <nl> existing cluster that has security features enabled . the response <nl> of a call to this api contains all the necessary information that <nl> the new node requires in order to configure itself and bootstrap <nl> trust with the existing cluster . <cm-sep> fix doc reference <para-sep> allows a node to join to a cluster with security features enabled using the enroll node api . <nl> asynchronously allows a node to join to a cluster with security features enabled using the enroll node api . <nl> retrieves information needed about configuration so that new node can join a secured cluster <nl> tag : :node-enrollment-execute <nl> end : :node-enrollment-execute <nl> tag : :node-enrollment-response <nl> end : :node-enrollment-response <nl> tag : :node-enrollment-execute-listener <nl> end : :node-enrollment-execute-listener <nl> tag : :node-enrollment-execute-async <nl> end : :node-enrollment-execute-async <nl> > <nl> you must have the > to use this api . <nl> test [ skip : determine behavior for keystore with multiple keys ],enroll node api can be used by new nodes in order to join an <nl> existing cluster that has security features enabled . the response <nl> of a call to this api contains all the necessary information that <nl> the new node requires in order to configure itself and bootstrap <nl> trust with the existing cluster .,1619118510,"this commit introduces the which <nl> restricts allocation of partial shards only to those nodes with a <nl> configured shared cache , and also the which <nl> tracks which nodes do/do n't have a frozen cache configured .",0.9884103536605835
confluentinc_ksql/6365,"capture key and value formats as part of . <nl> when building a query , the captures the schema and serde features used when creating each value serde . this is later used by qtt to build historical plans that capture this information , giving us confidence that any changes we make are n't changing the schema and serde features being used by historical queries . <nl> this commit extends this to capture details from _key_ serde , not just _value_ serde , and to capture full and info . <nl> the benefit is two fold : increased test coverage of historical plans and its a necessary improvement to enable testing of non-kafka key formats . a follow up pr will improve the to use this more detailed information . <cm-sep> historical plans <para-sep> pojo for holding data about the physical schemas in use at the different stages within a topology of a query . contains an ordered mapping of 'logger name prefix ' to the schema used , where the logger name prefix can be used to map the schema to a stage in the topology . <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given :","when building a query , the captures the schema and serde features used when creating each value serde . this is later used by qtt to build historical plans that capture this information , giving us confidence that any changes we make are n't changing the schema and serde features being used by historical queries . <nl> this commit extends this to capture details from _key_ serde , not just _value_ serde , and to capture full and info . <nl> the benefit is two fold : increased test coverage of historical plans and its a necessary improvement to enable",1602002493,the idea here is that the call should make it clear what properties are at their default value . we already have a marker for . i 've added a new marker for those properties that are not set via server config or have local overrides . <nl> so you now get an output like : . <nl> not sure if we should also add a tag too ... ?,0.9682850241661072
apache_incubator-pinot/5349,"remove many addtime methods <cm-sep> keep only 0 addtime method <para-sep> tests that record extractor is able to handle missing fields correctly ( incoming and outgoing are missing from data ) <nl> constructs a datetimefieldspec with basic fields name , datatype , format and granularity constructs a datetimefieldspec with basic fields - name , datatype , format , granularity - and also with defaultnullvalue and transformfunction <nl> add single value dimensionfieldspec add single value dimensionfieldspec with a defaultnullvalue add multi value dimensionfieldspec add single value dimensionfieldspec with defaultnullvalue add metricfieldspec add metricfieldspec with defaultnullvalue add timefieldspec with incoming and outgoing granularity spec todo : this is going to be deprecated in favor of adddatetime ( ) . many tests use this to construct schema with timefieldspec . this will continue to exist for a while , as it helps to test backward compatibility of schemas containing timefieldspec <nl> add datetimefieldspec with basic fields add datetimefieldspec with basic fields plus defaultnullvalue and transformfunction","when timefieldspec gets deprecated in favor of datetimefieldspec , one of the changes will be in the class . is used only in tests ( not sure if external integrations use it ) . <nl> schemabuilder has ~0 methods to . these will be replaced with ( barring a few places where we intentionally want to add time to test that we get date_time . ) <nl> removing most of the addtime methods , keeping only <nl> 0 ) <nl> this will help when making the code change to datetimefieldspec . <nl> these above method gets replaced by <nl> 0",1588884868,"moving metricasdimension configs from dataset to metric . we are encountering usecases where we can havedifferent metric configs for different metrics of a dataset , and having a dataset level flag for this does n't make sense anymore . this pr gives us the ability to setup a metric with flag dimensionasmetric . the other configs needed by the metric , such as metric anmes , metric names column and metric values column can be set in metricproperties . <nl> tested for a dataset which has dimensionasmetric for certain metrics , and not for others .",0.959833562374115
quarkusio_quarkus/15708,"update vert.x to version and netty to version <para-sep> set whether the server will try to use a compressed response . <nl> whether or not the mail should always been sent as multipart even if they do n't have attachments . <nl> avoid directly referencing optional dependencies <nl> common meterfilter ( uri variation limiter ) <nl> avoid imports due to related deps not being there <nl> rest client listener spi <nl> rest client listener <nl> protect from uri tag flood <nl> other things use this bean to test whether or not http server/client metrics are enabled <nl> add support for vert.x instrumentation . http instrumentation is dependent on vert.x , but has been pulled out into its own processor <nl> if you invoke requests , http server and client meters should be registered <nl> /one should map to /two , which is ignored . neither should exist w/ timers <nl> uris for server : /ping/ { message } , /pong/ { message } , /vertx/item/ { id } , /vertx/item/ { id } / { sub } , /servlet/ <nl> if you invoke requests , http server and client meters should be registered leading context root ( /foo ) should be stripped from resulting _server_ tag application path ( /bar ) only impacts rest endpoints <nl> uris for server should include application path : /bar/ping/ { message } , /bar/pong/ { message } <nl> application path does not apply to non-rest endpoints : /vertx/item/ { id } <nl> if you invoke requests , http server and client meters should be registered leading context root ( /foo ) should be stripped from resulting _server_ tag <nl> uris for server : /ping/ { message } , /pong/ { message } , /vertx/item/ { id } <nl> server will have both /ping/ { message } and /pong/ { message } due to limit , there should only be one . <nl> vertx binder should exist if you invoke requests , no http server or client meters should be registered <nl> vertx binder should exist <nl> if you invoke requests , http server and client meters should be registered <nl> for server : /ping/ { message } and /pong/ { message } . <nl> for client : /pong/ { message } <nl> apply global filters to the global registry",this pr is a branch of the updating to the latest vert.x release . <nl> let 's see how far it goes .. .,1615736451,this pr is basically a big refactoring of and .,0.9796172380447388
apache_pulsar/8851,"enable spotbugs for pulsar functions . <para-sep> there might be two clients conflicting at creating table , so let 's retrieve the table again to make sure the table is created .",enable spotbugs for pulsar functions . <nl> enable spotbugs for pulsar functions .,1607349703,"allow user to specify the initial position for consumer source builder . <nl> add initial position for pulsarconsumersource . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( yes ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no",0.9174726605415344
apache_shardingsphere/9307,add exception for table rewrite error,add exception for table rewrite error when routed table is not exist .,1612405607,changes proposed in this pull request : <nl> - fix shadow value in literal expression,0.9516125321388245
hazelcast_hazelcast/18283,"wip <cm-sep> wip <cm-sep> wip <cm-sep> finish <cm-sep> fix style . <cm-sep> remove the usage of global indexes for single-partition queries <para-sep> - blocked ( one of the handler wants to stop with the pipeline ) ; one of the usages is tls handshake - blocked ( one of the handler wants to stop with the pipeline ) ; one of the usages is tls handshake <nl> this class is not thread-safe . <nl> for deserialization <nl> performance note : the query will use non-partitioned indexes . if not all partitions of a member are in the set , the index will return entries for all the partitions , but those will be subsequently eliminated . if all ( or most ) partitions of a member are in the set , the performance hit is small . performance note : the query will use non-partitioned indexes . if not all partitions of a member are in the set , the index will return entries for all the partitions , but those will be subsequently eliminated . if all ( or most ) partitions of a member are in the set , the performance hit is small . performance note : the query will use non-partitioned indexes . if not all partitions of a member are in the set , the index will return entries for all the partitions , but those will be subsequently eliminated . if all ( or most ) partitions of a member are in the set , the performance hit is small . performance note : the query will use non-partitioned indexes . if not all partitions of a member are in the set , the index will return entries for all the partitions , but those will be subsequently eliminated . if all ( or most ) partitions of a member are in the set , the performance hit is small . <nl> queryengine orchestrates the queries and merging the result queryrunner - & gt ; runs the query logic in the calling thread ( so like evaluates the predicates and asks the index ) used only for tests to disable the fallback to partition operations . we had issues when the fallback fixed the results in the normal case and the much worsened performance went unnoticed . ( e.g .","improves the implementation of queries on a subset of partitions . the previous implementation was incomplete and worked only thanks to the migration fallback mechanism . <nl> this pr adds a field to which contains the partitions it 's supposed to run on . when the query is supposed to scan a global ( non-partitioned ) index , it scans all partitions in it and subsequently filters out non-included partitions - this creates extra overhead when the index is n't selective . on the other hand , the alternative is not using the index at all , which also is",1614166623,remaining classes converted to identifieddataserializable .,0.9620571732521057
grpc_grpc-java/7453,"convert envoy proto virtualhost . <cm-sep> define interface for watching individual lds/rds resources . <para-sep> todo ( chengyuanzhang ) : put data types into smaller categories . * / <nl> canonical name of this virtual host . <nl> a list of domains ( host/authority header ) that will be matched to this virtual host . <nl> the list of routes that will be matched , in order , for incoming requests . <nl> todo ( chengyuanzhang ) : delete me . <nl> total number of nanoseconds to keep alive an http request/response stream . <nl> the name of the route configuration to be used for rds resource discovery . <nl> the list virtual hosts that make up the route table . <nl> the list virtual hosts that make up the route table . <nl> todo ( chengyuanzhang ) : delete me . registers a data watcher for the given lds resource . <nl> unregisters the given lds resource watcher . <nl> registers a data watcher for the given rds resource . <nl> unregisters the given rds resource watcher .","sadly , is taken . so i made it . i am going to rename existing update/watchers to / , / for consistency .",1600900740,"this is only api plumbing for hedging , following exactly the same way as its retry counterpart , so it is almost trivial .",0.9716800451278687
apache_pulsar/9056,"add streaming dispatcher . <para-sep> objects that are waiting to be notified when new entries are persisted <nl> skip read as topic/dispatcher has exceed the dispatch rate or previous pending read has n't complete . <nl> if turn on precise dispatcher flow control , adjust the record to read <nl> if the connection is not currently writable , we issue the read request anyway , but for a single message . the intent here is to keep use the request as a notification mechanism while avoiding to read and dispatch a big batch of messages which will need to wait before getting written to the socket . <nl> throttle only if : ( 0 ) cursor is not active ( or flag for throttle-nonbacklogconsumer is enabled ) bcz active-cursor reads message from cache rather from bookkeeper ( 0 ) if topic has reached message-rate threshold : then schedule the read after message_rate_backoff_ms <nl> if dispatch-rate is in msg then read only msg according to available permit <nl> if dispatch-rate is in msg then read only msg according to available permit <nl> if messagestoread is 0 or less , correct it to 0 to prevent illegalargumentexception <nl> acquire message-dispatch permits for already delivered messages <nl> schedule a new read batch operation only after the previous batch has been written to the socket . <nl> skip read as topic/dispatcher has exceed the dispatch rate . <nl> if the connection is not currently writable , we issue the read request anyway , but for a single message . the intent here is to keep use the request as a notification mechanism while avoiding to read and dispatch a big batch of messages which will need to wait before getting written to the socket . <nl> if turn of precise dispatcher flow control , adjust the records to read <nl> throttle only if : ( 0 ) cursor is not active ( or flag for throttle-nonbacklogconsumer is enabled ) bcz active-cursor reads message from cache rather from bookkeeper ( 0 ) if topic has reached message-rate threshold : then schedule the read after message_rate_backoff_ms <nl> if dispatch-rate is in msg then read only msg according to available permit <nl> if dispatch-rate is in msg then read only msg according to available permit <nl> if messagestoread is 0 or less , correct it to 0 to prevent illegalargumentexception <nl> all consumers got disconnected before the",trying to streamline the dispatcher 's read requests to manager ledger instead of micro batch . <nl> created a streamingentryreader that can streamline read request to managed ledger . <nl> created streamingdispatcher interface with necessary method to interact with streamingentryreader . <nl> created persistentstreamingdispatchersingleactive/multipleconsumer that make use of streamingentryreader to read entries from managed ledger . <nl> add config to use streaming dispatcher . <nl> ( please pick either of the following options ) <nl> this change added tests and can be verified as follows : <nl> add unit tests . <nl> - does this pull request introduce a new,1608859329,"allow the option to mark messages for delayed delivery . <nl> notes : <nl> * if delayed delivery is disabled , messages are always delivered immediately and there 's no tracking overhead . <nl> * messages are only delayed on shared subscriptions . other subscriptions will deliver immediately . <nl> * the tracking of delayed messages is lazily initialized and if a messages has no delay , it will have no overhead . <nl> * the tracking is ephemeral and implemented in pulsar broker . the main reason is to avoid a client refetching messages multiple times when there are",0.9822332859039307
apache_druid/10448,added cronscheduler support for monitorscheduler <cm-sep> added javadoc and license <cm-sep> fixed formatting <para-sep> todo auto-generated method stub <nl> todo auto-generated method stub,"this pr fixes the clock drift issue while emitting metrics . <nl> i have changed the method in class . in this implementation , i have used method for periodically scheduling the monitor with constant rate . this method requires a which should be non-blocking , so the monitoring inside the crontask is happening as an async process using executor thread pool",1601377232,"document unsupported join on multi-value column . <nl> moreover , we should fail query that tries to join on multi-value column rather than silently ignoring multi-valued column and returning results back to user . this is because user may not be aware that druid actually do not support join on multi-value column and thinking that the result is because nothing match join condition",0.9534206986427307
vespa-engine_vespa/16638,add configurable response headers for blocked requests <cm-sep> test dryrun,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1614072116,sort list of document types in topological order ( according to document references ) when producing proton config . <nl> this is to ensure that config is applied in the right order in the search backend .,0.9311304092407227
hazelcast_hazelcast/18445,enable usage of expressionevalcontext while evaluating table function parameters,"refactored table functions , so the evaluation of arguments is performed during creation - it 's an enabler for future work on dynamic parameters .",1617345287,removed usage from the implementation . the executor service codec uses to send the task and hence ıt does not need to be .,0.9500656127929688
apache_druid/10199,"report missing segments when there is no segment for the query <nl> datasource in historicals <para-sep> note : clusterclient.getqueryrunnerforintervals ( ) can return an empty sequence if there is no segment to query , but this is not correct when there 's a right or full outer join going on . <nl> even though we did n't find a timeline for the query datasource , we simply returns a noopqueryrunner instead of reporting missing intervals because the query intervals are a filter rather than something we must find .","the currently returns a when there is no timeline for the query datasource . this will lead to an incorrect query result . instead , it should report all segments as missing , so that the broker can handle them properly",1595266204,"example config : . <nl> the example defines 0 lanes , ' ten ' , ' twenty ' , and ' fifty ' , which if the query context contains that lane name will be allowed to use up to 0 % , 0 % , or 0 % of the total capacity",0.9618086814880371
apache_camel/4811,": add option ' breakonshutdown ' to loop eip . <nl> setting the ' breakonshutdown ' option on the loop eip <nl> allows to break out of the loop earlier if the context <nl> is shutting down . <cm-sep> : add missing license header <cm-sep> : add option ' breakonshutdown ' to loop eip <para-sep> if the breakonshutdown attribute is true , then the loop will not iterate until it reaches the end when camel is shut down .",this pull request implements the option ' breakonshutdown ' for the loop eip . if the option is set it allows to break out of the loop when camel is shut down ( instead of iterating until the end of the loop is reached ) .,1608579430,"this is possible solution to handling for undertow <nl> if this is the correct approach , would need to handle streaming <nl> also some other tests may need to add a body so the status code does not switch on them . <nl> let me know what you think",0.9573399424552917
jenkinsci_jenkins/4825,"introduce migration <para-sep> in the case that external fingerprint storage is configured , there may be some fingerprints in memory that get saved before a load call ( because they are already in memory ) . this ensures that they get deleted from the file fingerprint storage . todo : consider improving keyeddatastorage so it provides an api for clearing the fingerprints in memory . <nl> in case an external storage is configured on top of a file system based storage : 0. external storage is polled to retrieve the fingerprint 0. if not found , then the local storage is polled to retrieve the fingerprint <nl> after external storage is configured , check if local storage fingerprint is still accessible . <nl> after loading the fingerprint , ensure it was moved to external storage . <nl> ensure that the loaded fingerprint was deleted from local storage after being loaded . <nl> this fingerprint is now implicitly saved without making a load call . we want the file storage to not have this fingerprint now .",* developer : migration of fingerprints from local file based storage to configured external storage is introduced,1593454985,"in a similar way that the environment variable _jenkins_url_ allows to execute different cli command without specifying the _-s_ option continuously , environment variable such as _jenkins_user_id_ and _jenkins_api_token_ might help configuring easily the executions without specifying the _-auth_ option in each executed command . <nl> idea . <nl> before . <nl> after . <nl> in case the _-auth_ option is specified , its value will prevail , although the env vars will not be unset for later use . <nl> * : allow jenkins_user_id and jenkins_api_token environment variables to configure the authentication when the cli is invoked .",0.9636377692222595
apache_beam/12634,do n't check the subscription that was created by testpubsub <cm-sep> checkifanysubscriptionexists - > assertsubscriptioneventuallycreated <cm-sep> use testpubsub.assertsubscriptioneventuallycreated instead of testpubsubsignal.waitforstart <para-sep> block until a subscription for this topic exists <nl> block until a subscription for this topic exists <nl> block until a subscription for this topic exists <nl> block until a subscription for this topic exists <nl> block until a subscription for this topic exists <nl> block until a subscription for this topic exists,"- renamed to ( original is still there and marked deprecated ) , and updated the docstring . <nl> - use everywhere that was being used to block before injecting data into a pubsub topic . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1597865226,"due to the new mailbox operator architecture in flink version , processing remaining <nl> timers during operator shutdown ca n't be achieved by releasing the checkpoint <nl> lock anymore . timers are only drained after the close ( ) method completes . <nl> however , at this point new timers also can not be set anymore . <nl> this does n't play well with some of beam 's code ( e.g . sdf ) which assumes that <nl> timers can set new timers which are guaranteed to fire at the end of the <nl> pipeline . with the current processing",0.9352025389671326
apache_pulsar/9738,change getworkerservice method to throw an unsupportedoperationexception directly .,but when we try to appy those method . broker will throw nullpointerexception instead of throwing a more user friendly error that explain the problem . <nl> this pr is trying to fix it . <nl> * throw an exception instead of returning null <nl> * add unit test for normal and abnormal conditions . <nl> - does this pull request introduce a new feature ? ( no ),1614338454,"create a partitioned topic , before client use this topic or create a subscription on this topic , when get stats of internal topic , will get error . but actually partitioned topic is already created , <nl> internal topic have not been generated yet . <nl> add following check : . <nl> 0. gettopicreference ( ) on a partitioned internal topic and partitioned topic is not exist will get <nl> 0. gettopicreference ( ) on a partitioned internal topic , partitioned topic is exist but internal topics not exist will get",0.9412698149681091
apache_kafka/10039,defer log recovery until logmanager startup <para-sep> visible for testing <nl> save memory by only including configs for topics with overrides <nl> visible for testing <nl> testtopicone configs loaded again due to the update <nl> testtopictwo configs not loaded again since there was no update <nl> topic partition from the list of initializing partitions and no configs are retrieved .,"currently log recovery begins as soon as we instantiate , but when using a raft-based metadata quorum we wo n't have configs until after we catch up on the metadata log . we therefore defer log recovery until we actually invoke on the instance . this timing difference has no effect when using zookeeper because we immediately invoke on the instantiated instance , but it gives us the necessary flexibility for accurate log recovery with updated configs when using a raft-based metadata quorum . <nl> the is currently instantiated during construction just after log recovery completes , and then it",1612371223,"very simple pr , introduce enummap in 0 places of the code . <nl> enummap is meant to be used when the key of a map is an enum . <nl> from the documentation : . <nl> > enum maps are represented internally as arrays . this representation is extremely compact and efficient . <nl> should use less memory per instance and also be faster in lookup .",0.8179618120193481
jenkinsci_jenkins/4888,"expose methods for plugins <para-sep> converter implementation for rangeset . <nl> check if the given class can be converted ( i.e . check if it is of type rangeset ) . used to serialize the range sets ( builds ) of the fingerprint using commas and dashes . for e.g. , if used in builds 0,0,0,0 , it will be serialized to 0-0,0",* developer : expose fingerprint range set serialization methods for plugins,1596208067,"refactored as run.getbuildsoverthreshold <nl> this is for discussion . <nl> notes : <nl> * most commits were created by intellij <nl> * individual commits are mostly self contained <nl> * in general , most commits should not change program behavior at all . <nl> * internal java code cleanup . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.874201774597168
OpenAPITools_openapi-generator/8158,generate java code with ' static final ' instead ' final static ' <cm-sep> regenerate code with ' static final ',"simple change , to follow general consensus , generated java code will have ' static final ' not ' final static ' .",1607638592,line 0 and 0 were missing the triple-htlm escape brackets ( line 0 had this correctly ) leading to code generation such as : . <nl> note the notation .,0.8673421144485474
confluentinc_ksql/6013,"break up insertvaluesexecutor for easier reuse in testing tool <para-sep> builds a java object , coerced to the desired type , from an arbitrary sql expression that does not reference any source data . <nl> we expect no column references , so we can pass in an empty generic row <nl> the set of columns users can supply values for includes the rowtime pseudocolumn , so include it in the schema : <nl> this is mostly used when generating data from sql expressions . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","this pr breaks up the into separate classes and adds more unit testing . <nl> no functional changes , all copy-pasta - but i added unit tests anyway .",1597295235,this change allows the user to forego providing inputs and instead add values to topics by using the statement .,0.9804242849349976
apache_druid/10194,fix itsqlinputsourcetest.java <para-sep> multiple query . no filter <nl> multiple query . filter on timestamp column <nl> multiple query . filter on data column <nl> single query . no filter <nl> single query . filter on timestamp column <nl> single query . filter on data column,"fix itsqlinputsourcetest so that it uses the correct ingestion spec . <nl> itsqlinputsourcetest has a typo which causes it to use incorrect ingestion spec ( that does not use the sql inputsource ) . this pr corrects this by updating itsqlinputsourcetest to use the correct ingestionspec that has the sql inputsource . additionally , batch-index test group was already very close to timeout and updating the itsqlinputsourcetest to use the correct ingestionspec can occasionally cause the batch-index test group to go over the limit . hence , this pr also moves itsqlinputsourcetest out into its own group",1595011778,update the maven dependency plugin to the latest version and fix all warnings for unused declared and used undeclared dependencies in the compile scope ( command : ) . added new travis job to add the check to ci . also fixed some source code files to use the correct packages for their imports,0.8501369953155518
jenkinsci_jenkins/4989,replaced deprecated <nl> ew nulloutputstream ( ) with null_output_stream because constructor gets private in apache.commons.io in version,replaced with because constructor gets private in apache.commons.io in version <nl> see apache commons . <nl> * internal : n/a,1602490294,"fixed 0 spotbugs issues . <nl> * sa_local_double_assignment <nl> * bc_vacuous_instanceof <nl> * dls_dead_local_store . <nl> * internal : minor internal improvements . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8397295475006104
OpenAPITools_openapi-generator/7306,update springboot dependencies <cm-sep> update doc,- update dependencies <nl> - mark java8 option as deprecated as jdk8 support is the default .,1598581407,- set supportasync to true as the default .,0.8141912221908569
ballerina-platform_ballerina-lang/24756,fix adding duplicated & wrong entries to lock file . <para-sep> check if this module should be added to lock file . modules and built-in modules not exists in directory avoided in the lock file . <nl> modules should be avoided in lock file <nl> built in modules in directory should be added to lock file <nl> non built in modules should be added to lock file <nl> check if module is a built in module .,also added logic to enter modules exists in to lock file if those modules have imported to the source .,1594809318,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.9270038604736328
Graylog2_graylog2-server/9804,"unblock jobschedulerservice on shutdown . <nl> the jobschedulerservice blocks in its run method until the server <nl> reaches the running state . it can not be unblocked even when interrupting <nl> the execution thread . so if one of the other services fails during <nl> startup , the service manager is unable to shutdown the <nl> jobschedulerservice . <nl> this change adds an interruptible implementation to wait for the server <nl> reaching the running state . the new method is then used in the <nl> jobschedulerservice . upon shutdown , the execution thread of the <nl> jobschedulerservice is interrupted so that the service can <nl> properly terminate . <para-sep> blocks until the server enters the running state and then executes the given runnable . this method is not interruptible while waiting for the server to enter the running state . <nl> blocks until the server enters the running state .","this change adds an interruptible implementation to wait for the server <nl> reaching the running state . the new method is then used in the <nl> jobschedulerservice . upon shutdown , the execution thread of the <nl> jobschedulerservice is interrupted so that the service can <nl> properly terminate . <nl> the jobschedulerservice blocks in its run method until the server <nl> reaches the running state . it can not be unblocked even when interrupting <nl> the execution thread . so if one of the other services fails during <nl> startup , the service manager is unable to shutdown the <nl>",1608039257,( cherry picked from commits sha and sha ),0.9318946599960327
elastic_elasticsearch/70548,the test abstractsearchablesnapshotsresttestcase.testclearcache ( ) <nl> sometimes fails because it assumes that all cache writes are completed <nl> when retrieving and comparing the searchable snapshots stat <nl> cached_bytes_written . <nl> this commit changes the test so that it now waits for searchable <nl> snapshots thread pools to finish to process cache related tasks <nl> before retrieving the stats . <cm-sep> fix,the test abstractsearchablesnapshotsresttestcase.testclearcache ( ) <nl> sometimes fails because it assumes that all cache writes are completed <nl> when retrieving and comparing the searchable snapshots stat <nl> cached_bytes_written . <nl> this commit changes the test so that it now waits for searchable <nl> snapshots thread pools to finish to process cache related tasks <nl> before retrieving the stats .,1616064236,"when target indices are remote only , ccs does not require user to have privileges on the local cluster . this pr ensure point-in-time reader follows the same pattern .",0.9112774133682251
elastic_elasticsearch/70716,mark step # isretryable abstract . <nl> this marks isretryable and implements it in the remaining places . <para-sep> this is marker step so it does n't make sense to be retryable <nl> this is marker step so it does n't make sense to be retryable <nl> this is marker step so it does n't make sense to be retryable,this marks as abstract and implements it in the remaining places .,1616494018,"currently we always call reduce even when we only have one internalaggregation . in some cases this is necessary but in others the reduce method is just making a copy of itself . this is normally not too expensive excepts for aggregations that hold expensive objects , for example cardinality or percentile aggregations . <nl> in order to prevent this necessary step this pr adds a new abstract method in internalaggregation that flags the framework if it needs to reduce on a single internalaggregation .",0.9552553296089172
ballerina-platform_ballerina-lang/24484,"fix setting field readonly flag <cm-sep> infer a type for mapping-constrs with readonly fields <cm-sep> fix error on readonly field with invalid type <cm-sep> make the inferred exclusive record type readonly if all constructor and cet fields are readonly <cm-sep> add tests for readonly fields in the mapping-constructor <cm-sep> add readonly modifier in record/object readonly field string representation <cm-sep> allow using readonly as the cet for map/list constructor exprs <cm-sep> fix anon record rest field not getting rewritten at desugar <cm-sep> fix constr type-checking against readonly in union and add tests <cm-sep> add tests for union cet with readonly <cm-sep> use intersection effective type for type-checking <cm-sep> add tests for readonly with mapping constr with diff . field kinds <para-sep> a record type is inferred for a record literal even if the contextually expected type is a map , if the mapping constructor expression has fields . <nl> if the expected type is a map , but a record type is inferred due to the presence of fields in the mapping constructor expression , we do n't override the expected type . <nl> has to be a varname field . <nl> already defined . <nl> updates should be allowed . <nl> updates should be allowed . <nl> this should represent the inferred type . <nl> this should represent the inferred type . <nl> ////////////////////////////////// records //////////////////////////////////// <nl> valid update since is not readonly . <nl> invalid update since is readonly . <nl> is now immutable since all fields are . <nl> invalid updates since is readonly . <nl> invalid updates since is readonly . <nl> is not since non-readonly fields are present . <nl> is since all the fields are and is closed . <nl> is not since is open . <nl> is not since is open . <nl> is not since non-readonly fields are present . <nl> ////////////////////////////////// maps //////////////////////////////////// <nl> is not since non-readonly fields may be present . <nl> valid update since is not readonly . <nl> invalid updates since is readonly . <nl> is not since non-readonly fields may be present . <nl> valid update since is not readonly . <nl> invalid updates since is readonly . <nl> valid update since is mutable . <nl> valid update since is mutable . <nl> invalid updates since is readonly . <nl> valid updates . <nl> valid updates .","this pr <nl> - adds support for fields in a mapping-constructor expression . <nl> such a mapping constructor will create a value of a type that belongs to the applicable contextually expected type , but additionally , the fields with which were used will be fields . <nl> the constraints this enforce on the value are the same as with fields in the type-descriptor . i.e. , <nl> 0. the values specified for such fields have to be immutable <nl> 0. the field can not be updated once the value is created <nl> 0. if the constructor creates a closed",1593411490,"this pr introduces the following changes to finite types : <nl> - assignment to broader types . <nl> - type test/type guard support . <nl> - casting . <nl> - array access by finite type . <nl> - array/tuple access by union types with finite type . <nl> this pr also allows the type test/type guard with intersecting union types . with the type guard , the type when the type test evaluates to true would be the intersection : .",0.9778261184692383
vespa-engine_vespa/15897,add system name to quota error message,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1609771478,"the previous method for retrieving quota usage did not work consistently . instead of finding a novel way of doing it on the controller side , i 'm just copying the same way our cluster retrieval code does it by asking the node repository . to avoid some issues with system applications i had to move quota usage retrieval a bit higher up in the call path - which is probably a good thing .",0.9308592081069946
quarkusio_quarkus/14766,close kubernetesclient in kubernetesclientutilstest <cm-sep> make quarkuscoredeploymentversionlocator inner class static <cm-sep> remove unused local variable in jbangdevmodelauncherimpl <cm-sep> remove unused variable definition,- close kubernetesclient in kubernetesclientutilstest <nl> - make quarkuscoredeploymentversionlocator inner class static <nl> - remove unused local variable in jbangdevmodelauncherimpl <nl> - remove unused variable definition . <nl> one pr to be nice to our ci .,1612272997,let 's see what ci has to say and i added a few comments here and there to be sure i do n't do anything wrong . <nl> thanks !,0.860966682434082
OpenAPITools_openapi-generator/7337,"replace go with go-experimental <cm-sep> update samples <cm-sep> extends with abstract go class <cm-sep> rearrange <para-sep> go-deprecated ( deprecated ) <nl> option to change how we process + set the data in the 'additionalproperties ' keyword . <nl> configures a friendly name for the generator . this will be used by the generator to select the library with the -g flag . <nl> configures the type of generator . <nl> returns human-friendly help for the generator . provide the consumer with help tips , parameters here <nl> generate the 'signing.py ' module , but only if the 'http signature ' security scheme is specified in the oas . <nl> underscoring would also lowercase the whole name , thus losing acronyms which are in capitals <nl> make sure the inline enums have plain defaults ( e.g . string , int , float ) <nl> the superclass determines the list of required golang imports . the actual list of imports depends on which types are used , some of which are changed in the code below ( but then preserved and used through x-go-base-type in templates ) . so super.postprocessmodels must be invoked at the beginning of this method . <nl> note this could have been done by adding the following line in processopts ( ) , however , we only want to represent the datetime object as nullabletime if it 's marked as nullable in the spec . typemapping.put ( ' datetime ' , ' nullabletime ' ) ; <nl> additional import for different cases oneof <nl> anyof <nl> additionalproperties : true and parent <nl> look up the model <nl> logger.error ( ' error in constructing examples . failed to look up the model ' + codegenparameter.datatype ) ; <nl> look up the model <nl> logger.error ( ' error in constructing examples . failed to look up the model ' + codegenproperty.datatype ) ; <nl> break infinite recursion . return , in case a model is already processed in the current context . <nl> default hide_generation_timestamp to true <nl> option to change the order of form/body parameter <nl> configures the type of generator . <nl> configures a friendly name for the generator . this will be used by the generator to select the library with the -g flag . <nl> returns human-friendly help for the generator . provide the consumer with help tips , parameters here <nl> location to write api",- rename generator as <nl> - replace generator with generator <nl> - remove ( deprecated ) samples .,1599121545,"this is a performance enhancement . the code generation behavior does not change : . <nl> 0. create a cache for <nl> 0. create a cache from named model to codegenmodel . used by <nl> 0. create a cache from named property to codegenproperty . used by <nl> 0. create a cache from language-specific model name to shema . <nl> 0. pre-compile regex patterns instead of calling string.replaceall ( ) . <nl> 0. other minor optimizations . <nl> i 've noticed for a large openapi doc , the code generation was taking more than 0 minutes and 0 % of",0.9451475143432617
elastic_elasticsearch/70878,"make restapiversion on xcontentbuilder final . <nl> when passing in restapiversion during creation of xcontentbuilder <nl> it makes it more clear that this field is final . <nl> this prevents accidental change of the version during the xcontent <nl> creation . <nl> the withcompatibleversion method can also be removed , since the field <nl> only needs to be set in constructor . <para-sep> creates a new builder using the provided xcontent , output stream and some inclusive and/or exclusive filters . when both exclusive and inclusive filters are provided , the underlying builder will first use exclusion filters to remove fields and then will check the remaining fields against the inclusive filters . stores restapiversion to help steer the use of the builder depending on the version .","when passing in restapiversion during creation of xcontentbuilder <nl> it makes it more clear that this field is final . <nl> this prevents accidental change of the version during the xcontent <nl> creation . <nl> the withcompatibleversion method can also be removed , since the field <nl> only needs to be set in constructor .",1616686347,"index-time analyzers are currently specified on the mappedfieldtype . this <nl> has a number of unfortunate consequences ; for example , field mappers that <nl> index data into implementation sub-fields , such as prefix or phrase <nl> accelerators on text fields , need to expose these sub-fields as mappedfieldtypes , <nl> which means that they then appear in field caps , are externally searchable , <nl> etc . it also adds index-time logic to a class that should only be concerned <nl> with search-time behaviour . <nl> this commit removes references to the index analyzer from mappedfieldtype , <nl> and",0.9573754668235779
apache_camel/5086,": camel-sql : preserve message body . <nl> ... when camelsqlretrievegeneratedkeys == true <para-sep> only populate if really needed <nl> transfer incoming message body data to prepared statement parameters , if necessary",... when camelsqlretrievegeneratedkeys == true . <nl> also refactored out some duplicate code .,1613338213,: camel-cdi - remove support for multiple camel context ( not fully implemented and not recommended - 0 context per app/deployment is only supported ) .,0.9058602452278137
apache_incubator-pinot/5669,fixing code to fetch the fsconfig from the right parent <cm-sep> adding test case <para-sep> asserts array properties can be read as string and array . <nl> asserts no error occurs when no configuration is provided in the spec .,"we were initializing the pinot fs class with incorrect configuration . <nl> before : . <nl> > got scheme s3 , initializing class org.apache.pinot.plugin.filesystem.localfs with config : { =org.apache.pinot.plugin.filesystem.localfs } . <nl> after . <nl> > got scheme s3 , initializing class org.apache.pinot.plugin.filesystem.localfs with config : { secretkey=secret , accesskey=access , region=myregion } . <nl> added test case <nl> # # upgrade notes <nl> does this pr prevent a zero down-time upgrade ? <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature",1594255415,"* print series in insertion order . <nl> * print index series , if any , first . <nl> * trim spaces at end of line",0.940531313419342
apache_beam/13616,implement reading unknown schema files for parquetio <cm-sep> update parquertio capability in changes.md <cm-sep> improve backward compatibility by creating separate and implementation for supporting files with unknown schema . <cm-sep> 0. fix javadoc example by using consistent words <nl> 0. other indentation and space fixes <cm-sep> make genericrecordpassthroughfn singleton <cm-sep> fix spotless apply <para-sep> parquetio add methods _readgenericrecords_ and _readfilesgenericrecords_ can read files with an unknown schema . <nl> * / <nl> * / <nl> * / <nl> if not genericrecord infer it from parsefn . <nl> passthrough function to provide seamless backward compatibility to parquetio 's functionality . <nl> * / <nl> returns list of json representation of genericrecords . * / <nl> sample parse function that converts genericrecord as json . for testing . * /,"data engineers encounter times when schema of parquet file is unknown at the time of writing the pipeline or multiple schema may be present in different files . reading parquet files using parquetio requires providing an avro ( equivalent ) schema , many a times its not possible to know the schema of the parquet files . <nl> supporting this functionality in parquetio is simple and requires minimal changes to the parquetio surface created instead of pr/0 due to change in source branch",1608852860,"adds support for beam schemas in bigquery reads . <nl> direct reads are not supported yet . support for different date/time types and record types are pending as well . <nl> the largest change is the refactoring of and classes . as the schema inference has to happen at pipeline construction time , the reusable code for accessing the table/query results have been extracted out to ' source definition ' classes named and . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger",0.9801710247993469
apache_beam/12831,"add a permanently failing test to replicate the flake <cm-sep> fix bug <cm-sep> clarify documentation on logicaltype , it should not need to handle nulls <para-sep> note for nullable types , null checking is always done externally . * / <nl> this value is supposed to be overridden with null","this pr also adds a test that will fail permanently ( rather than flake ) without this bugfix , and updates documentation on logicaltype to clarify that it should not need to handle nulls . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1599863407,* switches jdbc and tableprovider to autoservice <nl> * fixes caching of it results <nl> * adds context loader hack and tests that queries run . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9347259402275085
elastic_elasticsearch/72341,"* add docs for feature reset api <nl> * prose and style much improved by deb adair . <cm-sep> previously , the resetfeaturestatestatus object captured its status in a <nl> string , which meant that if we wanted to know if something succeeded or <nl> failed , we 'd have to parse information out of the string . this is n't a <nl> good way of doing things . <nl> i 've introduced a success/failure enum for status constants , and added a <nl> check for failures in the transport action . we return a 0 if some but not all <nl> reset actions fail , and for every failure , we also return information about the <nl> exception or error that caused it . <nl> * fix 0.x backport compilation issues . <para-sep> this class represents the response of the feature state reset api . it is a list containing the response of every feature whose state can be reset . the response from each feature will indicate success or failure . in the case of a failure , the cause will be returned as well . <nl> create a new resetfeaturesresponse <nl> a class representing the status of an attempt to reset a feature 's state . the attempt to reset either succeeds and we return the name of the feature and a success flag ; or it fails and we return the name of the feature , a status flag , and the exception thrown during the attempt to reset the feature . <nl> create a resetfeaturestatestatus .","previously , the resetfeaturestatestatus object captured its status in a <nl> string , which meant that if we wanted to know if something succeeded or <nl> failed , we 'd have to parse information out of the string . this is n't a <nl> good way of doing things . <nl> i 've introduced a success/failure enum for status constants , and added a <nl> check for failures in the transport action . we return a 0 if some but not all <nl> reset actions fail , and for every failure , we also return information about the <nl> exception",1619560546,"this commit moves away from the static rollup index <nl> naming strategy and moves towards a randomized rollup index name scheme . <nl> this will reduce the complications that exist if the rollupstep fails and retries <nl> in any way . a separate cleanup will still be required for failed temporary indices , <nl> but at least there will not be a conflict . <nl> this commit generates the new rollup index name in the lifecycleexecutionstate so <nl> that it can be used in rollupstep and updaterollupindexpolicystep on a per-index <nl> basis .",0.9788333773612976
elastic_elasticsearch/72183,add warning for path.data as a list to deprecation api . <nl> this commit adds a deprecation warning when a single data path is used <nl> with a yaml list .,this commit adds a deprecation warning when a single data path is used <nl> with a yaml list .,1619209276,ccs with remote indices only does not require any privileges on the local cluster . <nl> this pr ensures that search with scroll follow the permission model .,0.9367967844009399
apache_druid/10253,allow forcelimitpushdown in sql <para-sep> a flag to force limit pushdown to historicals .,can throw an exception while iterating candidate plans in sql planner . this pr postpones validation until it 's necessary,1596777771,"in this pull request : <nl> 0. memorize the computing of parser.parse <nl> 0. add some test cases <nl> 0. add expression schema in benchmarkschemas . <nl> the benchmark result ( as the complexity of the expression to be processed increases , the processing time also increases proportionately using old codes ) : . <nl> before . <nl> patch",0.9538703560829163
apache_ignite/8923,ability to specify postfix for ignitelogger instead of nodeid . <nl> * loggerpostfixaware interface introduced <nl> * loggernodeidaware interface deprecated,this pr adds an ability for ignite-related application to specify string log file postfix instead of nodeid . <nl> it will allow those applications to store their own log files near ignite logs . <nl> * loggerpostfixaware interface introduced <nl> * loggernodeidaware interface deprecated,1616532519,fix servicedescriptor.serviceclass failure in case of deployed via deploymentspi service .,0.9255200028419495
neo4j_neo4j/11403,"memorize computed nanosofdayutc in timevalue . <nl> such value will be adjusted with offset and will not wrap over midnight . <nl> so it will always be in [ 0 , +0 ] hour range . <nl> previously memorized the it was constructed with . <cm-sep> access temporal values in valuewriter . <nl> instead of their serialized form . this makes it easier for different <nl> implementations to use different serialization strategies . <nl> for example property store and schema index convert zoned date and time <nl> to utc . this makes it convenient to compare time/date-time . when bolt <nl> server uses same serialization it forces all clients ( driver ) to convert <nl> from and to utc , which is especially problematic for datetime containing <nl> timezone id . after this change bolt server should be able to send and <nl> receive local time/date-time with timezone information without doing <nl> double conversion . no conversion would then happen in clients . <cm-sep> use epochsecond of localdatetime for zoneddatetime in bolt . <nl> so that values of type ( represented with ) <nl> are not converted to utc . previously bolt server converted <nl> to epochsecond in utc before sending it and expected to <nl> receive value in utc as well . this forced clients to perform a <nl> conversion from utc and to utc . such conversion can be especially hard <nl> with named timezones . now clients will receive unadjusted value which <nl> can be directly converted to and used together with <nl> the timezone info . <para-sep> primary purpose of this class is to share serialization format between property store writer and schema indexes . <nl> version days = 0 days , 0 hours , 0 minutes * /","pr includes following changes : <nl> * fix for to only memorize value in [ -18h , +42h ] range <nl> * now gets access to temporal types from package instead of their numeric representation . this allows different s to use different formats without double conversion <nl> * now prints temporal types as iso strings . it is a and now has access to actual temporal objects which have nice <nl> * bolt server sends and receives local for values . it used to send adjusted to utc which forced drivers to perform additional conversion ( especially tricky for",1522166910,o added test that verifies database does not block writes while populating constraint index . <nl> o verifies that constraint deletion works in ha clusters . <nl> o added test to verify new slave joining cluster properly initializes constraints <nl> o added before/after records for schema commands to allow deleting schema rules from <nl> logical log .,0.9742085933685303
netty_netty/11015,fixed ipv6 address join ipv4 group failed,"motivation : . <nl> when is ipv6 and join a multicast group with ipv4 address will cause ( at least in ) . <nl> modification : . <nl> check if target group address is ipv6 before call . <nl> i 'm not sure if this modification is currect , but i checked source code of java nio . <nl> seems ipv6 address ca n't join ipv4 group except osx . <nl> result : . <nl> test on exception has fixed .",1612957217,create a stackless closedchannelexception to reduce overhead when the channel is closed . <nl> motivation : . <nl> in some benchmarks closing the channel attributes to a lot of overhead due the call of fillinstacktrace ( ) . we should reduce this overhead . <nl> modifications : . <nl> - create a stacklessclosedchannelexception and use it to reduce overhead . <nl> - only call channeloutboundbuffer.failflushed ( ... ) when there was a flushed message at all . <nl> result : . <nl> less performance overhead when closing the channel,0.9280397295951843
prestodb_presto/15205,move data preparation to benchmarkdata for benchmarkpageprocessor,"previously benchmarkpageprocessor filters out 0 % rows , and this makes <nl> project was not tested at all . this pr adds a new option for the <nl> filter to pass all rows so that projection can be tested . it also moves the creation of data and processors into a new inner class benchmarkdata , which allows for easier future parameter based expansions .",1600764096,"* add support for 'insert into select ' <nl> * add support for ctas <nl> * add support for native batch ( parallel ) ingestion <nl> * ingest data from a local holder . <nl> ingest by ctas . <nl> ingest by insert : . <nl> or even more . <nl> limitation : <nl> currently only supports limited data types such as timestamp , varchar , bigint , double and float .",0.9189043641090393
apache_beam/13006,"make read use sdf by default . override in runners . <para-sep> * / <nl> * / <nl> todo ( ) : remove the primitive read and make the splittable dofn the only option . <nl> todo ( ) : remove the primitive read and make the splittable dofn the only option . <nl> * / <nl> * / <nl> note that we specifically perform this replacement since this is what the dataflowrunner does and the dataflowrunner class does not expose a way to perform these replacements without running the pipeline . <nl> mapwithstate read for splittablepardo.primitiveunboundedread , preventing a post-mapwithstate shuffle . <nl> we do n't use create here since create is defined as a boundedsource and using it would cause an infinite expansion loop . we can reconsider this if create is implemented directly as a splittabledofn . <nl> we do n't use create here since create is defined as a boundedsource and using it would cause an infinite expansion loop . we can reconsider this if create is implemented directly as a splittabledofn . <nl> composites should not be visited here . <nl> there are multiple impulses in the graph so we do n't validate that we have n't seen one before .",we add a ptransform override which converts to a new primitive read transform updating the existing read translation logic to only apply to this new primitive read and not to read.bounded/read.unbounded . <nl> a good chunk of this change is fixing up test expectations since the expansion is always using sdf now,1601677980,this allows filtering on nested fields,0.9671258330345154
apache_pulsar/9781,"fix topic ownership is not checked when get topic policy ( target branch version ) . <nl> 0. currently , the api of topic policies does not check the ownership of topic . in the case of multiple brokers , a will appear . <para-sep> setup cluster with 0 broker <nl> for partitioned topic , we can get topic policies from every broker <nl> for non-partitioned topic , we can get topic policies from every broker","in the case of multiple brokers , a will appear . <nl> 0. the parameter validation of the read and write api should not be the same , and the read api should not verify . if is set , the read api will also be abnormal . <nl> 0. general api should not use .",1614759879,"this change introduces a new namespace policy , which will enable an override of broker settings on the namespace level . you may keep disabled for the broker and allow it on a specific namespace using this feature . <nl> - add new namespace policy : and associated api / cli interface for setting and removing . defaults to non-partitioned type , but also allows partitioned topics . <nl> - modifies brokerservice : when checking configuration , the broker first retrieves namespace policies from zookeeper . if the policy exists for that namespace then it uses those settings . if",0.950690507888794
elastic_elasticsearch/70967,fix canmatchprefiltersearchphasetests # testsortshards . <nl> fix test to handle the case where all shards are skipped . <nl> we ensure that we do n't skip all shards in the can match phase <nl> in order to be able to produce an empty result for aggs . <para-sep> we need at least one shard to produce the empty result for aggs,fix test to handle the case where all shards are skipped . <nl> we ensure that we do n't skip all shards in the can match phase <nl> in order to be able to produce an empty result for aggs .,1617006660,the iteration over starts when the cs applier <nl> thread is still running . <nl> since is idempotent we can just call it if we run into a stopped service <nl> on the cs thread to avoid the race with certainty ( because the iteration in starts after <nl> the stopped state has been set ) .,0.8474912047386169
elastic_elasticsearch/70657,"add scriptcompiler interface <para-sep> takes a script definition and returns a compiled script factory <nl> takes a script definition and returns a compiled script factory <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> indicate that this script wants the field call ' test ' , which is the name of this field <nl> painless actually call system.currenttimemillis . we could mock the time but this works fine too . <nl> indicate that this script wants the field call ' test ' , which is the name of this field","typeparser.parsercontext exposes a scriptservice allowing type parsers to <nl> compile scripts from runtime fields ( and in future , index-time scripts ) . however , <nl> scriptservice itself is a fairly heavyweight object , and you can only add script <nl> parsers to it via the plugin mechanism . <nl> to make testing easier , this commit extracts a scriptcompiler interface and makes <nl> that available from parsercontext instead .",1616427275,break the functionregistry monolith into a common ql base and a sql <nl> specific registry that handles aspects such as distinct and extract . <nl> in the process clean-up the names and signature of internal interfaces . <nl> most of the semantics were preserved however the error messages were <nl> slightly tweaked to make them more readable - this should n't be a <nl> problem as they are being used internally mainly in test assertions .,0.9659819602966309
apache_flink/14886,remove unused argument from shutdown ( ) in completedcheckpointstore <cm-sep> update javadoc for completedcheckpointstore.shutdown ( ),"a trivial change to remove unused method argument . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos , zookeeper : no <nl> - the s3 file system connector",1612614970,"fix computed column with escaped keyword can not work . <nl> fix a bug that computed column and escaped keyword can not work together . <nl> - add escape to field name in computed column . <nl> - add java doc to to remind others . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> - catalogtableitcase . testcomputedcolumnwithescapedkeywordfield ( ) . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any",0.7912929654121399
ballerina-platform_ballerina-lang/23513,refactor distinct type id calculation code <cm-sep> limit distinct to error and object type defs <cm-sep> improve jvm typechecker distinct type handling <cm-sep> fix error destructure pattern <para-sep> todo : detail type need to be a union representing all details of members of ` errortype <nl> todo : need to handle intersections <nl> create a new type for distinct type definition such as is different to in a type definition statement that use already defined type as the base type .,also fixes langlib unit tests . <nl> note : destructuring error cause is not yet supported . <nl> fixes # .,1590496773,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9644699096679688
apache_shardingsphere/10144,"refactor postgresqlerrorresponsepacket <para-sep> todo consider what severity to use <nl> create postgresql error response packet builder with required arguments . <nl> set severity non localized . <nl> set detail . <nl> set hint . <nl> set position . the first character has index 0 , and positions are measured in characters not bytes . <nl> set internal query and internal position . the first character has index 0 , and positions are measured in characters not bytes . <nl> set internal query . <nl> set where . <nl> set schema name . <nl> set table name . <nl> set column name . <nl> set data type name . <nl> set constraint name . <nl> set file . <nl> set line . <nl> set routine . <nl> build postgresql error response packet builder . <nl> todo consider what severity and error code to use <nl> todo consider what severity to use <nl> todo add field_type_code for common error and consider what severity to use",changes proposed in this pull request : <nl> - add builder with required arguments for postgresqlerrorresponsepacket .,1618973715,changes proposed in this pull request : <nl> - add unit test for historydatasynctaskgroup <nl> - move spilt logic to historydatasynctaskgroup <nl> - refactor historydatasynctaskgroup,0.9762426018714905
jenkinsci_jenkins/5027,use standardcharsets except deprecated charsets from apache commons,replace usage of deprecated charsets from apache commons by standartcharsets . <nl> just clean code from deprecated entries,1603491583,"> xstream is a generalizing library , it inspects and handles your types on <nl> > the fly . therefore it will normally be slower than a piece of optimised <nl> > java code generated out of a schema . however , it is possible to increase <nl> > the performance anyway : <nl> > - write custom converters for those of your types that occur very often in <nl> > your xml . <nl> > - keep a configured xstream instance for multiple usage . creation and <nl> > initialization is quite expensive compared to the overhead of stream",0.8785340785980225
elastic_elasticsearch/72533,"ensure shards are searchable after creation of a new internal index version . <para-sep> the check for existence is against local cluster state , so very cheap <nl> the index exists but is not ready yet <nl> check if shards are active <nl> the index exists but is not ready yet <nl> simulate the case that 1st the index does not exist , but got created and allocated meanwhile <nl> simulate the case that 1st the index does not exist , but got created , however allocation is pending",ensure shards are searchable after creation of a new internal index version .,1619775720,this adds new plugin level circuit breaker for the ml plugin . <nl> is the circuit breaker qualified name . <nl> right now it simply adds to the breaker when the model is loaded ( and possibly breaking ) and removing from the breaker when the model is unloaded .,0.9626043438911438
apache_beam/13467,supress keyfor for keyedtimerdata in samza,"error occurs when building java . <nl> not occuring on master , but no clear fix in master either",1606946851,"this change is effectively a revert of pr 0 with additional changes needed to remove references to the artifact based naming of projects . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.7699885368347168
apache_kafka/10206,; implement api <para-sep> we filter the state since it is a transient state which indicates that the transactionalid and its metadata are in the process of expiration and removal . <nl> the response should contain only transactionalids that the principal has permission to access . <nl> start a transaction and write to a topic . <nl> first verify that we can list the transaction <nl> now revoke authorization and verify that the transaction is no longer listable <nl> the minimum permission needed is <nl> let new time be smaller ; when transiting from empty the start time would be updated to the update-time <nl> the exhaustive match is intentional here to ensure that we are forced to update the test case if a new state is added . <nl> note that transactions are never returned . this is a transient state which is used when the transaction state is in the process of being deleted ( whether though expiration or coordinator unloading ) .,this is only the server-side implementation and does not contain the api .,1614221973,"this adds a new trogdor fault spec for inducing network latency on a network device for system testing . it operates very similarly to the existing network partition spec by executing the linux utility . this utility was already available in our docker image so no change was needed there . <nl> the spec json looks like : . <nl> the executed command looks like : . <nl> if you find this confounding , you are not alone . here are some resources i used : . <nl> for now this fault spec targets a specific network device , meaning",0.9709497690200806
jenkinsci_jenkins/4667,removed unused deprecated hudsonexceptionnote <cm-sep> removed outdated comment,removed unused class hudsonexceptionnote . <nl> * internal : n/a,1587223403,"details : this fixes for a .groovy file in a plugin with a , specifically by fixing fast-loading via the . <nl> proposed changelog entries : . <nl> * entry 0 : , add findresource for pluginfirstclassloader .",0.8736609220504761
elastic_elasticsearch/71890,wip <cm-sep> wip <cm-sep> changes <cm-sep> changes,currently when the fleet global checkpoints api returns immediately if <nl> the index is not ready or shards are not ready . this commit modifies the <nl> api to wait on the index and primary shards active up until the timeout <nl> period .,1618894500,"we recently rewrote the code to encapsulate the rollover into a single <nl> cluster state . this is great , but we can do a bit better when there are concurrent rollover requests <nl> that occur , specifically , we should meet both of the following criteria : . <nl> - multiple concurrent unconditional rollovers should generate multiple rollovers without any concurrent <nl> modification exceptions . <nl> - multiple concurrent rollovers with conditions should roll over exactly once , assuming the <nl> condition is met only once . <nl> this commit changes the code to reach these goals . it",0.965122401714325
neo4j_neo4j/11185,"read the spacefillingcurveconfiguration from neo4j settings <cm-sep> fix performance bug in numbervalues <cm-sep> improved description for settings <cm-sep> rebased configurable spatial index search onto version . <nl> and simplified by separating maxlevels ( index creation ) setting from <nl> other index search settings , which also reduced the total size of the pr <para-sep> this simply stops at the maxdepth calculated in the maxdepth ( ) function , or if the overlap is over some fraction 0 % ( by default ) at the top levels , but reduces linearly to version ( by default ) when we get to maxdepth . <nl> can be used to build a histogram showing how many ranges were added at which depth .",make creation and searching of the spatial index highly configurable : . <nl> * maxdepth for 2d- > 1d mapping tree <nl> * extralevels for traversal exit <nl> * top and bottom thresholds for early traversal exit,1520418739,- these two classes are used to ensure that version ignores the serial <nl> version uuid on incoming messages and uses the serial version uuid of <nl> the previous neo4j version when in a mixed cluster as part of a rolling upgrade . <nl> - the second part works by capturing the serial version uuid of messages from <nl> the previous from the snapshot message which is sent to an instance when it <nl> first joins a cluster .,0.9629102349281311
netty_netty/11056,fix npe that can happen in the writetimeouthandler when multiple executors are used . <nl> motivation : . <nl> in writetimeouthandler we did make the assumption that the executor which is used to schedule the timeout is the same that is backing the write promise . this may not be true which will cause concurrency issues . <nl> modifications : . <nl> ensure we are on the right thread when try to modify the doubly-linked-list and if not schedule it on the right thread . <nl> result : . <para-sep> check if its safe to modify the ' doubly-linked-list ' that we maintain . if its not we will schedule the modification so its picked up by the executor .. <nl> so let 's just pass outself to the executor which will then take care of remove this task from the doubly-linked list . schedule ourself is fine as the promise itself is done .,fix npe that can happen in the writetimeouthandler when multiple executors are used . <nl> motivation : . <nl> in writetimeouthandler we did make the assumption that the executor which is used to schedule the timeout is the same that is backing the write promise . this may not be true which will cause concurrency issues . <nl> modifications : . <nl> ensure we are on the right thread when try to modify the doubly-linked-list and if not schedule it on the right thread . <nl> result : .,1614799754,httpcontentdecoder must continue read when it did not produce any message and auto read is false . <nl> motivation : . <nl> when httpcontentdecoder ( and so httpcontentdecompressor ) does not produce any message we need to make sure it calls ctx.read ( ) if auto read is false to not stale . <nl> modifications : . <nl> - keep track if we need to call ctx.read ( ) or not <nl> - add unit test . <nl> result : .,0.9272191524505615
confluentinc_ksql/6693,refactors rate limiter within logginghandler to be singleton <para-sep> already validated as having double values <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then :,otherwise the limit is multiplied by the number of server verticles .,1606774535,"was recently enhanced to support any expression , rather than just column references . if the expression expression results in an error , e.g . a udf that throws an exception , this exception was not being handled - resulting in the query being terminated . <nl> udtfs were recently introduced . if a udtf throws an exception , or an exception occurs extracting a udtfs parameters , e.g . if a parameter is a udf that throws , then the exception was not being handled - resulting in the query being terminated . <nl> all these exceptions are now",0.967214822769165
elastic_elasticsearch/72332,"previously , the resetfeaturestatestatus object captured its status in a <nl> string , which meant that if we wanted to know if something succeeded or <nl> failed , we 'd have to parse information out of the string . this is n't a <nl> good way of doing things . <nl> i 've introduced a success/failure enum for status constants , and added a <nl> check for failures in the transport action . we return a 0 if some but not all <nl> reset actions fail , and for every failure , we also return information about the <nl> exception or error that caused it . <cm-sep> fix 0.x backport compilation issues <cm-sep> * remove redundant section of test <nl> * mention in javadoc that we check task index specifically <para-sep> this class represents the response of the feature state reset api . it is a list containing the response of every feature whose state can be reset . the response from each feature will indicate success or failure . in the case of a failure , the cause will be returned as well . <nl> create a new resetfeaturesresponse <nl> a class representing the status of an attempt to reset a feature 's state . the attempt to reset either succeeds and we return the name of the feature and a success flag ; or it fails and we return the name of the feature , a status flag , and the exception thrown during the attempt to reset the feature . <nl> create a resetfeaturestatestatus .","previously , the resetfeaturestatestatus object captured its status in a <nl> string , which meant that if we wanted to know if something succeeded or <nl> failed , we 'd have to parse information out of the string . this is n't a <nl> good way of doing things . <nl> i 've introduced a success/failure enum for status constants , and added a <nl> check for failures in the transport action . we return a 0 if some but not all <nl> reset actions fail , and for every failure , we also return information about the <nl> exception",1619553437,"this commit moves away from the static rollup index <nl> naming strategy and moves towards a randomized rollup index name scheme . <nl> this will reduce the complications that exist if the rollupstep fails and retries <nl> in any way . a separate cleanup will still be required for failed temporary indices , <nl> but at least there will not be a conflict . <nl> this commit generates the new rollup index name in the lifecycleexecutionstate so <nl> that it can be used in rollupstep and updaterollupindexpolicystep on a per-index <nl> basis .",0.9788334965705872
pentaho_pentaho-kettle/7471,"* converting integer to timestamp type using select values step results in incorrect date . <nl> * use envutil instead of system . <nl> * updating copyrights . <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> ( cherry picked from commit sha ) <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> reverting the change in the default behaviour . <nl> by default , timestamp-to-integer returns milliseconds once again . <nl> ( cherry picked from commit sha ) <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> ( cherry picked from commit sha ) <cm-sep> fix tests and checkstyle changes . <nl> ( cherry picked from commit sha ) <cm-sep> sonar recommendations . <nl> ( cherry picked from commit sha ) <para-sep> this environment variable is used to define how timestamp should be converted to a number and vice-versa . <nl> convert milliseconds to nanoseconds ! <nl> if the nullvalue is specified , we try to match with that . <nl> if the polled value is equal to the spaces right-padded nullvalue , we have a match",it may be a good idea not to squash the commits for everyone to see these details .,1590222427,- validating extra parameter value before appending it 's key to url . <nl> - tests written <nl> - checking whether the underlying database for two databaseinterface 's is the same depending on the class hierarchy ( if check by pluginid fails ) .,0.9677106738090515
vespa-engine_vespa/15464,"add class that supports reconfiguring zokeeper <para-sep> starts or reconfigures zookeeper cluster <nl> starts zookeeper server and supports reconfiguring zookeeper cluster . created as a component without any config injected , to make sure that it is not recreated when config changes . <nl> returns items in set a that are not in set b <nl> tests dynamic reconfiguration of zookeeper cluster . <nl> created config has dynamicreconfig set to false <nl> created config has dynamicreconfig set to true <nl> test that equal config does not cause reconfiguration",new class supports reconfiguration . not used yet .,1606307823,this is the final piece to allow users to retrieve metrics via their application 's containers .,0.9827858805656433
vespa-engine_vespa/16337,"remove flag ' endpoint-cert-in-shared-routing ' <cm-sep> always use endpointcertificatemaintainer <cm-sep> unused endpoint certificates are always deleted <cm-sep> hopefully helpful comments <cm-sep> use permanent flag for alternative cert provider <cm-sep> fix assumption in unit test <para-sep> see also endpointcertificatemaintainer , which handles refreshes , deletions and triggers deployments updates refreshed endpoint certificates and triggers redeployment , and deletes unused certificates . see also endpointcertificatemanager , which provisions , reprovisions and validates certificates on deploy",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1612272835,i do n't think this has been used for a long time now ( used by one customer only years ago as far as i know ) .,0.9531984925270081
ballerina-platform_ballerina-lang/26828,"add isolated initial value expr . check for isolated variables <cm-sep> change error message from ' unique expr ' to ' isolated expr ' <cm-sep> disallow accessing isolated variables outside lock statements <cm-sep> fix copying in with clone <cm-sep> restrict copy out in lock with restricted var usage <cm-sep> allow passing values to isolated functions from within isolated object methods <cm-sep> restrict transferring across lock statements with isolated var access <cm-sep> fix more than one restricted var usage analysis <cm-sep> fix transfer in/out analysis with isolated variables <para-sep> analyzed via functions added to module level . <nl> this is used with a stream . <nl> will be validated for that expression . <nl> for lock statements with restricted var usage , invalid transfers and non-isolated invocations should result in compilation errors . this class holds potentially erroneous expression per lock statement , and the protected variables accessed in the lock statement . <nl> test cases related to isolated variables .","an module level variable can be accessed from within an function . such variables can only be accessed within a statement , and rules apply to transferring values in and out of such a statement , similar to objects . <nl> in the current master , a variable reference is considered to be an isolated expression if it is the only reference to the particular variable . the spec defines a variable reference to be an isolated expression if ' it refers to an identifier bound by a let-expr to an expression that is isolated . '",1604950003,this also adds xml attribute support and namespace declaration .,0.979749858379364
elastic_elasticsearch/71239,"use default application credentials for gcs repositories <para-sep> use a closure on the string to delay evaluation until tests are executed * / <nl> application default credentials <nl> fallback to manually load project id here as the above serviceoptions method has the metadata endpoint hardcoded , which makes it impossible to test <nl> this method imitates what metadataconfig.getprojectid ( ) does , but does not have the endpoint hardcoded . <nl> the sdk checks this endpoint to determine if it 's running within google compute engine","adds support for default application credentials for gcs repositories , making it easier to set up a repository on gcp , as all relevant information to connect to the repository is retrieved from the environment , not necessitating complicated keystore setups .",1617378814,"elasticsearch plugins can add a java security policy file to grant <nl> additional permissions . these policy files can contain permission grants <nl> for specific jar files , which are specified through system properties . <nl> unfortunately the java policy parser is lenient when a system property <nl> is missing , meaning we ca n't know if there is a typo or grant for a no <nl> longer relevant jar file . <nl> this commit adds validation to the policy parsing by overriding the <nl> system properties and tracking when a missing system property is used .",0.9437639117240906
apache_shardingsphere/9244,"merge untracked file <cm-sep> in windows environment , initialization of the embedded mysql instance is inconsistent with the ide file system , resulting in failure to instantiate mysql","changes proposed in this pull request : <nl> - fixed : in windows environment , initialization of the embedded mysql instance is inconsistent with the ide file system , resulting in failure to instantiate mysql",1612160623,"in keygeneratorconfigurationyamlswapper.swap ( final yamlkeygeneratorconfiguration yamlconfiguration ) , check whether the type of keygeneratealgorithm is null . <nl> in sharding.xsd , add use= ' required ' on attribute column of element key-generator .",0.8373929262161255
confluentinc_ksql/6344,support for key format . <cm-sep> historical plans,unit and integration tests are expected for any behavior changes._ .,1601555850,"as part of the pull query work the class was removed , but a test class for it remained . this commit cleans that up . <nl> test only change .",0.5197852849960327
apache_incubator-pinot/6007,[ te ] add labeler into yaml <para-sep> calculate the severity for list of anomalies <nl> only set renotify if the anomaly exists and its severity gets higher <nl> merge the anomaly severity <nl> set the highest severity <nl> output detection properties if neither filter and labeler is configured wrap detection properties around with filter properties if a filter is configured <nl> output filter properties if no labeler is configured <nl> wrap filter properties around with labeler properties if a labeler is configured,"this pr is second pr for severity-based alert feature , including the logic of parsing labeler configuration and constructing the detection pipelines based on the yaml .",1599853115,"this pr enables configuration of referencelinks and potential other subscription related settings in the dimensions_alerter_pipeline . for example , this can enable users to configure different oncall-runbooks per anomalous dimension .",0.9690610766410828
grpc_grpc-java/7451,add tostring to show address filter content . <cm-sep> add tostring for lb configs .,"do not implement equals ( ) /hashcode ( ) unless there is a reason to . <nl> there is probably more equals ( ) /hashcode ( ) to be deleted . e.g. , . but its test is relying on its equals ( ) /hashcode ( ) implementation .",1600885777,"testing for grpc components that instantiate a is hard since channel creation is inside 's primary constructor . <nl> introducing , a factory for creating xds channels .",0.9198552966117859
vespa-engine_vespa/16378,scale content clusters to minimum 0 nodes . <nl> there is no cluster controller redundancy with 0 nodes <nl> and this leads to operational problems . <para-sep> returns a copy of the given limits where the minimum nodes are at least the given value when allowed * /,there is no cluster controller redundancy with 0 nodes <nl> and this leads to operational problems .,1612374481,i suggest we do this first and consider handling it in if we <nl> can think of a safe way to update that cache . <nl> reduces test run time in this module by 0 seconds on my machine .,0.9637240171432495
confluentinc_ksql/6659,"remove unused validation code . <nl> is not yet used . however , the code calls when setting the value of a field . this check is not free and is on the critical path . ksqldb is strongly typed , so the only way the type would be wrong would be if a function or deserializer where returning incorrect data , i.e . a bug . we should not pay the production runtime cost of checking _every_ field we set during _every_ record we process . <cm-sep> switch to schema-less ksqlstruct . <nl> no other sql instance types , ( e.g . bigdecimal , string , double , map , list , etc ) , require the schema during instantiation . only the connect type and the ksqldb specific type , which is to be 's replacement , require the schema during construction . this can make working with structs more tricky than other types . <nl> this change removes the requirement to provide the schema when instantiating . the aim is to make this type easier to use . <nl> the type has also been moved into the class . the code base has many types . is specifically a struct field . making this an inner class of helps avoid confusion as to which field type we are talking about .","no other sql instance types , ( e.g . bigdecimal , string , double , map , list , etc ) , require the schema during instantiation . only the connect type and the ksqldb specific type , which is to be 's replacement , require the schema during construction . this can make working with structs more tricky than other types . <nl> this change removes the requirement to provide the schema when instantiating . the aim is to make this type easier to use . <nl> the type has also been moved into the class . the code",1606136842,"interactive & standalone support for multi-statement requests where later statements depend on earlier statements . <nl> this change fixes an issue in interactive and standalone modes where the method would throw when parsing a multi-statement string if later statements relied on earlier statements . some interdependence was supported , e.g . , , , but others were missing . the issue was that the had some post-processing logic in the call that attempted to update the metastore in the same way would . but this logic was incomplete and hence some statements fail . <nl> an example issue would be",0.9684418439865112
apache_shardingsphere/9395,fix the create user syntax of mysql and add the definition of mysql create user statement <cm-sep> code format,fix the create user syntax of mysql and add the definition of mysql create user statement,1612848222,lacks of visitor for . it is necessary to add antlr visitor . <nl> changes proposed in this pull request : <nl> - adds antlr visitor .,0.9585111141204834
ballerina-platform_ballerina-lang/24758,fix anonymous finite types <cm-sep> add annotations to doc search and refactor <cm-sep> fix api docs bugs <cm-sep> fix checkstyle error,> - fix sidebar links in error page .,1594812212,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9461989402770996
apache_pulsar/9546,fix problem caused by concurrent merge,this pr fixes this problem .,1612887293,debezium has released the major version v1.version.final . <nl> * upgrade version of debezium from version to version.final . <nl> local integration test,0.8852466344833374
grpc_grpc-java/7395,"eliminated the logic in cds lb policy that handles cds config change ( aka , cluster name change ) . a cds lb policy should be used for a single cluster , the cluster should be effectively final . if the upstream lb policy needs to change routing cluster , it should create separate cds lb policies , one for each cluster . <nl> this change also reimplemented the unit tests for cds lb policy . <para-sep> load balancer for cds_experimental lb policy . one instance per cluster . <nl> no-op <nl> no-op","eliminated the logic in cds lb policy that handles cds config change ( aka , cluster name change ) . a cds lb policy should be used for a single cluster , the cluster should be effectively final . if the upstream lb policy needs to change routing cluster , it should create separate cds lb policies , one for each cluster . <nl> this change also reimplemented the unit tests for cds lb policy .",1599174872,"a lot of locs here are whitespace changes or removals . <nl> function changes after vs before : . <nl> after <nl> ===== . <nl> binarylog.java is the class that is responsible for intercepting <nl> client and server calls . it now requires a callid to be passed <nl> in . the binarylogprovider is responsible for generating a <nl> callid . <nl> censusbinarylogprovider will generate a callid based on census <nl> info . for the server callid , my intention is to read the census <nl> info from the context . for the client callid , the census span is",0.9665600657463074
apache_kafka/10097,"add fetchsnapshot api doc in kafkaraftclient <para-sep> current leader and epoch ) . unlike partition replication , we also piggyback truncation detection on this api rather than through a separate truncation state . this happens when a fetchresponse includes a snapshot id due to the follower 's log end offset being less than the leader 's log start offset . <nl> send an outbound request message .","more detailed description of your change <nl> currently , we have added fetchsnapshot api in raft , so improve the docs in .",1612959131,"additionally , fixing some javadoc bugs .",0.8845179080963135
vespa-engine_vespa/16400,request metrics async <para-sep> assert that there are more than one hitgroup and that there are only hitgroups on the lowest level <nl> fetches metrics asynchronously for all hosts of an application . this call may be expensive . <nl> a response containing metrics for a collection of nodes . <nl> creates this from a metrics/v2 response * / <nl> consumer 'autoscaling ' defined in com.yahoo.vespa.model.admin.monitoring.metricconsumer <nl> a simple async http client * / <nl> implements the asynchttpclient interface by delegating to an apache http client * / <nl> suppress failures for manual zones for now to avoid noise,we fail to get through all applications in time in us-west,1612461155,"but in hosted it is within a group , we have had some very dirty and incorrect code for reasoning here . <nl> now this is taken care of at constrution of the redundancy object , so that use is identical later on .",0.9778560400009155
vespa-engine_vespa/16855,make controller emit json from secret store validation,this changes the output from the api to be of the following format : . <nl> with an error :,1615292055,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8841582536697388
confluentinc_ksql/5983,"uses pull query metrics for all paths , not just /query <para-sep> record latency at microsecond scale","now it should be used not only on by also the web socket code path . <nl> also , verified locally that it 's now in use .",1597171794,this affects only and classes . <nl> this is a partial refactoring to allow ksql impersonate users for every new request . a follow-up pr will include refactoring the to remove the internal . <nl> add a few tests to validate a is used and closed per request .,0.9680356979370117
vespa-engine_vespa/16181,revert ' add missing new line ' . <nl> this reverts commit sha .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1611407506,"restrict tenant and application names to not have double dashes , upon creation .",0.9012206196784973
hazelcast_hazelcast/18389,fixed an issue of picking a not complete index for hd sql plan . <nl> order global indexes by creation timestamp . as a result the hd map scan picks <nl> the oldest index that has the highest chance to be completely built . <para-sep> sort indexes by creation timestamp . some high-level sub-systems like hd sql optimizer may need the oldest index that has the most chances to be completely constructed and being usable for queries .,order global indexes by creation timestamp . as a result the hd map scan picks <nl> the oldest index that has the highest chance to be completely built .,1615534988,"we are using flush ( ) on imap instance to ensure that all changes have been persisted to our mapstore . however , i 've noticed that the same entries are stored twice ; first on the flush ( ) and then after some seconds due to the mapstore write-behind delay . the reason this is happening is because flush ( ) on concurrentmapmanager does not reset the dirty flag and store time of the record . pull request fixes this , with a modified test to prove it . <nl> another related issue is that flush ( ) does",0.8434849977493286
apache_druid/10452,close aggregators in hashvectorgrouper.close ( ),"there are 0 issues in . <nl> - when is used , is never closed . <nl> - when is used , the same can be used after it is closed since the same instance is used to create s which are . <nl> the von-vectorized groupby engine does n't have this issue because it creates a new per . this pr fixes the issue in by closing the when the outer is closed",1601418705,"adds a druid expression to allow use in and , as well as sql virtual column expression support .",0.9712814092636108
apache_pulsar/9706,[ pulsar transaction ] transaction coordinator metrics .,"this is transaction coordinator metrics , if have another useful metrics , we can add in other pr . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl>",1614223695,"since we can search through entries via publish time efficiently , we do n't need to get return all the entries to presto when there is a predicate concerning publish time . as an optimization when can only return the entries that satisfy the conditions in the predicate .",0.979826033115387
apache_flink/14505,fix the bug that it does't support field access for the result containing python udf in the projection <cm-sep> fix the bug that it does n't support field access of expression containing python udf in the condition of calc <para-sep> rule that splits the rexfield with the input of python function contained in the projection of [ ] s . <nl> rule that splits the rexfield with the input of python function contained in the condition of [ ] s . <nl> test for python scalar function . <nl> test for python scalar function .,"this pull request fix the bug that it does n't support field access of expression containing python udf . <nl> - does this pull request introduce a new feature ? ( no ) <nl> - if yes , how is the feature documented ? ( not applicable )",1609149837,"# # what is the purpose of the change . <nl> introduce new providers and parallelism api . <nl> pr for all public api . <nl> - introduce sourceprovider <nl> - introduce datastreamsourceprovider <nl> - introduce datastreamsinkprovider <nl> - introduce parallelismprovider <nl> - introduce sink_parallelism option . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : yes <nl> - the serializers : no <nl> -",0.944254994392395
vespa-engine_vespa/16452,re-enable junit4 tests . <nl> junit4 tests have been accidentally disabled since junit5 tests were added to this module . <cm-sep> use cheaper ec based crypto material . <nl> shaves ~0 seconds from test runtime,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1612880797,"since we only take the lock on status change , it should be fine to use the <nl> default timeout now .",0.8198102116584778
vespa-engine_vespa/15400,revert ' revert ' upgrade to curator 0 ' ' <para-sep> extends mockbackgroundaclpathandbytesablebuilder,"running a system test worked , please review only .",1605861658,"i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> only the last commit implements the fix . <nl> this is a rather vital part , so we 'd better get it right ....",0.9728711843490601
vespa-engine_vespa/16571,support numberic operation for float <cm-sep> support numberic operation for double <para-sep> equal to query . <nl> greater than or equal to query . <nl> greater than query . <nl> less than or equal to query . <nl> less than query . <nl> in range query . <nl> equal to query . <nl> greater than or equal to query . <nl> greater than query . <nl> less than or equal to query . <nl> less than query . <nl> in range query .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1613640316,"wip , so proper handling of the deployment response is not included .",0.9374078512191772
elastic_elasticsearch/71661,"a countermetric is used to track the number of completed and outstanding <nl> items , for example , the number of executed refreshes , the currently used <nl> memory by indexing , the current pending search requests . in all cases , <nl> the current count of countermetric is always non-negative . <nl> however , as this metric is implemented using a longadder , the returned <nl> count is not an atomic snapshot ; invocation in the absence of concurrent <nl> updates returns an accurate result , but concurrent updates that occur <nl> while the sum is being calculated might not be incorporated . <nl> we can replace longadder with atomiclong , but this commit chooses to <nl> continue using longadder but returns 0 when the sum value is negative . <para-sep> returns the current count of this metric . the returned value is always non-negative . <nl> returns the current count of this metric .","a countermetric is used to track the number of completed and outstanding <nl> items , for example , the number of executed refreshes , the currently used <nl> memory by indexing , the current pending search requests . in all cases , <nl> the current count of countermetric is always non-negative . <nl> however , as this metric is implemented using a longadder , the returned <nl> count is not an atomic snapshot ; invocation in the absence of concurrent <nl> updates returns an accurate result , but concurrent updates that occur <nl> while the sum is being calculated might",1618359177,"this mandates that any passwords that are fed into pbkdf2 must have at <nl> least 0 bits of entropy ( that is , be 0 characters long ) . <nl> this commit updates our keystore cli tests so that tests either : <nl> 0. use a 0+ character password when in fips mode , _or_ <nl> 0. are skipped on fips mode ( because they explicitly test empty <nl> passwords ) .",0.9194257259368896
elastic_elasticsearch/72089,"use the implicit tiebreaker sort value in the next request 's search_after <para-sep> implicit tiebreake , present only in the response and which does n't have a corresponding field <nl> returns the implicit elasticsearch tiebreaker value associated with a pit request for every search hit against which it is run . <nl> except the first request , the rest should have the previous response 's search_after _shard_doc value <nl> for desc ( tail ) sequences only the first criterion is descending the rest are asc , so flip it after the first query","following the recent addition of a default tiebreaker for pit requests , eql sequence queries that use should also include in the list of its values ( a timestamp and an optional eql tiebreaker ) the additional default tiebreaker value .",1619098344,"this commit adds a new api that allows opening reader contexts in a separate step before using them in subsequent search requests . some advantages of this api over the previous approach : <nl> - the flow is clearer : open readers - > use readers in search requests - > close readers <nl> - opening readers separately is faster than with a search request <nl> - better error handling : opening readers requires all shards available , and both and must be provided in search requests .",0.9783688187599182
apache_kafka/9986,"junit extensions for integration tests <para-sep> represents a requested configuration of a kafka cluster for integration testing <nl> raft <nl> cluster type . for now , only zk is supported . <nl> the cluster configuration used to create this cluster . changing data in this instance through this accessor will have no affect on the cluster since it is already provisioned . <nl> if unspecified by those sources , this will return the listener for the default security protocol plaintext <nl> the broker connect string which can be used by clients for bootstrapping <nl> a collection of all brokers in the cluster . in zk-based clusters this will also include the broker which is acting as the controller ( since zk controllers serve both broker and controller roles ) . <nl> a collection of all controllers in the cluster . for zk-based clusters , this will return the broker which is also currently the active controller . for raft-based clusters , this will return all controller servers . <nl> return any one of the broker servers . throw an error if none are found <nl> return any one of the controller servers . throw an error if none are found <nl> the underlying object which is responsible for setting up and tearing down the cluster . <nl> static methods can generate cluster configurations <nl> beforeeach run after class construction , but before cluster initialization and test invocation <nl> aftereach runs after test invocation and cluster teardown <nl> generate1 is a template method which generates any number of cluster configs <nl> any return value from the method is ignore . the method given here must be static since it is invoked before any tests are actually run . that is to say , each generated test invocation will have a separate lifecycle . for scala tests , the method should be defined in a companion object with the same name as the test class . <nl> specify the static method used for generating cluster configs <nl> the type of cluster config being requested . <nl> raft , <nl> the instance represents the underlying cluster being run for the current test . it can be injected into test methods or into the class constructor . n.b. , if injected into the class constructor , the instance will not be fully initialized until the actual test method is being invoked . this is","this pr adds a set of annotations that can be used to generate one or more kafka clusters for integration testing . the primary motivation for this is to reuse existing integration tests for both zk and raft based kafka clusters . a secondary motivation is to refactor the complex test hierarchy that exists and instead provide reusable functionality to tests through helper classes . <nl> a new annotation is introduced which allows for a test to declaratively configure an underlying kafka cluster . <nl> this annotation has fields for cluster type and number of brokers , as well as",1611784598,* added pluginstest file which did not exist before <nl> * removed converter : :configure test case <nl> * removed headerconverter test plugin and test cases <nl> * removed converter types test cases <nl> * removed classloader control test cases .,0.9662737846374512
apache_druid/10449,fix the offset in get of gcp object,there was another bug in the <nl> . offset was being set on the media downloader which is not actually used when is invoked . so setting the offset was a no-op,1601379995,syntax is the same as hive/presto 's .,0.9650139808654785
vespa-engine_vespa/16064,no functional changes <cm-sep> allocate max half of hosts actually available in zone <para-sep> returns true if the given resources could be allocated on any of the given host flavors * /,this switches to use max of hosts actually present in the zone instead .,1610712463,the prefix was used to separate between disk ( platform ) and file distribution ( application ) bundles . they are now in separate configs . <nl> the has a temporary workaround to handle old models that produce config with the prefix .,0.9284544587135315
jenkinsci_jenkins/5014,add equals and hashcode methods to implementation of parametersdefinition <cm-sep> equals working strictly only for same classes <cm-sep> create tests for comparison,declarative jenkins pipelines have to compare parametersdefinition from job configuration and pipeline for making a decision about updating configuration and save it on disk . <nl> the current implementation compares instances of parametersdefinition serialized to xmls because previously was n't implemented in parametersdefinition implementations . <nl> so this change should improve the performance of starting pipelines . <nl> add equals and hashcode to parameterdefinition implementations <nl> * entry 0 : equals working strictly only for the same classes to preventing issues with extended classes,1602957773,- google spreadsheet to explain the performance improvement . <nl> there are multiples methods that are impacted depending on the scenario . <nl> initial situation : the with glob was used . this means it list all the file recursively using ant library . _this invocation is done on the master directly._ <nl> : the correction added a check for every files if they are descendant of the root ( = workspace / artifact base folder ) . _the check was done on the master._ . <nl> this pr proposes to replace this method by recursive listing of file (,0.9600088596343994
jenkinsci_jenkins/4921,avoid anonymous class warning for huston.filepath $ 0,i can see on logs : . <nl> so this topic ( usages-in-remoting ) applies to fix the problem <nl> . <nl> * avoid warning on logs about anonymous class in hudson.filepath,1598887253,"details : this fixes for a .groovy file in a plugin with a , specifically by fixing fast-loading via the . <nl> proposed changelog entries : . <nl> * entry 0 : , add findresource for pluginfirstclassloader .",0.8658531308174133
apache_flink/15175,refactored prometheus metric reporters to use constructor initialization,clean-up for the initialization of the two prometheus metric reporters ( and ) by explicitly passing in arguments to the constructors as opposed to relying on resolving these values via the internal configuration properties . <nl> - removed argument resolution against defaults from the functions and instead resolved those within the factories and passed them into the respective reporter instances ( roughly modeled after the implementation ) . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl>,1615611091,"# # what is the purpose of the change . <nl> now hiveoptions is used for globalconfiguration.loadconfiguration ( ) . <nl> it is not natural for table , we should use configuration from tablefactory to enable table config . <nl> modify to read config from . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> -",0.9493553638458252
elastic_elasticsearch/70479,"disallow object creation without use . <nl> analogous to int , string and other literals , disallow creating a <nl> new object without using it in a bare statement . <nl> additionally , if a new object is created , always the result <nl> of so that when we at the end of the statement , there 's always <nl> something to . <para-sep> always dup so that visitstatementexpression 's always has something to pop <nl> ensure that new object creation without a read does not fail .","if a new object is created , always the result <nl> of so that when we at the end of the statement , there 's always <nl> something to .",1615940651,this pr introduces a distinction between the failures caused by where-filtering with aggs <nl> vs having-filtering with missing aggs and improving the error messaging around that .,0.9034866690635681
jenkinsci_jenkins/4587,"exclude 'untagged- ... ' tags , update message when tag is n't found <cm-sep> update at-since up to and including version","also update the script to deal with tags . <nl> none , internal",1584365033,* entry 0 : replaced text references to ' slave ' with ' agent ' in various comments and test references .,0.8785989880561829
Alluxio_alluxio/10962,"enable location fallback <para-sep> when no matching , all workers will be returned <nl> when no matching & no ufs locations , all workers will be returned","some applications ( e.g . presto ) require the block locations not empty otherwise the jobs will fail . when the path does n't have alluxio locations or ufs locations , always return the full worker locations .",1582232925,do not throw exception when loading metadata on a non-existing file/dir .,0.8168097138404846
apache_pulsar/8948,"support topic-level max subscriptions <para-sep> init cache <nl> set max subscriptions <nl> remove max subscriptions <nl> set invalidate value <nl> init cache <nl> set topic-level max subscriptions <nl> set namespace-level policy , but will not take effect <nl> removed topic-level policy , namespace-level should take effect <nl> removed namespace-level policy , broker-level should take effect <nl> clean up <nl> get the max number of subscriptions for specified topic . <nl> get the max number of subscriptions for specified topic asynchronously . <nl> set the max number of subscriptions for specified topic . <nl> set the max number of subscriptions for specified topic asynchronously . <nl> remove the max number of subscriptions for specified topic . <nl> remove the max number of subscriptions for specified topic asynchronously .",0.verify that the policy of each level is correct,1607934111,"we do n't know if it is disabled or using broker-level configuration . <nl> the ttl of the namespace-level can be set to null , which means it does not exist . it is consistent with topic-level ttl .",0.9739077091217041
runelite_runelite/12335,add iorweth warriors ( priff dungeon ) to list of targets for elves,"an update in april added elves in the iorweth slayer dungeon , but these are n't tagged correctly in runelite as they 're iorweth warriors . added iorweth warriors to the list of elves in the slayer plugin .",1597361243,the solution is to add an entry to the 's whitelist .,1.0
ballerina-platform_ballerina-lang/26663,introduce dummy listener for module <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests <cm-sep> enable tests,use this listener for testing in the ballerina-lang repository ( replacement for http listener ) .,1603919955,"0 ) update the struct initializer invocation order . now the default literal values are initialized first , then the initializer function , and then the struct literal <nl> 0 ) improve the type checking algorithm to consider the struct initializers when checking the equivalency of two structs .",0.9206475019454956
netty_netty/11049,ensure removal from queue happens before writeandflush ( ... ) is called . <nl> motivation : . <nl> we need to ensure that we call queue.remove ( ) before we cal writeandflush ( ) as this operation may cause an event that also touches the queue and remove from it . if we miss to do so we may see nosuchelementexceptions . <nl> modifications : . <nl> - call queue.remove ( ) before calling writeandflush ( ... ) <nl> - add unit test . <nl> result : . <para-sep> we need to remove the element from the queue before we call writeandflush ( ) as this operation may cause an action that also touches the queue . <nl> calling close so we will drop all queued messages in the chunkedwritehandler .,motivation : . <nl> we need to ensure that we call queue.remove ( ) before we cal writeandflush ( ) as this operation may cause an event that also touches the queue and remove from it . if we miss to do so we may see nosuchelementexceptions . <nl> modifications : . <nl> - call queue.remove ( ) before calling writeandflush ( ... ) <nl> - add unit test . <nl> result : .,1614672653,"motivation : . <nl> the may cache the received messages in a queue in order to do the flow control . however , if this handler is manually removed from pipeline during runtime , those cached messages might not be passed to the next channel handler forever . <nl> modification : . <nl> dequeue all these cached messages and call in method . <nl> result : <nl> avoid losing the received messages .",0.9070658087730408
ballerina-platform_ballerina-lang/26573,run df and isolation analysis for langlib modules <cm-sep> temporarily undo marking conditionally isolated stream langlib methods as isolated,"had to temporarily unmark certain conditionally isolated stream langlib methods as isolated , since the analysis fails for code written in ballerina .",1603528297,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.815228283405304
apache_incubator-pinot/6119,add code for v2 broker api <cm-sep> change v1 methods to use v2 signature,"add a new api in the controller . this api is an improvement over the previous api in the sense , that host and port are supplied along with the instance name . the plan is to deprecate the older api in the future . <nl> the change is being done so that the query clients such as jdbc and java client using this api do n't have to rely on the hack of splitting the instance name to fetch hostname and port . the splitting can result in incorrect hosts in case the pinot cluster is deployed in a",1602145266,"in this mode , offline segments are overwritten in a regular basis using the same segment names . we observed timeboundaryinfo ( tbi ) is not updated and advanced to reflect the max ( secondssinceepoch ) in the offline tables . because the tbi is stale , the data in offline segments will eventually dropped out of the combined query results . <nl> by default ( i.e. , if the table config does not have custom config banning direct message ) , the controller only sends messages to servers for segment reload but it does not ask brokers to refresh",0.9746915102005005
netty_netty/10795,<para-sep> negative index <nl> negative length <nl> buffer length oversize <nl> buffer length oversize <nl> negative srcindex <nl> src length oversize <nl> src length oversize,motivation : . <nl> passing a null value of byte [ ] to the would cause the jvm crash . <nl> modification : . <nl> add null checking before calling . <nl> result : .,1605115708,correctly calculate the produced bytes in all cases when calling referencecountedopensslengine.wrap ( ... ) . <nl> motivation : . <nl> we did not correctly account for produced bytes when ssl_write ( ... ) returns 0 in all cases . this could lead to lost data and so a corrupt ssl connection . <nl> modifications : . <nl> always ensure we calculate the produced bytes correctly . <nl> result : .,0.9188897013664246
OpenAPITools_openapi-generator/8183,"first commit parameterzied server support <cm-sep> fixed serverconfig classes <cm-sep> defautl constructor f. config , fixed regex replace <cm-sep> polosihed templates , added multiserver support <cm-sep> update readme . fixed multiserver . fixed def . value <cm-sep> passing global server to mustache . small fixes <cm-sep> updated samples , fixed mustache for multi server <para-sep> representing a server configuration .","this pr will enable multi server and parameterized server support for qt5 generator . <nl> it uses similar classes like java does . <nl> there are getter and setter functions to choose between the different servers and to change the server attributes that are provided in the server object . <nl> every endpoint can have its own server with arbitrary variables . <nl> if no server is provided , the global server will be used . <nl> there are two new classes : and . <nl> a stores an url , a description and a that stores all variables and",1607968853,- add helpers for primitive de-serialization <nl> - remove warnings due to unneeded commas <nl> - deserialize basic types in queries <nl> - add dependencies chain for external libraries <nl> - fixes wrong parameter passed to api handler <nl> - splitted the serialization of primitive types which are not handled by the json library .,0.9175697565078735
apache_beam/12653,centralized wildcardtoregex and doubleslashes methods <cm-sep> fixed an error in the doubleslashes method <cm-sep> added test code <para-sep> expands glob expressions to regular expressions . this method is intended for internal usage and does not guarantee backwards compatibility . <nl> one char lookahead for * * <nl> these need to be escaped in regular expressions <nl> emit the next character without special interpretation <nl> a backslash at the very end is treated like an escaped backslash,i moved code translated globs to regular expressions that was duplicated in several filesystems to a central location . i also fixed a bug in the method,1597974690,follow this checklist to help us incorporate your contribution quickly and easily : .,0.8621573448181152
confluentinc_ksql/6043,move physicalschema to common module <cm-sep> update queryschemas to contain physical schema <cm-sep> fix spec files with malformed names <cm-sep> correct directory naming for historic plans <cm-sep> regenerate specs with new format <para-sep> physical ksql schema . the physical ksql schema is a combination of a logical schema and the serialization options used to control the serialized form .,"this pr updates the ' schemas ' field of qtt historic plan specs so that instead of storing the persistence schema of the value for each source , the field now stores the logical schema and any serde options for the source . in doing so , the physical schema for both keys and values are captured . <nl> this pr also moves physicalschema from ksqldb-serde into ksqldb-common , and fixes some inconsistencies with existing historic plan specs . <nl> there are also some no-op re-ordering changes which are surprising since the order of sources should be fixed . this",1597727551,"instead of passing in multiple injectors , i mask them in a single . this will also enable future work if we need to add more injectors to the chain .",0.9766913652420044
Alluxio_alluxio/10891,support external stores which may not return full pages in one read . <cm-sep> add unit test . <para-sep> cache miss <nl> cache hit <nl> this implementation may not serve the full read in a single call . <nl> creates an fileinstream that may not serve read calls in a single call .,this is consistent with inputstream 's api .,1581465781,"skipping data from an inputstream used to fetch data from remote storage . now instead , a new stream is opened starting at the desired position .",0.9699360728263855
vespa-engine_vespa/15486,"setup components and config for container cluster when zookeeper is configured <para-sep> note : default client and server ports are used , so not set here","setup components and config for container cluster when zookeeper is configured . <nl> feature flag probably needed only short-term the way it is done now , but might be useful when we start testing this",1606399947,"this fixes . <nl> most of this code is to generate a helpful error message by printing ( the start of ) of the offending document . <nl> also removed a case where could be : i 'm not quite sure how this is possible , as long as we find a document id , should be ?",0.9233757257461548
apache_kafka/9902,": re-resolve ips after a client disconnects . <nl> this patch changes the networkclient behavior to resolve the target node 's hostname after disconnecting from an established connection , rather than waiting until the previously-resolved addresses are exhausted . this is to handle the scenario when the node 's ip addresses have changed during the lifetime of the connection , and means that the client does not have to try to connect to invalid ip addresses until it has tried each address . <para-sep> if a connection had previously been established , clear the addresses to trigger a new dns resolution because the node ips may have changed <nl> for testing nodes with a single ip address , use localhost and default dns resolution <nl> for testing nodes with multiple ip addresses , mock dns resolution to get consistent results <nl> connect to one the initial addresses , then change the addresses and disconnect <nl> we should have tried to connect to one initial address and one new address , and resolved dns twice <nl> refuse first connection attempt <nl> first connection attempt should fail <nl> second connection attempt should succeed <nl> we should have tried to connect to two of the initial addresses , none of the new address , and should only have resolved dns once <nl> refuse first connection attempt to the new addresses <nl> connect to one the initial addresses , then change the addresses and disconnect <nl> first connection attempt to new addresses should fail <nl> second connection attempt to new addresses should succeed <nl> we should have tried to connect to one of the initial addresses and two of the new addresses ( the first one failed ) , and resolved dns twice , once for each set of addresses","this patch changes the networkclient behavior to resolve the target node 's hostname after disconnecting from an established connection , rather than waiting until the previously-resolved addresses are exhausted . this is to handle the scenario when the node 's ip addresses have changed during the lifetime of the connection , and means that the client does not have to try to connect to invalid ip addresses until it has tried each address .",1610671192,"producer adds a topic to its metadata instance when send is requested . if metadata request for the topic fails ( e.g . due to authorization failure ) , we retain the topic in metadata and continue to attempt refresh until a hard-coded expiry time of 0 minutes . as a result , the producer remains unusable for 0 minutes if a send is requested on an unauthorized topic . this pr fails send only if metadata for the topic being sent to has an error ( or there is a fatal exception like authentication failure ) . <nl> consumer",0.9691318273544312
apache_pulsar/9615,pulsar-client-tools supports end-to-end encryption <para-sep> make sure subscription has been created,i enabled the command to encrypt message payloads . <nl> how to use :,1613642578,"if is set to 0 , consumer using message listener can not receive any messages . <nl> i think there are two causes : . <nl> - the consumer does not send flow command when the connection has been opened <nl> - even if the client receive a message , the message is not added to so the listener can not handle it . <nl> if the queue size is zero and the message listener is registered , . <nl> - the client sends a flow command when the connection has been opened <nl> - the received message is passed",0.9273561239242554
apache_shardingsphere/9572,add grammar for create table . <cm-sep> add grammar for create table . <cm-sep> add grammar for create table .,changes proposed in this pull request : <nl> - add relational table grammar in 'create table ' .,1614743847,changes proposed in this pull request : <nl> - adjust threadpool size in asyncload,0.8581675887107849
netty_netty/11089,continue reading when the number of bytes is less then the configured number of bytes when using datagramchannels . <nl> motivation : . <nl> in our fixedrecvbytebufallocator we dont continue to read if the number of bytes is less then what was configured . this is correct when using it for tcp but not when using it for udp . when using udp the number of bytes is the maximum of what we want to support but we often end up processing smaller datagrams in general . <nl> modifications : . <nl> - add new static method to fixedrecvbytebufallocator that should be used for datagramchannels <nl> - use this new static method <nl> - add unit test . <nl> result : . <nl> read more then once in the general case for datagramchannels with the default config <para-sep> we use the true_supplier as it is also ok to read less then what we did try to read ( as long as we read anything ) . <nl> we use the true_supplier as it is also ok to read less then what we did try to read ( as long as we read anything ) . <nl> we use the true_supplier as it is also ok to read less then what we did try to read ( as long as we read anything ) .,continue reading when the number of bytes is less then the configured number of bytes when using datagramchannels . <nl> motivation : . <nl> in our fixedrecvbytebufallocator we dont continue to read if the number of bytes is less then what was configured . this is correct when using it for tcp but not when using it for udp . when using udp the number of bytes is the maximum of what we want to support but we often end up processing smaller datagrams in general . because of this we should use continereading ( uncheckedbooleansupplier ) to determite if,1615813595,motivation : <nl> sslhandler currently throws a general sslexception if a wrap attempt <nl> fails due to the sslengine being closed . if writes are queued the <nl> failure rational typically requires more investigation to track down the <nl> original failure from a previous event . we may have more informative <nl> rational for the failure and so we should use it . <nl> modifications : <nl> - sslhandler # wrap to use failure information from the handshake or prior <nl> transport closure if available . <nl> result : <nl> more informative exceptions from sslhandler # wrap if the sslengine,0.8785756826400757
Alluxio_alluxio/11146,add logging when rpc or fuse calls too long,by setting two new properties . <nl> fuse or client-side rpc calls taking too long will be logged in warn level like the following :,1583735941,make jetty to extract web resources to a non system temp folder .,0.9248560070991516
apache_incubator-pinot/6096,add upsert related configs <para-sep> names of the columns that used as primary keys todo ( yupeng ) : add validation checks like duplicate columns and use of time column,"- added the primary key definition in the schema <nl> - changed the upsert config in table config . for the first phase , only support the full update mode . <nl> does this pr otherwise need attention when creating release notes ? things to consider : <nl> - new configuration options <nl> configurations related to upsert . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1601670260,"the refactoring has two purpose : <nl> 0. users do not need to update anomaly result manually : the classify method now returns only the issue type for the given anomaly . the update is performed by classification pipeline . <nl> 0. simplify the implementation of classify method because it takes one main anomaly at at time . therefore , users do not need to manually go through the list of main anomaly . <nl> test on local controllers .",0.9507538080215454
elastic_elasticsearch/72493,"grid aggregations with bounds should exclude touching tiles <para-sep> touching hashes are excluded <nl> compute minx , miny <nl> touching tiles are excluded , they need to share at least one interior point <nl> compute maxx , maxy <nl> touching tiles are excluded , they need to share at least one interior point <nl> cases . <nl> return a point within the bounds of the tile grid <nl> avoid numerical errors for sub-atomic values",the geo_point was implemented different and it was using the actual bounds to filter points which is not the right behaviour . the bounds on a geogrid aggregation filter the tiles it can generate but should not look into the actual points .,1619710279,"this commit changes how cache files synchronization interacts with <nl> the persistent cacge in searchable snapshots . before this change it <nl> was possible that synchronization reintroduces information about <nl> an evicted cache file in the persistent cache lucene index . <nl> this commit introduces an queue of cache file events that are <nl> periodically processed by the cache synchronization method . the <nl> events refer to a specific cache file and a type of event ( deletion or <nl> fsync needed ) that must be processed by the cache synchronization <nl> method , which in turn applies the appropriate",0.9781578779220581
OpenAPITools_openapi-generator/8110,"fix indexoutofboundsexception with no model <para-sep> alias to number , string , enum , etc , which should not be generated as model for pythonclientcodegen , all aliases are generated as models",fix indexoutofboundsexception when the spec does n't contain any model definitions .,1607311821,"without this pr , the generated code is as below . there are two problems : 0 ) the type of the requestbody argument is wrong ( it should be syslogpolicy , not policyabstractpolicy ) ; 0 ) the type of the requestbody argument uses generics . <nl> with this pr , the generated code is as follows , it fixes both problems : . <nl> this is not ready to be merged , but i need a bit of guidance to make progress .",0.8468748927116394
apache_druid/10481,fix json format <cm-sep> change all columns in sys segments to be json <cm-sep> change all columns in sys segments to be json <para-sep> is_published is false for unpublished segments is_available is assumed to be always true for segments announced by historicals or realtime tasks <nl> there is an assumption here that unpublished segments are never overshadowed,make sure all fields in sys.segments are json-serialized . <nl> this pr : <nl> - make sure all fields in sys.segments are json-serialized . this is to be consistent with other sys tables such as spec in sys.supervisors . this is also more standardized and prevent things like changing java class name from having end user impact ( as our contract is to maintain compatibility of the json-serialized string ) . <nl> - make all columns use the same casing,1601936120,"currently computes the available number of task slots for compaction based on the number of running compaction tasks , i.e. , total number of task slots - number of running compaction tasks . this pr is to consider pending and waiting compaction tasks as well to compute more accurate available compaction task slots . <nl> this change is .",0.8661473393440247
apache_shardingsphere/9064,alter index and drop index in oracleddlstatementsqlvisitor .,changes proposed in this pull request : <nl> - fix : alter index and drop index in oracleddlstatementsqlvisitor . <nl> - <nl> -,1610886119,changes proposed in this pull request : <nl> - try to extract sharding columns from target config if it 's available . <nl> - fix npe bug in datasourceconfiguration.getdatabasetype ( ) . <nl> - update usage document .,0.9070723056793213
apache_kafka/10153,": fix potential resource leak in kafka * backingstore . <nl> these kafkabackingstore classes used in connect have a recently-added deprecated constructor , which is not used within ak . however , this commit corrects a adminclient resource leak if those deprecated constructors are used outside of ak . the fix simply ensures that the adminclient created by the “ default ” supplier is always closed when the kafkabackingstore is stopped . <para-sep> create our own topic admin supplier that we 'll close when we 're stopped <nl> create our own topic admin supplier that we 'll close when we 're stopped <nl> create our own topic admin supplier that we 'll close when we 're stopped","these kafkabackingstore classes used in connect have a recently-added deprecated constructor , which is not used within ak . however , this commit corrects a adminclient resource leak if those deprecated constructors are used outside of ak . the fix simply ensures that the adminclient created by the “ default ” supplier is always closed when the kafkabackingstore is stopped .",1613675158,"two more edge cases i found producing extra taskcorruptedexception while playing around with the failing eos-beta upgrade test ( sadly these are unrelated problems , as the test still fails with these fixes in place ) . <nl> 0. need to write the checkpoint when recycling a standby : although we do preserve the changelog offsets when recycling a task , and should therefore write the offsets when the new task is itself closed , we do not write the checkpoint for uninitialized tasks . so if the new task is ultimately closed before it gets out of the created",0.8993617296218872
apache_incubator-pinot/5861,[ te ] merge time series snapshot when merging anomalies <para-sep> combine time series snapshot of parent and child anomalies <nl> a helper function to merge time series snapshot of two anomalies . this function assumes that the time series of both parent and child anomalies are aligned with the metric granularity boundary . <nl> use the values in parent anomalies when the time series overlap,this pr is to provide quick fix for merging time series snapshot when merging anomalies .,1597367739,"as the anomaly timelines view is also stored along with the anomaly result , we occasionally see exception of json_value overflow . main reason is because of the size of anomaly timelines view stored in the system . to tackle this problem , we compress the view and save more space .",0.927963137626648
apache_shardingsphere/9897,revert commit <para-sep> load users . <nl> get users path . <nl> convert users from yaml content . <nl> configuration converter for yaml user content . <nl> convert to users yaml content . <nl> convert to sharding sphere users . <nl> convert to yaml user configurations . <nl> convert to yaml user configuration . <nl> user yaml swapper .,- new yaml configuration for authentication of shardingproxy,1617247738,"- change encrypt derived columns ' sequence as cipher column , assisted query column , plain column for insert/update set with logic encrypt column . <nl> - keep insert values 's derived columns ' sequence with original one , which is append into generated key column .",0.9786560535430908
apache_flink/14652,option 'canal-json.database.include ' and 'canal-json.table.include ' support regular expression <para-sep> pattern of the specific database . * / <nl> pattern of the specific table . * /,currently canal format option 'canal-json.database.include ' and 'canal-json.table.include ' do n't support regular expression to match . it 's necessary to use regular expression to match the field 'database ' and 'table ' of canal binlog record . <nl> - matches the field 'database ' and 'table ' of canal binlog message using regular expression for canal format option 'canal-json.database.include ' and 'canal-json.table.include ' . <nl> - modifies the test case to use regular expression for option 'canal-json.database.include ' and 'canal-json.table.include ' to verify the regular matching of the field 'database ' and 'table ' of canal binlog record .,1610633992,"* support optional retention policy for influxdb metric reporter ( currently only default is allowed ) . <nl> * added support for retention policy specification for influxdb metrics reporter along with supporting tests and documentation . <nl> this change added tests and can be verified as follows : . <nl> * running the unit test suite . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths",0.9148104786872864
elastic_elasticsearch/70934,"data stream rollover retries backing index name collisions , cluster metadata no longer attempts to ensure that indices or aliases can not conflict with future backing index names for data streams <cm-sep> move datastreamtesthelper to org.elasticsearch.cluster.metadata to facilitate testing <cm-sep> add/fix new unit test <cm-sep> remove or update tests for metadata : :validatedatastreams <para-sep> visible for testing","if a naming conflict for a new write index is detected when a data stream rolls over , it will now increment its own generation until the new write index 's name does not conflict with any other indices , aliases , or data streams . this allows us to remove the trappy validation around name conflicts for the backing indices of data streams .",1616788413,"* removed custom data stream timestamp field validation and reuse the validation from and <nl> instead only check that the _timestamp field mapping has been defined on a backing index of a data stream . <nl> * moved code that injects _timestamp meta field mapping from method <nl> to method . <nl> * only apply _timestamp meta field if index is created as part of a data stream or data stream rollover , <nl> this fixes a docs test , where a regular index creation matches ( logs- * ) with a template with a data stream definition .",0.9363747239112854
vespa-engine_vespa/15264,reapply changes from original pr <cm-sep> vespazookeeperserver component is not available on clustercontroller <cm-sep> add documentaccess provider if reindexing is configured <para-sep> context required to configure automatic reindexing for a given cluster controller cluster ( for a given content cluster ) .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605028924,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9810966849327087
Alluxio_alluxio/11112,[ do not merge ] turn transform definition into configuration style <para-sep> accept semicolon as new lines for inline definitions <nl> the only way this throws an ioexception is if the definition is null which is n't possible . <nl> the definition of the compact action . <nl> expected number of files after compaction . <nl> default file size after coalescing . <nl> factory to create an instance .,definitions now must be parseable using properties.load ( ) after the semicolons have been replaced with new lines .,1583275581,"move getconfiguration ( scope ) to configurationutils since its <nl> types are specific to certain usages . <nl> implement configuration # keyset ( ) and use it as the basis for <nl> all other methods which act on all keys . <nl> after the configuration changes , started failing due to strange internal errors within . i 've addressed this by not using in",0.9847911596298218
confluentinc_ksql/6212,"extend serde benchmark to include all formats and key serde . <nl> enhances the serde benchmarks beyond just testing and formats via the to include , and formats and test key serde via the . <para-sep> single_key + protobuf excluded as pb is n't yet supported for single key schemas <nl> impressions + kafka excluded as kafka does not support multiple columns <nl> metrics + delimited_format excluded as delimited does not support complex types metrics + kafka excluded as kafka does not support multiple columns <nl> benchmark the key serde : <nl> benchmark the value serde : <nl> choose arbitrary key","enhances the serde benchmarks beyond just testing and formats via the to include , and formats and test key serde via the .",1600257795,"( previous releases created the command topic with default retention , which is likely to cause loss of command messages over time ) .",0.9758275747299194
elastic_elasticsearch/72535,"while looking at the test i noticed that <nl> - autofollowit extends esccrresttestcase which does not wipe <nl> clusters between tests ; <nl> - multiple tests use the same auto-follow pattern logs- * ; <nl> - tests do not always clean up indices/datastreams/auto-follow patterns <nl> on all test clusters , specially when the test fails and leaves existing <nl> resources that can conflict with subsequent tests . <nl> therefore i am <nl> committing some changes to add clean up logic for tests in <nl> blocks . it also changes the logs- * patterns for data streams tests <nl> so that they are not conflicting anymore . <para-sep> create auto follow pattern <nl> create data stream and ensure that is is auto followed first rollover and ensure second backing index is replicated : second rollover and ensure third backing index is replicated : <nl> initialize data stream prior to auto following <nl> create auto follow pattern <nl> rollover and ensure only second backing index is replicated : <nl> explicitly follow the first backing index and check that the data stream in follow cluster is updated correctly : <nl> create auto follow pattern <nl> create data stream and ensure that is is auto followed rollover in leader cluster and ensure second backing index is replicated : try rollover in follow cluster <nl> unfollow .ds-logs-tomcat- <nl> try again <nl> promote local data stream <nl> try again and now the rollover should be successful because local data stream is now : <nl> todo : verify that following a backing index for logs-tomcat-prod data stream in remote cluster fails , because local data stream is n't a replicated data stream anymore . unfollow .ds-logs-tomcat- , which is now possible because this index can now be closed as it is no longer the write index . <nl> create auto follow pattern <nl> create leader index and write alias : rollover in leader cluster and ensure second backing index is replicated : try rollover in follow cluster , this should fail , because is_write_index property of an alias is n't replicated to follow cluster . <nl> create auto follow pattern in follow cluster <nl> create auto follow pattern in leader cluster : <nl> first add remote cluster to leader cluster : <nl> then create the actual auto follow pattern : <nl> create data stream in leader cluster and ensure it is followed in follow cluster todo :","while looking at the test i noticed that <nl> - autofollowit extends esccrresttestcase which does not wipe <nl> clusters between tests ; <nl> - multiple tests use the same auto-follow pattern logs- * ; <nl> - tests do not always clean up indices/datastreams/auto-follow patterns <nl> on all test clusters , specially when the test fails and leaves existing <nl> resources that can conflict with subsequent tests . <nl> therefore i am <nl> committing some changes to add clean up logic for tests in <nl> blocks . it also changes the logs- * patterns for data streams tests <nl> so that",1619776050,= > removed it and made the test use other primitives as a replacement .,0.9078145027160645
quarkusio_quarkus/14563,securitycontext is application scoped . <nl> injection of the securitycontext will result in using <nl> the same securitycontext for all requests . <cm-sep> security fixes for resteasy reactive . <nl> - add ability to deny access to unannotated endpoints <nl> - make sure setsecuritycontext changes the current identity <nl> - port tests from resteasy extension,- add ability to deny access to unannotated endpoints <nl> - make sure setsecuritycontext changes the current identity <nl> - port tests from resteasy extension,1611549820,implement its for the mailer extension . <nl> verify the behavior in both jvm and native mode .,0.9727969169616699
apache_druid/10277,"make dimension column extensible with complex type <para-sep> if valuetype is complex , then the typename associated with it . <nl> note : things might be simpler if dimensionschema had a method ' getcolumncapabilities ( ) ' which could return type specific capabilities by itself . however , for various reasons , dimensionschema currently lives in druid-core while columncapabilities lives in druid-processing which makes that approach difficult .","~~ tag is added because i am still in the process of testing it more thoroughly , however code in current patch is working in preliminary testing . i will also try and add some uts for the changes . that said , code is totally reviewable.~~ <nl> # # # description . <nl> this patch adds support for adding complex type dimension column via extensions , similar support for metric columns exist . <nl> main changes are to add in interface and to add to enable extensions to register custom type specific , very similar to existing . <nl>",1597355019,this pr would allow clients submitting api requests for or tasks that utilize the http firehose to optionally specify username/password credentials within the json block of the spec . the credentials will be used to authenticate against uris which require basic authentication in order to successfully submit a get request to said uris . <nl> the change would not break any existing client code that uses the http firehose because omitting the new json key : value pairs from relevant json requests will result in the code acting as it did before this change : . <nl> - if the,0.9684647917747498
confluentinc_ksql/6556,fix spotbugs errors <cm-sep> fix spotbugs errors,"fix four findbugs ( and clean up code a little ) . <nl> question is ... why is our build not failing , given we have findbugs errors ? could it be that spotbugs is missing this check ? <nl> update : . <nl> ran locally without this fix and spotbugs did not report any issues ... which is bad ! <nl> here 's an example of the error in question : . <nl> note how is unintentionally being passed as a third parameter to rather than as a second parameter to the exception constructor . <nl> findbugs does find",1604336507,"with this change users can now supply just the key schema and use schema inference to get the value columns . for example , if the key is an serialized using kafka 's and the value is an avro record with the schema stored in the scheme registry , then such a stream can be registered in ksqldb with a statement such as : . <nl> qtt tests added .",0.9429593682289124
Alluxio_alluxio/12139,"fix bug : fuse pod hang forever if open & read many files without close the files <nl> root cause : <nl> mblockinstream in alluxiofileinstream wo n't be released even reading to end of the block . <nl> in this case , blockworkerclient will be held in blockinstream . given many files opened , blockworkerclient in the pool will be exhausted and the following operations will be blocked . <nl> fix : <nl> release mblockinstream after reading to end of the block . <para-sep> tests that reading the complete block works and the blockinstream is closed . <nl> tests that reading the complete file works and all streams are closed when to the end of file . <nl> tests the blockinstream is closed when reading to the end of the block .","fix bug : fuse pod hang forever if open & read many files without close the files . <nl> root cause : <nl> in wo n't be released even reading to end of the block . <nl> in this case , will be held in . given many files opened , in the pool will be exhausted and the following operations will be blocked . <nl> fix : <nl> release after reading to end of the block .",1600901106,"also added integration tests , which failed before this change and passes after this fix .",0.9403619170188904
apache_druid/10437,remove expr.visit . <nl> it is n't used and does n't have tests .,it is n't used and does n't have tests .,1601060724,- groupbyqueryenginev2 : fix leak of intermediate processing buffer when <nl> exceptions are thrown before result sequence is created . <nl> - pooledtopnalgorithm : fix leak of intermediate processing buffer when <nl> exceptions are thrown before the pooledtopnparams object is created . <nl> - blockingpool : remove unused ' take ' methods .,0.9071468710899353
confluentinc_ksql/6508,"add explicit qtt tests for null handling <cm-sep> fix npe in partition by . <nl> fixes a npe during stream processing where the value in the source stream is and the is on an expression other than a column reference , e.g . <nl> the npe would terminate the query .","fixes a npe during stream processing where the value in the source stream is and the is on an expression other than a column reference , e.g . <nl> the npe would terminate the query . <nl> usual .",1603450428,"review that first ! <nl> previously , a query such as : . <nl> would have resulted in a schema of . with the introduction of the 'any key name ' feature the in the projection is no longer a value column : its a key column , so the resulting schema is : , i.e . it has no value columns . <nl> ksqldb currently does n't support data sources with no value columns . hence the 'fix ' here is to reject the above query with the error . <nl> the change includes tests to ensure transient push",0.7985091805458069
apache_flink/14334,"fix unstable upsertkafkatableitcase.testtemporaljoin <cm-sep> address comments . <para-sep> kafka defaultpartitioner 's hash strategy is slightly different from flink keygroupstreampartitioner , which causes the records in the different flink partitions are written into the same kafka partition . when reading from the out-of-order kafka partition , we need to set suitable watermark interval to tolerate the disorderliness . for convenience , we just set the parallelism 0 to make all records are in the same flink partition and use the kafka defaultpartition to repartition the records .","in the origin test , it has 0 parallelisms and source will emit records to two producer threads . however , kafka hash strategy is slightly different from flink , which causes the records in the different flink partitions may be written into the same kafka partition . in the case above , the kafka partition is out-of-order and some records are late . this is the reason why we have the unstable test . <nl> here we just reset the parallelism to 0 to fix the test . if users has the same problem , he/she can adjust the",1607428631,"fix unstable upsertkafkatableitcase.testtemporaljoin . <nl> in the origin test , it has 0 parallelisms and source will emit records to two producer threads . however , kafka hash strategy is slightly different from flink , which causes the records in the different flink partitions may be written into the same kafka partition . in the case above , the kafka partition is out-of-order and some records are late . this is the reason why we have the unstable test . <nl> here we just reset the parallelism to 0 to fix the test . if users has the same problem",1.0
neo4j_neo4j/11231,"removed unused generic type <cm-sep> do n't write or read backups through page cache unless we have to . <nl> doing backup through the page cache was a necessary change to support <nl> block devices , however , this introduced an overhead in cases where it <nl> was n't necessary . this commit will revert the behaviour to the old way <nl> of doing thing , unless the underlying filesystem is not the default <nl> one , i.e . block device file system . <para-sep> e.g . the file system for block device will not work with generic open and read/write calls and all operations needs to be done through the page cache . <nl> default filesystem supports direct file access . <nl> read from paged file if mapping exists . otherwise read through file system . a file is mapped if it is a store , and we have a running database , which will be the case for both online backup , and when we are the master of an ha cluster .","doing backup through the page cache was a necessary change to support block devices , however , this introduced an overhead in cases where it was n't necessary . this commit will revert the behavior to the old way of doing things unless the underlying filesystem is not the default one , i.e . block device file system .",1520934250,"to make this fix , we had to introduce a hack for virtual nodes . <nl> the procedure has been implemented using a hack where virtual <nl> nodes and relationships were created with negative ids . this was done <nl> in order to display the results as a graph in the browser , and has been <nl> working well as long as we have been using the core api types in cypher . <nl> upon introducing the value types , this did not work anymore , as the hacked <nl> virtual node information was lost during conversions . <nl> this",0.9199531078338623
ballerina-platform_ballerina-lang/26581,fixed node factory issues <cm-sep> fixed separatednodelist function,and the creation method was also fixed to accept the correct type of node .,1603672657,"use observability.metrics.hostname configuration to bind http endpoint to a specific hostname . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.91324383020401
confluentinc_ksql/6698,"* fix : fix error categorization on npe from streams . <nl> fixes error categorization when streams exits due to an internal npe <nl> - fixes the regex categorizer to correctly handle npes . npes have null <nl> descriptions , so this patch changes the categorizer to ignore the <nl> description if its null . <nl> - fixes the uncaught handler to categorize errors as unknown if the <nl> categorizer throws <para-sep> if error classification throws then we consider the error to be an unknown error . we notify listeners and add the error to the errors queue in the finally block to ensure all listeners and consumers of the error queue ( e.g . the api ) can see the error . similarly , log in finally block to make sure that if there 's ever an error in the classification we still get this in our logs . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","* fix : fix error categorization on npe from streams . <nl> fixes error categorization when streams exits due to an internal npe <nl> - fixes the regex categorizer to correctly handle npes . npes have null <nl> descriptions , so this patch changes the categorizer to ignore the <nl> description if its null . <nl> - fixes the uncaught handler to categorize errors as unknown if the <nl> categorizer throws . <nl> unit and integration tests are expected for any behavior changes._ .",1606852244,unit and integration tests are expected for any behavior changes._ .,0.9505171775817871
confluentinc_ksql/6482,"internal server error for /healthcheck endpoint in rbac-enabled <para-sep> we add in all the paths that do n't require authentication/authorization from <nl> a user context is not necessary if a user context provider is not present or the user principal is missing . if a failed authentication attempt results in a missing principle , then the authentication plugin will have already failed the connection before calling this method . therefore , if we 've reached this method with a missing principle , then this must be a valid connection that does not require authentication . for these cases , we create a default service context that the missing user can use . <nl> when <nl> then <nl> when <nl> then <nl> auth header is omitted if username and password are null <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","context : <nl> there are endpoints in that do not require a security context initialized . some of these endpoints do not require authentication , so a security context should not be initialized because there is no authenticated . <nl> the current vert.x code in attempted to initialize the security context on endpoints where the user was not authenticated . this caused an error when calling these endpoints even with valid credentials . the fix was just to prevent initializing the security contexts , which is unnecessary . <nl> verified manually with confluent rbac library . <nl> * has valid",1603300515,"makes pull queries available on the restful and websocket endpoints , in the same way that push queries are . <nl> note : this change does not _remove_ pull query support from the endpoint , nor does it switch the cli over to use <nl> the endpoint . the cli continues to use the endpoint for pull queries . <nl> push and pull queries to the rest endpoint now return the schema of the rows in the first message . <nl> this is required as the 'describe ' that cli was previously running to get column headers does n't work",0.9764613509178162
apache_kafka/9970,": set length incorrectly <cm-sep> : set length incorrectly <cm-sep> add comment <para-sep> firstly we wrote some of the data <nl> ensure ( length > size - firstwritten ) <nl> but we still only write ( size - firstwritten ) , which is not fulfilled in the old version",summary of testing strategy ( including rationale ) <nl> unit test .,1611627822,"reload ssl trust stores and keystores on alterconfigsrequest from the admin client if the file was modified , even if the file name and password have n't changed .",0.9112749695777893
vespa-engine_vespa/15507,"remove unused fields <cm-sep> simplify test code <cm-sep> read stateful tag in clustermembership <para-sep> the format is ' clustertype/clusterid/groupid/index [ /exclusive ] [ /retired ] [ /stateful ] [ /combinedid ] ' <nl> todo ( mpolden ) : write stateful tag once all nodes can read it ( cluster.isstateful ( ) ? ' /stateful ' : ' ' ) + <nl> whether this cluster has state * / <nl> activate the hosts , thereby allocating the parents","the string format in is a bit wonky , so have to deploy <nl> read-support before doing more changes .",1606482743,* moved deleting old and processed coredumps to core-dump-handler in node-maintainer <nl> * added support for adding yinst state and rpm packages when analyzing coredump if argument is set,0.9653682112693787
apache_druid/10724,coordinator dynamic config changes to ease upgrading with new config value,"the mentioned change introduced undesirable behavior during upgrade . the new config value requires a value of 0 - 0. default is 0. however on upgrade the coordinator will load the dynamic config from metastore using for deserialization . since the config will not have existed pre-upgrade , it will be null for the constructor which violates the precondition check on the value . this would cause the code to load the builder default of coordinatordynamicconfig at startup . i believe this is undesirable . instead we want druid to load the existing persisted config with the default for the",1609442625,aggregators close ( ) method is not called when onheapincrementalindex tear down .,0.9329420328140259
elastic_elasticsearch/72044,[ ml ] use feature reset api for transform test cleanup,this moves all transform cleanup logic to use the feature reset api .,1619024373,"currently the logic for parsing vendor specific headers - i.e . application/vnd.elasticsearch+json ; compatible-with=0 is within rest-compatibility module . <nl> this commit is removing the rest-compatibility plugin and moving the version parsing logic <nl> into server module . it no longer needs to be injected from xpack into server , therefore can be directly used from restrequest .",0.9581689238548279
hazelcast_hazelcast/18493,"tidy up the defaultnodeentension and jetextension . <nl> - moved nodeinfo printings from jetextension to defaultnodeextension <nl> - changed the style of lossless restart enabled check to old imdg <nl> style . i was also thinking of calling jetextension.beforestart ( ) on the <nl> enterprise too , and not checking <nl> was creating a problem for this case .","in this pr , moved printings from to <nl> and also changed the style of lossless restart allowed check . <nl> i was thinking of calling on the enterprise side , and not checking was creating a problem . <nl> checklist : .",1617880846,this pr allows a shortcut in kerberos configurations ( authentication and identity ) . <nl> for simple scenarios it 's not necessary to define 0 additional security realms with configuration . instead the security realms are generated on the fly based on new configuration attributes : <nl> * - kerberos principal name <nl> * - path to a keytab file with user credentials . <nl> the ' shortcut ' is only used when the attribute is not configured . <nl> example of original configuration : . <nl> has its simplified form : . <nl> it 's not recommended for production,0.9328625798225403
apache_pulsar/9260,"ca n't create functions with m-tls . <nl> motivation . <nl> this unintentionally broke pulsar functions when m-tls is used for authentication . because it does n't <nl> taken tls port into consideration and always uses a non-tls port to communicate with the leader broker . <nl> the pr fixes the broken implementation and ensure pulsar functions use the right service url and <nl> authentication plugin to communicate with leader . <nl> tests . <nl> add an integration test to reproduce the issue and ensure functions worker with m-tls <cm-sep> add assertions <cm-sep> remove private line <para-sep> start local bookkeeper ensemble <nl> start brokers <nl> sleep until pulsarservices [ 0 ] becomes leader , this way we can spy namespace bundle assignment easily .",motivation . <nl> this unintentionally broke pulsar functions when m-tls is used for authentication . because it does n't <nl> taken tls port into consideration and always uses a non-tls port to communicate with the leader broker . <nl> the pr fixes the broken implementation and ensure pulsar functions use the right service url and <nl> authentication plugin to communicate with leader . <nl> tests . <nl> add an integration test to reproduce the issue and ensure functions worker with m-tls,1611229328,pulsar broker 's embedded jetty client does not disable http trace and track by default which causes the application to be flagged as insecure in certain corporate environments . <nl> created a new servlet filter : disabledebughttpmethodfilter that is attached to the servlets as they are added at startup . i used this stackoverflow answer for reference . <nl> this change added tests and can be verified as follows : . <nl> ( example : ) <nl> - added test case testdisablehttptraceandtrackmethods in webservicetest class . <nl> - the rest endpoints : ( yes ) -- the property is set,0.9500199556350708
jenkinsci_jenkins/4641,extracted duplicated code in method <cm-sep> removed unnecessary assignments,"this pr is for minor changes without a jira ticket . the goal was to reduce duplicated code by adding a method . <nl> n/a . <nl> - the refactoring done should not change the behaviour of existing code , so the tests should not need to be changed . <nl> n/a",1586576563,"accessing the rss feed for latest builds from the page returns a 0 error . whilst in and class the method exists , in this method is missing . <nl> i 've also made a small code refactor to avoid further duplication . <nl> * , prevent the rss feed in computer page from returning an error 0 . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8953123688697815
elastic_elasticsearch/71991,"increase trace logging for native user auth . <nl> this change adds new debug and trace logs for native user <nl> authentication ( and , by consequence other password based realms such <nl> as the reserved realm and ldap realms ) <para-sep> a new request should trigger a new authentication","this change adds new debug and trace logs for native user <nl> authentication ( and , by consequence other password based realms such <nl> as the reserved realm and ldap realms )",1618979501,"the packaging tests start elasticsearch in various ways . all of these <nl> currently expect it is started asynchronously , yet some tests expect it <nl> will fail to start and want to check the error output . this commit adds <nl> a daemonize flag to the utility methods to start elasticsearch for such <nl> cases , so that when the start method returns , all the error output <nl> should already be available since the process will have exited .",0.9212706685066223
jenkinsci_jenkins/4777,use the 'agent ' term more often <para-sep> that agent ) . see .,"also remove two untranslated files . <nl> * too minor . <nl> n/a . <nl> - [ n/a ] ( if applicable ) jira issue is well described <nl> - [ n/a ] changelog entries and upgrade guidelines are appropriate for the audience affected by the change ( users or developer , depending on the change ) . <nl> before the changes are marked as : .",1591605957,"* use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8839653730392456
hazelcast_hazelcast/18285,implement copyonwritearrayliststreamserializer # write with reflection,however due to nature of the cow data structures there are ways to make them serialize without cloning .,1614169569,"when the is called , client tries to create proxies that are unknown to it . however , formerly client was trying to do that by a remote call . this is unnecessary since the newly received proxies are already created on member . <nl> with this pr , newly received proxies are only initialized locally .",0.9342931509017944
apache_beam/13378,fix for quota_exceeded failures in bq storage streams split . <para-sep> verify that subsequent splitatfraction ( ) calls after a failed splitatfraction ( ) attempt do not invoke splitreadstream .,fix for bigquery storage streams failing with quota_exceeded errors in split,1605734165,"this avoids warnings like the following : . <nl> this would print an extra empty line on every logged line making the output <nl> verbose , e.g . <nl> before : . <nl> after : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.893027126789093
hazelcast_hazelcast/18361,revert ' make nearcacheconfig equal before and after it is used ' . <nl> this reverts commit sha . <cm-sep> copy nearcacheconfig when it needs to be changed . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used . <nl> ( cherry picked from commit sha ) <para-sep> create copy of eviction config <nl> create copy of nearcache config and set eviction config,this reverts commit sha . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used .,1614858513,"added the property to the hot restart persistence config . <nl> eventually , i would like to have this option on the data structure specific but there are potential compatibility issues with that . first , this is a patch-level release so i do n't think it is safe to meddle with the config serialization format . second , is included in which is a - which i understand essentially means that the class is set in stone and can not change without breaking client compatibility etc . and lastly , the map and cache configs are persisted in the",0.9380028247833252
ballerina-platform_ballerina-lang/23884,"predeclared error , object , xml module prefixes <cm-sep> add auto-import tests <para-sep> importcompunit is null for predeclared modules <nl> get the completion item for the error type . <nl> add the error type completionitem <nl> 'object : listener ; <nl> obj : listener ; <nl> obj : listener ; <nl> 'object : listener ;","> version import declaration says : <nl> a module prefix of t , where t is one of error , object or xml , is predeclared as referring to the lang.t lang library module , but this can be overridden by an import-decl .",1591787240,"java bytecode generation phase uses these annotations to link with existing java classes that the developer wants to interoperate with . annotation attachments are not available anywhere in the current bir model implementation . therefore this pr improve the current codebase by adding annotation attachment values to bir function nodes . ideally , we should add annotation attachment all nodes if the language spec permits . but this pr improves bir just enough to implement java interop .",0.9612467288970947
grpc_grpc-java/7273,"support v3 for xdsclient <cm-sep> duplicate xdsclientimpltest for v2 <cm-sep> use v3 protocol for xdsclientimpltestv3 <para-sep> however , the test xds server still sends update with v2 resources for testing compatibility . <nl> only the connection to management server is established , no rpc request is sent until at least one watcher is registered . <nl> always test the real workflow and integrity of xdsclient : rds protocol should always followed after at least one lds request-response , from which the rds resource name comes . cds and eds can be tested separately as they are used in a standalone way . <nl> discovery responses should follow management server spec and xds protocol . <nl> client receives an lds response that does not contain a listener for the requested resource . the lds response is acked . the config watcher is notified with resource unavailable after its response timer expires . <nl> client sends an lds request for the host name ( with port ) to management server . <nl> client sends an ack lds request . <nl> an lds response contains the requested listener and an in-lined routeconfiguration message for that listener . but the routeconfiguration message is invalid as it does not contain any virtualhost with domains matching the requested hostname . the lds response is nacked , as if the xdsclient has not received this response . the config watcher is notified with an error after its response timer expires .. <nl> client sends an lds request for the host name ( with port ) to management server . <nl> client sends an nack lds request . <nl> client resolves the virtual host config from an lds response that contains a routeconfiguration message directly in-line for the requested resource . no rds is needed . the lds response is acked . the config watcher is notified with an update . <nl> client sends an lds request for the host name ( with port ) to management server . <nl> client sends an ack request . <nl> client receives an rds response ( after a previous lds request-response ) that does not contain a routeconfiguration for the requested resource while each received routeconfiguration is valid . the rds response is acked . after the resource fetch timeout expires , watcher waiting for the resource is notified with resource unavailable . <nl> client sends an lds request for the","duplicated for v3 . and all other tests are still using v2 . even for , although the protocol is v3 , the test xds server still sends v2 resources in its v3 response .",1596172676,,0.0
Alluxio_alluxio/12081,fix active sync manager error on secondary master,there has been errors when an active sync enabled secondary master get promoted to primary . it is caused by active sync manager trying to access ufs when master is in secondary mode . ufs client are not initialized for mount points on secondary master so error occurs when active sync manager accesses it during snapshotting and server stopping process . <nl> this fix updated active sync manager to avoid unnecessary access to ufs client on a secondary master .,1599589737,create extensions directory if does not exist,0.9311076402664185
apache_pulsar/8930,"monitor if a cursor moves its mark-delete position . <nl> motivation . <nl> or does n't provide a clear idea <nl> if position is advanced or not . add a new metric <nl> in subscriptionstat to monitor if its mark-delete position <nl> is advanced or not . <para-sep> if the service unit is not owned , return a completablefuture with empty optional . <nl> last markdelete position advanced timesetamp . * /",motivation . <nl> or does n't provide a clear idea <nl> if position is advanced or not . add a new metric <nl> in subscriptionstat to monitor if its mark-delete position <nl> is advanced or not .,1607729502,"currently , the bookkeeper client gets the lac is the piggyback lac which is carried by the next message . this causes the pulsar sql connector will always get the messages . if we want to query all messages , we need to use the explicit lac to get the total number of entries . <nl> bookkeeper version makes us can use the to enable using v3 protocol which will get the explicit lac . <nl> - add the properties for the pulsar sql . <nl> - update the integration test to query the last message .",0.9310831427574158
apache_incubator-pinot/5334,"temp <cm-sep> change return type of constantexecutionnode <para-sep> 0 ) convert ( from_format , to_format , bucketing ) note : toepochxxxbucket methods are only needed to convert from timefieldspec to datetimefieldspec , to maintain the backward compatibility . practically , we should only need the toepochxxxrounded methods . use of toepochxxxbucket bucket functions is discouraged unless you know what you are doing - ( e.g . 0-minutes-since-epoch does not make sense to someone looking at the timestamp , or writing queries . instead , millis-since-epoch rounded to 0 minutes makes a lot more sense ) an example timefieldspec that needs the bucketing function : ' timefieldspec ' : { ' incominggranularityspec ' : { ' name ' : ' incoming ' , ' datatype ' : ' long ' , ' timetype ' : ' milliseconds ' } , ' outgoinggranularityspec ' : { ' name ' : ' outgoing ' , ' datatype ' : ' long ' , ' timetype ' : ' minutes ' , ' timesize ' : 0 } } an equivalent datetimefieldspec is ' datetimefieldspecs ' : [ { ' name ' : ' outgoing ' , ' datatype ' : ' long ' , ' format ' : ' 0 : minutes : epoch ' , ' granularity ' : ' 0 : minutes ' , ' transformfunction ' : ' toepochminutesbucket ( incoming , 0 ) ' } ]","setting the returntype in constantexecutionnode based on the value , instead of always returning string . this prevents parsing the string to number on every record .",1588704722,"- create a new package com.linkedin.pinot.core.realtime.stream in pinot-core . <nl> - move kafkastreammetadata to com.linkedin.pinot.core.realtime.stream , renaming it to streammetadata <nl> - get rid of ( unused ) streammetadata <nl> - move ( and rename ) classes to be kafka-agnostic ( which they are for most parts ) <nl> - add todo in a couple of places where classes are kafka-specific",0.9533562064170837
Graylog2_graylog2-server/9292,use the annotation instead of org.jetbrains.annotations.notnull ` which is not available in all environments .,"use the annotation instead of which is not available in all environments . <nl> this incorrect import only caused the following error in some environments , such as running the graylog server with the docker tool .",1603872186,"this led to a logged error , because multiple instances of were configured . the configuration happens in a static constructor and due to the relocation we had multiple class definitions in multiple packages , which were n't properly configured . <nl> in addition we added a suffix to the shaded dependencies ' version so that we can deploy new artifacts without bumping the underlying version for the shaded library . <nl> local setup .",0.8656313419342041
runelite_runelite/12160,update minigame locations for ferox enclave <cm-sep> add citharede abbey and eagles outpost mining spots <cm-sep> add ferox enclave—ring of dueling teleport location,"updates minigame icon descriptions for clan wars , castle wars portal , and last man standing . <nl> added mining spot information for citharede abbey and eagles outpost mining spots . <nl> adds new ring of dueling teleport location for ferox enclave .",1594905140,before : . <nl> after : .,0.8327386975288391
ballerina-platform_ballerina-lang/25276,"make the parser to always re-parse upon syntax error <cm-sep> remove passing syntax-kind as an argument <cm-sep> fix tests <cm-sep> cleanup code <para-sep> parse version keyword . <nl> at the correct place , but some token after that is not . <nl> braced actions are just parenthesis enclosing actions , no need to add a diagnostic there when we have added <nl> treat everything else as a single expression . if something is missing , expression-parsing will recover it .",with this change the recovered node from step 0 ) will be re-used for step 0 ) .,1597393718,,0.0
ballerina-platform_ballerina-lang/26173,update array and tuple type logic and tests,this pull request fixes the mentioned issues .,1601573590,> add annotation in the resource signature instead of having req.getqueryparamvalue ( string key ) function . <nl> > add annotation for path params .,0.9699645042419434
elastic_elasticsearch/71896,"reject multiple data paths on frozen capable nodes . <nl> nodes with a frozen cache no longer supports multiple data paths . this <nl> simplifies cache sizing and avoids the need to support multiple cache <nl> files . <para-sep> ok to ignore these <nl> peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this does n't work , but we can bypass this by forcing soft deletes to be used . <nl> ok <nl> the extra segments_n file created for bootstrap new history and associate translog makes us unable to precisely assert this . <nl> the extra segments_n file only has a new history uuid and translog uuid , both of which have constant size . it 's size is therefore identical to the original segments_n file from the snapshot . we expect at least 0 byte of other content , making it safe to assert that the total data set size is less than 2x the size . <nl> the extra segments_n file created for bootstrap new history and associate translog makes us unable to precisely assert this . <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , true , noncachedextensions ) ; <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , false , noncachedextensions ) ; <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , false , noncachedextensions ) ; <nl> todo : be resilient to this check failing and try next path ? <nl> todo : leave some margin for error here",nodes with a frozen cache no longer supports multiple data paths . this <nl> simplifies cache sizing and avoids the need to support multiple cache <nl> files .,1618904122,"make it possible to reuse the cluster state update of rollover for <nl> simulation purposes by extracting it . also now run the full rollover in <nl> the pre-rollover phase and the actual rollover phase , allowing a <nl> dedicated exception in case of concurrent rollovers as well as a more <nl> thorough pre-check .",0.9265152812004089
apache_shardingsphere/8988,"support for creating private temporary , shared , duplicated table in oracle . <cm-sep> support for creating table with sharing , optimize , parent in oracle . <cm-sep> keep one empty line in the end of file . <cm-sep> keep one empty line in the end of file . <cm-sep> support for create object table in oracle .",changes proposed in this pull request : <nl> - feat : support for creating object table in oracle .,1610413718,changes proposed in this pull request : <nl> - adjust threadpool size in asyncload,0.8339244723320007
confluentinc_ksql/6545,"add constraint to no drop sources referenced by other create_as sources <cm-sep> return drop source constraints from describe extended <cm-sep> drop sources in order for rest qtt cleanup methods <cm-sep> fix tests <para-sep> returns a list of sources that have a drop constraint reference on this source . this source can not be dropped until all sources returned by this method are deleted . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> these sources have a constraint that can not be deleted until the references are dropped first <nl> replace the datasource if one exists , which may contain changes in the schema , with a copy of the previous source info <nl> remove drop constraints from the referenced sources <nl> add a constraint to the referenced sources to prevent deleting them <nl> add all references to the source <nl> parent sources that this source references to ; it is used to remove constraints from the parent table when this source is deleted <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when <nl> then : <nl> returns an ordered list of sources to drop . sources may have referenced sources that havea a drop constraint against this source . if that 's the case , this method walks through the each linked source and builds a list of sources that must be dropped in order . example : - create stream ' a ' ; - create stream ' b ' as select from ' a ' ; - create stream ' c ' as select from ' b ' ; in the above example . the source ' a ' has a drop constraint reference from ' b ' , and ' b ' has a drop constraint reference from ' c ' . source ' a ' can not be dropped until all the child sources are dropped . this method will return a list with [ ' c ' , ' b ' , ' a '","this pr only adds extra work to : <nl> * return drop source constraints from describe extended <nl> * drop sources in order for rest qtt cleanup methods . <nl> the change for this pr adds a constraint to a source to not delete it if it is referenced by another source . for instance : . <nl> even if queries are terminated , the stream or table can not be deleted until all sources that reference to it are deleted . this is a common approach in other dbs , which could keep constraints and references on tables thus",1604001109,"makes pull queries available on the restful and websocket endpoints , in the same way that push queries are . <nl> note : this change does not _remove_ pull query support from the endpoint , nor does it switch the cli over to use <nl> the endpoint . the cli continues to use the endpoint for pull queries . <nl> push and pull queries to the rest endpoint now return the schema of the rows in the first message . <nl> this is required as the 'describe ' that cli was previously running to get column headers does n't work",0.9763333797454834
jenkinsci_jenkins/4685,allow system read to view more admin monitors <para-sep> systemread,screenshots . <nl> allow system read to view more admin monitors,1587677222,"the manual sanity testing of these changes was done in the context of that pr . <nl> * bug , - “ detached ” plugins—those split out of jenkins core at some point , including the former “ modules ” —will now be installed upon jenkins startup when needed as implied dependencies of other plugins which were already present . this simplifies compatibility for specialized installation scenarios not using the update center , such as when jenkins is run from a docker image prepackaged with some plugins . <nl> * bug , the detached version of the script security plugin",0.9605284333229065
apache_kafka/9606,improve javadoc for aggregate . <nl> tell that the store used internally is always a timestamped one .,tell that the store used internally is always a timestamped one . <nl> this is related to . <nl> no tests are necessary because only javadoc was changed .,1605647627,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.9501015543937683
jenkinsci_jenkins/5011,runlist.sublist : reduce allocations in internal arraylist <cm-sep> logrotator.perform : remove copy of already new instance from sublist <cm-sep> logrotator.perform : change list to runlist for strict new list instance in builds.sublist <cm-sep> remove unused imports,logrotator and runlist allocated a lot of arrays during the creation of the sub-list . <nl> fix contains small optimizations . <nl> set initial capacity in runlist.sublist <nl> * entry 0 : do n't copy already a new instance of list in logrotator.perform,1602932368,"just a minor bug , which may potentially happen due to the race condition if a task gets interrupted with system authentication . <nl> - userinterruption # getuser ( ) uses user.get ( string ) , which creates users on demand . <nl> - when we create causeofinterruption.userinterruption , we expect it exists <nl> - but : the user may be deleted from parallel thread by the time we call userinterruption # print , which invokes getuser ( ) <nl> - in such case the recently deleted user may be recreated .",0.870559573173523
elastic_elasticsearch/71933,only clear cache for frozen tier shards,"makes it so that the experimental searchable snapshot clear cache api only clears the shared cache ( ) , leaving unchanged . <nl> this api is only useful to measure how much shared_cache a query might take ( take cache stats , reset the cache , then run the query , the check cache stats again ) . running this api against the cold tier would dramatically mess with query performance there , as it undoes the pre-warming , so this pr removes that effect .",1618924781,enhanced part of a test in this pr to make it show up in also even though we practically never use this method with stream targets that actually .,0.8641412258148193
apache_druid/10243,"add maxnumfiles to splithintspec <cm-sep> missing link <para-sep> there are two known issues when a split contains a large list of files . - 'jute.maxbuffer ' in zookeeper . this system property controls the max size of znode . as its default is 500kb , task allocation can fail if the serialized ingestion spec is larger than this limit . - 'max_allowed_packet ' in mysql . this is the max size of a communication packet sent to a mysql server . the default is either 64mb or 4mb depending on mysql version . updating metadata store can fail if the serialized ingestion spec is larger than this limit . the default is conservatively chosen as 0 . <nl> this ingestion spec has a splithintspec of maxsplitsize of 0 to test whether or not the task can handle maxsplitsize of 0 properly . this ingestion spec has a splithintspec of maxsplitsize of 0 to test whether or not the task can handle maxsplitsize of 0 properly .","this pr adds to splithintspec which is a new limit on the max number of files in a split . also , the human readable format is now supported for",1596652198,"this pr modifies property to compute a reasonable default based on the amount of direct memory , number of processing threads , and number of merge buffers instead of using a fixed 1gib default buffer size . this should be much more friendly behavior out of the box , ensuring reasonably efficient usage of direct memory resources provided to the process , without interfering with operators who still wish to fine tune such things . <nl> on process startup , does a check : . <nl> to validate that the process has been given enough direct memory . configs for",0.9513757824897766
runelite_runelite/11900,add config section for filter lists . <nl> the chat filter config can get pretty unruly if you have a lot of word and regex filters . this adds a config section akin to the section in . config was shifted down to be with the rest of the configs .,the chat filter config can get pretty unruly if you have a lot of word and regex filters . this adds a config section akin to the section in . config is shifted down to be with the rest of the configs .,1592174609,i have added a checkbox in the boosts information plugin to enable/disable notification sending . a value of 0 will still disable notification .,0.8240166902542114
apache_incubator-pinot/5755,add profilecredentialsprovider & instanceprofilecredentialsprovider <nl> to the credentials provider chain for s3pinotfs <cm-sep> use a generic credentialprovider and fix a bug in isdirectory func,use defaultcredentialprovider which chains common ways to provider credentials <nl> for example : credentials provider file and instance profile based credentials were missing . <nl> fixig a bug in isdirectory s3pinotfs headobjectrequst key contained a ' / ' as prefix which is causing it to fail . <nl> remove headobjectrequest infavor of listobjectsv2 with a limit on number of keys retrieved to 0 . <nl> there 's seems to a bug in s3mock which was causing to pass previously .,1595640548,fix anomalyapplicationendtoendtest error with alert filter factory,0.8525689244270325
apache_shardingsphere/9692,add merge update clause test case <cm-sep> modify literal expression index,"changes proposed in this pull request : <nl> - added test cases for . <nl> - i modified antlr definition for : added two new rules , and removed parenthesis for and . <nl> - i tried to visit in the . <nl> - i chose and for the similar to in the statement . <nl> - since contains columns as values , to expect them , i added in the and to assert columns , i added in the . <nl> i 'll change them according to your feedback .",1615894137,changes proposed in this pull request : <nl> - support heart beat for sharding jdbc with yaml .,0.9681476354598999
elastic_elasticsearch/72079,"add index details to hlrc get-snapshots parser . <nl> this class is also used as part of the <nl> response to a get-snapshots request by the hlrc , but the hlrc uses a <nl> different parser from the one which reads the blobs held in the <nl> repository and this other parser was not extended to deal with the new <nl> details . this commit addresses that . <para-sep> explicitly include the index details , excluded by default , since this is required for a faithful round-trip <nl> do n't inject random fields into the custom snapshot metadata , because the metadata map is equality-checked after doing a round-trip through xcontent serialization/deserialization . even though the rest of the object ignores unknown fields , does n't ignore unknown fields ( it just includes them in the parsed object , because the keys are arbitrary ) , so any new fields added to the metadata before it gets deserialized that were n't in the serialized version will cause the equality check to fail . also do n't inject random junk into the index details section , since this is keyed by index name but the values are required to be a valid indexsnapshotdetails the actual fields are nested in an array , so this regex matches fields with names of the form","this class is also used as part of the <nl> response to a get-snapshots request by the hlrc , but the hlrc uses a <nl> different parser from the one which reads the blobs held in the <nl> repository and this other parser was not extended to deal with the new <nl> details . this commit addresses that .",1619091336,"secondary authorization headers are to be used to facilitate kibana spaces support + ml jobs/datafeeds . <nl> now on put/update/preview datafeed , and put data frame analytics the secondary authorization is preferred over the primary ( if provided ) .",0.9323911070823669
apache_incubator-pinot/5487,"add multi-value support to segmentdumptool . <nl> also , add segment dump tool as part of the pinot-tool.sh script","also , add the segment dump tool as part of the pinot-tool.sh script . <nl> currently segment dump tool supports single-value only . this change adds the multi-value support . it also makes segment dump tool a subcommand in script .",1591151669,"* currently , it is not easy to get all the tables of a certain tenant . you have to start by getting the instances and manually finding the tables on those instances . <nl> * this api will look at table config in zk and gather the tables that are tagged with the particular tenant .",0.9198960661888123
apache_flink/14333,"avoid dynamic partition grouping if the input defines collation . <cm-sep> add tests for dynamic partition with order by . <para-sep> some hive feature relies on the results being sorted , e.g . bucket table",this is a cherry pick back to .0 branch .,1607427052,"# # what is the purpose of the change . <nl> bug when use jdbc sink with float type . <nl> in flink <nl> - sql , we regard float as java float . <nl> - but in jdbc , real type is java float , float/double are java double . <nl> we have dealt with data very well in jdbcutils , but mismatch in jdbctypeutil to match java float to jdbc float . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class",0.9359113574028015
OpenAPITools_openapi-generator/7364,"update vert.x web template to vert.x 0 . <para-sep> if there is a file upload , exclude other form params since it 's not clear how the user should access to these <nl> in vert.x 0 web openapi the forms are handled as single json object we create a dummy param here and remove the other ones <nl> param extraction <nl> for production use case , you need to enable this flag and provide the proper security handler <nl> complete the start promise <nl> for production use case , you need to enable this flag and provide the proper security handler <nl> complete the start promise <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> implement this class <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> implement this class <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> param extraction <nl> implement this class <nl> a category for a pet * / <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> describes the result of uploading an image resource * / <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> an order for a pets from the pet store * / <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> a pet for sale in the pet store * / <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> a tag for a pet * / <nl> convert the given object to string with each line indented by 0 spaces ( except the first line ) . <nl> a user who is purchasing from the pet store * / <nl> convert the given object to string with each line indented by 0","changes to the codegen/template : . <nl> * update to vert.x 0 <nl> * removed rx java : although it 's used by some people in vert.x community , it 's an opinionated choice and rx users ( which usually are not beginners ) can easily add it without much pain . on the contrary , removing it for a beginner it 's non trivial . <nl> * removed some useless classes on the template that are already provided by vert.x itself ( like apiexception , which maps to httpstatusexception ) . <nl> so the generator works perfectly , generates",1599474346,we 'll move the security tests to a separate branch ' security-tests ' instead,0.90227872133255
elastic_elasticsearch/71756,frozen autoscaling decider based on storage pct . <nl> the frozen tier partially downloads shards only . this commit <nl> introduces an autoscaling decider that scales the total storage <nl> on the tier according to a configurable percentage relative to <nl> the total data set size .,the frozen tier partially downloads shards only . this commit <nl> introduces an autoscaling decider that scales the total storage <nl> on the tier according to a configurable percentage relative to <nl> the total data set size .,1618504938,"adds analytics plugin usage stats to _xpack/usage . it looks like the usage <nl> did n't report the actual usage in the previous versions . so , while it looks <nl> like it is reported in version , the numbers are always 0. because code between version <nl> and 0.x/master is significantly different , i can open a separate pr for version if <nl> we want to fix it there .",0.9861020445823669
ballerina-platform_ballerina-lang/24025,add the maximum upper bound to the number of polls in listener of email connector,in that case the test should fail after a finite number of polls .,1591966396,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.8316992521286011
OpenAPITools_openapi-generator/7648,fix ruby default datetime value <cm-sep> update samples for testing <cm-sep> use datetime parse <cm-sep> use date.parse <cm-sep> revert changes to spec,to fix exception when datetime property has a default value . <nl> the updated code looks like the following : .,1602421400,"…rializable , by adding the config option serializablemodel= ( true|false ) . <nl> i added a new configoption ' serializablemodel= ( true|false ) ' to org.openapitools.codegen.languages.abstractkotlincodegen and to the files <nl> * kotlin-server/data_class.mustache <nl> * kotlin-client/data_class.mustache . <nl> in order to allow to generate kotlin data classes that implement the interface ' java.io.serializable ' . this will come in handy if data classes are generated with the intention to store data in databases or in distributed caches ( i.e . hazelcast )",0.8958200812339783
apache_incubator-pinot/5740,"[ te ] added a backfill start date for anomaly detection . <nl> when an alert is created , it automatically triggers a yaml onboarding task <nl> which detects all anomalies in the past 0 days . this change makes the <nl> setting configurable by providing a backfill start timestamp . <nl> not providing the value or simply providing a dubious entry would result <nl> in the system defaulting to the 0 day lookback . <nl> this change also updates the alert template ui to make it easy for a new <nl> user to try this config <para-sep> if no value is present , set the default lookback <nl> the lasttimestamp value is used as a checkpoint/high watermark for onboarding data . this implies that data entries post this timestamp will be processed for anomalies .",this change makes the <nl> setting configurable by providing a backfill start timestamp . <nl> not providing the value or simply providing a dubious entry would result <nl> in the system defaulting to the 0 day lookback . <nl> this change also updates the alert template ui to make it easy for a new <nl> user to try this config . <nl> there are no backward incompatible changes .,1595475866,taking steps towards making realtime consumption work with generic stream,0.9266307353973389
elastic_elasticsearch/72367,"fail geoip processor if database is older than 0 days <para-sep> only downloaded databases will have lastupdate ! = 0 , we never update it for default databases or databases from config dir <nl> 0 days check passed but we mocked mmdb data so parsing will fail",as required by maxmind license we ca n't use databases that are older than 0 days as we could miss ' do n't sell ' request . <nl> this check was missing before and this change fixes that .,1619607145,"allows configuring searchable snapshots to avoid caching certain types of files , for example ' fdt ' files for stored fields .",0.9526585340499878
apache_pulsar/9083,"message ttl expires 0 message at a time <cm-sep> fix message expiration in case of topic unload <cm-sep> clean log <cm-sep> add end-to-end tests <cm-sep> remove debug <para-sep> roll a new ledger <nl> we want to assert here that the algorithm returns the position of the last message <nl> unload a reload the topic this action created a new ledger having a managed ledger with more than one ledger should not impact message expiration <nl> wall clock time , we have to make the message to be considered ' expired ' <nl> verify that the markdeleteposition was moved forward , and exacly to the last message","this is how opfindnewest ( the operation involved in message expiry , persistentmessageexpirymonitor ) works : <nl> - first check if first message is expired <nl> - test in the last message <nl> - perform a search .. . <nl> at step two we are jumping to a position that is not valid , and the search ends immediately , returning only the first message . <nl> ensure that we are jumping only to a valid position , this change allows the persistentmessageexpirymonitor to find the best range of messages to expire . <nl> this change added tests : <nl>",1609248928,"so , fixing func-url validation method .",0.9626232385635376
jenkinsci_jenkins/4626,"un-inline javascript from reverseproxysetupmonitor <para-sep> some of the possible values : ' /jenkins ' or ' ' <nl> getrooturl 's contract is to end with / , we need to ensure the contextpath is not starting with one and as only the empty string does not contain a leading slash , we have to also add one at the end <nl> to cover the case where the jenkinsrooturl is configured without the context <nl> this means the root url was configured but without the contextpath , so different message to display <nl> redirect failed . <nl> as the context was already set inside the referer , adding another one will fail <nl> no referer <nl> wrong referer <nl> as the rooturl is missing the context , a regular test will fail <nl> when testing with the context , it will be ok , allowing to display an additional message <nl> adding the context does not have any impact as there is no configured context <nl> no referer <nl> referer using ip <nl> by default the jenkinsrule set the rooturl to localhost : /jenkins even with similar request and referer , if the root url is set , this will show a wrong proxy setting <nl> referer using ip <nl> referer using ip <nl> as the rooturl is missing the context , a regular test will fail <nl> when testing with the context , it will be ok , allowing to display an additional message","as i was playing with the rooturl and the reverse proxy monitor , i fall into a situation where my root url does not contain the contextpath ( manually set ) and thus it told me that the configuration is not good . so i added a logic for adding a warning message when such situation occurs . <nl> the existing test was not really testing stuff , so i added several ones . <nl> at the same time , i did some cleanup . if some of the changes do not satisfy you , we can keep only the",1586087090,added a simple diagnostic http response to the tcpslaveagentlistener .,0.9199714660644531
hazelcast_hazelcast/18477,implement default timeout for customspringjunit4classrunner . <nl> this is a copy of the same functionality from abstracthazelcastclassrunner .,"there are some failures in the spring tests , causing the tests to run indefinitely and timing out the whole job . <nl> this adds default timeout to the customspringjunit4classrunner , which will timeout the individual tests . <nl> this is a copy of the same functionality from abstracthazelcastclassrunner .",1617715931,"when getting cache proxy via <nl> the must be created on other cluster members before the <nl> method returns to the caller ( as is the case when getting or creating a <nl> via interface ) . otherwise , it is possible cache operations <nl> may fail with until the proxy creation event <nl> is processed on all members . <nl> also includes a small compatibility code cleanup as a separate commit .",0.9442115426063538
Graylog2_graylog2-server/9227,"remove code that creates explicit user view permissions . <nl> this is now handled via ownership grants <cm-sep> clear the shiro authorization cache if grants change . <nl> otherwise the we might run into a race when ownership grants <nl> are created for new entities , but the cache does n't contain <nl> the new permissions .","clear the shiro authorization cache if grants change . <nl> otherwise the we might run into a race when ownership grants <nl> are created for new entities , but the cache does n't contain <nl> the new permissions .",1603299694,switch all implementations from polling for changes every second to subscribing to change events . <nl> this avoids unneeded load on the graylog and mongodb servers .,0.9740004539489746
OpenAPITools_openapi-generator/7864,fix async in java play generator,- fix compilation issues when using the supportasync option .,1604383740,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) . <nl> the problem : <nl> api generation for c # , java and ruby creates a class based on the tag and then adds ' api ' after it . <nl> ideally though we have a class like ' study ' or ' study { { suffix } } ' not ' studyapi ' . <nl> i introduced a apinamesuffix parameter in order to add suffixes to the generated api class/file/document names . added the option '",0.919425368309021
apache_druid/10356,avoid large limits causing int overflow in buffer size checks,"the size check in limitedbufferhashgrouper can overflow and hence pass inadvertently . this results in the limited grouper being used when the buffer is too small and so the buffer.limit call within init fails with an illegalargumentexception . <nl> this is likely to only occur at large limits which are n't common but we 've seen it occur on our production cluster . the following test added to limitedbufferhashgroupertest fails prior to this commit and passes after , i 'm not sure it 's useful enough to include in the commit itself but included here for anyone interested",1599208895,"holders are complete if they have a start , sequence of abutting objects , and <nl> then an end . there is n't any reason to check whether or not the objects _after_ <nl> the end are abutting ( the extensible set ) . <nl> this is really a performance patch , since behavior should n't be changing . the <nl> extensible shardspecs ( where we could have shards after the end ) are always <nl> abutting each other anyway . performance does n't usually matter much in this <nl> function , but it can when there are thousands of",0.8033173680305481
grpc_grpc-java/7523,only one stopwatch is needed for the loadreportclient . <cm-sep> eliminate reportclientstats/cancelclientstatsreport apis . <cm-sep> start load reporting internally in xdsclient in the first call of addclusterstats . <para-sep> cluster : cluster_service . the first call of this method starts load reporting via lrs . load reporting may be terminated if there is no stats to be reported . <nl> todo ( chengyuanzhang ) : stop load reporting if containing no stats .,"currently there are two load reporting related apis on the xdsclient interface : and . the former is for creating/getting the stats object for a cluster and the latter is to start load reporting rpc . this is a bit cumbersome as the two are always called together : the stats object is retrieved to record loads to be reported to the management server . in the context of sharing xdsclient between channels , all lb policy facing apis need be thread-safe . it is unnecessarily cumbersome to make each of these two apis thread-safe given that they are always",1602731325,"previously clientcallimpl 's stream listener would call <nl> stream.setdecompressor ( ) , but this has always been a bit strange as the <nl> only case where the call listener calls the stream and forms a bit of a <nl> loop . it also turned out to be racy in the presence of <nl> delayedclientstream since delayedclientstream does not guarantee that <nl> the listener has processed before returning . <nl> now we let the stream handle decompressor selection itself . compressor <nl> selection on client and server and decompressor selection on server <nl> remain unchanged . nothing prevents them from being",0.9361047148704529
elastic_elasticsearch/72201,"refactor geogridtiler classes <cm-sep> iter <para-sep> implements most of the logic for the geohash aggregation . <nl> check if the provided hash is in the solution space of this tiler * / <nl> todo : optimize for when a whole shape ( not just point ) fits in a single tile an for when brute-force is expected to be faster than rasterization , which is when the number of tiles expected is less than the precision <nl> optimization for setting just one value for when the shape represents a point <nl> todo : this way to discover cells inside of a bounding box seems not to work as expected . i can see that eventually we will be visiting twice the same cell which should not happen . <nl> implements most of the logic for the geotile aggregation . <nl> check if the provided tile is in the solution space of this tiler * / <nl> max size of the solution space * / <nl> if the shape resides between geotileutils.normalized_latitude_mask and 0 or between geotileutils.normalized_negative_latitude_mask and 0 degree latitudes , then the shape is not accounted for since geo-tiles are only defined within those bounds . <nl> geo tiles are not defined at the extreme latitudes due to them tiling the world as a square . <nl> sets a singular doc-value with the provided x/y .","while working on improving how bounded geogrid aggregations work , i realise that the current hierarchy of classes was confusing and difficult to work with . thispr modifies this hierarchy by adding an and .",1619423706,"fetchsubphase has two 'execute ' methods , one which takes all hits to be examined , <nl> and one which takes a single hitcontext . it 's not obvious which one should be implemented <nl> by a given sub-phase , or if implementing both is a possibility ; nor is it obvious that we first <nl> run the methods of all subphases , and then subsequently call all the <nl> methods . <nl> this pr removes entirely , and changes the signature of to take <nl> an array of objects , instead of an array of . a convenience method",0.9699544310569763
ballerina-platform_ballerina-lang/26113,"introduce the isolatedparam annotation <cm-sep> fix symbolbirtest <cm-sep> fix diagnostics and add tests <cm-sep> fix isolatedparam analysis for arrow functions <cm-sep> add isolatedparam tests for default values <para-sep> can have positional and named args . <nl> positional argument . <nl> named argument , there can not be positional arguments after this . <nl> no parameter defaults are added and there should not be named args . <nl> vararg is only for the rest param . <nl> part of the non-rest params are provided via the vararg . <nl> args for rest param provided as both individual args and vararg . <nl> test cases for the annotation .",parameters annotated with require an function argument if the function is being called in an context . <nl> this pr also fixes isolation analysis not happening for test source .,1601055819,> this do not support sender panic related scenarios .,0.9757188558578491
apache_flink/14730,"improve tracing of buffers . <nl> this commit provides additional contextual information that is easing debugging . <cm-sep> fix channelstatepersister # checkforbarrier . <nl> this commit also checks if # startpersisting called correctly . <nl> note that a few test cases in unalignedcontrollertest already fail with this new check , such that no new tests are needed . <cm-sep> adding magic bytes to unalignedcheckpointitcase to detect corruption quicker . <nl> currently , a corruption is often only detected only downstream which makes debugging harder .","with unusual barrier flow , checkpoints may miss certain buffers and become unrecoverable . <nl> - fix channelstatepersister . <nl> - improve unalignedcheckpointitcase to detect data corruption faster . <nl> - adding more trace output for network and checkpoint buffers as shown in the following . <nl> already covered by existing unalignedcontrollertest when assertion is added . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers :",1611323447,"this is the bug fix for , where the checking for deadlock caused by exchange in the deadlock break-up algorithm does not work for some cases . <nl> - fix checking for deadlock caused by exchange . <nl> this change added tests and can be verified by running the added tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) :",0.9373023509979248
vespa-engine_vespa/15643,pass only parameters needed for incremental reconfig <cm-sep> log the applied config <cm-sep> fix format of joining servers <cm-sep> fix format of leaving servers,"( hopefully ) . <nl> this fixes a bunch of things . <nl> * when using incremental reconfig , the third parameter ( ) to <nl> should be . <nl> the format of joining servers must * include the server id . <nl> the format of leaving servers must * only contain server ids .",1607008962,this pr ensures 0 ) by expiring a from only if it has no children .,0.9554709792137146
netty_netty/11148,"fire after last decoded data chunk . <nl> motivation : . <nl> may produce if it <nl> receives alert . this alert indicates that the engine is <nl> closed and no more data are expected in the pipeline . however , it fires <nl> the event before the last data chunk . as the result , further handlers <nl> may loose data if they handle . <nl> modifications : . <nl> - add tests to reproduce described behavior ; <nl> - move after fire of the last ; . <nl> result : . <nl> correctly indicates that the engine is <nl> closed and no more data are expected on the pipeline . <para-sep> handshake : <nl> send data : <nl> respond with data and close_notify : <nl> consume server response with close_notify : <nl> make sure client automatically responds with close_notify : <nl> jdk impl of tlsv1.0 does not automatically generate ' close_notify ' in response to the received ' close_notify ' alert . handle it differently : <nl> use sslcontext.newhandler ( alloc ) instead of new sslhandler ( sslcontext.newengine ( alloc ) ) to create non-jdk compatible openssl engine that can process partial packets :","motivation : . <nl> may produce if it <nl> receives alert . this alert indicates that the engine is <nl> closed and no more data are expected in the pipeline . however , it fires <nl> the event before the last data chunk . as the result , further handlers <nl> may lose data if they handle . <nl> modifications : . <nl> - add tests to reproduce described behavior ; <nl> - move after fire of the last ; . <nl> result : . <nl> correctly indicates that the engine is <nl> closed and no more data are expected",1617900242,use gathering writes if java version > = 0 and the channelbuffer is an instanceof compositechannelbuffer . <nl> this is mostly for discuss and testing,0.9581610560417175
OpenAPITools_openapi-generator/7423,[ go ] re-add deleted model template files,this line was mistakenly omitted when moving go-experimental to go and now the go generator does n't generate any models at all . this pr fixes that issue .,1600172348,"this pr only removes typemapping for ' list ' . all other custom mappings ( e.g . ' uuid ' ) still remain . while i believe they must not be there also , i 'm being conservative to minimize the impact .",0.9272456169128418
apache_shardingsphere/9599,add a merge statement test case,changes proposed in this pull request : <nl> - added a test case for statement,1614939369,fixes . <nl> changes proposed in this pull request : <nl> - add master-slave config for the proxy independently . <nl> - handle the sharding executing and m-s executing respectively . <nl> - clear master visited info after closing the connection .,0.9476271271705627
elastic_elasticsearch/72077,abort writes in repo analyzer . <nl> however we are also relying on the repository <nl> implementation correctly handling the case where a write is aborted <nl> before it completes . this is not guaranteed for third-party <nl> repositories . <nl> this commit adds a rare action during analysis which aborts the write <nl> just before it completes and verifies that the target blob is not found <nl> by any node .,however we are also relying on the repository <nl> implementation correctly handling the case where a write is aborted <nl> before it completes . this is not guaranteed for third-party <nl> repositories . <nl> this commit adds a rare action during analysis which aborts the write <nl> just before it completes and verifies that the target blob is not found <nl> by any node .,1619090807,"this commit introduces aarch64 packaging , including bundling an aarch64 jdk distribution . we had to make some interesting choices here : <nl> - ml binaries are not compiled for aarch64 , so for now we disable ml on aarch64 <nl> - depending on underlying page sizes , we have to disable class data sharing .",0.9489917159080505
ballerina-platform_ballerina-lang/25520,"fix typeof context completion for qualified names <cm-sep> add trap expression context completion support <cm-sep> add completion support for table type descriptor <para-sep> get let keyword snippet block . <nl> router can be called recursively . therefore , if there is an already checked resolver in the resolver chain , that means the particular resolver could not handle the completions request . therefore skip the particular node and traverse the parent ladder to find the nearest matching resolver . in order to handle this , the particular resolver chain check has been added . resolver chain check has been added to cover the use-case in the documentation of the method",- completion support for trap expression context <nl> - completion support for table type descriptor context <nl> - completion support fix for typeof expression context . <nl> - add table type descriptor resolver .,1598618277,"this requirement is a common one in most syntax tree editing scenarios . <nl> while descending , i check for the node to be replaced and replace it with the given replacement . then the new tree nodes are created while ascending . <nl> the original tree will not be modified ; if the node to be replaced can not be found . this implementation does not traverse through the whole tree . that would be a very inefficient approach . it traverses through potential branches in which the node to be replaced can be found .",0.9861819744110107
apache_kafka/10205,refactor the unit test a bit,# # # committer checklist ( excluded from commit message ) .,1614199931,"remove duplcated code , use common function in utils instead .",0.8584066033363342
neo4j_neo4j/10970,move logging to report actual listening port <para-sep> ipv6 <nl> ipv4,"this change alters the log output to report the actual port ( s ) on which the bolt connector ( s ) is/are listening . <nl> while not commonly used outside testing environments , it is possible to configure the socket to bind to port zero , which asks the network stack to select a vacant , high-numbered port . previously , this was reported in the log as rather than as the actual port number selected : . <nl> this pr moves the logging to a point when the actual port number is known and simply reports that instead",1517939268,makes * proceduresit flaky tests less flaky,0.9091512560844421
prestodb_presto/15390,refactor sessionpropertydefaults to load properties map,"goal <nl> - support session property override <nl> - presto on spark does n't have resource group , make regex matching rule for resource group optional . <nl> test <nl> - end to end test done .",1604422711,"i accidentally did n't merge it before , so merging now .",0.924655556678772
runelite_runelite/12752,updated neitiznot bridge values . <nl> only the northeast ( to the center island mine ) requires 0 agility,"update four neitiznot bridges to 0 agility requirement , only northeast bridge to the center island mine requires 0 agility",1604634310,the port sarim stash was reported as incorrect by an individual in discord . <nl> upon further testing of other stashes with non zero planes the wizards tower stash was discovered as being incorrect also .,0.9457262754440308
elastic_elasticsearch/71826,"introduce repositorydata.snapshotdetails . <nl> today we track a couple of values for each snapshot in the top-level <nl> blob : the overall snapshot state and the version of <nl> elasticsearch which took the snapshot . in the blob these values are <nl> fields of the corresponding snapshot object , but in code they 're kept in <nl> independent maps . in the near future we would like to track some more <nl> values in the same way , but adding a new field for every tracked value <nl> is a little ugly . this commit refactors these values into a single <nl> object , , so that it can be more easily extended in <nl> future . <para-sep> the details of each snapshot in the repository .","today we track a couple of values for each snapshot in the top-level <nl> blob : the overall snapshot state and the version of <nl> elasticsearch which took the snapshot . in the blob these values are <nl> fields of the corresponding snapshot object , but in code they 're kept in <nl> independent maps . in the near future we would like to track some more <nl> values in the same way , but adding a new field for every tracked value <nl> is a little ugly . this commit refactors these values into a single <nl> object ,",1618832679,"the blob store cache is used to cache a variable length of the begining of lucene files in the system index . this is useful to speed up lucene directory opening during shard recovery and to limit the number of bytes downloaded from the blob store when a searchable snapshot shard must be rebuilt . <nl> this pull request adds support for compound files segment ( .cfs ) when they are partially cached ( ie , ) so that the files they are composed of can also be cached in the blob store cache index .",0.9697788953781128
elastic_elasticsearch/72543,"allow some repository settings to be updated dynamically . <nl> this commit serves two purposes . for one , we need the ability to dynamically <nl> update a repository setting for the encrypted repository work . <nl> also , this allows dynamically updating repository rate limits while snapshots are <nl> in progress . this has often been an issue in the past where a long running snapshot <nl> made progress over a long period of time already but is going too slowly with the <nl> current rate limit . this left no good options , either throw away the existing <nl> partly done snapshot 's work and recreate the repo with a higher rate limit to speed <nl> things up or wait for a long time with the current rate limit . <nl> with this change the rate limit can simply be increased while a snapshot or restore <nl> is running and will take effect imidiately . <para-sep> use a small chunk size so the rate limiter does not overshoot to far and get blocked a very long time below <nl> we only run concurrent verification when we have a large snapshot pool on the data node because otherwise the verification would deadlock since the small pool is already blocked by the snapshot on the data node <nl> this setting update will fail so we can set the verification parameter randomly even if the snapshot pool is already blocked since we will never actually get to the verification step <nl> we only run concurrent verification when we have a large snapshot pool on the data node because otherwise the verification would deadlock since the small pool is already blocked by the snapshot on the data node <nl> we 're updating in place so the updated metadata must point at the same uuid and generations <nl> repository settings that can be updated dynamically without having to create a new repository . <nl> allow updating dummy setting for test purposes","this commit serves two purposes . for one , we need the ability to dynamically <nl> update a repository setting for the encrypted repository work ( hence the ignored settings parameter enabling <nl> nested repo types ) . <nl> also , this allows dynamically updating repository rate limits while snapshots are <nl> in progress . this has often been an issue in the past where a long running snapshot <nl> made progress over a long period of time already but is going too slowly with the <nl> current rate limit . this left no good options , either throw away",1619781856,"today the disk-based shard allocator accounts for incoming shards by <nl> subtracting the estimated size of the incoming shard from the free space on the <nl> node . this is an overly conservative estimate if the incoming shard has almost <nl> finished its recovery since in that case it is already consuming most of the <nl> disk space it needs . <nl> this change adds to the shard stats a measure of how much larger each store is <nl> expected to grow , computed from the ongoing recovery , and uses this to account <nl> for the disk usage of",0.9756469130516052
vespa-engine_vespa/15257,add a new java application for evaluating tensor conformance tests . <nl> * based on tensorconformancetest unit test class <nl> * reads json into slime structure <nl> * annotates with actual results from vespajlib evaluation <cm-sep> add script wrapper <cm-sep> install binary for vespa-tensor-conformance,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605018096,this is the final piece to allow users to retrieve metrics via their application 's containers .,0.9375301003456116
apache_incubator-pinot/5772,add user info in url to auth header,"but when the http request is redirected , the userinfo is discarded . hence to retain the basic authentication during redirects , we can set the request http header with the basic authentication token .",1596094872,"the gettimelinesviewinmonitoringwindow ( ) takes only the bucket time granularity from dataset configs . the function also has bucket time granularity from user . this design fails when the two config are not the same . this pull request is to resolve this issue . it takes both definitions of buckets , and apply the definition from function in default . but , it also compares the definition from dataset . if the function 's is smaller than the dataset 's , it applies the dataset 's instead . <nl> another part is to allow users to update function bucket",0.8829621076583862
quarkusio_quarkus/15126,update openapi to version . <cm-sep> apply user filter when storing openapi document . <cm-sep> add mutiny and vert.x core extensions to vault dependencies . <nl> ( cherry picked from commit sha ) <cm-sep> add mutiny and vert.x core extensions to spring cloud config dependencies . <nl> ( cherry picked from commit sha ) <cm-sep> add mutiny and vert.x core extensions to consul config dependencies . <nl> ( cherry picked from commit sha ) <cm-sep> use proper metrics path in kubernetes annotation . <cm-sep> have hibernate reactive depend on quarkus-mutiny correctly . <nl> ( cherry picked from commit sha ) <para-sep> store the document if needed <nl> filter to name the document <nl> also check if the custom filter applied,"please do n't merge , i will merge it myself .",1613509038,"please do n't merge , i will merge it myself .",0.96617591381073
apache_druid/10555,check exec status before return signal,"fixes druid throws java.util.concurrent.rejectedexecutionexception when ingest task is stopping . <nl> the root cause of this exception is that the function 'call ' in 'schedulewithfixeddelay ' always return signal.repeat all the time . it will constance submit jobs to exec , even though exec is shutdown . <nl> this pr checks exec status before return signal",1604473665,aggregators close ( ) method is not called when onheapincrementalindex tear down .,0.9253981709480286
vespa-engine_vespa/16517,"use singletons for all fallback components <para-sep> provide a singleton instance for all component fallbacks , otherwise fallback injection may lead to a cascade of components requiring reconstruction .",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1613395798,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8537358045578003
Alluxio_alluxio/10977,use meter for io metrics in client cache .,this will provide throughput numbers as well .,1582312459,do not create directory breadcrumbs on liststatus or isdirectory .,0.8603048920631409
apache_shardingsphere/10148,implement oracleprivilegehandler and add unit test,changes proposed in this pull request : <nl> - implement and add unit test .,1619051118,changes proposed in this pull request : <nl> - check the connection availability of source 's datasource . <nl> - check the connection availability of target 's datasource .,0.9634866118431091
confluentinc_ksql/6032,move deserialization to commandrunner and introduce degraded to commandrunnerstatus <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,review only last commit <nl> prevents the server from processing a command from a newer version than it . <nl> - start with fresh command topic <nl> - start up server on this branch <nl> - issue a bunch of statements to the command topic ( cs/csas ) <nl> - stopped the server <nl> - created a new branch and increment the version in command.java which is the expectedversion <nl> - start server and issue ddl statements <nl> - switched to this branch and start up server <nl> - verify with jconsole the commandrunnerstatus is degraded <nl> - verify all,1597646437,"at the moment static queries do not support returning rowtime as this information is not available in the response for ks iq . so this pr explicitly handles cases where rowtime appears in the projects and gives a better error message than just . <nl> in the future , we _may_ choose to support this by always including rowtime in the value of the changelog topic , but this is out of scope for this initial mvp . <nl> suitable tests added .",0.9494878649711609
elastic_elasticsearch/71876,"refactor shard-level snapshot state machine for better readability . <nl> refactoring this incredibly complicated loop into an object that holds <nl> all state required for looping through existing snapshots and updates . <nl> this hopefully makes it clearer what the different paths are across the <nl> various combinations of snapshots and clones by drying up across both <nl> where possible and splitting the logic to different methods for both <nl> otherwise . <para-sep> number of updated shard snapshot states as a result of applying updates to the snapshot entries seen so far <nl> number of started tasks as a result of applying updates to the snapshot entries seen so far <nl> current cluster state <nl> snapshot entries computed by applying tasks to existing snapshot entries <nl> updates outstanding to be applied to existing snapshot entries <nl> updates that were used to update an existing in-progress shard snapshot <nl> completed snapshots do not require any updates so we just add them to the output list and keep going . also we short circuit if there are no more unconsumed updates to apply . <nl> per snapshot entry state <nl> iterator containing the updates yet to be applied to # entry <nl> builder for updated shard snapshot status mappings if any could be computed <nl> builder for updated shard clone status mappings if any could be computed <nl> index lookup ( index name - > indexid ) cache for # entry used to translate from shardid to repositoryshardid <nl> loop over all the shard updates that are potentially applicable to the current snapshot entry <nl> the update applies to a different repository so it is irrelevant here <nl> update a currently running shard level operation <nl> try starting a new shard level operation because one has completed <nl> no point in doing noop updates that might happen if data nodes resends shard status after a disconnect . <nl> the update was already executed on the clone operation it applied to , now we check if it may be possible to start a shard snapshot or clone operation on the current entry <nl> we applied the update for a shard snapshot state to its snapshot entry , now check if we can update either a clone or a snapshot <nl> current entry is a snapshot operation so we must translate the repository shard id to a routing shard id <nl> the index name","refactoring this incredibly complicated loop into an object that holds <nl> all state required for looping through existing snapshots and updates . <nl> this hopefully makes it clearer what the different paths are across the <nl> various combinations of snapshots and clones . <nl> the hope here is that by drying up across both where possible and splitting the logic to different <nl> methods for both otherwise , the corner become easier to understand .",1618859885,changes the output format of preview regarding deduced mappings and enhances it to return all the details about auto-index creation . this allows the user to customize the index creation . using hlrc you can create a index request from the output of the response .,0.9725916981697083
ballerina-platform_ballerina-lang/24934,"fix actions in expressions . <nl> disallow actions where only expressions are allowed . change the asserts <nl> for tests asserts that had wrong trees . <para-sep> braced actions are just paranthesis enclosing actions , no need to add a diagnostic there when we have added diagnostics to its children",modified existing test asserts to go with the new change .,1595595036,"grpc blocking client call , does n't handle error responses properly . so return value to ballerina becomes null . so we set error type as return value . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9337204694747925
apache_druid/10653,fix post-aggregator computation <cm-sep> remove commented code <para-sep> following extractionfn will generate null value for one kind of quality,"post-aggregators , when used with subtotals , errors if the post-aggregator depends on a dimension that is absent in one of the subtotal . an example query is as follows . <nl> the exception is . <nl> i have removed the dimension renaming . we only carry over the dimensions included in the subtotal spec while generating results for any subtotal",1607429283,"- do n't use locks in . <nl> - behaviour of was unsafe , it was able to ' steal ' a valid reference of other segment 's accessor . because flag is set only when ' there are no more references ' to the basesegment . so it was able to call twice and it would decrement reference count twice and close the basesegment , even if there are active accessors ( via ) . <nl> - do n't use locks in . <nl> - some uses of were unsafe because they did n't acquire reference to segment while",0.9267072677612305
elastic_elasticsearch/72296,"we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects . <para-sep> not supported , close and create a new instance instead <nl> release whatever output we already buffered and write error response to fresh buffer <nl> this method should only be called once per request . <nl> fallback in case of encountering a bug , release the existing buffer if any ( to avoid leaking memory ) and acquire a new one to send out an error response <nl> releases the current output buffer for this channel . <nl> the production implementation in defaultrestchannel always releases the output buffer , so we must too",we must not reset the shared buffer after it has been used ( can happen in error handling in ) . <nl> there is never a good reason to reset a pooled bytes output either and the behavior is n't clearly defined so this commit <nl> disables the operation as it had unintended side effects .,1619513796,* faster and for which is nice since with this change we use it for the search cache <nl> * lighter for that should save memory and some indirection relative to the one on the abstract bytes reference <nl> * lighter implementation <nl> * build a instead of a whenever possible to save indirection and memory,0.9528781175613403
vespa-engine_vespa/15813,"add ( ignored , since it is failing ) test for chaning nodes used by cluster controllers <para-sep> add 0 node to see if this changes index of already existing cluster controllers <nl> todo : fails here because index has changed","add ( ignored , since it is failing ) test for changing nodes used by cluster controllers .",1608025467,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8462710976600647
crate_crate/10766,update jdbc to version . <nl> guava is updated as well to avoid a dependeny version conflict with <nl> org.checkerframework : checker-qual . <nl> ( cherry picked from commit sha ) <cm-sep> fix npe causing stuck queries in insert returning . <nl> if there is a failure on an individual item the results are which <nl> caused a nullpointerexception in the result collection for . <nl> an example where the failure happened is if the insert contains a <nl> duplicate primary key . <nl> ( cherry picked from commit sha ),mergify commands and options . <nl> you can also trigger mergify actions by commenting on this pull request : . <nl> - will re-evaluate the rules <nl> - will rebase this pr on its base branch <nl> - will merge the base branch into this pr <nl> - will backport this pr on branch . <nl> - look at your merge queues <nl> - generate the mergify configuration with the config editor .,1605175549,"cherry-pick of sha has failed : . <nl> to fixup this pull request , you can check out it locally .",0.8810687065124512
grpc_grpc-java/7422,update grpcsslcontexts.java . <nl> add support for ibmjsse2 <cm-sep> add files via upload . <nl> compiled on macbook <cm-sep> delete grpc-netty-.version-snapshot.jar <cm-sep> update grpcsslcontexts.java <cm-sep> update grpcsslcontexts.java <cm-sep> prebuilt jar for ibmjsee testing <cm-sep> delete grpc-netty-.version-snapshot.jar,"i made this very simple change to test for ibmjsse2 security provider in addition to the others . <nl> ibm jre does not support the sun provider , but instead has ibmjsse2 which supports the same api calls . <nl> i tested this on z/os machine as now it works when before it could n't find a security provider",1600099552,added and tested accessing peer attributes map from the handshaker result,0.8995097875595093
apache_druid/10325,fix npe in stringgroupbycolumnselectorstrategy # buffercomparator,"this patch defaults to use the lexicographic comparator , which i think was the original intention from reading the code",1598495908,"when joining on index tables with string keys , caching the computation of row id to row numbers improves performance on the * benchmarks by about 0 % if the column cache is enabled an by about 0 % if the column cache is disabled",0.960225522518158
netty_netty/11081,also support compositebytebuf with segmenteddatagrampacket . <nl> motivation : . <nl> sha introduced support for <nl> udp_segment but did restrict it to continous buffers . this is not needed <nl> as it is also fine to use compositebytebuf . <nl> modifications : . <nl> - allow to use compositebytebuf as well <nl> - add unit test . <nl> result : . <nl> more flexible usage of segmented datagrams possible,motivation : . <nl> sha introduced support for <nl> udp_segment but did restrict it to continous buffers . this is not needed <nl> as it is also fine to use compositebytebuf . <nl> modifications : . <nl> - allow to use compositebytebuf as well <nl> - add unit test . <nl> result : . <nl> more flexible usage of segmented datagrams possible,1615549811,"motivation : . <nl> starting with version.rc9 , conscrypt supports a buffer allocator . <nl> modifications : . <nl> - updated the creation process for the engine to pass through the <nl> bytebufallocator . <nl> - wrap a bytebufallocator with an adapter for conscrypt . <nl> - added a property to optionally control whether conscrypt uses <nl> netty 's buffer allocator . <nl> result : . <nl> netty+conscrypt will support using netty 's bytebufallocator .",0.9576506614685059
apache_kafka/10143,"changed becomeleaderorfollower to ignore partitions with invalid ids and return unknown_topic_id error <para-sep> checks if the topic id provided in the request is consistent with the topic id in the log . if a valid topic id is provided , and the log exists but has no id set , set the log id to be the request id . <nl> if the request had an invalid topic id , then we assume that topic ids are not supported . the topic id was not inconsistent , so return true . if the log is empty , then we can not say that topic id is inconsistent , so return true . <nl> check if topic id is in memory , if not , it must be new to the broker and does not have a metadata file . this is because if the broker previously wrote it to file , it would be recovered on restart after failure . topic id is consistent since we are just setting it here . <nl> topic id in log exists and matches request topic id <nl> next check the topic id and the partition 's leader epoch <nl> send request with invalid id .","changes how invalid ids are handled in leaderandisr requests . the id check now occurs before leader epoch . if the id exists and is invalid , the partition is ignored and a new error is returned in the response . <nl> this error should be rare , but if it occurs , it signals the need for manual intervention . <nl> added tests for this behavior .",1613595309,leftover threads doing network i/o can interfere with subsequent tests . add missing shutdown in tests and include admin client in the check for leftover threads .,0.8636789321899414
hazelcast_hazelcast/18176,"wip <cm-sep> wip <cm-sep> wip <para-sep> there is a bug in rexbuilder.makecast ( ) . if the operand is a literal , it can directly return a literal with the desired target type instead of an actual cast , but when doing that it does n't check for numeric overflow . for example if this method is converting [ 0 as tinyint ] is converted to 0 , which is obviously incorrect . it should have failed . we throw an error ( it would have been thrown if the conversion was performed at runtime anyway ) , before delegating to rexbuilder.makecast ( ) . the literal 's type might be different from the operand type for example here : cast ( cast ( 0 as smallint ) as tinyint ) the operand of the outer cast is validated as a smallint , however the operand , thanks to the simplification in rexbuilder.makecast ( ) , is converted to a literal [ 0 : smallint ] . and literalutils converts this operand to [ 0 : tinyint ] - we have to use the literal 's type instead of the validated operand type . <nl> not a literal <nl> calcite always uses decimal or double for literals . if the decimal is an integer that fits into a smaller integer type , replace the type . <nl> dealing with integer type family","in , calcite converts , in case is a literal , directly to a . however , it does n't correctly check for overflows , for which we had a workaround . however the workaround was insufficient : in case of it applied to the inner cast , but not to the outer , to which , after conversion , the parameter was also a rexliteral . for example , produced due to the overflow : the inner cast is valid , but the outer cast should throw . <nl> the fix improves the so that it can derive the",1612885840,"* when the leader is stepping down , it will not accept any new appends . <nl> it also notifies pending-response futures with . <nl> * is initialized only after <nl> the cp subsystem discovery process is completed . <nl> * metadata leader should not broadcast active cp members list before <nl> the cp subsystem discovery is completed . <nl> * we can not shutdown all cp members concurrently . if we have cp <nl> members , we can concurrently shutdown cp members first , wait for <nl> them to complete their shutdown , and then shutdown the remaining <nl>",0.9750779271125793
apache_incubator-pinot/5760,"enhance datatypetransformer to handle nested map/list/object [ ] <para-sep> note : the standardized value could be null for empty collection/map/object [ ] . <nl> standardize the value into supported types . empty collection/map/object [ ] will be standardized to null single-entry collection/map/object [ ] will be standardized to single value ( map key is ignored ) multi-entries collection/map/object [ ] will be standardized to object [ ] ( map key is ignored ) <nl> tests for map <nl> empty map <nl> map with single entry <nl> map with multiple entries <nl> should fail because map with multiple entries can not be standardized as single value <nl> expected <nl> tests for list <nl> empty list <nl> list with single entry <nl> list with multiple entries <nl> should fail because list with multiple entries can not be standardized as single value <nl> expected <nl> tests for object [ ] <nl> empty object [ ] <nl> object [ ] with single entry <nl> object [ ] with multiple entries <nl> should fail because object [ ] with multiple entries can not be standardized as single value <nl> expected <nl> tests for nested map/list/object [ ] <nl> map with empty list <nl> map with single-entry list <nl> map with one empty map and one single-entry map <nl> can be standardized into single value because empty map should be ignored <nl> map with multi-entries list <nl> should fail because map with multiple entries can not be standardized as single value <nl> expected <nl> map with one empty map , one single-entry list and one single-entry object [ ] <nl> should fail because map with multiple entries can not be standardized as single value <nl> expected <nl> list with two single-entry maps and one empty map <nl> should fail because list with multiple entries can not be standardized as single value <nl> expected <nl> object [ ] with two single-entry maps <nl> should fail because object [ ] with multiple entries can not be standardized as single value <nl> expected <nl> object [ ] with one empty object [ ] , one multi-entries list of nested map/list/object [ ] <nl> expected",- empty will be treated as <nl> - single-entry will be treated as single-value ( map key is ignored ) <nl> - multi-entry will be treated as multi-value ( map key is ignored ) <nl> - move after to handle the from empty . <nl> note : <nl> multi-entry will no longer be accepted for single-value column ( instead of using the first value because that will cause data loss ),1595891060,automatically update the kafka assignment if the capacity or the number of kafka partitions <nl> or the number of replicas per partition changes for the realtime table . the changes will take <nl> effect after the next succcessful run of validationmanager,0.9778432250022888
runelite_runelite/11866,slayer plugin : add activate slayer gem functionality and fix existing task for konar and wilderness tasks,slayer plugin : add activate slayer gem functionality and fix existing task for konar and wilderness tasks . <nl> i updated the regex for when you talk to a slayer master when already having a task to also work for konar and wilderness tasks and i also updated it to work for when you activate the slayer gem and i have added tests for these scenarios .,1591785470,"null tasks are technically valid , it only means they arent explicitly defined in the task enum . allow them through so that if there is a task capture failure the counter will still work . <nl> this functionality was especially useful when konar was released as every one of her tasks were not captured properly and ended up being null , this allowed people to have counters that worked as they expected until the release that captured her tasks correctly .",0.8915724754333496
elastic_elasticsearch/71484,"[ 0.x ] [ ml ] fix error on data frame analytics using a dest index without mappings . <nl> this commit fixes a failure to update the mappings of the destination index <nl> of a data frame analytics job during startup . the failure only occurs in . <nl> in particular , the bug occurs when the destination index contains no mappings <nl> at all . the code used to assume there will at least be mappings for the single <nl> type in the dest index . this assumption does n't hold . the fix checks whether <nl> the mappings are empty and if so creates an empty map for the type . <para-sep> test with and without mappings in the dest index <nl> we should never fail to create empty mapping_metadata","…t mappings . <nl> this commit fixes a failure to update the mappings of the destination index <nl> of a data frame analytics job during startup . the failure only occurs in . <nl> in particular , the bug occurs when the destination index contains no mappings <nl> at all . the code used to assume there will at least be mappings for the single <nl> type in the dest index . this assumption does n't hold . the fix checks whether <nl> the mappings are empty and if so creates an empty map for the type .",1617896861,"as requestoptions add requestconfig , users can set some request config per request , e.g sockettimeout . <nl> without requestconfig , sockettimeout can only set in restclient init . <nl> as different kind of request maybe have different request options , users can set requestconfig optional .",0.9408239126205444
elastic_elasticsearch/70829,"<para-sep> this test ensures that after a cluster restart , the forbidprivateindexsettings value is kept <nl> create / delete an index with forbidden setting <nl> full restart <nl> create / delete an index with forbidden setting <nl> create / delete an index with forbidden setting <nl> rolling restart <nl> create / delete an index with forbidden setting","forbidprivateindexsettings is a test tool to add internal setting to indexes , for example faking the version when they were created . the setting is controlled by overrides a method on esintegtestcase . <nl> currently if we do a cluster restart in one method , the setting is always set to true . this pr makes sure we keep honouring the value provided in the test .",1616607299,"today , ccr only checks the historyuuid of the leader shard when it has <nl> operations to replicate . if the follower shard is already in-sync with <nl> the leader shard , then ccr wo n't detect if the historyuuid of the leader <nl> shard has been changed . while this is not an issue , it can annoy users <nl> in the following situation : . <nl> 0. the follower index is in-sync with the leader index . <nl> 0. users restore the leader index from snapshots . <nl> 0. ccr wo n't detect the issue and report ok",0.9114574193954468
elastic_elasticsearch/71650,"* warn users if security is implicitly disabled . <nl> elasticsearch has security features implicitly disabled by default for <nl> basic and trial licenses , unless explicitly set in the configuration <nl> file . <nl> this may be good for onboarding , but it also lead to unintended insecure <nl> clusters . <nl> this change introduces clear warnings when security features are <nl> implicitly disabled . <nl> - a warning header in each rest response if security is implicitly <nl> disabled ; <nl> - a log message during cluster boot . <cm-sep> fixing the merge <para-sep> construct a basic auth header <nl> randomise between implicitly and explicitly disabled security <nl> if this is one of the first two runs ( security not yet enabled ) , then do n't clean up afterwards because we want to test restart with data <nl> security runs third , and should see the docs from the first two ( non-security ) runs security explicitly disabled runs second and should see the doc from the first ( implicitly disabled ) run","elasticsearch has security features implicitly disabled by default for <nl> basic and trial licenses , unless explicitly set in the configuration <nl> file . <nl> this may be good for onboarding , but it also lead to unintended insecure <nl> clusters . <nl> this change introduces clear warnings when security features are <nl> implicitly disabled . <nl> - a warning header in each rest response if security is implicitly <nl> disabled ; <nl> - a log message during cluster boot .",1618336773,"should n't really need a review , merge conflicts were minimal , but did want a ci run .",0.943213164806366
apache_kafka/9677,"create small abstraction for marking isr changes . <nl> this allows us to update the isr metrics in replicamanager without introducing it <nl> as a dependency to partition . <nl> also , this change includes updating these metrics for isr changes done through <nl> alterisr <cm-sep> add supporting test code <para-sep> complete the isr expansion",this pr adds a small abstraction that allows us to mark these metrics without bringing replicamanager in as a dependency of partition .,1606938028,otherwise the join-group would not be resend and we 'd just fall into the endless loop .,0.8623325228691101
ballerina-platform_ballerina-lang/23544,refactor the output stream <cm-sep> change the default access modifier to private <cm-sep> add the new array util functions <cm-sep> change the mappings to use the new array util functions <para-sep> this class contains the util methods related to the maven support of ballerina bindgen cli tool . <nl> returns a java boolean handle for a ballerina boolean <nl> returns a java integer handle for a ballerina integer <nl> returns a java character handle for a ballerina integer returns a java short handle for a ballerina integer returns a java long handle for a ballerina integer returns a java byte handle for a ballerina integer <nl> returns a java float handle for a ballerina float <nl> returns a java character handle for a ballerina float <nl> returns a java short handle for a ballerina float <nl> returns a java long handle for a ballerina float returns a java double handle for a ballerina float <nl> returns a java byte handle for a ballerina float <nl> returns a java integer handle for a ballerina float <nl> returns a java byte handle for a ballerina byte <nl> returns a java float handle for a ballerina byte <nl> returns a java character handle for a ballerina byte <nl> returns a java short handle for a ballerina byte <nl> returns a java long handle for a ballerina byte <nl> returns a java double handle for a ballerina byte returns a java integer handle for a ballerina byte <nl> returns a ballerina boolean from a java boolean handle <nl> returns a ballerina integer from a java integer handle <nl> returns a ballerina integer from a java byte handle <nl> returns a ballerina integer from a java short handle <nl> returns a ballerina integer from a java long handle <nl> returns a ballerina integer from a java character handle <nl> returns a ballerina float from a java float handle <nl> returns a ballerina float from a java short handle <nl> returns a ballerina float from a java byte handle <nl> returns a ballerina float from a java double handle <nl> returns a ballerina float from a java character handle <nl> returns a ballerina float from a java long handle <nl> returns a ballerina float from a java integer handle <nl> returns a ballerina byte from a java byte handle,- improve the array util functions and modify the bindings template accordingly . <nl> - refactor the output stream related code .,1590579501,change open tracer api to include init method to pass in configurations file . this will init an opentracing implementation and print the startuplog,0.971739649772644
apache_kafka/9985,": support non-routable quorum voter addresses <para-sep> update the voter endpoints ( if valid ) with what 's in raftconfig <nl> initialize the client . <nl> raftconfig encapsulates configuration specific to the raft quorum voter nodes . specifically , this class parses the voter node endpoints into an addressspec for use with the kafkaraftclient/kafkanetworkchannel . if the voter endpoints are not known at startup , a non-routable address can be provided instead .","with , we expect the raftconfig to specify the quorum voter endpoints upfront on startup . in the general case , this works fine . however , for testing we need a more lazy approach that discovers the other voters in the quorum after startup ( i.e . controller port bind ) . this approach also lends itself well to cases where we might have an observer that discovers the voter endpoints from , say a event .",1611781095,subtask jira <nl> main changes of this pr <nl> * deprecate old consumer.internal.partitionassignor and add public consumer.consumerpartitionassignor with all ootb assignors migrated to new interface <nl> * refactor assignor 's assignment/subscription related classes for easier to evolve api <nl> * removed version number from classes as it is only needed for serialization/deserialization . <nl> other previously-discussed cleanup included in this pr : <nl> * remove assignment.error added in pt 0 <nl> * remove consumercoordinator # adjustassignment added in pt 0,0.9668310284614563
apache_beam/13516,change fhir search dofn 's output type from string to jsonarray <cm-sep> apply spotless,change the output type of fhir search in the fhirio library from string to jsonarray,1607558831,added support for bit_or aggregation function in beam sql . <nl> i ran and that passed on my computer,0.9223198294639587
hazelcast_hazelcast/18390,"support plus and minus operations for interval types <para-sep> normalize interval literals to year-month or day-second literals . <nl> coerce only numeric or temporal types . <nl> if there is an interval on the one side , assume that the other side is a timestamp , because this is the only viable overload . <nl> if interval is the first parameter , then use the second parameter as return type . <nl> check numeric operation with temporal operands . date operands are coerced to timestamp . <nl> temporal + interval or temporal - interval . <nl> interval + temporal <nl> convert the given temporal type to timestamp . <nl> the inverse mapping is not needed , because we map multiple interval type to two internal types . <nl> check null values when one side is interval <nl> check null values when one side is temporal type . since we can not deduce the type of the other side , we fail . <nl> check normal operations <nl> check the inverse order of operands <nl> check parameter as temporal operand <nl> parameter on the other side of temporal operand should fail , because we do not expose interval literals . <nl> check null values when one side is interval <nl> check null values when one side is temporal type . since we can not deduce the type of the other side , we fail . <nl> check normal operations <nl> check the inverse order of operands <nl> check parameter as temporal operand . time is extended to timestamp <nl> parameter on the other side of temporal operand should fail , because we do not expose interval literals . <nl> check null values when one side is interval <nl> check null values when one side is temporal type . since we can not deduce the type of the other side , we fail . <nl> check normal operations <nl> check the inverse order of operands <nl> check parameter as temporal operand <nl> parameter on the other side of temporal operand should fail , because we do not expose interval literals . <nl> check null values when one side is interval <nl> check null values when one side is temporal type . since we can not deduce the type of the other side , we fail . <nl> check normal operations <nl> check the inverse order of operands <nl> check parameter as temporal",this pr introduces support for the following operations : <nl> 0 . <nl> 0 . <nl> 0 . <nl> where . <nl> validation logic is extended to support interval literals . inference strategies of and operations are adjusted accordingly : <nl> 0 . ( similar to postgres behavior ) <nl> 0 . ( similar to postgres behavior ) <nl> 0 . <nl> 0. . <nl> conversion logic is extended to normalize all interval literals into either or literals . these literals are then converted to our internal types . <nl> this pr does n't expose the interval types through a,1615541008,"this pr improves consistency checks for indexes when used from the sql service : <nl> 0. now indexes track precisely which partitions are indexed . in addition to this , we track when a partition is being indexed ( dynamic index creation , migration to the local member ) or unindexed ( migration from the local member ) <nl> 0. when the sql query is in progress , we request a stamp for the partitions that are expected to be available locally . then we validate that the stamp is still valid before returning the results . the stamp could",0.9667074680328369
apache_incubator-pinot/5324,"utility for conversion from timefieldspec to datetimefieldspec <cm-sep> tests <cm-sep> remove unused data provider <cm-sep> remove unused method <para-sep> eg : 0 ) round ( time , roundingvalue ) - round ( minutes , 0 ) , round ( millis , 0 : minutes ) 0 ) simple date time transformations 0 ) convert ( from_format , to_format , bucketing ) convert epoch millis to epoch seconds <nl> convert epoch millis to epoch minutes <nl> convert epoch millis to epoch days <nl> convert epoch millis to epoch seconds , round to nearest rounding bucket <nl> convert epoch millis to epoch minutes , round to nearest rounding bucket <nl> convert epoch millis to epoch hours , round to nearest rounding bucket <nl> convert epoch millis to epoch days , round to nearest rounding bucket <nl> todo : toepochxxxbucket methods are only needed to convert from timefieldspec to datetimefieldspec . practically , we need the toepochxxxrounded methods . convert epoch millis to epoch seconds , divided by given bucket , to get nsecondssinceepoch <nl> convert epoch millis to epoch minutes , divided by given bucket , to get nminutessinceepoch <nl> convert epoch millis to epoch hours , divided by given bucket , to get nhourssinceepoch <nl> convert epoch millis to epoch days , divided by given bucket , to get ndayssinceepoch <nl> converts epoch seconds to epoch millis <nl> converts epoch minutes to epoch millis <nl> converts epoch hours to epoch millis <nl> converts epoch days to epoch millis <nl> converts nsecondssinceepoch ( seconds that have been divided by a bucket ) , to epoch millis <nl> converts nminutessinceepoch ( minutes that have been divided by a bucket ) , to epoch millis <nl> converts nhourssinceepoch ( hours that have been divided by a bucket ) , to epoch millis <nl> converts ndayssinceepoch ( days that have been divided by a bucket ) , to epoch millis <nl> toepochseconds <nl> toepochseconds w/ rounding <nl> toepochseconds w/ bucketing <nl> toepochminutes <nl> toepochminutes w/ rounding <nl> toepochminutes w/ bucketing <nl> toepochhours <nl> toepochhours w/ rounding <nl> toepochhours w/ bucketing <nl> toepochdays <nl> toepochdays w/ rounding <nl> toepochdays w/ bucketing <nl> fromepochdays <nl> fromepochdays w/ bucketing <nl> fromepochhours <nl> fromepochhours w/ bucketing <nl> fromepochminutes <nl> fromepochminutes w/ bucketing <nl> fromepochseconds <nl> fromepochseconds w/ bucketing <nl> nested <nl> do nothing <nl> 0 ] only incoming * / <nl> incoming epoch millis <nl> incoming epoch hours <nl>","this pr adds a utility function which converts a timefieldspec to an equivalent datetimefieldspec . <nl> note that datetimefieldspec does n't have the concept of incoming/outgoing , and hence we add a transform function to convey the conversion . <nl> note : the toepochxxxbucket method is added to help with conversion from timefieldspec to datetimefieldspec . practically , we would only be using toepochxxx and toepochxxxrounded .",1588357167,"introduce datetimefieldspec to pinot schema for the following reasons : <nl> 0. have an ability in the pinot schema to distinguish between time column format and data granularity . currently there 's no way to specify data granularity , and the timespec is being used stretched to do both in one shot . <nl> 0. bring in a placeholder for creating a uniform time column across all pinot tables ( will be useful in doing rollups ) <nl> 0. provision for supporting multiple time columns of different type ( primary , derived etc ) .",0.9790375828742981
elastic_elasticsearch/72087,"we should n't loop over the listeners under the mutex in since in most use-cases we used <nl> with this class . <nl> also , no need to create an for direct execution . we use this listener on the hot path in authentication <nl> making this a worthwhile optimization i think . <nl> lastly , no need to clear and thus loop over , the list is not used again after the call returns anyway <nl> so no point in retaining it at all ( especially when in a number of use cases we add listeners only after the call <nl> so we can also save the instantiation by making the field non-final ) . <para-sep> this executor service does not support being <nl> notified of a response or exception on the thread completing this future . <nl> call get in a non-blocking fashion as we could be on a network thread or another thread like the scheduler , which we should never block !","we should n't loop over the listeners under the mutex in since in most use-cases we used <nl> with this class . <nl> also , no need to create an for direct execution . we use this listener on the hot path in authentication <nl> making this a worthwhile optimization i think . <nl> lastly , no need to clear and thus loop over , the list is not used again after the call returns anyway <nl> so no point in retaining it at all ( especially when in a number of use cases we add listeners only after the",1619097427,"just a cleanup i found when working on the recovery logic : . <nl> a class with 0 fields does not need a builder , especially <nl> when in many cases the builder result is just equivalent to the <nl> singleton to begin with . <nl> removed the builder and simplified related code accordingly .",0.9630640149116516
Graylog2_graylog2-server/9210,publish a userdeletedevent on user deletion,this allows plugins to react to user deletions .,1603128770,"in order to avoid leaving sidecars running in an unexpected state , this pr adds some restrictions on when it is possible to do certain actions : . <nl> - deleting a collector is only possible if there is not any configurations using it <nl> - deleting a configuration is only possible if there is not any sidecars using it <nl> - changing the collector associated to a configuration is only possible if there are no sidecars using that configuration .",0.9663268327713013
apache_incubator-pinot/5495,[ te ] push down top k filter to data provider <cm-sep> add top n support for scv and sql data source,this pr is to make the top k filter for dimension explore more efficient . <nl> originally we pull all dimension combinations and do the top k filter later . however for datasets with huge cardinality this is not efficient and caused multiple incidents . <nl> we need to pushdown the filter when querying the data .,1591285872,- moving monitoring window <nl> - moving window aligned to dataset granularity,0.9820584058761597
apache_druid/10198,"fix timeseries query constructor when postaggregator has an expression reading timestamp result column <para-sep> the below should be executed after context is initialized . <nl> if ' timestampresultfield ' is set , we must include a copy of the timestamp in the result . this is used by the sql layer when it generates a timeseries query for a group-by-time-floor sql query . the sql layer expects the result of the time-floor to have a specific name that is not going to be ' __time ' . this should be done before computing post aggregators since they can reference ' timestampresultfield ' . <nl> this class is for testing both timeseries and groupby queries with the same set of queries . <nl> can not vectorize with an expression virtual column <nl> can not vectorize with an expression virtual column <nl> can not vectorize with an expression virtual column","the timestamp result column should be passed to for timeseries queries , otherwise the query can fail at the sanity check with the below error if there are some post aggregators which read the timestamp result column",1595042632,"update the flag when a segment is dropped by a realtime task . <nl> in added a check in when none of the replicas is a realtime server type , mark . <nl> added unit test . <nl> this is marked because the semantics of the flag for a segment is changed , earlier a segment would be marked realtime , if any realtime task was serving the segment . it 's now changed to that a segment would be marked realtime , if _only_ realtime task is serving the segment and if a historical starts serving the segment ,",0.9540895819664001
quarkusio_quarkus/15548,"make sure version is mocked in snapshots . <nl> ( cherry picked from commit sha ) <cm-sep> do n't use real looking version in mocked data for snapshot testing . <nl> ( cherry picked from commit sha ) <cm-sep> fix some infelicities in the ide tooling guide . <nl> ( cherry picked from commit sha ) <cm-sep> use single mock when backing bean is the same instance . <cm-sep> make doc links relative . <nl> useful for versioned docs . <nl> ( cherry picked from commit sha ) <cm-sep> remove index.adoc . <nl> it is useless , unmaintained and harmful for versioned docs . <nl> ( cherry picked from commit sha ) <cm-sep> make sure the base quarkus-bom platform does not force its bom over other platforms found in the project . <nl> ( cherry picked from commit sha ) <cm-sep> make jackson work with readerinterceptors . <cm-sep> make mutable-jar work with jib in all cases . <cm-sep> revert ' fix : kubernetesdeployer now always deletes existing resources ' . <nl> this reverts commit sha . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> small path fix for the dev ui <nl> signed-off-by : phillip kruger . <nl> ( cherry picked from commit sha ) <para-sep> the first one wins <nl> the first one wins <nl> ignore for now <nl> here we are about to collect platform descriptors found among the project 's dependency constraints . normally , it 's a straightforward exercise , i.e . simply collect dependencies that match a pre-defined artifactid suffix . the ordering of the descriptors in our platform boms might not be consistent across different builds though . so this code is doing rough filtering to make sure the base platform ( quarkus-bom ) descriptor does not appear to be forcing its bom over the other platforms found in the project . luckily , though , this code is going to be replaced in the next version using the new extension catalog api . <nl> the first one wins <nl> the first one wins <nl> having completed the link : getting-started-testing [ testing your application guide ] <nl> this removes the last / from the path <nl> javac_options -parameters","please do n't merge , i will merge it myself .",1615230842,now users can just add simple annotations to their classes and an initializer class to automatically generate marshaller ( s ) and proto schemas that are then automatically registered in the injected remotecachemanager .,0.9813987612724304
runelite_runelite/11914,loottracker-hallowed-sepulchre : tracking for sepulchre w/ inventory snapshot <cm-sep> loottracker-hallowed-sepulchre : additional check before grabbing ground items <para-sep> hallow sepulchre coffin handling <nl> is player currently within the provided map regions,"this time leveraging inventorysnapshot , lot less changes required and now benefiting from the recent merge into loottracker of picking up potential grounditems . i did add an additional check to ensure players inventory has 0 items before trying to grab ground spawns .",1592408529,counts game ticks since login and displays them on the report button,0.8756118416786194
grpc_grpc-java/7503,"bdp ping accounting should occur after flow control . <nl> it 's hoped that this resolves the ' too_many_pings ' issue some users are <nl> seeing that is worked around by grpc_experimental_autoflowcontrol=false . <nl> this change also avoids resetting the ping count for empty data frames <nl> ( which should n't really happen with grpc ) . <nl> the previous code failed to reset the ping count on headers and <nl> window_update . the code _appeared_ to have callbacks for window_update , <nl> but was layered above the http2connection so was never called . thus , <nl> this version is much more aggressive then the previous version while <nl> also addressing the correctness issue . <cm-sep> reset bdp ping counter only for data . <nl> this makes the bdp pings more conservative , to the level of what existed <nl> before sha , to reduce risk that the bug fix introduces issues of <nl> its own .","it 's hoped that this resolves the ' too_many_pings ' issue some users are <nl> seeing that is worked around by grpc_experimental_autoflowcontrol=false . <nl> this change also avoids resetting the ping count for empty data frames <nl> ( which should n't really happen with grpc ) . <nl> the previous code failed to reset the ping count on headers and <nl> window_update . the code _appeared_ to have callbacks for window_update , <nl> but was layered above the http2connection so was never called . thus , <nl> this version is much more aggressive then the previous version while <nl> also",1602281594,"now that there is a config , the new defaults are now being enabled . <nl> previously there were no default limits . now keepalives may not be more <nl> frequent than every 0 minutes and only when there are outstanding rpcs .",0.8201661109924316
elastic_elasticsearch/70836,"[ ml ] this adds the ability for users to supply job and datafeed configs in datafeed preview <para-sep> create a new request to preview the provided datafeed config and optional job config <nl> test [ skip : set up kibana sample data ] <nl> nb : this is using the client from the transport layer , not the internal client . this is important because it means the datafeed search will fail if the user requesting the preview does n't have permission to search the relevant indices . <nl> fake datafeedtimingstatsreporter that does not have access to results index","previously , a datafeed and job must already exist for the api to work . <nl> with this change , users can get an accurate preview of the data that will be sent to the anomaly detection job <nl> without creating either of them . <nl> example : .",1616612951,"this pr enables stats on inference to be gathered and stored in the indices . <nl> each node + model_id will have its own running stats document and these will later be summed together when returning _stats to the user . <nl> is ilm managed ( when possible ) . so , at any point the underlying index could change . this means that a stats document that is read in and then later updated will actually be a new doc in a new index . this complicates matters as this means that having a running knowledge of seq_no and",0.9767976403236389
elastic_elasticsearch/71803,improve error message for operatorprivilegesit . <nl> an action must be declared to be either operator-only or non-operator . <nl> this pr adds more information about where to add the actions <nl> respectively in case of test failures .,an action must be declared to be either operator-only or non-operator . <nl> this pr adds more information about where to add the actions <nl> respectively in case of test failures .,1618795118,"if an email action is used in a foreach loop , message ids could have <nl> been duplicated , which then get rejected by the mail server . <nl> this commit introduces an additional static counter in the email action <nl> in order to ensure that every message id is unique .",0.9026613831520081
vespa-engine_vespa/15947,count lock timeout as unsuccessful run for exclusive maintainers <cm-sep> disallow non-staggered initial delay <para-sep> lock exception is treated as a failure,let it build pls . did n't bother building all the modules .,1610024594,do not start cluster monitor thread in test as it will race with explicit ping in test .,0.9671621918678284
hazelcast_hazelcast/18430,add table name & upsert descriptors to map planobjectkey,added sql table name & upsert descriptors to map as they are required by jet to support plan caching .,1616498184,avoid producing a thread dump ( and dumping it to system err ) when the test includes an expectedexception rule,0.8898032307624817
Graylog2_graylog2-server/9599,adding tests for missing host field in response . <cm-sep> gracefully handle missing field in nodes response .,"in some es implementations , the nodes api response is missing the field . before this change , parsing it resulted in an npe . <nl> this change is now handling the absence of this field gracefully and returns an empty optional .",1606217100,this led to an 0 server error <nl> and the api endpoint could not be used .,0.9618478417396545
apache_beam/13621,fix for the case when truststorelocation and keystorelocation are not specified <cm-sep> fix nullable coders casting,"in case if and/or parameters are n't specified the pipeline would fail . <nl> this pr fixes this issue and enables the scenario where the user does not want to provide key/trust stores , and only wants unencrypted communication",1609168521,this pr updates snowflake jdbc and adds ' application=beam ' string to url when building snowflake jdbc connection,0.9061346650123596
elastic_elasticsearch/71912,add deprecation warnings to geo fields that defined multifields,"with the exception of , no geometry field mappers actually support <nl> the use of multifields . however , we happily accept multifield definitions on these <nl> mappers and silently ignore them when it comes to indexing documents . with <nl> this commit , we emit deprecation warnings when a multifield definition is included <nl> on a geometry field mapper that does not in fact support one .",1618914168,"currently runtime fields from search requests do n't appear in the output of the <nl> field capabilities api , but some consumer of runtime fields would like to see <nl> runtime section just like they are defined in search requests reflected and <nl> merged into the field capabilities output . <nl> this change adds parsing of a ' runtime_mappings ' section equivallent to the one <nl> on search requests to the endpoint , passes this section down to <nl> the shard level where any runtime fields defined here overwrite the mapping of <nl> the targetet indices .",0.9354372620582581
apache_incubator-pinot/5846,adding /health endpoint in pinot controller <cm-sep> adding controller health check endpoint,existing check : is still available without any change of the behavior .,1597182297,"make time column name available from table/user config in places where primary time column is needed , in order to be able to support migration of single time column to multiple datetime columns",0.8772571086883545
elastic_elasticsearch/71836,[ ml ] use reset feature api for internal cluster ml tests,replaces the bespoke ml cleanup code with the feature reset api for internal cluster tests,1618837238,"this commit adds java compilation to the base precommit task , and adds <nl> that to the java plugin . this further reduces dependence on the build <nl> plugin .",0.8603107929229736
keycloak_keycloak/7220,include algorithm parameters . <nl> adds the capacity to add both public and secret algorithm <nl> specific data to a passwordcredentialmodel . the default <nl> way to create the models in maintained to minimize the change <nl> impact for the default hash infrastructure . <nl> publishes the passwordcredentialmodel constructor to <nl> ease in building such extended credential models .,adds the capacity to add both public and secret algorithm <nl> specific data to a passwordcredentialmodel . the default <nl> way to create the models in maintained to minimize the change <nl> impact for the default hash infrastructure . <nl> publishes the passwordcredentialmodel constructor to <nl> ease in building such extended credential models .,1593592508,"login form from sdk-html uses the same style for both saas and realm , but has slightly different configuration for each : <nl> - different background <nl> - no logo on realm ( until we can support upload of realm logo ) <nl> - powered by keycloak only shown on realm",0.8043986558914185
elastic_elasticsearch/70725,"add support for .tgz files in geoipdownloader <para-sep> there might be ./ entry in tar , we should skip it <nl> flatten structure , remove any directories present from the path ( should be ./ only ) <nl> this class is not suitable for general purpose tar processing ! <nl> go to the end of the current entry",we have to ship and files alongside files for legal compliance . infra will pack these in single ( gzipped tar ) archive provided by geoip databases service . <nl> this change adds support for that format to and,1616500958,"when a document which is distant from existing buckets gets collected , the will create a new bucket and then insert it into the ordered list of buckets . <nl> currently , a new merge map array is created to move this bucket . this is very expensive as there might be thousands of buckets . <nl> this pr creates methods in and , and updates the to use them . this eliminates the need to create an entire merge map array for each new bucket and reduces the memory overhead of the algorithm .",0.977912187576294
ballerina-platform_ballerina-lang/25690,add type information to assertion error message <para-sep> type check function ballerina/test # getballerinatype .,this will help users to identify the reason for assertion failure more easily .,1599652026,pr adds <nl> - removeheaders native function to remove all headers from the message <nl> - test cases <nl> - refactor doc comments .,0.9556300044059753
vespa-engine_vespa/16409,ignore maintenance collisions in controller and node-repository <cm-sep> revert back to initial nameservicedispatcher interval <para-sep> record completion of given job * /,"concluded that this approach is fine . some maintainers have unpredictable run <nl> durations while also needing to run as often as possible , which causes frequent <nl> timeouts and log noise .",1612517928,"if docker image is set for a node type , use that image when preloading docker image by host-admin for the corresponding host type . avoids unnecessarily downloading an image that will not be used .",0.8921997547149658
ballerina-platform_ballerina-lang/26578,update in progress gauge to not use main tags . <nl> this reduces the lookup time in the response path as well removes the need to have the separation between main tags and additional tags . <cm-sep> remove the separation between main tags and additional tags from observer context <cm-sep> remove downcasting of metrics in possible places in the metrics registry <cm-sep> remove unused max queue size check . <para-sep> todo : remove this method once all the usages in the standard libraries had been updated . <nl> the in progress counter is stored so that the same counter can be decremted when the observation ends . this is needed as the the program may add tags to the context causing the tags to be different at the end compared to the start .,"moreover , this contains some minor fixes to the metrics registry and some of the observability extensions .",1603637994,removed the google gson dependency and added fasterxml.jackson for better streaming support . <nl> -contributor : anjana fernando,0.9567552804946899
elastic_elasticsearch/70492,java8 and bwc changes <para-sep> prunes client stats of entries that have been disconnected for more than five minutes . <nl> the listener code about should never throw <nl> visible for testing <nl> returns a key suitable for use in a hash table for the specified httpchannel <nl> always use an identity-based hash code rather than one based on object state,"elasticsearch currently provides only the count of http clients currently holding an open connection and the number of http connections that have been opened on the node . <nl> this change adds the following to the ' http ' section of node stats : . <nl> some notes about the fields above : <nl> - : this is pulled from the or http header if either is present . note that it would be nice if elastic products identified themselves with a user-friendly tag . the header reports the go client or the js client for beats and kibana ,",1615987158,"elasticsearch currently provides only the count of http clients currently holding an open connection and the number of http connections that have been opened on the node . <nl> this change adds the following to the ' http ' section of node stats : . <nl> some notes about the fields above : <nl> - : this is pulled from the or http header if either is present . note that it would be nice if elastic products identified themselves with a user-friendly tag . the header reports the go client or the js client for beats and kibana ,",0.9997640252113342
prestodb_presto/15414,"fix lambdadefinitionexpression canonicalization . <nl> when canonicalize the body of the lambdadefinitionexpression , we might encouter <nl> block type constant . block.tostring implementation is not unqiue with respect <nl> to the uniqueness of the oject value . so change to use hashcode instead . <cm-sep> chage block 's tostring to be unique with respect to hashcode . <nl> we override the tostring method to be readable but did n't preserve it 's <nl> uniqueness . include the object hashcode in the string so we can easily <nl> tell whether two blocks are the same .",test plan - added new test in abstracttestqueries .,1604951811,fix the query and task state machines <nl> fix bugs with communicating ' no more data ' via http response codes,0.8947645425796509
apache_pulsar/9584,add maximum allowed amount of resources setting for functions <para-sep> max resources are not set,"the pulsar cluster may not allow users to request an arbitrary amount of resources for functions for various reasons , like quotas , limited physical resources , etc . and it 's better to check the function creation requests and explicitly reject those of which the resources requested are greater than allowed . <nl> add a worker config to set the maximum amount of resource a function must request . <nl> this change added tests and can be verified as follows : . <nl> - added unit tests to verify the configurations and checks . <nl> a sample configuration has",1613297079,"if the topic has relatively low traffic , the de-duplication cursor will not move . this can cause messages that are not able to be deleted based on the retention policy . we should add a policy to take de-duplication snapshots based on time .",0.9543443322181702
neo4j_neo4j/11182,"support byte [ ] as allowed procedure type for input and output <para-sep> fields that are not supported full stack ( ie . by cypher ) need to be mapped from cypher to internal types * / <nl> currently only byte [ ] is not supported as a cypher type , so we have specific conversion here . should we add more unsupported types we should generalize this . <nl> verify that the number of passed arguments matches the number expected in the mthod signature <nl> some input fields are not supported by cypher and need to be mapped <nl> verify and possibly map the input <nl> verify and possibly map the input <nl> verify and possibly map the input <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> expect <nl> when <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> expect <nl> when <nl> make sure argument here is not auto parameterized away as that will drop all type information on the floor <nl> given <nl> when <nl> then","changelog : support byte [ ] as valid input and output types for procedures , user defined functions and aggregation functions",1520375392,"do not sort property ids from schema descriptors as part of propertyexistenceenforcer creation . <nl> avoid sorting of property ids as part of enforcer creation since that will change <nl> property ids order in index descriptor , descriptors hashcode that as a result can cause <nl> incorrect index updates , inability to find an index with correct descriptor etc .",0.9667920470237732
OpenAPITools_openapi-generator/7437,"httpsigning implementation for csharpsdk <cm-sep> updated the sample for httpsigning <para-sep> / / httpsigning configuration / <nl> / / gets and sets the httpsigningconfiuration / <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key / <nl> / / gets the http signing header / <nl> / / gets the hash algorithm sha256 or sha512 / <nl> / / gets the signing algorithm / <nl> / / gets the signature validaty period in seconds / <nl> / / gets the headers for httpsigning / / / / / <nl> the time when the http signature expires . the api server should reject http requests that have expired . <nl> the 'date ' header . <nl> the 'host ' header . <nl> the time when the http signature was generated . <nl> when the 'digest ' header is included in the http signature , the client automatically computes the digest of the http request body , per rfc 0 . <nl> the 'authorization ' header is automatically generated by the client . it includes the list of signed headers and a base64-encoded signature . <nl> hash table to store singed headers <nl> get the body <nl> concatinate headers value separated by new line <nl> / / gets the ecdsa signature / / / <nl> last readbyte was n't a removed zero , so back up a byte <nl> / / detect the key type from the pem file . / / key file path in pem format / <nl> this type of key can hold many type different types of private key , but here due lack of pem header <nl> todo : - update the key based on oid <nl> / / gets the httpsigning configuration / <nl> / / httpsigning configuration / <nl> / / gets and sets the httpsigningconfiuration / <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key / <nl> / /",implemented the httpsigning auth for csharp sdk . <nl> it provides rsa key support and ecdsa key support ( for ecdsa key support it require dotnetcore3 and above ) . <nl> example to configure httpsigning configuration .,1600323420,"moshi does n't support parsing a base64 encoded string ( as defined for fields with type : string , format : byte ) to a kotlin.bytearray . the simplest solution to overcome this limitation was to convert those fields to kotlin.string instead of kotlin.bytearray . another solution would be to write a custom type adapter for moshi to support string to bytearray conversions . i have chosen the first method as this was the simplest for now . if there 's something against it , i have already prepared a custom type adapter ; ) . <nl> ps : there",1.0
apache_pulsar/9672,replace before/aftersuite with before/afterclass <cm-sep> remove the unnecessary usage of static fields <cm-sep> improve pulsarstandalonetestbase.stopcluster,"integration test classes misuse beforesuite and aftersuite annotations . when aftersuite is used to cleanup resources , it results in resources piling up for the duration of the complete test suite run . it 's like a memory leak since resources are n't properly cleaned up during test execution . <nl> some test classes implemented itest , which caused misleading error messages from testng . there should n't be a need to implement itest . <nl> besides the annotation issue , some resources were using static fields without a real reason . <nl> the usage of beforesuite & static fields",1614005585,the following changes were made in this pull request : . <nl> * configured the checkstyle plugin <nl> * fixed reported style violations . <nl> this pull request has only cosmetic changes in the pulsar client api module and should n't introduce any change in the business logic .,0.9300301671028137
hazelcast_hazelcast/18327,update the sql error messages when the cluster topology changed,this pr adds more details to the sql error message shown after the cluster topology change while executing a sql query .,1614685967,testing hazelcaststarter with 0.x instances in some tests is broken <nl> due to incompatible changes in version as expected .,0.7838902473449707
ballerina-platform_ballerina-lang/26256,deprecate bexecutor.submit ( ) method .,this will remove it from lang repo .,1602096239,"however , since it 's difficult to get current when performing above operation , we have introduced interface to access those observability related local properties from and . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no",0.9729908108711243
apache_pulsar/9164,move additional servlet module to pulsar broker common module <para-sep> the additional servlet interface for support additional servlet . <nl> load plugin config <nl> get the base path of prometheus metrics <nl> get the servlet holder <nl> metadata information about an additional servlet . <nl> the name of the additional servlet . <nl> the description of the additional servlet to be used for user help . <nl> the class name for the additional servlet . <nl> the collection of additional servlet definition . <nl> the metadata of additional servlet <nl> the definition of the additional servlet . <nl> the path to the additional servlet package . <nl> retrieve the additional servlet definition from the provided nar package . <nl> search and load the available additional servlets . <nl> load the additional servlets according to the additional servlet definition . <nl> an additional servlet with it 's classloader . <nl> a collection of loaded additional servlets . <nl> load the additional servlet for the given servlet name list . <nl> compatible with the current proxy configuration <nl> pulsar proxy servlet plugin . <nl> necessary to make powermockito.mockstatic work with testng . <nl> no-op,"# # # motivation . <nl> * update the class name to remove the proxy prefix <nl> * move to the a module . <nl> how to use this generic module . <nl> 0. add configuration and to the configuration file <nl> 0. call the following code . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api : ( yes / no ) <nl> - the schema : ( yes / no / do n't know",1610280364,# # # motivation . <nl> there are so many classes in functions code that are called utils.java . <nl> this makes find methods different and development unwieldy . <nl> consolidate some utils classes and rename some classes as well .,0.949996292591095
elastic_elasticsearch/72278,"remove mdp from persistedclusterstateservice . <nl> this commit removes multiple data path support from the <nl> persistedclusterstateservice . most notably , many error cases are no <nl> longer possible where duplicate/conflicting data could previously exist <nl> across multiple paths , there is now only one path . <para-sep> write empty cluster state just so that we have a persistent node id . there is no need to write out global metadata with cluster uuid as coordinating-only nodes do not snap into a cluster as they carry no state <nl> delete legacy cluster state files <nl> write legacy node metadata to prevent downgrades from spawning empty cluster state <nl> remove all persisted cluster states from the given data path , for use in tests . <nl> returns the node metadata for the given data path , and checks if the node ids are unique <nl> loads the available on-disk cluster state . <nl> if someone attempted surgery on the metadata index by hand , e.g . deleting broken segments , then maybe the global metadata is duplicated <nl> if someone attempted surgery on the metadata index by hand , e.g . deleting broken segments , then maybe some index metadata is duplicated","this commit removes multiple data path support from the <nl> persistedclusterstateservice . most notably , many error cases are no <nl> longer possible where duplicate/conflicting data could previously exist <nl> across multiple paths , there is now only one path .",1619474441,"this is mostly motivated by the performance issues we are seeing around the get mappings <nl> rest api which ( in case of a large number of indices ) will create decompressing streams in a hot loop <nl> which takes a significant amount of time for the system calls involved in instantiating deflaters <nl> and inflaters . <nl> also , this fixes a leaked deflater when deserializing cached repository data .",0.9493670463562012
grpc_grpc-java/7562,add a v2 test for cds response with upstreamtlscontext <para-sep> cds response containing upstreamtlscontext for a cluster . <nl> management server sends back cds response with upstreamtlscontext . <nl> client sent an ack cds request . <nl> cds response containing upstreamtlscontext for a cluster . <nl> management server sends back cds response with upstreamtlscontext . <nl> client sent an ack cds request .,this adds one test each for clientxdsclient and xdsclientimpl2 to partially address lack of test coverage,1603843802,"besides api changes , this implementation is also up-to-date with the <nl> latest design : . <nl> 0. delegate to round-robin and pick-first policies if requested by <nl> the naming system . <nl> 0. oob channels to loadbalancer always use the lb authority provided by <nl> the naming system . <nl> 0. never send application rpcs to balancer addresses , even if the <nl> address returns unimplemented error .",0.9252123236656189
hazelcast_hazelcast/18296,"update the javadocs of partitionlostevent and partitionlostlistener <para-sep> the event is fired when a primary replica of the partition is lost . if a backup node crashes when owner of the partition is still alive , a partition lost event wo n't be fired .",this pr updates the javadocs of partitionlostevent and partitionlostlistener classes .,1614251111,"this pr introduces a minor performance improvement to the routine . previously we closed the sql result by creating a specific upfront , even if the result set is fully consumed , and the result is already closed . after the fix , this exception is created only if the user calls on the result set that is not closed yet . this brings marginal , but visible improvement to the sql engine performance .",0.8479440808296204
apache_flink/14655,"add networkactionslogger for easier debugging <cm-sep> make source split assignment in unalignedcheckpointitcase stable . <nl> currently , the assignment is only stable if all splits are assigned at once . for any unexpected failure , the split assignment becomes more dynamic and the previously employed hash map made the assignment non-deterministic . the fix is to always assign a split to the same source instance , such that the base number ( nextnumber % increment ) is equal to the reader index .","currently , the assignment is only stable if all splits are assigned at once . for any unexpected failure , the split assignment becomes more dynamic and the previously employed hash map made the assignment non-deterministic . the fix is to always assign a split to the same source instance , such that the base number ( nextnumber % increment ) is equal to the reader index . <nl> - add networkactionslogger for easier debugging <nl> - make source split assignment in unalignedcheckpointitcase stable . <nl> mostly test with some new debug code . <nl> - dependencies ( does it",1610651641,"after . there are bugs in orctablesource . <nl> the case is there are some filters to be pushed down to source , but source can not consume them . we need distinguish empty filters from no pushed down in expainsource . <nl> return ' null ' if no filter pushed down , return ' true ' there is filter pushed down . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no",0.8448282480239868
elastic_elasticsearch/71993,"ensure no duplicate names among aggs , pipeline aggs and groups",this pr makes sure the generated names of groups and aggs are never the same .,1618984412,"the retention run goes through a number of steps and can randomly take more than 10s . <nl> = > increased timeout to 30s like we did in other spots in this test . <nl> also , noticed that we had a hard wait of 10s in this test , removed it and adjusted following <nl> busy assert in a way that can deal with a missing snapshot ( from when the assert runs before <nl> the snapshot was put into the cs ) .",0.8349370360374451
confluentinc_ksql/6109,fix typo <cm-sep> add component to ( de ) serialization processing log messages <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"currently , there 's nothing in the processing log message for ( de ) serialization errors to indicate whether it was the record key or value that failed to serialize/deserialize . this pr adds a new field to the relevant processing log message schemas called ' component ' with value ' key ' or ' value ' to indicate so . <nl> not in love with the name ' component ' but could n't think of anything better . suggestions appreciated ! <nl> also fixes a typo in the kafka deserializer error message that indicated the wrong format ( delimited",1598541399,"will match the first udf that has the correct number of arguments and the types match ( excluding the nulls ) . <nl> also updated the to throw an exception if a is passed in for a type that is expecting a primitive , i.e. , you ca n't cast ; .",0.9653924107551575
apache_shardingsphere/8986,"support to instrument the same method repeatedly <para-sep> wrapped class for target and provide a context to store variable during invocation . <nl> get the variable from context . <nl> store a variable into context . <nl> weaving the advice around the static methods of target class . <nl> intercept the target method and weave the method before origin method . it will invoke before the origin calling . <nl> intercept the target method and weave the method after origin method . it will invoke after the origin calling . <nl> weaving the method after origin method throwing . <nl> weaving the advice around the target method . <nl> intercept the target method and weave the method before origin method . it will invoke before the origin calling . <nl> intercept the target method and weave the method after origin method . it will invoke after the origin calling <nl> weaving the method after origin method throwing . <nl> compose class static method around advice . <nl> proxy class for bytebuddy to intercept methods of target and weave pre- and post-method around the target method . <nl> only intercept static method . <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> proxy class for bytebuddy to intercept methods of target and weave post-method after constructor . <nl> intercept constructor . <nl> checkstyle : off <nl> checkstyle : on <nl> proxy class for bytebuddy to intercept methods of target and weave pre- and post-method around the target method . <nl> only intercept instance method . <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> checkstyle : off <nl> checkstyle : on <nl> have to redefine this class dynamic , so never add modifier . <nl> mock method for testing .",fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,1610377477,changes proposed in this pull request : <nl> - add config/datasource package <nl> - optimize datasourceconfiguration <nl> - optimize datasourcefactory <nl> - rename variable configuration to config,0.953765869140625
apache_druid/10313,"make numeric_hashing_threshold configurable . <nl> change the default numeric hashing threshold to 0 and make it configurable . <nl> benchmarks attached to this pr show that binary searches are not more faster <nl> than doing a set contains check . the attached flamegraph shows the amount of <nl> time a query spent in the binary search . given the benchmarks , we can expect <nl> to see roughly a 2x speed up in this part of the query which works out to <nl> ~ a 0 % faster query in this instance .","change the default numeric hashing threshold to 0 and make it configurable . <nl> benchmarks attached to this pr show that binary searches are not faster <nl> than doing a set contains check . the attached flamegraph shows the amount of <nl> time a query spent in the binary search . given the benchmarks , we can expect <nl> to see roughly a 2x speed up in this part of the query which works out to <nl> ~ a 0 % faster query in this instance . <nl> in this flamegraph , a query is taking ~0 % of the",1598249308,"now that is being updated , it would make it easier for users to update to if they could easily revert to old behavior without having to update all segmentmetadataqueries they use . <nl> suggest not only providing an option to revert to old behavior but also be able to specify their own defaultanalysistypes using .",0.9516408443450928
quarkusio_quarkus/15976,revert ' register all profile properties in the default config source . ' <nl> this reverts commit sha . <cm-sep> fix quarkussecurityidentity.isanonymous check . <nl> ( cherry picked from commit sha ) <cm-sep> support for providing a custom extension registry client impl in a maven artifact . <nl> ( cherry picked from commit sha ) <para-sep> should be the first <nl> sets an anonymous identity status . <nl> todo auto-generated method stub <nl> todo auto-generated method stub <nl> todo auto-generated method stub <nl> todo auto-generated method stub <nl> registry client factory service provider interface that will be looked up on the class path using the serviceloader mechanism .,"please do n't merge , i will merge it myself .",1616572320,"please do n't merge , i 'll merge it myself .",0.9812240600585938
elastic_elasticsearch/71581,change runtime field script context names <cm-sep> remove extraneous comment,"this changes all the script context names specifically for runtime fields to be * _field such as and , etc . i tested this change locally on a mixed cluster to ensure scripts stored with the old runtime fields context names are both still retrievable and delete-able . this works because the context name is only used during the request to check for valid compilation , but never actually stored as part of the cluster state .",1618253739,"the api name could cause issues in the client <nl> libs because is a reserved word in many languages . rename the <nl> api to avoid this , and rename the other apis for consistency .",0.8541145920753479
grpc_grpc-java/7353,refactor to delete retrypolicy.default <para-sep> todo ( zdapeng ) : delete this because hedgingpolicy will be always available prior to starting retriablestream . this method is used no more than once for each call . <nl> todo ( zdapeng ) : delete this because retrypolicy will be always available prior to starting retriablestream . this method is used no more than once for each call .,we used and for the value of in to distinguish the state between name resolution not being completed and name resolution being completed but no retry policy . it will be cleaner to get rid of and simply use for absence of retrypolicy . will be deleted in upcoming pr .,1598285605,"previously pickresult 's subchannel must be the actual implementation <nl> returned from the channel 's helper , and channel would cast it to the <nl> implementation class in order to use it . this will be broken if <nl> subchannel is wrapped in the case of hierarchical loadbalancers . <nl> getinternalsubchannel ( ) is the guaranteed path for the channel to get <nl> the internalsubchannel implementation . it is friendly for wrapping .",0.9444143772125244
vespa-engine_vespa/15742,log allocation details of node being moved . <nl> ... and not for the host we 're moving from ( which is always allocated to <nl> ),... and not for the host we 're moving from ( which is always allocated to <nl> ) .,1607437727,this should fix the perf . test without any change on the other side ( although that change still make sense ) .,0.8275083899497986
apache_druid/10382,csvinputformattest should extend initializednullhandlingtest <cm-sep> firehosefactorytoinputsourceadaptortest should extends initializednullhandlingtest,"run mvn clean test passed on my macbook , but failed on the wsl ubuntu version . <nl> after some investigation , i found that the unit test cases run in different orders in these two environments . ut can pass on macos because other test cases called nullhandling.initializefortests ( ) ; before it . <nl> unit test , fail due to missing extend initializednullhandlingtest",1599799362,* remove remaining direct references to sun.misc.unsafe <nl> * replace jdk internal exceptions with closest publicly available one .,0.8671879172325134
apache_incubator-pinot/5748,"groovy transform function udf for queries <para-sep> evaluate the groovy function with bindings provided as an array of object the number of elements in the values must match the numarguments <nl> the groovytransformfunction executes groovy expressions 1st argument - json string containing returntype and issinglevalue e.g . ' { ' returntype ' : ' long ' , ' issinglevalue ' : false } ' 2nd argument - groovy script ( string ) using arg0 , arg1 , arg2 ... as arguments e.g . 'arg0 + ' ' + arg1 ' , 'arg0 + arg1.tolist ( ) .max ( ) + arg2 ' etc rest of the arguments - identifiers/functions to the groovy script sample queries : select groovy ( ' { ' returntype ' : ' long ' , ' issinglevalue ' : false } ' , 'arg0.findindexvalues { it==0 } ' , products ) from mytable select groovy ( ' { ' returntype ' : ' int ' , ' issinglevalue ' : true } ' , 'arg0 arg1 0 ' , arraylength ( units ) , columnb ) from bob <nl> 1st argument is a json string <nl> 2nd argument is groovy expression string <nl> 3rd argument onwards , all are arguments to the groovy function <nl> construct arguments string for groovyfunctionevaluator <nl> tests the groovy transform function <nl> max in array ( returns sv int ) <nl> simple addition ( returns sv long ) <nl> minimum of 0 numbers ( returns sv double ) <nl> ( returns sv float ) <nl> string operations ( returns sv string ) <nl> find all in array that match ( returns mv int ) <nl> ( returns mv long ) <nl> no-args function ( returns mv string ) <nl> nested groovy functions <nl> nested with other functions <nl> incorrect number of arguments <nl> first argument must be literal <nl> second argument must be a literal <nl> first argument must be a valid json <nl> first argument json must contain non-null key returntype <nl> first argument json must contain non-null key issinglevalue <nl> return type must be valid datatype enum <nl> arguments must be columns/transform functions <nl> invalid groovy expression","syntax : . <nl> - 1st argument is a json string representing all return value metadata . example : <nl> - 2nd argument is the groovy expression . use arg0 , arg1 etc for referring to arguments . <nl> - all remaining arguments ( 3rd to nth ) are arguments to the function ( identifiers/functions ) . <nl> examples : <nl> - single value result - . <nl> - single value result from array input - . <nl> - list result - . <nl> - nested with other pinot functions - . <nl> - multi line groovy script , with",1595560164,"this udf should be invoked with arguments : <nl> 0. column name to convert eg . eg : 0 : milliseconds : epoch , 0 : weeks : epoch , 0 : days : simple_date_format : yyyymmdd <nl> 0. granularity to bucket data into eg : 0 : hours , 0 : minutes . <nl> tested queries : <nl> select count ( * ) from tablename group by datetimeconvert ( timecolumn , ' 0 : hours : epoch ' , ' 0 : days : simple_date_format : yyyymmdd ' , ' 0 : days ' ) . <nl> select count",0.9740554690361023
apache_shardingsphere/10056,fix wrong table rewrite in update statement set clause,changes proposed in this pull request : <nl> - fix wrong table rewrite in update statement set clause,1618238250,changes proposed in this pull request : <nl> - fix visit,0.8593925833702087
apache_flink/15081,"copy record if needed when flush window buffer records to state . <para-sep> whether to copy key and input record , because key and record are reused . * / <nl> serializer to copy record if required . * / <nl> the incoming record is reused , we should copy it if state backend does n't copy it","this pull request aims to fix a minor bug in wtf which may cause unstable output . <nl> - update combinerecordsfunction to copy record if needed when flush window buffer records to state <nl> - update slicingwindowaggoperatorbuilder to pass inputrowtype to combinerecordsfunction.factory . <nl> - existed unstable case . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance",1614831775,"table like this will fail in sql-cli . <nl> the root cause is we will convert the properties into catalogtableimpl and then convert into properties again . the schema type properties will use new type systems then which is not equal to the legacy types due to conversion classes . <nl> we should avoid compare tableschema in . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers",0.8517560958862305
grpc_grpc-java/7644,remove temporary apis and update xds example to use new servercreds <para-sep> unsupported call . <nl> creates a server using the given xdsclient .,xds example with new api tested . this can be backported to version ...,1605805990,refactor to reuse and the implementation in .,0.9492571949958801
ballerina-platform_ballerina-lang/25472,update bir spec with intructions info,this pr also complete the taint_table and doc_attchment info in the spec .,1598526543,the current implementation considers this value to be specified in milliseconds . this pr fixes this value to be considered as seconds . <nl> this pr also updates the websub package.md file to include possible configurations .,0.8548480868339539
Alluxio_alluxio/12103,refactor tool registry to supply more information <para-sep> abstract class for validation environment . <nl> interface for a validation task run by validateenv command . <nl> gets the name of the task .,"i updated the tool interface so that it 's easier to determine the list of possible tasks that can come from each tool , as well as run a specific task",1599853097,"this pr fixes a recently-introduced issue where grpc clients hang when querying a backup master . in previous versions , backup masters would bind no ports , so queries would fail quickly . with the grpc changes , backup masters began binding the rpc and web port to reserve them . however , they would n't serve requests on the ports , so queries would connect to the ports , but then hang for an ~0 minute timeout . <nl> this affects failover scenarios and all embedded journal scenarios . when leadership changes , clients may still attempt to query",0.9683221578598022
apache_kafka/9729,: improve consumer group coordinator unavailable message,"when a consumer encounters an issue that triggers marking it to mark coordinator as unknown , the error message it prints does not give much context about the error that triggered it . this change includes the response error that triggered the transition or any other cause if not triggered by an error code in a response .",1607643163,"added a boolean to specify testing with no keys and pre-set partitions for records . <nl> also added a boolean to specify whether the batch is flushed by the throttle . usually this is to prevent added latency measurements , but it prevents testing with linger.ms and other scenarios to fill batches . <nl> modified a test to include these new parameters -- both set to false which was the default behavior . <nl> all previous trogdor producebench tests will run as before if these fields are not specified .",0.8910085558891296
confluentinc_ksql/6485,"add engine-common module + move sqlvaluecoercer . <nl> adds a module for ... well , common engine/server side stuff . historically , too much server side stuff gets put in , which is also used by the cli . this blurred the server/client lines . <nl> moved from to so that its accessible within . <nl> split into two impls of . the default one that 's used internally and a new api specific one . <para-sep> null can be cast to any type : <nl> if there was a field in the struct that was n't in the schema we can not coerce <nl> if we can not find the field in the struct , we can ignore it <nl> util class for working with sql identifiers <nl> given a user supplied identifier , return the sql identifier text . this method does not validate unquoted identifiers are valid sql identifiers . user supplied identifier can be quoted or unquoted . unquoted identifiers are converted to uppercase . quoted identifiers retain their case , and can contain escaped quotes . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when / then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> then : <nl> null can be cast to any type : <nl> if there was a field in the struct that was n't in the schema we can not coerce <nl> if we can not find the field in the struct , we can ignore it <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when / then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> coercer adds","adds a module for ... well , common engine/server side stuff . historically , too much server side stuff gets put in , which is also used by the cli . this blurred the server/client lines . <nl> moved from to so that its accessible within . <nl> split into two impls of . the default one that 's used internally and a new api specific one . <nl> usual .",1603365158,"this pr looks to add ssl support to ksql server . <nl> - while github may be showing as a new file , it is actually just a rename from without any changes , as i needed to add some unit tests for this class . please refrain from reviewing this file . <nl> - the documentation is probably the best place to start . luckily its at the top ! <nl> - the pr involves a fair amount of refactoring as it was necessary to allow me to test the changes . <nl> - i 've moved common handling",0.977249264717102
apache_druid/10696,"fix kinesis it <cm-sep> fix checkstyle <para-sep> all data written to stream within 0 secs . each task duration is 0 secs . hence , one task will be able to consume all data from the stream . <nl> shutdown all tasks of supervisor","fix kinesis integration test . <nl> this pr should now really fix it . ( verify by 0 consecutive passing of the kinesis it group . ) <nl> there were two causes for kinesis intermittent failure : <nl> 0 ) part of the kinesis it verify ingested data after the ingestion task completed ( so that segments are loaded onto historical and are no longer ' realtime ' . the test was doing this by terminating the supervisor to force the ingestion task to complete . however , it seems like there might be a bug that causes the running",1608538129,"this means that the coordinator will operate correctly until a server disappears for any reason , which will then lead to an exception of the form : . <nl> this pr fixes the issue by not shutting down the executors",0.940058171749115
apache_kafka/10085,"basic implementation for loading snapshot <cm-sep> add test for snapshot loading api <para-sep> ignore snapshots ; only interested in records appended by this leader <nl> a batch of records . this type contains a list of records along with the information associated with those records . <nl> the offset of the last record in the batch . <nl> the offset of the first record in the batch . <nl> the list of records in the batch . <nl> the epoch of the leader that appended the record batch . <nl> create a batch without any records . internally this is used to propagate offset information for control batches which do not decode to the type t . <nl> create a batch with the given base offset , epoch and records . <nl> when there is only a single voter , become candidate immediately <nl> this api is used when the listener needs to be notified of a new snapshot . this happens when the context 's next offset is less than the log start offset . <nl> initialize the client . this should only be called once on startup . <nl> buffer used as the backing store for nextbatches if needed <nl> number of bytes from records read up to now <nl> firstbatchsize ( ) is always non-null because the minimum buffer is header_size_up_to_magic . <nl> not enough bytes read ; create a bigger buffer <nl> update the buffer position to reflect the read batch <nl> read size of body in bytes <nl> read unused attributes <nl> read offset delta <nl> creates a slize of unaligned records from the position up to a size . <nl> returns all of the records backing this snapshot reader . <nl> a type for reading an immutable snapshot . a snapshot reader can be used to scan through all of the objects t in a snapshot . it is assumed that the content of the snapshot represents all of the objects t for the topic partition from offset 0 up to but not including the end offset in the snapshot id . <nl> returns the end offset and epoch for the snapshot . <nl> closes the snapshot reader . <nl> a type for writing a snapshot for a given end offset and epoch . <nl> advance the highwatermark <nl> check that listener was notified of the new snapshot <nl> advance the highwatermark <nl> check",implement raft snapshot loading api . <nl> 0. adds a new method to which is called whenever the determines that the needs to load a new snapshot before reading the log . this happens when the 's next offset is less than the log start offset also known as the earliest snapshot . <nl> 0. adds a new type which provides a interface and de-serializes records in the into s . <nl> 0. adds a new type that implements an by scanning a object and deserializes the batches and records into . this type is used by both and internally,1612829198,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.9754484295845032
apache_druid/10680,"integration test for coordinator and overlord leadership , added sys.servers is_leader column <cm-sep> docs <cm-sep> remove not needed <para-sep> no way to configure this since the config was stolen by the overlord <nl> no way to configure this since the config was stolen by the overlord <nl> if coordinator is not leader then it will return 0 instead of 0 <nl> fetch current leaders , make sure queries work , then swap leaders and do it again <nl> we expect leadership swap to happen <nl> host + ' : ' which should be enough to distinguish subsets , e.g . 'druid-coordinator:0 ' from 'druid-coordinator-two:0 ' for example <nl> no reason to kill the results if something is sad and there are no leaders <nl> returns a row for all node types which do n't serve data . the returned row contains only static information .","the goal is to get some coverage for in the integration tests and avoid any sort of regressions if possible . <nl> to aid in my sanity while testing this stuff , i have added to which is a long column which returns if the server is the leader and 0 if it is not ( for coordinators and overlords ) , and for services which do not have the concept of leadership , will return the default long value ( 0 in default mode , null if ) . <nl> the integration tests add a new test group ,",1608011919,"this request uses a mysql database to store configurations for how indexer workers should be created . previously , these configs were part of the jvm configs , and updates to the indexer coordinator were required in order to update worker configs . this commit introduces http endpoints on the indexer coordinator in which worker configs can be read and updated .",0.9853529930114746
apache_pulsar/9094,"support chained authentication with same auth method name . <nl> motivation . <nl> chained authentication is a very useful mechanism for migrating a cluster from <nl> one authentication provider to the other authentication provider . however , <nl> pulsar does n't support configuring multiple authentication providers with same <nl> auth method name . <nl> for example , a pulsar cluster was using standard jwt authentication initially . <nl> the users want to upgrade the pulsar cluster to use an oauth2 authentication <nl> mechanism . but both jwt and oauth2 share the same authentication method name . <nl> this change improves the authentication logic to support chained authentication <nl> with same auth method name . <para-sep> an authentication provider wraps a list of auth providers . <nl> store the exception so we can throw it later instead of a generic one <nl> when symmetric key is configured config keys <nl> generate tokens","motivation . <nl> chained authentication is a very useful mechanism for migrating a cluster from <nl> one authentication provider to the other authentication provider . however , <nl> pulsar does n't support configuring multiple authentication providers with same <nl> auth method name . <nl> for example , a pulsar cluster was using standard jwt authentication initially . <nl> the users want to upgrade the pulsar cluster to use an oauth2 authentication <nl> mechanism . but both jwt and oauth2 share the same authentication method name . <nl> this change improves the authentication logic to support chained authentication <nl> with same",1609322851,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> ( yes / no ) <nl> if yes , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> if a feature is not applicable for documentation , explain why ? <nl> if a feature is not documented yet in this pr , please create a followup issue for adding the documentation",0.9896613955497742
apache_pulsar/9240,: implement load-manager leader election using new coordinationservice interface <para-sep> loadmanager is a leader and let it refresh load-report from all the brokers,moving the load manager leader election to use the new coordingationservice leader election .,1611084095,"- clean up function , sink , source code <nl> - improving source and sink validation <nl> - refactor some code to avoid duplication",0.9548373222351074
elastic_elasticsearch/71877,[ ml ] using feature reset api for integration test clean up : external multi-node <para-sep> ignore <nl> ignore <nl> ignore <nl> ignore,"in machine learning integration tests there is logic for cleaning up created anomaly jobs , datafeeds and data frame analytics <nl> jobs . <nl> this commit removes all that logic and makes sure the integration tests are cleaned up with the feature state reset api .",1618860467,"today in tests we often use a utility method that creates and starts a <nl> transport service , and then we start it again in the tests anyway . this <nl> commit removes this unnecessary code and asserts that we only ever call <nl> once .",0.9352477788925171
Alluxio_alluxio/11484,"add hive metastore connectivity and permission check tool <para-sep> if the given hive metastore uris are valid if the hive metastore client connection can be established with the target server if hive metastore client operations can be run against the given database and tables <nl> run tests against an existing hive metastore . <nl> the maximum number of table objects that this test will get . used to avoid issuing too many calls to the hive metastore which may need a long time based on network conditions <nl> default hive metastore client socket timeout in minutes <nl> runs tests against an existing hive metastore . if an error occur , all the following tests will be skipped . <nl> check if the given configuration is valid . <nl> in ha mode , all the uris format need to be valid , but only one of the uris needs to be reachable . <nl> checks if the given uri is a valid and reachable hive metastore uri . <nl> note that the port may be reachable but not the actual hms port <nl> sets hive configuration based on input parameters . <nl> create hive metastore client . <nl> happens when the hms port is reachable but not the actual hms port thrown as runtimeexception with this error message <nl> this call may take too long if the database contains hundred thousands of tables and the network between hms and client is really bad <nl> should not reach here ! <nl> an action to connect to remote hive metastore . <nl> utilities to run the validation tests . <nl> task state . <nl> represents the result of a given task . <nl> output stores stdout if test passed or stderr if error thrown <nl> sets task state . <nl> sets task name . <nl> sets task output . <nl> sets task advice .",add a tool to check the connectivity and functionalities of an existing hive metastore .,1590686949,"created an alluxio shell command that does a bunch of environment checks to ensure alluxio can start correctly . it includes the following checks : . <nl> - check alluxio master port is open and available <nl> - check alluxio worker port is open and available <nl> - check nodes specified in conf/worker can be reached through ssh . <nl> user can run a specific set of commands by giving the check name or prefix . if no argument is given , it will run all checks . the command runs without requiring alluxio being started .",0.9927278161048889
apache_pulsar/9259,motivation . <nl> function worker should use authorization service to check <nl> a role if a superuser . <nl> modifications . <nl> - fix the issuperuser method in the function . <nl> verify this change . <nl> please pick either of following options . <nl> - adjust the original test case to verify it <para-sep> create a non-superuser admin to test the api <nl> test pulsar super user <nl> test super roles is null and it 's not a pulsar super user,motivation . <nl> function worker should use authorization service to check <nl> a role if a superuser . <nl> modifications . <nl> - fix the issuperuser method in the function . <nl> verify this change . <nl> - adjust the original test case to verify it,1611223436,"kubernetes has restrictions on the naming aspects of the jobs . currently there is no way of enforcing this at submission time . this means that such errors will only manifest themselves when the function is scheduled . this pr fixes it by adding admission time checks . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9158151745796204
apache_druid/10362,fix negative queuedsize problem in curatorloadqueuepeon <para-sep> when load failed a segment will be removed from the segmentstoload twice and null value will be returned at the second time in which case queuesize may be negative . <nl> pass,"this pr try to fix the negative queuesize problem . when we upgrade our clusters to version version , after running for a while , queuedsize of the loadqueuepeon will be negative . <nl> this can be reproduce by adding the following codes to the tail of testfailassign method in loadqueuepeontest . <nl> and the full testfailassign method will be : . <nl> after running the above method , we got the following logs : . <nl> finally , we found that the cause is actioncompleted method in curatorloadqueuepeon may be executed twice when failed loading happened and queuedsize will",1599403062,if i define a combiningfirehose with an ingestsegmentfirehose delegate in an indextask : . <nl> the following null check in ingestsegmentfirehosefactory.connect ( ) is triggered : . <nl> this pr adjusts indextask so that it passes the tasktoolbox to delegate ingestsegmentfirehosefactory objects inside a combiningfirehosefactory .,0.8561655879020691
apache_pulsar/9607,fix expired tls certs for cpp tests,problem . <nl> the current master is broken due to an expired ca cert is used in cpp tests . <nl> modification . <nl> use the certs we used for integration tests to keep it consistent across the rep .,1613555983,"when it is setting to use token authn , standalone pulsar will failed to start because of function worker authentication fail . <nl> it happens like this : <nl> standalone will start function workerservice , then workerservice will create a pulsar client to create topics . but this pulsar client in worker could not get properly configuration , and caused failure when it connects to server , which has authn enabled . <nl> add authn related configs , so user could config the client in worker , and make it work .",0.7694546580314636
Alluxio_alluxio/12121,improve job failure history rest api endpoint - add error type . <cm-sep> move presto config in emr to before starting alluxio . <nl> in order to set all configurations before starting alluxio processes . <cm-sep> fix slow and contented local cache restart . <nl> cherry-pick of existing commit . <cm-sep> update localcachemanager.java <cm-sep> reply with errors correctly in abstractwritehandler abort . <cm-sep> add s3 connection ttl config property . <cm-sep> add filters to job failure history . <para-sep> state of a cache . <nl> this cache is not in use . <nl> this cache is read only . <nl> this cache can both read and write .,merge changes in master branch to ratis-journal branch . <nl> bring ratis-journal branch up-to-date,1600733086,"it displays the metrics of short-circuit read , remote alluxio remote as well as ufs read . <nl> note this pr introduced tagging concept , which is of pattern . for example , the metric of becomes",0.9754723310470581
apache_pulsar/9716,fix to support to specify topics and subscriptions,- fix option for cli to specify multi topics . <nl> - add option for cli consume to specify multi subscriptions . <nl> - deprecate and hide the option . <nl> - modify the corresponding doc .,1614247087,"so we 'll able to read from ledger without creating additional subscription , it can benefit like querying compacted topic from pulsar sql . <nl> this change added tests and can be verified as follows : <nl> - added unit test to verify correct compacted ledger info is returned after compaction . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : yes <nl> - the schema : no <nl> - the default values of configurations : no <nl> - the wire protocol : no <nl> - the rest endpoints",0.9165419936180115
ballerina-platform_ballerina-lang/23996,improve diagnostics reporting for receive-action <cm-sep> improve diagnostic reporting in wait-action parsing <cm-sep> fix a bug in receive action parsing <cm-sep> improve enum related diagnostic reporting <cm-sep> improve diagnostic reporting in xml navigation <cm-sep> improve diagnostic reporting in right shift op parsing <cm-sep> improve diagnostic reporting in right shift operators <cm-sep> improve diagnostic reporting in tuple member parsing <cm-sep> remove unused old error reporting methods,"with this pr , i 've removed the old way of reporting missing tokens and nodes in the new parser .",1591946267,code will be generated as below . <nl> this also fixes the printing garbage values when instruction does n't have positions in bir emitter .,0.9453330039978027
elastic_elasticsearch/71354,fix scroll contexts counter in searchservice <para-sep> returns the number of scroll contexts opened on the node,the scroll context counter can be negative even become after handling many search requests . this bug causes two issues : . <nl> - disable the limit of open scroll contexts when the counter is negative <nl> - prevent opening new scroll contexts when the counter is greater than the limit of open scroll contexts . <nl> this bug was already fixed in version and later . i will add the assertions in this pr to 0.x and master .,1617723075,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.9408592581748962
OpenAPITools_openapi-generator/8181,make frequently used io resources autoclosable,"to reduce memory use and unlock them for use by operating system resource scheduler/allocator . <nl> below you can see i run the same template manager test which opens and reads io resources . i added extra line on debugger just to keep resources busy a bit longer for lsof to scan though them , this allows me to compare before/after results of my changes , as it would be much more difficult to automate this test inside maven , it 's all manual . <nl> list of files open by linux checked with . <nl> before changes : .",1607961669,"casting an to after a produces error in some cases . <nl> this is because of the implementation of ( the second part of the method ) : . <nl> in the case commented with ' // assume it 's an array if maxitems , minitems is set ' we have an . <nl> when we try to read the value , we need to check if we are allowed to cast or not .",0.9206613302230835
elastic_elasticsearch/72489,latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated . <para-sep> list of ignored timezones .,latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated .,1619709089,"relies on the resource watcher to detect the cert file overwriting . <nl> resource watcher detects changes by only inspecting the file size on disk and the last access timestamp . <nl> for the last access timestamp , the resolution can be as low as one second depending on the jdk and the fs type . <nl> it is thus preferable to rely on file size differences in tests .",0.8968687057495117
apache_pulsar/9225,support get topic applied policy for message ttl <para-sep> namespace-level default value is null <nl> topic-level default value is null <nl> use broker-level by default <nl> get message ttl applied for a topic .,"in pulsar , the topic will apply the topic level policy if present or apply the namespace policy if present or use the broker level configuration . it needs to support get the applied policy for a topic that might use the namespace policy or topic policy or broker level default configuration .",1610869421,"currently , pulsar support delete inactive topic which has no active producers and no subscriptions . this pull request is support to delete inactive topics that all subscriptions of the topic are caught up and no active producers/consumer . <nl> expose inactive topic delete mode in broker.conf , future more we can support namespace level configuration for the inactive topic delete mode . <nl> new unit tests added for each inactive topic delete mode . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no",0.9572985768318176
ballerina-platform_ballerina-lang/24691,add the cookie field in the config <cm-sep> add the new line,"so , this pr fixes this issue and add test cases for this .",1594368506,,0.0
vespa-engine_vespa/16926,"do n't store full bundle objects in cluster state history . <nl> bundles have a lot of sub-objects per state , so in systems with a <nl> high amount of node entries , this adds unnecessary pressure on the <nl> heap . instead , store the string representations of the bundle and <nl> the string representation of the diff to the previous state version <nl> ( if any ) . this is also inherently faster than computing the diffs <nl> on-demand on every status page render . <nl> also remove mutable field from . not worth <nl> violating immutability of an object just to get some prettier ( but <nl> with high likelihood actually more confusing ) status page rendering . <cm-sep> move zk/election-related info away from top of cc status page . <nl> much less immediately interesting than the actual cluster node information . <nl> move it just above the general event log instead . <cm-sep> move config output further down on the status page . <nl> always print regardless of leader eligibility state ; config is not <nl> predicated on this . <para-sep> tracks a configurable max number of cluster state history entries , pruning old entries as newer entries are added . to save memory , state diffs are computed once and cached as a string upon adding a new state bundle . only the most recent bundle is retained in its entirety . <nl> sets limit on how many cluster states can be kept in the in-memory queue . once the list exceeds this limit , the oldest state is repeatedly removed until the limit is no longer exceeded . <nl> represents the absolute cluster states ( baseline + derived ) for a given version as well as the relative diffs ( baseline + derived ) since the previous version . <nl> no diffs for the first entry in the history . <nl> yes , it 's correct to get the diff by doing old.gethtmldifference ( new ) rather than the other way around . <nl> state of master election <nl> overview of current config <nl> write cluster state history in descending time point order ( newest on top ) <nl> do n't bother duplicating output for non-baseline states if they exactly match what 's being output for the baseline state .","this primarily contains a memory usage optimization for state history tracking , but also some quality of life improvements for status page structuring and rendering . <nl> bundles have a lot of sub-objects per state , so in systems with a <nl> high amount of node entries , this adds unnecessary pressure on the <nl> heap . instead , store the string representations of the bundle and <nl> the string representation of the diff to the previous state version <nl> ( if any ) . this is also inherently faster than computing the diffs <nl> on-demand on every status page",1615559925,"it seems to me that the macros generated depends on the types of input macros , which differents between rank profiles . <nl> it is wasteful to do large constants per rank profile though , we should change that , but i want to keep it simple for now .",0.9816529750823975
ballerina-platform_ballerina-lang/25079,"add findnode api to parser <para-sep> find the inner most node encapsulating the a text range . note : when evaluating the position of a node to check the range this will include the start offset while excluding the end offset <nl> find a child node enclosing the given text range . if there is no child node which can wrap the given range , this method will return empty <nl> populate the external node . <nl> ignore <nl> list symbolcompletionitems = filterutils.filtervariableentriesondelimiter ( ctx , symboltoken , delimiter , defaulttokens , defaulttokentypes.lastindexof ( delimiter ) ) ;",therefore this particular api will fetch the node enclosing the given position .,1596204741,"following changes are added , . <nl> * fix the issue when proto file is depends on multiple proto files . current implementation needs to put all the proto files relative to the source proto file . created new issue [ 0 ] to support specifying dependent proto file path . <nl> * fix the code generator issue in computing output directory path from the proto file package . <nl> * fix the error handling issue in client stub initializing . <nl> * refactor proto message marshalling/unmarshalling logic to create ballerina value directly from input stream and write ballerina value",0.9737444519996643
apache_pulsar/9657,fix namespace-level maxunackedmessagesperconsumer did not take effect and can not be disabled <cm-sep> add update <para-sep> unblock consumer-throttling when limit check is disabled or receives half of maxunackedmessages = > consumer can start again consuming messages <nl> set namespace-level policy <nl> consumer-throttling should take effect <nl> disable limit check,"when the policy is modified , only the newly created consumer can use the new policy . the previously created consumer still uses the old policy . <nl> it is very difficult to restart consumers in the online environment . <nl> 0. this policy can not be disabled .",1613814831,that will make integration tests easier in future without forcing it to sleep and wait the block to kick in backlog quota check .,0.9546853303909302
apache_druid/10659,"forbid characters that can not be used in znodes . <para-sep> curator does n't permit any of the following ranges , so we ca n't either , because ids are often used as znode paths . the first two ranges are control characters , the second two ranges correspond to surrogate pairs . this means that characters outside the basic multilingual plane , such as emojis , are not allowed . 😢",objects like datasources and tasks are commonly used in znode paths .,1607473610,aggregators close ( ) method is not called when onheapincrementalindex tear down .,0.9286121129989624
elastic_elasticsearch/72195,"validate ip filter settings . <nl> today it is possible to set up an ip filter which throws an exception on <nl> creation , which is fatal to the cluster . this commit adds validation to <nl> the ip filtering settings to prevent this . <para-sep> it 's enough just to create the specified rule :","today it is possible to set up an ip filter which throws an exception on <nl> creation , which is fatal to the cluster . this commit adds validation to <nl> the ip filtering settings to prevent this .",1619372376,this pr ensures that api key role descriptors are always rewritten to a target node <nl> compatible format before a request is sent .,0.9243684411048889
apache_incubator-pinot/5484,"extract all fields if fieldstoread is null/empty <cm-sep> comment , remove dependency <para-sep> note about json behavior - can not distinguish between int/long and float/double . datatypetransformer fixes it .","doing this for json and avro for starters . the fieldstoread can become as the ' includelist ' . in the future we can introduce an ' excludelist ' . this will all be useful once we start doing advanced flattening ( e.g . flatten everything , include x , y exclude p , q , r ) . <nl> additionally , removing some sample groovy schemas , as we stopped using them when the refactoring to exclude schema from recordreaders/decoders was done . <nl> followup : do the same for all extractors .",1591066500,"autoloadpinot service has changed to autoloadservice . each data source config , can specify an auto onboard class . the autoloadservice will periodically run each data source 's autoload .",0.9614204168319702
elastic_elasticsearch/70668,"add cfs index caching support for full_copy searchable snapshots <cm-sep> extract caching <para-sep> accessing the byte buffer anymore that was passed to readwithoutblobcache <nl> always fill up buf to the max <nl> add the remaining bytes to buf <nl> ensure that last write is aligned on 4k boundaries ( = page size ) <nl> searchable snapshots index input that supports fully caching metadata files as well as header/footer information for each file , consisting of a two-level cache ( blobstorecacheservice and cacheservice ) . <nl> if > 0 , represents a logical file within a compound ( cfs ) file or is a slice thereof represents the offset of the logical compound file within the physical cfs file <nl> last read position is kept around in order to detect ( non ) contiguous reads for stats <nl> last seek position is kept around in order to detect forward/backward seeks for stats <nl> may have partially filled the buffer before the exception was thrown , so try and get the remainder directly . <nl> can we serve the read directly from disk ? if so , do so and do n't worry about anything else . <nl> we would have liked to find a cached entry but we did not find anything : the cache on the disk will be requested so we compute the region of the file we would like to have the next time . the region is expressed as a tuple of { start , end } where positions are relative to the whole file . <nl> we must fill in a cache miss even if cache_not_ready since the cache index is only created on the first put . todo tbd use a different trigger for creating the cache index and avoid a put in the cache_not_ready case . <nl> oh well , no big deal , at least we can return them to the caller . <nl> we assume that we only cache small portions of blobs so that we do not need to : - use a bigarrays for allocation - use an intermediate copy buffer to read the file in sensibly-sized chunks - release the buffer once the indexing operation is complete <nl> nb use channels.readfromfilechannelwitheofexception not readcachefile ( ) to avoid counting this in the stats <nl> normally does n't happen , we 're already obtaining a range covering all cache misses above","this pr unifies cachedblobcontainerindexinput and frozenindexinput so that they share the same infrastructure for caching metadata blobs as well as header and footer ranges for data blobs . the idea is to always use cacheservice for this , which does not evict the metadata , and which efficiently stores the information on disk ( using sparse file support ) . <nl> this also allows us to align writes in frozencacheservice to 4kb block sizes in this pr , which addresses an issue when reusing regions from the shared cache , as writes that are not aligned on page cache boundaries",1616430717,"the mapping refresh action was used when every local node used to process mappings , to eventually ask the master node to refresh its mappings and re-send them to all nodes . <nl> this is no longer needed and could actually be hiding some unexpected situations that we would like to know about and handle specifically . <nl> this commit removes the node refresh action which is not expected to be called by any node , and replaces it with an assertion that verifies that we never end up in a situation where we need a refresh . <nl> also",0.9677055478096008
apache_kafka/9792,: handle rebalance_in_progress error in joingroup <para-sep> make sure we 'll retry on next poll <nl> make sure both onjoinprepare and onjoincomplete got called,handle rebalance_in_progress error in joingroup to log correct info and request a rejoin .,1609147497,loop call consumer.endoffsets throw timeoutexception : failed to get offsets by times in 30000ms after a leader change,0.93155437707901
elastic_elasticsearch/70463,"change default format for date_nanos field . <nl> this commit updates the default format of date_nanos field <nl> on existing and new indices to use instead of <nl> . <nl> using as the default format for date_nanos does n't <nl> make sense because it accepts and parses dates with nanosecond precision , <nl> but when it formats it drops the nanoseconds . <nl> the change should be transparent for users , these formats accept the same input .","this commit updates the default format of date_nanos field <nl> on existing and new indices to use instead of <nl> . <nl> using as the default format for date_nanos does n't <nl> make sense because it accepts and parses dates with nanosecond precision , <nl> but when it formats it drops the nanoseconds . <nl> the change should be transparent for users , these formats accept the same input .",1615908115,this commit migrates the esintegtestcase tests in x-pack to the <nl> internalclustertest source set .,0.9168539643287659
elastic_elasticsearch/71155,enforce data_frozen for partial searchable snapshot _tier_preference . <nl> this commit makes the setting validate that the <nl> setting is only when set on a partial searchable snapshot index .,this commit makes the setting validate that the <nl> setting is only when set on a partial searchable snapshot index .,1617227112,"there is no guarantee of wire compatibility between nodes running <nl> different builds of the same version , but today we do not validate <nl> whether two communicating nodes are compatible or not . this results in <nl> confusing failures that look like serialization bugs , and it usually <nl> takes nontrivial effort to determine that the failure is in fact due to <nl> the user running incompatible builds . <nl> this commit adds the build hash to the transport service handshake and <nl> validates that matching versions have matching build hashes .",0.9493484497070312
Alluxio_alluxio/11470,fix permission denied while creating a directory <para-sep> this should never be reached since input gid is always valid <nl> this should never be reached since input uid is always valid,use-case : . <nl> alluxio superuser : . <nl> usera : . <nl> master.log .,1590254144,"this pr covers : <nl> 0. fix for the bug , that wrong header is sent to softlayer object store . this was caused authentication issues . <nl> 0. replace wrong ' apikey ' with ' password ' . new change is backward compatible and still supports ' apikey ' .",0.8965488076210022
apache_shardingsphere/9884,add testcase for mysqlprivilageloader <para-sep> administrativeprivilege <nl> databaseprivilege,changes proposed in this pull request : <nl> - add testcase for mysqlprivilageloader <nl> - fix mysqlprivilageloader load problem,1617118602,changes proposed in this pull request : <nl> - add test case,0.9494888186454773
elastic_elasticsearch/71854,"rename string_field script context to keyword_field . <nl> up until now , the name of the script contexts that runtime fields use was internal only . they recently got exposed through the painless execute api . this commit fixes the discrepancy between the field type used to define a runtime field of type keyword and the script context needed to simulate its corresponding script : string_field should be keyword_field .","up until now , the name of the script contexts that runtime fields use was internal only . they recently got exposed through the painless execute api . this commit fixes the discrepancy between the field type used to define a runtime field of type keyword and the script context needed to simulate its corresponding script : string_field should be keyword_field .",1618847060,renaming api before release . should be for uniformity with the other apis .,0.8671382665634155
elastic_elasticsearch/70575,"add _size and _doc_count to fields output . <nl> currently metadata fields like or can not be retrieved using <nl> the fields api . with this change , we allow this if the field is explicitely <nl> queried for using its name , but wo n't include metadata fields when e.g . <nl> requesting all fields via ' * ' . <nl> with this change , not all metadata fields will be retrievable by using its name , <nl> but support for ' _size ' and ' _doc_count ' ( which is fetched from source ) is <nl> added . support for other metadata field types will need to be decided case by <nl> case and an appropriate valuefetcher needs to be supplied . <para-sep> this should not work when requesting fields via wildcard expression <nl> we want to skip metadata fields if we have a wildcard pattern <nl> several other metadata fields throw exceptions via their value fetchers when trying to get them","currently metadata fields like or can not be retrieved using <nl> the fields api . with this change , we allow this if the field is explicitely <nl> queried for using its name , but wo n't include metadata fields when e.g . <nl> requesting all fields via ' * ' . <nl> with this change , not all metadata fields will be retrievable by using its name , <nl> but support for ' _size ' and ' _doc_count ' ( which is fetched from source ) is <nl> added . support for other metadata field types will need to",1616086101,eagerly creates the first backing index when a data stream is created .,0.9463893175125122
ballerina-platform_ballerina-lang/26629,error detail spec compliance . <nl> new check added to see if error detail type is sealed at the semantic analyzer phase .,"with the spec update , error detail type should be an inclusive-record-descriptor which is open to cloneable .",1603800007,we are still using custom redirection for post requests ( subscription ) since redirection is not supported for post requests .,0.855728268623352
grpc_grpc-java/7631,"move callcounterprovider interface definition into resolver provider <cm-sep> implement cluster_impl lb policy which is used to handle drops and circuit breaking for each prioity . <para-sep> load balancer for cluster_impl_experimental lb policy . this lb policy is the child lb policy of the priority_experimental lb policy and the parent lb policy of the weighted_target_experimental lb policy in the xds load balancing hierarchy . this lb policy applies cluster-level configurations to requests sent to the corresponding cluster , such as drop policies , circuit breakers . <nl> the following fields are effectively final . <nl> assume load report server does not change throughout cluster lifetime . <nl> counts the number of outstanding requests . <nl> the provider for the cluster_impl load balancing policy . this class should not be directly referenced in code . <nl> name of the cluster . <nl> resource name used in discovering endpoints via eds . only valid for eds clusters . <nl> load report server name . null if load reporting is disabled . <nl> cluster-level max concurrent request threshold . null if not specified . <nl> drop configurations . <nl> provides the direct child policy and its config . <nl> updated by endpoint discovery . <nl> populate configurations used by downstream lb policies from the freshest result . <nl> load balancing policy for each priority . <nl> config update updates drop policies . <nl> config update increments circuit breakers max_concurrent_requests threshold . <nl> create a locality-labeled address . <nl> no-op <nl> downstream lb hierarchy : prioritylb - > clusterimpllb ( one for each priority ) - > weightedtargetlb - > lrslb ( one for each locality ) - > roundrobinlb","implementation for cluster_impl lb policy as per c2p design . this policy sits in the middle of priority lb policy and weighted_target lb policy , its major functionality is to handle drops and apply circuit breakers . <nl> the idea is to move implementations of handling drops and circuit breakers from the eds lb policy ( will be split to cluster_resolver lb policy and cluster_impl lb policy ) to cluster_impl lb policy .",1605642784,"instead of failing after a a missing a/aaaa record , this change <nl> makes the resolver keep going and try out srv records too . this <nl> is needed for use with alts , and is part of the grpclb spec . <nl> this change also moved the jndi code to a separate , reflectively <nl> loaded file . this makes it easy to exclude the file and not worry <nl> about the missing class references on android . additionally , if <nl> javax.naming might be available on android , this allows it to be <nl> loaded . a key",0.9798813462257385
grpc_grpc-java/7737,"bump gradle and plugin versions . <nl> android plugins were n't touched , since they will need a lot more testing <nl> when doing so . <para-sep> we want this to throw an exception if it is n't working <nl> we want this to throw an exception if it is n't working","android plugins were n't touched , since they will need a lot more testing <nl> when doing so . <nl> validatorexception extends certificateexception",1608229852,unused variables in tests were deleted . the unused variable in netty <nl> was a future that needed completing ; that was a bug .,0.8156532049179077
confluentinc_ksql/6537,"allow '-e ' parameter to use variable substitution <cm-sep> show variables is not working with run script and '-f ' parameter <cm-sep> run script and '-f ' parameter do not handle print/select queries <para-sep> commands executed by the '-e ' parameter do not need to execute specific cli commands . for run script commands , users can use the '-f ' command parameter . <nl> handle and execute statements on the ksql servers and handle the response . <nl> given : <nl> when : <nl> then :",there are three fixes in this pr : <nl> * fix : allow '-e ' parameter to use variable substitution <nl> * fix : show variables is not working with run script and '-f ' parameter <nl> * fix : run script and '-f ' parameter do not handle print/select queries .,1603897926,fix issues with : <nl> - ssl context moved to build in kafka clients <nl> - kafka streams default state directory moved to '/var/lib ' which is inaccessible in on build servers .,0.9124345779418945
OpenAPITools_openapi-generator/7366,"templatedefinition as base for supportingfile . <nl> this allows encapsulation of supportingfile properties rather than <nl> direct field access . templatedefinition will be used as the base to <nl> allow for different types of supporting file extensions . <cm-sep> support user-defined templates . <nl> users would previously be forced to extend their target generator and go <nl> through more complicated customization steps just to add new files to <nl> generated output . <nl> this adds support for user-defined templates . <nl> users can now : . <nl> * add supporting files that are n't referenced in the target generator <nl> * include additional templates for api/model and their docs and <nl> templates <nl> * modify file extensions/suffixes for api/model ( docs+tests ) . <nl> notes on the new feature : . <nl> * this is currently a ' merge ' operation . existing definitions will be <nl> overwritten , but other template definitions will be untouched . this <nl> allows users to add files by default . <nl> * to modify generated suffixes/extensions for others ( not supporting <nl> files ) , may require inspection of source to exactly match the map key <nl> used in the target generator . e.g . ' model_doc.mustache ' , ' doc.md ' <nl> would output dogdoc.md . if the target generator includes <nl> ' model_doc.mustache ' and user passes ' model-doc.mustache ' , this will <nl> result in duplicate docs being generated . we do n't currently have a <nl> mechanism in place to inspect these . <para-sep> copy to the generated output directory without processing via the template engine ( due to template file extension ) . the empty object definition following allows the tool to infer the target output filename in the root of the output directory . compile a user-provided following our usual api template compilation logic . that is , one file will be created per api ; apis are generated defined according to tags in your spec documentation . the destination filename of will act as a suffix for the filename . so , a tag of will output a corresponding . because is the same mustache filename as used in your target generator ( in this example ) , we support the following : <nl> compile with the supporting files bundle , and output to in your output directory . note that we do n't currently support",users would previously be forced to extend their target generator and go <nl> through more complicated customization steps just to add new files to <nl> generated output . <nl> this adds support for user-defined templates . <nl> users can now : . <nl> * add supporting files that are n't referenced in the target generator <nl> * include additional templates for api/model and their docs and <nl> templates <nl> * modify file extensions/suffixes for api/model ( docs+tests ) . <nl> notes on the new feature : . <nl> * this is currently a ' merge ' operation . existing definitions,1599494472,"modified templates for , , , , , , , , and generators to only add double quotes around non-string and string enum default values , since already adds the quotes to non-enum string values . <nl> the issue is also present in code generated by , but attempted fixes caused problems with non-query params and likely require more substantial changes . <nl> also fixes a related issue with generation where the quotes on string default values were being html escaped , and string enum default values were not being quoted at all .",0.9785692691802979
vespa-engine_vespa/16313,bump interval of maintainers that collide often <cm-sep> use exceptions.tomessagestring,looks like these collide often : .,1612202907,this makes the window considered about 0 hour regardless of cluster size .,0.8588866591453552
grpc_grpc-java/7427,do not purge local cache when re-creating the ads stream . <cm-sep> make xds protocol version info persist across the lifetime of xdsclient . <cm-sep> fix v3 test interacting with ads stream closure and retry . <cm-sep> fix v2 test interacting with ads stream closure and retry . <para-sep> last successfully applied version_info for each resource type . starts with empty string . a version_info is used to update management server with client 's most recent knowledge of resources . <nl> client sent an ack cds request ( omitted ) .,"as discussed previously , the in the xds protocol represents the client 's knowledge for the state of that resource type . it should persist across ads stream recreation . even if the ads stream is recreated , the xdsclient should persist its knowledge for resources it has received . with this implementation , client and server are stateful across the xds communication . with persisted version_info , the management server knows resources that the client currently knows even after the stream is recreated . so it does not need to re-send resources that the client received with the previous",1600220753,this class will be reused to count servercall stats .,0.8582331538200378
apache_druid/10224,segment backed broadcast join indexedtable <cm-sep> fix comments <para-sep> prepare for broadcast <nl> load the data <nl> query metadata until druid schema is refreshed and datasource is available joinable <nl> now do some queries,"this is probably longer term done better as being part of , maybe a method , but since there might be other optimizations/customizations to the segment we are writing out to use for joins , i wanted to defer this change to future work to determine if there is a better segment format for this use case . <nl> the implementation is based on and similar to , but is fed with a which is scanned and the key columns are read to create the value indexes of the key columns , which are stored in heap memory in a",1596055411,"this request uses a mysql database to store configurations for how indexer workers should be created . previously , these configs were part of the jvm configs , and updates to the indexer coordinator were required in order to update worker configs . this commit introduces http endpoints on the indexer coordinator in which worker configs can be read and updated .",0.9812402129173279
apache_beam/12830,testpubsub deletes subscriptions created in the same project,"see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1599860663,description here . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .,0.8920135498046875
ballerina-platform_ballerina-lang/26611,add dependency and other entry details <cm-sep> create packagedescriptor with dependency and other entries <cm-sep> add cases to test packagedescriptor creation <para-sep> other entries hold other key/value pairs available in the ballerina.toml file . these keys are not part of the ballerina package specification . <nl> todo do we need to custom key/value par mapping here <nl> ballerina toml processor which processes the toml file parsed and populate the ballerinatoml pojo . <nl> parse file in to object . <nl> todo validate todo following parse is done only to validate . we can remove it once we refactor this parser <nl> process dependencies <nl> parse file stream in to object . <nl> parse file stream in to object . <nl> validate the package block in ballerinatoml . <nl> check org exists <nl> check org is valid identifier <nl> check name exists <nl> check that the package name is valid <nl> check version exists <nl> check version is compatible with semver <nl> validate dependencies block in ballerinatoml . <nl> lowercase the first letter of this string .,"with this pr , i am introducing the following format in to declare dependencies and platform-specific dependencies .",1603753997,- receiveactionnode <nl> - asyncsendactionnode <nl> - syncsendactionnode <nl> - forkstatementnode .,0.9634044766426086
neo4j_neo4j/11189,"fixed thread stickiness condition and add a couple of tests <para-sep> currently , we 're doing our best to keep things together we should not switch threads when there 's an active statement ( executing/streaming ) also , we 're currently sticking to the thread when there 's an open transaction due to cursor errors we receive when a transaction is picked up by another thread linearly .","in its initial version , thread stickiness of a bolt connection was decided based on the condition . <nl> which was causing problems when the state machine is interrupted with a message . now , the condition is changed to . <nl> which delegates the decision to actual statement processor that knows of both active transaction and statement ( result ) handle .",1520429498,"when client transactions are not closed appropriately , bolt server continues to hold related transactions even if the server is configured to time out transactions . this pr addresses this problem and validates the transaction ( if any ) and releases it in case it is timed out . with releasing , the transaction state machine is reset - closing any open statement handles and transactions . <nl> in case the client tries to interact with the server , the recorded termination status message is returned to the client as a failure message .",0.9373048543930054
keycloak_keycloak/6616,not hide exception in email templating,"if the email template is not valid ( ex . on a custom theme ) , there is an exception that does not explicit the correct error cause . it 's an exception about javax.mail ( email without body ) . <nl> instead , in the console output , i want to see the freemarker error that helps me to fix the template .",1576838567,modified 0 source files : <nl> ./adapters/oidc/adapter-core/src/main/java/org/keycloak/adapters/basicauthrequestauthenticator.java <nl> ./core/src/main/java/org/keycloak/util/basicauthhelper.java <nl> ./services/src/main/java/org/keycloak/protocol/saml/profile/ecp/authenticator/httpbasicauthenticator.java,0.8005537390708923
apache_shardingsphere/9467,add support grant <cm-sep> add visitor and format code <cm-sep> fix <para-sep> | adddate <nl> | require_table_primary_key_check <nl> | skip <nl> | subdate <nl> acl type enum . <nl> grant level segment . <nl> grant level type enum . <nl> privilege type enum . <nl> mysql privilege segment . <nl> role or privilege segment . <nl> todo add assert for grant . todo add assert for revoke .,changes proposed in this pull request : <nl> - fix g4 of revoke and grant <nl> - add and statement definitions <nl> - add visitor,1613975747,- fix get data source for shadow <nl> - add shadow insert values token generator <nl> - add remove shadow column token generator <nl> - add the executeupdate,0.956485390663147
confluentinc_ksql/6267,new cli parameter to execute a command and quit ( without cli interaction ) <para-sep> handles the run script command if found <nl> ignore - only used by runinteractively ( ) to exit the cli <nl> append a colon if not specified <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"adds a new paramter to the cli to execute a command and quit . this without having to interact with the cli console . <nl> you can use a different output format to easily parse the command result . for instance , json : .",1600711562,"it uses a , that should be returned by the , to verify if the user has access to the ksql cluster . <nl> the returns a dummy authorizer that allows access to any user . <nl> testing the actual functionality of this change requires a non-default implementation of ksqlsecurityextension .",0.9587830305099487
grpc_grpc-java/7610,"api , core : interceptor-based config selector <para-sep> todo ( zdapeng ) : delete calloptions and committedcallback fields , and migrate to use interceptor only . <nl> returns an interceptor that will be applies to calls . <nl> sets the committed callback . this field is optional . sets the interceptor . this field is optional . <nl> todo ( zdapeng ) : remove this arg <nl> a client call for a given channel that applies a given config selector when it starts . <nl> todo ( zdapeng ) : delete this when migrating to use interceptor-based config selector only . <nl> todo ( zdapeng ) : delete this when migrating to use interceptor-based config selector only . <nl> converts the service config to config selector . * / <nl> * / <nl> the underlying call directly created by the channel . <nl> an interceptor that mutates calloptions based on headers value . <nl> calloptions actually received from the channel when the call is created . <nl> an interceptor that mutates calloptions based on headers value . <nl> make the transport available <nl> clean up as much as possible to allow the channel to terminate .","interceptor-based config selector will be needed for fault injection . <nl> add field to . keep and fields for the moment , because it needs a refactoring to migrate the existing xds config selector implementation to the new api .",1605036675,"add a new a metadata.binarystreammarshaller interface which serializes to/from instances of inputstream , and a corresponding key.of ( ) factory method . <nl> values set with this type of key will be kept unserialized internally , alongside a reference to the marshaller . a new method internalmetadata.serializepartial ( ) , returns values which are either <nl> byte [ ] or inputstream , allowing transport-specific handling of lazily-serialized values . <nl> for the regular serialize ( ) method , stream-marshalled values will be converted to byte [ ] via inputstreams . <nl> transport-internal code can also create metadata with pre-parsed values",0.979505717754364
apache_pulsar/8995,remove duplicated broker prometheus metrics type <para-sep> check for duplicate type definitions,"if there are multiple topics from different namespaces , the broker prometheus metrics will print out duplicated definition for pulsar_ml_addentrybytesrate and other managed ledger metrics . <nl> on the broker , run this command to check validity of pulsar broker metric format . <nl> to prevent duplicated metrics type definition , the definition is now tracked and only printed out once . it leverages the existing metrics name set already defined under parsemetricstoprometheusmetrics ( ) in prometheusmetricsgenerator.java . <nl> this change added tests and can be verified as follows : . <nl> added two topics under new namespaces to trigger",1608248893,"currently for functions running in kubernetes both the request and limit for cpu and memory are specified by resources arguments . the problem is that sometimes it makes sense for the request and limit to be different values . <nl> this commit adds the ability to the basickubernetescustomizer to individualy override the request and limit values for cpu and memory . <nl> this change added tests and can be verified as follows : . <nl> - added test to ensure that the values specified in the custom runtime options are passed to the containers . <nl> if was chosen ,",0.9299280643463135
confluentinc_ksql/6321,"update historic plans with serde features . <nl> as noted in a previous pr , not have the and in the post condition check for sources in the metastore means qtt wo n't check the key and value features . <nl> while this is n't an issue at the moment , ( as the nodes _will_ check these ) , it 's likely safer to add in these checks , so that future changes do n't inadvertently remove the checks from the , leaving nothing checking the serde features . <nl> this commit also fixes a bug where the was being incorrectly set to the key format , and adds in that to the files . <nl> note : using the to regenerate the historic plans can result in the order of nodes within the node 's to be re-ordered , making the diff larger than it need to be . to stop this happening next time the nodes are now sorted alphabetically . <cm-sep> historical plans <para-sep> sort so that we get consistent ordering in historic specs : <nl> given : <nl> when : <nl> then :","as noted in a previous pr , not have the and in the post condition check for sources in the metastore means qtt wo n't check the key and value features . <nl> while this is n't an issue at the moment , ( as the nodes _will_ check these ) , it 's likely safer to add in these checks , so that future changes do n't inadvertently remove the checks from the , leaving nothing checking the serde features . <nl> this commit also fixes a bug where the was being incorrectly set to the key format ,",1601454725,"if a stream with no key column is created over a topic : . <nl> and if the underlying topic 's records has data in the key , then any use of the stream was failing with the error ' data should be null for a voiddeserializer . ' <nl> this failure was because we were using the stream 's inbuilt serde to handle the key of streams with no key columns . however , the deserializer was throwing this error . the fix is to use our own deserializer which ignores any data in the topic record . <nl>",0.8869351148605347
Alluxio_alluxio/11399,compiles and works <para-sep> an example to show to how use alluxio 's api .,"this moves , and from to module . <nl> moving too as it uses . is also renamed to to be more expressive .",1588912578,"previously , the will log all the messages on the console . when running against object stores , many retry messages will show on the console to make users confusing . moving the logs to user.log . fix one ufs test .",0.9140000343322754
ballerina-platform_ballerina-lang/26610,"modify syntax tree and test cases <cm-sep> add isolated module var declaration parsing support <para-sep> clones the last node in list with the invalid node as trailing minutiae and update the list . clones the first node in list with the invalid node as leading minutiae and update the list . <nl> clones the a node in list with the invalid node as leading minutiae and update the list . <nl> parse module variable declaration . module-var-decl : = module-init-var-decl | module-no-init-var-decl module-init-var-decl : = metadata isolated-final-quals typed-binding-pattern = expression ; module-no-init-var-decl : = metadata type-descriptor variable-name ; isolated-final-quals : = ( final | isolated-qual ) * <nl> check if the first two qualifiers are belong to the variable declaration . if they do , extract them to a separate list and return . <nl> treat readonly as a top level qualifier only with class definition .",case i . <nl> case ii . <nl> case iii .,1603744227,this pr is to support passing custom headers with grpc message and handle in both client and server side . following changes are done to support custom headers . following will be supported from this fix . <nl> server side header support <nl> ` . <nl> client side header support <nl> `,0.9845598936080933
grpc_grpc-java/7696,"refactor cdsupdate definition to support logical dns and aggregate clusters . <cm-sep> support parsing cds responses with logical dns and aggregate cluster tyes . <para-sep> todo ( chengyuanzhang ) : implementations for logical dns and aggregate clusters . <nl> clustername = / update.clustername , edsservicename = / clusterconfig.edsservicename , lrsservername = / clusterconfig.lrsservername , maxconcurrentrequests = / clusterconfig.maxconcurrentrequests , tlscontext = * / clusterconfig.upstreamtlscontext , <nl> cds responses represents the state of the world , eds resources not referenced in cds resources should be deleted . <nl> if the service_name field is set , that value will be used for the eds request . <nl> endpoint level load balancing policy . <nl> list of underlying clusters making of this aggregate cluster . <nl> load report server name for reporting loads via lrs . <nl> max number of concurrent requests can be sent to this cluster . fixme ( chengyuanzhang ) : protobuf uint32 is int in java , so this field can be integer . <nl> tls context used to connect to connect to this cluster . <nl> alternative resource name to be used in eds requests . <nl> exclude upstreamtlscontext as its string representation is cumbersome . <nl> exclude upstreamtlscontext as its string representation is cumbersome . <nl> client sent an ack cds request .",i am splitting out the part for migrating to clusterresolverloadbalancer as the child lb for cdsloadbalancer to a separate pr . this pr should only change how the xdsclient parses cds responses . it can be reviewed and merged separately .,1607136566,"previously , the round-robin list that the client uses ( effective <nl> round-robin list , errl ) was the received round-robin list ( rrrl , from <nl> remote balancer ) excluding non-ready backends . drop and backend <nl> entries are in the same list . <nl> the problem with it is that when not all backends are ready , drop <nl> entries take a larger proportion in errl than they do in the rrrl , <nl> resulting a larger drop ratio than intended . <nl> to fix this , we employ a two-list scheme : . <nl> - a _drop",0.9732735753059387
quarkusio_quarkus/15135,"fix potential npe in instrumentation based update . <cm-sep> activate annotation processors again for panache <nl> we depend on the jpamodelgen annotation processor in the panache modules , to create the meta model for e.g . the panacheentity class . <nl> ( cherry picked from commit sha ) <cm-sep> fix typos in kotlin guide . <nl> ( cherry picked from commit sha ) <cm-sep> disable liquibase hub prompt/warning . <nl> ( cherry picked from commit sha ) <para-sep> do n't block app startup with prompt : do you want to see this operation 's report in liquibase hub , which improves team collaboration ? if so , enter your email . if not , enter [ n ] to no longer be prompted , or [ s ] to skip for now , but ask again next time ( default ' s ' ) :","please do n't merge , i will merge it myself .",1613545000,"this is a pre-requisite for a sequence of fixes i 'll be sending later ; they all need the version upgraded first , so it would be simpler to first merge this and then send individual prs for each fix .",0.9311659336090088
apache_pulsar/8992,": waitforexclusive producer access mode <para-sep> if a producer reconnects , but all the topic epoch has already moved forward , this producer needs to be fenced , because a new producer had been present in between . <nl> there are currently no existing producers <nl> if the producer is queued waiting , we will get an immediate notification that we need to pass to client","implemented the 2nd part of the proposal for . <nl> with mode , a producer is pending until there are other producers connected and then it will be created . <nl> the change in the client logic is to make sure that we do n't time out the producer creation request . the broker will send a 1st response saying that the producer creation is pending . at this point the client will disable the timeout on the original request .",1608229562,"this provides more context about a consumer and is useful for debugging , ui interaction , and/or metrics aggregation .",0.9790107607841492
elastic_elasticsearch/71446,avoid return negative value in countermetric <para-sep> returns the current count of this metric . the returned value is always non-negative . <nl> returns the current count of this metric .,"the reason is that the returned value of a longadder is not an atomic snapshot . <nl> we can replace longadder with atomiclong , but this commit continues using longadder but returns 0 when the value is negative instead .",1617832505,"the goal of the version field was to quickly show when you can expect to find something new in the search response , compared to when nothing has changed . this can also be done by looking at the section and returned with the search response . in fact when there has been one or more additional reduction of the results , you can expect new results in the search response . otherwise , the section could notify of additional failures of shards that have completed the query , but that is not a guarantee that their results will be",0.9189501404762268
apache_kafka/9916,"import raftconfig parameters into kafkaconfig . <nl> - typically , raft quorum configuration is provided through the same <nl> properties file as the broker/controller a.k.a kafkaconfig <nl> - during the lifecycle of the broker/controller , we do reference the <nl> quorum configuration outside of the raftconfig ( eg : raftmanager.scala )","- typically , raft quorum configuration is provided through the same <nl> properties file as the broker/controller a.k.a kafkaconfig <nl> - during the lifecycle of the broker/controller , we do reference the <nl> quorum configuration outside of the raftconfig ( eg : raftmanager.scala ) .",1610751576,subtask jira <nl> main changes of this pr <nl> * deprecate old consumer.internal.partitionassignor and add public consumer.consumerpartitionassignor with all ootb assignors migrated to new interface <nl> * refactor assignor 's assignment/subscription related classes for easier to evolve api <nl> * removed version number from classes as it is only needed for serialization/deserialization . <nl> other previously-discussed cleanup included in this pr : <nl> * remove assignment.error added in pt 0 <nl> * remove consumercoordinator # adjustassignment added in pt 0,0.9414870142936707
ballerina-platform_ballerina-lang/25937,enable function mocking tests <cm-sep> add mock function test for new class implementation <cm-sep> enable object mocking test cases <cm-sep> remove object mocking test that use stdlibs <para-sep> class calling mocked function,also fixes small issue with mocked functions not working inside class functions .,1600424844,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9190952777862549
neo4j_neo4j/11197,ability to enable detailed printing in old importer surface . <nl> available as long as it sticks around ... <cm-sep> prints correct imported data even after restart <cm-sep> fixes id generator issue on restarted temp store in importer <cm-sep> lets batchingneostores do store existence checks . <nl> instead of importtool because behaviour may vary between importers <cm-sep> adds high-io in overview printing on start of import <cm-sep> checks for null on force and close in batchingneostores . <nl> because close ( ) may be called for semi-constructed store <para-sep> given <nl> when <nl> then,found in some corner-cases when doing more hands-on testing of the importer,1520493705,if writer reach a tree node with a valid successor it means that the <nl> tree is not consistent in one out of three ways : <nl> 0. tree state point to a root that is outdated ( has a successor ) <nl> 0. child pointer in parent does not point to latest successor of child . <nl> 0. sibling pointer does not point to latest successor of sibling .,0.9581127762794495
Alluxio_alluxio/10970,close files.walk stream resource in localpagestore,close files.walk stream resource in localpagestore,1582306566,fix bug where 0 file size would make ui crash,0.8269186615943909
apache_kafka/9716,"; ensure raft io thread respects linger timeout <para-sep> wakeup the network channel if either this is the first append or the accumulator is ready to drain now . checking for the first append ensures that we give the io thread a chance to observe the linger timeout so that it can schedule its own wakeup in case there are no additional appends . <nl> the linger timer begins running when we have pending batches . we use this to infer when the accumulator is empty to avoid the need to acquire the append lock . <nl> get the number of completed batches which are ready to be drained . this does not include the batch that is currently being filled . <nl> this test verifies that the client will set its poll timeout accounting for the lingerms of a pending append <nl> this test verifies that the client will get woken up immediately if the linger timeout has expired during an append <nl> append entries until we have 0 batches to drain ( 0 completed , 0 building )","when there are no pending operations , the raft io thread can block indefinitely waiting for a network event . we rely on asynchronous wakeups in order to break the blocking wait in order to respond to a scheduled append . the current logic already does this , but only for the case when the linger time has been completed during the call to . it is possible instead that after making one call to to start the linger timer , the application does not do any additional appends . in this case , we still need the io thread",1607472650,"when fixing 0 , it only touches on kv stores , but it turns out that we should fix for window and session store as well . <nl> 0 ) also apply the optimization that was in session-store already : when the new value bytes and old value bytes are all null ( this is possible e.g . if there is a put ( k , v ) followed by a remove ( k ) or put ( k , null ) and these two operations only hit the cache ) , upon flushing this mean the underlying store does",0.9375572800636292
elastic_elasticsearch/72198,service accounts - audit logging for service token name,"multiple service tokens can be created for the same service account . each token has a name to uniquely identify itself . this pr ensures the token name is logged for audit events of , ( when applicable ) , and . <nl> ps : auditing for security configuration changes of service account tokens will be tackled in a separate pr .",1619417107,"allows configuring searchable snapshots to avoid caching certain types of files , for example ' fdt ' files for stored fields .",0.9448332190513611
vespa-engine_vespa/15837,use feature flag to decide how to run zookeeper server . <nl> add flag to choose between reconfigurable zookeeper server or not for <nl> the zookeeper server used by cluster controller,add flag to choose between reconfigurable zookeeper server or not for <nl> the zookeeper server used by cluster controller .,1608120854,"in container clusters , if it is determined that a restart is required to swicth <nl> to a new config generation , mark that config as applicable only after a restart . <nl> this avoids wasting resources on a config change just before a restart , and the <nl> potential of prematurely applying config changes which depend on other changes <nl> which are not effective before a restart has been done .",0.9503329992294312
elastic_elasticsearch/71725,"this commit adds a bit more information about file sizes like the number of files <nl> ( count ) , the min , max and average file sizes in bytes that share the same extension . <nl> here is a sample : <nl> ' cfs ' : { <nl> ' description ' : ' compound files ' , <nl> ' size_in_bytes ' : 0 , <nl> ' min_size_in_bytes ' : 0 , <nl> ' max_size_in_bytes ' : 0 , <nl> ' average_size_in_bytes ' : 0 , <nl> ' count ' : 0 <nl> } . <nl> these new information are provided to give a better view of the segment <nl> files and are useful in many cases , specially with frozen searchable snapshots <nl> whose segment stats can now be introspected thanks to the <nl> include_unloaded_segments parameter . <cm-sep> adjust version for version","this commit adds a bit more information about file sizes like the number of files <nl> ( count ) , the min , max and average file sizes in bytes that share the same extension . <nl> here is a sample : <nl> ' cfs ' : { <nl> ' description ' : ' compound files ' , <nl> ' size_in_bytes ' : 0 , <nl> ' min_size_in_bytes ' : 0 , <nl> ' max_size_in_bytes ' : 0 , <nl> ' average_size_in_bytes ' : 0 , <nl> ' count ' : 0 <nl> } . <nl> these new information are",1618474950,"this commit changes how cache files synchronization interacts with <nl> the persistent cacge in searchable snapshots . before this change it <nl> was possible that synchronization reintroduces information about <nl> an evicted cache file in the persistent cache lucene index . <nl> this commit introduces an queue of cache file events that are <nl> periodically processed by the cache synchronization method . the <nl> events refer to a specific cache file and a type of event ( deletion or <nl> fsync needed ) that must be processed by the cache synchronization <nl> method , which in turn applies the appropriate",0.9741613268852234
elastic_elasticsearch/71860,"there 's a few places where we need to access all of the supported runtime fields script contexts . up until now we have listed them in all those places , but a better way would be to have them listed in one place and access that same list from all consumers . this is what this commit introduces . <nl> along with the introduction of runtime fields contexts in scriptmodule , we rename the whitelist files so that they contain their corresponding context name to simplify looking them up .","there 's a few places where we need to access all of the supported runtime fields script contexts . up until now we have listed them in all those places , but a better way would be to have them listed in one place and access that same list from all consumers . this is what this commit introduces . <nl> along with the introduction of runtime fields contexts in scriptmodule , we rename the whitelist files so that they contain their corresponding context name to simplify looking them up .",1618848550,"i added the enumsetting option to as suggested in the issue . additionally , i changed the settings mentioned in the issue into s . <nl> this is my first elasticsearch contribution , so no doubt i missed some details or forgot to do something while following the contribution guide . please let me know ! <nl> i was n't certain of some impl . details . i have added comments at file level illustrating this .",0.9397718906402588
apache_incubator-pinot/6073,"* adding more table config validation ( retention , pushtype and tenant ) <nl> * fixing bug where retention manager does not work for real-time tables <nl> if the pushtype is missing . <cm-sep> adding newline at end of tableconfigutilstest.java <para-sep> validates the tenant config for the table . in case of a single tenant cluster , if the server and broker tenants are not specified in the config , they 're auto-populated with the default tenant name . in case of a multi-tenant cluster , these parameters must be specified in the table config . <nl> for offline tables , ensure that the segmentpushtype is append . <nl> 0. field config list table name should n't contain dot or space in it validates retention config . checks for following things : - valid segmentpushtype - valid retentiontimeunit <nl> segmentpushtype is not needed for realtime table <nl> retention may not be specified . ignore validation in that case . <nl> - validates retention config - checks for valid field spec for timecolumnname in schema , if timecolumnname and schema are non-null <nl> expected",no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no . <nl> does this pr otherwise need attention when creating release notes ? <nl> no,1601418435,added new anomaly function minmaxthreshold <nl> added custom metric function ( sum/avg/count ) into anomalyfunctionspec <nl> added feedback support in anomalyresult object,0.9557344913482666
Graylog2_graylog2-server/9116,"prevent npes if streams are referencing missing outputs . <nl> streams contain references to their outputs by storing an array of <nl> output ids in their documents . this happens , because instead of the <nl> output is returned from an identity map during output lookup . <nl> this change is doing two things : . <nl> - ensure that the output list a stream is initialized with does not <nl> contain values <nl> - logs a warning that a stream is referencing a missing output .","streams contain references to their outputs by storing an array of output ids in their documents . this happens , because instead of the output is returned from an identity map during output lookup . <nl> this change is doing two things : . <nl> - ensure that the output list a stream is initialized with does not contain values <nl> - logs a warning that a stream is referencing a missing output .",1602160367,"before this change , any alert conditions associated with a stream were <nl> cloned identically ( including using the same id ) when cloning a stream . <nl> this was leading to a bug , where the alert condition was shown as being <nl> associated with the source of the clone process instead of the target . <nl> with this change , the alert condition is recreated during cloning , <nl> including generating a new id for it . <nl> ( cherry picked from commit sha )",0.850313127040863
pentaho_pentaho-kettle/7545,"backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <cm-sep> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <para-sep> one or more steps failed on initialization . transformation is now stopped . <nl> halt the other threads as well , signal end-of-the line to the outside world ... also explicitly call dispose ( ) to clean up resources opened during init ( ) ; we will not pass this exception up to prepareexecution ( ) entry point . <nl> scenario : step not stopped <nl> scenario : step stopped <nl> common base for testsetinternalentrycurrentdirectory 's ' tests . <nl> a step that is already disposed <nl> a step not yet disposed <nl> only 'stepdatamock2 ' is to be disposed <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'stopped ' <nl> all cases should result in status being 'stopped ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'finished ' <nl> all cases , except where stopped is set , should result in status being 'end ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> set 'paused ' <nl> it ca n't be 'finished ' nor 'stopped ' <nl> all cases should result in status being 'end ' . <nl> : a stopped transformation would be logged as 'running ' . <nl> it ca n't be 'finished ' , 'paused ' nor 'stopped ' <nl> all cases should result in status being 'running ' . <nl> :","backport of - when the database connection which is used in the transformation step is invalid , the status in pentaho_dilogs .trans_logs table does shows as ' running ' when the transformation has failed . ( version suite ) <nl> backport of - when the database connection which is used in the transformation step is valid , status in pentaho_dilogs .trans_logs table does shows as ' running ' even though the transformation has failed . ( version suite ) . <nl> this pull request refers to two issues because the original prs were done along some time and have some",1596057285,"converting integer to timestamp type using select values step results in incorrect date . <nl> the kettle property is now called 'kettle_timestamp_number_conversion_mode ' and controls how timestamp should be converted to a number and vice-versa . <nl> there 're three possible values : <nl> - 'legacy ' : ( the default , the behaviour that existed until now ) timestamp to number uses milliseconds but number to timestamp uses nanoseconds <nl> - 'milliseconds ' : both conversions use milliseconds <nl> - 'nanoseconds ' : both conversions use nanoseconds . <nl> added several unit tests to guarantee all three scenarios (",0.9463107585906982
apache_beam/12850,"ensure registration of the accumulator occurs . <nl> prior to this , if the accumulator was recovered from a checkpoint it <nl> was n't registered and resulted in a runtime exception .","move registration of accumulator so as to include those recovered from checkpoints . prior to this , if the accumulator was recovered from a checkpoint it would not be registered , resulting in a runtime exception",1600188123,fixes . <nl> this pr addresses the findings . <nl> i used gradle-lint-plugin to confirm ken 's findings . <nl> - sdks/java/extensions/sql/jdbc had ' declared but unused ' guava dependency . <nl> - runners/google-cloud-dataflow-java/worker depends on 0 classes without declaring . these classes should not depend on guava class . so i updated them to use vendored guava . <nl> - sdks/java/io/kinesis has ' used but undeclared ' guava dependency . <nl> - sdks/java/extensions/sql/zetasql has ' used but undeclared ' guava dependency . <nl> - sdks/java/io/elasticsearch-tests/elasticsearch- has ' declared but unused ' guava dependency,0.704291582107544
apache_beam/13387,"decode data channel elements after , rather than before , placing them in the queue . <nl> this ensures the decoding operations are done in the worker , not grpc , threads . <para-sep> a receiver of encoded data , decoding it and passing it onto a downstream consumer . * /","this ensures the decoding operations are done in the worker , not grpc , threads",1605835381,"due to the new mailbox operator architecture in flink version , processing remaining <nl> timers during operator shutdown ca n't be achieved by releasing the checkpoint <nl> lock anymore . timers are only drained after the close ( ) method completes . <nl> however , at this point new timers also can not be set anymore . <nl> this does n't play well with some of beam 's code ( e.g . sdf ) which assumes that <nl> timers can set new timers which are guaranteed to fire at the end of the <nl> pipeline . with the current processing",0.94523024559021
apache_pulsar/9302,add subscription backlog size info for topicstats . <para-sep> get estimated backlog size from a specific position .,sample output . <nl> in admin rest api and cli add option to get subscription backlog . <nl> this change added tests and can be verified as follows : <nl> added check in existing test to verify backlog size . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : yes ( added option to get subscription 's backlog size when getting topic-stats/partitioned-topic-stats ) <nl> - the schema : no <nl> - the default values of configurations : no <nl> - the wire protocol : no <nl> - the rest,1611533207,"enable get precise backlog and backlog without delayed messages . <nl> added new unit tests for the change . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no",0.9644571542739868
Graylog2_graylog2-server/9500,"provide verbose failure support through new authservicerealm . <nl> if the ldap/ad authentication can not be done due to a server <nl> error , throw an authenticationserviceunavailableexception . <nl> this gives the user ( and the audit log ) an indicator , that <nl> it was n't his fault that he could n't log in . <cm-sep> do n't log authentication failures by default . <nl> that restores the behaviour of previous graylog releases .","if the ldap/ad authentication can not be done due to a server <nl> error , throw an . <nl> this gives the user ( and the audit log ) an indicator , that <nl> it was n't his fault that he could n't log in .",1605540482,this pr fixes the content-type detection for web interface assets by pulling in a mime type database ( taken from debian linux ) instead of relying on ( wonky ) system defaults . <nl> additionally it fixes the caching behavior of .,0.9198259115219116
apache_incubator-pinot/5618,"[ te ] upgrade pinot version to version <para-sep> for every table in pinot , fetches the following : 0. pinot schema 0. timecolumnname from pinot table config 0. custom property map from pinot table config <nl> verify schema name and presence of field spec for time column <nl> returns the map of custom configs of the given dataset from the pinot table config json .",handled that in onboarding utils .,1593048794,"a derived metric expression can now be composed of metrics from different datasets . when creating the metric config , put only one of the dataset 's name in the dataset field . <nl> the datasets should have the same time granularity and time column name . heatmaps will only work if dimensions are identical .",0.9840096235275269
apache_beam/13294,": fix keyedtimerdata . <nl> outputtimestamp is a new field added to keyedtimerdata recently , which should be encoded/decoded at last . <para-sep> all new fields should be encoded at last","outputtimestamp is a new field added to keyedtimerdata recently , which should be encoded/decoded at last .",1605035666,"countingsource reports incorrect backlog when is > 0. if the source has 0 splits , each split has stride of 0. intention of existing imlementation is correct : return , but the missing braces make it return values 0-0 bytes as well . this fixes that . <nl> the main negative effect of such spurious backlog is that it can cause unnecessary upscaling .",0.7823439836502075
OpenAPITools_openapi-generator/8125,set skipformmodel to true by default <para-sep> return the sanitized variable name for enum,- set skipformmodel to true by default ( based on users ' feedback ) <nl> - minor code formatting enhancement .,1607442241,"initially kotlin only supported the libraries jvm ( with okhttp ) and multiplatform . <nl> now it supports one extra jvm library that is retrofit2 . <nl> so the options are jvm-okhttp4 ( default ) , jvm-okhttp3 , retrofit2 ( also jvm ) , multiplatform . <nl> i think that for consistency in the name the retrofit2 should be called jvm-retrofit2 . <nl> and in the future all the libraries should respect jvm- or multiplatform- . <nl> this pr also reuses unifies jvm code to avoid duplication by introducing a directory called ivm-common . <nl> one last thing is that",0.8525867462158203
apache_pulsar/9799,add cmd to get service url of the leader broker <para-sep> get the information of the leader broker . get the information of the leader broker . response example : { serviceurl : ' prod1-broker1.messaging.use.example.com:0 ' } <nl> get the service url of the leader broker asynchronously . get the service url of the leader broker . response example : { serviceurl : ' prod1-broker1.messaging.use.example.com:0 ' } <nl> broker information,"yes <nl> if yes , how is the feature documented ? ( javadocs )",1614845065,"currently we do n't have a way to unset offload policies for namespaces , we may need one . <nl> add a rest api . <nl> ( please pick either of the following options ) . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> ( or ) . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> ( or ) . <nl> this change added tests and can be verified as follows : . <nl> ( example : ) <nl> - added",0.9712947010993958
apache_beam/13345,"enable checker on beamfnloggingclient <cm-sep> keep a reference to loggers in beamloggingclienttest.testlogging <para-sep> ignore cancellations <nl> keep a strong reference to the loggers in this block . otherwise the call to client.close ( ) removes the only reference and the logger may get gc 'd before the assertions ( ) . <nl> keep a strong reference to the loggers . otherwise the call to client.close ( ) removes the only reference and the logger may get gc 'd before the assertions ( ) . <nl> keep a strong reference to the loggers in this block . otherwise the call to client.close ( ) removes the only reference and the logger may get gc 'd before the assertions ( ) . <nl> verify that after close , log levels are reset .",the javadoc for notes : . <nl> > note : the logmanager may only retain a weak reference to the newly created logger . it is important to understand that a previously created logger with the given name may be garbage collected at any time if there is no strong reference to the logger . <nl> once the client is closed the only reference to the logger is removed and there 's the possibility it gets gc 'd before we try to access it for the assertion . <nl> this pr also removes warning suppression in beamfnloggingclient . <nl> see,1605310471,"motivation . <nl> - cleanup the code of on register process boundle descriptor . <nl> - correct the implementation of fn api , i.e. , would be better to cater to the asynchronous design principles of the beam api . <nl> changes <nl> - 0 : <nl> update the client side implementation of fn api to make sure registration is executed successfully before executing process_bundle . personally i think that the client side implementation of fn api should not assume that the implementation of registration in sdk harness is synchronous . the registration api itself is asynchronous and the client",0.9309462904930115
elastic_elasticsearch/72438,make nodeenvironment.indexpaths singular . <nl> this commit renames the indexpaths method to be singular and return a <nl> single path instead of an array . this is done in isolation from other <nl> nodeenvironment methods to make it reviewable .,this commit renames the indexpaths method to be singular and return a <nl> single path instead of an array . this is done in isolation from other <nl> nodeenvironment methods to make it reviewable .,1619671093,the structure is changed so that when a stringbuilder is used for string concatenation it will be the first value pushed onto the stack prior loading the left-hand side of the compound assignment .,0.962531328201294
apache_pulsar/9876,add the broker connection metrics . <para-sep> connection metrics,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1615428966,that will make integration tests easier in future without forcing it to sleep and wait the block to kick in backlog quota check .,0.9649534821510315
ballerina-platform_ballerina-lang/24342,introduce tosourcecode ( ) method to get exact source text from the tree . <nl> this change was done to fix the following issue . <cm-sep> add a case to test position when there are invalid nodes <cm-sep> fix a typo in the test class <para-sep> the following line triggers the calculation of line ranges,this is a blocker for the release .,1592512969,the web-socket remote servers that are started from some of the web-socket related test cases now will use different port .,0.8604806661605835
apache_beam/12670,add elasticsearchio : delete document support <para-sep> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted and the other half is partially updated using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted and the other half is partially updated using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted and the other half is partially updated using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted and the other half is partially updated using bulk delete request . the test then asserts the documents were deleted successfully . <nl> this test verifies volume deletes of elasticsearch . the test dataset index is cloned and then around half of the documents are deleted using bulk delete request . the test then asserts the documents were deleted successfully . <nl> tests deletion of documents from elasticsearch index . documents with odd integer as id are deleted and those with even integer are partially updated . documents to be deleted needs to have criteria within the fields of the document . <nl> partial documents containing the id and group only <nl> scientist names at,"what <nl> this change introduces a new builder function ( ) with which can be used to effectively delete documents from the elasticsearch index . previously , elasticsearchio only supports upsert operations within an index but it is impossible to delete documents . <nl> why <nl> by using the function , the apache beam user can dynamically decide the bulk operation to be carried out for the document . mostly , in streaming update environment , it might happen that some of the previously indexed document needs to be deleted based on some conditions but the current version of elasticsearchio",1598191832,"0. add annotation to allow define functions as udf in calcite . <nl> 0. add some functions as an extension to beamsql , which allow beamsql provides a rich function set . functions added : is_inf , is_nan , cosh , tanh , sinh . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .",0.9481392502784729
Graylog2_graylog2-server/9256,do n't expose shares with invisible grantees . <nl> filter the activeshares result so it contains only grantees <nl> that are visible to the requesting user . <para-sep> owner got removed ignore owners that were invisible to the requesting user <nl> owner capability got changed <nl> this test can also see the ' invisible user ',filter the activeshares result so it contains only grantees <nl> that are visible to the requesting user .,1603446685,"this pull request prevents the content pack exporter from exporting clones of default streams when including pipelines that are connected to e.g . ' all messages ' . <nl> in the project i 'm working we intend to bootstrap a graylog container from scratch without any manual configuration for consistent production deployments and automated updates . this requires us to include out ' entrypoint pipeline ' on ' all messages ' for initial routing . currently this is not possible , as the import will fail . <nl> as of now the changes have been tested in a local test",0.952215850353241
prestodb_presto/15418,refactor staticfunctionnamespacestore to load properties map <cm-sep> support function namespace manager for presto-on-spark,"summary <nl> - similar to catalog configurations , for , key is namespace/catalog , value is properties .",1605027745,"i accidentally did n't merge it before , so merging now .",0.919000506401062
elastic_elasticsearch/70483,"avoid atomic overwrite tests on fs repositories . <nl> today we leniently permit overwrites of blobs in a repository not to be <nl> atomic , since they are not in shared filesystem repositories . in fact <nl> it 's worse , on windows overwrites do not even work if there is a <nl> concurrent reader . in practice this is n't very important , we do almost <nl> no overwrites and almost never read the file that 's being overwritten , <nl> but we do still test for atomic overwrites in the repository analyzer . <nl> with this commit we suppress the atomic overwrite checks in the <nl> repository analyzer for fs repositories , and remove the lenience since <nl> all other repositories should implement atomic overwrites correctly .","today we leniently permit overwrites of blobs in a repository not to be <nl> atomic , since they are not in shared filesystem repositories . in fact <nl> it 's worse , on windows overwrites do not even work if there is a <nl> concurrent reader . in practice this is n't very important , we do almost <nl> no overwrites and almost never read the file that 's being overwritten , <nl> but we do still test for atomic overwrites in the repository analyzer . <nl> with this commit we suppress the atomic overwrite checks in the <nl> repository",1615977266,"we removed index-time boosting back in 5x , and we no longer document the 'boost ' <nl> parameter on any of our mapping types . however , it is still possible to define an <nl> index-time boost on a field mapper for a surprisingly large number of field types , and <nl> they even have an effect ( sometimes , on some queries ) . <nl> as a first step in finally removing all traces of index time boosting , this comment emits <nl> a deprecation warning whenever a boost parameter is found on a mapping definition .",0.8622375130653381
confluentinc_ksql/6518,json_sr tests and minor fixes <para-sep> given ; <nl> when : <nl> then :,- add key tests <nl> - fix wiring issue with and json_sr . <nl> this change is nearly all testing : d .,1603493137,"previously the topic name would be uppercased . this did n't really make sense as kafka topics are case sensitive . <nl> also manually test ksql cli , this shows suggestion for reversed case topic where it the reversed case form exists : .",0.8721182942390442
confluentinc_ksql/6067,support if exists keyword on drop connector <para-sep> given : <nl> when : <nl> then :,"added keyword to the command . <nl> previously , this error message would have shown if the connector does not exist : . <nl> with this change , if the keyword is used , the response is : . <nl> if the keyword is not used , the response is the original error response . <nl> i added a new class called that prints a message without the error header .",1597954591,it 's just nick 's changes with : <nl> - the merge issues resolved <nl> - a slight refactor to make it easier to ensure the status message is always reset <nl> - a test case or two .,0.9710490107536316
runelite_runelite/12834,"runelite-api : add worldchanged event <cm-sep> runelite-api : add playerchanged event <para-sep> posted when the game world the client wants to connect to has changed this is posted after the world id and type have updated , but before a new connection is established <nl> null = > we need to make a new profile <nl> generate the new key deterministically so if you ' create ' the same profile on 0 different clients it does n't duplicate <nl> a profile/save of a osrs account . <nl> profile key used to save configs for this profile to the config store . <nl> the profile that has changed , if any <nl> posted when the user switches to a different runescape save profile this might be because they logged into a different account , or hopped to/from a beta/tournament/dmm/leagues world <nl> timetracking ... = :","this adds support for per runescape save configuration , allowing plugins to correctly keep account data ( slayer task , farming timers , etc . ) separate on leagues from the standard game .",1606166682,fixes assertion failure introduced in sha .,0.9391635656356812
OpenAPITools_openapi-generator/7876,"fix decimal mapping in scala generators <cm-sep> add mapping for decimal , number in scala generators",- better decimal support in scala generators .,1604507974,"intro <nl> historically , typescript generators had typemapping ' datetime=date ' . however only select generators generate code that really does serialization/deserialization of dates at runtime . <nl> some other generators support serialization of date query parameters , but not deserialize models returned from api . without proper model deserialization , the whole datetime=date mapping is simply incorrect ( declared data type is , but real value at runtime coming from api is still ) . <nl> - generators that fully implement serialization : , , . <nl> - generators with partial support ( query params only , but not",0.8481127023696899
apache_druid/10350,support searchquerydimfilter in sql via new methods <para-sep> this class implements a function that checks if one string contains another string . it is required that second string be a literal . this expression is case-insensitive . <nl> creates the function eagerly to avoid branching in eval . <nl> same behavior as regexp_like . <nl> this class implements a function that checks if one string contains another string . it is required that second string be a literal . this expression is case-sensitive .,"native druid query has that is faster and supports case-insensitive search . this patch adds the via two new functions - and . <nl> i have not chosen / name as the function names since is a standard operator in calcite similar to . however , in calcite , only support periods/date as an input . to avoid conflicts with on , i have chosen different names altogether . <nl> from . <nl> the method name for case insensitive search is different as it is more in line with standard sql ( and ) . the other reason is that",1599163631,add integration tests for all inputformat . <nl> add integration tests for all inputformat using local inputsource . the set of new tests cover happy path for all inputformat . <nl> this also fix a bug for handling number value starting with negative sign or decimal point when use with a quantilesdoublessketch for csv ( which ingest objects as string ),0.9616875052452087
apache_beam/13633,"add flink_versions to gradle.properties . <para-sep> todo ( ) running tests of all flink versions in parallel can be too harsh on jenkins memory . run them serially for now , to avoid ' exit code 0 ' , i.e . jenkins host killing the gradle test process . <nl> disables classloader.check-leaked-classloader unless set by the user . <nl> project ( ' : runners : flink : $ { latestflinkversion } : job-server ' ) .shadowjar.archivepath is not resolvable until runtime , so hard-code it here .","this pr only changes gradle files ( tests and examples ) . i will make separate prs for other usages , such as jenkins test configs , python , release scripts , the website , and miscellaneous comments",1609282439,"be sure to do all of the following to help us incorporate your contribution <nl> quickly and easily : . <nl> travis-ci on your fork and ensure the whole test matrix passes ) . <nl> number , if there is one . <nl> individual contributor license agreement .",0.8871721625328064
vespa-engine_vespa/15234,rewrite configconvergencechecker to use apache instead of jersey client . <nl> the effective exception handling for some confiserver apis may have changed as webapplicationexception leaked out with old jersey-based implementation . <nl> connections will now be reused for a short duration . <cm-sep> do n't use private inner class in return type of public methods <cm-sep> deprecate vespaclientbuilderfactory + vespajerseyjaxrsclientfactory <cm-sep> do n't use shared fork join pool <cm-sep> do n't reuse connections . <nl> disable connection reuse . increase max simultaneous connections . <nl> remove default request config .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1604920935,this avoids creating an excessive number of connections <nl> to search clusters when the application ( incorrectly ) creates <nl> many local provider chains to the same search cluster .,0.977925181388855
apache_incubator-pinot/5494,fix distinctcountrawhll ( ) return value on sql path <cm-sep> cleanup <para-sep> 0. test aggregation only query with sql response format <nl> verify cardinality <nl> 0. test aggregation only query with sql exec + response format <nl> 0. test aggregation-only query with filter <nl> verify cardinality <nl> 0. test aggregation-only query with filter with sql exec and response format <nl> 0. test aggregation + group by query <nl> verify cardinality <nl> 0. test aggregation + group by query with sql exec and response format group by column is returned with actual type int <nl> 0. test aggregation + filter + group by query <nl> verify cardinality <nl> 0. test aggregation + filter + group by query,"while the final return type of the function is string , the final return value ( serializedhll object ) is never transformed in the broker reducer ( for sql path ) to hex encoded string . <nl> so the resulttable has the column type as string but the data is object of type serializedhll . we need to format the final return value to a serializable value on the sql path just like we have done on pql path . <nl> enhanced the tests . <nl> note : ideally each query execution unit test under should be enhanced to run",1591257885,* support groupbyvalue across multiple columns . <nl> * hashmap performance tweaks,0.9368968605995178
crate_crate/10459,"fix value of sys.health.partition_ident . <nl> as documented , a null should be returned instead of an empty string <nl> for non-partitioned tables . <nl> ( cherry picked from commit sha ) <cm-sep> fix sys.health.health state for partitions . <nl> use the setting of a partition instead of the <nl> partitioned table . <nl> they could differ through the possibility of changing only the shards for <nl> future partitions . <nl> if the value for the table is greater then the value of the <nl> partition itself , using the tables value will result in missing shards <nl> and thus a health . <nl> ( cherry picked from commit sha )",mergify commands and options . <nl> you can also trigger mergify actions by commenting on this pull request : . <nl> - will re-evaluate the rules <nl> - will rebase this pr on its base branch <nl> - will merge the base branch into this pr <nl> - will backport this pr on branch . <nl> - look at your merge queues <nl> - generate the mergify configuration with the simulator .,1598705654,first commit will be required to move the predicate push downs from the <nl> analyzer to the new rule based optimizer . <nl> second commit is mostly a cosmetic change ( see commit message for <nl> details ) .,0.9056797027587891
jenkinsci_jenkins/4718,"avoid olddatamonitor avoids jenkins load a plugin <para-sep> avoid any error in olddatamonitor to be catastrophic . see and the root cause is the olddatamonitor extension is not ready before a plugin triggers an error , for example when trying to load a field that was created by a new version and you downgrade to the previous one . <nl> it should be already reported , but we report with info just in case <nl> it should be already reported , but we report with info just in case","this pr is an easy fix , filed to raise a discussion . i do n't know at this point if there is a better way . <nl> tested manually with the ec2-plugin . downgrading from version to version . <nl> internal avoid an error when reporting errors because of field unmarshalling to stop loading a plugin . <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs <nl> - [ n/a ] if the change needs additional upgrade steps from users , label is set and there is a",1589123640,display an explanatory message when jenkins cli attempts to build an unbuildable project .,0.8627998232841492
netty_netty/11150,"less blocking in chunkedstream . <nl> motivation : <nl> we should avoid blocking in the event loop as much as possible . <nl> the inputstream.read ( ) is a blocking method , and we do n't need to call it if available ( ) returns a positive number . <nl> modification : <nl> bypass calling inputstream.read ( ) if available ( ) returns a positive number . <nl> result : <nl> fewer blocking calls in the event loop , in general , when chunkedstream is used .","motivation : <nl> we should avoid blocking in the event loop as much as possible . <nl> the inputstream.read ( ) is a blocking method , and we do n't need to call it if available ( ) returns a positive number . <nl> modification : <nl> bypass calling inputstream.read ( ) if available ( ) returns a positive number . <nl> result : <nl> fewer blocking calls in the event loop , in general , when chunkedstream is used .",1617965691,motivation . <nl> modification . <nl> just use alloc ( ) .heapbuffer ( ... ) for the allocation . <nl> result . <nl> no possibility of ' missing ' array allocations when bytebuf # copy is used .,0.8504402041435242
Graylog2_graylog2-server/9524,updates to graylog common schema constants <para-sep> user fields <nl> to be removed <nl> to be removed <nl> user fields,this pr updates the schema constants based on those changes .,1605638889,this change adds the following metrics for extractors : . <nl> * conditionhits ( number of times the condition succeeded ) <nl> * conditionmisses ( number of times the condition failed ) <nl> * conditiontime ( time spent in evaluating the condition ) <nl> * completeexecutiontime ( total time spent in the extractor ) .,0.8748337626457214
elastic_elasticsearch/72025,this commit fixes <nl> that regression and adds a testnullvalues method to mappertestcase <nl> to ensure that all field mappers correctly handle nulls .,this commit fixes <nl> that regression and adds a testnullvalues method to mappertestcase <nl> to ensure that all field mappers correctly handle nulls .,1619016984,"currently we always call reduce even when we only have one internalaggregation . in some cases this is necessary but in others the reduce method is just making a copy of itself . this is normally not too expensive excepts for aggregations that hold expensive objects , for example cardinality or percentile aggregations . <nl> in order to prevent this necessary step this pr adds a new abstract method in internalaggregation that flags the framework if it needs to reduce on a single internalaggregation .",0.9436612725257874
OpenAPITools_openapi-generator/7445,issue 0 : fixed comments that referred to resttemplate . <para-sep> build the webclient used to make http requests . <nl> build the webclient used to make http requests .,corrected comments that referred to resttemplate instead of webclient in libraries/webclient/apiclient.mustache and libraries/webclient/pom.mustache .,1600342323,- update petstore samples so that shippable tests will pass,1.0
vespa-engine_vespa/16666,move classes '.core ' to '.server.jetty ' <cm-sep> determine local port for requests processed after connector is closed . <nl> fallback to configured listen port for requests that are unable to <nl> complete before connector shutdown is initiated .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1614187789,* return 0 instead of 0 when node not found .,0.8820809721946716
OpenAPITools_openapi-generator/7829,fix spring kotlin generation of array/map models <para-sep> note : modelutils.ismapschema ( p ) returns true when p is a composed schema that also defines additionalproperties : true,* fix generation of nested map/arrays and map/array models ( code taken from abstractjavacodegen ) <nl> * fix data class extension constructor ( there 's still an issue when parent has attributes and mutablemodels is false that will need to be fixed in another pr ) <nl> * fix generation of annotation .,1603873993,add more security methods to avoid unnecessary imports .,0.9369317293167114
Alluxio_alluxio/12145,add polling master timeout <cm-sep> handle deadline exceeded exception,added a deadline for master ping requests .,1601064036,setting ' alluxio.underfs.object.breadcrumbs.enabled ' to false will disable breadcrumb creation when doing a ' list ' operation .,0.9226333498954773
elastic_elasticsearch/72260,"do n't assign persistent tasks to nodes shutting down . <nl> this commit changes the to limit nodes for a task to a subset of <nl> nodes ( candidates ) that are not currently shutting down . <nl> it does not yet cancel tasks that may already be running on the nodes that are shut down , that will <nl> be added in a subsequent request . <para-sep> return all the nodes as a collection <nl> filter all nodes that are marked as shutting down , because we do not want to assign a persistent task to a node that will shortly be leaving the cluster <nl> task assignment should not rely on node order <nl> returns true if the given node is marked as shutting down with any shutdown type . <nl> right now we make no distinction between the type of shutdown , but maybe in the future we might ? <nl> the default implementation returns the least loaded data node from amongst the collection of candidate nodes <nl> finds the least loaded node from amongs the candidate node collection that satisfies the selector criteria <nl> now that we have a bunch of tasks that need to be assigned , let 's mark half the nodes as shut down and make sure they do not have any tasks assigned <nl> 'candidatenodes ' is not actually used here because the assignment for the task is already filtered elsewhere ( jobnodeselector ) , this is only finding the node a task has already been assigned to . <nl> this class is for testing that when shutting down a node , persistent tasks are not assigned to that node . <nl> start two nodes , one will be marked as shutting down <nl> mark the node as shutting down <nl> tell the persistent task executor it can start allocating the task <nl> issue a new cluster state update to force task assignment <nl> wait until the task has been assigned to a node <nl> check that the node that is not shut down is the only candidate <nl> check if it 's true , setting it to false if we are going to start task","this commit changes the to limit nodes for a task to a subset of <nl> nodes ( candidates ) that are not currently shutting down . <nl> it does not yet cancel tasks that may already be running on the nodes that are shut down , that will <nl> be added in a subsequent request .",1619457030,as the datastream information is stored in the we exposed <nl> the to the method in order for <nl> the steps to be able to identify when a managed index is part of a datastream . <nl> if a managed index is part of a datastream the rollover target is the datastream <nl> name and the highest generation index is the write index ( ie . the rolled index ) .,0.9728221297264099
elastic_elasticsearch/70596,do n't use filesystem concat for resource paths,"is a filesystem-specific method , and gives a different result on windows than it does on mac or linux . however , the method is expecting a resource path for the call to . <nl> i believe we can fix the issue with windows and save some steps by calling directly . if there 's a reason not to do this , we still need some way of fixing the windows issue .",1616118689,week_year is replaced by weekyear . this is a single field yyyy date <nl> format .,0.8955521583557129
gocd_gocd/8419,- use internal api instead of public one <nl> - show latest modification details ( truncated if needed ) in the header <nl> - show the modification details in panel body <cm-sep> on expand of a materials panel <nl> - make a call to fetch the usgaes of that material <nl> - store it in a cache <nl> - after successful fetching - render the results as a tree structure <cm-sep> - only show major attributes which can be used to identify the material <nl> - add a link to pluggable scm and package for the materials of the respective kind <cm-sep> remove unused attribute from representer <para-sep> tslint : disable-next-line,description : <nl> - use the internal materials api to render the config ( only necessary attributes ) and the latest modification for the same . <nl> - we no longer show the dependency materials as the same is visible via vsm page <nl> - added links to vsm for the given modification : revision and fingerprint <nl> - showed the material usages in various pipelines in a tree structure . <nl> preview : .,1596603482,"perhaps to get some user feedback ? but this seems more like a ui decision rather than a feature toggle to have . besides , it is disabled for 0 months now . feel free to close the pr if you want to keep this around .",0.8227878212928772
quarkusio_quarkus/15550,"handle null values in rest data panache jsonb serializer . <nl> ( cherry picked from commit sha ) <cm-sep> bump kubernetes-client-bom from version to version . <cm-sep> make missing password and error . <nl> if the url is set but no password <nl> this is clearly a config error . <nl> ( cherry picked from commit sha ) <cm-sep> make sure the base quarkus-bom platform does not force its bom over other platforms found in the project . <nl> ( cherry picked from commit sha ) <cm-sep> revert ' fix : kubernetesdeployer now always deletes existing resources ' . <nl> this reverts commit sha . <nl> ( cherry picked from commit sha ) <para-sep> the first one wins <nl> the first one wins <nl> ignore for now <nl> here we are about to collect platform descriptors found among the project 's dependency constraints . normally , it 's a straightforward exercise , i.e . simply collect dependencies that match a pre-defined artifactid suffix . the ordering of the descriptors in our platform boms might not be consistent across different builds though . so this code is doing rough filtering to make sure the base platform ( quarkus-bom ) descriptor does not appear to be forcing its bom over the other platforms found in the project . luckily , though , this code is going to be replaced in the next version using the new extension catalog api . <nl> the first one wins <nl> the first one wins","please do n't merge , i will merge it myself .",1615231533,"note : we validate the deployment in two batches : 0 ) dependencies , 0 ) other bean attributes + custom validators . <nl> example build failure :",0.9559563398361206
apache_beam/13608,fix for the case when truststorelocation and keystorelocation are not specified,in case if and/or parameters are n't specified the pipeline would fail . <nl> this pr fixes this issue,1608735760,this pr updates snowflake jdbc and adds ' application=beam ' string to url when building snowflake jdbc connection,0.9061346650123596
elastic_elasticsearch/72251,handle tombstone building entirely within parseddocument <para-sep> create a no-op tombstone document <nl> store the reason of a noop as a raw string in the _source field <nl> create a delete tombstone document <nl> see internalengine.updateversion to see where the real version value is set,"documentmapper contains some complicated logic to load <nl> metadata fields so that it can build tombstone documents . <nl> however , we only actually need three metadata mappers for <nl> this purpose , and they are all stateless so this logic is <nl> unnecessary . this commit adds two new static methods to <nl> parseddocument to build no-op and delete tombstones , <nl> and removes some ceremony elsewhere .",1619452835,"this pull request factorizes in the basesearchablesnapshotindexinput class some common code used to read the footer checksum of searchable snapshots implementations . <nl> this change helps to maintain the code to read the footer checksum in one place and helps to enable this optimisation for . it also helps to assert the non-usage of the cache fetch async thread pool when reading from a index input in a single place . <nl> finally , the index input unit tests have been adapted to account for the footer checksum read optimisation : they now generate a binary content that contains a",0.9687578678131104
OpenAPITools_openapi-generator/7776,"add gitignore to c # version , nancyfx generators <para-sep> .rsuser <nl> _h.h .iobj .ipdb _wpftmp.csproj .opendb .vc.db .vc.vc.opendb .sap <nl> .e2e <nl> .coverage .coveragexml <nl> .snupkg / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .appx .appxbundle .appxupload <nl> .jfm <nl> .rptproj.bak .ndf .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> .rsuser <nl> _h.h .iobj .ipdb _wpftmp.csproj .opendb .vc.db .vc.vc.opendb .sap <nl> .e2e <nl> .coverage .coveragexml <nl> .snupkg / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .appx .appxbundle .appxupload <nl> .jfm <nl> .rptproj.bak .ndf .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> .rsuser <nl> _h.h .iobj .ipdb _wpftmp.csproj .opendb .vc.db .vc.vc.opendb .sap <nl> .e2e <nl> .coverage .coveragexml <nl> .snupkg / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .appx .appxbundle .appxupload <nl> .jfm <nl> .rptproj.bak .ndf .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ]","- add gitignore to c # version , nancyfx generators <nl> - update samples and remove .net standard project ( deprecated ) from the ci tests .",1603260700,"ps : after running ./run/ { lang } -petstore.sh , i got change on the version and unrelated stuff like . should i revert this change ?",0.9150993227958679
vespa-engine_vespa/16070,move log statement inside runnable <cm-sep> guice modules passed to testdrivers will always override config module <cm-sep> remove checked ioexception from tojson ( ) <cm-sep> rewrite jettyconnectionlogger to deduplicate jetty connections . <nl> use socketchannelendpoint to uniquely identity tcp/ip connections . <nl> rename 'aggregatedconnectioninfo ' to 'connectioninfo ' . <nl> implement sslhandshakelistener to read ssl session after handshake . <cm-sep> use correct getter <cm-sep> simplify locking in connectioninfo <cm-sep> only include counters if initialized . rename 'bytes ' fields <para-sep> todo store details on proxy-protocol <nl> sslhandshakelistener methods start <nl> todo store details on failed ssl handshake <nl> sslhandshakelistener methods end <nl> this methods iterates through the endpoints recursively to find the underlying socket endpoint . <nl> todo include connection duration or timestamp closed,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610734612,i recommend looking at each commit separately in order .,0.9668857455253601
apache_incubator-pinot/5443,add broker request info to the error msg in combine operator . <nl> current log indicates exception/timeout in combine operator but <nl> this does not give much information for debugging . adding broker <nl> request to the log will help for debugging .,current log indicates exception/timeout in combine operator but <nl> this does not give much information for debugging . adding broker <nl> request to the log will help for debugging .,1590454467,"the failure message was not being propagated from controller to the client . client received only status code and status reason , which are insufficient indicators of the failure . passing the failure message in the response entity . <nl> incoming segment size : 0 ( bytes ) to controller : xxxx , version : unknown <nl> `",0.906430184841156
apache_pulsar/8952,add properties default value for schemainfobuilder,"when using schemainfobuilder to create a schemainfo , not setting properties will result in an npe . properties are optional in schemainfo and have default values . <nl> add default values for properties in schemainfobuilder . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api : ( yes / no ) <nl> - the schema : ( yes / no /",1607942322,the metrics for the reader backlog keep increasing when data is dropped because the reader cursor only moves on the next read attempt . <nl> instead we should proactively move the cursor forward on the first valid ledger .,0.8885063529014587
apache_ignite/8937,formalizes the names of the metrics included in the metric registry . <para-sep> register existing metrics in this group with the specified name . note that the name of the metric must start with the name of the current registry it is registered into .,current pr constraints name of the metrics that can be registered through metricregistry # register ( metric ) - it must start with the name of metric registry it 's registered into . <nl> the purpose of this change is to make all metrics that belongs to one metricregistry have the name that obeys mentioned above rule regardless how they were registered . it helps to use a consistent approach to work with all metrics . <nl> the following metric names was changed to obey this rule : . <nl> joinednodes - > io.discovery.joinednodes <nl> leftnodes - > io.discovery.leftnodes <nl>,1616755276,sqlviewmetricexporterspi moved to the internal package to eliminate it from public api . <nl> instances of this spi will be created automatically in case the indexing module available during node startup,0.8974313735961914
apache_pulsar/9382,fix setting backlogquota will always succeed <para-sep> ensure that the cache has not been updated after a long time,"# # # motivation <nl> since setbacklogquota does not have a return , it can actually be updated successfully even if there is a check error .",1612096603,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( yes ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) . <nl> (",0.8993605971336365
Alluxio_alluxio/11001,refactor commonutils.waitfor and use new api capabilities on couple usages <para-sep> waits for the object to meet a certain condition . <nl> waits for the object to meet a certain condition .,we have many instances in our code where we use commonutils.waitfor to wait for a certain condition to be equal to something but the last state of the object is not clear when there is a timeout . this code has a new api that could be opted into to get such a benefit .,1582578221,"the previous user group mapping does not work , so i also think it 's a bug . in addition , the user group translation is mistakenly included in the version doc ( and a user asked about it in mailing list before ) so we should cherry pick it to version .",0.9421613812446594
Alluxio_alluxio/11504,fix npe associated with s3 account owner,fixes mount failure and npe when a user tries to mount s3 bucket with a userid to username mapping configured .,1591119891,"with the new async persist feature , add a test for checking persist timeout .",0.9351678490638733
quarkusio_quarkus/15152,"test property access in hibernate search . <cm-sep> do n't register user classes for reflection in hibernate search extension . <nl> we do n't need to , because : . <nl> 0. we perform all reflection operations , except getting values from entities , <nl> at static init . <nl> 0. after static init , we hold references to all methods/fields that we <nl> will actually use at runtime . substratevm is able to detect those and <nl> to properly build a native image that will handle calling invoke ( ) on <nl> these methods/fields . <cm-sep> use methodhandles rather than java.lang.reflect for entity reading in hibernate search with graalvm 0+ . <nl> graalvm version supports method handles , so let 's use them . the main <nl> benefit is that we 'll use them in jvm mode too , where they should <nl> theoretically perform slightly better . <para-sep> graalvm 0 or below does n't support method handles <nl> graalvm 0+ and openjdk can handle the default ( method handles ) <nl> while indexing , hsearch will read the entity property by calling a synthetic getter <nl> ' otherproperty ' has no value in the index ... <nl> but ' property ' has . <nl> while indexing , hsearch will read the entity property by calling a synthetic getter , ensuring that it gets initialized automatically <nl> the entity is not initialized <nl> we update ' otherproperty ' <nl> ' otherproperty ' was updated in the index ... <nl> and ' property ' still has a value , proving that it was lazily initialized upon indexing . <nl> while indexing , hsearch will read the entity property through its getter method","we do n't need to enable runtime reflection on user classes , because : . <nl> 0. we perform all reflection operations , except getting values from entities , <nl> at static init . <nl> 0. after static init , we hold references to all methods/fields that we <nl> will actually use at runtime . substratevm is able to detect those and <nl> to properly build a native image that will handle calling invoke ( ) on <nl> these methods/fields . <nl> also , when using graalvm 0 or openjdk , we can move from to . which is what",1613585078,also adding integration tests for db2 + mysql,0.9573017954826355
jenkinsci_jenkins/4773,": extend downloadable api slightly . <nl> this mainly adds : <nl> - a static downloadable.idfor ( class ) method , which returns the id to <nl> use for a given class <nl> - existing code using a class now uses this method to do the mapping <nl> to an id value <nl> - an overload of the static downloadable.get ( ) method taking a class <nl> - applies idfor ( ) and forwards to the existing string-based get ( ) . <para-sep> creates a new downloadable . <nl> creates a new downloadable . <nl> creates a new downloadable . <nl> creates a new downloadable with a specific id . <nl> creates a new downloadable with a specific id and url . the default interval will be used . <nl> generates an id based on a class .","this mainly adds : <nl> - a static downloadable.idfor ( class ) method , which returns the id to <nl> use for a given class <nl> - existing code using a class now uses this method to do the mapping <nl> to an id value <nl> - an overload of the static downloadable.get ( ) method taking a class <nl> - applies idfor ( ) and forwards to the existing string-based get ( ) . <nl> no testcases added ; the existing tests already exercise the code changes . <nl> * : extend the downloadservice.downloadable api slightly",1591377312,"* internal : make proxyconfiguration compatible with configuration-as-code plugin . workaround on the jcasc plugin side is no longer required . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . ) <nl> it 's just getters and setters and requires a plugin dependency to test that configuration as code works , i 've ran the test and manually tested it <nl> - na for dependency updates : links to external changelogs and , if possible , full diffs .",0.963160514831543
apache_incubator-pinot/5557,fix backward incompatibility in streamfactoryconsumerprovider . <nl> this commit re-introduces the deleted method,"this commit re-introduces the deleted method . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1592003544,- filter out child anomaly in data provider anomaly fetching <nl> - fill in timezone/bucket for anomaly filter <nl> - the final child keeping merger does not fetch anomalies from the database . <nl> - replay remove anomaly flag .,0.9060064554214478
apache_shardingsphere/10203,using stream replace for loop in shardingunicastroutingengine <cm-sep> extracting multiple tables route in shardingunicastroutingengine to an independent function <cm-sep> using stream to replace forloop for reducing the complexity of the function <cm-sep> eliminating availabledatasourcenames may throw a nullpointerexception warning,changes proposed in this pull request : <nl> - using stream to reduce forloop <nl> - extracting code block to an independent function to reduce the length of route function,1619494894,changes proposed in this pull request : <nl> - dynamic init or stop heartbeat detection after configuration changed <nl> - remoe useless method,0.8856590986251831
trinodb_trino/6979,make testmemsqlcaseinsensitivemapping extensible <cm-sep> add comment for single-threaded case-insensitive-mapping tests <para-sep> with case-insensitive-name-matching enabled colliding schema/table names are considered as errors . some tests here create colliding names which can cause any other concurrent test to fail . with case-insensitive-name-matching enabled colliding schema/table names are considered as errors . some tests here create colliding names which can cause any other concurrent test to fail . with case-insensitive-name-matching enabled colliding schema/table names are considered as errors . some tests here create colliding names which can cause any other concurrent test to fail . with case-insensitive-name-matching enabled colliding schema/table names are considered as errors . some tests here create colliding names which can cause any other concurrent test to fail . <nl> with case-insensitive-name-matching enabled colliding schema/table names are considered as errors . some tests here create colliding names which can cause any other concurrent test to fail .,adds comments about why case-insensitive-name-matching tests are marked single-threaded so we can avoid mistakenly removing them .,1613975029,"the new order is more reasonable . <nl> the method was added after last release , so it is a safe change to do <nl> now .",0.7135533690452576
quarkusio_quarkus/15616,switches the 0 and 0 points for according to pom 's snippet . <nl> ( cherry picked from commit sha ) <cm-sep> fix thread-safe issue and memory leak with log history handler . <cm-sep> reintroduce routebuilditem # builder ( ) public ctor . <nl> it used to be public and was made private when it was marked as <nl> deprecated ( the default constructor is public ) . <nl> it is used by extensions out there so we need to maintain it . <nl> ( cherry picked from commit sha ) <cm-sep> avoid race condition when creating the dev ui routes . <nl> we need the static resources route to be defined before /dev/ * and this <nl> was n't guaranteed with two concurrent methods . <nl> ( cherry picked from commit sha ) <para-sep> add the static resources <nl> the number of history log entries to remember .,"please do n't merge , i will merge it myself .",1615417160,"please do n't merge , i 'll merge it myself .",0.9194231629371643
Alluxio_alluxio/10968,keep workerinfolist cached across instream and outstream <para-sep> cached map for workers . * / <nl> the policy to refresh workers list . * /,"was originally a singleton before version , so can keep worker info cached across input and output streams . <nl> this pr moves and to as the shared state . <nl> this pr also changes the job servers to use cached worker info list instead of keep getting the most updated worker info list .",1582275269,- improves configuration initialization <nl> - cleans up configuration validation <nl> - adds configuration validation for test cluster,0.9582085013389587
apache_pulsar/8996,"ack response <para-sep> batching and chunking ca n't be enabled together <nl> ok <nl> ack will return receipt but does not mean that the message will not be resent after get receipt . <nl> when we flush the command , we should ensure current ack request will send correct <nl> when flush the ack , we should bind the this ack in the currentfuture , during this time we ca n't change currentfuture . but we can lock by the read lock , because the currentfuture is not change any ack operation is allowed . <nl> ack this ack carry bitset index and judge bit set are all ack <nl> if we prevent batchindexack , we ca n't send the ack command to broker when the batch message are all ack complete <nl> ack the pre messageid , because we prevent the batchindexack , we can ensure pre messageid can ack <nl> when flush the ack , we should bind the this ack in the currentfuture , during this time we ca n't change currentfuture . but we can lock by the read lock , because the currentfuture is not change any ack operation is allowed . <nl> when flush the ack , we should bind the this ack in the currentfuture , during this time we ca n't change currentfuture . but we can lock by the read lock , because the currentfuture is not change any ack operation is allowed . <nl> we can not group acks if the delay is 0 or when there are properties attached to it . fortunately that 's an uncommon condition since it 's only used for the compaction subscription . <nl> when flush the ack , we should bind the this ack in the currentfuture , during this time we ca n't change currentfuture . but we can lock by the read lock , because the currentfuture is not change any ack operation is allowed . <nl> cumulative ack chunk by the last messageid <nl> if do n't support multi message ack , it also support ack receipt , so we should not think about the ack receipt in this logic <nl> client cnx do n't support ack receipt , if we do n't complete the future , the client will block .","0. we will add two ackrequests struct for async and sync flush . <nl> 0. add a timer to handle timeout and the timeout task do n't need to lock , because the timeout is sequential . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no",1608271204,support nested fields in pojos to be able to be queried by sql,0.9835777282714844
Graylog2_graylog2-server/9000,allow specifying default user/password for discovered nodes .,"prior to this pr , it was not possible to combine elasticsearch node discovery and authentication . discovered elasticsearch nodes must not have authentication enabled , because there was no way to configure credentials for them in graylog . <nl> this pr adds functionality for the user to supply a default user/password which is used for all discovered nodes . the same user & password must be used across all nodes in the elasticsearch cluster , as the same user/password is used for every discovered node added to the node list . <nl> the configuration settings are : . <nl>",1600428184,"this adds constructors to the remaning configuration fields <nl> that were lacking this option : , and .",0.9197157025337219
gocd_gocd/8302,add user can_operate field on individual stages of the dashboard pipeline . <nl> * add an ability to compute individual stage operate permissions as part of dashboard pipeline permissions <nl> * add can_operate field to the dashboard api .,description : . <nl> * add an ability to compute individual stage operate permissions as part of dashboard pipeline permissions <nl> * add can_operate field to the dashboard api .,1593683000,"this allows an artifact plugin to introduce environment variables into the job , after fetching an external artifact . this was planned for earlier versions of the k8s work but was not finished . without this , you 'll need to use external tools to parse the metadata json . with this , the plugin can expose environment variables which are then made available to all the tasks following the fetch artifact . <nl> assume there 's a new version of the docker artifact plugin . assume a config which contains : . <nl> at the end of ' task",0.9630522727966309
apache_kafka/9617,factor out common response parsing logic <cm-sep> add test case for mismatched correlationid for forwarded request <para-sep> raised if the correlationid in a response header does not match the expected value from the request header . <nl> fast-forward buffer to start of the request as expects,"this patch factors out some common parsing logic from and . as a result of this refactor , we are now verifying the correlationid in forwarded requests . this patch also adds a test case to verify handling in this case .",1605732608,adds a new custom security provider class configuration .,0.9504455327987671
jenkinsci_jenkins/4742,"show when a plugin version newer than offered exists <para-sep> the latest existing version of this plugin . may be different from the version being offered by the update site , which will result in a notice on the ui .","this adds notices to entries on the 'updates ' and 'available ' tabs of the plugin manager when a newer version exists than is being offered for installation . <nl> if the instance has the latest offered plugin release installed , new virtual ( uninstallable ) entries are created on the 'updates ' tab to inform users that something newer exists . on one hand i like that this shows unavailable content right where it would appear , otoh it could be weird or confusing , especially if admins do n't read . feedback welcome . <nl> screenshots . <nl>",1590439240,this is a hacktoberfest contribution . <nl> * add information about incompatible dependencies to the updates view in the plugin manager <nl> * change the classes for the warnings in the updates view to use 'alert-danger ' . <nl> before : . <nl> after :,0.9605526328086853
Alluxio_alluxio/11972,improve exception messages for filealreadyexistsexception <para-sep> creating the file path again results in no new inodes .,"filealreadyexistsexception message is not always obvious what it means , so adjusted the messages to be more specific to the situation .",1597261717,getworker should not be communicating with any other components so ioexceptions do not make as much sense as .,0.9346856474876404
apache_shardingsphere/9227,"added embedded mysql support for integration testing <nl> fixed multiple database type testing , if h2 is enabled , other database type data sources are not initialized <nl> fixed the problem of not closing the target database connection pool after integration testing <cm-sep> merge untracked file <cm-sep> merge untracked file <para-sep> checkstyle : off <nl> checkstyle : on <nl> todo if you do n't use h2 in the future , you need to implement this method . <nl> create embedded database resource by database type and environment . <nl> todo return default database resource <nl> drop embedded database resource . <nl> embedded database resource . <nl> start embedded database resource . <nl> stop embedded database resource . <nl> mysql database resource . <nl> get database distribution url . <nl> get database distribution version .","changes proposed in this pull request : <nl> - in order to improve the quality of integration testing , we want to introduce embedded mysql .",1611931964,changes proposed in this pull request : <nl> - add springboot configuring method for orchestrationencryptdatasource <nl> - add springnamespace configuring method for orchestrationencryptdatasource,0.979225754737854
vespa-engine_vespa/16030,"ensure minimum window size is never less than version , as that stops the session silently <para-sep> todo jonmv : remove this ? only used sensibly by feedhandlerv3 , where only timeout varies . <nl> use floating point window sizes , so the algorithm sees the difference between version and version window size .","ensure minimum window size is never less than version , as that stops the session silently .",1610539712,previous fix was not sufficient for always writing new version . <nl> previously could risk that state transition grace period would elide <nl> write to zookeeper if state changes happened within previous grace <nl> period .,0.8713868856430054
elastic_elasticsearch/70983,ensure token name does not being with a hyphen <para-sep> token name with a leading hyphen requires an option terminator,the cli tool needs an option terminator ( ) for another option names that begin with a hyphen . otherwise it errors out with message of ' not recognized option ' . the service account token name can begin with a hyphen . hence we need to use when it is the case . an example of equivalent command line is .,1617021032,re-enabled and fixed test to work when persisting metadata in lucene .,0.9301984906196594
apache_druid/10413,"add is_compacted to sys.segments table <para-sep> task . - in metadata store information api of the coordinator , ' lastcompactionstate ' is part of the sys.segments table <nl> this context is used in compaction . when it is set in the context , the segments created by the task expecte compaction state to exist as store compaction state by default expecte compaction state to exist as store compaction state by default expecte compaction state to exist as store compaction state by default <nl> expecte compaction state to exist as store compaction state by default <nl> expecte compaction state to exist after compaction as we store compaction state by default this is a regular index so we need to explicitly add this context to store the compactionstate <nl> wikipedia segment 0 and 0 are compacted while 0 are not compacted","add last_compaction_state to sys.segments table . <nl> segments being compacted or not compacted have a big impact on query performance . <nl> currently it is not easy to verify questions like : <nl> - if performance of query can be improve by compaction <nl> - if a performance of query is bad , was it because segments for that interval was not compacted . <nl> - if a segment was compacted , what was it compacted with ? was it compacted with the auto compaction config set ? <nl> this pr expose the lastcompactionstate via the sys.segments table ( so",1600731210,"this pr introduces an additional lifecycle stage , which runs first on startup and last on shutdown . <nl> additionally , ties 'task-master ' lifecycle to lifecycle in order to gracefully stop being leader when task master is stopping . <nl> also adds a field to which helps with additional logging around lifecycle stage startup and stops and which lifecycle they belong to . <nl> on startup : . <nl> and stopping : .",0.9370248317718506
elastic_elasticsearch/72051,ensure gcs repository metadata blob writes are atomic . <nl> in the corner case of uploading a large ( > 5mb ) metadata blob we did not set content validation <nl> requirement on the upload request ( we automatically have it for smaller requests that are not resumable <nl> uploads ) . this change sets the relevant request option to enforce a crc32c hash check when writing <nl> to gcs ( as is the case with all but data blob writes ) . the custom crc32c implementation <nl> here can be removed after backporting to 0.x . i copied over the guava version of crc32c with slight <nl> adjustments for consuming instead of pulling the guava dependency into the compile path <nl> so that we can use the jdk 's implementation of crc32c in 0.x without having different dependencies in 0.x <nl> and 0.x .,in the corner case of uploading a large ( > 5mb ) metadata blob we did not set content validation <nl> requirement on the upload request ( we automatically have it for smaller requests that are not resumable <nl> uploads ) . this change sets the relevant request option to enforce a md5 hash check when writing <nl> to gcs ( as is the case with all but data blob writes ) .,1619032618,"currently we open and close the checkpoint file channel for every fsync . <nl> this file channel can be kept open for the lifecycle of a translog <nl> writer . this avoids the overhead of opening the file , checking file <nl> permissions , and closing the file on every fsync .",0.9700755476951599
vespa-engine_vespa/15919,revert ' revert ' reapply ' upgrade to curator 0 ' ' ' <para-sep> extends mockbackgroundaclpathandbytesablebuilder,please review only . need to fix some code related to deletion of tenants before this can go in .,1609862099,"i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> only the last commit implements the fix . <nl> this is a rather vital part , so we 'd better get it right ....",0.9744062423706055
grpc_grpc-java/7675,"example-xds : mirror helloworld and hostname example . <nl> -- secure was moved to front since many languages need flags to precede <nl> positional parameters , and we 'd like other languages to use the same <nl> flags when feasible . <nl> :0 was removed from xds : target in the readme , as it is n't all that <nl> useful and is confusing as xds itself provides the backend port numbers . <cm-sep> example-xds : prefix class names with xds , instead of suffix . <nl> this aligns with normal naming practice . <para-sep> construct client for accessing helloworld server using the existing channel . * / <nl> say hello to server . * / <nl> greet server . the second argument is the target server . <nl> the example defaults to the same behavior as the hello world example . to enable xds , pass an ' xds : ' -prefixed string as the target . <nl> the xds credentials use the security configured by the xds server when available . when xds is not used or when xds does not provide security configuration , the xds credentials fall back to other credentials ( in this case , insecurechannelcredentials ) . <nl> this uses the new channelcredentials api . grpc.newchannelbuilder ( ) is the same as managedchannelbuilder.fortarget ( ) , except that it is passed credentials . when using this api , you do n't use methods like , as that configuration is provided by the channelcredentials . <nl> the xds credentials use the security configured by the xds server when available . when xds is not used or when xds does not provide security configuration , the xds credentials fall back to other credentials ( in this case , insecureservercredentials ) . <nl> since the main server may be using tls , we start a second server just for plaintext health checks <nl> start graceful shutdown <nl> wait for rpcs to complete processing <nl> that was plenty of time . let 's cancel the remaining rpcs <nl> shutdownnow is n't instantaneous , so give a bit of time to clean resources up gracefully . normally this will be well under a second . <nl> this would normally be tied to the service 's dependencies . for example , if hostnamegreeter used a channel to contact a required service , then when 'channel.getstate ( ) == transient_failure '","-- secure was moved to front since many languages need flags to precede <nl> positional parameters , and we 'd like other languages to use the same <nl> flags when feasible . <nl> :0 was removed from xds : target in the readme , as it is n't all that <nl> useful and is confusing as xds itself provides the backend port numbers .",1606770927,"should not expose server stub methods , because it is wrong to call server stub methods directly .",0.8062493205070496
apache_pulsar/9852,add logs for cleanup offloaded data operation,"the cleanup offloaded data operation was lack of logs , it 's hard for users to analyze the tiered storage data loss reason . <nl> add some logs for the cleanup offloaded data operation .",1615305901,- changed default options in cpp and java client producerconfigurations <nl> - fixed some test cases <nl> - changed perf tests to block if queue is full . <nl> sendasync becomes a non-blocking call .,0.8865777850151062
apache_pulsar/9910,"motivation . <nl> when zookeeper ledgers root path is changed , using pulsar-sql to query messages will cause . <nl> modifications . <nl> to use new defaultbkfactory ( clientconfiguration ) ，so that zk will be null in bookeeper constructor ; ( bookeeper.java row 0 ) <nl> when metadatadriver will be initialized ( bookeeper.java row 0 ) , zookeeper conection is null ; we can jump to another branch.if we have done the above steps , <nl> finally , zkservers will be localhost:0 rather than localhost:0/pulsar in row 0 ( zkmetadatadriverbase.java ) ; the path that we use to get ledger is localhost:0/pulsar/ledger/0/0/l0001 rather than localhost:0/pulsar/pulsar/ledger/0/0/l0001 ;","motivation . <nl> when zookeeper ledgers root path is changed , using pulsar-sql to query messages will cause . <nl> modifications . <nl> to use new defaultbkfactory ( clientconfiguration ) ，so that zk will be null in bookeeper constructor ; ( bookeeper.java row 0 ) <nl> when metadatadriver will be initialized ( bookeeper.java row 0 ) , zookeeper conection is null ; we can jump to another branch.if we have done the above steps , <nl> finally , zkservers will be localhost:0 rather than localhost:0/pulsar in row 0 ( zkmetadatadriverbase.java ) ; the path that we use to get ledger",1615860055,the metrics for the reader backlog keep increasing when data is dropped because the reader cursor only moves on the next read attempt . <nl> instead we should proactively move the cursor forward on the first valid ledger .,0.9374759197235107
apache_pulsar/9031,websocket proxy should return status code depending on type of pulsarclientexception <para-sep> expected <nl> expected <nl> expected <nl> expected,"if the websocket proxy fails to create a producer or consumer , it should return the suitable http status code to the client depending on the type of that occurred . however , there are currently only a few exceptions where the websocket proxy returns a status code other than 0 . <nl> moved the method from and to and increased the types of to handle .",1608684952,"for batchpushsource , since we are using linkedblockingqueue , user 's can not simply pass a null value . thus we need a special mechanism to indicate the end of a batch - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding the documentation",0.9467464089393616
prestodb_presto/15295,"revert ' revert ' defer the creation of dictionary in slicedictionaryselectivereader ' ' . <nl> this reverts commit sha . <cm-sep> revert ' revert ' remove stripedictionarydata buffer in slicedictionaryselectivereader ' ' . <nl> this reverts commit sha . <para-sep> each rowgroup has roughly 10k rows , and each batch reads 1k rows . so there 're about 0 batches in a rowgroup . <nl> materialization_ratio should be greater than or equal to versionf to compensate the extra cpu to materialize blocks . <nl> compact values ( ids ) array , and calculate 0 ) the slice sizeinbytes if materialized , and 0 ) number of nulls <nl> if all selected positions are null , just return rle block . <nl> if the expected materialized size of the output block is smaller than a certain ratio of the dictionary size , we will materialize the values <nl> direct and dictionary direct and dictionary materialized presentstream is null in some row groups & dictionary materialized","it introduced a nullscount variable that intended to early return a runlengthencodedblock when all output positions are null even when allnulls is false . this was theoretically possible : suppose outputpositions = [ 0 , 0 ] , outputpositioncount = 0 , but both position 0 and 0 are null , <nl> then there is no need to create the normal block . however there are some cases that the outputpositioncount was dropped after applying filter functions . in such cases , if the dropped outputpositioncount happens to be equal to nullscount , a runlengthencodedblock of all nulls would be",1602221429,"* empty files do n't have encryptiongroups , so ignore any keys <nl> * adding encrypted streams was getting short circuited if unencrypted streams had a row group dictionary <nl> * filestatistics for encryption groups was n't implemented correctly ( format requires a list of encrypted file statistics objects corresponding to then nodes of the encryption group , not a single filestatistics object for all the nodes ) .",0.9038156867027283
Graylog2_graylog2-server/9899,"supporting and properties in relative time ranges . <nl> this change is implementing functionality to support an alternative way <nl> to use relative time ranges . instead of a property that defines <nl> the length of the range in seconds going backwards from now , it allows <nl> defining and properties defining the endpoints of a range in <nl> relation to . this allows e.g . defining a range that goes from 0 <nl> minutes ago to 0 minute ago by specifying a relative range as : .","this change is implementing functionality to support an alternative way to use relative time ranges . instead of a property that defines the length of the range in seconds going backwards from now , it allows defining and properties defining the endpoints of a range in relation to . this allows e.g . defining a range that goes from 0 minutes ago to 0 minute ago by specifying a relative range as : .",1610547947,"the events search code is now checking if the user that executes the <nl> search is allowed to see events based on the ' source_streams ' field . <nl> example : . <nl> if an event got created from a message in stream a , the event has stream <nl> a in its ' source_stream ' field . if a user has read permissions on stream <nl> a , the event is visible to the user in the events search .",0.9428917169570923
quarkusio_quarkus/15604,"disable devui for remote dev mode . <nl> ( cherry picked from commit sha ) <cm-sep> added descriptions to health openapi filter responses <nl> signed-off-by : phillip kruger . <nl> ( cherry picked from commit sha ) <cm-sep> fix classroutinghandler not using sortedoriginalmediatypes in else block . <nl> ( cherry picked from commit sha ) <cm-sep> fix graphql queries returning collection.class in native mode . <nl> ( cherry picked from commit sha ) <cm-sep> fix potential race condition with multipart upload in resteasy reactive . <cm-sep> fix race condition on reading input in resteasy reactive . <cm-sep> fix polyglot with fast-jar . <nl> ( cherry picked from commit sha ) <cm-sep> look for redisclient in all modules . <nl> ( cherry picked from commit sha ) <cm-sep> fix devconsole paths ; httprootpathbuilditem.builder . <nl> * expose configured http paths to the devui <nl> * add builder to httprootpathbuilditem to help create <nl> routebuilditems using resolved paths <nl> * create devconsoleappend attribute for resolving static dev <nl> console resources . <cm-sep> tests for quarkus.rest.path . <nl> ( cherry picked from commit sha ) <cm-sep> look for mongo client in the whole deployment . <nl> ( cherry picked from commit sha ) <para-sep> assume your ui will be nested under the dev endpoint . do not provide a way to customize this without a strong reason . never construct your own absolute paths . adding a suffix to a known , normalized and resolved path is fine . <nl> make mongoclients an unremoveable bean <nl> per spec : paths are relative . for an annotated class the base uri is the application path , see applicationpath . for an annotated method the base uri is the effective uri of the containing class . for the purposes of absolutizing a path against the base uri , a leading '/ ' in a path is ignored and base uris are treated as if they ended in '/ ' . <nl> this is expected behavior ( relative path appended to http root path ) <nl> per spec : identifies the application path that serves as the base uri for all resource uris provided by path . may only be applied to a subclass of application . this path will also be relative to the configured http root <nl> the rootpath under which queries will be served . default to graphql by default , this value",please do n't merge i will merge it myself .,1615389709,"please do n't merge , i will merge it myself .",0.9747936725616455
apache_beam/13513,"added a test method reproducing bufferoverflowexception <cm-sep> fixed bufferoverflowexception in xmlreader <para-sep> avoiding buffer overflow . the number of bytes to push to the buffer might be larger than buf_size due to additional 'charbytes ' . <nl> we have to reset the size of the buffer to 'buf_size ' to prevent it from infinitely increasing . <nl> the magicnumber was found imperatively and will be different for different xml content . test with the current setup causes bufferoverflow in xmlreader # getfirstoccurenceofrecordelement method , if the specific corner case is not handled <nl> tags which start the same way as the record element , trigger a special flow , which could end up with bufferoverflow exception","fixing java.nio.bufferoverflowexception in getfirstoccurenceofrecordelement method of xmlreader . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1607541303,"when tumble works as table-valued function , make sure basic aggregation works . <nl> current implementation idea is , we just ' window ' pcollection in tablescanrel , such than any following aggregation or join will be applied on ' windowed ' stream directly",0.8968042731285095
apache_flink/14393,"ease debugging of errors during slot allocation . <nl> when transitioning from pending to allocated we now first verify that the job id is matching because this is a more serious issues . <nl> furthermore , if either the slot state of job id conditions are not met we now print better error messages . <nl> finally , log the state transitions of all slots . <para-sep> it is important that the returned future is already completed otherwise it will be cancelled when the task executor is unregistered <nl> it is important that the returned future is already completed otherwise it will be cancelled when the task executor is unregistered","properly skip the processing of slot allocation that have already concluded by no longer relying on the cancellation of futures , as it is unreliable when using async operations since other operations may occur in-between , and instead using a set for tracking pending allocations and checking at the start of processing . <nl> basically , in the current code the future to be cancelled can be completed without the async portion having run but being scheduled . if now some operation occurs that would lead to the future being cancelled , then the async portion still runs because a",1608051457,"fix the deadlock while releasing memory triggered by multiple threads in . <nl> - make the call of outside in <nl> - refactor the as a separate class for using in other tests . <nl> this change is covered by new test * . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime",0.9445810317993164
apache_kafka/9801,code cleanup for kafka streams task interface . <nl> not functional change . pure code cleanup . <para-sep> non-idempotent life-cycle methods <nl> attempt a clean close but do not close the underlying state <nl> runtime methods ( using in running state ),not functional change . pure code cleanup .,1609366597,changes to keep the operation name as is and make the sensor name unique .,0.8386635184288025
apache_pulsar/9236,"transaction buffer stable position and lowwatermark implementation . <cm-sep> fix some test <cm-sep> fix some comments <cm-sep> fix some comments <cm-sep> fix the checkstyle <cm-sep> transaction time out implementation . <cm-sep> tc end transaction retry . <cm-sep> fix some checkstyle <para-sep> ongoing transaction , map for remove txn stable position , linked for find max read position . aborts , map for jude message is aborted , linked for remove abort txn in memory when this position have been deleted .","does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1611051803,while deploying proxy/websocket we need a mechanism to add/remove host from the vip . <nl> add rest api which checks the existence of and we can add/remove host in vip based on the file availability .,0.9684019088745117
ballerina-platform_ballerina-lang/24917,fix parsestringliteral . <nl> wrapped the stringliteral token with basicliteraltoken <cm-sep> fix parsestringliteral . <nl> changed stringliteral being returned as a token . <nl> wrapped it with basicliteralnode for expressionlhs <nl> and added tests .,added parser tests to test for this .,1595500157,allow function pointers to be used under type guard .,0.8753703832626343
hazelcast_hazelcast/18307,"add total number of created proxies per service to phone home data . <nl> as per discussion on slack , this adds information about proxies that <nl> were created but were subsequently destroyed .","as per discussion on slack , this adds information about proxies that <nl> were created but were subsequently destroyed .",1614519110,"i have cleared all the code about synchronizing mapstore loadall among cluster members . <nl> it was too complicated , and have concurrency problems , may easily cause deadlocks . <nl> so currently all nodes tries to loadall and operations do not wait load all . <nl> if this improvement needed , it should be carefully redesigned .",0.9303821921348572
apache_pulsar/9232,"allow to configure bk opportunistc striping <para-sep> default value <nl> overridable by subclasses <nl> with bookkeeper opportunistic striping feature we can allow pulsar to work with only wq bookie during temporary outages of some bookie . <nl> starting only two bookies <nl> we would like to stripe over 0 bookies <nl> we want 0 copies for each entry <nl> verify that all ledgers has the proper writequorumsize , equals to the number of available bookies ( in this case 0 )","bookkeeper version introduces the 'opportunistic striping ' feature . <nl> in bk terms 'striping ' happens when ensemblesize is greater than writequorumsize , in this mode the entries are distributed round robin over a set of bookies , in order to achieve better performances as you can use the resources of more bookies . <nl> for instance in a small ha cluster , with only 0 bookies , you must run pulsar with 0-0-0 replication parameters ( ensemblesize=0 , writequorumsize=0 , ackquorumsize=0 ) . <nl> you can not set ensemblesize=0 ( and thus use 'striping ' ) because in case",1610986943,"sha changed topic delete logic to delete the schema when the <nl> topic is deleted ( though this only seems to be enabled for idle topic <nl> gc ) . this exposed a bug in compatibility checking whereby if the a <nl> subscription tries to attach to the topic , even if using the same <nl> schema as had been used previously , a compatibility exception will be <nl> thrown . <nl> this is because the topic still appears to have a schema , even though <nl> there is no actual schema data , just a tombstone . i 've",0.963344156742096
apache_shardingsphere/9560,add test case for yamldatasourceconfigurationswapper.swaptodatasources <cm-sep> add test case for yamldatasourceconfigurationswapper.swaptodatasources,changes proposed in this pull request : <nl> - test case added for yamldatasourceconfigurationswapper.swaptodatasources,1614656113,changes proposed in this pull request : <nl> -assertnewinstancewithdbcreateexistsexception <nl> -assertnewinstancewithdbdropexistsexception <nl> -assertnewinstancewithtableexistsexception <nl> -assertnewinstancewithcircuitbreakexception <nl> -assertnewinstancewithshardingsphereconfigurationexception <nl> -assertnewinstancewithsqlparsingexception <nl> -assertnewinstancewithunsupportedcommandexception <nl> -assertnewinstancewithunsupportedpreparedstatementexception,0.9129311442375183
apache_kafka/9597,": document prohibition on header mutation by smts <para-sep> if such objects need to be changed , a new connectrecord should be created and returned .",adds a sentence to the javadoc for about not mutating headers .,1605519309,"a lot of confusion seems to have arisen from the streambuilder # addglobalstore ( ... processorsupplier ) method . users have assumed they can safely use this to transform records before populating their global state store ; unfortunately this results in corrupted data as on restore the records are read directly from the source topic changelog , bypassing their custom processor . <nl> we should probably provide a means to do this at some point but for the time being we should clarify the proper use of # addglobalstore as it currently functions",0.9024798274040222
apache_shardingsphere/9987,add sqlserverprivilegeloader <cm-sep> merge master <cm-sep> merge master <cm-sep> add sqlserverprivilegeloader <para-sep> sqlserver privilege loader .,changes proposed in this pull request : <nl> - load users and privileges from sqlserver,1617864473,changes proposed in this pull request : <nl> - add test cases for datanode,0.9849145412445068
Graylog2_graylog2-server/9805,fix order of tabs in dashboard after install . <nl> since we can not change the order of the tabs <nl> this is quite inconvinient for the user . <nl> - instead of using the serach queryids we use the views queryids which <nl> we previously fixed in the order . <nl> - when loading a view and selecting the activequery we also use the <nl> view.state queryids instead of the search ones .,"since we can not change the order of the tabs <nl> this is quite inconvinient for the user . <nl> - instead of using the serach queryids we use the views queryids which <nl> we previously fixed in the order . <nl> - when loading a view and selecting the activequery we also use the <nl> view.state queryids instead of the search ones . <nl> 0. create a dashboard <nl> 0. create multiple tabs with names [ 0 , 0 , 0 , 0 , 0 ] <nl> 0. create a content pack with this dashboard <nl> 0. install that",1608039541,"this led to a logged error , because multiple instances of were configured . the configuration happens in a static constructor and due to the relocation we had multiple class definitions in multiple packages , which were n't properly configured . <nl> in addition we added a suffix to the shaded dependencies ' version so that we can deploy new artifacts without bumping the underlying version for the shaded library . <nl> local setup .",0.8365037441253662
ballerina-platform_ballerina-lang/26161,"add nodes constantdeclarationnode , parameterizedtypedescriptornode and typeparameternode <cm-sep> add nodes functiontypedescriptornode and parenthesisedtypedescriptornode <cm-sep> add several node implementations . <nl> externalfunctionbodynode , annotationnode , mappingconstructorexpressionnode , specificfieldnode , listconstructorexpressionnode <cm-sep> add several node implementations . <nl> errortypedescriptornode , panicstatementnode , intersectiontypedescriptornode , modulevariabledeclarationnode , expressionfunctionbodynode , typecastexpressionnode , typecastparamnode , indexedexpressionnode , computednamefieldnode , tupletypedescriptornode , listbindingpatternnode , restbindingpatternnode , tabletypedescriptornode , keytypeconstraintnode , matchstatementnode , matchclausenode , matchguardnode",* constantdeclarationnode <nl> * parameterizedtypedescriptornode <nl> * typeparameternode <nl> * functiontypedescriptornode <nl> * parenthesisedtypedescriptornode <nl> * externalfunctionbodynode <nl> * annotationnode <nl> * mappingconstructorexpressionnode <nl> * specificfieldnode <nl> * listconstructorexpressionnode <nl> * errortypedescriptornode <nl> * panicstatementnode <nl> * intersectiontypedescriptornode <nl> * modulevariabledeclarationnode <nl> * expressionfunctionbodynode <nl> * typecastexpressionnode <nl> * typecastparamnode <nl> * indexedexpressionnode <nl> * computednamefieldnode <nl> * tupletypedescriptornode <nl> * listbindingpatternnode <nl> * restbindingpatternnode <nl> * tabletypedescriptornode <nl> * keytypeconstraintnode <nl> * matchstatementnode <nl> * matchclausenode <nl> * matchguardnode <nl> * lockstatementnode <nl> * fieldaccessexpressionnode <nl> * metadatanode <nl> * enumdeclarationnode <nl> * enummembernode <nl> * markdowndocumentationnode <nl> *,1601452139,are not getting rendered in the diagram atm . this is to fix it .,0.9493355751037598
keycloak_keycloak/6734,fix ' invalid state ' error due to ie requesting favicon . <nl> internet explorer occasionally requests a favicon before doing the <nl> actual redirect to localhost . this commit adds undertow to properly <nl> handle those unwanted requests .,"internet explorer occasionally requests a favicon before doing the <nl> actual redirect to localhost . this commit adds undertow to properly <nl> handle those unwanted requests . <nl> remarks : . <nl> * i tried to keep it as low-level as possible but miserably failed . i 'm obviously not smart enough to implement the http protocol properly . <nl> * the statements have been auto-organized by the ide , hope that 's okay . <nl> * interface for customized login and logout responses has been removed . that might be a breaking change but i really doubt that 's",1580912297,note that we are upgrading freemarker to version ' version-incubating ' . this only denotes that the project is moved to the apache incubator . it is the official version release .,0.8177086710929871
ballerina-platform_ballerina-lang/25899,allow using refs of module definitions within isolated functions <cm-sep> merge master <para-sep> todo : 0/0/0 remove this error once stdlibs are migrated <nl> todo : 0/0/0 remove this once stdlibs are migrated <nl> todo : 0/0/0 remove this once stdlibs are migrated,this pr also makes incorrect default value usage a warning only for ballerina and ballerinax modules . for other modules such usage will now result in an error .,1600358352,with this pr endpoints can be defined using objects . struct support will be removed in next version . <nl> eg :,0.9354137182235718
gocd_gocd/8069,- added no dependency material error as the global error when a fetch artifact task uses a material which is not declared as dependency <nl> - showcase global errors on the modal of material edit <nl> - removed the current pipeline name from pipeline list for dependency materials <nl> - fixed the issue of no apparent change but still prompt for changes on materials <nl> - updated pipeline activity to use latest version of api <cm-sep> - added support for filter and invert_filter for scm materials <nl> - added margin botton for switch <nl> - updated the material editor for blacklist <para-sep> remove the original one and save the updated one,description : <nl> - showcasing name when material is deleted when a name is not explicitly added <nl> - making sure that if changes is cancelled it does not affect the main tab content <nl> - updated message to contain instead of <nl> - showcase circular dependencies error messages <nl> - not showcasing the current pipeline in the list of pipelines on dependency material popup <nl> - showcasing message when a material is deleted which is used in a fetch artifact task <nl> - adding support for for scm materials,1588176660,"- allow updating notification filter from event type to others <nl> - validate the pipeline name and stage name before creating the filter <nl> * [ any pipeline ] : allow creating a filter , no validation will be performed . <nl> * [ any stage ] : allow creating a filter if pipeline exists . <nl> - error out when invalid event name specified .",0.931921660900116
pentaho_pentaho-kettle/7440,"* converting integer to timestamp type using select values step results in incorrect date . <nl> * use envutil instead of system . <nl> * updating copyrights . <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> ( cherry picked from commit sha ) <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> reverting the change in the default behaviour . <nl> by default , timestamp-to-integer returns milliseconds once again . <nl> ( cherry picked from commit sha ) <cm-sep> converting integer to timestamp type using select values step results in incorrect date . <nl> ( cherry picked from commit sha ) <cm-sep> fix tests and checkstyle changes . <nl> ( cherry picked from commit sha ) <cm-sep> sonar recommendations . <nl> ( cherry picked from commit sha ) <para-sep> this environment variable is used to define how timestamp should be converted to a number and vice-versa . <nl> convert milliseconds to nanoseconds ! <nl> if the nullvalue is specified , we try to match with that . <nl> if the polled value is equal to the spaces right-padded nullvalue , we have a match",it may be a good idea not to squash the commits for everyone to see these details .,1588284040,- validating extra parameter value before appending it 's key to url . <nl> - tests written <nl> - checking whether the underlying database for two databaseinterface 's is the same depending on the class hierarchy ( if check by pluginid fails ) .,0.9677916765213013
apache_druid/10721,"javascript filter result convert to java boolean <para-sep> direct return js function result ( like arr.includes ) will return org.mozilla.javascript.nativeboolean , context.toboolean always treat it as true , even if it is false . convert it to java.lang.boolean first to fix this mistake . <nl> test for return org.mozilla.javascript.nativeboolean <nl> test for return java.lang.boolean <nl> test for return other type <nl> test for return null","i found the js engine ( rhino ) 's return type of the former usage is , and will treat it as true even though the value is false ! the return type of the latter is , it will behave correctly . <nl> so i add a convert js function , convert to , so that will return the correct result . <nl> this problem ( or feature ? ) <nl> > toboolean <nl> > boolean ( new boolean ( false ) ) is false for all versions before version . it is true ( and thus ecma conformant",1609306559,"recently , i observed the overlord sometimes does n't run pending tasks for a while even if there are enough capacity to run the tasks and the workers are n't in the black list . in my scenario , it may delay several minutes sometimes . i have n't found the root cause , but call the method when assigned a task that is already pending can help this . <nl> since it will also call the when add a new task that is not in the pending list , and is thread safe , so there is no side",0.9116063714027405
elastic_elasticsearch/71911,"this pr adds a new rest endpoint to clear caches used by service account <nl> authentication . <para-sep> do not cache failed attempt <nl> invalidate cache entries with keys matching to the specified qualified token names . <nl> wildcard case of invalidating all tokens for a service account , e.g . ' elastic/fleet-server/ ' <nl> this is the wildcard case for tokennames <nl> 5th auth with the wrong token2 again does not use cache <nl> invalidate a single entry <nl> invalidate all entries <nl> auth everything again <nl> validation should pass",this pr adds a new rest endpoint to clear caches used by service account <nl> authentication .,1618914039,"currently a failed peer recovery action will fail an recovery . this <nl> includes when the recovery fails due to potentially short lived <nl> transient issues such as rejected exceptions or circuit breaking <nl> errors . <nl> this commit adds the concept of a retryable action . a retryable action <nl> will be retryed in face of certain errors . the action will be retried <nl> after an exponentially increasing backoff period . after defined time , <nl> the action will timeout . <nl> this commit only implements retries for responses that indicate the <nl> target node has not executed",0.9727632403373718
vespa-engine_vespa/15383,"list _all_ tenants in all tenant view . <nl> previously we only listed tenants with usage data , but now we list <nl> all tenants regardless of their usage .","previously we only listed tenants with usage data , but now we list all tenants regardless of their usage .",1605716416,make it possible to configure and change status code in /state/v1/health api . <nl> make inital value configurable and make it possible to get and set it <nl> in statemonitor . <nl> use this to set state to 'initalizing ' until bootstrap is done in config server,0.9188244342803955
jenkinsci_jenkins/4708,fix up protector class <para-sep> one of the fields is empty <nl> will be null if it was n't encrypted <nl> require that both values are protected or unprotected ; do not allow user to change just one text field <nl> passwords are different encrypted values <nl> passwords are different plain values,"while it would _generally_ be a pretty severe problem to use des , the way this class is written and used makes it fairly harmless . still , get rid of it . <nl> the benefit of a session specific key here makes it very easy to just change the algorithm etc . without having to be able to decrypt old data . <nl> an argument could be made that we should just use here , and perhaps as the form field ; otoh i like the idea with a session-specific encryption and probably want to use it elsewhere .",1588590563,"unixreflection class did n't support java 0+ apis , and is removed from recent java versions . multi-release jar is probably a way to go , but so far i would like to apply a quick patch . <nl> * rfe : update unix process management logic to support process tree termination in java 0 <nl> * .. . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9546637535095215
elastic_elasticsearch/70547,the test abstractsearchablesnapshotsresttestcase.testclearcache ( ) <nl> sometimes fails because it assumes that all cache writes are completed <nl> when retrieving and comparing the searchable snapshots stat <nl> cached_bytes_written . <nl> this commit changes the test so that it now waits for searchable <nl> snapshots thread pools to finish to process cache related tasks <nl> before retrieving the stats . <cm-sep> fix,the test abstractsearchablesnapshotsresttestcase.testclearcache ( ) <nl> sometimes fails because it assumes that all cache writes are completed <nl> when retrieving and comparing the searchable snapshots stat <nl> cached_bytes_written . <nl> this commit changes the test so that it now waits for searchable <nl> snapshots thread pools to finish to process cache related tasks <nl> before retrieving the stats .,1616064120,"when target indices are remote only , ccs does not require user to have privileges on the local cluster . this pr ensure point-in-time reader follows the same pattern .",0.9112772941589355
apache_flink/15053,add job id to runtimecontext <para-sep> standalone collection executor ) . note that job id can change in particular upon manual restart . the returned id should not be used for any job management tasks .,"existing workarounds does n't look clean ( reliable ) . <nl> this pr adds to the ( the latter already contains some information of the same level , such as subtask index ) . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : yes <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects",1614630618,"fixes an issue where the rest api status response for asynchronous operations was n't documented properly . <nl> the async operation result has a generic parameter , which obviously does n't work with the rest api generation since it relies on classes . as a result the generator always considered the inner ( generic ) result as an , basically not documenting anything . <nl> this pr provides a stop-gap solution by hard-coding additional logic for . <nl> i exposed the inner class by making public , generate a separate schema for it , and overwrite the corresponding property entry",0.8923112750053406
quarkusio_quarkus/15620,amazon lambda http : refactoring query bypass and tests <cm-sep> amazon lambda http test : path starting from root <cm-sep> google function http test : path starting from root <cm-sep> azure http function tests,amazon lambda query handling slightly improved,1615446941,we can plug into shamrock 's enhancement capabilities so that people do n't need to setup the hibernate maven tools . <nl> upgrading asm while at it ; not necessary but seems harmless and aligns it with the version used in hibernate .,0.9714257121086121
quarkusio_quarkus/16495,"fix case of kafka servicebinging properties . <nl> ( cherry picked from commit sha ) <cm-sep> attempt to fix the kafka ci issues . <nl> today , we are starting three brokers side-by-side , which include three kafka instances and three zookeeper instances . that may be too much and may lead to unexpected issues . <nl> this commit split the tests into three different modules : . <nl> - kafka verifies the typical kafka behavior ( producer , consumer , codecs ... ) <nl> - kafka-ssl verifies the connection with ssl <nl> - kafka-sasl verifies the connection with sasl . <nl> each of them starts a single broker with a specific configuration . <nl> ( cherry picked from commit sha ) <cm-sep> rewrote kafka ssl tests . <nl> * the previous code was actually not configured ssl consistently <nl> * switch to test container ( strimzi containers ) <nl> * configure the native test to actually use ssl . <nl> ( cherry picked from commit sha ) <cm-sep> rewrote kafka sasl tests . <nl> - switch to test containers ( using strimzi containers ) <nl> - make sure sasl is configured consistently . <nl> ( cherry picked from commit sha ) <cm-sep> switch from debezium to test containers to start the kafka brokers . <nl> debezium requires kafka and scala which lead to issues when updating these libraries ( alignment ) . <nl> ( cherry picked from commit sha ) <cm-sep> upgrade to hibernate search version.final <para-sep> methodhandles do n't work at all in graalvm 0 and below , and seem unreliable on graalvm 0 <nl> add many other entities , so that mass indexing has something to do . do not remove , it 's important to have many entities to fully test mass indexing . <nl> endpoint to check the ssl/sasl connection . <nl> used by the test <nl> used by the application <nl> use a fixed port container to ease sasl configuration . <nl> sort kafka version from low to high <nl> exposing kafka port from the container <nl> we need it for the startzookeeper ( ) ; and startkafka ( ) ; to run container before ... <nl> endpoint to check the ssl connection . <nl> used by the test <nl> used by the application <nl> sort kafka version from low to high <nl> exposing kafka port from the container <nl> we need it for","please do n't merge , i will merge it myself .",1618382642,- the logic was moved from resteasy standalone <nl> - thanks to that static resources are served even for vertx-web,0.9688242673873901
apache_kafka/9761,"add a test for bytebufferinputstream to bytebufferloginputstreamtest . <nl> i made a test for bytebufferinputstream in the bytebufferloginputstreamtest . <nl> first , i add a bytebuffer that it 's not empty to the bytebufferinputstream , in order to verify it . <nl> after that , i try to use bytebufferinputstream 's read function and check return value whether it 's correct .","i made a test for bytebufferinputstream in the bytebufferloginputstreamtest . <nl> first , i add a bytebuffer that it 's not empty to the bytebufferinputstream , in order to verify it . <nl> after that , i try to use bytebufferinputstream 's read function and check return value whether it 's correct .",1608137399,"this pr adds unit tests for , , and . <nl> increase kafkaproducer junit code coverage from 0 % methods , 0 % lines to 0 % methods , 0 % lines .",0.8998039364814758
apache_kafka/9839,"factor out of <para-sep> block in poll until we get the expected wakeup <nl> poll a second time to send request and receive response <nl> attempt a graceful shutdown of the client . this allows the leader to proactively resign and help a new leader to get elected rather than forcing the remaining voters to wait for the fetch timeout . note that if the client has hit an unexpected exception which has left it in an indeterminate state , then the call to shutdown should be skipped .",this patch factors out a class from which will be needed when we integrate this layer into the server . this class encapsulates the logic to build as well as its io thread .,1609985544,"in general the behavior of window stores with is not well documented or enforced , so we should attempt to clarify things better in the javadocs and in the code itself . this explicitly skips the put/delete when the value is null and duplicates are allowed , and specifies this behavior in the docs .",0.9013494849205017
apache_druid/10304,"first draft <para-sep> skip vectorization for string types which may be parseable to numbers . there is no vector equivalent of <nl> getting the object from value selectors is outside this class . <nl> getting the object from value selectors is outside this class . <nl> use dense storage for aggregation <nl> these have to set in every call since limits are transient and lost during serialization-deserialization <nl> nothing to close <nl> no resources to cleanup <nl> merge another datapoint into this one . <nl> getting the object from value selectors is outside this class . <nl> nothing to close <nl> ( 0 , 0 ) , ( version , 0 ) , ( version , 0 ) , ( version , 0 ) , ( 0 , 0 ) <nl> put rest of 0 elements using the access indirection . second vector gets the same element always <nl> default value of null is 0 which is an outlier . <nl> tests when there is a level of indirection in accessing the vector","this pr adds vectorization support for aggregators in the extension . while these changes are unlikely to result in the usage of simd instructions , they can still help gain performance in two ways i can think of <nl> - being more cache-friendly and less number of function calls <nl> - enable vectorization for the whole query when one of the participating aggregator is assuming other aggregators in query support vectorization . <nl> the code is refactored to reduce duplicate code . much of the buffer manipulations are now called from classes which are in-turn used by and",1597930747,add sql inputsource support for ingesting events from rdbms using parallel indexing,0.969584047794342
confluentinc_ksql/5969,add config to disable suppress andbound buffer size <cm-sep> add suppress feature flag and buffer configs <cm-sep> fix checkstyle <cm-sep> fix checstyle violation <para-sep> checkstyle_rules.off : cyclomaticcomplexity checkstyle_rules.on : cyclomaticcomplexity <nl> given : <nl> when : <nl> then :,unit and integration tests are expected for any behavior changes._ <nl> unit tests and qtts have been added <nl> # # # reviewer checklist .,1596835440,"the api is a new method added in kafka version . if ksql runs on kafka version or lower , this api will return null causing a npe in ksql and denying any operation executed on a kafka version environment . <nl> to avoid the npe issue , ksql avoids enabling the topic validator instead . look at the which checks if the from the cluster is null . <nl> run local tests with kafka version . warning message is printed : . <nl> [ 0-0-0 0:0:0,0 ] warn the kafka broker has an authorization service enabled , but the",0.9345893263816833
ballerina-platform_ballerina-lang/25892,"add support for classes in formatter <cm-sep> expand test case scenarios for class related formatting <cm-sep> expand the testing scope of class related formatting <para-sep> converts the syntax tree into source code , remove superfluous spaces and newlines at the ending and returns it as a string . <nl> test the formatting of class definition declarations . <nl> defines the data provider object for test execution . <nl> specify the file names to be skipped during the test execution . <nl> returns the directory path inside resources which holds the test files . <nl> a ; <nl> a",> used the following python script to match and reformat each of the ballerina files used for assertion in formatter related test cases . <nl> 0. add formatting support for having anonymous objects within a class . <nl> 0. add formatting support for following kind of syntax .,1600352230,the struct initializer function name should be equal to the struct name and this function can not accept any input parameters or return types .,0.965038001537323
Alluxio_alluxio/11383,reserve space on directories only when required <para-sep> set reserved bytes on directories if tier aligning is enabled .,"this is to improve the compatibility of multi-tier management for configurations that do n't need the functionality . <nl> for when the reserved space is required by a later configuration change , the task will make sure reserved space will be carved out if necessary .",1588658750,for all the tests that <nl> ( 0 ) use single master local alluxio cluster <nl> ( 0 ) can support both embedded journal and ufs journal . <nl> this pr : <nl> use embedded journal as the default journal type <nl> support easy change embedded journal to ufs journal,0.9378280639648438
apache_pulsar/9905,"try to ease the wait time for some of test case for streamingentryreader to reduce flakiness . <para-sep> read entries in streaming way , that said instead of reading with micro batch and send entries to consumer after all entries in the batch are read from ledger , this method will fire numentriestoread requests to managedledger","the testcanreadentryfrommledgersizeexceededlimit test method fails sporadically - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding the documentation",1615711679,this makes it very difficult and confusing to use standard ports for the service .,0.9116601347923279
neo4j_neo4j/11438,"improve inbound message handling and related cleanup <cm-sep> fail on unsupported types instead of terminating connections <para-sep> returns the packer that 's used to generate response streams <nl> we processed all pending messages , let 's flush underlying channel <nl> implementations install related channel handlers into the given channel pipeline that facilitates the protocol to play . <nl> used for version negotiation * / <nl> represents a component that instantiates bolt protocol handlers . <nl> instantiate a handler for bolt protocol with the specified version . <nl> implements version one of the bolt protocol when transported over a socket . this means this class will handle a simple message framing protocol and forward messages to the messaging protocol implementation , version 0. versions of the framing protocol are lock-step with the messaging protocol versioning . <nl> now we have a complete message in the input buffer <nl> increment ref count of the buffer and create it 's duplicate that shares the content duplicate will be the output of this decoded and input for the next one <nl> signal that whole message was read by making input buffer seem like it was fully read/consumed <nl> pass the full message to the next handler in the pipeline <nl> try to fill out handshake buffer <nl> we filled up the handshake buffer <nl> let 's handshake <nl> announce selected protocol to the client <nl> install related protocol handlers into the pipeline <nl> if we somehow end up with more data in the incoming buffers , let 's send them down to the pipeline for the chosen protocol handlers to handle whatever they are . <nl> log insecure handshake to the bolt message log <nl> translates websocket frames to bytebufs , and bytebufs to frames . intermediary layer between our binary protocol and nettys built-in websocket handlers . <nl> handler is not created <nl> handler with correct version is created <nl> it uses the expected worker <nl> and halts this same worker when closed <nl> when <nl> then <nl> given <nl> when <nl> whole chunk with header and body arrives at once <nl> after buffer is written there should be something to read on the other side <nl> there should only be a single chunk available for reading <nl> it should have no size header and expected body <nl> first part of the chunk contains size header and some bytes <nl> nothing should be","previously , the connection was terminated when an unsupported message / type was encountered during message deserialization . although a couple of improvements were made over time , those were only handling very special cases , namely when or keys were received for map values which was resulting in a message . <nl> while this pr mainly targets improving unsupported value handling , it contains following notable changes ; . <nl> 0. splitting handshake & protocol logic into distinct netty handlers and enabling message deserialization to work on a one-message-containing-buffer without catering for unconsumed buffers on failures ( we can",1522689246,,0.0
ballerina-platform_ballerina-lang/24189,"improve jwt validator config <cm-sep> update docs <cm-sep> update test cases <para-sep> test cases for jwt signature validation with truststore and jwk based authentication/authorization scenarios . the following 0 scenarios are tested here . t ( true ) - parameter/config is available . f ( false ) - parameter/config is not available . | 0 | t | t | t | fail | | 0 | t | t | f | fail | | 0 | t | f | t | pass | | 0 | t | f | f | pass | <nl> jwt used in the test : { ' alg ' : ' rs256 ' , ' typ ' : ' jwt ' , ' kid ' : ' ntaxzmmxndmyzdg3mtu1zgm0mzezodjhzwi4ndnlzdu1ogfknjfimq ' } { ' sub ' : ' admin ' , ' iss ' : ' ballerina ' , ' exp ' : 0 , ' jti ' : ' sha ' , ' aud ' : [ ' vewzbcasjvqm1jvyhuhcjhxz4tya ' ] } <nl> jwt used in the test : { ' alg ' : ' rs256 ' , ' typ ' : ' jwt ' , ' kid ' : ' ntaxzmmxndmyzdg3mtu1zgm0mzezodjhzwi4ndnlzdu1ogfknjfimq ' } { ' sub ' : ' admin ' , ' iss ' : ' ballerina ' , ' exp ' : 0 , ' jti ' : ' sha ' , ' aud ' : [ ' vewzbcasjvqm1jvyhuhcjhxz4tya ' ] } <nl> jwt used in the test : { ' alg ' : ' rs256 ' , ' typ ' : ' jwt ' , ' kid ' : ' ntaxzmmxndmyzdg3mtu1zgm0mzezodjhzwi4ndnlzdu1ogfknjfimq ' } { ' sub ' : ' admin ' , ' iss ' : ' ballerina ' , ' exp ' : 0 , ' jti ' : ' sha ' , ' aud ' : [ ' vewzbcasjvqm1jvyhuhcjhxz4tya ' ] } <nl> jwt used in the test : { ' alg ' : ' rs256 ' , ' typ ' : ' jwt ' , ' kid ' : ' ntaxzmmxndmyzdg3mtu1zgm0mzezodjhzwi4ndnlzdu1ogfknjfimq ' } { ' sub ' : ' admin ' , ' iss ' : ' ballerina ' , ' exp ' : 0 , ' jti ' : ' sha ' , ' aud ' : [ ' vewzbcasjvqm1jvyhuhcjhxz4tya ' ] } <nl> jwt used in the test : { ' alg '","the current record has field which validates the signature either from one of these . but with the new config , user can configure either one of these or both . then the signature can be validated depending on the property of the provided/inbound jwt . with this change , we only need to update the field name from to if using jwk for signature validation . also , this will remove the breaking changes from version.x to latest .",1592293292,"this pr updates that check to only check if it anydata . expression validation happens for values to check if they are valid const expressions . in contrast to normal constants , this is allowed with with records and list types too . <nl> this pr also fixes source only annotations not being desugared .",0.9563683867454529
netty_netty/10776,"allow and skip null handlers when adding a vararg list of handlers . <nl> motivation . <nl> allowing null handlers allows for more convenient idioms in <nl> conditionally adding handlers , e.g. , . <nl> ch.pipeline ( ) .addlast ( <nl> new foohandler ( ) , <nl> condition ? new barhandler ( ) : null , <nl> new bazhandler ( ) <nl> ) ; . <nl> modifications . <nl> * change addfirst ( .. ) and addlast ( .. ) to skip null handlers , rather than <nl> break or short-circuit . <nl> * add new unit tests . <nl> result . <cm-sep> allow and skip null handlers when adding a vararg list of handlers . <nl> motivation . <nl> allowing null handlers allows for more convenient idioms in <nl> conditionally adding handlers , e.g. , . <nl> ch.pipeline ( ) .addlast ( <nl> new foohandler ( ) , <nl> condition ? new barhandler ( ) : null , <nl> new bazhandler ( ) <nl> ) ; . <nl> modifications . <nl> * change addfirst ( .. ) and addlast ( .. ) to skip null handlers , rather than <nl> break or short-circuit . <nl> * add new unit tests . <nl> result .","allowing null handlers allows for more convenient idioms in <nl> conditionally adding handlers , e.g. , . <nl> * change addfirst ( .. ) and addlast ( .. ) to skip null handlers , rather than <nl> break or short-circuit . <nl> * add new unit tests .",1604512863,motivation : <nl> the http2connection state is updated by the defaulthttp2connectiondecoder after the frame listener is notified of the goaway frame . if the listener sends a frame synchronously this means the connection state will not know about the goaway it just received and we may send frames that are not allowed on the connection . this may also mean a stream object is created but it may never get taken out of the stream map unless some other event occurs ( e.g . timeout ) . <nl> modifications : <nl> - the http2connection state should be updated before the,0.8898726105690002
Alluxio_alluxio/11351,always use pread when the hdfs ufs is remote <cm-sep> update default underfs remote option to be true,"in addition , make remote the default configuration for hdfs ufs",1587760857,do not throw exception when loading metadata on a non-existing file/dir .,0.8731838464736938
hazelcast_hazelcast/18048,"add placement_aware group strategy . <para-sep> zone_aware partition groups in this scheme , groups are allocated according to the metadata provided by discovery spi . node_aware partition groups placement_aware partition groups in this scheme , groups are allocated according to the placement metadata provided by discovery spi . depending on the cloud provider , this metadata indicates the placement information ( rack , fault domain , etc . ) of a vm in a zone . this scheme provides a finer granularity than zone_aware for partition groups and is useful to provide good redundancy when running members within a single availability zone . & lt ; partition-group enabled= ' true ' group-type= ' placement_aware ' / & gt ; placement aware . backups will be created in other placement groups . if only one placement group is available , backups will be created in the same group . <nl> placementawaremembergroupfactory is responsible for membergroups creation according to placement group metadata . placement groups are logical or physical groups of vms based on their racks , power sources , network , resources , etc . assigned by cloud providers . it provides good redundancy when running members within a single availability zone . <nl> placement aware backup strategy is based on the placement strategies of the virtual machines on which hazelcast members run . unlike zone aware , this strategy can group members within a single availability zone based on their racks , power sources , network , etc . <nl> metadata key definition for the placement group to which vms belong if a placement strategy is applied by cloud providers .","adds placement aware partition group strategy to form partition groups based on the placement metadata of vms assigned by cloud providers . unlike zone aware ( which is useful for multi-zone setups ) , this strategy provides availability within a single zone as high as possible by spreading partitions and their replicas across different racks .",1610367702,"when metric dictionary word was longer than 0 characters , incorrect <nl> compressed stream was produced . this pr pushes the limit to 0 <nl> characters and fails fast if exceeded . <nl> also removes unnused from .",0.9719534516334534
vespa-engine_vespa/16281,we only new a handfull of threads for the httpserver in the clustercontroller and metricsproxy .,we only new a handfull of threads for the httpserver in the clustercontroller and metricsproxy .,1611857460,"this pr makes it possible to set up containers with ipv4 as before , while setting up containers with ipv6 using docker 's networking .",0.8613762855529785
ballerina-platform_ballerina-lang/26619,introduce compilerbackend concept to decouple backend specific tasks <cm-sep> refactor with the new jballerinabackend api <para-sep> an abstract class that represents a ballerina compiler backend . <nl> this class represent the results of the emit operation . <nl> this class represents the ballerina compiler backend that produces executables that runs on the jvm . <nl> todo handle the emitresult properly <nl> todo improve error handling <nl> todo we need to generate a root package <nl> enum to represent output types . <nl> contains a list of jvm versions that are supported by the jballerina backend . <nl> this class compiles a module up to the codegen phase at the moment . <nl> todo temporary workaround,"with this pr , i am introducing to handle the backend-specific tasks . here is the update api now .",1603783252,"for the time being , we use -- jvmtarget flag to differentiate these two flows ( like when u build some package with -- jvmtarget flag , then it will look bir files for dependent packages as well .",0.9721358418464661
apache_pulsar/9500,"optimize built-in source/sink startup by eliminating redundant nar unpacking and checksum calculation part 0. allow threadruntime to used cached built-in connectors instead of unpacking and loading again . <cm-sep> cleaning up <para-sep> let 's first try to treat it as a nar archive <nl> create the function class loader <nl> extract class loader for function <nl> once the thread quits , clean up the instance","allow the threadruntime to leverage the already loaded and cached built-in connector registry so that it does not need to unpack nars and calculate md5 checksums as well . <nl> - moved the jar loading logic from javainstancerunnable to threadruntime . <nl> - add logic in threadruntime to extract a classloader from a function package , e.g . jar , or if it is a built-in connector just get it from the connectormanager . <nl> - refactored javainstancerunnable to take in classloader for the user function instead of jar paths . <nl> - change the runtimefactory interface to allow connectorsmanager",1612575436,"adds and configuration settings . <nl> removes configuration setting . <nl> the user can how set the address the service will bind on , for example : . the user can also advertise a different address via zookeeper . the latter setting makes it much easier to setup pulsar in environments such as amazon ec2 . <nl> …address .",0.9561721682548523
elastic_elasticsearch/70481,"rest api specs define the api 's used at the rest level , however these specs <nl> only define the endpoint and the parameters . we miss definitions for the <nl> body , especially when it comes to rich bodies like they are used in ml . <nl> this change introduces an abstract testcase for json schema validation . this <nl> allows developers to validate any object that is serializable to json - using <nl> the - to be tested against a json schema . you can use it for rest <nl> input and outputs , but also for internal objects ( documents ) and <nl> . <nl> as the overall goal is to ensure it validates properly , the testcase enforces <nl> strictness . a schema file must spec all properties . this will ensure that once <nl> a schema test has been added , it wo n't go out of sync . every change to the <nl> pojo enforces a schema update as otherwise the test would fail . <nl> schemas can load sub-schemas from extra files . that way you can re-use schemas <nl> e.g . in hierarchies or re-use a schema for similar but not same interfaces . <cm-sep> repair json schema for transform stats <para-sep> json schema validation dependencies <nl> ensure the schema meets certain criteria like not empty , strictness <nl> creates a random instance to use in the schema tests . <nl> return the filename of the schema file used for testing . <nl> root folder for all schema files . <nl> version of the json schema spec to be used by the test . <nl> loader for the schema factory . uses the ootb factory but replaces the loader for sub schema 's stored on the file system . <nl> enforce that the schema as well as all sub schemas define all properties . this uses an implementation detail of the schema validation library : if strict validation is turned on ( ) , the schema validator injects an instance of additionalpropertiesvalidator . the check loops through the validator tree and checks for instances of additionalpropertiesvalidator . if it is absent at expected places the test fails . note : we might not catch all places , but at least it works for nested objects and array items . <nl> if not a leaf , additional property strictness must be set","rest api specs define the api 's used at the rest level , however these specs <nl> only define the endpoint and the parameters . we miss definitions for the <nl> body , especially when it comes to rich bodies like they are used in ml . <nl> this change introduces an abstract testcase for json schema validation . this <nl> allows developers to validate any object that is serializable to json - using <nl> the - to be tested against a json schema . you can use it for rest <nl> input and outputs , but also for internal",1615969673,this commit adds leak tracking infrastructure that enables assertions <nl> about the state of objects at gc time ( simplified version of what netty <nl> uses to track instances ) . <nl> this commit uses the infrastructure to improve the quality of leak <nl> checks for page recycling in the mock nio transport ( the logic in . <nl> does not run for all tests and tracks too little information to allow for debugging <nl> what caused a specific leak in most cases due to the lack of an equivalent of the added <nl> logic ) . <nl> added to,0.9736074209213257
apache_incubator-pinot/5503,"the writer version <nl> was bumped to 0. this was done to support > 2gb indexes . <nl> the change was backward compatible to continue the support <nl> for reading existing/old segments using 0-byte offsets . <nl> while there is no problem with the change , it prevents rollback . <nl> so if there is any orthogonal issue while rolling out a release , <nl> we ca n't rollback to older pinot release since segments already <nl> generated with 0-byte offsets ca n't be read by old code . <nl> this config option is temporary to help with internal roll-out <nl> by keeping the 0-byte format disabled by default thus allowing <nl> rollback due to any issues . in the next couple of weeks after <nl> internal rollout , we plan to remove this option . <para-sep> todo : remove this before release version","the writer version was bumped to 0. this was done to support > 2gb indexes . the change was backward compatible to continue the support for reading existing/old segments using 0-byte offsets . <nl> while there is no problem with pr 0 , it prevents rollback . so if there is any orthogonal issue while rolling out a release , we ca n't rollback to older pinot release since segments already <nl> generated with 0-byte offsets ca n't be read by old code . <nl> this pr introduces a config option to set the writer version ( 0 for using",1591391422,"time series : given a query with dimensions = [ d1 , d2 ] , time series client returns the query results of group by d1 , d2 insteads of those of group by d1 and group by d2 . <nl> anomaly detection : anomaly detection worker and merger now can handle anomaly functions that group by multiple dimensions , i.e. , they automatically explore the combinations of the values of the given dimensions .",0.9701128602027893
apache_shardingsphere/9925,import executeprocessengine for rawexecutor <cm-sep> import executeprocessengine for driverjdbcexecutor,changes proposed in this pull request : <nl> - import executeprocessengine for rawexecutor,1617375895,changes proposed in this pull request : <nl> - add sqlserver with clause for delete statement . <nl> - add sqlserver test case for delete with clause .,0.9068626165390015
ballerina-platform_ballerina-lang/25835,update to support runtime changes for decimal and xml value types <cm-sep> sync with master branch <cm-sep> fix and enable variable evaluation tests <cm-sep> enable expression evaluation tests,- enables debugger integration tests for debug variables and expression evaluation .,1600233478,"this pr fixes that . <nl> previous output : <nl> [ ' abc ' , ' d ' , ' s ' ] . <nl> with this pr , new output : <nl> [ ' abc ' , ' d ' , ( ) , ' s ' ] .",0.9293293952941895
apache_druid/10235,"add ' offset ' parameter to groupby query . <nl> it works by doing the query as normal and then throwing away the first <nl> ' offset ' number of rows on the broker . <para-sep> simultaneously sorts and limits its input . the sort is stable , meaning that equal elements ( as determined by the comparator ) will not be reordered . not thread-safe . note : this class does n't have its own unit tests . <nl> offer an element to the sorter . <nl> drain elements in sorted order ( least first ) . <nl> returns a sorted copy of the provided sequence . this will materialize the entire sequence in memory . use at your own risk . the sort is stable , meaning that equal elements ( as determined by the comparator ) will not be reordered . <nl> a sequence that skips the first few elements . <nl> simultaneously sorts and limits its input . the sort is stable , meaning that equal elements ( as determined by the comparator ) will not be reordered . <nl> materialize the topn values <nl> now return them when asked <nl> nothing to do <nl> create a sequence whose yielders will yield for each element , regardless of what the accumulator passed to ' toyielder ' does . <nl> do nothing . <nl> ca n't use ' testall ' because its ' testyield ' implementation depends on the underlying sequence _not_ yielding . <nl> this class has test cases using a comparator that sometimes returns zero for unequal things . <nl> ' a ' , ' c ' , ' e ' , ... all come before ' b ' , 'd ' , ' f ' , ... <nl> verify that the output of the sequence is stable relative to the input . <nl> sanity check ; must not have ' offset ' at this point . <nl> sanity check ; must not have ' offset ' at this point . <nl> constructor that does not accept ' offset ' . useful for tests that only want to provide ' columns ' and ' limit ' . <nl> offset for this query ; behaves like sql ' offset ' . zero means no offset . negative values are invalid . <nl> offset for this query ; behaves like sql ' limit ' . will always",it works by doing the query as normal and then throwing away the first <nl> ' offset ' number of rows on the broker .,1596503669,"currently , of search query uses a cost-based planner which needs to compute the exact selectivity of the filter specified in the query . according to the result of jmc profiling , i figured out the bottleneck is calling the expensive operation of bitmaps . so , i propose an alternative way to estimate filter selectivity . <nl> in this patch , i simply assumed dimension values are independent to calculate approximate selectivity . as a result , the calculated selectivity may not be exact . <nl> however , i think it 's worthwhile because the planning cost of will",0.9804205298423767
apache_druid/10366,"proposed changes for making joins cacheable <para-sep> currently , datasources that do not actually reference segments ( like 'inline ' ) , are not cacheable since cache keys are always based on segment identifiers . <nl> returns true if this datasource is made out of a join operation <nl> utility class for working with prefixes in join operations <nl> otherwise , throws an exception . <nl> check if any prefixes in the provided list duplicate or shadow each other . <nl> this is a naive approach that assumes we 'll typically handle only a small number of prefixes <nl> compute the cache key for a data source participating in join operation . <nl> if the number of join clauses is > 0 ) . <nl> compute column correlations here and rhs correlated values <nl> compute a cache key prefix for data sources that participate in the rhs of a join . this key prefix can be used in segment level cache or result level cache . the function can return following wrapped in an optional - non-empty byte array - if there is join datasource involved and caching is possible . it may happen if one of the participating datasource in the join is not cacheable . <nl> encountered a data source which did n't support cache yet <nl> computes the given function assuming that only one joinable factory will return a non-empty result . <nl> returns whether this indexed table can be cached for the join operations <nl> the class allows passing in a cache key . if the key is non-null , results of any join on this table can be cached . that cache becomes invalidated if this key changes . creators of this class can pass in a non-null cache key if its possible to construct a small identifier - that must change when contents of this indexed table chances - may remain unchanged when contents of this indexed table how the cache key is constructed itself , depends on how the rowbasedindexedtable is being built . <nl> an inner class that is used solely for computing cache keys . its a separate class to allow extensive unit testing of cache key generation . <nl> querycachekey can be null if segment level cache is not being used . however , etag is still computed since result level cache may still be on . <nl> it is","this pr adds caching capabilities to queries with join . the support is limited for now and only supported if the right-hand data source in the join is . but it can be extended to more data sources in follow-up prs . <nl> the cache key is computed independently of objects . , and use which then loops through all objects and <nl> - builds the cache key for data source participating in clause ( 0 ) <nl> - calls . returns absent if caching is not supported . returns a key computed using the segment of the broadcast table",1599588876,"- added various hook methods to and and call them from . when somebody needs the hooks added to for other query types , corresponding query engine ( s ) could be updated to call the hooks , in another pr . <nl> - added , an abstraction that wraps and provides ability to record the bitmap construction ' form ' ( hierarchical tree of bitmap unions , intersections , and complements ) and report it via a query metric dimension .",0.9750195741653442
apache_incubator-pinot/5645,fix orc record reader to ignore extra fields . <nl> cleaned up the messages and exceptions thrown so that we know which <nl> field is the problematic one .,"cleaned up the messages and exceptions thrown so that we know which <nl> field is the problematic one . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1593624967,"we were swallowing the exception when the schema fetch fails , and were running into another <nl> exception as we process the generic record . <nl> added more information in the logs .",0.8661240935325623
elastic_elasticsearch/72196,"make snapshotsinprogress.entry # indices a map . <nl> we constantly need to look up from index name to , might as well <nl> just have this field as a map to simplify some code here and there and save <nl> a few cycles during cluster state updates for snapshots of large index counts .","we constantly need to look up from index name to , might as well <nl> just have this field as a map to simplify some code here and there and save <nl> a few cycles during cluster state updates for snapshots of large index counts .",1619379429,* return empty map singleton from builder <nl> * remove dead methods <nl> * cleanup duplicate iterator,0.9633732438087463
vespa-engine_vespa/15815,"shut down zookeeper properly <cm-sep> use exponential backoff for zookeeper restart <para-sep> starts/stops a zookeeper server . extends quorumpeermain to be able to call initializeandrun ( ) and wraps exceptions so it can be used by code that does not depend on zookeeper . <nl> if shutdown fails , we have no other option than forcing the jvm to stop and letting it be restarted . when a vespazookeeperserver component receives a new config , the container will try to start a new server with the new config , this will fail until the old server is deconstructed . if the old server fails to deconstruct/shut down , the new one will never start and if that happens forcing a restart is the better option . <nl> starts/stops a zookeeper server . extends quorumpeermain to be able to call initializeandrun ( ) and wraps exceptions so it can be used by code that does not depend on zookeeper . <nl> if shutdown fails , we have no other option than forcing the jvm to stop and letting it be restarted . when a vespazookeeperserver component receives a new config , the container will try to start a new server with the new config , this will fail until the old server is deconstructed . if the old server fails to deconstruct/shut down , the new one will never start and if that happens forcing a restart is the better option . <nl> interface for a component that starts/stops a zookeeper server . <nl> do nothing",... and kill it with fire if it does n't .,1608027896,account for resource tax when autoscaling . <nl> i went a bit back and forth so probably best top read the end result .,0.9690802097320557
Alluxio_alluxio/11218,create new client pool map during context reinit,"when a filesystemcontext is re-initialized , any acquired clients are expected to be released back into the same pool . <nl> before this change , it 's possible for the following scenario to occur : <nl> - a thread would acquire a block worker client from the pool map with key . <nl> - the context is re-initialized . all pools in the map are closed , the pool map is cleared <nl> - another thread acquires a block worker client with key as well . this creates a new pool map entry with the same key . <nl> -",1585537339,make jetty to extract web resources to a non system temp folder .,0.9110647439956665
apache_incubator-pinot/5828,"improving retention manager to handle segment lineage clean-up . <nl> 0. added the logic to handle segment lineage clean-up in the <nl> retention manager . <nl> 0. added the unit test <para-sep> delete segments based on segment lineage and clean up segment lineage metadata <nl> fetch segment lineage <nl> 0. the original segments can be deleted once the merged segments are successfully uploaded 0. the zombie lineage entry & merged segments should be deleted if the segment replacement failed in the middle <nl> if the lineage state is 'completed ' and segmentfrom are removed , it is safe clean up the lineage entry <nl> if the lineage state is 'completed ' , it is safe to delete all segments from 'segmentsfrom ' <nl> if the lineage state is 'in_progress ' , we need to clean up the zombie lineage entry and its segments <nl> if the lineage state is 'in_progress ' and source segments are already removed , it is safe to clean up the lineage entry . deleting lineage will allow the task scheduler to re-schedule the source segments to be merged again . <nl> if the lineage state is 'in_progress ' , it is safe to delete all segments from 'segmentsto ' <nl> write back to the lineage entry <nl> delete segments based on the segment lineage <nl> create server tenant <nl> create broker tenant <nl> enable lead controller resource <nl> create the retention manager <nl> update table config <nl> create metadata for original segments <nl> create metadata for merged segments . <nl> validate the case when the lineage entry state is 'in_progress ' <nl> validate the case when the lineage entry state is 'completed ' <nl> validate the case when the lineage entry state is 'completed ' and all segments are deleted <nl> validate the case when the lineage entry state is 'in_progress ' and timestamp is old",0. added the logic to handle segment lineage clean-up in the <nl> retention manager . <nl> 0. added the unit test,1596797475,adding type offline to handle delete from offline tables which also have a realtime component,0.9649336338043213
apache_pulsar/9769,"print jvm info while running pulsar-perf commands <para-sep> utility for test clients <nl> print useful jvm information , you need this information in order to be able to compare the results of executions in different environments .",log jvm configuration at boot : <nl> - netty max memory <nl> - jvm command line arguments <nl> - actual max heap size . <nl> this change is a trivial rework / code cleanup without any test coverage .,1614614521,it can be helpful when client requested lookup request to bad broker which failed to send back the response . <nl> added binary lookup timeout .,0.9104390144348145
vespa-engine_vespa/16643,ignore test for jdks where tlsv1.0 is disabled <para-sep> only ignore a subset of exceptions,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1614086313,reuse threadpool between metric requests . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.7905393242835999
Alluxio_alluxio/10999,"add metrics doc generator and update metric docs <para-sep> client : any process with the alluxio client library . <nl> meter : measures the rate of events over time ( e.g. , ' requests per minute ' ) <nl> table of contents <nl> cluster metrics are collected and calculated by the leading master and displayed in the metrics tab of the web ui . <nl> process metrics are collected by each alluxio process and exposed in a machine-readable format through any configured sinks . <nl> utility for generating docs . <nl> main entry for this util class . <nl> prints the help message . <nl> csv_file_dir utility to generate property keys to csv files . <nl> writes property key to csv files . <nl> hashmap for filewriter per each category <nl> write the csv file header and line separator after the header <nl> put filewriter <nl> register file writer <nl> sort defaultkeys <nl> quote the whole description to escape characters such as commas . <nl> write property key and default value to csv <nl> writes description of property key to yml files . <nl> hashmap for filewriter per each category <nl> put filewriter <nl> register file writer <nl> sort defaultkeys <nl> puts descriptions in single quotes to avoid having to escaping reserved characters . still needs to escape single quotes with double single quotes . <nl> write property key and default value to yml files <nl> generates the configuration docs . <nl> generate csv files <nl> generate yml files <nl> generates metric key information in docs . <nl> writes the supported files for metrics system docs . <nl> gets and sorts the metric keys <nl> map from metric key prefix to metric category <nl> register file writer <nl> the key for a file writer .","this pr adds an automatic metrics doc generator to get the metric key name , type , description from and put in the metric files for showing on the docs .",1582572114,"as for yml file and description update , it will be another pr coming soon .",0.9851688742637634
hazelcast_hazelcast/18091,"initial fetch/offset implementation . <nl> a naive implementation of the fetch/offset sql clauses without <nl> pushing the operator on the individual member . <nl> both fetch-only and offset-only clauses are supported . <nl> unit testing of the operators as well as integration testing . <para-sep> whether the input is actually requires sorting <nl> do n't push down the fetch/offset operators if merging phase is needed <nl> empty collation means the fetch-only operation <nl> fetch/offset only scenario <nl> the top level select is used to filter out nested selects with fetch/offset <nl> check for nested fetch offset <nl> derive the types for offset-fetch expressions , calcite does n't do that automatically . <nl> populate stable map data <nl> limit/offset core support . <nl> skip the whole batch <nl> mark offset as finished and adjust the start index accordingly . <nl> tooffset is smaller than the batch size and casting to int is safe <nl> calculate the end position . <nl> return the whole remainder . <nl> an executor that applies offset and limit clauses to the rows .. <nl> special implementation of row which is used for limit/offset expressions . these expressions can not refer to real columns , which is checked during query planning phase . <nl> no-op . <nl> optional limit on the number of returned results . <nl> optional offset value for the results . <nl> fetch expression . <nl> offset expression <nl> number of returned rows . <nl> the offset value applied to the result rows . <nl> no-op . <nl> physical fetch plan node . <nl> limit expression . * / <nl> offset expression . * / <nl> no-op . <nl> limit expression . <nl> offset expression . <nl> test empty state . <nl> consume several batches , still insufficient to produce a result . <nl> one more batch , finally producing some rows . <nl> one more batch <nl> final batch to finalize the result <nl> consume several batches , still insufficient to produce a result . <nl> consume more batches <nl> consume more batches <nl> no-op .",a naive implementation of the fetch/offset sql clauses without <nl> pushing the operator on the individual member . <nl> both fetch-only and offset-only clauses are supported . <nl> unit testing of the operators as well as integration testing .,1611584608,"this pr improves consistency checks for indexes when used from the sql service : <nl> 0. now indexes track precisely which partitions are indexed . in addition to this , we track when a partition is being indexed ( dynamic index creation , migration to the local member ) or unindexed ( migration from the local member ) <nl> 0. when the sql query is in progress , we request a stamp for the partitions that are expected to be available locally . then we validate that the stamp is still valid before returning the results . the stamp could",0.9703177213668823
hazelcast_hazelcast/18317,"fix gc metrics not getting updates issue . <nl> although gc metrics are ' mandatory ' metrics , the periodic publisher <nl> of these metrics was registered at the info level . since the default <nl> ' hazelcast.diagnostics.metric.level ' is ' mandatory ' in this imdg <nl> version , gc metrics did not get updates by default . the reason why this <nl> issue is not seen in future versions is that the default value of <nl> ' hazelcast.diagnostics.metric.level property is changed to ' info ' .","although gc metrics are metrics , the periodic publisher <nl> of these metrics was registered at the level . since the default <nl> is in this imdg <nl> version , gc metrics did not get updates by default . in this pr , i changed <nl> that metric publisher registration to level . <nl> the reason why this issue is not seen in future versions is that the default <nl> value of property is changed to .",1614611581,there is a very severe performance issue with jdk 0 in combination with <nl> the paging predicate . this is caused by sublist.sort . this issue is resolved <nl> with jdk9 but we need to fix the issue for a large number of people using <nl> jdk 0 . <nl> the problem is fixed by switching from linkedlist to arraylist in the <nl> queryresult . benchmarks are included in the ticket .,0.8087298274040222
apache_beam/13210,update hot key detection log message . <nl> this makes the hotkeyloggingenabled pipeline option more discoverable .,this makes the hotkeyloggingenabled pipeline option more discoverable,1603841339,"the error messages emit from bigquery io : <nl> 0. for java sdk , updated error message when templocation is not set . <nl> 0. for python sdk , updated error message when neither gcs_location nor <nl> temp_location is set",0.8504115343093872
elastic_elasticsearch/70824,"update mapping version check assertion to allow for changes to mapping representation across versions <para-sep> mapping representations may change between versions ( eg text field mappers used to always explicitly serialize analyzers ) , so we can not simply check that the incoming mappings are the same as the current ones : we need to parse the incoming mappings into a documentmapper and check that its serialization is the same as the existing mapper <nl> text fields are not stored by default , so an incoming update that is identical but just has should not require an update <nl> however , an update that really does need a rebuild will throw an exception","when a mapping update is received on a node , we currently check to see if it has the <nl> same version as the node 's current mappings , allowing us to skip applying the update <nl> if the versions are equal . we also do a more expensive check , hidden behind an <nl> assertion , that the incoming mapping has the same json representation as the current <nl> mapper . this check unfortunately means that it is not possible to ever change the <nl> serialized form of a field mapper , because the index metadata of an index",1616602387,this pr ensures that api key role descriptors are always rewritten to a target node <nl> compatible format before a request is sent .,0.9277178049087524
apache_incubator-pinot/5868,implemented te bigquery datasource logic <cm-sep> added te bigquery resources config and doc <para-sep> * * * <nl> * * * <nl> 0 : prerequisites * <nl> 0 : update the data sources configuration * <nl> 0 : run thirdeye frontend * <nl> 0 : import metric from bigquery * <nl> 0 : start an analysis * <nl> ) <nl> init bigquery datasources <nl> timeout before an abandoned ( in use ) connection can be removed . <nl> convert java simpledateformat to bigquery standardsql 's format,"design points : <nl> - the jdbc driver for bigquery has to be downloaded and put into the maven project . also , the driver requires specific version for some dependencies . <nl> a normal build is unchanged : and a build with bigquery is . <nl> also , i 've added the same principle for : <nl> has the same behavior as before , downloads and install the driver , and compile with the bigquery profile . <nl> the install.sh loop can look a bit complex/over-engineered , but i am anticipating the fact that we will have other databases",1597449129,"this pr allows rule-based anomaly detection and algorithm-based detection to run for the same anomaly function at the same time and merge the results . also , enable the potential to add multiple secondary detection functions .",0.9476203918457031
vespa-engine_vespa/16022,revert ' revert ' allow expressions as arguments ' ' . <nl> this reverts commit sha . <cm-sep> allow expressions as arguments to functions <para-sep> tests correct deriving of expressions as arguments to functions .,"so , with more comprehensive testing . the rank deriving test in is a guard as it tests what was previously parseable ( the old function in ) does not change with this pr , e.g . constants ( including negative ones ) , rank features and identifiers . <nl> the test in tests that autogenerated features are generated for the rest , e.g . arithmetic , if 's , tensor functions and slices ( with required wrapper ) . <nl> system test is incoming .",1610467100,"this fixes . <nl> most of this code is to generate a helpful error message by printing ( the start of ) of the offending document . <nl> also removed a case where could be : i 'm not quite sure how this is possible , as long as we find a document id , should be ?",0.943145215511322
apache_pulsar/10002,"allow to use keyvalue . <nl> fix a problem in httplookupservice # getschema <cm-sep> support multiple data types <cm-sep> implementation <cm-sep> more work <cm-sep> remove code duplication <cm-sep> simplify code <cm-sep> clean up <cm-sep> more clean up <cm-sep> fix spotbugs <cm-sep> remove change in pulsarsink <cm-sep> tostring <cm-sep> clean up <cm-sep> add zero copy getbytes implementation <para-sep> this is a bytebuffer schema that reports schemainfo from another schema instance . <nl> do not copy data if the bytebuffer is a simple wrapper over an array <nl> kafka source that transfers the data from kafka to pulsar and sets the schema type properly . we use the key and the value deserializer in order to decide the type of schema to be set on the topic on pulsar . in case of kafkaavrodeserializer we use the schema registry to download the schema and apply it to the topic . if you set stringdeserializer for the key then we use the raw key as key for the pulsar message . if you set another deserializer for the key we use the keyvalue schema type in pulsar with the separated encoding . this way the key is stored in the pulsar key , encoded as base64 string and with a schema , the value of the message is stored in the pulsar value with a schema . this way there is a one-to-one mapping between kafka key/value pair and the pulsar data model . <nl> if the key is a string we can use native pulsar key otherwise we use keyvalue schema that allows you to set a schema for the key and a schema for the value . using separated encoding the key is saved into the binary key so it is used for routing and for compaction <nl> we have substituted the original deserializer with bytebufferdeserializer in order to save memory copies so here we can have only a bytebuffer or at most a byteswithkafkaschema in case of extractkafkaavroschemadeserializer <nl> this is a struct with schema downloaded by the schema registry the schema may be different from record to record <nl> we want to simply transfer the bytes , by default we override the kafka consumer configuration to pass the original bytebuffer <nl> for the key we use the string value and we want stringdeserializer <nl> in this case we have to inject our custom deserializer that extracts avro schema information","with this change the kafka connector supports non-string keys and it also apply the correct schema to the pulsar topic . <nl> for primitive datatypes we are not decoding the kafka key pair into java objects , we are simply passing a reference to the internal bytebuffer ( that is a wrapper for a byte [ ] ) . <nl> the schema type is decided using the and parameters that you pass to the kafka source configuration . <nl> this is the mapping ; <nl> * bytearraydeserializer , bytebufferdeserializer , bytesdeserializer : schema.bytebuffer <nl> * stringdeserializer.class : schema.string <nl> *",1616408642,motivation . <nl> - the code for encoding and decoding key/value schema is spreading over multiple places . <nl> - make code changes to prepare supporting key/value schema in auto consumers <nl> - make schema tools display key/value schema in a pretty format . <nl> modifications . <nl> - move the common logic of encoding and decoding key/value schema to a common class keyvalueschemainfo <nl> - expose the common class in defaultimplementation so that it can be available for public usage <nl> - fix the display problem on displaying key/value schema . <nl> verify this change . <nl> - add,0.9771752953529358
elastic_elasticsearch/72083,refactor repository # snapshotshard . <nl> create a class for holding the large number of arguments to this method <nl> and to dry up resource handling across snapshot shard service and the <nl> source-only repository .,"create a class for holding the large number of arguments to this method <nl> and to dry up resource handling across snapshot shard service and the <nl> source-only repository . <nl> also , we do wrap and delegate this method call a number of times , which is a lot cleaner this way instead of by passing all the parameters over and over i think .",1619093505,adds a ' node ' field to the response from the following endpoints : . <nl> 0. open anomaly detection job <nl> 0. start datafeed <nl> 0. start data frame analytics job . <nl> if the job or datafeed is assigned to a node immediately then <nl> this field will return the id of that node . <nl> in the case where a job or datafeed is opened or started lazily <nl> the node field will contain an empty string . clients that want <nl> to test whether a job or datafeed was opened or started lazily <nl> can therefore,0.9599705934524536
ballerina-platform_ballerina-lang/25561,update bir spec with types related infomation <cm-sep> fix a bug with null type tag value <cm-sep> fix compilation issues in typed-binding-pattern test file <cm-sep> add chunk length for type values to skip reading <cm-sep> read and skip bytes that are now being written <cm-sep> add validation test using lang-lib test sources <cm-sep> improve test coverage with basic-blocks and instructions <cm-sep> add values test source <para-sep> assert constants <nl> assert type definitions <nl> assert annotations <nl> assert functions <nl> assert required param count <nl> assert arguments count <nl> assert basic blocks <nl> assert true bb name <nl> assert false bb name <nl> assert pkg name <nl> assert call name <nl> assert then bb id <nl> assert goto bb id <nl> assert var name <nl> string afloatnumber = ' version ' ; <nl> result [ ' afloatnumber ' ] = afloatnumber.fromjsonstring ( ) ; <nl> ///////////////////////// tests for /////////////////////////// <nl> ///////////////////////// tests for /////////////////////////// <nl> ///////////////////////// tests for /////////////////////////// <nl> ///////////////////////// tests for ///////////////////////////,also this has test cases added to cover basic-blocks and instructions .,1599038245,when a new code action is added now we need to extend the implementation from the lscommandexecutor interface,0.9548935294151306
apache_kafka/9925,"tag as and tweak it . <nl> the test takes over 0 minute to run , so it should not be considered a <nl> unit test . <nl> also : <nl> * replace prefix with prefix for helper methods . <nl> * replace functional interface with built-in .","the test takes over 0 minute to run , so it should not be considered a <nl> unit test . <nl> also : <nl> * replace prefix with prefix for helper methods . <nl> * replace functional interface with built-in . <nl> * remove unnecessary . <nl> * remove from since it 's not used <nl> in that way .",1610987541,the tag key for store level metrics specified in streamsmetricsimpl <nl> is unified with the tag keys on thread and task level .,0.8166049718856812
elastic_elasticsearch/70855,cleanup date_nanos rolling upgrade test . <nl> this change rewrites the rolling upgrade yml test that was added for <nl> date_nanos in java . this is needed to allow extra logic when backporting to <nl> 0.x . date_nanos are not available in 0.x so we need to skip the upgraded test <nl> based on the version of the old cluster .,this change rewrites the rolling upgrade yml test that was added for <nl> date_nanos in java . this is needed to allow extra logic when backporting to <nl> 0.x . date_nanos are not available in 0.x so we need to skip the upgraded test <nl> based on the version of the old cluster .,1616664396,"each precommit task is currently registered inside the shared <nl> precommittasks class . having a single class with all precommit tasks <nl> makes individualizing which precommit tasks are needed based on type of <nl> project difficult , where we often just disable somet tasks eg for all qa <nl> projects . this commit creates plugins for each precommit task , and moves <nl> the configuration of the task into each plugin . precommittasks remains <nl> for now , and just delegates to each plugin , but will be removed in a <nl> future change .",0.9471135139465332
ballerina-platform_ballerina-lang/24256,change to use the util functions in stdlib <para-sep> java : jobject ;,these functions were later added to and modules in the standard library in order to make it more centralized and available for other use cases . <nl> this pr migrates the tool to use these util functions from the standard library instead of generating them within the module . it also refactors some code and fixes minor issues .,1592388406,this also enables type test ( is ) related test cases .,0.9113603234291077
OpenAPITools_openapi-generator/8145,"migration from php-ze-ph to php-mezzio-ph <cm-sep> sample regen after rebase <para-sep> ( generators/php-mezzio-ph.md ) ( php-mezzio-ph.md ) <nl> todo : rename to x- prefixed vendor extensions , per specification . <nl> add operation to group override of default grouping - group by resource path , not tag <nl> ignore duplicate operation ids - that means that operation has several tags <nl> return the file name of the api test <nl> output the api ( class ) name ( capitalized ) ending with ' api ' return defaultapi if name is empty <nl> remove } <nl> generate additional model definitions from query parameters <nl> add internal extension directly , because addextension filters extension names <nl> array <nl> add internal extension directly , because addextension filters extension names <nl> add internal extension directly , because addextension filters extension names <nl> producing content with media type ' / ' is not supported <nl> all operations have same path because of custom operation grouping , so path pattern can be calculated only once <nl> todo add regular expressions for other types if they are actually used for path parameters",as we discussed in june code generated with requires a huge dependency update because all zend packages were moved to new organization - laminas . this pr solves this issue : <nl> * templates were updated to use ' fresh ' packages ( composer.json and namespaces in php code ) <nl> * generator renamed to ( mezzio is a new name for zend expressive ) <nl> * common code moved to separate library and covered with tests : ) .,1607539580,test results from : <nl> .,0.8549205660820007
ballerina-platform_ballerina-lang/25782,"parser changes for func type and anon func . <nl> parsing logic isolate support for function type desc and anonymous function expression . <cm-sep> error handler changes . <cm-sep> fix checkstyle issue . <cm-sep> fix wrong use of context in error handler . <cm-sep> update assert files . <cm-sep> add test cases <nl> add test cases for isolated function type and isolated anon func expr . <cm-sep> remove isolated implicit anon functions . <cm-sep> update assert files . <cm-sep> refactor code . <cm-sep> use parsefunctionqualifiers method to parse func type desc and anon funcs . <cm-sep> remove unwanted if condition . <cm-sep> add isolated recovery support for top level functions and func type desc . <cm-sep> introduce analysis for isolated anon functions and function typedescs <cm-sep> fix isolation flag issues for function typedescs and arrow functions <cm-sep> mark relevant langlib functions as isolated <para-sep> only analyze the type node if it is not available at module level , since module level type definitions have already been analyzed . <nl> todo : 0/0/0 this feels hack-y but can not think of a different approach without a class variable maintaining isolated-ness . <nl> qualifiers are only allowed in the following cases for func type desc . isolated qualifier allowed . public or private qualifier allowed in object field . <nl> check if it is a complex type desc starting with function type . <nl> function-type-descriptor : = function function-signature <nl> explicit-anonymous-function-expr : = function function-signature anon-func-body <nl> context ended inside parseanonfuncbody method <nl> invalid arrow functions as isolated functions .",this pr also marks relevant langlib functions as isolated .,1600113407,"with this commit , you can use the ballerina import keyword to import your dependent packages .",0.9626856446266174
hazelcast_hazelcast/18312,convert given key to appropriate nearcachekey for client-txn-map interactions <para-sep> populate server-side-map <nl> populate server-side-map 's near-cache <nl> update map in a client txn,"…ractions . <nl> fixes when there is near-cache configured for both server and client sides for the same map and is ( default value ) . in this situation , txn done with client-side proxy does n't proceed .",1614596967,the loop was exiting too early if connection was closed for one of pending invocations,0.9803575277328491
jenkinsci_jenkins/4681,"move getchanneltomaster to a separate class . <nl> this should avoid classloading issues i 've seen , such as . <nl> caused by : java.lang.noclassdeffounderror : <nl> javax/servlet/servletexception <nl> at hudson.util.processtree.get ( processtree.java:0 ) <nl> ...","this should avoid classloading issues i 've seen , such as . <nl> * fix a classloading issue while executing",1587553199,"corrected a misspelled class name ; and introduced a new overload of that does not make you remember to use a -block . considered having it take but this throws which is inconvenient ; lets that be parameterized but i settled on simple by comparing the following jdk 0 λ snippets : . <nl> vs. the more readable and natural . <nl> ( i remember seeing some proposal for that would be better than for this case , but can not find it now . can not find anything more suitable in either , and anyway we could not yet",0.939453125
elastic_elasticsearch/70982,"this commit adds a new parameter for listing tasks in the transport layer . <nl> this allows tasks to be filtered by and so that matching specific tasks <nl> within a particular action is possible . <para-sep> the list tasks action itself is filtered out via this description filter <nl> the list tasks action itself is kept via this description filter which matches everything <nl> description patters on which to match . if other matching criteria are set , descriptions are matched last once other criteria are satisfied matching on descriptions is only available if is . <nl> should the task match specific descriptions .",this commit adds a new parameter for listing tasks in the transport layer . <nl> this allows tasks to be filtered by and so that matching specific tasks <nl> within a particular action is possible .,1617020870,"adds and support to fields , <nl> specifically those with the of . others <nl> s will return an error if provided with those parameters .",0.9565452337265015
OpenAPITools_openapi-generator/8215,include model and api dir init mustaches <cm-sep> update examples,"these files exist in the petstore example because they are not entirely refreshed . these samples are overwritten . in fresh generation of the petstore code , is missing from directory and needed a rewrite because it is using python legacy 's mustache file .",1608138403,"it does the same stuff as in the .travis.yml but just for gitlab ci : run nosetests . <nl> i see a but does n't use it , so i do n't know whether nosetests is the way to go here .",0.9318970441818237
ballerina-platform_ballerina-lang/26153,fix continuing loop even after fail <cm-sep> continue failed retry till max retry count reached <para-sep> var $ retryfunc $ = function ( ) returns any|error { } ; <nl> add lambda function call any|error $ result $ = $ retryfunc $ ( ) ; <nl> create while loop : while ( $ result $ is error & & $ retrymanager $ .shouldretry ( $ result $ ) ) <nl> returns $ result $ ; <nl> at this point ; retrymanager $ retrymanager $ = new ( ) ; var $ retryfunc $ = function ( ) returns any|error { } ; any|error $ result $ = $ retryfunc $ ( ) ; while ( $ result $ is error & & $ retrymanager $ .shouldretry ( $ result $ ) ) { $ result $ = $ retryfunc $ ( ) ; } if ( $ result $ is error ) { fail $ result $ ; } returns $ result $ ; <nl> fail e ;,"> fix exiting retrying with on fail , when fail statement is executed .",1601378335,"by default , it will be executed in the same parent os thread . more details are explained in doc [ 0 ] .",0.9594558477401733
grpc_grpc-java/7709,"add tls context to cluster_impl lb policy config . <cm-sep> adds ci coverage for building example/android/strictmode and examples/example-jwt-auth . also cleans up existing gradle and maven build command in the cis . <cm-sep> decorating lb helper with logic of attaching ssl context provider supplier to eags when creating subchannels in cluster_resolver lb policy . <cm-sep> pass tls context through eds lb policy . <cm-sep> delete logic for wrapping lb helper with logic of attaching tls context to eags when creating subchannels in cds lb policy . <para-sep> tlscontext = * / newupdate.getupstreamtlscontext ( ) , <nl> tls context for connections to endpoints . <nl> exclude tlscontext as its string representation is cumbersome . <nl> exclude tlscontext as its string representation is cumbersome . exclude upstreamtlscontext as its string representation is cumbersome . <nl> one locality with two endpoints . <nl> simulates leaf load balancer creating subchannels . <nl> removes upstreamtlscontext from the config . <nl> config with a new upstreamtlscontext . <nl> no-op","we will be supporting aggregate clusters in cds lb policy ( see design at go/grpc-xds-directpath-c2p-fallback ) . this pr moves the xds security implementation that attaches an sslcontextprovidersupplier as eag attributes from cds lb policy to cluster_impl lb policy . <nl> it is similar to how dropoverload and circuit breakers work . <nl> the upstreamtlscontext configuration is obtained from cdsupdate , then it is passed through the child eds lb policy 's config and then the priority lb policy . <nl> each cluster 's upstreamtlscontext will be part of its and then passed to cluster_impl lb policy 's config .",1607390339,"this is the second part of implementation for grpclb selection . <nl> main changes in this pr : . <nl> - slightly changed and its jndi implementation . returns a list of so that it only parse srv records and does nothing more . it 's grpc 's name resolver 's logic to use information parsed from srv records . <nl> - created a class that extends . logic of using information from srv records to set balancer addresses as resolutionresult attributes is implemented in only . <nl> - refactored , mainly the method . logics for resolving backend addresses",0.9702809453010559
apache_beam/12706,add support for bundle finalization to dofnoperator for non-portable streaming pipelines . <nl> i used the unboundedsourcefunction as a guide to implementing the bundle finalization hook for the dofnoperator . <nl> since checkpointing support is only supported when using shutdownsourcesafteridlems so i added a new validates runner task that runs a subset of the tests that rely on bundle finalization . <nl> i also added support for impulse translation for non-portable streaming pipelines . <para-sep> teststreamsource does not support checkpointing <nl> stores new finalizations being gathered . * / <nl> pending bundle finalizations which have not been acknowledged yet . * / <nl> confirm all finalizations that were associated with the checkpoint,i used the unboundedsourcefunction as a guide to implementing the bundle finalization hook for the dofnoperator . <nl> since checkpointing support is only supported when using shutdownsourcesafteridlems so i added a new validates runner task that runs a subset of the tests that rely on bundle finalization . <nl> i also added support for impulse translation for non-portable streaming pipelines . <nl> this is the base for swapping over non-portable flink to use sdf instead of unboundedsources,1598564435,when writetables is used to create temporary tables different logic is required for altering the write and create dispositions .,0.9570476412773132
apache_camel/5278,"added new jdbc based idempotentrepository which addresses the problem of orhpan lock that can be left behind by jvm crashes <para-sep> lock entry does not exist then the lock is provided using the base implementation of . <nl> lock already exists and the createdat < system.currenttimemillis ( ) - lockmaxagemillis . in this case it is assumed that an active instance has the lock and the lock is not provided to the new instance requesting the lock <nl> lock already exists and the createdat > = system.currenttimemillis ( ) - lockmaxagemillis . in this case it is assumed that there is no active instance which has the lock and the lock is provided to the requesting instance . the reason behind is that if the original instance which had the lock , if it was still running , it would have updated the timestamp on createdat using its keepalive mechanism <nl> when an instance of the application acquires a lock on the idempotent repository , the lock attributes are added to a hashset . while the lock is help by the instance , the instance keeps updating the createdat column with the current timestamp indicating the instance holding the lock is active . a lock is granted to an instance if either the entry for the lock attributes do not exists in the camel_messageprocessed table or if in case the instance holding the lock has crashed . this is determined if the timestamp on the createdat column is more than the lockmaxage . * <nl> max age of read lock in milliseconds * * / <nl> intervals after which keep alive is sent for the locks held by an instance * * / <nl> if the update timestamp time is more than lockmaxage then assume that the lock is orphan and the process which had acquired the lock has died <nl> update in case of orphan lock where a process dies without releasing exist lock <nl> schedule a task which will keep updating the timestamp on the acquired locks at lockkeepaliveinterval so that the timestamp does not reaches lockmaxage",added a new jbbc based implementation of idempotentrepository which handles orphan locks which can be left due to jvm crash or rolling restarts,1617069341,"it adds the behaviour , that camel logcomponent looks for the instance in current repository or uses user-provided logger in uri parameter ' logger ' .",0.9620282053947449
Alluxio_alluxio/11598,"fix bug in meta cache in metadatacachingbasefilesystem <para-sep> puts the status into cache . <nl> puts the directory status into cache . <nl> puts dir and its children into cache . all of them ( dir1 , dir1_file , dir1_dir2 ) should be in cache . <nl> adds dir1_dir2_file into cache . <nl> checks parent directory","description : <nl> meta data may be deleted in client cache although it is very hot . <nl> now metadatacache holds mstatus which stores the current file/dir status and mdirstatuses which stores the children status . <nl> 0. for example , there is a path '/a/b/c ' . <nl> 0. we run the liststatus request on the directory '/a/b ' . after receiving result from alluxio master , it caches ' a/b ' into the cache map which stores the children status for the path '/a/b ' as mdirstatuses and its children '/a/b/c ' into the cach map which stores",1592535409,"the previous user group mapping does not work , so i also think it 's a bug . in addition , the user group translation is mistakenly included in the version doc ( and a user asked about it in mailing list before ) so we should cherry pick it to version .",0.9336548447608948
Graylog2_graylog2-server/9165,expose to frontend . <nl> still needs cleaning up and will probably fail if the cloud plugin is <nl> not loaded . <cm-sep> do n't use environment variable to transport value for iscloud <para-sep> the is_cloud variable will be set by webpack via the defineplugin . eslint-disable-next-line no-undef <nl> otherwise just use the directory name of the webpack config file,"exposes an flag via . <nl> when running in production mode , the flag is mirroring the server configuration parameter which is by default and has to be enabled explicitly . <nl> when running in development mode ( ) , the flag is by default but will be automatically set to when the cloud plugin is present . <nl> when running in a cloud context , certain ui elements need to be different than for an on-premise deployment . with this flag exposed , the ui has an easy way to know about the context . <nl> to see if",1602753603,- return ' terms_mapping ' in quickvalueswidgetstrategy . this ensures that we also use a more visible separator when using stacked fields . <nl> - use a darker color for the quickvalues field separator . the previous one was too bright . <nl> note : this needs to be cherry-picked into version as well,0.8491696119308472
ballerina-platform_ballerina-lang/24909,fix : ballerina-lang : string : createbalo task issue <cm-sep> fix : ballerina-lang : table : createbalo task issue <cm-sep> fix : ballerina-lang : stream : createbalo task issue <cm-sep> fix : ballerina-lang : object : createbalo task issue <cm-sep> fix : ballerina-lang : xml : createbalo task issue <cm-sep> fix : ballerina-lang : query : createbalo task issue,> this fix is only tested within the compile time . it needs to be tested and verified in the runtime as well . <nl> > tested with command on ubuntu version ( replace string with each of the other langlib tasks that are fixed here when testing ) .,1595486680,this also enables type test ( is ) related test cases .,0.9239662289619446
ballerina-platform_ballerina-lang/25108,"change order by clause behavior <cm-sep> add more tests for order by clause <cm-sep> add isnan function <cm-sep> fix lang-server tests <cm-sep> add newline <para-sep> type [ ] arr passed to stream ordering helper . <nl> should limit after ordering the stream <nl> if no limit given order the entire stream <nl> limit the frames if order by clause is not given <nl> desugar orderbyclause to below and return a reference to created orderby _streamfunction . _streamfunction orderbyfunc = createorderbyfunction ( function ( _frame frame ) { _frame frame = { ' orderkey ' : frame [ ' x2 ' ] + frame [ ' y2 ' ] , $ orderdirection $ : true + false ' } ; } ) ; <nl> each order-key expression is added to sortfieldsarrayexpr . corresponding order-direction is added to sortmodesarrayexpr . <nl> order-key expressions and order-directions are evaluated for each frame . $ frame $ [ ' $ orderkey $ ' ] = sortfieldsarrexpr ; <nl> $ frame $ [ ' $ orderdirection $ ' ] = sortmodesarrayexpr ; <nl> check whether a order-key expression type is a basic type . <nl> add the sorted stream values to arr <nl> check whether a float is nan <nl> add orderkey and orderdirection values to respective arrays . <nl> need to keep the stream value to sort the stream . <nl> _streamfunction ; <nl> ( ) should always come last irrespective of the order direction . <nl> need to check the direction because nan should always come last . <nl> need to check the direction because nan should always come last . <nl> implementation of lang.query : checknan ( float ) .",if the is a complex type a compilation error is given .,1596464451,this also fixes xml.length ( ) function returning incorrect number of codepoints when applied to char sequence .,0.9786392450332642
ballerina-platform_ballerina-lang/23555,mark leading comma nodes as optional <cm-sep> generate classs with leading comma nodes,this is a temporary change .,1590608736,"use observability.metrics.hostname configuration to bind http endpoint to a specific hostname . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.909218430519104
elastic_elasticsearch/71433,templates match indices with date math expressions,"before version , an ingest pipeline with a date_index_name processor would ( accidentally ) work around that problem , but the simple statement below would fail to execute the final pipeline in any es version ( assuming a template that defines a final pipeline for an index pattern of ) : . <nl> a change to the way ingest pipelines work in version caused the date_index_name scenario to fail as well . this change resolves both problems .",1617817303,setting to a value larger than 0 causes the operation to fail . <nl> proposed change : read the number of replica shards from the template object : . <nl> this set of changes reads the index.number_of_replicas value from the template body ( defaults to 0 - no replicas- ) value when setting an index template . this enables the index.wait_for_active_shards value to be interpreted correctly . <nl> * read number of replicas from template <nl> * added tests to validate with default and specified replicas <nl> * rename replicas variable .,0.955159068107605
apache_pulsar/9907,add forwardsourcemessageproperty to sourcespec and add tests <para-sep> source property related test cases . <nl> get source info <nl> get source status <nl> delete source,- add to <nl> - add set from pulsar admin client <nl> - add related logic in <nl> - add integration test .,1615778973,"support build pulsar client with serviceurlprovider method . <nl> with serviceurlprovider we can store the pulsar service url in zookeeper or any other config service . <nl> and we can watch the service url change event then control the pulsar client , such as change pulsar client serviceurl , force close client connection or re-connect with new service url . <nl> add serviceurlprovider interface . <nl> add forcecloseconnection method in pulsarclient .",0.9767000079154968
jenkinsci_jenkins/4712,"avoid missingclasstelemetry populates the log <para-sep> list of events , one per stack trace , to send to telemetry . list of all events registered on this execution , to avoid printing an event more than once in the log . this map is not limited . on every jenkins restart is cleaned because it 's not persisted , so the cnfe is printed again . the key is the class name not found to quickly look for it on every cnfe thrown . <nl> we add the event to the list of already printed events . we used the name of the missing class instead of the full stack trace as a key to avoid filling the log with cnfe talking about the same class even though the stack traces are different . worse scenario , if we do n't put the exception on the ignored_places correctly , the administrator will see the message again and we will be able to add the new one to the ignored_places . in addition , the event is also sent to telemetry . <nl> returns true if the class name was already registered previously , during the current execution of this jenkins instance . <nl> to clean on every test execution <nl> do n't add ' java.base/ ' before sun.reflect.generics.factory.corereflectionfactory <nl> only one class miss gathered <nl> 0 log entries <nl> the stack trace of these cnfe are different but we only look at class names when printing on logs , so just one log entry <nl> the class name and also the stack trace of these cnfes are the same , so 0 log event <nl> no log <nl> only a max number of events is gathered . in this test , just one with two occurrences backup to restore at the end of the test <nl> exceptions thrown at the same line , with the same stack trace become occurrences of just one event <nl> get the events gathered <nl> only one event gathered <nl> backup to restore at the end of the test <nl> get the events gathered <nl> only one event gathered <nl> log has nothing to do with the limit for the sending . we print both because they have different class names","* internal : avoid populating logs with missing classes telemetry warnings upgade . <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs",1588695184,"in general it needs to do disk i/o once per session , but there is no good reason to throw away the results until either jenkins is restarted or an explicit configuration reload is requested . rechecking disk every 10s just seems wasteful . <nl> ( in principle we could try to optimize away ever loading of stored configurations but i suspect calls are more or less unavoidable in practice , so it seems simpler to just move it into the startup sequence . ) <nl> while there , i noticed that the storage of was quite wrong . generally",0.9377966523170471
hazelcast_hazelcast/18204,code changes <cm-sep> set trace log level for migrationcorrectnesstest,this pr : <nl> * set log level trace for migrationcorrectnesstest <nl> * removes field from as the same field exists in super class <nl> * use diamond operator <nl> * replace anonymous classes with lambdas in tests,1613140203,in and the initial capacity must be 0 <nl> or more .,0.8713635206222534
elastic_elasticsearch/71471,"<para-sep> the listener code above should never throw <nl> will always return a non-null value when httpchannel is non-null <nl> due to non-deterministic ordering in map iteration , the second client may not be the second entry in the list",as this improves a not-yet-released feature .,1617886510,this commit removes all but one reference to . <nl> this is to support more than one result index for a single job .,0.9627724289894104
Alluxio_alluxio/11449,"updates for incremental sync <para-sep> use debug because this can be a noisy log <nl> remove any previously completed sync tasks <nl> this returns a list of ufsuris that we need to sync . <nl> parallelize across sync points <nl> journal the latest processed txid <nl> we should only enter the loop if the task queue is full . this would occur if all sync tasks in the last 0 / ( heartbeats/minute ) minutes have not completed . <nl> attempts to return a status from the cache . if it does n't exist , reaches to the ufs for it . <nl> recreates the mount table with the local ufs as a spy 'd mockito object .",this pr improves a number of items over the previous incremental sync implementation . <nl> - the activesyncer heartbeat thread no longer performs incremental syncs synchronously within the heartbeat . a sync is scheduled as a future on an executor during the heartbeat and the status is checked in the following heartbeat . <nl> - the dfsinotifystream returns eventbatches that the previous implementation assumed contains a significant number of events per batch ( on the order of thousands ) . this is not the case . the eventbatch object contains only events pertaining to a specific transaction id on the,1589831132,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9798203110694885
apache_pulsar/9551,motivation . <nl> direct using jackson to parse json to avoid introduce the bookkeeper-common <nl> into the pulsar-common . that will make other modules which are using pulsar-common <nl> has some unused bookkeeper dependencies . <para-sep> expected error,motivation . <nl> direct using jackson to parse json to avoid introduce the bookkeeper-common <nl> into the pulsar-common . that will make other modules which are using pulsar-common <nl> has some unused bookkeeper dependencies .,1612932005,"this creates additional load on zookeeper and broker , slows down brokers and makes them less stable . also this causes scalability issues - adding more brokers increases operations duration even more .",0.9527812004089355
apache_camel/4990,"re-use http client and consume response <para-sep> create post object <nl> 2xx is ok , anything else we regard as failure",re-use http client and consume response .,1612203391,added support for get with body content on camel-http4 . this is triggered with the 'getwithbody=true ' uri parameter .,0.937115490436554
Alluxio_alluxio/11683,"add thread-factory for fork-join-pool threads <para-sep> default forkjoinworkerthreadfactory implementation ; creates a new forkjoinworkerthread using the system class loader as the thread context class loader . <nl> new runtimepermission ( ' setcontextclassloader ' ) , // java9-concurrent-backport changed <nl> forkjoinworkerthread index counter . <nl> thread properties .",this pr introduces a thread-factory implementation for use by in order to provide a custom name for worker threads .,1593459961,this will speed up list recursive .,0.9483182430267334
runelite_runelite/12352,anti drag : add deposit box for bank drag . <nl> adds anti drag to deposit box using bank drag delay,adds anti drag to deposit box using bank drag delay,1597592819,changes the ' attempting to kick player from friends chat ... ' message to include the name instead of player .,0.8793548941612244
vespa-engine_vespa/16575,"less docker <cm-sep> avoid suggesting node moves to spares <para-sep> node assignable to a tenant to run application workloads / host of a tenant nodes / <nl> node serving the shared proxy layer / host of a proxy node / <nl> config server node * / <nl> host of a config server node * / <nl> controller node * / <nl> returns whether given node type can run on this * / <nl> - linux containers : fake- returns the container images to use for nodes in this . * / - to parked : if the node has known hardware failure , hosts are moved to parked only when all of their failed containers ( vespa , not linux ) are expired early as there 's no data to potentially recover . <nl> metric for number of nodes that we want to fail , but can not due to throttling * / <nl> if the node is a host , it will only be removed if it has no children , <nl> addresses in this are available for use by linux containers . a node acl declares which nodes , networks and ports a node should trust . - ssh : if the host has one container , and it is using the host 's network namespace , opening up ssh to the host is done here as a trusted port . for simplicity all nodes have adds a list of newly created reserved nodes to the node repository * / <nl> adds a list of ( newly created ) nodes to the node repository as provisioned nodes . this method is used by the rest api to handle readying nodes for new allocations . for linux <nl> spare hosts are the hosts in the system with the most free capacity . a zone may reserve a minimum number of spare hosts to increase the chances of having replacements for failed nodes . <nl> returns whether host has room for requested capacity * / <nl> returns the number of available ip addresses on given host * /",moves to spares never succeed because spares can only be used in cases where <nl> we 're replacing a failed node . <nl> merge together with internal pr due to first commit .,1613657118,i 'll give the highlights if you give me a minute or two .,0.9574857354164124
Alluxio_alluxio/11463,throw exception when fail to create local cache <para-sep> todo ( binfan ) : remove the ioexception throwing or make this into a factory method <nl> errors when creating cache . * / <nl> errors when getting pages due to failed reads from cache storage . * / <nl> errors when adding pages due to failed writes to cache storage . * /,"with this pr , a presto query will fail with following error message when the cache is unable to create : .",1590132502,adding metrics for backup and restore from backup to track number of entries and time taken for backup .,0.9092636704444885
apache_druid/10125,fix cachingclusteredclient when querying specific segments <cm-sep> delete useless test <cm-sep> roll back timeout,"can be called when retries the query for missing segments . since it is possible to query only a subset of core partition set per time chunk , should use instead . the query can return incomplete result otherwise . maybe later , it is possible to refactor to use the given segments as they are instead of creating a timeline with them",1593687663,"announcertest essentially . <nl> 0. makes a pathchildrencache for and writes something on a in background . the pathchildrencache has an event listener for the event . <nl> 0. deletes transactionally . <nl> 0. expects pathchildrencache recreates the removed path on event . <nl> however , if the delete in the second step is performed before the write in the first step is finished , pathchildrencache never receives event . <nl> i fixed this issue by waiting for the path to be created before calling the delete operation . however , i 'm still concerned with that this issue may",0.9145017862319946
apache_pulsar/8961,"motivation . <nl> when users configure to use zkisolatedbookieensembleplacementpolicy , <nl> it is hard to configure autorecovery to respect to the isolation group <nl> settings . because we do n't store the isolation group information as <nl> part of ledger metadata , the framework does n't have any information <nl> to use for choosing the bookies . <nl> modifications . <nl> - change the zkisolatedbookieensembleplacementpolicy to use the policy <nl> passed from the custommetadata <para-sep> build additional metadata for the placement policy config . <nl> add a default constructor for decode data from bytes to construct this . <nl> using a pair to save the isolation groups , the left value is the primary group and the right value is the secondary group . <nl> parse the ensemble placement policy from the custom metadata , if it is present , we will apply it to the isolation groups for filtering the bookies . <nl> test case for auto-recovery . when the auto-recovery trigger from bookkeeper , we need to make sure the placement policy can read from custom metadata and apply it when choosing the new bookie . <nl> we configure two groups for the isolation policy , one is the 'primary ' group , and the another is 'secondary ' group . we put bookie1 , bookie2 , bookie3 into the 'primary ' group , and put bookie4 into the 'secondary ' group . <nl> prepare a custom placement policy and put it into the custom metadata . the isolation policy should decode from the custom metadata and apply it to the get black list method . <nl> do the test logic <nl> we assume we have an ensemble list which is consist with bookie1 and bookie3 , and bookie3 is broken . we want to get a replace bookie from the 'primary ' group and that should be bookie2 . because we only have bookie1 , bookie2 , and bookie3 in the 'primary ' group .","motivation . <nl> when users configure to use zkisolatedbookieensembleplacementpolicy , <nl> it is hard to configure autorecovery to respect to the isolation group <nl> settings . because we do n't store the isolation group information as <nl> part of ledger metadata , the framework does n't have any information <nl> to use for choosing the bookies . <nl> modifications . <nl> - change the zkisolatedbookieensembleplacementpolicy to use the policy <nl> passed from the custom metadata",1608019485,"with this feature it is possible to configure own schemareader and schemawriter on schemadefinition instantiation . with this it is possible to e.g . reuse already configured jackson objectmapper instances . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api : ( yes / no ) <nl> - the schema : ( yes / no / do n't know ) <nl> - the default values of configurations : ( yes / no ) <nl> - the",0.979453980922699
apache_pulsar/9388,[ pulsar sql ] support keyvalue schema separate mode .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1612149470,"if the topic has relatively low traffic , the de-duplication cursor will not move . this can cause messages that are not able to be deleted based on the retention policy . we should add a policy to take de-duplication snapshots based on time .",0.9354748129844666
Alluxio_alluxio/11733,fix cases for objectunderfilesystem when looking at root and does n't end with path separator,path of s3 : // currently does n't work while s3 : /// does because . <nl> s3 : /// gets currently replaced with the empty string when using it with the correct client while <nl> s3 : // does not get replaced with the empty string .,1594180001,"in light of preserving behavior , the command behaves the same as in <nl> previous versions . this change adds the -r option which can be specified <nl> optionally so that users can see part or all of the revision output <nl> appended to the end of the normal version string . <nl> added two new maven plugins to retrieve the git revision .",0.9156847596168518
apache_pulsar/8962,"add integration shade test for pulsar-client and pulsar-cient-admin . <para-sep> should not able to read message using normal message . <nl> verify that encrypted message contains encryption-context <nl> acknowledge the consumption of all messages at once <nl> make sure that messages are received in order <nl> make sure that there are no duplicates <nl> redelivery functionality guarantees that customer will get a chance to process the message again . in case of shared subscription eventually every client will get a chance to process the message , till one of them acks it . for client with encryption enabled where in cases like a new production rollout or a buggy client configuration , we might have a mismatch of consumers - few which can decrypt , few which ca n't ( due to errors or cryptoreader not configured ) . in that case eventually all messages should be acked as long as there is a single consumer who can decrypt the message . consumer 0 - can decrypt message consumer 0 - has invalid reader configured . consumer 0 - has no reader configured . <nl> consuming from consumer 0 and 0 no message should be returned since they ca n't decrypt the message <nl> all messages would be received by consumer 0 <nl> consuming from consumer 0 and 0 again just to be sure no message should be returned since they ca n't decrypt the message <nl> checking if all messages were received <nl> 0. invalid key name <nl> ok <nl> 0. producer with valid key name <nl> 0. keyreder is not set by consumer receive should fail since key reader is not setup <nl> 0. set consumer config to consume even if decryption fails <nl> receive should proceed and deliver encrypted message <nl> 0. set keyreader and failure action <nl> set keyreader <nl> verify that encrypted message contains encryption-context <nl> acknowledge the consumption of all messages at once <nl> 0. set consumer config to discard if decryption fails <nl> receive should proceed and discard encrypted messages <nl> try to decrypt use default messagecryptobc <nl> try to uncompress <nl> ////////weeoh1eceqefq92cszpczuxtmdfqaadg1naw5nahvhuxumwdpec9a2 <nl> /0////////////////mdseep////0///////////////weeoh1eceqefq92csz <nl> ////////////////////////////////////////////////8wgz4eqgh///// ////////////////////////////////////////////////////////////// ///////////////arbuzu+uwgohjofkpoholafqo6i2njbmbmv87i0izgo8qnh <nl> //////////////////////////migebeib//////////////////////////// ////////////////////////////////////////////////////////weqvgv <nl> /////////////////////6uyahg78vlmt/zafi9wml0du1ybijneeuu2+3hpe4 <nl> //mdseep////0///////////////weeoh1eceqefq92cszpczuxtmdfqaadg1n <nl> should not able to read message using normal message . <nl> verify that encrypted message contains encryption-context <nl> acknowledge the consumption of all messages at once <nl> make sure that messages are received in order <nl>",* include the shading of pulsar-client-api .,1608034911,generalized the method to decode the raw headers and payload . this will make possible to have tools that scans raw payload in managed ledger and can decode the messages .,0.988341212272644
runelite_runelite/12237,add bird nest to loot tracker plugin .,this will track seed bird nests in the loot tracker plugin and ultimately get the data sent to the wiki to further improve their data sets . inspired from jihadsquad 's sheet where he asks people to send him seed data to improve his rates .,1595855239,"this is intended to make the tags feature more discoverable , as people keep requesting ' plugin categories ' . putting plugins into a singular category that will make sense for most users is impossible , as many plugins will can logically be placed into multiple categories . <nl> the category tag list is intended to be a short , curated , list of tags that are helpful to a user trying to find plugins . <nl> the icon for this list only shows up when the input is empty , otherwise it shows the existing clear button .",0.8393298387527466
hazelcast_hazelcast/18393,propagate test statements interrupts <cm-sep> propagate test statements interrupts <para-sep> propagate interrupt,"in jet we quite often use in combination with . <nl> such setup results in one thread spawned for the entire class ( single timeout for , , , and all the tests ) and a separate thread spawned for each ( a timeout for each test separately ) . <nl> the problem is : whenever a timeout occurs for the entire class , the interrupt is n't propagated to the test thread which if blocked ( i.e . ) wo n't get unstuck . the result is non-completed cleanups , hanging clients and instances .",1615548553,before this change custom hazelcast exceptions thrown by older versions <nl> were not catchable by regular catch statements in the tests because <nl> their classes were loaded by class loaders different from the class <nl> loader hosting the tests .,0.8804165124893188
elastic_elasticsearch/72232,"add more snapshot details to repo data . <nl> this commit adds the start and end time of the snapshot , and a list of <nl> the names of any indices which were partially snapshotted , to the <nl> top-level blob . these details will be used in a <nl> follow-up that allows for querying snapshots by time and completeness , <nl> and are likely also useful for slm retention cycles which today must <nl> iterate all the possible blobs to find this information . <para-sep> creates a copy of this instance that contains additional details read from the per-snapshot metadata blobs","this commit adds the start and end time of the snapshot ~and a list of <nl> the names of any indices which were partially snapshotted~ to the <nl> top-level blob . these details will be used in a <nl> follow-up that allows for querying snapshots by time and completeness , <nl> and are likely also useful for slm retention cycles which today must <nl> iterate all the possible blobs to find this information .",1619441653,"this commit adds the minimum , maximum and average length <nl> of files in the searchable snapshots stats api .",0.9778653979301453
confluentinc_ksql/6245,format cast arguments with passed context <para-sep> given : <nl> when : <nl> then :,"previously , the second argument in was not getting fully processed in the , causing field cases to not be preserved when casting to structs . this pr fixes that .",1600365274,"that change has a relatively large surface area , so for the backport i am making the most targeted change possible to address the edge case .",0.9109489917755127
vespa-engine_vespa/15826,"wait for component deconstruction to finish when shutting down . <nl> - wait up to 0 minuts . <nl> - add separate modes for reconfig and shutdown . <nl> - add test ctor for setting the delay before deconstruction starts <nl> in reconfig mode . ( tests are tbd . ) <cm-sep> add constant for the deconstruct delay in reconfig mode . <cm-sep> extract method for task waiting and exception handling . <cm-sep> switch test to use reconfig mode by default . <nl> - use shutdown mode for the latest test that uses a component <nl> with the delayed deconstruct method . <nl> - remove the now unnecessary explanation from the class comment . <cm-sep> optimize imports . <cm-sep> make the deconstruct executor private again . <nl> - add helper method in test to wait for deconstruct to finish . <para-sep> this must be smaller than the shutdowndeadlineexecutor delay in configuredapplication <nl> are deconstructed , to prevent shutting down while deconstruct is in progress . <nl> for testing only <nl> deconstruct is async in reconfig mode , so must wait even with a zero delay . <nl> add delay to verify that the deconstructor waits until this is complete before returning .",this is to prevent uninstalling bundles and classnotfound exceptions when the container is shutting down .,1608046181,i plan to use a feature flag so we can switch between these versions with shorter turnaround and without breaking builds for such a long time,0.9446263909339905
vespa-engine_vespa/16866,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> add some more /0 checking <cm-sep> add some info <para-sep> the predicted duration of a rescaling of this cluster * / <nl> todo : remove when we have reliable completion for content clusters <nl> what cost difference is worth a reallocation ? / what resource difference is worth a reallocation ? / <nl> cluster level metrics . these are aggregated at fetch time over the nodes in the cluster at that point in time . <nl> queries per second * / <nl> a series of metric snapshots for the nodes of a cluster used to compute load <nl> the measurements for all nodes in this snapshot * / <nl> the cluster this is a timeseries for * / <nl> the nodes of the cluster this is a timeseries for * / <nl> returns the average number of measurements per node * / <nl> returns the number of nodes measured in this * / <nl> returns the average load of this resource in this * / <nl> a list of metric snapshots from a cluster , sorted by increasing time ( newest last ) . <nl> the max query growth rate we can predict from this time-series as a fraction of the current traffic per minute * / <nl> find the period having the highest growth rate , where total growth exceeds 0 % increase <nl> the current query rate as a fraction of the peak rate in this timeseries * / <nl> metric time series by node ( hostname ) . each list of metric snapshots is sorted by increasing timestamp * / <nl> adds node snapshots to this . * / <nl> returns all cluster level metric snapshots for a given cluster * / <nl> node level metrics * / <nl> cluster level metrics . must be aggregated at fetch time to avoid issues with nodes and nodes joining/leaving the cluster over time . <nl> a single measurement of all values we measure for one node . <nl> queries per second * / <nl> the configuration generation at the time of this measurement , or 0 if not known * / <nl> ( 0 is timestamp ) <nl> this error seems non-recoverable <nl> ( 0 is timestamp ) <nl> we remove full days at once and we want to see at least three days to not",i just need a run with this and we have an rc ...,1615324099,"the changes brought each other on , and got jumbled together 😭 . <nl> the changes are : . <nl> 0. logs are stored as objects . <nl> 0. the log for an active run is stored with a curator , in chunks of reasonable sizes . <nl> 0. log entries is written through immediately upon logging , and are given a ( new ) sequence id as counted per run . <nl> 0. when a run finishes , its log chunks are aggregated and moved to long-term storage . <nl> 0. logs are served as log objects in the",0.9825294613838196
elastic_elasticsearch/71518,"this change allows users to specify dynamic templates in a bulk request . <cm-sep> adjust bwc version . <nl> bwc <cm-sep> fix parameters <para-sep> if a dynamic template does not define nor nor <nl> todo : support dynamic_templates in update requests <nl> specifies a map from the full path of field names to the name of dynamic mapping templates <nl> returns a map from the full path of field names to the name of dynamic mapping templates . <nl> if the template name parameter is specified , then we will check only the name of the template and ignore other matches . <nl> we have more than one types when ( 0 ) is ' * ' , and ( 0 ) match and/or path_match are defined but not . in the latter the template implicitly accepts all types and we do n't need to serialize the values . <nl> find a dynamic mapping template for the given field and its matching type <nl> returns a map from the full path ( i.e . foo.bar ) of field names to the names of dynamic mapping templates . <nl> empty dynamic templates <nl> old version <nl> new version <nl> empty condition <nl> match_mapping_type <nl> match name <nl> no match condition",this change allows users to specify dynamic templates in a bulk request .,1617936376,"phase 0 of operator privileges is to support operator-only settings . this includes : <nl> * prevent operator-only setting from being updated with cluster settings api unless the user is an operator <nl> * skip operator-only setting during restore unless the authenticating user is an operator . <nl> ~for the restore process , even if the user is not an operator , the restore will not fail , but rather succeeds by skipping any operator-only settings . this means , if the current cluster state has values for an operator-only setting , it will have the same value after restore",0.9741500020027161
Alluxio_alluxio/11293,improve performance of sasl authentication <para-sep> note the constructor for this object is expensive . take care with how many of these are instantiated .,"before this pr , the impersonationauthenticator class could effectively <nl> bottleneck the amount of concurrent channels that a worker could handle . <nl> the for the impersonationauthenticator class required iterating over <nl> all keys within an alluxio configuration , not only doing key lookups , but also <nl> performing regex matching . for some keys this could be especially expensive <nl> ( i.e , default supplier which calls runtime.getruntime ( ) .availableprocessors ( ) ) . <nl> on top of that , performing regex matching is also quite expensive for a few <nl> hundred keys . <nl> after taking a",1586851917,"otherwise the following could happen : <nl> 0. start master <nl> 0. take snapshot ( snapshotted next inode id = 0 ) <nl> 0. create root inode with id 0 , next inode id should be 0 <nl> 0. restart master , loading snapshot which thinks next inode id is 0 <nl> 0. create directory /x , it gets assigned id 0 <nl> 0. try to delete /x , fails because it thinks it 's the root inode",0.8930326700210571
vespa-engine_vespa/16568,"inject configcurator . <nl> the injected config curator is created based on config values , which <nl> is the correct way of doing it in non-test code . in addition , <nl> configcurator will test connnection to server when it is created , so <nl> it is not good to create it for every tenant as was done before","the injected config curator is created based on config values , which <nl> is the correct way of doing it in non-test code . in addition , <nl> configcurator will test connection to server when it is created , so <nl> we do n't want to create it for every tenant , as was done before .",1613603463,"remove misleading prefix of some deploy messages . <nl> parent-host-not-ready : <nl> 0/0 hosts for vespa.album-recommendation.default-t have completed <nl> provisioning and bootstrapping , still waiting for <nl> h33908.staging.aws-us-c.vespa-external-cd.aws.oath.cloud . <nl> load-balancer-not-ready : <nl> failed to ( re ) configure load balancer for cluster in application , <nl> targeting : reals . the operation will be retried on next deployment . <nl> out-of-capacity one of : <nl> could not satisfy request for 0 nodes with ... <nl> not enough capacity to start 0 r4.xlarge instances ... <nl> no host flavor matches [ vcpu : 0 , memory : ... ] ,",0.9073867201805115
Alluxio_alluxio/10877,"calculate throughput value at master directly <para-sep> likely when all should report metrics are counters and this client does n't do any actual operations ( only used for meta sync ) <nl> currently all metrics that should be reported are all counters , the logic here is to support reporting metrics of all types for future convenience <nl> note that one minute rate may return 0 in the first several seconds that a value marked . for clients , especially short-life clients , the minute rates will be zero for their whole life . that 's why all throughput meters are not aggregated at cluster level . <nl> gets metric with the given full metric name . <nl> registers the corresponding throughput of the given counter . <nl> the time of the most recent metrics store clearance . this tracks when the cluster counters start aggregating from the reported metrics . <nl> put the metrics from a client with a hostname . <nl> update the reported metrics received from a worker or client .","alluxio clients are usually short-lived especially those created through running alluxio cli . alluxio throughput is recorded as . can be zero when the data is first marked since the one minute rate is a one-minute exponentially-weighted moving average rate . when a client is shutting down , it will report metrics the last time to leader master . because they are too short-lived , the reported is always zero , client metrics can be considered as lost in this scenario . <nl> in this pr , cluster throughput values are not aggregated value of client/worker reported meter one minute",1581375959,"a few caveats for this pr : <nl> - it turns out the major complexity of this pr is to figure out where to apply umask logic . after a few iterations , i finally put the umask logic into the method in class . the reason behind is that umask only matters for newly created files/directories , and is the critical path for those operations . <nl> - like linux , new files created in alluxio have default permission bits 0 and directories have 0. this is achieved by two different applyumask functions , one for file and one",0.9578049778938293
apache_pulsar/9732,"fix marking individual deletes as dirty . <nl> when we mark cursors as dirty , we are n't marking when individual acks <nl> cause a dirty cursor . <nl> this results in cursors not being flushed and causing redelivery . <nl> this one line fix will ensure we mark the cursor as dirty in this <nl> situation as well <para-sep> give chance to the flush to be automatically triggered . note : this ca n't be set too low , or it causes issues with zk thread pool rejecting <nl> abruptly re-open the managed ledger without graceful close <nl> reopen the cursor and we should see entries not be flushed <nl> give chance to the flush to be automatically triggered . note : this ca n't be set too low , or it causes issues with zk thread pool rejecting <nl> abruptly re-open the managed ledger without graceful close","when we mark cursors as dirty , we are n't marking when individual acks <nl> cause a dirty cursor . <nl> this results in cursors not being flushed and causing redelivery . <nl> this one line fix will ensure we mark the cursor as dirty in this <nl> situation as well .",1614307978,if client acks with invalid message-id ( message-id > ledger.lastconfirmedentry ) then broker does n't do validation and it tries to process it which can corrupt the state of cursor . <nl> eg : if is invalid then ledger.getnextvalidposition ( ) returns null and broker stores . <nl> and it creates below exception : . <nl> validate mark-delete position before processing it . <nl> prevents any state corruption at cursor .,0.9379645586013794
apache_shardingsphere/9874,support governance <cm-sep> support governance <para-sep> get adapter container . <nl> get storage container . <nl> get target datasource for writer . <nl> get target datasource for reader . <nl> get all target datasources . <nl> container compose .,changes proposed in this pull request : <nl> - improve it engine for supporting to test case involving governance or writer/reader splitting scenario .,1617081292,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - support rename table and column <nl> - add mysql alter table composite operate for column <nl> - refresh proxy fro create table,0.962857186794281
elastic_elasticsearch/71432,* adds to eql and sql requests allowing users to <nl> define search time runtime fields which will be used in queries . <nl> ( cherry picked from commit sha ) <para-sep> top level objects are fields <nl> add the runtime fields <nl> define the runtime field <nl> perform a superficial check for runtime_mappings structure . the full check can not happen until the actual search request <nl> top level objects are fields <nl> an optional list of runtime fields that can be added to the request similar to the way it is done in query dsl search requests <nl> set runtime mappings,* adds to eql and sql requests allowing users to <nl> define search time runtime fields which will be used in queries . <nl> ( cherry picked from commit sha ),1617815886,this adds a way to specify the on a search request <nl> which are always ' runtime ' fields . it looks like : . <nl> note : <nl> if we have to send a search request with runtime mappings to a node that <nl> does n't support runtime mappings at all then we 'll fail the search <nl> request entirely . the alternative would be to not send those runtime <nl> mappings and let the node fail the search request with an ' unknown field ' <nl> error . i believe this is would be hard to surprising because,0.9828191995620728
Alluxio_alluxio/11573,reduce number of clients in distributedloadcommand,creating many clients in distributedloadcommand creates an issue in certain environments . reduce the number of clients and also remove the parallelism around it to prevent race conditions when using the same client .,1592349204,valid prefixes ending in a path separator will be counted as ' existing ' paths .,0.8822920322418213
grpc_grpc-java/7722,"implement the new cds lb policy , which is capable of discovering an aggregate cluster with tree hierarchy . <para-sep> load balancer for cds_experimental lb policy . one instance per top-level cluster . the top-level cluster may be a plain eds/logical-dns cluster or an aggregate cluster formed by a group of sub-clusters in a tree hierarchy . <nl> following fields are effectively final . <nl> created and started when receiving the cds lb policy config with the top-level cluster name . <nl> level-order traversal . collect configurations for all non-aggregate ( leaf ) clusters . <nl> following fields are effectively final . <nl> all watchers should receive the same error , so we only propagate it once . <nl> other attributes not used by cluster_resolver lb are omitted . <nl> cluster ( aggr . ) - > [ cluster1 ( aggr . ) , cluster2 ( logical dns ) ] <nl> cluster1 ( aggr . ) - > [ cluster3 ( eds ) , cluster4 ( eds ) ] <nl> clusters on higher level has higher priority : [ cluster2 , cluster3 , cluster4 ] <nl> cluster ( aggr . ) - > [ cluster1 ( eds ) ] <nl> cluster ( aggr . ) - > [ cluster1 ( eds ) , cluster2 ( logical dns ) ] <nl> revoke cluster1 , should still be able to proceed with cluster2 . <nl> all revoked . <nl> cluster ( aggr . ) - > [ cluster1 ( eds ) , cluster2 ( logical dns ) ] <nl> cluster ( aggr . ) - > <nl> cluster ( aggr . ) - > [ cluster2 ( aggr . ) ] <nl> cluster2 ( aggr . ) - > [ cluster3 ( eds ) ] <nl> cluster2 revoked <nl> cluster ( aggr . ) - > <nl> cluster ( aggr . ) - > [ cluster1 ( logical dns ) ]","implementation for ( new ) cds lb policy that supports cluster discovery for aggregate clusters . <nl> the new implementation takes takes the same lb config as before , which contains a single cluster name . but this cluster can be representing an aggregate cluster , which is a composition for a tree-structured cluster hierarchy ( precisely speaking , it can be a directed graph with no cycles . that is , the hierarchy can contain diamond , where a cluster belongs to more than one aggregate clusters ) . therefore , the output ( aka , lb config for",1607654224,"the top-level lb policy , which is an aggregator for cds policies . it maintains the lifecycle of cds lb policy instances . the pick argument taken from the channel contains the information to determine which child cds policy instance should the picking operation be delegated to . <nl> the implementation is similar to the action part of what we currently have in the routing policy . the existing routing policy will be refactored to two parts , with the route match part moved into configselector and action part being this top-level lb policy .",0.9766875505447388
hazelcast_hazelcast/18432,"fix handling of user-provided default schema . <para-sep> if some of objects used in the plan have changed , then the plan should be re-created .","the pr lacks a test because it 's not possible to test it in imdg because imdg currently uses only a single schema ( partitioned ) and any value here is ignored . <nl> a test could be added to jet , but on the other hand , jet does n't yet depend on imdg version . but i tested it locally . ¯_ ( ツ ) _/¯ .",1616505682,this backport differs just in configuration part . instead of xml+java config model support the behavior is controlled by a new hazelcast group property . <nl> allowed values remain the same : <nl> * ( default ) <nl> * <nl> *,0.875843346118927
elastic_elasticsearch/70580,prevent snapshot backed indices to be followed using ccr <para-sep> create a regular index on leader <nl> create a snapshot backed index on leader,"today nothing prevents ccr 's auto-follow patterns to pick up snapshot backed indices on a remote cluster . this can lead to various errors on the follower cluster that are not obvious to troubleshoot for a user ( ex : ) . <nl> this pull request adds verifications to ccr to make it fail faster when a user tries to follow an index that is backed by a snapshot , providing a more obvious error message .",1616092201,"today when prewarming a searchable snapshot we use the to <nl> lock each ( part of a ) snapshotted blob , blocking any other readers from <nl> accessing this data until the whole part is available . <nl> this commit changes this strategy : instead we optimistically start to download <nl> the blob without any locking , and then lock much smaller ranges after each <nl> individual call . this may mean that some bytes are downloaded twice , <nl> but reduces the time that other readers may need to wait before the data they <nl> need is available .",0.9713624715805054
apache_druid/10451,virtual column on __time should be in pre-join,"if there is a virtual column with and base table columns as required columns , the virtual column can still be created past join . this pr avoids that from happening",1601397109,"add support for hadoop batch ingestion in azure blob storage . <nl> note hadoop paths through wasb : // do not support colons in filenames . the colons were removed by using for segment paths , and are also explicitely replaced by underscores . so , older segments created with real-time ingestion will not be recognized any more and will have to be re-imported since the naming of segments has changed .",0.9178537726402283
elastic_elasticsearch/71952,<para-sep> empty is safe here because we do n't use namedobject,"adds a device type into user agent processor . <nl> process is pretty simple , based on os and browser extracted via ua parser lib , this pr creates few simple patterns based on those , correct device type is matched , . <nl> one pattern for example to match desktop devices is this . <nl> ` - regex : '^ ( windows $ |windows nt $ |mac os x|linux $ |chrome os|fedora $ |ubuntu $ ) ' <nl> ` <nl> so if extracted os name is one of these , there are high chances that device is desktop .",1618933430,"adds a device type into user agent processor . <nl> process is pretty simple , based on os and browser extracted via ua parser lib , this pr creates few simple patterns based on those , correct device type is matched , . <nl> one pattern for example to match desktop devices is this . <nl> ` - regex : '^ ( windows $ |windows nt $ |mac os x|linux $ |chrome os|fedora $ |ubuntu $ ) ' <nl> ` <nl> so if extracted os name is one of these , there are high chances that device is desktop .",0.9944957494735718
jenkinsci_jenkins/4689,minor pom cleanup and switched assertions to junit5 because class was already switched to junit5,minor pom cleanup and switched assertions to junit5 because class was already switched to junit5 . <nl> * n/a : just internal,1587977075,"updated the parent pom to the latest version , which has spotbugs support , and migrated any remaining pom references from findbugs to spotbugs . this exposed the following new spotbugs error : . <nl> looking at the code , this seems like a false positive , because it is wrapped in the conditional , and returns if is null . spotbugs does n't seem to be able to detect this . to silence the error , i added an explicit null check ( which is harmless ) . <nl> the only other issue i had was this error :",0.770993173122406
Alluxio_alluxio/12214,"fix backup coordination and error handling <cm-sep> interrupt correctly on pause <para-sep> when using suspend , the caller needs to provide a callback method as parameter . this callback is invoked when the journal needs to reload and thus can not suspend the state changes any more . the callback should cancel any tasks that access the master states . after the callback returns , the journal assumes that the states is no longer being accessed and will reload immediately . <nl> cancel catching up thread if active . <nl> resets the suspend applier . should only be used when the state machine is reset . <nl> this callback is used for interrupting someone who suspends the journal applier to work on the states . it helps prevent dirty read/write of the states when the journal is reloading . here is an example of interrupting backup tasks when the state machine reloads : - backup worker suspends state machine before backup , passing in the callback . - backup worker writes journal entries to ufs . - raft state machine downloads a new snapshot from leader . - raft state machine transitions to pause state and invokes the callback . - backup worker handles the callback and interrupts the backup tasks . - raft state machine starts reloading the states . - raft state machine finished the reload and transitions back to running state . <nl> make sure there are no pending entries <nl> nothing to do - just use this method to transition from pause to running state <nl> when using suspend , the caller needs to provide a callback method as parameter . this callback is invoked when the journal needs to reload and thus can not suspend the state changes any more . the callback should cancel any tasks that access the master states . after the callback returns , the journal assumes that the states is no longer being accessed and will reload immediately . <nl> add a marker file indicating the file is completed .","this change fixed a few issues related to backup : . <nl> - make backup interrupt correctly when raft journal needs to reload from a snapshot . currently if backup occurs right before a journal reload it can buffer up some entries and then corrupt journal by resuming after the reload is completed . this change added an interrupt callback to make sure backup is correctly canceled and journal is resumed before a reload happens . <nl> - block backup when journal is being reloaded . when a raft journal is being reloaded , the backup should not happen because",1602282170,current journal entry log may not be closed before a crash . make sure that the log is readable before a close by using createoptions.ensureatomic = false .,0.9545203447341919
Graylog2_graylog2-server/9703,"make messagequeue implementation configurable . <nl> - clean up and unify guice modules . <nl> - add a new config option ' message_journal_mode = kafka , pulsar ' <para-sep> todo use enum ?",- clean up and unify guice modules . <nl> - add a new config option .,1607076311,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.950263500213623
OpenAPITools_openapi-generator/7410,fix typescriptnodeclientcodegen import filenames and related templates ; add tests,"_model is created by generator_ . <nl> _byomodel_ . <nl> therefore the logic was updated to a simpler version , assuming the mapping is created by prior areas . <nl> this resulted in the following import for : . <nl> _created model_ . <nl> _byomodel_ . <nl> per the above , this fixed the issue of the improper render which led to the bad i.e . what led to the following . <nl> the next issue was the extra which is embedded as part of the template . <nl> for this purpose , the extra directory listing was remove from",1600044905,"questions <nl> - project structure : i imagine there is a better place to put these files but nothing jumped out at me when i looked through <nl> - the list of reserved words is now missing a few of the previous reserved words ( just the ones that are a keyword with an asterisk , eg . async , yield ) <nl> - not sure if this is a problem , if it is maybe we should add a separate check for special characters ?",0.9251574277877808
elastic_elasticsearch/71688,"fix rest validation of search request using a pit . <nl> the rest validation of the search request ensures that the indices options <nl> are set to the default value . however , the comparison is too strict and should <nl> use equals since we create a new indicesoption object when parsing from http or transport .","the rest validation of the search request ensures that the indices options <nl> are set to the default value . however , the comparison is too strict and should <nl> use equals since we create a new indicesoption object when parsing from http or transport .",1618403477,"removing these limits as they cause unnecessarily many object in the blob stores . <nl> we do not have to worry about bwc of this change since we do not support any 3rd party <nl> implementations of azure or gcs . <nl> also , since there is no valid reason to set a different than the default maximum chunk size at this <nl> point , removing the documentation ( which was incorrect in the case of azure to begin with ) for the setting <nl> from the docs .",0.8586412072181702
OpenAPITools_openapi-generator/7752,"add client config getter and setter <cm-sep> update gradle , sbt config <para-sep> gets the client config . <nl> set the client config . <nl> rebuild http client according to the new ' clientconfig ' value . <nl> use the default client config if not yet initialized <nl> get the default client config . <nl> gets the client config . <nl> set the client config . <nl> rebuild http client according to the new ' clientconfig ' value . <nl> use the default client config if not yet initialized <nl> get the default client config . <nl> gets the client config . <nl> set the client config . <nl> rebuild http client according to the new ' clientconfig ' value . <nl> use the default client config if not yet initialized <nl> get the default client config . <nl> gets the client config . <nl> set the client config . <nl> rebuild http client according to the new ' clientconfig ' value . <nl> use the default client config if not yet initialized <nl> get the default client config . <nl> gets the client config . <nl> set the client config . <nl> rebuild http client according to the new ' clientconfig ' value . <nl> use the default client config if not yet initialized <nl> get the default client config .","- add clientconfig getter , setter <nl> - remove performadditionalclientconfiguration ( breaking changes ) .",1603098931,"this pr updates to process only files with an ending supported by the targeted templating engine . <nl> this also fixes some sonar recommendations , one of which may be a breaking change ; template and output directories now may not include for directory traversals .",0.9568850994110107
elastic_elasticsearch/71263,"this commit adds a node level deprecation log message when multiple <nl> data paths are specified . <para-sep> note : we use initialenvironment here , but assertequivalent below ensures the data paths do not change <nl> unit tests do not run with the bundled jdk , if there are warnings we need to filter the no-jdk deprecation warning",this commit adds a node level deprecation log message when multiple <nl> data paths are specified .,1617401776,"this adds a new flag for get transform api . <nl> this flag is useful for when a transform needs to be cloned within a cluster or exported/imported between clusters . <nl> it removes certain fields that are not able to be set via the put api ( e.g . version , create_time ) .",0.9356296062469482
OpenAPITools_openapi-generator/8142,add postprocess method to show donation message <para-sep> override with any message to be shown right before the process finishes <nl> post-process,"add postprocess method to show donation message , e.g . <nl> generators can override this method to show tips ( e.g . using code formatter to format the output ) , etc .",1607531234,description of the pr <nl> add an testfolder property for kotlin in general and add api_test.mustache files for kotlin-spring generator .,0.8313076496124268
netty_netty/10935,allow blocking calls in unixresolverdnsserveraddressstreamprovider # parse . <nl> motivation : . <nl> internally unixresolverdnsserveraddressstreamprovider # parse calls fileinputstream.read ( ... ) <nl> when parsing the etcresolverfiles . <nl> this will cause the error below when blockhound is enabled <nl> reactor.blockhound.blockingoperationerror : blocking call ! java.io.fileinputstream # readbytes <nl> at java.io.fileinputstream.readbytes ( fileinputstream.java ) <nl> at java.io.fileinputstream.read ( fileinputstream.java:0 ) . <nl> modifications : . <nl> - add whitelist entry to blockhound configuration <nl> - add test . <nl> result : .,motivation : . <nl> internally calls <nl> when parsing the . <nl> this will cause the error below when is enabled . <nl> modifications : . <nl> - add whitelist entry to configuration <nl> - add test . <nl> result : .,1610618829,"motivation : . <nl> if the encoded value of a form element happens to exactly hit the chunk limit ( 0 bytes ) , the post request encoder will throw a nullpointerexception . <nl> modification : . <nl> catch the null case and return . <nl> result : .",0.9227471947669983
apache_kafka/10082,use 'mapkey ' to avoid unnecessary grouped data,as title . thanks to great krpc : ) . <nl> 0. add 'mapkey=true ' to <nl> 0. rename to for <nl> 0. add 'mapkey=true ' to <nl> 0. rename to for <nl> 0. add 'mapkey=true ' to .,1612793523,0. get rid of that creates a new for each state since all the callers do not require it to be a seq . <nl> 0. modify replicafetcherthread constructor to fix the broken benchmark path .,0.9201387166976929
vespa-engine_vespa/16150,"allows setting a node safely to maintenance in these two new circumstances : . <nl> 0. the node has state maintenance with ( user ) wanted state up . <nl> 0. there are other nodes in the same hierarchical group that are set in <nl> maintenance with the same description . <nl> also made the following change . <nl> 0. deny a request for safe maintenance or down , if the wanted state is already <nl> set but with a different description . if the descriptions are the same , it <nl> is assumed to be the same operator ( e.g . orchestrator ) having changed its <nl> mind . <para-sep> returns non-null iff index is a configured nodes ( except perhaps in tests ) . / returns non-null iff index is a configured nodes ( except perhaps in tests ) . /","allows setting a node safely to maintenance in these two new circumstances : . <nl> 0. the node has state maintenance with ( user ) wanted state up . <nl> 0. there are other nodes in the same hierarchical group that are set in <nl> maintenance with the same description . <nl> also made the following change . <nl> 0. deny a request for safe maintenance or down , if the wanted state is already <nl> set but with a different description . if the descriptions are the same , it <nl> is assumed to be the same operator (",1611245728,"i 've tried to generalize the waiting criteria a bit more since our discussion . <nl> note that this pr does not cover the client tool . we want the default behavior to be ' wait until acked ' , which is what it will get until any client override support is in place . <nl> it also does not cover the desired change in logic where we do not require all distributors to have acked the exact same version , but rather look at the minimum acked version across all distributors . this is more of an availability optimization",0.9831826090812683
Graylog2_graylog2-server/9760,"fix linter error <cm-sep> show test notification field after type selected . <nl> in order to test a notification the user must select a type first , so it <nl> is better to hide the field away until a notification type was selected . <cm-sep> make email notification sender optional . <nl> the server already uses the sender configured in the config file as <nl> default , so make this field optional . <cm-sep> hide email notification sender in cloud . <cm-sep> fix linter error <cm-sep> hide legacy email alarm callback 's sender in cloud","- make field in email alert notification optional , since that will use the default set in the graylog configuration file <nl> - hide field in both the email alert notification and the legacy email alarm callback <nl> - small linter and ux fixes .",1607601108,"the parameter has been removed from elasticsearch about version years ago <nl> before the release of version and requests have it will fail . <nl> this has n't been noticed so far because it only happens when the <nl> indices # move ( ) method runs . that method is only called by the <nl> fixdeflectorbymovejob periodical . the job does n't run that often , <nl> apparently . <nl> also the only test that is using it is the messagesit test and that is <nl> using ' assumetrue ( ) ' so it does n't fail but gets skipped",0.8362590670585632
apache_druid/10370,"push down valuetype to exprtype conversion , tidy up <cm-sep> determine expr output type for given input types <cm-sep> revert unintended name change <cm-sep> add nullable <cm-sep> tidy up <cm-sep> fixup <para-sep> compute the output type of this function for a given lambda and the argument expressions which will be applied as its inputs . <nl> output type is accumulator type , which is last argument <nl> output type is input array type <nl> a null value means that either the binding does n't exist , or , that the type information is unavailable . <nl> given 0 'input ' types , choose the most appropriate combined type , if possible <nl> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if both arguments are a string , type becomes a string <nl> given 0 'input ' types , choose the most appropriate combined type , if possible <nl> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if either argument is a string , type becomes a string <nl> all numbers win over longs <nl> floats vs doubles would be handled here , but we currently only support doubles ... <nl> compute the output type of this function for a given set of argument expression inputs . <nl> anything goes <nl> evaluate arguments and collect output type <nl> the greatest/least functions are not in the sql standard . emulate the behavior of postgres ( return null if all expressions are null , otherwise skip null values ) since it is used as a base for a wide number of databases . this also matches the behavior the the long/double greatest/least post aggregators . some other databases ( e.g. , mysql ) return null if any expression is null . <nl> noinspection optionalgetwithoutispresent ( empty list handled earlier ) <nl> noinspection optionalgetwithoutispresent ( empty list handled earlier ) <nl> noinspection optionalgetwithoutispresent ( empty list handled earlier ) <nl> can only know cast output type if cast to argument is constant <nl> output type is defined by else <nl> else else_result . <nl> matching when boolean_expr then result <nl> output type is defined by else <nl> else else_result . <nl> matching when value then result <nl> output type is defined by else <nl> nulls output nulls <nl> only long stays long <nl> only string stays string <nl> for operators , doubles","it is worth mentioning that _nothing is currently using or taking advantage of this_ , and that this pr is scaffolding for follow-up work which will introduce vectorized expressions ( and could potentially be used to optimize non-vectorized expressions as well ) . <nl> anyway , the main changes in this pr have been added to : . <nl> with similar methods added to and so that the output types of functions can be computed . <nl> i think there is a lot of room for further improvement , for example this could potentially be combined with the input analysis",1599615937,"this request uses a mysql database to store configurations for how indexer workers should be created . previously , these configs were part of the jvm configs , and updates to the indexer coordinator were required in order to update worker configs . this commit introduces http endpoints on the indexer coordinator in which worker configs can be read and updated .",0.9764379262924194
apache_kafka/9888,: use statelistener to catch each state change,"the tests are flaky because we used the to wait for a state . is using poll to check the current stream state , which might miss some state changes . <nl> ex : . <nl> i use to keep the new state of each state change . so when we verify a specific state , we can always find it if existed . also have small refactor .",1610615455,"allow even distribution of lost/new tasks when more than one worker joins the group at the same time . <nl> issue description : <nl> existing issue 0 description : when more than one worker joins the consumer group the incremental co operative assignor revokes and re assigns atmost average number of tasks per worker . <nl> issue : this results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks . <nl> fix : as part of task assignment calculation following a deployment , the reassignment of",0.9274495840072632
apache_incubator-pinot/5788,[ te ] error handling refactor of entitymanagerresource . <nl> changes : <nl> - throw 0 instead of 0 for invalid query params <nl> - added a placeholder for resource utility methods : resourceutils <nl> - added badrequestwebexception to better handle invalid requests . <nl> the long term goal is to have a suite of utilities to make the resource code <nl> simple by easing out validations and error handling <para-sep> this exception is thrown when the user makes an error in the request . <nl> this class is expected to house static utilities that help responding to resource requests . <nl> ensure a condition is true and respond with bad request otherwise <nl> ensure the object exists and respond with bad request otherwise <nl> utility method to throw badrequest,the long term goal is to have a suite of utilities to make the resource code <nl> simple by easing out validations and error handling,1596315064,"[ te ] endpoint clean up , move detectionresources to dashboard resource folder , <nl> add endpoints to activate and deactivate functions in batch .",0.9499061107635498
elastic_elasticsearch/71568,"elasticsearch enumerates lucene files extensions for various <nl> purposes : grouping files in segment stats under a description , <nl> mapping files in memory through hybriddirectory or adjusting <nl> the caching strategy for lucene files in searchable snapshots . <nl> but when a new extension is handled somewhere ( let 's say , <nl> added to the list of files to mmap ) it is easy to forget to add it <nl> in other places . this commit is an attempt to centralize in a <nl> single place all known lucene files extensions in elasticsearch . <cm-sep> cherry picking fixes <para-sep> compound files are tricky because they store all the information for the segment . benchmarks suggested that not mapping them hurts performance . <nl> dim files only apply up to lucene 0.x indices . it can be removed once we are in lucene 0 <nl> mmapdirectory has special logic to read long [ ] arrays in little-endian order that helps speed up the decoding of postings . the same logic applies to positions ( .pos ) of offsets ( .pay ) but we are not mmaping them as queries that leverage positions are more costly and the decoding of postings tends to be less a bottleneck . <nl> doc values are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> old extension <nl> old extension <nl> lucene version point format metadata file <nl> norms are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> term dictionaries are typically performance-sensitive and hot in the page cache , so we use mmap , which provides better performance . <nl> we want to open the terms index and kd-tree index off-heap to save memory , but this only performs well if using mmap . <nl> lucene version terms metadata file <nl> temporary lucene file <nl> lucene version indexed vectors metadata <nl> lucene file 's extension . <nl> short description of the lucene file <nl> some lucene files should be memory-mapped when applicable . <nl> some lucene files are considered as ' metadata ' files and should therefore be fully cached when applicable . those files are usually fully read by lucene when a directory is opened . for non-metadata files lucene usually only reads the header and footer checksums .","elasticsearch enumerates lucene files extensions for various <nl> purposes : grouping files in segment stats under a description , <nl> mapping files in memory through hybriddirectory or adjusting <nl> the caching strategy for lucene files in searchable snapshots . <nl> but when a new extension is handled somewhere ( let 's say , <nl> added to the list of files to mmap ) it is easy to forget to add it <nl> in other places . this commit is an attempt to centralize in a <nl> single place all known lucene files extensions in elasticsearch .",1618237005,"could actually call the internal method more than once on contention . <nl> if i read the javadocs , it says : . <nl> so , it could be getting multiple updates on contention , thus having a race condition where stats are double counted . <nl> to fix , i am going to use a . the objects allows fast thread safe writes in high contention environments . these can be protected by the . <nl> when stats are persisted , i need to call reset on all these adders . this is not thread safe if additions are",0.9457501173019409
ballerina-platform_ballerina-lang/24931,disable exprbodiedfunctiontest.testsyntaxerrors <cm-sep> add empty list binding pattern support to parser . <cm-sep> enable exprbodiedfunctiontest.testsyntaxerrors <para-sep> handle empty list binding pattern,- $ subject <nl> - enable exprbodiedfunctiontest.testsyntaxerrors .,1595592039,this fixes a bug with worker/fork-join scenarios where the worker receive waits indefinitely when the value is null . this is fixed by handling ballerina null value and non-null values separately by using a wrapper class .,0.9096872210502625
elastic_elasticsearch/71855,"frozen default cache size . <nl> this commit adds a default cache size to frozen tier of the greater of <nl> 0 % and total disk size minus 0 gb . <nl> additionally , configuring a frozen cache is now warned against on nodes <nl> with multiple data paths . <cm-sep> add separate flood stage limit for frozen . <nl> dedicated frozen nodes can survive less headroom than other data nodes . <nl> this commits introduces a separate flood stage threshold for frozen as <nl> well as an accompanying max_headroom setting that caps the amount of <nl> free space necessary on frozen . <para-sep> tag : :cluster-routing-flood-stage-tag [ ] <nl> skip checking high/low watermarks for frozen nodes , since frozen shards have only insignificant local storage footprint and this allows us to use more of the local storage for cache . <nl> flood stage bytes are reversed compared to percentage , so we special handle it . <nl> a byte size value that allows specification using either of : 0. absolute value ( 200gb for instance ) 0. relative percentage value ( 0 % ) 0. relative ratio value ( version ) <nl> calculate the size to use , optionally catering for a max headroom . <nl> ignore , see if it parses as bytes <nl> todo : fix numberformatexception case in bytesizevalue . <nl> node1 is below low watermark , so no logging from it .",dedicated frozen nodes can survive less headroom than other data nodes . <nl> this commits introduces a separate flood stage threshold for frozen as <nl> well as an accompanying max_headroom setting that caps the amount of <nl> free space necessary on frozen .,1618847064,"adds data streams to cluster state and implements their create , delete , and get operations .",0.9708678722381592
apache_shardingsphere/10071,add ownertoken . <cm-sep> add combinationalsqltoken . <para-sep> combinational sql token . <nl> add sql token . <nl> get sql tokens . <nl> owner token . <nl> get quotecharacter .,- add ownertoken . <nl> - add combinationalsqltoken .,1618306601,changes proposed in this pull request : <nl> - add interface <nl> - add configuration <nl> - add tests,0.9796912670135498
elastic_elasticsearch/72511,"convert index path listeners to single path . <nl> the listeners for deletion of index and shard paths previously accepted <nl> an array of paths , since they could exist on several different data <nl> paths . this commit converts the consumer to take a single path .","the listeners for deletion of index and shard paths previously accepted <nl> an array of paths , since they could exist on several different data <nl> paths . this commit converts the consumer to take a single path .",1619727973,"this change adds three nodes that support negative brace accesses into collections , arrays , and for def types . this helps separate that logic out from brace accesses in general . this also has some renaming for nodes adding an ir prefix to help differentiate ir node variables from user node variables .",0.9475439786911011
vespa-engine_vespa/15488,"allow preprovision capacity on partially filled hosts . <nl> adds new functionality that can be disabled by setting the <nl> compact-preprovision-capacity flag to false . <nl> preprovision-capacity can be satisfied by hosts with spare resources . the <nl> dynamicprovisioningmaintainer does this as follows : <nl> 0. for each cluster in preprovision-capacity , try to <nl> a. allocate the cluster using nodeprioritizer <nl> b. if there is a deficit , provision the deficit with hostprovisioner , which <nl> may provision larger shared hosts depending on shared-hosts , and retry <nl> ( 0 ) from the first cluster again . <nl> c. otherwise , pretend the nodes are allocated and go to next cluster . <nl> 0. all of preprovision-capacity was successfully allocated , and empty hosts <nl> are therefore excess that can be deprovisioned .","adds new functionality that can be disabled by setting the <nl> compact-preprovision-capacity flag to false . <nl> preprovision-capacity can be satisfied by hosts with spare resources . the <nl> dynamicprovisioningmaintainer does this as follows : <nl> 0. for each cluster in preprovision-capacity , try to <nl> a. allocate the cluster using nodeprioritizer <nl> b. if there is a deficit , provision the deficit with hostprovisioner , which <nl> may provision larger shared hosts depending on shared-hosts , and retry <nl> ( 0 ) from the first cluster again . <nl> c. otherwise , pretend the nodes are allocated and go",1606400558,"i failed today , but i 'll make another attempt at not working on this tomorrow . <nl> the index-matrix case is now 10x faster - less than 0 ms , but still 10x slower than using individual vectors .",0.9702523946762085
Alluxio_alluxio/10908,add metrics tests <para-sep> a map from alluxiouri to corresponding cached escaped path . <nl> sleep 0 seconds to make sure sinks do happen and include the new metrics changes <nl> sleep 0 second to make sure the clear time is updated,this pr does some cleaning jobs of metrics : <nl> ( 0 ) add time loggings for metrics related methods <nl> ( 0 ) reduce the heavy string operations by memorizing the result of escapepath <nl> ( 0 ) reduce the call for metric_registry.getgauges ( ) since each getgauges call traverse the whole metrics and make a full copy of gauges . <nl> ( 0 ) add the metricsstoretest and metricssystemtest,1581628102,channelkey 's equals ( ) method was wrong and was missing hashcode ( ) implementation . this caused grpc channel pooling to always create new managed channel upon every request . this pr fixes it and adds further optimization to delay actual channel destruction .,0.9667351245880127
apache_shardingsphere/9357,create index in oracle . <cm-sep> add unit tests in create index .,changes proposed in this pull request : <nl> - modify grammar of the ' create index ',1612582632,changes proposed in this pull request : <nl> - set default readonly value to false,0.5901547074317932
neo4j_neo4j/10949,"adding support for scalar temporal values in the propertystore . <nl> this commit does only support scalar values , except datetimes with <nl> zoneids . it ignores checking whether the underlying store actually <nl> supports temporal values . it does not add array supoort yet . <cm-sep> check store capability before storing temporal values . <nl> this creates a new capability for the most recent store format . <nl> in the property store , the most two recent capabilities , both <nl> introduced in version ( points and temporal ) are merged into one boolean . <para-sep> date : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxx1 ] [ 0 , type ] [ k ] [ k ] [ k ] epochday date : [ , ] [ , ] [ , ] [ , 0 ] [ 0 , type ] [ k ] [ k ] [ k ] epochday in next long block localtime : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxx1 ] [ 0 , type ] [ k ] [ k ] [ k ] nanoofday localtime : [ , ] [ , ] [ , ] [ , 0 ] [ 0 , type ] [ k ] [ k ] [ k ] nanoofday in next long block localdtime : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ 0 , type ] [ k ] [ k ] [ k ] nanoofsecond epochsecond in next long block time : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ 0 , type ] [ k ] [ k ] [ k ] secondoffset ( =zoneoffset ) nanoofday in next long block datetime : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxx1 ] [ 0 , type ] [ k ] [ k ] [ k ] nanoofsecond epochsecond in next long block secondoffset in next long block todo alternative datetime format duration : [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [ xxxx , xxxx ] [","this does only support scalar values , except datetimes with <nl> zoneids . it does not add array support yet .",1517574734,"this is a step towards making store-copying , for backup and ha , do reads and writes through the page cache . we need this to make those things work with proprietary io integrations .",0.9738094806671143
elastic_elasticsearch/72048,delegate to wrapped map for tostring,this changes has dynamicmap delegate to its interally wrapped map for tostring to give better debugging information . this is particularly relevant to debug.explain in painless .,1619030446,"restclient add a isrunning method , so users can check if restclient is ok. if restclient is not running , user can reset a new restclient .",0.9163345694541931
OpenAPITools_openapi-generator/7965,"python- > python-legacy , python-experimental- > python <cm-sep> test with openjdk8 <cm-sep> test with openjdk11 <cm-sep> comment out rm <cm-sep> move kotlin tests to circleci <cm-sep> move kotlin tests <cm-sep> move tests to circleci <cm-sep> fix circleci <cm-sep> rearrange test <cm-sep> move tests <cm-sep> use wrapper <para-sep> python ( experimental ) ( generators/python-legacy.md ) ( python.md ) ( python-legacy.md ) <nl> for pythonclientcodegen , all aliases are generated as models <nl> a cache to efficiently lookup a schema instance based on the return value of . <nl> composed schemas can have the 'additionalproperties ' keyword , as specified in json schema . in principle , this should be enabled by default for all code generators . however due to limitations in other code generators , support needs to be enabled on a case-by-case basis . <nl> when the 'additionalproperties ' keyword is not present in a oas schema , allow undeclared properties . this is compliant with the json schema specification . <nl> this may set datatype right for additional properties <nl> this generator does not use sort_params_by_required_flag this generator uses the following order for endpoint paramters and model properties required params/props with no enum of length one required params/props with enum of length one ( which is used to set a default value as a python named arg value ) optional params/props with * * kwargs in python <nl> add the models and apis folders <nl> generate the 'signing.py ' module , but only if the 'http signature ' security scheme is specified in the oas . <nl> default this to true so the python modelsimple models will be generated <nl> configures a friendly name for the generator . this will be used by the generator to select the library with the -g flag . <nl> skip the warning as the spec can have no model defined logger.warn ( ' allschemas can not be null/empty in unaliasschema . returned 'schema ' ' ) ; <nl> top-level enum class <nl> treat it as a typical map <nl> free form object ( type : object ) <nl> non object non array non map schemas that have validations are returned so we can generate those schemas as models we do this to : - preserve the validations in that model class in python - use those validations when we use this schema in composed oneof schemas <nl> if a variable has no","this pr makes these generator changes <nl> - becomes <nl> - becomes . <nl> we are switching the python-experimental generator in as our stable python generator because it has significantly better composed schema support , many new features , and uses python3 only . <nl> also i improved string regex handling in python-legacy . <nl> for python-legacy using the openapi ( v3 ) spec sample tests of models have been regenerated and for non composed models , python-legacy now has auto-written tests that test instantiating a model instance with optional , and optional + required arguments . the regex fix",1605626218,"the language option ( -- lang and -l in cli , language in maven plugin ) has <nl> drifted from the original intention of defining a top-level language <nl> implementation with variance on library . generators began to encode <nl> generator type into language ( e.g . erlang-client ) , reused language as <nl> framework-only ( e.g . scalatra ) , or embedded language and framework ( e.g . <nl> typescript-angular ) . <nl> with the version release of openapi-generator , we 've moved to a <nl> standardization of these names , which means they no longer fit into the",0.93649822473526
apache_beam/12855,"update bigqueryavroutils.java . <nl> see fromtablefieldschematype of bigqueryutils - bigquery doesnt have type boolean it has type bool and it reflected in bigqueryutils , but in this class you use boolean which is inconsistent and breaks the schema . <nl> case 0 : <nl> if ( typename.equals ( ' bool ' ) ) { <nl> var3 = 0 ; <nl> } <nl> break ;","see fromtablefieldschematype of bigqueryutils - bigquery doesnt have type boolean it has type bool and it reflected in bigqueryutils , but in this class you use boolean which is inconsistent and breaks the schema . <nl> case 0 : <nl> if ( typename.equals ( ' bool ' ) ) { <nl> var3 = 0 ; <nl> } <nl> break ; .",1600281718,this test was only recently enabled so i do n't think it 's a big deal to ignore this until the flakiness is fixed . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.706501841545105
confluentinc_ksql/6182,"fail on non-string map keys . <nl> fixes ksqldb so that statements that create maps with non-string keys fail . <nl> crux of the issue was in , which ignored the key type . <nl> additionally , there were many places in the code that checked for non-string keys , but they always were string keys by this point . these checks have generally been removed in prep for supporting non-string keys . it is the format that should decide if it can handle non-string keys or not , hence the code now fails these statements because the key/value format rejects them as unsupported . this opens the way to protobuf supporting integer keys in the future : only the protobuf serde could should need to change . <para-sep> add the statement text to the ksqlexception <nl> given : <nl> when : <nl> then : <nl> when : <nl> then","fixes ksqldb so that statements that create maps with non-string keys fail . <nl> crux of the issue was in , which ignored the key type . <nl> additionally , there were many places in the code that checked for non-string keys , but they always were string keys by this point . these checks have generally been removed in prep for supporting non-string keys . it is the format that should decide if it can handle non-string keys or not , hence the code now fails these statements because the key/value format rejects them as unsupported . this opens",1599764974,"adds support for rowtime in pull queries by switching to the newer store types that expose timestamp . <nl> note : for session window stores , the upper bound of the session window is equivalent to rowtime . <nl> breaking change : the rows returned by pull queries that do a now include a column , where previously they did not . <nl> usual .",0.9748973250389099
elastic_elasticsearch/71425,"this commit updates transform feature reset to : . <nl> - wait for transform tasks to complete <nl> - wait for all indexing actions to transform indices to complete <nl> - and prevents transform audit messages from being written while the reset is being processed . <para-sep> noop , nothing for us to do , simply return fast to the caller <nl> this parser follows the pattern that metadata is parsed leniently ( to allow for enhancements ) <nl> merge the diff with the transform metadata . <nl> assert transforms are gone <nl> assert transform indices are gone",this commit updates transform feature reset to : . <nl> - wait for transform tasks to complete <nl> - wait for all indexing actions to transform indices to complete <nl> - and prevents transform audit messages from being written while the reset is being processed .,1617812967,"fixes several bwc issues in x_pack/usage discovered after introduction of the <nl> bwc test . <nl> even though master no longer reports flatten as a feature we still can receive it from 0.x nodes during upgrade . i was n't sure if i should add these piece back or just hard code flatten in the reader , read a string , two booleans and an int and be done with it . please , let me know what you think .",0.98106449842453
elastic_elasticsearch/71701,add node level cache stats for searchable snapshots <para-sep> test [ setup : node ] <nl> testresponse [ s/ ' reads ' : 0/ ' reads ' : 0/ ] testresponse [ s/ ' bytes_read_in_bytes ' : 0/ ' bytes_read_in_bytes ' : 0/ ] testresponse [ s/ ' writes ' : 0/ ' writes ' : 0/ ] testresponse [ s/ ' bytes_written_in_bytes ' : 0/ ' bytes_written_in_bytes ' : 0/ ] testresponse [ s/ ' evictions ' : 0/ ' evictions ' : 0/ ] testresponse [ s/ ' num_regions ' : 0/ ' num_regions ' : 0/ ] testresponse [ s/ ' size_in_bytes ' : 0/ ' size_in_bytes ' : 0/ ] testresponse [ s/ ' eerrtbmtqeisohzzxblusw ' /\ $ node_name/ ] > <nl> node level stats about searchable snapshots caches . <nl> node level stats for searchable snapshots caches .,this pull request adds a first set of node-level statistics about the shared cache . <nl> the rest endpoint is : . <nl> and the returned informations are : . <nl> i 'm opening this pr as a draft since it is lacking tests but i 'd like to get feedback about the api and the stats .,1618418167,"adds super basic usage information for searchable snapshots , to be extended later .",0.9858361482620239
apache_flink/14383,remove jobmanageroptions.scheduling_strategy <cm-sep> remove lazyfromsourcesschedulingstrategy <cm-sep> remove eagerschedulingstrategy,"after the implementation of the pipelined region scheduler ( ) , we no longer need the old lazyfromsourcesschedulingstrategy and eagerschedulingstrategy strategies and the components required by it . in order to simplify the maintenance , i suggest to remove these components . <nl> - this pr addresses the first three subtasks of . <nl> verified by ci . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers",1607977475,"* stopped using mode <nl> * fixed tests that were failling in the mode <nl> * reverted sha . <nl> all existing tests pass . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> -",0.9197912812232971
apache_druid/10429,"vectorize remaining math expressions <para-sep> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if either argument is a string , type becomes a string <nl> any number is long <nl> default best effort numeric type conversion . <nl> make a 0 argument math processor with the following type rules long - > long double - > long <nl> make a 0 argument , math processor with the following type rules long , long - > double long , double - > double double , long - > double double , double - > double <nl> make a 0 argument , math processor with the following type rules long , long - > long long , double - > long double , long - > long double , double - > long <nl> nulls output nulls <nl> all numbers are longs <nl> any string makes become string <nl> unless it is an array <nl> can not vectorize due to unknown nulls in numeric column <nl> vectorized group by does not work for null numeric columns <nl> vectorized group by does not work for null numeric columns <nl> vectorized group by does not work for null numeric columns","this pr fixes a bug with for sql compatible null handling mode , including for non-vectorized queries . <nl> additionally , this pr fixes another bug by disabling vectorized group by engine whenever it encounters grouping on numeric null values , which the engine does n't currently handle",1600899219,"hi , . <nl> this is an initial implemenation of supporting protocol buffers messages in the kafka firehose . <nl> regards , <nl> jan",0.9640495777130127
Graylog2_graylog2-server/9558,"avoid npe when resolving broken dependencies . <nl> if an entity contains a dependency to a no longer existing <nl> object , we 'd throw an npe when trying to resolve the object 's title . <nl> - return a replacement string if the title ca n't be resolved . <nl> - add a unit test for the entitydependencyresolver .","if an entity contains a dependency to a no longer existing <nl> object , we 'd throw an npe when trying to resolve the object 's title . <nl> - return a replacement string if the title ca n't be resolved . <nl> - add a unit test for the entitydependencyresolver .",1605803134,"if returns false for a bulk indexing result , retrying <nl> the whole bulk will lead to infinite loops in case of index mapping <nl> errors or other permanent errors . <nl> this change also adds an informational logging message whenever a bulk <nl> was indexed successfully on the n-th ( n > 0 ) attempt , indicating that <nl> indexing has recovered from a formerly erroneous condition .",0.9665272831916809
apache_druid/10603,add new coordinator metrics for duty runtimes <cm-sep> fix spelling for a constant variable value <para-sep> emit the runtime of the full dutiesrunnable <nl> emit coordinator runtime stats,"adds two new metrics to the coordinator . these metrics help operators evaluate coordinator runtimes and allow for analyzing runtimes for individual duties if the metrics are emitted ( as of now , only historicalmanagementduties runnable will emit the individual duty runtime metrics ) . <nl> = the time for an individual duty to execute <nl> = the time for the whole duties runnable to execute . <nl> example metric json :",1606257235,- combiningsequence leaked the input yielder from ' toyielder ' if it ran <nl> into an exception while accumulating the last value from the input <nl> yielder . <nl> - mergesequence leaked input yielders from ' toyielder ' if it ran into <nl> an exception while building the initial priority queue . <nl> - scanqueryrunnerfactory leaked the input yielder in its <nl> ' priorityqueuesortandlimit ' strategy if it ran into an exception <nl> while scanning and sorting . <nl> - yieldingsequencebase.accumulate chomped ioexceptions thrown in <nl> ' accumulate ' during yielder closing . <nl> the first bug ( in combiningsequence,0.9545038342475891
hazelcast_hazelcast/18462,make jet tests use smallinstanceconfig <cm-sep> use small instance configuration in jobrestartwithsnapshottest,this pr changes the instance configs of jet tests to use . it aims to reduce the run time of these tests . <nl> checklist : .,1617609751,,0.0
ballerina-platform_ballerina-lang/24178,fix issue in rabbitmq message receiver,fixes : . <nl> fixes : .,1592281165,"in this testcase , we are testing error message when client called unavailable service . but seems like when test case is running , service from another testcase is up and running in the same port . so testcase is hanging waiting for the server response . <nl> change the port from 0 to 0",0.830112099647522
Graylog2_graylog2-server/9783,add annotation to hide rest resources on cloud . <nl> this commit adds a annotation that can be used in rest <nl> resource classes that need to be registered in on-premise setups but not <nl> on graylog cloud . <nl> when registering resources in jersey we skip those resources including <nl> the annotation if we are running on cloud . <cm-sep> hide api-browser and api-docs resources on cloud .,"this pr adds an annotation for rest resources that let us mark resources that should be available in on-premise setups but not on cloud . it also uses that annotation to mark the and as hidden on cloud . <nl> there probably is a better way to do this , but i could not find it with my ( little ) knowledge in that part of our stack , so i 'm open for suggestions if you have any !",1607701448,"in order to avoid leaving sidecars running in an unexpected state , this pr adds some restrictions on when it is possible to do certain actions : . <nl> - deleting a collector is only possible if there is not any configurations using it <nl> - deleting a configuration is only possible if there is not any sidecars using it <nl> - changing the collector associated to a configuration is only possible if there are no sidecars using that configuration .",0.9647008180618286
apache_druid/10213,"skip queue removal on timeout <para-sep> this decides whether additional replication is needed for segments that have failed to load due to a load timeout . when enabled , the coordinator will attempt to replicate the failed segment on a different historical server . the historical which failed to load the segment may still load the segment later . therefore , enabling this setting works better if there are a few slow historicals in the cluster and segment availability needs to be sped up . <nl> avoid removing the segment entry from the load/drop list in case config.getloadtimeoutdelay ( ) expires . this is because the zk node is still present and it may be processed after this timeout and so the coordinator needs to take this into account . <nl> this may have failed for a different reason and so act like it was completed . <nl> this is to enable additional replication of the timed out segments for improved availability . timed out segments need to be replicated in another server for faster availability . therefore we skip incrementing numreplicants for timed out segments if replicateafterloadtimeout is enabled . <nl> this will fail inside segmentchangeprocessor.run ( ) <nl> set time-out to 0 ms so that loadqueuepeon will fail the assignment quickly <nl> simulate incompletion of load request since request has timed out <nl> simulate completion of load request by historical after time out on coordinator <nl> ensure that the segment is assigned to one of the historicals <nl> ensure that the primary segment is assigned again in case the peon timed out on loading the segment <nl> ensure that the segment is assigned to one of the historicals <nl> add the segment to the timed out list to simulate peon timeout on loading the segment <nl> default behavior is to not replicate the timed out segments on other servers","no longer deletes segment load/drop entries in case expires . deleting these entries after a timeout can cause the balancer to work incorrectly , as described in the linked issue . <nl> with this fix , the segment entries will remain in the load/drop queue for a peon until the zk entry is deleted by the historical , unless a non-timeout related exception occurs . this helps the balancer to account for the actual queue size for historicals and can lead to better balancing decisions",1595617401,"this pr adds a new method to the interface , . which produces _parseable_ expression strings so that any tree can be converted back into a which can later be parsed into an equivalent expression . <nl> prior to this pr , not all which could exist at evaluation time were actually parseable , specifically empty numeric arrays and arrays with null elements . to make all able to satisfy the contract , the grammar has been updated to support these constructs . empty arrays may now be defined like so : , , , and arrays like are now",0.9770366549491882
elastic_elasticsearch/71382,add token name to metadata of authentication response <cm-sep> formalise additional metadata,"this pr adds the service account token name in a new top level field , , to the authenticate response . for now , this new field is only shown when the authentication is for a service account .",1617753613,"date processor was incorrectly parsing week based dates as when a <nl> weekbased year was provided ingest module was thinking year was not <nl> on a date and was trying to applying the logic for type of <nl> dates . <nl> for testing ingest has to have access to isocalendardataprovider in <nl> order to correctly calculate week based dates with iso rules . <nl> date processor is also allowing users to specify locale parameter . it <nl> should be taken into account when parsing dates - currently only used <nl> for formatting . if someone specifies 'en-us ' locale ,",0.948343813419342
apache_shardingsphere/9818,fixed the defect that the order of multiple sharding keys in the hint strategy <cm-sep> update hintmanager junit test,"in the hint strategy , since hintmanager uses hashmultimap to store the sharding keys , the order of the multiple sharding keys obtained by the sharding algorithm may be inconsistent with expectations .",1616667420,changes proposed in this pull request : <nl> - remove sets & maps referred from guava,0.88967365026474
elastic_elasticsearch/71696,rework geo mappers to index value by value <para-sep> the value can be <nl> build an index document using a parsed geometry <nl> todo phase out geohash ( which is currently used in the completionsuggester ) <nl> index configured for pointsonly <nl> multipoint data : index each point separately,"the various geo field mappers are organised in a hierarchy that shares <nl> parsing and indexing code . this ends up over-complicating things , <nl> particularly when we have some mappers that accept multiple values <nl> and others that only accept singletons . it also leads to confusing <nl> behaviour around behaviour : geo fields will ignore <nl> all values if a single one is badly formed , while all other field mappers <nl> will only ignore the problem value and index the rest . finally , this <nl> structure makes adding index-time scripts to geo_point needlessly <nl> complex .",1618411957,break the functionregistry monolith into a common ql base and a sql <nl> specific registry that handles aspects such as distinct and extract . <nl> in the process clean-up the names and signature of internal interfaces . <nl> most of the semantics were preserved however the error messages were <nl> slightly tweaked to make them more readable - this should n't be a <nl> problem as they are being used internally mainly in test assertions .,0.979175865650177
OpenAPITools_openapi-generator/7729,"fix files sort and path provider issue . <nl> the files metadata is supplementary , but was logging a warning while <nl> generating ada client that files could n't be written . an exception was <nl> being thrown because path was being reported as two different ' types of <nl> path ' . one would be reported as mac file , while the other was reported <nl> as a unix file . the fix here is to disconnect path details from the <nl> underlying file system provider by creating a new path based on the <nl> file 's absolute path . this change also fixes sorting so it works <nl> alphabetically in ascending order . <cm-sep> regenerate <para-sep> intentionally creates a new absolute path instance , disconnected from underlying filesystem provider of file","the files metadata is supplementary , but was logging a warning while <nl> generating ada client that files could n't be written . an exception was <nl> being thrown because path was being reported as two different ' types of <nl> path ' . one would be reported as mac file , while the other was reported <nl> as a unix file . the fix here is to disconnect path details from the <nl> underlying file system provider by creating a new path based on the <nl> file 's absolute path . this change also fixes sorting so it works",1602814633,this pr updates the asp.net server generator to support asp.net core version .,0.8907474279403687
neo4j_neo4j/11426,allow execution of snapshot queries over bolt endpoint . <nl> restore possibility of executing snapshot queries over bolt endpoint . <nl> do not expect results of specific type in transactionstatemachinespi . <nl> introduce interface that marks result that can supply queryresult instead . <nl> add additional rest endpoint integration test for snapshot execution . <para-sep> nothing to close,restore possibility of executing snapshot queries over bolt endpoint . <nl> do not expect results of specific type in transactionstatemachinespi . <nl> introduce interface that marks result that can supply queryresult instead . <nl> add additional rest endpoint integration test for snapshot execution .,1522328101,changelog : added set-password command to neo4j-admin,0.9831618666648865
apache_incubator-pinot/5410,"fix flaky test for intersegmentresulttablemultivaluequeriestest . <nl> the test was checking 1st row of the group by result , where all <nl> 0 aggregated group by values are the same . so , sometimes the test <nl> fails because the order of 0 resulting rows is somtimes different . <nl> fixing this issue by adding ' top 0 ' to have deterministic result .","the test was checking 1st row of the group by result , where all <nl> 0 aggregated group by values are the same . so , sometimes the test <nl> fails because the order of 0 resulting rows is somtimes different . <nl> fixing this issue by adding ' top 0 ' to have deterministic result .",1589865679,this is part 0 of cleanup for removing references to kafka in places which should be generic . this pr only involves renaming,0.8961386680603027
apache_beam/13593,"convert scalarfn to method . <nl> the method will be passed to createudfoperator in a future pr . <para-sep> * / <nl> if we have at least one match , then either it should be the only match or it should be an extension of the other matches ( which came from parent classes ) . <nl> method must be public . <nl> * /",the method will be passed to createudfoperator in a future pr,1608597085,"be sure to do all of the following to help us incorporate your contribution <nl> quickly and easily : . <nl> number , if there is one . <nl> individual contributor license agreement . <nl> the java directrunner needs to be well-defined with a payload in order to detect ( and provide ) runner-specified sharding .",0.973160445690155
apache_beam/13116,refactor checkpointing configuration code <para-sep> rocksdb state backend ( included in the flink distribution ) <nl> legacy way of setting the state backend,"we should make it easier to configure a flink state backend . at the moment , <nl> users have to either : . <nl> ( a ) configure the default state backend in their flink cluster . <nl> ( b1 ) include the dependency in their gradle/maven <nl> project ( e.g . ' org.apache.flink : flink-statebackend-rocksdb_2.0 : $ flink_version ' <nl> for rocksdb ) . <nl> ( b2 ) set the state backend factory in the flinkpipelineoptions . this only works <nl> in java due to the factory specification being in java ! <nl> we can make it easier by",1602704688,"basic bundling support for portable runner . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9570066928863525
apache_druid/10260,"longmaxvectoraggregator support and test case . <cm-sep> doubleminvectoraggregator and test cases . <cm-sep> doublemaxvectoraggregator and unit test . <cm-sep> floatminvectoraggregator and floatmaxvectoraggregator . <cm-sep> documentation update to include the other vector aggregators . <cm-sep> bug fix . <cm-sep> checkstyle formatting fixes . <cm-sep> calcitequerytest cases update . <cm-sep> separate test classes for floatmaxaggregation and floatmniaggregation . <cm-sep> remove the cannotvectorize for float max/min aggregator in test . <cm-sep> tests in groupbyqueryrunner , groupbytimeseriesqueryrunner and timeseriesqueryrunner . <para-sep> nothing to close . <nl> nothing to close . <nl> nothing to close . <nl> nothing to close . <nl> nothing to close . <nl> some sanity . <nl> some sanity . <nl> some sanity . <nl> some sanity . <nl> some sanity . <nl> can not vectorize due to ' cardinality ' aggregator . can not vectorize due to expressions .","summary of changes : <nl> the vectorized implementations of the above min/max aggregators are each in <nl> * adds new unit test classes -- and to test the floatmin and floatmax aggregations . <nl> * add new test cases and update existing tests in , , and . <nl> * update documentation to reflect that these aggregators now have vectorized versions .",1597072109,this strategy can be enabled by setting to,0.9798750877380371
apache_kafka/9978,"persist uuid , some cleanup in kafkastreams <para-sep> sanity check to fail-fast in case we can not build a processortopology due to an exception <nl> use client id instead of thread client id since this admin client may be shared among threads <nl> if we ca n't transition to pending_shutdown but not because we 're already shutting down , then it must be fatal <nl> the process file is used to persist the process id across restarts . for compatibility reasons you should only ever add fields to the json schema","to stabilize the task assignment across restarts of the jvm we need some way to persist the process-specific uuid . we can just write it to a file in the state directory , and initialize it from there or create a new one if no prior uuid exists . <nl> this also adds a state directory-level lock -- partly to protect the ' process file ' where we write the uuid , and partly to address an issue that has been plaguing users for a long time : with this top-level lock , we can now strictly enforce that only",1611716116,0. removed task field from taskmigrated ; the only caller that encodes a task id from streamtask actually do not throw so we only log it . to handle it on streamthread we just always enforce rebalance ( and we would call onpartitionslost to remove all tasks as dirty ) . <nl> 0. added taskcorruptedexception with a set of task-ids . the first scenario of this is the restoreconsumer.poll which throws invalidoffset indicating that the logs are truncated / compacted . to handle it on streamthread we first close the corresponding tasks as dirty ( if eos is enabled we,0.9682913422584534
elastic_elasticsearch/71538,"use bytebufferstreaminput to stream byte arrays . <nl> for bulk operations that fall back to hotspot intrinsic code ( reading short , int , long ) <nl> using this stream brings a massive speedup . the added benchmark for reading values <nl> sees a ~100x speedup in local benchmarking and the vlong read benchmark still sees a slightly <nl> under ~10x speedup . <nl> also , this pr moves creation of the out of the hot benchmark loop for all the bytes <nl> reference benchmarks to make the benchmark less noisy and more practically useful . <nl> ( the case using intrinsic operations is so fast that it would n't even show up in a profile relative to <nl> instantiating the stream otherwise ) .","for bulk operations that fall back to hotspot intrinsic code ( reading short , int , long ) <nl> using this stream brings a massive speedup . the added benchmark for reading values <nl> sees a ~100x speedup in local benchmarking and the vlong read benchmark still sees a slightly <nl> under ~10x speedup . <nl> also , this pr moves creation of the out of the hot benchmark loop for all the bytes <nl> reference benchmarks to make the benchmark less noisy and more practically useful . <nl> ( the case using intrinsic operations is so fast that it",1618075350,"today searchable snapshots implementations use the _blob store cache_ to cache the first bytes of every lucene files . after some experiments we think that we could adjust the length of the cached data depending of the lucene file that is read , caching up to 64kb for lucene _metadata_ files ( ie files that are fully read when a directory is opened ) and only 1kb for other files . <nl> the files that are cached up to 64kb are the files with the following extensions : . <nl> > ' cfe ' , // compound file 's entry",0.9719038605690002
quarkusio_quarkus/15145,this reverts commit sha . <cm-sep> enable java serialization for graalvm 0+,( i tested our kafka it but i 'm not sure it 's enough ),1613567471,"this is a stop gap measure , we need <nl> a more extensible solution to this .",0.945414125919342
Alluxio_alluxio/11354,stop tracking connections in copycat client/server <para-sep> nothing to clean up,"many connections can be created by the transport layer , but it is rare for copycat to close the client . tracking the created connections is unnecessary because copycat closes them before closing the clients anyways . this prevents us from holding on to the connection references for extended periods of time , which then causes behavior resembling a memory leak . <nl> additionally we bump the copycat version to version to avoid cycling connections . version introduces a changes to the keepaliveresponse serde to respect unresolved addresses .",1587874043,- replace individual members in in favor of storing and using directly . <nl> - add getprimaryindex in multiprocesscluster for determining primary master .,0.9383781552314758
apache_incubator-pinot/5643,"sql compilation fixes <para-sep> assumes that the passed in expression is a filter expression . <nl> first operand is the always the column <nl> in-built functions like regexp_like , text_match , timeconvert etc that are not natively supported by calcite grammar","two fixes : . <nl> - make in-built functions like text_match , regexp_like case insensitive on sql path . should be converted to upper case since that is what is there in enum definitions and is also followed by calcite for all functions/operators part of it 's grammar . <nl> - add support for converting pinotquery to brokerrequest for is null and is not null . calcite supports these natively as part of it 's grammar but we missed handling them when converting filterexpression to filterquery .",1593589904,extend anomaly hierarchy to multiple levels,0.9230930805206299
apache_shardingsphere/9929,revert commit <cm-sep> fix binding tables using 'join on ... and condition in ( ? ) ' or 'join on ... and condition = ? ' can not sharding correct . <para-sep> get join where segment from selectstatement .,changes proposed in this pull request : <nl> - binding tables using 'join .. on .. and column_x= ? ' or 'join .. on .. and cloumn_x in ( ? ) ' sharding correct .,1617460623,changes proposed in this pull request : <nl> - using multithreading make loaddefaulttables faster,0.9276915788650513
crate_crate/10228,"add a doc-value-aggregator for max on smallint/int/bigint/timestamp . <nl> system/jvm metrics ( durations in ms , byte-values in mb ) <nl> | young gc | old gc | heap | alloc <nl> | cnt avg max | cnt avg max | initial used | rate total <nl> v1 | 0 version version | 0 version version | 0 0 | version 0 <nl> v2 | 0 version version | 0 version version | 0 0 | version 0 . <nl> v1 top allocation frames <nl> lucene84postingswriter.newtermstate ( ) :0 <nl> bytesstore.writebyte ( byte ) :0 <nl> blocktreetermswriter $ termswriter.write ( ... ) :0 <nl> blocktreetermswriter $ pendingterm. ( ... ) :0 <nl> arraylist.grow ( int ) :0 <nl> v2 top allocation frames <nl> lucene84postingswriter.newtermstate ( ) :0 <nl> bytesstore.writebyte ( byte ) :0 <nl> blocktreetermswriter $ termswriter.write ( ... ) :0 <nl> blocktreetermswriter $ pendingterm. ( ... ) :0 <nl> arraylist.grow ( int ) :0","system/jvm metrics ( durations in ms , byte-values in mb ) <nl> | young gc | old gc | heap | alloc <nl> | cnt avg max | cnt avg max | initial used | rate total <nl> v1 | 0 version version | 0 version version | 0 0 | version 0 <nl> v2 | 0 version version | 0 version version | 0 0 | version 0 .",1594847874,todo : <nl> - support multiple rows <nl> - support params <nl> - response affected rows ( tbd ),0.9364031553268433
Graylog2_graylog2-server/9287,"revert ' use clustereventbus instead ' . <nl> this reverts commit sha . <cm-sep> revert ' clear the shiro authorization cache if grants change ' . <nl> this reverts commit sha . <cm-sep> only cache authorization results within a request context . <nl> - introduce a per-request random id by using a commonly known http <nl> header : x-request-id <nl> this id is either set by clients , load balancers , etc . <nl> if it 's not found , we create our own . <nl> - the request headers were already accessible within shiro 's threadcontext . <nl> but this is now refactored into a separate filter : shirorequestheadersbinder . <nl> - finally add the request id into the authorizationcachekey <para-sep> generate a random uuid v4 that will perform reasonably when used by multiple threads under load . <nl> identify this as a version 0 uuid , that is one based on a random value . <nl> set the variant identifier as specified for version 0 uuid values . the two high order bits of the lower word are required to be one and zero , respectively . <nl> needs to run before shiroauthorizationfilter <nl> needs to run after requestidfilter","- revert the event based cache invalidation . <nl> - only cache authorization results within a request context . <nl> - introduce a per-request random id by using a commonly known http <nl> header : x-request-id <nl> this id is either set by clients , load balancers , etc . <nl> if it 's not found , we create our own . <nl> - the request headers were already accessible within shiro 's threadcontext . <nl> but this is now refactored into a separate filter : shirorequestheadersbinder . <nl> - finally add the request id into the authorizationcachekey .",1603794110,"in order to clean up the code and research relevant differences between <nl> different supported elasticsearch versions , the two classes generating index <nl> mapping templates for es5 & 0 were refactored and most code was moved <nl> into the abstract base class . tests were added before to make sure that <nl> the refactoring does not change the logic .",0.9727415442466736
hazelcast_hazelcast/18328,support named parameters in sql hazelcastfunction <para-sep> transform name = > 'value ' into name = > cast ( 'value ' ),added support for named parameters to sql .,1614689015,"for parallel tests we use runtime # availableprocessors parallel test <nl> method runners . for most of the tests , it 's a reasonable default and it <nl> works well , but for heavily multi-threaded tests we may overload the <nl> system , especially if there are multiple builds running in parallel . <nl> this change puts a more tight limit on basicmaptest 's and <nl> abstractnearcachebasictest 's parallel test method count . <nl> ( cherry-picked from sha ) .",0.9005554914474487
jenkinsci_jenkins/4615,"session hijacking protection hardening <cm-sep> workaround bad test <cm-sep> better approach in terms of test <cm-sep> get rid of small whitespace <para-sep> system property name to force the session tracking by cookie . this prevents tomcat to use the url tracking in addition to the cookie by default . if you allow semicolon in url and the session to be tracked by url and you have a securityrealm that does not invalidate session after authentication , your instance is vulnerable to session hijacking . the securityrealm should be corrected but this is a hardening in jenkins core . as this property is read during startup , you will not be able to change it at runtime depending on your application server ( not possible with jetty nor tomcat ) when running hpi : run , the default tracking is cookie+url . when running java -jar with winstone/jetty , the default setting is set to cookie only . when running inside tomcat , the default setting is cookie+url . <nl> without this gymnastic , the jenkins-test-harness adds a nolistenerconfiguration that prevents us to inject our own custom webappmain with this approach we can make the server calls the regular contextinitialized <nl> future-proof <nl> default behavior of nolistenerconfiguration <nl> ensuring our custom context will received the contextinitialized event","the test failure was due to the contextinitialized being called when the context is already started , that is wrong considering the javadoc contract . <nl> there is no issue in terms of production code ( at least until now ) , it was just a test design issue . <nl> this pr could be merged after the original proposal as a better way to test the stuff , not needed to wait for this one . <nl> * session hijacking protection hardening <nl> - [ n/a ] appropriate autotests or explanation to why this change has no tests <nl>",1585656904,"without the patch , the test passes , but with a warning . <nl> * - bug - whitelist to prevent deserialization exception when listing agent files in non-existent directory or invalid filter ( ) . <nl> * - major rfe - remoting version : always send over the channel along with original exceptions , so that jenkins core can always deserialize exceptions even if the original type is not whitelisted ( ) .",0.9174038171768188
elastic_elasticsearch/71939,"nodes with a frozen cache no longer supports multiple data paths . this <nl> simplifies cache sizing and avoids the need to support multiple cache <nl> files . <para-sep> ok to ignore these <nl> peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this does n't work , but we can bypass this by forcing soft deletes to be used . <nl> ok <nl> the extra segments_n file created for bootstrap new history and associate translog makes us unable to precisely assert this . <nl> the extra segments_n file only has a new history uuid and translog uuid , both of which have constant size . it 's size is therefore identical to the original segments_n file from the snapshot . we expect at least 0 byte of other content , making it safe to assert that the total data set size is less than 2x the size . <nl> the extra segments_n file created for bootstrap new history and associate translog makes us unable to precisely assert this . <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , true , noncachedextensions ) ; <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , false , noncachedextensions ) ; <nl> todo : fix assertsearchablesnapshotstats ( restoredindexname , false , noncachedextensions ) ; <nl> todo : be resilient to this check failing and try next path ? <nl> todo : leave some margin for error here",nodes with a frozen cache no longer supports multiple data paths . this <nl> simplifies cache sizing and avoids the need to support multiple cache <nl> files .,1618926541,"make it possible to reuse the cluster state update of rollover for <nl> simulation purposes by extracting it . also now run the full rollover in <nl> the pre-rollover phase and the actual rollover phase , allowing a <nl> dedicated exception in case of concurrent rollovers as well as a more <nl> thorough pre-check .",0.9248688220977783
apache_pulsar/9215,"keep topic-level policies commands consistent with that for namespace level <para-sep> annotation was changed to hidden , reset it . <nl> deprecated commands <nl> deprecated commands <nl> deprecated commands <nl> the commands in this set are hidden and not shown to users <nl> this method is copied from defaultusageformatter , but the ability to skip deprecated commands is added . <nl> skip the deprecated command","for example , <nl> on namespace-level , the policies commands are : . <nl> on topic-level , the polices commands are : .",1610697363,when there are bk write errors we need to fence the topic and reset highestsequencedpushed - > highestsequencedpersisted .,0.956058144569397
jenkinsci_jenkins/4886,slave_log_handler should avoid synch logging <para-sep> see logrecord.writeobject for dangers of serializing non-string/null parameters,* reattempted fix for a deadlock in agent logging . <nl> before the changes are marked as : .,1596146738,"windows does n't allow deleting directories that have a file open inside of them , so this test is invalid on windows .",0.8088299036026001
hazelcast_hazelcast/18446,"cache 'jet ' sql plans <para-sep> a table with deterministic schema . plans containing it can be cached . <nl> a table with non-deterministic schema ( i.e . result of a file table function ) . plans containing it must/can not be cached . <nl> table is always available and its field list does not change <nl> table is always available and its field list does not change <nl> table is always available and its field list does not change <nl> table is always available and its field list does not change <nl> plan that can be cached . <nl> if some of objects used in the plan have changed , then the plan should be re-created . examples are index creation , map destroy , external object redefinition .",enabled plan caching for _jet_ based queries . <nl> this pr does not address the way plans are invalidated ( periodically - it is possible that user 's query will reuse stale plan ) . this should be done in a separate pr ( based on new metadata storage that is being worked on ? ) .,1617347227,"it adds a check for imap permission for maps involved in the query execution . <nl> implementations details : <nl> 0. the existing is removed <nl> 0. when the plan is created , a list of required permissions is collected ( ) . for imdg these are permissions for observed maps . jet sql will have its own logic in its implementation <nl> 0. when a query is being executed in the secure context , the collected permissions are checked ( , ) <nl> 0. the sql security context is created for both a client invocation ( ) and an",0.9846522808074951
apache_beam/12764,"add microsinstant.java <cm-sep> add support for micros_instant in portability <cm-sep> logicaltype support in python schema translation and rowcoder <cm-sep> add support for micros_instant in python <cm-sep> add integration test for micros_instant <cm-sep> commoncodertest.java : add support for parsing logical types <cm-sep> standard_coders_test.py : add support for parsing rows and logical types <para-sep> logical types are represented as their representation types in yaml . parse as the representation type , then convert to the base type . <nl> a schema type representing how to interpret the argument . <nl> only check argument equality if argument type is non-null . null indicates argument is ignored . <nl> todo ( ) : populate this with a logicaltyperegistrar , which includes a way to construct the logicaltype given an argument . <nl> todo ( ) : ' javasdk ' types should only be a last resort . types defined in beam should have their own urn , and there should be a mechanism for users to register their own types by urn . <nl> a timestamp represented as microseconds since the epoch . warning : this logical type exists solely for interoperability with other type systems such as sql and other beam sdks . <nl> todo ( ) : this should be a constant <nl> todo ( ) : this should be a constant <nl> beam logicaltype corresponding to zetasql timestamp type . * /","this pr adds support for in python and java . it also adds logic for translating logical types which do not use the argument to portable beam schemas . <nl> in python , is the default mapping for the microsecond-precision type when inferring a schema . <nl> the change is tested via unit tests in python and java , as well as a new entry in . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1599088347,"fix handling of time variables . row 's internal storage is instant , and the generated code assumed it was a datetime .",0.9498687386512756
OpenAPITools_openapi-generator/8105,sets 'iscollectionformatmulti ' to true on file uploads .,"the logic to update the flag was moved to , as contains a copy of the parameter , and not the reference . <nl> therefore , was still returning the parameters with the 'iscollectionformatmulti ' flag set to false .",1607171750,"to enable skipping ' form ' model generation , please use the following as stated in the updated doc : .",0.861425518989563
vespa-engine_vespa/16818,always use dedicated cluster controllers when hosted ( except in some tests ) <para-sep> check container cluster <nl> check admin clusters <nl> check content clusters <nl> ... <nl> ... <nl> ... <nl> ...,always use dedicated cluster controllers when hosted ( except in some tests ) .,1614952330,"in order to use the docker-api as a bundle , all github.docker-java has been moved internal to docker-api , which meant some apis have been moved between docker/dockerimpl and dockeroperations/dockeroperationsimpl . <nl> i have disabled tests in integrationtests , as they are partially overlapping with existing tests , and valerijf will take a look at rewriting them if we want to keep them . i 'll discuss this with dybdahl offline . <nl> this change should not introduce any observed changes .",0.957232654094696
jenkinsci_jenkins/4758,escape special characters from href attrib,"currently the jenkins allows single quotes ( ' ) in job names . <nl> so if an upstream job triggers downstream jobs ( having single quotes ) , ( multijob , trigger another job or paramterized builds ) , console log rendering hyperlinknote of jobs has correct text but href value redirects to incomplete job url .",1590832824,"call setusezip64 ( zip64mode.asneeded ) . <nl> * issue , support 0+gb files in zip ( ) . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.932691216468811
elastic_elasticsearch/71490,"refactor empty role marker in autoscaling . <nl> some autoscaling deciders can apply to policies that specify an empty <nl> set of roles . this is useful for testing . today this is done by a <nl> special empty marker role which can be included in the list of roles <nl> that the decider supports . that marker is checked for when a policy that <nl> specifies an empty set of roles is encountered . this commit refactors <nl> this so that there is an interface method for answering the same <nl> question that implementors can override . <nl> we make this change to support removing the ability to plugin roles . <para-sep> whether or not the decider applies to a policy that specifies an empty set of roles . the default implementation is false , as it is expected that most deciders will apply to specific roles . the application of a policy that specifies an empty set of roles is useful for testing .",some autoscaling deciders can apply to policies that specify an empty a set of roles . this is useful for testing . today this is done by a special empty marker role which can be included in the list of roles that the decider supports . that marker is checked for when a policy that specifies an empty set of roles is encountered . this commit refactors this so that there is an interface method for answering the same question that implementors can override . <nl> we make this change to support removing the ability to plugin roles .,1617904447,"we currently create the .async-search index if necessary before performing any action ( index , update or delete ) . truth is that this is needed only before storing the initial response . the other operations are either update or delete , which will anyways not find the document to update/delete even if the index gets created when missing . this also caused failures as we were trying to delete the document twice from the .async-search index , once from and once as a consequence of the search task being completed . the latter may be called after the test",0.9403486251831055
vespa-engine_vespa/16065,do n't propagate exceptions out of listener implementations <cm-sep> add additional fields to connection log <para-sep> todo decide on handling of connection upgrade where old connection object is closed and replaced by a new ( e.g for proxy-protocol auto detection ),i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610714909,- a report can be patched to the node repository by using nodeattributes and <nl> noderepository.updatenodeattributes ( ) . <nl> - a report can be retrieved as a jackson class from nodespec and its <nl> nodereports .,0.9735997915267944
elastic_elasticsearch/71185,"setting to permit disabling of http client stats <para-sep> enables or disables collection of http client stats . <nl> when disabling , immediately clear client stats <nl> the listener code above should never throw <nl> http client stats should default to enabled <nl> after disabling , http client stats should be cleared immediately <nl> after disabling , http client stats should not track new clients <nl> after re-enabling , http client stats should now track new clients","in scenarios with high http client churn , it could be beneficial to disable collection of http client stats to reduce load . <nl> as this improves a not-yet-released feature .",1617288087,"the rollover action would perform a datastream rollover irrespective if the <nl> managed index was the write index or not . this could lead to multiple rollovers <nl> being executed eg . a manual call rolls over the datastream and later an ilm <nl> managed index , the previous write index , will do so too . there are similar <nl> scenarios possible if the step failed ( due to various reasons including <nl> ) and succeded when retried . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan .",0.962490439414978
apache_incubator-pinot/6129,"this pr includes a basic framework for us to build compatibility tests across releases <nl> the actual tests and a lot of code is yet to be written . <nl> the framekwork is set up so that we can run operations during a cluster upgrade , and <nl> detect incompatibility across releases . the value of the tests will be in the operations <nl> we choose to test during upgrades . <nl> configuration is done via yaml , and some sample yaml files and skinny classes have been <nl> provided . <para-sep> executes queries in the query file , and compares the results with the ones given in the expected results file todo : - if we use current timestamp for realtime tables , we may not be able to use pre-canned queries . <nl> segment operations : upload : generates a segment for a table from the data in the input file . uploads the segment , and verifies that the segments appear in externalview delete : deletes the segment from the table . todo : - maybe segment names can be auto-generated if the name is ' auto ' . - we can add segmentgeneration config file as an option also - we can consider supporting different readers , starting with csv . will help in easily scanning the data . <nl> produce produce events onto the stream , and verify that the number of rows in the tables increased by the number of rows produced . also , verify the segment state for all replicas of the tables todo : consider using a file-based stream , where ' pushing ' events is simply adding new files to a folder named after the ' stream ' . the implementation for the consumer would need to watch for new files and read them out . there could be one sub-folder per partition . this approach can save us handling kafka errors , etc . <nl> tableop creates , or deletes a table , or updates the table config . create verifies table exists , after it is created . delete verifies that the table does not exist , after the operation . update_config updates the table config update_schema updates the schema and executes a reload on the table . awaits reload status","this pr includes a basic framework for us to build compatibility tests across releases <nl> the actual tests and a lot of code is yet to be written . <nl> the framework is set up so that we can run operations during a cluster upgrade , and <nl> detect incompatibility across releases . the value of the tests will be in the operations <nl> we choose to test during upgrades . <nl> configuration is done via yaml , and some sample yaml files and skinny classes have been <nl> provided . <nl> issue 0 . <nl> a good description should",1602287562,submitting the pr for early review/feedback . <nl> here is how we want the end state of pinot distribution . <nl> - pinot-distribution <nl> - bin/ <nl> - lib/ <nl> - plugins/ <nl> - record_readers <nl> - pinot-avro/pinot-avro-shaded.jar <nl> - pinot-parquet/pinot-avro-parquet.jar <nl> - ... <nl> - connectors <nl> - pinot-.0/pinot-.0-shaded.jar <nl> - pinot-.0/pinot-.0-shaded.jar <nl> - ... <nl> - file-sytem <nl> - pinot-hdfs/pinot-hdfs-shaded.jar <nl> - pinot-s3/pinot-s3-shaded.jar <nl> - pinot-azure/pinot-azure-shaded.jar <nl> - .. . <nl> all launchers will take two parameters plugin.directory and plugin.includes . these two parameters can be set as a system property and pluginmanager will iterate recursively through the,0.9847116470336914
grpc_grpc-java/7559,create a synchronizationcontext inside xdsclient . <cm-sep> replace locks with synchronizationcontext for client side . <cm-sep> use xdsclient 's internal synchronizationcontext for server side . <para-sep> todo ( chengyuanzhang ) : better error handling .,the xdsclient will create its own synchronizationcontext internally . all of its work will be done inside that synchronizationcontext . watcher callbacks need to be synchronized with the watching party ( on client side this is done by scheduling the task back to client channel 's synchronizationcontext ) .,1603829160,"as a prerequisite , added to . <nl> has gone through a small refactor around the runnable , which makes it a little simpler .",0.9519628882408142
elastic_elasticsearch/71516,service accounts - update privileges for elastic/fleet-server,"this pr grants service account index privileges of for the index pattern . <nl> also allow indexing into index pattern similar to , and .",1617931101,this allows the step to move past the allocation check <nl> if the tier routing settings are manually unset . <nl> this helps a user unblock ilm in case a tier is removed ( ie . if the warm tier <nl> is decommissioned this will allow users to resume the ilm policies stuck in <nl> waiting for the warm nodes to become available and the managed <nl> index to allocate . this allows the index to allocate on the other available tiers ) .,0.9293087124824524
apache_flink/14563,"introduce bytesmultimap to support buffering records <para-sep> bucket area : pointer + hashcode . bytes 0 to 0 : a pointer to the record in the record area bytes 0 to 0 : key 's full 0-bit hashcode record area : the actual data in linked list records , a record has four parts : bytes 0 to 0 : len ( k ) bytes 0 to 0 + len ( k ) : key data bytes 0 + len ( k ) to 0 + len ( k ) : len ( v ) bytes 0 + len ( k ) to 0 + len ( k ) + len ( v ) : value data <nl> used to serialize hash map value into recordarea 's memorysegments . * / <nl> returns an iterator for iterating over the entries of this map . * / <nl> get the second hashcode based log2numbuckets and numbucketsmask2 <nl> a smaller bucket can make the best of l1/l2/l3 cache . <nl> the map will be expanded once the number of elements exceeds this threshold . * / <nl> the segments where the actual data is stored . * / <nl> used to serialize map key into recordarea 's memorysegments . * / <nl> used as a reused object when lookup and iteration . * / <nl> used as a reused object when retrieve the map 's value by key and iteration . * / <nl> used as a reused object which lookup returned . * / <nl> metric","introduce to support buffering records . <nl> - extract a common base class for and <nl> - update the code generation for the refactoring <nl> - introduce the class of . <nl> - the existing tests and added a . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths (",1609863198,"# # what is the purpose of the change . <nl> integrate file compaction to hive connector . <nl> - introduce <nl> - introduce hivecompactreader.java <nl> - integrate file compaction to hivetablesink and refactor it . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components )",0.9858220219612122
hazelcast_hazelcast/18140,"fixes delegatingcompletablefuture <nl> and subclass clientdelegatingfuture behaviour <nl> when hazelcastserializationexception is thrown : . <nl> - serialization exception is now properly wrapped <nl> in ( execution|completion ) exception when thrown <nl> from get , getnow or join methods . <nl> - whencomplete , handle and exceptionally <nl> can act on the hazelcastserializationexception . <nl> ( cherry picked from commit sha ) <para-sep> deserialize to ensure no hazelcastserializationexception occurs <nl> a deserialization failure makes this future being considered to complete exceptionally , therefore futures from dependent stages will be completed with a hazelcastserializationexception ( unless the dependent stage transforms the outcome ) . <nl> if super is completed , then value deserialization has already happened , so we know if this future is completed exceptionally <nl> otherwise , check the delegate future : if that one is done , try resolve the completion value <nl> deserialize to ensure no hazelcastserializationexception occurs <nl> test delegatingcompletablefuture dependent actions when these fail with hazelcastserializationexception .","fixes delegatingcompletablefuture <nl> and subclass clientdelegatingfuture behaviour <nl> when hazelcastserializationexception is thrown : . <nl> - serialization exception is now properly wrapped <nl> in ( execution|completion ) exception when thrown <nl> from get , getnow or join methods . <nl> - whencomplete , handle and exceptionally <nl> can act on the hazelcastserializationexception . <nl> ( cherry picked from commit sha ) .",1612349653,"getcacheentryrequest is used by mc to browse cache entries . currently , <nl> the entryprocessor it uses is not serializable and does n't work for <nl> keys on remote members , causing deserialization failure on the member <nl> when it tries to get the entry from another member . this commit makes <nl> both the entryprocessor used and its return type serializable .",0.9666141867637634
OpenAPITools_openapi-generator/7587,"custom template in java example <cm-sep> fallback to templates using classpath rather than os-specific paths . <nl> previous checks would cause logic in windows to return early , for <nl> built-in templates only . this reorganizes and simplifies the ordering <nl> behavior . <cm-sep> match classpath check in workflowsettings with that in templatemanager <para-sep> hack : this duplicates templatemanager.getcpresourcepath a bit . we should probably move that function to core . <nl> windows users may pass path specific to os , but classpath must be ' / ' separators <nl> we can freely set to templatedir here and allow templating to manage template lookups <nl> automatically generated by the openapi generator * <nl> for whatever reason , resource path templates fail in this test in windows <nl> note that in java 0+ , this anything matching this condition could fail due to illegal reflective access by org.codehaus.groovy.reflection.cachedclass and cause tests to fail . this is more to document for engineers . <nl> automatically generated by the openapi generator * <nl> note that in java 0+ , this anything matching this condition could fail due to illegal reflective access by org.codehaus.groovy.reflection.cachedclass and cause tests to fail . this is more to document for engineers . <nl> a base test class where we can add helper methods and whatnot <nl> looks for user-defined file or classpath supports template dir which refers to local file system or custom path in classpath as defined by templatedir <nl> check the supplied template main folder for the file file.separator is necessary here as the file load is os-specific looks for user-defined file or classpath supports template dir which refers to local file system or custom path in classpath as defined by templatedir <nl> only looks for those files in classpath as defined by embeddedtemplatedir only looks for those files in classpath as defined by embeddedtemplatedir <nl> generator should report a library templated file as a generated file <nl> generated file should exist on the filesystem after generation <nl> generated file should contain some expected text <nl> generator should report readme.md as a generated file <nl> generated file should exist on the filesystem after generation <nl> readme.md should contain some expected text <nl> create custom template <nl> generator should report a library templated file as a generated file <nl> generated file should exist on the filesystem after generation <nl> generated file should contain our custom templated text","* updates workflowsettings to duplicate the logic which checks for classpath files ( previously , would break on windows , or on all os if template directory did not match structures in openapi-generator 's resource directory ) <nl> * updates java-client.xml in maven example to allow spot-check of property <nl> * fixes classpath check in template manager to work on windows for paths defined in property of a codegen config <nl> * adds tests for template resource locator . <nl> the maven plugin follows a different flow for template directory versus resource loaded templates . i 'd tried reproducing the",1601756229,"when you use the boolean option with the generator , there is a problem with the paths . <nl> example spec : tags.yaml ( added to this pr as test case ) . <nl> then the endpoints are : . <nl> they are driven by the tags ( and tags name ) . <nl> they should be as specified in the section : . <nl> this pr introduces a new variable accessible in the jaxrs templates : . <nl> this is because the when tags are used can not be used in the top level annotation value . <nl> contains",0.9629197716712952
Graylog2_graylog2-server/8952,add grants support for eventnotifications . <nl> fix a few wrong checks,also fix a few wrong checks .,1599834615,"the frontend needs to know which entities a user <nl> currently owns . this is expressed with a new permissions <nl> type , that is incompatible with the existing wildcardpermission . <nl> introduce a new field into the usersummary object . <nl> the serialized format of a grnpermission is . <nl> e.g . : .",0.9753589034080505
apache_incubator-pinot/6108,[ te ] datalayer refactor . reorganizing guice module inside daoproviderutil . <nl> changes <nl> - moved datasourcemodule outside to thirdeyepersistencemodule <nl> - refactored module logic to leverage guice to inject dependencies <nl> - making all services singletons on guice level instead of manual handling <nl> - moved unit test from to check code sanity . <nl> no logic changes . <para-sep> create schema for default database <nl> tmp file gets deleted automatically * / <nl> pool size configurations <nl> when returning connection to pool <nl> timeout before an abandoned ( in use ) connection can be removed . <nl> create schema <nl> find by id,changes <nl> - moved outside to <nl> - refactored module logic to leverage guice to inject dependencies <nl> - making all services singletons on guice level instead of manual handling <nl> - moved unit test from to <nl> - promoting to be a top level dependency in <nl> - removing from pom since class has been moved to <nl> - removing class since it is now redundant . <nl> no behavior changes .,1601931909,changes : <nl> * pushed the responsibility of updating watermark/vectorclocks and updatingbaseline values outside of the detectionemailalerter up to the detectionalerttaskrunner . vectorclocks will be updated after we send out all the alerts . <nl> * moved vectorclock utilities under alertutils .,0.943501889705658
quarkusio_quarkus/15577,fix confusion between native image name and executable name . <nl> this confusion broke the native executable build on windows in <nl> version.final . <cm-sep> trigger a sample native executable build on windows,draft until it 's green on my fork .,1615294495,"some typos , and reduce logging .",0.8425785899162292
neo4j_neo4j/11337,close page cache instances and shutdown test dbs . <nl> close leaked not closed page caches . <nl> prevent batch importer to create page cache when directory lock ca n't be obtained . <nl> close test databases that were not shutdown before . <para-sep> when opening and pruning all except the one we test <nl> then only the one we kept should have data in it,close leaked not closed page caches . <nl> prevent batch importer to create page cache when directory lock ca n't be obtained . <nl> close test databases that were not shutdown before .,1521653430,- close statements in tests <nl> - close statements in built in procedures,0.9445075392723083
apache_ignite/8820,": implement acquireandexecute utility method . <nl> this commit introduces a new method which takes in a semaphore and a callable task , acquires the <nl> semaphore , executes the task and returns a future immediately . <nl> the semaphore is released when the future completes . <para-sep> acquires the given semaphore , executes the given callable and schedules the release of permits asynchronously","this commit introduces a new method which takes in a semaphore and a callable task , acquires the <nl> semaphore , executes the task and returns a future immediately . <nl> the semaphore is released when the future completes .",1613987594,added new cache metric : <nl> - - true if index rebuilding is in progress . <nl> added new field into : <nl> - - true if index rebuilding is in progress .,0.9355778694152832
confluentinc_ksql/6336,"fail joins where the key format differs . <nl> add code to throw a useful error message if a join has incompatible key formats . qtt test added too . <para-sep> note : we deliberately do not fail if one side is hopping and the other is tumbling , or fail on different window sizes . this is because we only fail if the _schema_ of the key is different . neither of these differences make the schemas different . <nl> when : <nl> when : <nl> then : <nl> when : <nl> when : <nl> then : <nl> when : <nl> when : <nl> then : <nl> when : <nl> when : <nl> then : <nl> when : <nl> when : <nl> then : <nl> when : <nl> when : <nl> then : did not throw <nl> when : <nl> when : <nl> then : did not throw",add code to throw a useful error message if a join has incompatible key formats . qtt test added too . <nl> usual .,1601499180,"the next step in the saga , this validates that the upgrades are compatible from a schema perspective . it does not yet implement the physical plan check to make sure that we allow the topology evolution . <nl> more unit testing .",0.9719183444976807
vespa-engine_vespa/16338,add histogram buckets for hits_per_query metric . <cm-sep> add histogram buckets for totalhits_per_query metric . <cm-sep> whitelist new metrics for the 'vespa ' consumer .,"please review carefully . is it necessary to declare the values explicitly , and is logging of the mean for totalhits desirable ? <nl> i have verified in a docker container , that the metrics will be output from the metrics-proxy .",1612273115,"i do n't think there is any need to call orchestrator if there are no active nodes , but there could be some corner case here i have n't thought through .",0.8831357955932617
apache_incubator-pinot/5409,"faster bit unpacking <para-sep> read dictionaryid for a particular docid <nl> array based api to read dictionaryids for a contiguous range of docids starting at startdocid for a given length <nl> array based api to read dictionaryids for an array of docids which are monotonically increasing but not necessarily contiguous . so even though the docids in docids [ ] array are monotonically increasing , they may not necessarily be contiguous . they can have gaps . this api although works on docids with gaps , it still tries to leverage the underlying bulk contiguous api as much as possible to get benefits of vectorization . for a given docids [ ] array , we determine if we should use the bulk contiguous api or not by checking if the length of the array is > = 0 % of actual docidrange ( lastdocid - firstdocid + 0 ) . this sort of gives a very rough idea of the gaps in docids . we will benefit from bulk contiguous read if the gaps are narrow implying fewer dictids unpacked as part of contiguous read will have to be thrown away/ignored . if the gaps are wide , a higher number of dictids will be thrown away before we construct the out array this method of determining if bulk contiguous should be used or not is inaccurate since it is solely dependent on the first and last docid . however , getting an exact idea of the gaps in docids [ ] array will first require a single pass through the array to compute the deviations between each docid and then take mean/stddev of that . this will be expensive as it requires pre-processing . to increase the probability of using the bulk contiguous api , we make this decision for every fixed-size chunk of docids [ ] array . <nl> use the bulk api . it takes care of populating the values array correctly by throwing away the extra dictids <nl> use the single read api <nl> use the single read api <nl> decode integers starting at a given index . this is efficient because of simplified bitmath . <nl> decode integers for a contiguous range of indexes represented by startindex and length . this uses vectorization as much as possible for all the aligned reads and also takes care of the small byte-sized window of unaligned read .","couple of improvements have been done for bit-unpacking . <nl> - use hand-written unpack methods for power of 0 ( 0 , 0 , 0 , 0 , 0 , 0 ) number of bits used to encode the dictionaryid . the hand-written methods are faster than generic due to simplified bit math . <nl> - amortize the overhead of function calls . <nl> right now , the new code is n't yet wired into existing bit reader and writer . couple of follow-ups will be coming soon : . <nl> - evaluate this optimization for non power of 0",1589842766,"changed fixedbytesinglecolumnmultivaluereaderwriter so that the header sections also expands like the data <nl> section , so that we do n't have to allocate data for max number of rows in the beginning . <nl> for now , the same allocation is maintained so that we do n't see any change in the behavior in production . <nl> this , and the next few prs should help us limit consumption by memory ( instead of by number of rows ) or time , <nl> making it easier to configure real-time service in pinot .",0.9368652701377869
apache_shardingsphere/10253,add alter system definition <cm-sep> modify code <cm-sep> change rules <para-sep> alter system statement . <nl> oracle alter system statement . <nl> alter system statement assert . <nl> assert alter system statement is correct with expected parser result . <nl> alter system statement test case .,i 've added sql definition for alter system . please check it . <nl> changes proposed in this pull request : <nl> - added sql definition for <nl> - added test cases for,1620189016,changes proposed in this pull request : <nl> - use spi for datasources check,0.9532200694084167
elastic_elasticsearch/70860,"runtimefield.parser currently requires a bifunction but in reality parsercontext can be made an argument to the method that creates the runtime field itself , so that the bifunction becomes a function . at the same time , buildfieldtype can be renamed to createruntimefield ( following the split between runtimefield and the corresponding mappedfieldtype . <nl> additionally , the creation logic for all of the currently supported runtime fields is the same : if the script is not provided , initialize the script factory with the predefined script that extract values from source , otherwise compile the script and create the runtime field . this logic can be shared by refactoring the runtimefield.builder . <nl> these steps simplify things , and will help with the creation of the runtime object field . in fact , more logic will be introduced around the creation of a runtime field that can this way be shared instead of repeated for each field type .","runtimefield.parser currently requires a bifunction but in reality parsercontext can be made an argument to the method that creates the runtime field itself , so that the bifunction becomes a function . at the same time , buildfieldtype can be renamed to createruntimefield ( following the split between runtimefield and the corresponding mappedfieldtype . <nl> additionally , the creation logic for all of the currently supported runtime fields is the same : if the script is not provided , initialize the script factory with the predefined script that extract values from source , otherwise compile the script and create the",1616667156,"this pr refactors all spatial field mappers to a common that implements shared parameter functionality ( e.g. , , ) and provides a common framework for overriding type parsing , and building in xpack . common shape functionality is implemented in a new that is reused and overridden in , , , and , respectively . this abstraction provides a reusable foundation for adding new xpack features ; such as coordinate reference system support .",0.9607829451560974
elastic_elasticsearch/72064,"add , a space-efficient variant of . <nl> this adds a new field , which indexes the same data as a <nl> field that has and and uses the <nl> for positional queries like . unlike , this field does n't <nl> support scoring . <para-sep> > , the traditional field type for full-text content <nl> > , a space-optimized variant <nl> term queries are ok <nl> disable scoring <nl> disable scoring <nl> this query matches and scores the same way as the wrapped query . <nl> create an approximation for the given query . the returned approximation should match a superset of the matches of the provided query . <nl> only a prefix , approximate with a prefix query <nl> a combination of a phrase and a prefix query , only use terms of the phrase for the approximation <nl> similarity that produces the frequency as a score . <nl> no need to ever look at the _source for non-scoring term queries <nl> do n't cache queries that may perform linear scans <nl> todo what is a right value ? defaults to a high-ish value so that it likely runs last . <nl> a high number since we need to parse the _source <nl> not using matchesprovider and valuefetcherprovider , which do n't identify this source but are only used to avoid scanning linearly through all documents <nl> not using matchesprovider and valuefetcherprovider , which do n't identify this source but are only used to avoid scanning linearly through all documents <nl> term query with missing term <nl> sloppy phrase query <nl> phrase query with no matches <nl> phrase query with one missing term <nl> sloppy multi phrase query <nl> multi phrase query with no matches <nl> multi phrase query with one missing term <nl> sloppy multi phrase prefix query <nl> multi phrase prefix query with no matches <nl> multi phrase query with one missing term <nl> sloppy span near query <nl> span near query with no matches <nl> span near query with one missing term <nl> same test , but with a bad approximation now","this adds a new field , which indexes the same data as a <nl> field that has and and uses the <nl> for positional queries like . unlike , this field does n't <nl> support scoring .",1619074336,this change adds high level rest client support for index templates v2 . <nl> added > non-issue label as component templates are still behind feature flag,0.9864194989204407
elastic_elasticsearch/71677,"improve snapshotinfo serialization tests . <nl> today we have no tests that directly verify that <nl> correctly round-trips through its in-repository -based <nl> representation . we do have tests that verify that it correctly <nl> round-trips through the wire format , but these tests always use an empty <nl> collection for . <nl> this commit strengthens the wire format round-trip tests to use <nl> nontrivial , and generalizes these tests to also verify <nl> that the representation is faithful .","today we have no tests that directly verify that <nl> correctly round-trips through its in-repository -based <nl> representation . we do have tests that verify that it correctly <nl> round-trips through the wire format , but these tests always use an empty <nl> collection for . <nl> this commit strengthens the wire format round-trip tests to use <nl> nontrivial , and generalizes these tests to also verify <nl> that the representation is faithful .",1618394959,"documentmapperparser parses xcontent mappings into a documentmapper , through documentmapper.builder . most of the work is done to construct a mapping instance , that then gets provided to the documentmapper . <nl> moving forward , we would like to rely more on mapping and less on the entire documentmapper , but currently it is cumbersome to create mapping without creating an instance of documentmapper . <nl> this commit removes documentmapperparser and documentmapper.builder in favor of a new class called mappingparser that given xcontent mappings returns a mapping instance , which can be used on its own or provided to documentmapper",0.9735801815986633
elastic_elasticsearch/72006,fix wildcard intervals when prefixes are indexed .,wildcard intervals on fields mistakenly use the sub prefix field . <nl> since this is a non-released bug .,1619008577,setting to a value larger than 0 causes the operation to fail . <nl> proposed change : read the number of replica shards from the template object : . <nl> this set of changes reads the index.number_of_replicas value from the template body ( defaults to 0 - no replicas- ) value when setting an index template . this enables the index.wait_for_active_shards value to be interpreted correctly . <nl> * read number of replicas from template <nl> * added tests to validate with default and specified replicas <nl> * rename replicas variable .,0.9242554903030396
apache_beam/12618,changed snowflakeio parameters to valueprovider and moved most of functionalities to expand methods <cm-sep> changed quotation mark to value provider variable <cm-sep> added required pipeline options,changed basic types in snowflakeio to valueprovider and refactored necessary functionalities due to support dataflow templates,1597778019,"thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9846147894859314
apache_druid/10551,remove build in kafka consumer config : <cm-sep> modify druid docs of kafka indexing service <para-sep> insert 0 records initially,"and open source druid ( from version to version ) only can support to consume messages from kafka version.x or better . and when consume kafka version , it throws unsupportedversionexception : . <nl> and as the druid docs says . <nl> the root cause of this exception ( sdk version + kafka version ) is hard-coded ‘ props.put ( ' isolation.level ' , ' read_committed ' ) ; ’ in the ‘ kafkaconsumerconfigs ’ which is unnecessary . <nl> this pr adds a new config named in . default is true , druid can consume kafka topics consumetransactionally same",1604396432,aggregators close ( ) method is not called when onheapincrementalindex tear down .,0.9055653214454651
apache_camel/5194,": add initial manual kafka offset <cm-sep> : add manual kafka offset capability to vertx kafka <para-sep> set headers for the manual offsets commit <nl> note : to take full control of the offset committing , you may need to disable the kafka consumer default auto commit behavior by setting 'enableautocommit ' to 'false ' . <nl> can be used for forcing manual offset commit when using kafka consumer . <nl> commit offsets to kafka <nl> creates a new instance <nl> noop <nl> noop <nl> noop <nl> clean all test topics <nl> we disable the default autocommit and we take control on committing the offsets first step : we send first 0 records to kafka , we expect our consumer to receive them and commit the offsets after consuming the records through manual.commit ( ) ; <nl> second step : we shut down our route , we expect nothing will be recovered by our route <nl> third step : while our route is stopped , we send 0 records more to kafka test topic <nl> fourth step : we start again our route , since we have been committing the offsets from the first step , we will expect to consume from the latest committed offset e.g from offset 0 <nl> give some time for the route to start again <nl> whether to allow doing manual commits via org.apache.camel.component.vertx.kafka.offset.vertxkafkamanualcommit . if this option is enabled then an instance of org.apache.camel.component.vertx.kafka.offset.vertxkafkamanualcommit is stored on the exchange message header , which allows end users to access this api and perform manual offset commits via the kafka consumer . note : to take full control of the offset committing , you may need to disable the kafka consumer default auto commit behavior by setting 'enableautocommit ' to 'false ' . the option is a : & lt ; code & gt ; boolean & lt ; /code & gt ; type . default : false group : consumer <nl> factory to use for creating org.apache.camel.component.vertx.kafka.offset.vertxkafkamanualcommit instances . this allows to plugin a custom factory to create custom org.apache.camel.component.vertx.kafka.offset.vertxkafkamanualcommit instances in case special logic is needed when doing manual commits that deviates from the default implementation that comes out of the box . the option is a : & lt ; code & gt ; org.apache.camel.component.vertx.kafka.offset.vertxkafkamanualcommitfactory & lt ; /code & gt ; type . group : consumer ( advanced ) <nl> whether to","this will add the capability to handle manual offsets on the user side . api is very similar to camel-kafka , with difference it does n't yet support state repo .",1615377914,the key_shared subscription type was added in pulsar version as a beta feature . this pr is to add the capability to camel due to its potential usefulness . it 's already possible to set the pulsar message key through exchange headers .,0.9515483379364014
vespa-engine_vespa/16437,"allow only one node down at a time for cluster controller clusters . <nl> if we are replacing nodes and have 0 old and 0 new nodes in a cluster , <nl> allowing 0 per cent down would lead to 0 being allowed to go down . <nl> when deploying to remove the 0 old nodes there might be ( for a short time ) <nl> config that says that there should be 0 nodes in the zookeeper cluster . <nl> this mean 0 of them need to be up for the cluster to have a quorum . <nl> this will not work in this case .","if we are replacing nodes and have 0 old and 0 new nodes in a cluster , <nl> allowing 0 per cent down would lead to 0 being allowed to go down . <nl> when deploying to remove the 0 old nodes there might be ( for a short time ) <nl> config that says that there should be 0 nodes in the zookeeper cluster . <nl> this mean 0 of them need to be up for the cluster to have a quorum . <nl> this will not work in this case .",1612792758,"as we changed to add a 0 % summary cache some time ago , we should also change default read to directio . <nl> that was an oversight at the time .",0.8966209888458252
ballerina-platform_ballerina-lang/23500,"add initial imple of the internal compiler diagnostic representation . <nl> this is the initial version . we 'll be adding more members soon <cm-sep> add internal represenation of a diagnostic attached to nodes <cm-sep> add a mechanism that uniquly identifies a diagnostic <cm-sep> introduce a class to represent the severity of a diagnostic <cm-sep> introduce a mechanism to include additional info about a diagnostic <cm-sep> introduce a mechansim to represent the abstract shape of an diagnostic . <nl> this shape is independent of the location and message arguments . <cm-sep> add the initial diagsnotic api <cm-sep> add an imple of diagnostic to represent syntax errors <cm-sep> rename a token kind to fix the consistency issues <cm-sep> rename a token kind to fix the consistency issues <cm-sep> update stnode to store syntax diagnostics . <nl> here is a summary of the design : <nl> - each stnode instance will store its syntax diagnostics . <nl> - each stnode instnace inherits the diagnostic flag from its children <cm-sep> update stmissingtoken to be created with diagnostics <cm-sep> enrich node api with methods that expose diagsnostic information <cm-sep> update token with methods to expose diagnostics <cm-sep> update nonterminalnode with methods to expose diagnostics <cm-sep> update syntaxtree with methods to get diagnostic information <cm-sep> store missing token errors in the missing token itself . <nl> this is the initial implementation <para-sep> a diagnostic represents a compiler error , a warning or a message at a specific location in the source file . <nl> a sample usage would be to record all symbol information related to duplicate symbol error . <nl> represents a diagnostic code . diagnostic code uniquely identifies a diagnostic . <nl> represents a diagnostic error code . <nl> todo figure out an order of these error codes tokens <nl> keywords <nl> represents a diagnostic warning code . <nl> todo we need a generic location here . todo node location is associated with a node . <nl> todo fix the following conversion <nl> todo todo severity comes from the error code <nl> todo fix this <nl> todo following way of getting the token is suboptimal todo try this code and see ; function ( int s ) return error ? { } <nl> todo seems like we can get these tokens from a cache <nl> return from the function if at lest one child has diagnostics . <nl> internal representation of diagnostic that",each internal node maintains a flag to indicate whether there exists diagnostics attached to them or not . a parent internal node inherits this flag from its child nodes . <nl> we need to visit each place where a syntax error is reported in the new parser and migrate those places to use the new diagnostics api .,1590482216,"add support for creating new structured types with ballerina , and use those types everywhere in the ballerina code . <nl> eg : below is a sample for creating a new type 'person ' and using that type inside a ballerina function .",0.9854099750518799
vespa-engine_vespa/15898,always set 'is-master ' metric . remove 'master-change ',only setting on leadership change might hide bad states . <nl> is unexposed/unused,1609772712,previous fix was not sufficient for always writing new version . <nl> previously could risk that state transition grace period would elide <nl> write to zookeeper if state changes happened within previous grace <nl> period .,0.8765749335289001
quarkusio_quarkus/15969,"fix signatures of uniinvoker . <nl> ( cherry picked from commit sha ) <cm-sep> allow any image to be used in devservices . <nl> we trust the user that they have supplied an appropriate image . <nl> ( cherry picked from commit sha ) <cm-sep> allow adding multiple realms . <cm-sep> fix jbang dev mode . <nl> ( cherry picked from commit sha ) <cm-sep> minor keycloak-authorization code and doc updates . <nl> ( cherry picked from commit sha ) <cm-sep> update oidcconfigurationmetadata to return the scopes and minor error log updates . <nl> ( cherry picked from commit sha ) <cm-sep> update to keycloak version . <nl> ( cherry picked from commit sha ) <cm-sep> introduce utility jsonextensioncatalog.addcategory . <nl> for code simplification purposes . <nl> ( cherry picked from commit sha ) <cm-sep> register keycloakpolicyenforcerauthorizer if both oidc and policy authorizer are enabled . <nl> ( cherry picked from commit sha ) <cm-sep> fix quarkustestresourcelifecyclemanager bug . <nl> ( cherry picked from commit sha ) <cm-sep> add a more informative error message when dockerfile is unavailable during s2i . <nl> ( cherry picked from commit sha ) <cm-sep> add opentelemetry and jaeger exporter extensions with native support . <nl> ( cherry picked from commit sha ) <para-sep> jaeger spanexporter support . jaeger spanexporter support is enabled by default . <nl> the jaeger endpoint to connect to . defaults to if unset . <nl> the maximum amount of time to wait for the collector to process exported spans before an exception is thrown . a value of will disable the timeout : the exporter will continue waiting until either exported spans are processed , or the connection fails , or is closed for some other reason . <nl> only create the jaegergrpcspanexporter if an endpoint was set in runtime config <nl> create batchspanprocessor for jaeger and install into lateboundbatchspanprocessor <nl> find all known spanexporters and spanprocessors <nl> todo this needs modification to use conditional behaviors when it 's present <nl> should not be reached : dump what was injected if it somehow passed <nl> should not be reached : dump what was injected if it somehow passed <nl> opentelemetry support . opentelemetry support is enabled by default . <nl> build / static runtime config for tracer * / <nl> set tracer provider if present <nl> add propagators . //todo need a way to handle this with config <nl> not","please do n't merge , i will merge it myself .",1616530196,... and finally mark the hibernate search extension as stable .,0.9857091307640076
apache_druid/10432,"add vectorizevirtualcolumns query context parameter <para-sep> constants and identifiers are supported for any column type is supported for numeric and string types math operators : , , , , , are supported for numeric types comparison operators : , , , , , are supported for numeric types math functions : , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , are supported for numeric types time functions : ( with constant granularity argument ) is supported for numeric types other : is supported for numeric and string types","this context parameter is layered on top of , which also must be set to ( the default ) for a query to use vectorized engines , but by default is set to to disable vectorization selectively for only queries with virtual columns by default . <nl> vectorizing virtual columns can be enabled by default by adding . <nl> to the",1600936724,"now that is being updated , it would make it easier for users to update to if they could easily revert to old behavior without having to update all segmentmetadataqueries they use . <nl> suggest not only providing an option to revert to old behavior but also be able to specify their own defaultanalysistypes using .",0.9646571278572083
jenkinsci_jenkins/4845,minor refactorings either for performance or readybility,minor refactorings either for performance or readability . <nl> * to <nl> * to <nl> * missing <nl> * diamond operator <nl> * added a break to a for loop . <nl> * internal : n/a,1594560874,* no tests <nl> * changelogs are not required .,0.8805654644966125
vespa-engine_vespa/15277,"fix thread lock detection bug . <nl> the effect of the bug was that a deadlock would be reported as long as the <nl> current thread t0 that tries to acquire the zk path p0 is in the following <nl> situation : <nl> 0. thread t0 tries to acquire zk path p0 , held by t1 . <nl> 0. thread t1 tries to acquire zk path p1 , held by t2 . <nl> instead , t2 would need to equal t0 . or , <nl> 0. thread t2 tries to acquire zk path p2 , held by t3 = one of ( t0 , t1 ) . <nl> etc . <para-sep> reentry","the effect of the bug was that a deadlock would be reported as long as the <nl> current thread t0 that tries to acquire the zk path p0 is in the following <nl> situation : <nl> 0. thread t0 tries to acquire zk path p0 , held by t1 . <nl> 0. thread t1 tries to acquire zk path p1 , held by t2 . <nl> instead , t2 would need to equal t0 . or , <nl> 0. thread t2 tries to acquire zk path p2 , held by t3 = one of ( t0 , t1 ) .",1605090838,"allowing preinstall should not be default for vespa bundles , as some of them are used as application bundles . <nl> the name change is to make sure that developers do n't want to use it .",0.8598149418830872
apache_pulsar/8907,"motivation . <nl> fix the issue when uploading a package , it will show update metadata failed . <nl> modifications . <nl> - fix the issue <nl> - enabel the integration tests for this","motivation . <nl> fix the issue when uploading a package , it will show update metadata failed . <nl> modifications . <nl> - fix the issue <nl> - enable the integration tests for this",1607646917,clarifying the code in the . <nl> removes the unnecessary argument in the constructor . <nl> removes magic values . <nl> no functional changes .,0.8940996527671814
apache_pulsar/9553,"motivation . <nl> we need the same fix on the branch version . so <nl> we do the same fix on the branch version . <para-sep> start local bookkeeper ensemble <nl> start brokers <nl> worker talks to local broker <nl> inherit broker authorization setting <nl> client in worker will use this config to authenticate with broker <nl> inherit super users <nl> sleep until pulsarservices [ 0 ] becomes leader , this way we can spy namespace bundle assignment easily .",motivation . <nl> we need the same fix on the branch version . so <nl> we do the same fix on the branch version .,1612940899,in some cases it 's desirable to throttle the number of http requests made against brokers to avoid impact from either malign attacks or misconfigured clients . <nl> this add a very simple servlet filter and could be later expanded with more sophisticated logic .,0.9369722604751587
apache_incubator-pinot/5782,"enhancing the segment replacement api . <nl> 0. chekcing online state from the ev when updating <nl> the segment lineage . <nl> 0. trigger the routing table rebuild to brokers when <nl> updating the segment lineage . <para-sep> this ( helix ) message is sent from the controller to brokers when a request is received to rebuild the routing table . when the broker receives this message , it will rebuild the routing table for the given table . note : changing this class to include new fields is a change in the protocol , so the new fields must be made optional , and coded in such a way that either controller , broker or server may be upgraded first . <nl> give it infinite time to process the message , as long as session is alive <nl> set the pinot specific fields note : do not use helix fields ' resource_name ' and ' partition_name ' for them because these 0 fields can be overridden by helix while sending the message <nl> constructor for the receiver . <nl> todo : make this configurable <nl> send table config refresh message to brokers <nl> send message with no callback and infinite timeout on the recipient <nl> todo : would be nice if we can get the name of the instances to which messages were sent <nl> check that all the segments from 'segmentsto ' exist in the table <nl> check that all the segments from 'segmentsto ' become online in the external view <nl> if the segment lineage metadata is successfully updated , we need to trigger brokers to rebuild the routing table because it is possible that there has been no ev change but the routing result may be different after updating the lineage entry .",0. chekcing online state from the ev when updating <nl> the segment lineage . <nl> 0. trigger the routing table rebuild to brokers when <nl> updating the segment lineage .,1596173853,currently helix will derived hostname/port from the server instanceid string ( as demonstrated in the test _testdisablelogicalserverid ( ) _ ) if the instance id is set in server config . this pr decouples the configuration of server instance id and hostname/port . this allows pinot user to set the following field independently : . <nl> - instance id . <nl> - server_netty_host . <nl> - server_netty_port . <nl> this is done by overwriting the helix zk data after server connects to the zk cluster . it is hidden behind a flag now so the current use cases will not,0.9747108221054077
hazelcast_hazelcast/18429,made the current java version retrievable from javaversion enum,this pr changes the visibility of constant . the is not part of public api ( its an internal enum ) .,1616493675,"wrap into equal connections in firewallingserver . <nl> each call to wraps the <nl> connection into a new instance of . jet , to <nl> guarantee exactly-once and in-order delivery , checks , that the <nl> connection did n't change and restarts the job , if it did . this pr adds <nl> an method so that even though the connection instance is <nl> different , it 's equal if the delegate is the same . <nl> also contains some unrelated grammar fixes .",0.7528629899024963
apache_pulsar/9190,fix broker and functions-worker authentication compatibility .,"the is boxed type in for solve broker and functions-worker authentication compatibility , so should not be in . <nl> - commented out in",1610446595,the metrics for the reader backlog keep increasing when data is dropped because the reader cursor only moves on the next read attempt . <nl> instead we should proactively move the cursor forward on the first valid ledger .,0.9015450477600098
apache_pulsar/9482,fixes 0 <cm-sep> additional docs for kafka autooffsetreset,the kafka source sets auto.offset.reset to ' earliest ' . this means all old messages from kafka are produced to pulsar . often is it desirable to start form the present location ' latest ' . <nl> the option is set after the user config has been loaded so it can not be changed : <nl> source code link . <nl> added an autooffsetreset option to kafkasourceconfig . <nl> ( please pick either of the following options ) . <nl> this change added tests and can be verified as follows : <nl> added to unit test and verified behaviour .,1612446640,"but pulsar-client should be handling any failure and client should not have to exist from the process . so , make perf-producer continue on publish-failure and also record message failure rate .",0.8518834710121155
apache_flink/14371,"fix method misuse in dynamictablefactorytest <para-sep> pk can be defined on cdc table , should pass","( for example : ) <nl> - use correct method to get options for creating table . <nl> ( please pick either of the following options ) . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects",1607765788,"this fix the unstable test with ' topic 'changelog_topic ' already exists ' exception . <nl> currently is executed multiple times because the super class is with different formats . the kafka cluster has a known issue that the topic cleanup is not guarenteed to take effect immediately . <nl> however , this case only need to be executed once . thus , we update the test to only execute when it is json format . <nl> manually run in my local for hundreds of times . <nl> - dependencies ( does it add or upgrade a dependency ) :",0.8163945078849792
apache_kafka/9668,"add test for repartition/source-topic/changelog optimization . <nl> if topology optimization is enabled , kafkastreams does not create store <nl> changelog topics but re-uses source input topics if possible . however , <nl> this optimization should not be applied to internal repartition topics , <nl> because those are actively purged .","if topology optimization is enabled , kafkastreams does not create store <nl> changelog topics but re-uses source input topics if possible . however , <nl> this optimization should not be applied to internal repartition topics , <nl> because those are actively purged .",1606851531,loop call consumer.endoffsets throw timeoutexception : failed to get offsets by times in 30000ms after a leader change,0.9286484718322754
apache_incubator-pinot/5707,"allow pinot to accept query with from clause in the format of . <para-sep> check if table is in the format of [ database_name ] . [ table_name ] . only update tablename in querysource if there is no existing table in the format of [ database_name ] . [ table_name ] , but only [ table_name ] . <nl> check if table is in the format of [ database_name ] . [ table_name ] <nl> update table name if there is no existing table in the format of [ database_name ] . [ table_name ] but only [ table_name ] <nl> use tablecache to check case insensitive table name . <nl> use routingmanager to check case sensitive table name . <nl> by default 0 rows will be returned , so use high limit","for case sensitive mode ( default ) , use routingmanager to check table existence . <nl> for case insensitive mode , use tablecache to check table existence . <nl> some thoughts here : <nl> we should try to prevent user creating table with dot in the table name .",1594807166,"recipient provider factory now could instantiate both external and internal recipient providers . it first check the property file ( if it exists ) and try to instantiate the provider using the given class . if it fails , then it try to instantiate the provider using internal classes . if both fails , then a dummy provider is used . <nl> tested on local controller .",0.9165237545967102
ballerina-platform_ballerina-lang/26641,"add support for xml template expressions with tests <cm-sep> add support for shift expressions <cm-sep> refactor tests and add tests for shift expressions <para-sep> string template expression xml template expression shift expression <nl> int , int todo - filter unsigned integers and signed integers with 0 , 0 and 0 bits <nl> todo - add support for signed and unsigned integers <nl> xml template expression evaluator implementation . <nl> xml element <nl> xml text assertexpression ( context , ' xml ' , ' hello , world ! ' , ' xml ' ) ; xml comment assertexpression ( context , ' xml ' , ' the lost worldhello , world ! ` ' , ' ' , ' xml ' ) ; <nl> assertvariable ( globalvariables , ' namewithouttype ' , ' ballerina ' , ' string ' ) ; assertvariable ( globalvariables , ' namewithtype ' , ' ballerina ' , ' string ' ) ;",this pr adds ballerina debug expression evaluation support for . <nl> this pr also adds integration test scenarios for the added expression types .,1603859604,do n't merge until the above pr is merged and carbon-messaging version is updated to the respective version .,0.9183299541473389
Alluxio_alluxio/11023,remove deprecated endpoints <para-sep> mock for rpc address mock for metrics mock for start time <nl> mock for up time <nl> validate configuration <nl> validate rpc address <nl> validate metrics <nl> validate starttimems <nl> validate uptimems <nl> validate version <nl> validate capacity bytes <nl> validate used bytes <nl> validate ufs capacity <nl> validate workers,removing rest endpoints marked with deprecated and should have been removed in version .,1582733709,"recall that in the future , we will only use local fs for integration tests and leave ufs part to ufs contract tests",0.9359731674194336
apache_shardingsphere/9112,add support alter sharding rule <cm-sep> fix <para-sep> function segment . <nl> alter replica query rule statement . <nl> alter sharding rule statement . <nl> sharding rule statement converter . <nl> convert create sharding rule statement context to yaml sharding rule configuration . <nl> convert function segment to yaml algorithm configuration . <nl> convert table rule segment to yaml sharding strategy configuration . <nl> create yaml sharding strategy configuration . <nl> convert table rule segment to yaml key generate strategy configuration . <nl> generate real algorithm name . <nl> sharding rule not existed exception . <nl> sharding table rule existed exception . <nl> alter replica query rule backend handler . <nl> alter sharding rule backend handler .,changes proposed in this pull request : <nl> - fix create sharding rule grammar <nl> - add alter sharding rule grammar <nl> - add support for alter sharding rule,1611199629,changes proposed in this pull request : <nl> - support query hint context for sharding-proxy <nl> - sctl : hint show status <nl> result like that : .,0.983880877494812
confluentinc_ksql/6617,"support arrays with mismatched elements . <nl> ( map / struct remaining ) <para-sep> numeric types can be coerced to a wider numeric type . for example , an expression can <nl> types can be coerced to any other type where the source array 's element type can <nl> types can be coerced to any other type where both the source map 's key and value types <nl> types can be coerced to any other type where the types of any field that exists <nl> all of the above general rules , plus : any literal can be coerced to a . a literal containing a number can be coerced to a numeric type wide enough to store the <nl> a literal containing a boolean value can be coerced to a . valid boolean values <nl> : then all other expressions must be coercible to . numeric : then all other expressions must be coercible to a number . the common type being the numeric <nl> : then all other expressions must be coercible to . : then all other expressions must be s and have element types that can be coerced <nl> : then all other expressions must be s and have key and value types that can be coerced <nl> : then all other expressions must be s. common field names must have types that <nl> sqldecimal does not support negative scale : <nl> coercion is performed in order . so the type of the first non-null expression drives the common type . for example , if the first non-null expression is a string , then all other expressions must be coercible to a string . if its numeric , then all other expressions must be coercible to a number , etc . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :",also contains a few edge case fixes for the general cast of coercing lists of expressions . <nl> - 1st commit fixes constructor . <nl> - 2nd commit fixes constructor . <nl> - 3rd commit removes now unnecessary casts from <nl> - 4th commit adds test covering coercion of array of structs where structs have different fields and field types . <nl> usual .,1605531082,"( previous releases created the command topic with default retention , which is likely to cause loss of command messages over time ) .",0.9743211269378662
apache_kafka/10006,"; fix flaky <para-sep> before the response is handled , we get a request to reset to the latest offset <nl> the list offset result should be ignored",this test has been flaky due to a race condition of some kind . i rewrote it so that it no longer relies on multiple threads .,1611960575,"0. in activetasks.suspend , we should also close all restoring tasks as well . closing restoring tasks would not require as in , since the topology is not initialized yet , instead only state stores are initialized . so we only need to call . <nl> 0. unit tests updated accordingly .",0.9022052884101868
elastic_elasticsearch/72024,"merge dynamic field type lookup into fieldtypelookup <para-sep> defines a mappedfieldtype that exposes dynamic child field types if the field is named 'my_field ' , then a user is able to search on the field in both of the following ways : - using the field name 'my_field ' , which will delegate to the field type as usual . - using any sub-key , for example 'my_field.some_key ' . the field may create a new field type dynamically in order to handle the search . to prevent conflicts between these dynamic sub-keys and multi-fields , any field mappers generating field types that implement this interface should explicitly disallow multi-fields . <nl> returns a dynamic mappedfieldtype for the given path <nl> for testing <nl> check if the given field corresponds to a dynamic key mapper of the form 'path_to_field.path_to_key ' . if so , returns a field type that can be used to perform searches on this field . otherwise returns null . <nl> no parent fields defined <nl> if the field is dynamically generated then return its full path","flattened field mappers have a specialised lookup class to handle <nl> the fact that their mappedfieldtypes are dynamic and generated <nl> on-the-fly , rather than being registered up front . the way this is <nl> implemented means that this lookup class also has to be aware of <nl> field aliases , which is blocking our attempt to re-implement aliases <nl> as runtime fields . <nl> this commit removes the specialised lookup class and moves <nl> dynamic lookup handling directly into fieldtypelookup . if a field <nl> containing dots does not have a mappedfieldtype directly registered <nl> against it , the",1619016776,"this commit refactors some of the rest test transformations unit tests . <nl> specifically , this refactor introduces a common parent that the ' match ' <nl> tests ( and other future tests ) can consume . also , the example tests <nl> have been simplified to better illustrate the change . <nl> there should no functional changes , just refactoring . this will help with <nl> future commits to allow focus only for the relevant changes .",0.969596803188324
apache_kafka/9926,migrate codebuffertest from junit4 to junit 0 <cm-sep> migrate all testcases in the generator module from junit4 to junit5 .,migrate generator module to junit5 .,1610992213,"as decided in , the uuid class has been named uuid . this pr changes all instances of org.apache.kafka.common.uuid to org.apache.kafka.common.uuid . <nl> it also modifies the uuid class so that it no longer wraps a java.util.uuid object . now it simply stores two longs .",0.9122207760810852
apache_incubator-pinot/5372,re-work on adding template support for pinot ingestion job spec,"templating is based on groovy simpletemplateengine . <nl> we need to support pinot ingestion job take an ingestion job spec template file and passing thru values . <nl> this will make user to schedule daily job simpler , without generating new yaml file everyday . <nl> - adding groovy template render support for pinot . <nl> - adding parameter in ( in format of 'k1=v1 ' 'k2=v2 ' ... ) which will be the context to set in the template . <nl> - adding parameter in which takes a list of parameters ( in format of 'k1=v1 ' 'k2=v2 '",1589281118,0. add hdfs segment fetcher support <nl> 0. make sure all segment fetcher is initialized during controller/server startup <nl> 0. fix bug in segmentfactory where it can not grab config for fetcher <nl> 0. add unit test for segment fetcher factory,0.9794541597366333
apache_camel/5373,"fixing incorrect span information generated by camel-zipkin in parallel processing of multicast or recipientlist . the original zipkinstate object ends up getting shared by different exchange object copies resulting in issues during push/pop operations . added interface to allow safe copy of properties which can provide deep object copies for safe copy operations <cm-sep> using thread safe datastructure for keeping span information <cm-sep> fixing unused imports <cm-sep> try to perform safe copy of properties only if explicitly specified on the exchange <cm-sep> cleaner way to implement copy safe properties <para-sep> original object intact <nl> new object has the new span <nl> method to set safecopyproperties on the exchange . <nl> method to get safecopyproperties from the exchange <nl> an interface that allows safe copy of property value object when creating copy of exchange objects . this allows the property value object to return a copy object to be set on the target exchange object instead of the original value object . this protects the properties from unintended mutation when using parallelprocessing in multicast or recipientlist eip <nl> implementations should implement this method to return a deep copy of the object which can be mutated independently of the original object . <nl> avoid the nullpointexception <nl> if the value is null , we just remove the key from the map",fixing . <nl> cleaner way of implementing copy safe properties on extendedexchange,1618449887,"should we not backport this to 0.x ? if not , please just ignore and close it unmerged . thanks .",0.9667970538139343
apache_flink/14821,"applicationclusterentrypoints should explicitly close packagedprogram <para-sep> lifecycle of the entry point is bound to that of the specific application being executed , and the <nl> close the packaged program explicitly to clean up temporary jars .","to make it obvious that this also happens in the application cluster entrypoints . should adjust the entrypoints to explicitly close the . <nl> - overrides the to invoke the method of . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes /",1612083504,"adds support to the for modifying the rootlogger level , and sets it to debug by default . <nl> future follow-ups could include making this configurable from the command-line , say to set it to trace .",0.887274980545044
pentaho_pentaho-kettle/7672,"performance degradation due to opening of xml files . <para-sep> try to read only if the file exists <nl> retry opening the inputstream on first error . because of the way defaultfilecontent handles open streams , in multithread executions , the stream could be closed by another stream without notice . the retry is a way to recover the stream . <nl> sonar squid s2142 requires the handling of the interruptedexception instead of ignoring it","now , before trying to read the file , the file is checked for existence .",1599329115,- changed gssapi auth to be enabled depending on -d parameter <nl> - added unit tests,0.9527120590209961
ballerina-platform_ballerina-lang/24528,"methods for mapping match pattern <cm-sep> mapping-match-pattern support to match statement . <cm-sep> added missing files . <cm-sep> test cases for adding mapping-match-pattern support to match statement . <cm-sep> add missing assert file . <para-sep> parse mapping match pattern . mapping-match-pattern : = { field-match-patterns } field-match-patterns : = field-match-pattern ( , field-match-pattern ) * [ , rest-match-pattern ] | [ rest-match-pattern ] field-match-pattern : = field-name : match-pattern rest-match-pattern : = ... var variable-name <nl> following loop will only run if there are more fields after the rest match pattern . try to parse them and mark as invalid . <nl> if the parser recovered by inserting a token , then try to re-parse the same rule with the inserted token . this is done to pick the correct branch to continue the parsing . <nl> parse filed match pattern . field-match-pattern : = field-name : match-pattern <nl> if the parser recovered by inserting a token , then try to re-parse the same rule with the inserted token . this is done to pick the correct branch to continue the parsing . <nl> this is a generated internal syntax tree node . <nl> this is a generated internal syntax tree node . <nl> this is a generated syntax tree node . <nl> this is a generated tree node modifier utility . <nl> this is a generated syntax tree node . <nl> this is a generated tree node modifier utility . <nl> { ' completionwithininvocationargs6.json ' , ' function ' } , { ' completionwithininvocationargs7.json ' , ' function ' } ,",notes <nl> commented failing test cases in the language server .,1593604955,"add maping-binding-pattern support to typed binding pattern . <nl> mapping-binding-pattern : = { field-binding-patterns } <nl> field-binding-patterns : = <nl> field-binding-pattern ( , field-binding-pattern ) * [ , rest-binding-pattern ] <nl> | [ rest-binding-pattern ] <nl> field-binding-pattern : = <nl> field-name : binding-pattern <nl> | variable-name <nl> rest-binding-pattern : = ... variable-name .",0.9923393726348877
jenkinsci_jenkins/4961,fixed spotbugs issue rv_negating_result_of_compareto <cm-sep> fixed spotbugs issue rv_return_value_ignored_bad_practice,fixed spotbugs issues : <nl> * rv_negating_result_of_compareto <nl> * rv_return_value_ignored_bad_practice . <nl> * internal : n/a,1601718671,"this fix implements an optional retry loop for cli buildcommand <nl> the retry is not for the actual command , but for reading the log file <nl> ( when -v is used ) this is so that slow machines , which may create the log <nl> file so slowly that is it not present when reading of it starts , <nl> will optionally try to start reading it multiple times . <nl> this is implemented via a use of an optional ' -r int ' cmd option",0.8481369018554688
Graylog2_graylog2-server/9313,"add binding for empty grnregistry . <nl> the object mapper needs a binding to a grnregistry . in the context of <nl> the journal decode command we do n't care about grns , so we just <nl> add a binding to an empty registry . <para-sep> todo : implement missing grn descriptor providers","the object mapper needs a binding to a grnregistry . in the context of <nl> the journal decode command we do n't care about grns , so we just <nl> add a binding to an empty registry . <nl> tested from the ide that the decode command works again .",1604051425,"extracted as an interface and renamed the implementation to . <nl> by extracting the interface of the input status service , we can bind a default implementation but provide the possibility to bind an alternative implementation in a different context . <nl> the service is not used yet . temporarily modified another service to have the inputstatusservice injected and made sure that the server did still start .",0.9038840532302856
OpenAPITools_openapi-generator/8275,fix issue with form data with null file <cm-sep> fix issue with form data with null file on alamofire implementation <cm-sep> update sample projects <para-sep> { { description } } * / { { /description } } { { # isdeprecated } } <nl> mapstring | [ string : string ] | | mapmapstring | [ string : [ string : string ] ] | | <nl> param | [ string : string ] | request body | mapmapofstring | [ string : [ string : string ] ] | | mapofenumstring | [ string : string ] | | directmap | [ string : bool ] | | map * | [ string : animal ] | | <nl> [ string : int ] * <nl> mapstring | [ string : string ] | | mapmapstring | [ string : [ string : string ] ] | | <nl> param | [ string : string ] | request body | mapmapofstring | [ string : [ string : string ] ] | | mapofenumstring | [ string : string ] | | directmap | [ string : bool ] | | map * | [ string : animal ] | | <nl> [ string : int ] * <nl> mapstring | [ string : string ] | | mapmapstring | [ string : [ string : string ] ] | | <nl> param | [ string : string ] | request body | mapmapofstring | [ string : [ string : string ] ] | | mapofenumstring | [ string : string ] | | directmap | [ string : bool ] | | map * | [ string : animal ] | | <nl> [ string : int ] * <nl> [ string : int ] * <nl> mapstring | [ string : string ] | | mapmapstring | [ string : [ string : string ] ] | | <nl> param | [ string : string ] | request body | mapmapofstring | [ string : [ string : string ] ] | | mapofenumstring | [ string : string ] | | directmap | [ string : bool ] | | map * | [ string : animal ] | | <nl> [ string : int ] * <nl> mapstring | [ string : string ] | | mapmapstring | [ string : [ string :,previously it was only possible to use the encoding when sending files . <nl> with this pr that is fixed . <nl> this pr also contains some fixes on code formatting .,1609068420,# # # pr checklist .,1.0
elastic_elasticsearch/71011,"[ ml ] complete ml plugin feature state clean up integration <para-sep> call into the original listener to clean up the indices <nl> validate no pipelines are using machine learning models <nl> indicate that a reset is now in progress <nl> noop , nothing for us to do , simply return fast to the caller <nl> we can not throw any exception here . it might break other pipelines .",this completes the machine learning feature state cleanup integration . <nl> this commit handles waiting for machine learning tasks to complete and adds a new <nl> field to the ml metadata cluster state to indicate when a reset is in progress for machine <nl> learning .,1617045996,"this implements the distance_feature for valued s. this produces the same numbers running against an indexed date , but it does n't have the same performance characteristics at all . which is normal for sdistance_feature ` against an indexes fields does a lot of work to refine the query as it goes , limiting the number of documents that it has to visit . we ca n't do that because we do n't have an index . so we just spit out the same numbers and hope it is good enough .",0.9837223291397095
elastic_elasticsearch/71199,use latest busybox musl binaries for docker distribution,"the busybox binaries we were using for our docker distribution were slightly out of date , and did n't play nice with older kernel versions on aarch64 . this pull request updates our docker build to use the same static binaries used in the busybox docker image itself .",1617301267,"the rest api uses ' thread_pool ' as the name of the thread pool metric . <nl> if we use this name internally when we serialize nodes stats and info <nl> requests , we wo n't need to do any fancy logic to check for and switch <nl> out ' threadpool ' , which was the previous internal name .",0.892208993434906
apache_kafka/10045,"allow kafkaapis to be configured for raft controller quorums <para-sep> the below will be replaced once is implemented <nl> visible for testing <nl> visible for testing <nl> provide a uniform way of getting to the forwardingmanager , which is a shared concept despite being optional when using zookeeper and required when using raft <nl> return this instance downcast for use with zookeeper <nl> return this instance downcast for use with raft <nl> confirm that this instance is consistent with the given config","is configured differently when it is used in a broker with a raft-based controller quorum vs. a zookeeper quorum . for example , when using raft , is required rather than optional , and there is no , , or . this pr introduces to abstract the two possibilities : and . this provides a fluent way to decide what to do based on the type of support that has been configured with . certain types of requests are not supported when using raft ( , , etc . ) , and gives us an intuitive way to identify the",1612394357,- fixed clusterid reference in metadata . <nl> - fixed log message with respective error in kerberoslogin .,0.7925971746444702
apache_incubator-pinot/5737,"improvements to realtimeprovisioninghelper command . <nl> - fixed a bug where we were looking for push frequency setting in the table config <nl> push frequency is not usually set in realtime table , so changed that to be an <nl> optional argument instead . <nl> - instead of push frequency , the user may specify retentionhours , meaning the number <nl> of hours of most recent data that will be queried most often . <nl> - added the amount of total mapped memory to the output <nl> - added the number of segments queried per host to the output . <nl> - added a link to the documentation to the output . <nl> - instead of accepting the time taken to consume the segment , introduced an argument <nl> to accept the ingestion rate per partition . this is determined easier when looking <nl> at metrics for the topic that we need to ingest , and is more convenient when <nl> an offline segment is being provided as a sample <nl> - added the command line arguments printed with the output so that it is easy for us <nl> to debug when we get questions from the community . <nl> todo next : . <nl> can we compute a score and just recommend a configuration ? we know we want to minimize <nl> num segments scanned per host , num hosts , segment size ( to fit memory ) . <nl> here is a sample output : <nl> ============================================================ <nl> realtimeprovisioninghelpercommand -tableconfigfile /users/ssubrama/tmp/samza/realtimetableconfig.json -numpartitions 0 -pushfrequency null -numhosts 0,0,0 -numhours 0,0,0,0 -samplecompletedsegmentdir /users/ssubrama/tmp/samza/testsamzaanalyticsfeatures_1593411480000_1593500340000_0/ -ingestionrate 0 -maxusablehostmemory 48g -retentionhours 0 . <nl> note : . <nl> memory used per host ( active/mapped ) . <nl> optimal segment size . <nl> consuming memory . <nl> number of segments queried per host . <para-sep> this is a realtime-only table . pick up the retention time","- fixed a bug where we were looking for push frequency setting in the table config <nl> push frequency is not usually set in realtime table , so changed that to be an <nl> optional argument instead . <nl> - instead of push frequency , the user may specify retentionhours , meaning the number <nl> of hours of most recent data that will be queried most often . <nl> - added the amount of total mapped memory to the output <nl> - added the number of segments queried per host to the output . <nl> - added a link to",1595459072,"currently , schema does not allow us to represent the time format and assumes its always sinceepoch format . <nl> this pr add timeformat field to the schema . now one can specify the format is in either in simple_date_format or epoch format . the default is epoch to maintain backward compatibility . <nl> unfortunately , this is not forward compatible i.e the if anyone uploads schema with timeformat , then the old code will fail to parse . we should first roll out this version before we upload schema with timeformat field . <nl> have a couple of todo",0.9650115370750427
apache_camel/5435,safer way to fix incorrect span timing information reported by camel-zipkin when using parallel processing with multicast/recipientlist <cm-sep> make defensive copy of zipkinstate <para-sep> original object intact <nl> new object has the new span,fixing zipkin spans in lts jira :,1618864272,"should we not backport this to 0.x ? if not , please just ignore and close it unmerged . thanks .",0.9015347957611084
jenkinsci_jenkins/4577,fix a bug in fingerprintcleanupthread and add tests .,fixed java.lang.classcastexception in fingerprintcleanupthread . <nl> too minor ?,1584191240,added a simple diagnostic http response to the tcpslaveagentlistener .,0.9462270140647888
Alluxio_alluxio/10940,add more metrics to client cache . <cm-sep> improve style . <para-sep> puts a page into the cache manager . this method is best effort . it is possible that this put operation returns without page written . <nl> wraps the page in a channel or null if the queried page is not found in the cache or otherwise unable to be read from the cache . <nl> wraps a part of the page in a channel or null if the queried page is not found in the cache or otherwise unable to be read from the cache .,adds bytes evicted and bytes written . also makes the localcachemanager tolerant of page store failures .,1582074891,"this pr : <nl> - adds retry for the initial block / file worker session heartbeat <nl> - adds session metrics collection to file worker ( for consistency with block worker ) <nl> - changes max sleep and # of retries for the exponential back-off policy from 10s and 0 to 5s and 0 , reducing the timeout window from ~0 minutes to ~0 minute <nl> - makes the retry logic of , , and consistent , deprecating the property in favor of <nl> - reduces logging verbosity of non-critical errors <nl> - reduces logging level of non-critical errors from",0.958739697933197
apache_beam/12994,"add support for gracefully aborting workers . on complete_work_status received ( by the work progress updater thread ) , abort the corresponding map task executor thread . this relies on thread.interrupt ( ) to unblock the worker thread if blocked and raise an exception -- the exception is actually ignored by the backend since the backend already decided to abort this thread . must also check the current thread for interrupts in the valuesiterator when it consumes a stream of values behind the same key , else control does not return to the runreadloop ( ) to check the interruption . <para-sep> if the task is cancelled for any reason , signal that the iterator and any underlying valuesiterable should abort . this is typically signalled via thread.interrupted ( ) , but user code ( and other libraries , including io ones ) may improperly handle that signal . we use this as a fail-safe to ensure that no further records are processed , especially when there may be hot keys with many values . <nl> given that the underlying readoperation already checks the abort status after every record it advances over ( i.e. , for every distinct key ) , we skip the check when at the first value as that is redundant . signal by thread interruption may be better , but it may also have unintended side-effects . <nl> current thread that execute ( ) is running on ; null when not running . <nl> save the current thread that is executing so that abort ( ) can interrupt it , we save it before starting the progress reporter thread , therefore ensuring thread safety through implicit serialization of events . <nl> signal the read loop to abort on the next record and async abort any iterators . <nl> called if the reader must be notified that it ought to abort . overrides must ensure thread safety as this method may not be called from the same thread , or serialized with , calls to the rest of the api . <nl> by default , do nothing . <nl> the asyncabort ( ) method does not need to be synchronized . * / <nl> operation must be an instance of readoperation or receivingoperation per preconditions in maptaskexecutor .","on complete_work_status received ( by the work progress updater thread ) , abort the corresponding map task executor thread . this relies on thread.interrupt ( ) to unblock the worker thread if blocked and raise an exception -- the exception is actually ignored by the backend since the backend already decided to abort this thread . must also check the current thread for interrupts in the valuesiterator when it consumes a stream of values behind the same key , else control does not return to the runreadloop ( ) to check the interruption",1601594340,"adds a to so that actually runs . since this test has n't been running it has a few issues , which i 've also attempted to resolve here . a summary of the changes to that end : <nl> - when testing a sub-class use the components list as the expected components , rather than the usual arguments list . <nl> - add to list of dataflow known coders . <nl> - now only validates that dataflow known coders do n't have a rather than _all_ model coders . <nl> - add equals and hashcode for schemacoder and rowcoder",0.965428352355957
elastic_elasticsearch/72514,"make nodepaths ( ) singular . <nl> this commit converts the nodepaths ( ) methods in nodeenvironment to be <nl> singular . <para-sep> determine folders to move and check that there are no extra files/folders <nl> node state directory , containing metadatastateformat-based node metadata as well as cluster state <nl> indices <nl> searchable snapshot cache lucene index <nl> ignore",this commit converts the nodepaths ( ) methods in nodeenvironment to be <nl> singular .,1619738328,this change ensures that the shard index that is used to tiebreak documents with identical sort <nl> remains consistent between two requests that target the same shards . the index is now always computed from the <nl> natural order of the shards in the search request . <nl> this change also adds the consistent shard index to the shardsearchrequest . that allows the slice builder <nl> to use this information to build more balanced slice query .,0.9671409130096436
jenkinsci_jenkins/4881,"do not block rendering of manage jenkins while waiting for uc data <para-sep> do not display message during this page load , but possibly later .","this is easiest to test with plugin updates being available . instructions below are written for that case . disable the following administrative monitors : . <nl> * deprecated plugin monitor <nl> * jenkins update notification <nl> * update site warnings . <nl> all of these end up checking update site data , which is what we do n't want . <nl> then run in script console . <nl> from that point on , jenkins will probably have unparsed data on disk ( ) , which will only be parsed , asynchronously , after you visit manage jenkins . the",1595869460,"actually this patch adds some diagnostics instead of the unchecked class cast we had here before . <nl> * , bug , - prevent unhandled classcastexception when loading fingerprints from corrupted files <nl> * .. . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.916226327419281
elastic_elasticsearch/71313,add access to dense_vector values . <nl> allow direct access to a dense_vector ' values in script <nl> through the following functions : . <nl> - getvectorvalue – returns a vector 's value as an array of floats <nl> - getvectormagnitude – returns a vector 's magnitude . <para-sep> calculates vector magnitude <nl> decodes a bytesref into the provided array of floats <nl> get dense vector 's value as an array of floats <nl> get dense vector 's magnitude,allow direct access to a dense_vector ' values in script <nl> through the following functions : . <nl> - getvectorvalue – returns a vector 's value as an array of floats <nl> - getvectormagnitude – returns a vector 's magnitude .,1617657716,the synchronization is executed every 0 seconds by default ( this interval <nl> can be changed using a new xpack.searchable.snapshot.cache.sync.interval <nl> setting ) .,0.9767489433288574
Graylog2_graylog2-server/9836,add heatmapvisualizationconfig <cm-sep> add heatmapvisualizationconfiguration component <cm-sep> use visualizationconfig in component <cm-sep> add reversescale config options <cm-sep> add useful config options <cm-sep> xxx <cm-sep> create heatmapvisualizationconfig for the backend <cm-sep> validation to color scheme <cm-sep> adapting failing test <cm-sep> fix linter warnings,"instead of hard coding a single color scale <nl> we should provide that list to the use so he can use a colorscale matching to his data . <nl> also it is often useful to define the range of the scale . for example if we have 0 data points in the range from 0 to 0 <nl> and 0 data points in the range 0 to 0 , the range of the colorscale is defined from 0 to 0. the 0 data points are now invisible . <nl> if the user now selects the data range from 0 to",1608542850,"this pr is adding the required boilerplate to load the elasticsearch6 <nl> storage module as a plugin by reusing the existing plugin loading <nl> mechanism . therefore it exposes an implementation of the <nl> interface , offering the metadata and the bindings module classes .",0.935674250125885
grpc_grpc-java/7564,fix channel builders abi backward compatibility broken in v1.version <para-sep> the default constructor . <nl> this method serves to force sub classes to ' hide ' this static factory . <nl> this method serves to force sub classes to ' hide ' this static factory . <nl> overriding method can return different value . <nl> returns the correctly typed version of the builder . <nl> temporarily duplicates io.grpc.forwardingserverbuilder ( temporarily package-private ) to fix abi backward compatibility .,"brings back and to the class hierarchy to fix broken abi backward compatibility . <nl> - since was introduced in v1.version , i changed it to . and made it package-private .",1603919291,"introduced , in the same pattern as , , , , , and .",0.992022693157196
apache_pulsar/9490,"transaction buffer snapshot implementation . <para-sep> create a transaction buffer snapshot writer . <nl> create a transaction buffer snapshot reader . <nl> remove a topic client from cache . <nl> close transaction buffer snapshot service . <nl> this future is for publish txn message in order . <nl> in order to avoid the opaddentry retain <nl> in order to promise the publish txn message orderly , we should change the transactioncompletablefuture <nl> message has been successfully persisted <nl> immediately acknowledge duplicated message","- now only sore the max read position and aborts transaction , follow-up will store ongoing txns . <nl> - implement this by a namespace event topic . <nl> - add and to control taking snapshot <nl> - add to create take snapshot and and cache the same namespace client . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the",1612514761,"add multiversionavroreader . <nl> add multiversiongenericavroreader . <nl> add multiversiongenericjsonreader . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( yes ) <nl> the schema : ( yes ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no )",0.9830179214477539
apache_pulsar/9521,add -- batch-index-ack for the pulsar-perf . <nl> add -- batch-index-ack for the pulsar-perf consume command and keep it as false by default .,add -- batch-index-ack for the pulsar-perf consume command and keep it as false by default . <nl> it 's better to allow users to do the performance test for the batch index acknowledgment . <nl> add -- batch-index-ack for the pulsar-perf consume command and keep it as false by default .,1612708177,"modifications . <nl> * added [ '-p ' , ' -- max-multipartition-outstanding ' ] parameter to the producer performance benchmark",0.8847204446792603
hazelcast_hazelcast/18438,increase asyncsnapshotwriterimpltest timeout . <nl> so this is just an attempt .,so this is just an attempt .,1617033345,* an from a version member will not have the versioned flag set ( was not in version ) so it is valid for to read from an that has <nl> * should become so all objects serialized on its observe a proper set .,0.4875228703022003
apache_incubator-pinot/5506,"moved streampartitionmsgoffset to be an interface . <nl> - changed streampartitionmsgoffset class to be an interface . <nl> - introduced a longmsgoffsetfactory class that can be used for kafka . other <nl> streams will need to provide their own factory to create offsets of <nl> various types . keeping longmsgoffsetfactory in spi , so we can also use <nl> it in tests . alternative was to introduce this for each test , but implement <nl> one in kafka that does the same thing . <nl> - introduced a new config 'stream .. partition.offset.factory.class.name ' <nl> stream providers need to set the offset factory class with this config key . <nl> - all classes now use streampartitionmsgoffset instead of 'long ' , except for <nl> cases where the offset is received from the stream or the offset is being <nl> read or written to persistent zk metadata . <nl> - marked todos explicity on items still to be done to complete impleemntation <nl> of generic offsets . <para-sep> todo issue 0 remove this code once we have both sides be able to live without _offset . <nl> todo 0 remove this once we are all upgraded in controllers and servers . <nl> todo issue 0 make it a jsonproperty when we are ready to move the protocol <nl> todo issue 0 remove the block below once we have both parties be fine without _offset being present . ignore . if the receiver expects _offset , it will return an error to the sender . <nl> todo issue 0 remove this backup use of offset when server and controller are upgraded . <nl> todo issue 0 remove the long parsing once metadata is set correctly . <nl> todo issue 0 use string offset in the metadata <nl> todo issue 0 fix when metadata changes in zk <nl> todo issue 0 fix when offset in metadata is fixed <nl> todo issue 0 fix when we get streampartitionoffset from getpartitionoffset ( ) method . <nl> todo issue 0 : pick the offset string from metadata <nl> todo issue 0 need to find a way to bump metrics without getting actual offset value . _servermetrics.setvalueoftablegauge ( _metrickeyname , servergauge.highest_kafka_offset_consumed , _currentoffset.getoffset ( ) ) ; _servermetrics.setvalueoftablegauge ( _metrickeyname , servergauge.highest_stream_offset_consumed , _currentoffset.getoffset ( ) ) ; <nl> todo issue 0 fix when we have streams returning offsets as streampartitionmsgoffset instead of long <nl> todo issue","- changed streampartitionmsgoffset class to be an interface . <nl> - introduced a longmsgoffsetfactory class that can be used for kafka . other <nl> streams will need to provide their own factory to create offsets of <nl> various types . keeping longmsgoffsetfactory in spi , so we can also use <nl> it in tests . alternative was to introduce this for each test , but implement <nl> one in kafka that does the same thing . <nl> - introduced a new config 'stream .. partition.offset.factory.class.name ' <nl> stream providers need to set the offset factory class with this config key",1591402459,"add tagoverrideconfig to define tag overrides for servers . <nl> add javadoc to tagoverrideconfig class use tagoverrideconfig inside realtimetagconfig to return the right consuming and completed tags . <nl> rename tenantnamebuilder to tagnamebuilder , because that 's what it really is . <nl> iterate over all places using tagnamebuilder and use tag overrides where relevant",0.9420185685157776
elastic_elasticsearch/70719,"rename runtimefieldtype to runtimefield . <nl> runtimefieldtype was recently made an interface , hence it no longer extends mappedfieldtype . it makes sense then to rename it to runtimefield . <cm-sep> more rename <para-sep> definition of a runtime field that can be defined as part of the runtime section of the index mappings <nl> prints out the parameters that subclasses expose <nl> exposes the name of the runtime field <nl> exposes the type of the runtime field <nl> parser for a runtime field . <nl> parse runtime fields from the provided map , using the provided parser context .","runtimefieldtype was recently made an interface , hence it no longer extends mappedfieldtype . it makes sense then to rename it to runtimefield .",1616495239,this change renames reader context to search context in the rest layer .,0.9768465757369995
grpc_grpc-java/7482,"add implementation note regarding server interceptors and thread locals <para-sep> required to be thread-safe , but they must not be thread-hostile . the caller is free to call an instance from multiple threads , but only one call simultaneously . a single thread may interleave calls to multiple instances , so implementations using threadlocals must be careful to avoid leaking inappropriate state ( e.g. , clearing the threadlocal before returning ) . required to be thread-safe , but they must not be thread-hostile . the caller is free to call an instance from multiple threads , but only one call simultaneously . a single thread may interleave calls to multiple instances , so implementations using threadlocals must be careful to avoid leaking inappropriate state ( e.g. , clearing the threadlocal before returning ) .","there seems to be some confusion regarding the correct usage of thread locals inside s . <nl> in all these examples the thread local is assigned during / and only removed on completion/error/close . <nl> i try to warn about these broken implementations , but they are still out there after all and even new ones are created . imo we should add a hint to the that strongly warns about the wrong usage of thread locals inside s . <nl> i also considered adding such a hint to and the the corresponding client classes , but i would like",1601710928,"change the message to refer to , and include some usage examples that users may find useful .",0.9126512408256531
ballerina-platform_ballerina-lang/26322,"add minor fix for typdesc value presentation <cm-sep> add typeof expression evaluation support <cm-sep> add evaluation support for deep value and reference equality expressions <cm-sep> add tests for typeof and equality expressions <cm-sep> add minor change for json type <cm-sep> resolve conflicts with master . <para-sep> helper classes <nl> helper methods <nl> misc loads and returns ballerina jvm runtime method instance for a given qualified class name + method name . <nl> search within loaded classes in jvm . <nl> tries to load the required class instance using ' java.lang.class.forname ( ) ' method . <nl> binary bitwise expression logical expression conditional expression typeof expression equality expression <nl> value equality <nl> reference equality <nl> checks for deep value equality . <nl> checks for reference equality . <nl> java jvm generated instance method representation . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> removes injected arguments added during the jvm method gen phase . <nl> todo - important : add remaining steps to validate and match named , defaultable and rest args todo - verify here we use the parent strand instance to execute the function invocation expression . <nl> returns the required set of argument values to invoke underlying jvm method . <nl> ballerina jvm generated static method representation . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> removes injected arguments added during the jvm method gen phase . <nl> todo - important : add remaining steps to validate and match named , defaultable and rest args todo - verify here we use the parent strand instance to execute the function invocation expression . <nl> ballerina jvm runtime static method representation . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> expression evaluator implementation . <nl> primitive types need to be handled separately , as the jvm runtime util method accepts only the sub classes of 'java.lang.object ' . therefore java primitive types are converted into their wrapper implementations first . <nl> primitive types <nl> reference types <nl> value equality <nl> reference equality",this pr adds ballerina debug expression evaluation support for . <nl> this pr also adds integration test scenarios for the added expression types .,1602563260,"> - and records are renamed to and to align with ballerina conventions . <nl> > - will introduce the apache avro serialization / deserialization support for ballerina kafka module . <nl> > - non-required fields in and are now optional fields , as opposite to previously defined fields or default values . <nl> > <nl> > # # # # <nl> > - - to specify the schema registry to use in avro serialization . <nl> > - additionally , is introduced as a to represent avro deserialization . <nl> > <nl> > # # # # <nl> >",0.9844902753829956
apache_druid/10464,"separate timeout exceptions <para-sep> base serializable error response queryresource and sqlresource are expected to emit the json form of this object when errors happen . <nl> this exception is thrown when a query does not finish before the configured query timeout . <nl> represents all wrapped exceptions other than interrupt , cancellation , resource limit exceeded , unauthorized","this pr separates out query timeout exceptions and avoids it from being thrown as a . timeout exceptions are now handled using a new . timed out queries will now return http 0 status code instead of the default http 0 status . this makes it easier for clients to identify timeout exceptions and handle it accordingly . <nl> to preserve the query metrics behavior , timeout exceptions are still being clubbed under , but i feel <nl> there should be a separate metric for query timeouts which can be done in a separate pr . <nl> if there are",1601654894,- include query json in explain output . <nl> - fix a bug where semi-joins and nested groupbys were not fully explained . <nl> - fix a bug where limits were not included in ' select ' query explanations .,0.9594016075134277
apache_beam/12738,eliminate nullability errors from : sdks : java : extensions : sql : jdbc <cm-sep> fixing checkstyle issue for comments <para-sep> nullable inputstream is being handled inside sqlline.begin . * / <nl> suppressing initialization warning as it is being initialized while setting up the test <nl> * /,fixing nullability errors from module : sdks : java : extensions : sql : jdbc,1598894219,"this enables the checker analyzer in the zetasketch extension , preventing nullability errors in this module . <nl> in this pr is an independent commit that prepares for other modules to use nullability analysis",0.8628727197647095
apache_pulsar/9563,[ issue 0 ] <nl> fix logic in managedledgerwriter when config threadnum > = ledgernum <cm-sep> [ issue 0 ] add friendly comment on . <nl> when without setting . <nl> origin logic will read the . <nl> which can cause zookeeperservers blank and throw npe .,when without setting . <nl> origin logic will read the . <nl> which can cause zookeeperservers blank and throw npe .,1613033344,"when it is setting to use token authn , standalone pulsar will failed to start because of function worker authentication fail . <nl> it happens like this : <nl> standalone will start function workerservice , then workerservice will create a pulsar client to create topics . but this pulsar client in worker could not get properly configuration , and caused failure when it connects to server , which has authn enabled . <nl> add authn related configs , so user could config the client in worker , and make it work .",0.9126288890838623
apache_shardingsphere/9283,"merge untracked file <cm-sep> support for parallel testing of integration tests by scenario <nl> fixed integration test batchdmlit case thread safety issue <para-sep> parameters can be injected via constructor or into annotated fields . <nl> represents a strategy for scheduling when individual test methods should be run ( in serial or parallel ) . warning : still experimental , may go away . <nl> todo gets the parameters of the runnable closure <nl> parallel parameterized by parameter . <nl> only called reflectively . do not use programmatically . <nl> checkstyle : on",changes proposed in this pull request : <nl> - support for parallel testing of integration tests by scenario <nl> - fixed integration test batchdmlit case thread safety issue,1612276743,changes proposed in this pull request : . <nl> - add sharding-scaling page in shardingsphere-ui .,0.9838416576385498
jenkinsci_jenkins/4905,do not render parts of serialized a consolenote if output begins in the middle of it . generalize finding pre/postamble <cm-sep> do not render parts of serialized a consolenote while writing non-html output as well . test sample script output . <cm-sep> add positive scenario test case . fine-tune implementation,no jira ticket exists . <nl> while rendering log output for a large logfile jenkins skips the beginning and shows the last of data . it is possible that the beginning of such a shortlog falls in the middle of a serialized and then part of a gziped and base64-encoded string gets rendered in the output . <nl> this may lead to suspicions that something in the build went wrong and/or that jenkins or one of its plugins did something wrong . in fact there is a pretty old issue in ansicolor-plugin suspecting just that . <nl> this pr takes,1596988838,added a simple diagnostic http response to the tcpslaveagentlistener .,0.9416959881782532
apache_shardingsphere/10121,report execution process from one proxy <para-sep> execute process summary report event . <nl> execute process unit report event . <nl> report execute process summary . <nl> report execute process unit . <nl> todo lock on the same jvm <nl> execute process context for yaml . <nl> execute process unit for yaml .,changes proposed in this pull request : <nl> - implement <nl> - finish a unit job for <nl> - import for <nl> - store to governance in,1618758550,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - add proxy meta data <nl> - fix some problems <nl> -,0.9747315645217896
apache_pulsar/8881,"transaction pending ack persistent <cm-sep> fix some named <para-sep> get the persistent newest mark deleted position on this cursor . <nl> this position is have persistent mark delete position <nl> for non partition topics , use a negative index so dispatcher wo n't sort consumers before picking an active consumer for the topic . <nl> pending ack recover whether ready future . <nl> close the pending ack handle . <nl> call back for pending ack reply . <nl> pending ack replay complete callback for pending ack store . <nl> handle metadata entry . <nl> to store transaction pending ack . <nl> replay pending ack to recover the pending ack subscription pending ack state . <nl> close the transaction pending ack store . <nl> append the individual pending ack operation to the ack persistent store . <nl> append the cumulative pending ack operation to the ack persistent store . <nl> append the pending ack commit mark to the ack persistent store . <nl> append the pending ack abort mark to the ack persistent store . <nl> provider of transaction pending ack store . <nl> construct a provider from the provided class . <nl> open the pending ack store . <nl> transaction pending ack store provider exception . <nl> the implementation for pending ack exceptions . <nl> mlpendingackstore reply call back . <nl> the implement of the pending ack store by manageledger . <nl> this is for replay <nl> the map is for pending ack store clear useless data . when ack message append to pending ack store , it will store the position which is persistent as key . when ack message append to pending ack store , it will store the position which is the max position of this ack by the original topic as value . it will judge the position with the max sub cursor position whether smaller than the subcursor mark delete position . if the max position is smaller than the subcursor mark delete position , the log cursor will mark delete the position . <nl> todo can control the number of entry to read <nl> store the persistent position in to memory <nl> store the persistent position in to memory store the max position of this entry retain <nl> provider is for mlpendingackstore . <nl> no-op <nl> if try to ack message already acked by committed transaction or normal acknowledge , throw exception . <nl>","0. when the sub unload , we will replay the pendingackhandle . <nl> 0. we use one manageledger to store the pending ack metadata by one sub , and replay by this managedledger open cursor . <nl> 0. when we commit or abort the transaction , we will append the marker to the pendingackstore then we will modify state memory in pendingackhandle <nl> 0. we also modify the in memory state when append fail , because we do n't know the persistent state , when we replay it , it will produce the wrong operation . so we append fail",1607528836,"- client ack with transaction will carry only this ack bit set 0 0 0 0 0 0 0 0，the 0 point is this transaction ack bit set point . <nl> - we will find the batch size from consumer pendingacks , when we do n't find it , the ack will fail . <nl> - the normal individual ack will sync the bitch size to pending ack handle . <nl> - we will remove the position from consumer pending acks after normal ack sync finish then check if batch position in pending ack handle all acked . <nl> -",0.9765920639038086
Alluxio_alluxio/11704,optimize ufs access on missing paths,"the main contribution of this pr is to remove a 2nd ufs call against the ufs when performing a liststatus/getstatus against a path which does n't exist in alluxio or the ufs . previously , would return null , and then call with a null status which then would make an call against the ufs . now we will instead throw a filenotfoundexception which is the same behavior as specified in the ufs api .",1593645318,this pr fixes the race conditions mentioned in the ticket by adding reference counting to the clientrwlock .,0.9092668890953064
grpc_grpc-java/7470,"modify builder methods for easier usages . <cm-sep> implement apis for watching lds/rds resources . <cm-sep> clean up xdsclient tests for covering watching each individual type of resources . <para-sep> longest time to wait , since the subscription to some resource , for concluding its absence . <nl> the node identifier to be included in xds requests . management server only requires the first request to carry the node identifier on a stream . it should be identical if present more than once . <nl> last successfully applied version_info for each resource type . starts with empty string . a version_info is used to update management server with client 's most recent knowledge of resources . <nl> for server side usage . <nl> currently in retry backoff . <nl> in case of listener watcher metadata to be updated to include port . * / <nl> todo ( sanjaypujare ) : eliminate usage of listening_addresses . <nl> establishes the rpc connection by creating a new rpc stream on the given channel for xds protocol communication . <nl> unpack listener messages . <nl> unpack httpconnectionmanager messages . <nl> unpack routeconfiguration messages . <nl> unpack listener messages . <nl> todo ( sanjaypujare ) : check listener.getname ( ) once we know what xds server returns <nl> todo ( sanjaypujare ) : check ip address once we know xds server will include it <nl> todo ( sanjaypujare ) : if myip to be checked against filterchainmatch.getprefixrangeslist ( ) <nl> handles cds response , which contains a list of cluster messages with information for a logical cluster . the response is nacked if messages for requested resources contain invalid information for grpc 's usage . otherwise , an ack request is sent to management server . response data for requested clusters is cached locally , in case of new cluster watchers interested in the same clusters are added later . <nl> unpack cluster messages . <nl> cluster information update for requested clusters received in this cds response . <nl> cds responses represents the state of the world , eds services not referenced by clusters are those no longer exist . <nl> skip information for clusters not requested . management server is required to always send newly requested resources , even if they may have been sent previously ( proactively ) . thus , client does not need to cache unrequested resources . <nl> the type",first take for replacing configwatcher with ldsresourcewatcher and rdsresourcewatcher . <nl> effective changes should be for lds/rds protocols only . tests for xdsclientimpl are cleaned up .,1601371623,,0.0
vespa-engine_vespa/15966,"ensure fresh node with lock <para-sep> returns a node mutex with the same mutex as this , but the given node . be sure to close only one . * / <nl> todo : work out a safe lock acquisition strategy for moves , e.g . migrate to locknode . returns the unallocated/application lock , and the node acquired under that lock . * / <nl> as an optimization we first try finding the node in the same state <nl> the wrong lock was held when the fresh node was fetched , so try again <nl> returns the unallocated/application lock , and the node acquired under that lock . * / <nl> returns the unallocated/application lock , and the node acquired under that lock . * / <nl> returns the unallocated/application lock , and the node acquired under that lock . * / <nl> above is an optimization to avoid unnecessary locking - now repeat all conditions under lock","defines a method noderepository : :lockandget that implements the common and correct pattern : having a node , acquire the appropriate lock depending on the allocation owner , and then refetch the node under that lock . <nl> and , acquire the lock for all children with recursive patch at /nodes/v2/node/ .",1610101469,"it seems to me that the macros generated depends on the types of input macros , which differents between rank profiles . <nl> it is wasteful to do large constants per rank profile though , we should change that , but i want to keep it simple for now .",0.9745558500289917
apache_druid/10714,use actual datainterval in cache key <para-sep> stubs below this line not important for tests,"currently , the interval used in cachingqueryrunner by cacheutil.computesegmentcachekey ( ) is the intersection of query interval and segment interval from segment identifier . <nl> it 's better to use the intersection of query interval and the actual datainterval of the segment ( the min/max data time in the segment , not the interval in the segment identifier ) . <nl> for example , when the segment granularity is day and there are many partitions built by realtime tasks : <nl> datasource_name1_2020-0-28t00:0 : versionz_2020-0-29t00:0 : versionz_2020-0-28t00:0 : versionz : <nl> datasource_name1_2020-0-28t00:0 : versionz_2020-0-29t00:0 : versionz_2020-0-28t00:0 : versionz_1 : <nl> datasource_name1_2020-0-28t00:0",1609237324,"hi , . <nl> i use another date format for the intervals which does not contain ' : ' symbols . i also replace ' : ' characters with ' _ ' in the version string . <nl> i tested this with .version-cdh4 . the segments are now pushed to hdfs properly and loaded to compute nodes properly . <nl> thanks for accepting the modification . <nl> -- jan",0.9480365514755249
crate_crate/10693,replace text with string in pendingclustertask . <nl> text was only used in the pendingclustertask . the pendingclustertask is <nl> only ever accessed via calls in the test framework . <nl> this allows us to remove and ignore the streaming compatibility . <nl> we should eventually expose the pending tasks in a table and <nl> remove the transport in its current form .,text was only used in the pendingclustertask . the pendingclustertask is <nl> only ever accessed via calls in the test framework . <nl> this allows us to remove and ignore the streaming compatibility . <nl> we should eventually expose the pending tasks in a table and <nl> remove the transport in its current form .,1603375006,see commits : . <nl> - avoid one level of supplier indirection for sys tables <nl> - produce result for sys.health lazy,0.8755781650543213
elastic_elasticsearch/71207,"deprecate multiple path.data entries . <nl> this commit adds a node level deprecation log message when multiple <nl> data paths are specified . <para-sep> note : we use initialenvironment here , but assertequivalent below ensures the data paths do not change",this commit adds a node level deprecation log message when multiple <nl> data paths are specified .,1617317276,"we were n't originally going to backport this , but then the vs refactor landed in 0.x sooner than expected , so this should come too . but it got held up by other parts that had to be backported / fixed first . : )",0.9360308051109314
vespa-engine_vespa/16847,using the jackson objectmapper directly at the rootlevel causes the whole object structure to be build in memory . <nl> a compromise here is to drive the parsing with the stream api and use an object mapper per entry in the array . <para-sep> fetch metrics for a given vespa service <nl> read everything from this start_object to the matching end_object and return it as a tree model objectnode <nl> do whatever you need to do with this object,"using the jackson objectmapper directly at the rootlevel causes the whole object structure to be build in memory . <nl> a compromise here is to drive the parsing with the stream api and use an object mapper per entry in the array . <nl> json does not guarantee any order as it is a map , but do we guarantee order in how we produce the metrics ? <nl> if not i guess we need optional post processing of the metrics to update the timestamp .",1615240024,"this should go out before the next push , to make sure we do n't lose writes during upgrade .",0.9671614170074463
apache_shardingsphere/9766,adjust encrypt column order for alter table <cm-sep> always remove logic column from alter table for encrypt <cm-sep> refactor encryptaltertabletokengenerator <cm-sep> refactor encryptaltertabletoken <cm-sep> refactor encryptaltertabletokengenerator,changes proposed in this pull request : <nl> - always remove logic column from alter table for encrypt <nl> - adjust rewrite order for alter table with encrypt,1616396846,changes proposed in this pull request : <nl> - parse constraint for alter table for mysql <nl> - parse constraint for alter table for postgresql <nl> - parse constraint for alter table for sqlserver <nl> - parse constraint for alter table for oracle <nl> - parse constraint for alter table for sql92 <nl> - add assert on parser test engine <nl> - fix parser test cases,0.9562159180641174
grpc_grpc-java/7500,default implementation of xdsclient.shutdown ( ) <cm-sep> add a new xdsclientpoolfactory interface that takes responsibility for reading bootstrap file and create the xds channel . <para-sep> introduced for testing . <nl> * / <nl> getobject once <nl> getobject twice <nl> returnobject once <nl> returnobject twice,"implemented , which is a global that multiple grpc clients will call to obtain an instance . <nl> - the first call of reads the xds bootstrap file and creates the xds channel . s are propagated up from the downstreams . it returns a thread-safe with ref-counting applied to the xdsclient it returns to its callers . <nl> - the first call of creates the xdsclient instance . <nl> note , it seems not ideal to read bootstrap file and create the xds channel before the actually creating the xdsclient instance . but interface does not throw any exception",1602236457,"this pr performs some pre-work for integrating client side load reporting with xds load balancer . ( this pr ) <nl> 0. integrate load reporting with xds load balancer , with tests verifying load reporting apis are invoked by xds load balancer properly . ( next pr ) . <nl> main changes in this pr : <nl> - put self-defined class into a separate file and rename it to . it is used both in load reporting and xds load balancer . <nl> - deleted delegation calls of , , and in . eds response handler in xds load balancer",0.9800378084182739
apache_druid/10341,"create basesequence early <cm-sep> unit test <para-sep> calling baserunner.run ( ) ( which is specificqueryrunnable.run ( ) ) in the retryingsequenceiterator could be better because we can minimize the chance that data servers report missing segments as we construct the query distribution tree when the query processing is actually started . however , we call baserunner.run ( ) here instead where it 's executed while constructing a query plan . this is because resultlevelcachingqueryrunner requires to compute the cache key based on the segments to query which is computed in specificqueryrunnable.run ( ) . <nl> runnableafterfirstattempt is only for testing , it must be no-op for production code . <nl> tests extending this class can query those segments as below : public void test ( ) { preparecluster ( 0 ) ; // prepare a cluster of 0 servers query query = makequery ( ) ; queryrunner baserunner = cachingclusteredclient.getqueryrunnerforintervals ( query , query.getintervals ( ) ) ; queryrunner queryrunner = makequeryrunner ( baserunner ) ; queryrunner.run ( queryplus.wrap ( query ) , responsecontext ( ) ) ... }","this pr changes to call in its , so that the segments to query can be determined early enough for . in theory , after this change , there might be a little higher chance to see missing segments in response context , but it should be small enough to ignore because the query execution will be likely started immediately right after query distribution tree is constructed . <nl> i believe we need integration tests for this fix , but i 'm not sure how to add it without introducing a metricsmonitor for integration tests . welcome any idea",1599023249,"for example , the below transformspec filters out all rows . <nl> this pr fixes it by falling back to the previous behavior when has a complex type . <nl> another bug with on multi-valued columns is fixed in this pr as well . the function should allow only single-valued columns . on the query side , the caller should be able to automatically apply to each element in the multi-valued column , which is already implemented . on the ingestion side , however , it does n't explode multi-valued column automatically , and on multi-valued columns should fail",0.9475807547569275
confluentinc_ksql/6348,backup files are re-created on every restart <para-sep> given <nl> when <nl> then <nl> given <nl> when <nl> then,"the cause was that sometimes the command topic comes with command properties ( originalproperties ) with nulls and empty values . when the backup serializes those properties to write them as json in the file , the nulls and empty are missing . later , when restarting the server , the command properties read from command topic are not equals from the ones found in the backup file ; so a new backup file is created . <nl> the fix makes sure to include nulls and empty properties in the backup file . it also adds a header to include",1601588699,"the is now responsible for creating all logical node types . <nl> main changes : <nl> * rather than creating the the now builds a , which is stored in . uses this info to build the . <nl> * rather than creating the the now stores a in . uses this info to build the ( s ) . <nl> * resolves all the columns in a using the schemas of all the source ( s ) involved , rather than using the schemas of the source logical nodes . <nl> * the now passes the list of sources",0.9710163474082947
elastic_elasticsearch/71258,whitelist cidr api . <nl> exposes the cidr convenience class in painless . <nl> api : .,exposes the cidr convenience class in painless . <nl> api : .,1617391392,"previously , backquote could n't not be used inside an escaped identifier , <nl> e.g . : . <nl> was not allowed . introduce escaping of the backtick with a leading <nl> backslash : .",0.867333173751831
apache_kafka/10158,": handle exceptions better in topicadmin . <nl> refactored the kafkabasedlog logic to read end offsets into a separate method to make it easier to test . also changed the topicadmin.endoffsets method to throw the original unsupportedversionexception , leadernotavailableexception , and timeoutexception rather than wrapping , to better conform with the consumer method and how the kafkabasedlog retries those exceptions . <nl> added new tests to verify various scenarios and errors . <para-sep> visible for testing <nl> note that we 'd prefer to not use the consumer to find the end offsets for the assigned topic partitions . that is because it 's possible that the consumer is already blocked waiting for new records to appear , when the consumer is already at the end . in such cases , using 'consumer.endoffsets ( ... ) ' will block until at least one more record becomes available , meaning we ca n't even check whether we 're at the end offset . since all we 're trying to do here is get the end offset , we should use the supplied admin client ( if available ) to obtain the end offsets for the given topic partitions . <nl> deprecated constructors do not provide an admin supplier , so the admin is potentially null . <nl> use the admin client to immediately find the end offsets for the assigned topic partitions . unlike using the consumer <nl> this may happen with really old brokers that do n't support the auto topic creation field in metadata requests <nl> forget the reference to the admin so that we wo n't even try to use the admin the next time this method is called <nl> continue and let the consumer handle the read <nl> other errors , like timeouts and retriable exceptions are intentionally propagated <nl> the admin may be null if older deprecated constructor is used or if the admin client is using a broker that does n't support getting the end offsets ( e.g. , version.x ) . in such cases , we should use the consumer , which is not ideal ( see above ) .","refactored the kafkabasedlog logic to read end offsets into a separate method to make it easier to test . also changed the topicadmin.endoffsets method to throw the original unsupportedversionexception , leadernotavailableexception , and timeoutexception rather than wrapping , to better conform with the consumer method and how the kafkabasedlog retries those exceptions . <nl> added new tests to verify various scenarios and errors .",1613702881,"allow even distribution of lost/new tasks when more than one worker joins the group at the same time . <nl> issue description : <nl> existing issue 0 description : when more than one worker joins the consumer group the incremental co operative assignor revokes and re assigns atmost average number of tasks per worker . <nl> issue : this results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks . <nl> fix : as part of task assignment calculation following a deployment , the reassignment of",0.9545998573303223
Alluxio_alluxio/11255,"hold state lock for duration of journal context <para-sep> use the state change lock for the journal context , since all modifications to journaled state must happen inside of a journal context . <nl> use a fair state lock , so that when a backup is triggered , acquiring the write lock does not block indefinitely . <nl> context for correctly managing the state change lock for a wrapped journal context . <nl> must release the state lock after the journal context is closed . <nl> start <nl> the pause lock should block <nl> since the journal context is still open , the pause should be blocked <nl> after closing the journal context , the pause lock should succeed <nl> new journal contexts should be blocked <nl> since state is paused , new contexts should not be created <nl> after un-pausing , new journal contexts can be created <nl> create tasks that continually create journal contexts <nl> ignore <nl> task that attempts to pause the state <nl> the pause lock should block <nl> since the journal context is still open , the pause should be blocked <nl> after closing the journal context , the pause lock should succeed , even when there are many threads creating journal contexts .","the state change lock should be held for the duration of the rpc , so that when the pause lock is held , there are no outstanding rpcs . this change makes the state change lock to be held during the whole journal context , so that when backups pause the state , it is guaranteed there are no state changes or journal changes in progress .",1586476005,in this pr : <nl> - ufs.create has a new createparent option to safeguard against permissions issues with recursive parent directory creation . <nl> - persist on worker in case of multiple mount points had a potential bug .,0.9620267748832703
apache_flink/14452,use different fs for each input path,"# # what is the purpose of the change . <nl> hivetableinputformat will throws the illegalargumentexception if partitions of a table are in different hdfs nameservices : . <nl> the introduced this issue . <nl> - use inputpath to get filesystem when checking the input existence . <nl> ( please pick either of the following options ) . <nl> this change is already covered by existing tests , such as tableenvhiveconnectoritcase.testnonexistingpartitionfolder ( ) . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class",1608608477,"the exmaple raised in the jira that batch can run successfully , but streaming will fail . the root cause is that the join key may be duplicate and the constructed key rowtype will have duplicate field names . <nl> we do not provide field names for the result key type , because we may have duplicate key fields and the field names may conflict . <nl> added an it case to verify this , the it case will fail without this fix . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes /",0.8387212753295898
quarkusio_quarkus/16167,fix completionstage response type handling in quarkus-rest-client-reactive . <cm-sep> fix uni response type handling in quarkus-rest-client-reactive . <nl> uni was not being treated as an async return type resulting in <nl> the client making blocking calls and trying to deserialize the <nl> result into a uni . <para-sep> with entity,uni was not being treated as an async return type resulting in <nl> the client making blocking calls and trying to deserialize the <nl> result into a uni .,1617259132,"please do n't merge , i will merge it myself .",0.957737147808075
ballerina-platform_ballerina-lang/26422,"revamp ballerinaparser qualifier parsing . <nl> give methods performing qualifier based directions , self qualifier parsing capabilities thus allowing them to direct without worrying about the qualifiers . <cm-sep> address added todos from the previous commit <para-sep> clones the first node in list with the invalid node as minutiae and update the list . <nl> top level qualifiers <nl> top level qualifiers","further , those methods are generalized so that it does n't matter whether qualifiers are already passed in a previous stage and come . <nl> - parsetoplevelnode <nl> - parsetypedescriptorinternal <nl> - parsestatement <nl> - parseobjectmemberwithoutmeta <nl> - parseobjectmethodorfield <nl> - parsetypedbindingpatternorexpr <nl> - parsetypedescorexpr <nl> - parsestatementstartbracketedlistmember .",1603179136,"this pr will add worker debugging functionality . <nl> the worker debugging works same as debugging java threads in idea . <nl> what happens is debug will only work for one worker , so other workers will run in the background . <nl> for example <nl> if there are two workers and we have debug points in both of them , then debug will hit only one worker ( ca n't guarantee which will get hit , because it hits the first point which reaches first ) . <nl> when hitting a debug point , the debugger will acquire a",0.9757339954376221
ballerina-platform_ballerina-lang/24233,add a child first classloader <cm-sep> update the reserved words <cm-sep> add alias support to bindgen <cm-sep> update the child first classloader <cm-sep> add class with conflicting names to integration test <cm-sep> fix java subtyping issue <cm-sep> remove an unused check <cm-sep> fix the integration test after the subtyping issue <cm-sep> refactor the classloader <para-sep> ignore if the classloader is not a urlclassloader . <nl> append the prefix ' j ' in front of bindings generated for java exceptions . <nl> silently ignore if the exception class can not be found . <nl> append the prefix ' j ' in front of bindings generated for java exceptions . <nl> silently ignore if the exception class can not be found . <nl> append the prefix ' j ' in front of bindings generated for java exceptions . <nl> silently ignore this assignment if the class is not found . <nl> this class represents a childfirstclassloader for checking specified jars before the parent .,the intention is to let the user change this unique object name to something meaningful using ide support . <nl> * updates the list of reserved keywords .,1592351769,before code action : . <nl> after code action : .,0.975473940372467
Alluxio_alluxio/11108,improve how tests handle restarting workers <para-sep> forces all workers to be lost . this should only be used for testing . <nl> updates the metadata for the specified lost worker . <nl> forget all the workers in the master,"instead of relying on waiting for lost worker detection , force the workers to be lost .",1583261601,"this fixes 0 issues . <nl> master synchronization . <nl> we update client metrics by removing the old client metrics and adding the new ones . this needs to be synchronized against the code which aggregates client metrics . otherwise , metrics that should only go up could be seen to go down . ( 0 ) clear metrics for client a , ( 0 ) aggregate the metrics and report to web ui ( does n't include client a ) , ( 0 ) add metrics for client a . <nl> previously we synchronized the remove/add on the field",0.9230727553367615
elastic_elasticsearch/70464,add searchable snapshot stats for reads from lucene,adds information about how many bytes lucene is requesting . this helps compare it to how many bytes are requested from the blob store to better understand how much random access reads are happening .,1615909620,the failed_category_count statistic records the number of times <nl> categorization wanted to create a new category but could n't <nl> because the job had reached its model_memory_limit .,0.941173791885376
jenkinsci_jenkins/4705,"update at-since up to may 0 , 0","ideally merged before version , so we have nice lts javadoc .",1588515632,* entry 0 : replaced text references to ' slave ' with ' agent ' in various comments and test references .,0.9208976030349731
vespa-engine_vespa/15917,install sia-provider config definition <cm-sep> reduce log level,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1609860432,make sure to merge with other pr .,0.8336232304573059
grpc_grpc-java/7257,"parse timeout from rds responses . <para-sep> cluster_specifier = cluster , default timeout <nl> cluster_specifier = cluster , infinity timeout <nl> cluster_specifier = cluster , infinity timeout <nl> cluster_specifier = cluster_header",a small part of implementing per-method timeout configuration .,1595969904,"this adds a method on grpchttp2connectionhandler which , when called , indicates that the channel associated with the handler is no longer needed . <nl> notes : . <nl> * the handler may not be on the channel , but will either a. need to be added or will never be added . <nl> * the channel will only be ' unused ' on the server side . <nl> * it is expected that after calling , the channel will be deregistered from the loop without being properly shut down . this allows the channel to be handed off to",0.9197686314582825
elastic_elasticsearch/72492,"[ ml ] use appropriate master timeouts for master actions . <nl> master node actions have a master timeout . one thing this <nl> does is define how long the transport layer waits for a <nl> master node to be elected if no master node exists at the <nl> time the master node request is made . <nl> when a persistent task invokes a master node action it <nl> makes sense for the master node timeout to be high . we do <nl> not want persistent tasks to fail because of a master <nl> timeout while a cluster is upgraded . for a request sent <nl> by an end user a master timeout of the order of 0 seconds <nl> makes sense , and the user can make a decision of whether <nl> to try again , but for a persistent task if the task fails <nl> due to a master timeout then it will never try again until <nl> somebody restarts the task . since the user will not be <nl> expecting persistent tasks to fail during upgrade the <nl> tasks may not get restarted for a very long time , which is <nl> unacceptable . <nl> therefore , this change increases the master timeout for <nl> master actions invoked by persistent tasks to 0 minutes . <nl> this means that the tasks will tolerate much longer than <nl> normal periods without a master node during upgrades , <nl> which should stop them spuriously failing . <para-sep> when a master node action is executed and there is no master node the transport will wait for a new master node to be elected and retry against that , but will only wait as long as the configured master node timeout . in ess rolling upgrades can be very slow , and a cluster might not have a master node for an extended period - over 0 minute was observed in the test that led to this constant being added . the default master node timeout is 0 seconds , which makes sense for user-invoked actions . but for actions invoked by persistent tasks that will cause the persistent task to fail if they time out waiting for a master node we should wait pretty much indefinitely , because failing the task just because a rolling upgrade was slow defeats the point of the task being ' persistent ' .",master node actions have a master timeout . one thing this <nl> does is define how long the transport layer waits for a <nl> master node to be elected if no master node exists at the <nl> time the master node request is made . <nl> when a persistent task invokes a master node action it <nl> makes sense for the master node timeout to be high . we do <nl> not want persistent tasks to fail because of a master <nl> timeout while a cluster is upgraded . for a request sent <nl> by an end user a master,1619710235,"this change ensures that internal client requests spawned by the <nl> transform persistent task executor and that use the end user security <nl> credentials , have the parent task id assigned . the objective here is <nl> to permit auditing ( as well as tracking for debugging purposes ) of all <nl> the end-user requests executed on its behalf by persistent tasks . <nl> because transform tasks already implements graceful shutdown of the <nl> child tasks , this change does not interfere with that by opting out of <nl> the persistent task cancellation of child tasks .",0.9395775198936462
apache_incubator-pinot/6009,"adjust schema validation logic in avroingestionschemavalidator <para-sep> column 0 is of int type in the avro . column3 and column16 are both of array of map structure . metric_not_found does n't exist in input avro <nl> check single-value multi-value mismatch <nl> check data type mismatch <nl> check single-value multi-value mismatch <nl> check data type mismatch <nl> check multi-value column structure mismatch <nl> even though the column schema is of array type , the element type of that array could be of complex type like array , map , etc .","the current logic does n't check the actual data type for multi-value column , which could have returned incorrect validation results . <nl> e.g . if column3 is of array structure ( like object [ ] ) and its base element is of string type in avro and if column3 is of string type as well in pinot schema , the current code would mark it . <nl> e.g . if column3 is of array of map structure ( like map [ ] ) , the current logic would miss marking it .",1599860940,check alert 's lasttaskruntime . if there is no success run within 0 days then disable it .,0.9086219668388367
elastic_elasticsearch/70628,"[ ml ] ensure auc_roc curve is monotonic . <nl> as we collect points for our auc roc curve from two <nl> different percentiles aggregations , the result may <nl> contain points with equal threshold that are not <nl> monotonic . this is because the percentiles aggregation <nl> is an approximation . <nl> this commit ensures the fina auc roc curve we calculate <nl> is monotonic by collapsing points of equal threshold into <nl> a single point that is the average of the equal threshold <nl> points it represents . <para-sep> as our auc roc curve is comprised by two sets of points coming from two percentiles aggregations , it is possible that we get a non-monotonic result because the percentiles aggregation is an approximation . in order to make our final curve monotonic , we collapse equal threshold points . <nl> collapses points with equal threshold by replacing them with a single point that is the average . <nl> visible for testing we subtract the minimum value possible here in order to ensure no point has a threshold of version as we are adding that point separately so that fpr = tpr = 0 .","as we collect points for our auc roc curve from two <nl> different percentiles aggregations , the result may <nl> contain points with equal threshold that are not <nl> monotonic . this is because the percentiles aggregation <nl> is an approximation . <nl> this commit ensures the fina auc roc curve we calculate <nl> is monotonic by collapsing points of equal threshold into <nl> a single point that is the average of the equal threshold <nl> points it represents .",1616414553,"the date/time related query params of a jdbc prepared statement <nl> serialized using java.util.date . the rules for serializing <nl> objects though reside in <nl> which is not available in the <nl> jdbc jar as this class is in module . therefore , a <nl> custom extension of the iface has been <nl> added to the jdbc module/jar . <nl> moreover the sql 's project had as dependency the <nl> module which depends on so the <nl> was available for the integ tests hiding the real problem .",0.9569552540779114
ballerina-platform_ballerina-lang/26372,compile package with test by default <cm-sep> add a test case to test package compilation with tests <para-sep> parse source files <nl> parse test source files todo use the compileroption such as -- skip-tests to enable or disable tests <nl> todo not sure why we need to do this . it is there in the current implementation <nl> todo why we need two different diagnostic positions . this is how it is done in the current compiler . so i kept this as is for now . <nl> 0 ) initialize the project instance <nl> 0 ) load the package <nl> 0 ) compile the current package <nl> the current package has e test modules and each module has one semantic or syntactic error . this shows that all 0 modules has been compiled <nl> syntactic error <nl> semantic error <nl> semantic error,it is fixed with this pr . i will introduce to pass options to the projectapi in a separate pr .,1602776989,due to this symbols get deferred making bir contents null .,0.9476500749588013
Alluxio_alluxio/11513,add readonly check while delete recursively <para-sep> create ufs file . <nl> will throw accesscontrolexception because /mnt/local is a readonly mount point,"when i use to delete an alluxio path with a descendant which is a readonly mount point , alluxio will delete all the descendants no matter if it is a readonly mount point , this is extremely dangerous . so it 's important to add readonly check while delete recursively . <nl> use-case : . <nl> usera with all the permission did : . <nl> usera with all the permission did : . <nl> as a result , was unexpectedly deleted",1591185227,fix infinite retries when a directory can not be created in ufs due to permission issue .,0.905002772808075
elastic_elasticsearch/71527,"remove the ability for plugins to add roles . <nl> this commit removes the ability for plugins to add roles . roles are <nl> fairly tightly coupled with the behavior of the system ( as evidenced by <nl> the fact that some roles from the default distribution leaked behavior <nl> into the oss distribution ) . we previously had this plugin extension <nl> point so that we could support a difference in the set of roles between <nl> the oss and default distributions . we no longer need to maintain that <nl> differentiation , and can therefore remove this plugin extension <nl> point . this was technical debt that we were willing to accept to allow <nl> the default distribution to have additional roles , but now we no longer <nl> need to be encumbered with that technical debt . <para-sep> this method can be called before the o.e.n.noderolesettings.node_roles_setting is initialized <nl> whether or not the role is enabled by default given the specified settings <nl> represents the role for a node that can be a remote cluster client . <nl> represents the role for a machine learning node . <nl> represents the role for a transform node . <nl> the set of possible roles <nl> a map from role names to their role representations <nl> this will detect duplicate role names <nl> now we can collect the roles , do n't do this first and then collect the role map because the set collector will allow duplicates <nl> this will detect duplicate role abbreviations <nl> the possible node roles . <nl> the set of possible role names . <nl> get an optional representing the role with the given role name , if such a role exists . <nl> get a representation of the role with the given role name , if such a role exists , otherwise an exception is thrown .","this commit removes the ability for plugins to add roles . roles are fairly tightly coupled with the behavior of the system ( as evidenced by the fact that some roles from the default distribution leaked behavior into the oss distribution ) . we previously had this plugin extension point so that we could support a difference in the set of roles between the oss and default distributions . we no longer need to maintain that differentiation , and can therefore remove this plugin extension point . this was technical debt that we were willing to accept to allow the",1617981429,"just a cleanup i found when working on the recovery logic : . <nl> a class with 0 fields does not need a builder , especially <nl> when in many cases the builder result is just equivalent to the <nl> singleton to begin with . <nl> removed the builder and simplified related code accordingly .",0.9612512588500977
apache_druid/10255,default server.maxsize <para-sep> guice inject added here to properly bind this dependency into its dependents such as statusresource,"will now default to the sum of values defined within the . user can still provide a custom value for which will take precedence over the default value . <nl> since there are n't many usecases where this property needs to be different from the segmentcache size , we could gradually remove this user property in the future",1596831074,"adds a druid expression to allow use in and , as well as sql virtual column expression support .",0.977929949760437
apache_druid/10338,wip vectorized any aggregators <para-sep> rightmost bit for is null check ( 0 for is null and 0 for not null ) second rightmost bit for is found check ( 0 for not found and 0 for found ) <nl> initialize the buffer value given the initial offset position within the byte buffer for initialization,"this patch provides a vectorized implementation of the aggregators . since these aggregators already only read 0 value from the column , the performance gain comparing a vectorized implementation and non-vectorized implementation is expected to be minimal ( maybe even slightly slower since we read a batch of values ) . <nl> however , providing a vectorized implementation allows for queries of the following shape to be vectorized . <nl> where we know there is a 0:0 mapping between id and name",1598981018,"new druid expressions for filtering ipv4 addresses : <nl> - ipv4address_match : check if ip address belongs to a subnet <nl> - ipv4address_parse : convert string ip address to long <nl> - ipv4address_stringify : convert long ip address to string . <nl> these expressions operate on ip addresses represented as either strings <nl> or longs . the filtering is more efficient when operating on ip addresses <nl> as longs . in other words , the intended use case is : . <nl> 0 ) use ipv4address_parse to convert to long at ingestion time <nl> 0 ) use ipv4address_match to filter",0.9841569066047668
apache_beam/12621,"add use_deprecated_read experiment for testsimpleinsert , testsimpleinsertflat <para-sep> todo ( ) : reading from pubsub should n't require deprecated read <nl> todo ( ) : reading from pubsub should n't require deprecated read","adding the use_deprecated_read experiment temporarily to fix sql postcommit , as sdf seems to break these tests . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1597784787,set batchpath on google.api.services.storage.storage storage builder . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.8442206382751465
apache_camel/5183,": camel-core - optimize core to reduce object allocations by pooloing reusable tasks in the routing engine . <para-sep> this test is mocking and its easier to test with prototype scoped <nl> must be prototype scoped ( not pooled ) so we create the exchange via endpoint <nl> must be prototype scoped ( not pooled ) so we create the exchange via endpoint <nl> make defensive copy <nl> must be prototype scoped ( not pooled ) so we create the exchange via endpoint <nl> must be prototype scoped ( not pooled ) so we create the exchange via endpoint <nl> ensure consumer is started <nl> camel-reactor does not work with pooled exchanges <nl> camel-rxjava does not work with pooled exchanges <nl> must be prototype scoped ( not pooled ) so we create the exchange via endpoint <nl> whether the factory is pooled . <nl> factory for pooled objects or tasks . <nl> utilization statistics of the this factory . <nl> number of new exchanges created . <nl> number of exchanges acquired ( reused ) when using pooled factory . <nl> number of exchanges released back to pool <nl> number of exchanges discarded ( thrown away ) such as if no space in cache pool . <nl> reset the counters <nl> whether statistics is enabled . <nl> sets whether statistics is enabled . <nl> the current number of objects in the pool <nl> the capacity the pool uses for storing objects . the default capacity is 0 . <nl> the capacity the pool uses for storing objects . the default capacity is 0 . <nl> whether statistics is enabled . <nl> whether statistics is enabled . <nl> reset the statistics <nl> purges the internal cache ( if pooled ) <nl> gets the usage statistics <nl> acquires an object from the pool ( if any ) <nl> releases the object back to the pool <nl> todo : pool this task , and the states array <nl> detour the exchange with the pipeline that has before and after included <nl> build pipeline with befofe/after processors <nl> detour the exchange using synchronous processing <nl> prepares the task for the given exchange and its callback <nl> resets the task after its done and can be reused for another exchange . <nl> creates a new task to use for processing the exchange . <nl> attempts to acquire a pooled task to use for processing the exchange",some more optimizations on the way in the routing engine .,1615136164,"should we not backport this to 0.x ? if not , please just ignore and close it unmerged . thanks .",0.967344343662262
OpenAPITools_openapi-generator/7508,protect against potential but unlikely npes <cm-sep> regenreate,wraps a couple potential npes in null checks .,1600999315,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) .",0.8394784331321716
Alluxio_alluxio/10904,reconstruct the multivaluemetricsaggregator to reduce overhead <para-sep> a map from alluxiouri to corresponding cached escaped path . <nl> a pattern to get the . from the full metric name <nl> gets all the master metrics belongs to the given metric names .,"fix the bug of . it previously only returns the metric stored in metricsregistry with the exact same name . in this pr , it returns the metrics that start with the given metric name ( the metrics can have multiple tags ) . <nl> reduce the logics in update values , reduce the traverse of the whole metrics .",1581621211,this change applies dependency injection so that we do n't need to use sleeping or whitebox to test the sleeping timer .,0.9777573943138123
elastic_elasticsearch/72326,"feature reset integration test should tolerate failed resets <cm-sep> remove redundant section of test <cm-sep> remove unused imports <cm-sep> mention that we check task index specifically <para-sep> this test assumes that at least one of our defined features should reset successfully . since plugins should be testing their own reset operations if they use something other than the default , this test tolerates failures in the response from the feature reset api . we just need to check that we can reset the ' tasks ' system index .","this did n't cause a problem in the branch builds , but it did on the intake build . basically , in this test we should just be looking for at least one success , but the matcher required the result to just be ' success ' . this was wrong . in fact , it was redundant with a check a few lines above , so it 's probably best to just remove it and add a comment about what the test is looking for .",1619548977,add correct assert for jdk 0+ .,0.8887399435043335
elastic_elasticsearch/71241,"speed up terms agg when not force merged . <nl> this speeds up the aggregation when it ca n't take the fancy <nl> path , there is more than one segment , and any of those <nl> segments have only a single value for the field . these three things are <nl> super common . <nl> here are the performance change numbers : . <nl> this works by hooking global ordinals into . <nl> without this you could unwrap singletons if the segment 's ordinals <nl> aligned exactly with the global ordinals . if they did n't we 'd return an <nl> doc values iterator that you ca n't unwrap . even if the segment ordinals <nl> were singletons . <nl> that speeds up the terms aggregator because we have a fast path we can <nl> take if we have singletons . it was previously only working if we had a <nl> single segment . or if the segment 's ordinals lined up exactly . which , <nl> for low cardinality fields is fairly common . so they might not benefit <nl> from this quite as much as high cardinality fields . <cm-sep> finish words <para-sep> we can manage a singleton if the total value count fits in an and the segment ords are a singleton . we need the first one just because sorteddocvalues returns instead of <nl> force a second segment <nl> do n't use searchandreduce because we only want a single aggregator .","this speeds up the aggregation when it ca n't take the fancy <nl> path , there is more than one segment , and any of those <nl> segments have only a single value for the field . these three things are <nl> super common . <nl> here are the performance change numbers : . <nl> this works by hooking global ordinals into . <nl> without this you could unwrap singletons if the segment 's ordinals <nl> aligned exactly with the global ordinals . if they did n't we 'd return an <nl> doc values iterator that you ca n't unwrap",1617378922,this pr completes the implementation of the model <nl> memory estimation endpoint : . <nl> post _ml/anomaly_detectors/estimate_model_memory .,0.9801865220069885
pentaho_pentaho-kettle/7549,backport of sonar cleanup . <cm-sep> backport of - modified javascript value : bignumber value incorrect in non-compatability mode ( version suite ) .,backport of - modified javascript value : bignumber value incorrect in non-compatability mode ( version suite ) .,1596099093,"refactor work on pancommandexecutor/kitchencommandexecutor to promote code reuse . <nl> this pull request holds zero changes to the logic . it 's a mere refactor work aimed at promoting code reuse . <nl> - promoted util method to , rather than being duplicated in / <nl> - was doing both the _ ' print repos ' _ , _ ' list repos ' _ , etc ... type of operations , as well as the action of loading a trans/job from the repository <nl> - decoupled the 0 : now addresses the _ ' print repos ' _ , _",0.9276503920555115
apache_flink/14441,[ connectors/jdbc ] add hang test case to reveal deadlock when loading different sql driver classes concurrently using class.forname . <cm-sep> [ connectors/jdbc ] fix deadlock when loading different sql driver classes concurrently using class.forname . <para-sep> load drivermanager first to avoid deadlock between drivermanager 's static initialization block and specific driver class 's static initialization block . see comments in simplejdbcconnectionprovider for more details . <nl> load drivermanager first to avoid deadlock between drivermanager 's static initialization block and specific driver class 's static initialization block when two different driver classes are loading concurrently using class.forname while drivermanager is uninitialized before . this could happen in jdk 0 but not above as driver loading has been moved out of drivermanager 's static initialization block since jdk 0 . <nl> load drivermanager first to avoid deadlock between drivermanager 's static initialization block and specific driver class 's static initialization block . see comments in simplejdbcconnectionprovider for more details . <nl> load drivermanager first to avoid deadlock between drivermanager 's static initialization block and specific driver class 's static initialization block . see comments in simplejdbcconnectionprovider for more details .,this is a cherry pick back to .0 branch .,1608519625,"thank you very much for contributing to apache flink - we are happy that you want to help us improve flink . to help the community review your contribution in the best possible way , please go through the checklist below , which will get the contribution into a shape in which it can be best reviewed . <nl> please understand that we do not do this to make contributions to flink a hassle . in order to uphold a high standard of quality for code contributions , while at the same time managing a large number of contributions ,",0.8305771350860596
hazelcast_hazelcast/18264,add managementpermission - i.e . rbac support for mc executed actions . <para-sep> cluster management <nl> hazelcast permission type used in client protocol actions intended for management center operations . actions are not used and the permission name can end with a wildcard ' . ' ( e.g . ' cluster . ' ) .,this pr adds a new permission type for management messagetasks . <nl> newly the client used in management center will need to have either the granted or the new permission type . e.g . <nl> this change can affect hazelcast enterprise users with security enabled but without the management client having the granted . in such a case managementcenter operations on the cluster will fail with the thrown .,1614006738,- removed as it duplicates the purpose of and in one case was not updated properly .,0.9239739775657654
confluentinc_ksql/6587,"extend cast to structured types . <nl> extend cast to the structured types , and . <cm-sep> extend test coverage <cm-sep> refactor cast evaluator . <nl> clean up the code . <cm-sep> fix null handling and extend to array , map , struct <para-sep> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> map of source sql type to the supported target types and their handler . <nl> boolean : <nl> int : <nl> bigint : <nl> decimal : <nl> double : <nl> string : <nl> array : <nl> map : <nl> struct : <nl> generates code to handle cast . <nl> from is null if source is sql null <nl> inefficient , but only way to pass type until sqltojavavisitor supports passing additional parameters to the generated code . hopefully , jvm optimises this away . <nl> functions to help with generating code to work around the fact that the script engine does n't support lambdas . <nl> helper functions around null handling <nl> when : <nl> cast is also tested by . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> run combinationtest again , for arrays with different element types : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> run combinationtest again , for maps with different key types : <nl> run combinationtest again , for maps with different value types : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> run combinationtest again , for structs with different field types : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> tests covering different fields in source and target struct types : <nl> given : <nl> when : <nl> then : <nl> run combinationtest again , for nested structured types with different element types : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when","overhaul the cast code to fix issues with null handling , ( all most all cast calls with null values resulting in npe ) and extend it to support casting structured types , e.g . cast to . or to . etc . <nl> s can also be cast . any field that existings in both the struct types will be cast . for example : . <nl> will result in . <nl> usual . <nl> has extensive tests to ensure : <nl> - unsupported casts fail early <nl> - supported casts succeed and output code that : <nl> -",1604933012,"udfs are loaded from the jars by searching for the anotations and . each method ( in a class with ) marked with is compiled into a class that can be called via the existing function call code . each udf gets it 's own child first classloader so that they are free to include versions of jars that are different than those provided by ksql . <nl> classes can be ' blacklisted ' from being called from a udf , i.e. , so they ca n't call , for example . <nl> have also changed the to this new",0.982729971408844
jenkinsci_jenkins/4596,websockets : use abstractbytebuffercommandtransport to transport messages,* fix websocket connections crash if message size is greater than 64kb ( requires a matching with remoting version or later ),1584706754,"* optional extensions are now loaded without requiring to restart jenkins after installing an optional dependency . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9472703337669373
grpc_grpc-java/7266,"refactor adsstream to envoy proto agnostic abstractadsstream <para-sep> fall trough <nl> fall through <nl> fall through <nl> fall through <nl> nonce in each response is echoed back in the following ack/nack request . it is used for management server to identify which response the client is acking/nacking . to avoid confusion , client-initiated requests will always use the nonce in most recently received responses of each resource type . <nl> adsstream v3",in preparation of xds-v3 support .,1596066510,"instead of failing after a a missing a/aaaa record , this change <nl> makes the resolver keep going and try out srv records too . this <nl> is needed for use with alts , and is part of the grpclb spec . <nl> this change also moved the jndi code to a separate , reflectively <nl> loaded file . this makes it easy to exclude the file and not worry <nl> about the missing class references on android . additionally , if <nl> javax.naming might be available on android , this allows it to be <nl> loaded . a key",0.9588984251022339
apache_pulsar/9826,"fix message not dispatch for key_shared sub type in non-persistent subscription . <para-sep> if not batching , need to wait for message to be persisted <nl> if batching , flush buffered messages","with a non-persistent topic , i see messages published in the topic stats , but consumers do not consume them if they use key_shared . other consumer modes work fine . <nl> covered by existing test case , verified manually .",1615013292,patching some bugs in the source cli and also adding extensive unit tests,0.9500465393066406
vespa-engine_vespa/15285,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> zookeeper-server-common is not loaded as a bundle <para-sep> todo bjorncs/jonmv : remove extraneous zookeeperprovider layer <nl> context required to configure automatic reindexing for a given cluster controller cluster ( for a given content cluster ) .",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605099789,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9835606217384338
apache_pulsar/9016,motivation . <nl> enable spotbugs check in the module pulsar-common .,motivation . <nl> enable spotbugs check in the module pulsar-common .,1608544791,there are several connectors ( sources/sinks ) related admin apis and rest endpoints that reside within functions admin api and rest endpoints which is n't necessary any more since sources and sinks having their own separate admin api and rest api now . <nl> also move getting a complete list of connectors ( sources and sinks ) for a worker from functions rest api to worker api since that more sense .,0.9321776628494263
Graylog2_graylog2-server/9352,"cleanup grants for streams , searches and event notifications . <cm-sep> remove role from users on role deletion .","- cleanup grants for streams , searches and event notifications <nl> - remove role from users on role deletion .",1604484606,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.9564627408981323
neo4j_neo4j/11353,"configurable spatial index . <nl> * moved spatial index settings to separate file <nl> * make extents configurable <nl> * saving and reading index settings <cm-sep> move half-open range computation to space filling curve . <cm-sep> descriptions for spatial index extents settings <cm-sep> port spatial index settings into gbptree header instead of separate file <cm-sep> fixed spatial index config settings support after fixes to header writer <cm-sep> got configurable spatial index working on new index framework <para-sep> these settings affect the creation of the 2d ( or 3d ) to 1d mapper . changing these will change the values of the 1d mapping , and require re-indexing , so once data has been indexed , do not change these without recreating the index .","fixes half-open range queries where the bound is smaller/greater than the default range . <nl> fixes for exclusive ranges , e.g is within the range when upper bound is set to .",1521728320,"filters are configured for the load balancing strategy called <nl> server_policy using a strategy-specific syntax . this syntax allows <nl> specifying a list of rules , each consisting of a chain of filters . <nl> this commit parses that syntax and enables several different policies <nl> with different rulesets to be defined and parsed . <nl> testing infrastructure has been added to make tests of the functionality <nl> easy and various valid as well as invalid configurations are tested so <nl> that they produce the expected result . <nl> three filters exist today : <nl> all : returns all servers",0.9828503727912903
Graylog2_graylog2-server/9485,"finish support for multiple ldap / ad servers . <nl> - add support to verify against multiple hosts in defaultx509trustmanager . <nl> - modify connection test to support and test multiple servers . <nl> - remove validation for single server . <para-sep> test each server separately , so we can see the result for each <nl> test each server separately , so we can see the result for each <nl> create a x509trustmanager that verifies the certificate chain and checks whether the cert matches one of the given hosts in the list . note : any matching host from the list is accepted . e.g . : given a host list [ a , b ] , the server b is allowed to offer a certificate issued to a <nl> create a x509trustmanager that verifies the certificate chain and checks whether the cert matches one of the given hosts in the list . note : any matching host from the list is accepted . e.g . : given a host list [ a , b ] , the server b is allowed to offer a certificate issued to a",- add support to verify against multiple hosts in defaultx509trustmanager . <nl> - modify connection test to support and test multiple servers . <nl> - remove validation for single server .,1605278575,"the events search code is now checking if the user that executes the <nl> search is allowed to see events based on the ' source_streams ' field . <nl> example : . <nl> if an event got created from a message in stream a , the event has stream <nl> a in its ' source_stream ' field . if a user has read permissions on stream <nl> a , the event is visible to the user in the events search .",0.969772219657898
neo4j_neo4j/11162,lazy evaluation of paths . <nl> there has been reported regressions because of the introduction of values <nl> when dealing with paths . this is caused by that we eagerly fetch all <nl> nodes and relationships of the path in order to construct the <nl> no matter if we use it or not . fix this by introduce a wrapping - just <nl> as we do for nodes and relationships - for paths . we will probably want <nl> to fix this nicer in later versions but this felt like the most non-evasive <nl> fix to the regression .,there has been reported regressions because of the introduction of values <nl> when dealing with paths . this is caused by that we eagerly fetch all <nl> nodes and relationships of the path in order to construct the <nl> no matter if we use it or not . fix this by introduce a wrapping - just <nl> as we do for nodes and relationships - for paths . we will probably want <nl> to fix this nicer in later versions but this felt like the most non-evasive <nl> fix to the regression . <nl> changelog : fixed performance regression with,1520255007,"individual commits tells the story , but generally this is about various issues with concurrent schema changes , such that the loaded representation of the schema may end up in state of permanently missing some updates , and also temporary reading temporarily broken schema . <nl> some of these issues has existed since the introduction of schema , but the more severe ones was introduced with the global schema lock split . <nl> the test could previously run into all these issues in one or two runs , consistently , so could reproduce very reliably . for that reason i",0.9586969017982483
apache_incubator-pinot/5836,return full paths along with scheme in listfiles <cm-sep> take only path instead of uri to create local file,the fix involves the following changes . <nl> - return full paths along with scheme in listfiles functions instead of path after the bucket . <nl> this change is needed because the output of the listfiles in passed to isdirectory function which throws exception since the path does n't contain the bucket . <nl> - take only the path instead of the full uri in segment generation job runner while creating a local file . <nl> the segment generator throws the error on creating the local file . this small change of taking instead of fixes this issue . <nl>,1597052592,"this pr refactors checks when shutting down pinot server , so that : . <nl> - will always be positive , which means the thread would n't be busy spinning to check the updates . can be non-positive , so that these two checks are configurable to be ignored . <nl> - pinot server is guaranteed to shutdown when reaching max waiting time . <nl> - is also included in the total waiting time .",0.9178541898727417
runelite_runelite/12531,sort spots alphabetically <cm-sep> update mammoth cannon spot,the mammoth 's spawn points have changed since the ferox enclave game update on 0/0/0 . i 've attached screenshots of the current and proposed spots . <nl> current : . <nl> proposed :,1600733624,"this pr updates a conditional in the so that price look-ups are triggered when examining items on the ground and a message is posted to chat , the same way it behaves when examining an inventory item . <nl> the diff looks a lot bigger than it is because of indentation changes .",0.6843679547309875
ballerina-platform_ballerina-lang/24727,remove unused import <cm-sep> prevent generating delete range when position is null <cm-sep> add models for record ast api <cm-sep> enable old parser for diagram ast for preserving ws <para-sep> get type info of the node . <nl> request to get record ast . <nl> represents with record ast . <nl> cache to contain record information .,enable old parser for diagram ast for preserving ws <nl> add models for record ast api,1594717229,"type casting ( implicit , explicit ) support added for native types .",0.9836127161979675
grpc_grpc-java/7349,fix core . <cm-sep> fix alts . <cm-sep> fix cronet .,"java 0 introduces overridden methods with covariant return types for the following methods in java.nio.bytebuffer : . <nl> - position​ ( int newposition ) <nl> - limit​ ( int newlimit ) <nl> - flip​ ( ) <nl> - clear​ ( ) <nl> - mark​ ( ) <nl> - reset​ ( ) <nl> - rewind​ ( ) . <nl> in java 0 they all now return bytebuffer , whereas the methods they override return buffer , resulting in exceptions like this when executing on java 0 and lower : . <nl> java.lang.nosuchmethoderror : java.nio.bytebuffer.limit ( i ) ljava/nio/bytebuffer . <nl> this",1598057084,"always set the remote address , no reason why this should be a tls-only <nl> feature . this is needed for channelz , and is especially useful in unit <nl> tests where we are using plaintext .",0.9005628228187561
grpc_grpc-java/7688,"allow handshakes to be interrupted by channel shutdown . <nl> if a handshake is ongoing during shutdown , this would substantially <nl> reduce the time it takes to shut down . previously , you would need to use <nl> channel.shutdownnow ( ) to have fast shutdown behavior , which is an <nl> unnecessary use of the variant . <nl> when the current approach was written writebufferingandexceptionhandler <nl> did n't exist and so it was hard to predict how the pipeline would react <nl> to events ( particularly because of http/0 handler 's re-definition of <nl> close ( ) ) . now that wbaeh exists , this is more straight-forward .","if a handshake is ongoing during shutdown , this would substantially <nl> reduce the time it takes to shut down . previously , you would need to use <nl> channel.shutdownnow ( ) to have fast shutdown behavior , which is an <nl> unnecessary use of the variant . <nl> when the current approach was written writebufferingandexceptionhandler <nl> did n't exist and so it was hard to predict how the pipeline would react <nl> to events ( particularly because of http/0 handler 's re-definition of <nl> close ( ) ) . now that wbaeh exists , this is more straight-forward .",1606957594,"in opencensus implementation we store an empty as default in thread local , but that 's an implementation detail and the behavior may vary between different implementations . update the test to compare thread-local with an api call instead , to avoid testing the underlying implementation .",0.8149923086166382
apache_pulsar/9487,update the ' -cluster ' parameter in the delete-cluster-metadata command to ' -- cluster ' . <nl> update the -cluster parameter in the delete-cluster-metadata command to -- cluster . <nl> update the -cluster parameter in the delete-cluster-metadata command to -- cluster .,# # # motivation . <nl> * change the -cluster parameter in the delete-cluster-metadata command to -- cluster for this parameter exist short name -c . <nl> * update the -cluster parameter to -- cluster .,1612483751,"docs missing . <nl> it 's not documented in the pulsar admin cli , but also supports a option .",0.7699885368347168
apache_druid/10171,"add integration tests for query retry on missing segments <para-sep> an extension point to create a custom druid service . this context is used in auto compaction . when it is set in the context , the segments created by the task <nl> this server manager is designed to test query retry on missing segments . a segment can be missing during a query if a historical drops the segment after the broker issues the query to the historical . to mimic this situation , the historical with this server manager announces all segments assigned , but reports missing segments for the first 0 segments specified in the query . <nl> query context key that indicates this query is for query retry testing . <nl> this class tests the query retry on missing segments . a segment can be missing in a historical during a query if the historical drops the segment after the broker issues the query to the historical . to mimic this case , this test spawns two historicals , a normal historical and a historical modified for testing . the later historical announces all segments assigned , but does n't serve all of them . instead , it can report missing segments for some segments . <nl> this test runs the same query multiple times . this enumeration represents an expectation after finishing running the query . <nl> expect that all runs succeed . <nl> expect that all runs returns the 0 http response , but some of them can return incorrect result . <nl> expect that some runs can return the 0 http response . for the runs returned the 0 http response , the query result must be correct . <nl> ensure that wikipedia segments are loaded completely <nl> since retry is disabled and partial result is not allowed , we can expect some queries can fail . if a query succeed , its result must be correct . <nl> since retry is disabled but partial result is allowed , all queries must succeed . however , some queries can return incorrect result . <nl> since retry is enabled , all queries must succeed even though partial result is disallowed . all queries must return correct result . <nl> disable cache so that each run hits historical . <nl> when granularity = all , there is no grouping key for this query . to","to mimic the case where historicals can report missing segments , this integration tests use 0 historicals , one normal historical and a historical modified for these tests . this modified historical announces all segments assigned , but it can report missing segments for some of them . to run them separately from other tests , these tests were added as a new test group , . the modified historical is spawned only for this test group",1594448444,this implementation follows those for s3 and googlecloud,0.9769678711891174
apache_druid/10613,"expression filter support for vectorized query engines <para-sep> null is n't really a type , so do n't claim anything <nl> otherwise , all vectorizable expressions must produce an output type to correctly operate with the vectorized engine . <nl> nil column , we can be anything , so be a string because it 's the most flexible ( numbers will be populated with default values in default mode and non-null ) <nl> need to cast to string [ ] because null columns come out as object [ ] <nl> fall through to normal math processor logic <nl> 'null ' expressions can have an output type of null , but still evaluate in default mode , so skip type checks <nl> 'null ' expressions can have an output type of null , but still evaluate in default mode , so skip type checks <nl> object predicate is currently only used by vectorized matchers for non-string object selectors . this currently means it will be used only if we encounter complex types , but will also include array types once they are more supported throughout the query engines . to preserve behavior with non-vectorized matchers which use a string predicate with null inputs for these 'nil ' matchers , we do the same thing here .","the signature of the interface method which checks if a matcher can be vectorized has been updated to accept a , so that the method can do its thing to determine if the underlying expression can be vectorized : . <nl> expression filters on string typed expressions use a new ( since string expressions most naturally use a instead of the dictionary encoded vector dimension selectors ) , and has been updated to include a method to make an object matching predicate to work with that . <nl> similarly , has been expanded with a new method to allow constructing",1606522824,"indexing service realtime : <nl> - add segmentannouncer , serverview , queryrunnerfactoryconglomerate to tasktoolbox <nl> - tasks can advertise ability to answer queries ( through returning non-null from <nl> getqueryrunner ) <nl> - workertaskmonitor ( the thing on a worker that tracks running tasks ) is now a <nl> querysegmentwalker <nl> - lockacquireaction is now blocking . <nl> standalone realtime : <nl> - metadataupdater now built from segmentannouncer , segmentpublisher instances . <nl> - sinks can take a version instead of always using interval.start . the realtime <nl> plumber selects a version using a versioningpolicy . <nl> - plumbers gained",0.9881872534751892
apache_incubator-pinot/5934,"segment processor framework <cm-sep> tests and pinot-admin command <cm-sep> mv tests <para-sep> collects and stores genericrows <nl> collects the given genericrow and stores it <nl> finish any pre-exit processing and seal the collection for reading provide an iterator for the genericrows in the collection <nl> the number of rows in the collection <nl> resets the collection of this collector by deleting all existing genericrows <nl> config for collector <nl> the type of the collector <nl> map containing aggregation types for the metrics <nl> the columns on which to sort <nl> builder for collectorconfig <nl> factory for constructing a collector from collectorconfig <nl> aggregate the metric values based on configured aggregation types on unique dimension + time column values <nl> append rows without doing any aggregations <nl> todo : add support for dedup <nl> construct a collector from the given collectorconfig and schema <nl> a collector implementation for collecting and concatenating all incoming rows <nl> a sorter for genericrows <nl> sorts the given list of genericrow <nl> max value aggregator <nl> min value aggregator <nl> a collector that rolls up the incoming records on unique dimensions + time columns , based on provided aggregation types for metrics . by default will use the sum aggregation on metrics . <nl> if a row already exists in the collection ( based on dimension + time columns ) , rollup the metric values , else add the row <nl> a representation for the keys of the generic row note that the dimensions can have multi-value columns , and hence the equals and hashcode need deep array operations <nl> note : not check class for performance concern <nl> sum value aggregator <nl> interface for value aggregator <nl> given two values , return the aggregated value <nl> factory class to create instances of value aggregator from the given name . <nl> construct a valueaggregator from the given aggregator type <nl> recordfilter which evaluates the filter function to decide whether record should be skipped or not . the filter function is expected to evaluate to true , if the record should be filtered <nl> record filter which does n't filter out any records <nl> used for filtering records in the mapper <nl> returns true if given record should be filtered out <nl> config for recordfilter <nl> the type of recordfilter <nl> filter function to use for filtering out partitions <nl> builder for a recordfilterconfig <nl> factory for","a segmentprocessorframeworkcommand is provided to run this on demand . run using command <nl> where spec.json is . <nl> note : <nl> 0. currently this framework attempts to do no parallelism in the map/reduce/segment creation jobs . each input file will be processed sequentially in map stage , each part will be executed sequentially in reduce , and each segment will be built one after another . we can change this in the future if the need arises to make this more advanced . <nl> 0. the framework makes the assumption that there 's enough memory to hold all records",1598567378,,0.0
vespa-engine_vespa/15457,split out a class that takes care of running zookeeper server . <nl> need this to simplify the way this will be done when we start supporting <nl> dynamic reconfiguration of zookeeper cluster <para-sep> writes zookeeper config and starts zookeeper server .,need this to simplify the way this will be done when we start supporting <nl> dynamic reconfiguration of zookeeper cluster .,1606299844,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9003426432609558
elastic_elasticsearch/71529,"frozen disk threshold monitor logging . <nl> frozen nodes are expected to be above 0 % disk usage , therefore we <nl> disable any logging from the disk threshold monitor until flood stage <nl> level . this commit also disables marking frozen indices read-only since <nl> if we did so we may never remove the marking again ( and they are already <nl> read-only ) . <para-sep> skip checking high/low watermarks for frozen nodes , since frozen shards have only insignificant local storage footprint and this allows us to use more of the local storage for cache . <nl> frozen is below flood stage , so no logging from it . <nl> node1 is below low watermark , so no logging from it .","frozen nodes are expected to be above 0 % disk usage , therefore we <nl> disable any logging from the disk threshold monitor until flood stage <nl> level . this commit also disables marking frozen indices read-only since <nl> if we did so we may never remove the marking again ( and they are already <nl> read-only ) .",1617982064,"previously we treated attribute filtering for -prefixed attributes a pass-through , meaning <nl> that they were essentially always treated as matching in , however , for <nl> exclude settings , this meant that the node was considered to match the node if a filter was <nl> specified . <nl> this commit prunes these attributes from the discoverynodefilters when considering the filters for <nl> so that they are only considered in .",0.9486358761787415
apache_incubator-pinot/5597,"filtering during ingestion <para-sep> with ingestion config <nl> serialize then de-serialize <nl> fixme : handle multiple_records_key for hll <nl> based on filter config , decide whether to skip or allow this record . if record should be skipped , puts a special key in the record . <nl> utility methods for extracting source and destination fields from ingestion configs <nl> the ingestion config ( e.g . filter ) can have fields which are not in the schema . <nl> no columns are derived from transformed columns <nl> expression false , not filtered <nl> expression true , filtered <nl> value not found <nl> invalid function <nl> expected <nl> multi value column <nl> gets pinot table <nl> tests filtering of records during segment generation <nl> tests many to one flattening based on presence of multiple_records_key in genericrow <nl> tests fields extraction from schema dna tableconfig for ingestion <nl> from groovy function <nl> groovy function , no arguments <nl> map implementation for avro - map__keys indicates map is source column <nl> map implementation for avro - map__values indicates map is source column <nl> time field spec only incoming <nl> incoming and outgoing different column name <nl> inbuilt functions <nl> inbuilt functions with literal <nl> inbuilt functions on datetimefieldspec <nl> class representing table ingestion configuration . for example , configs needed for decoding , data source configs , ingestion transformations ( flattening , filtering , transformations etc . ) todo : to begin with , we only have filterconfig . we will soon add transformconfig ( and move the transform function definitions from schema to this config ) <nl> todo : add a transformconfig for transform functions <nl> configs related to filtering records during ingestion <nl> this key is used by a decoder/recordreader to handle 0 record to many records flattening . if a decoder/recordreader produces multiple genericrows from the given record , they must be put into the destination genericrow as a list with this key the segment generation drivers handle this key as a special case and process the multiple records this key is used by the filtertransformer to skip records during ingestion the filtertransformer puts this key into the genericrow with value true , if the record matches the filtering criteria , based on filterconfig","tldr <nl> - new config added : . <nl> for example , consider a table with a string column campaign and a multi-value column double column prices . to filter out records where campaign = x or y and sum of all elements in prices is less than 0 . <nl> the expressions allowed here will be within the scope of the transform functions support that we have in pinot today i.e . groovy expressions , or any inbuilt functions . <nl> - filtering has been modeled as a recordtransformer called . <nl> - in order to filter the record",1592615619,"0. add a grouper scheduler which generates groupedanomaly that contains the anomalies from different anomaly functions in a certain grouping window . <nl> the end time of a grouping window is the minimum end time of the detection windows of all involved anomaly functions . the start time of a grouping window is the end time of the last grouping job ; if no such job exists , then it looks for the anomalies in the last 0 days ( by default ) . <nl> next step is to 0. add the execution pipeline for running any given grouping logic",0.9772494435310364
apache_pulsar/8931,add more information in send timeout exception . <nl> motivation . <nl> currently the timeoutexception does n't provide any useful information <nl> for troubleshooting . this change adds more information for troubleshooting .,motivation . <nl> currently the timeoutexception does n't provide any useful information <nl> for troubleshooting . this change adds more information for troubleshooting .,1607734567,"- right now , broker does n't validate dynamic-configuration value before updating it to zookeeper . so , user may update configuration with typo . <nl> - also , broker should validate dynamic-config value while starting in order to avoid picking up invalid value . <nl> eg : if someone has dynamic-config present for in old release and .0 has changed the classname then broker startup should notify invalid config value . <nl> - do dynamic-config validation before updating it <nl> - validate dynamic-config value on broker startup <nl> right now , we just have validation on configuration . <nl>",0.9324669241905212
ballerina-platform_ballerina-lang/26136,"remove parser support of service constructor and type <cm-sep> add parsing support for swan lake service part 0 changes <para-sep> indicates service remote attach point . <nl> the only case we are having 0 idents is service remote function <nl> can not have service and client qualifiers at the same time <nl> visibility is public by default for remote methods . explicit declaration is not allowed . <nl> can not have private qualifier with object member descriptors <nl> resource path is only allowed in method definition <nl> clones the first node in list with the invalid node as minutiae and update the list . <nl> note that following top level nodes can have service keyword at the beginning service-decl , service-object-type-desc and service-class-defn <nl> parse optional relative resource path .","- remove support <nl> - remove support <nl> - add qualifier support to , and <nl> - add qualifier support to <nl> - add new support . <nl> - add new support to and <nl> - replace attach point with <nl> - disallow with and . <nl> service-decl ( click to expand ) . <nl> resource-accessor-defn ( click to expand ) .",1601288429,"- to fix the compiler and cpu level issues due to the latest language changes . <nl> - fixes to stream test cases to align with the latest language changes <nl> - add initial implementation of patterns in streaming for logical patterns . <nl> logical patterns match events that arrive in temporal order and correlate them with logical relationships such as and , or and not . this pr contains the implementation of ' or ' along with a test case . with this , users can define streaming queries containing logical patterns with relationships made using ' or '",0.9838991165161133
elastic_elasticsearch/71569,"we have recently introduced the ability to associate an indexed field with a script . this commit updates the existing mappings stats to output stats about the script , similar to what we already do for runtime fields . <cm-sep> restore <para-sep> holds stats about the content of a script <nl> holds stats about a mapped field .","we have recently introduced the ability to associate an indexed field with a script . this commit updates the existing mappings stats to output stats about the script , similar to what we already do for runtime fields .",1618238939,"adds support for fetching and fields in . <nl> this only works if we can get global ordinals for those fields so we <nl> ca n't support the entire family , but this gets us somewhere .",0.9848296642303467
elastic_elasticsearch/70531,made small modifications to esresttestcase . <nl> * do n't try to invoke delete component/index templates apis if there are no templates to delete . <nl> * do n't delete deprecation templates by marking these as xpack templates . <para-sep> ideally we would want to check the version of the elected master node and send the delete request directly to that node . <nl> ideally we would want to check the version of the elected master node and send the delete request directly to that node .,* do n't try to invoke delete component/index templates apis if there are no templates to delete . <nl> * do n't delete deprecation templates by marking these as xpack templates .,1616018435,in case the local checkpoint in the latest commit is less <nl> than the last processed local checkpoint we would recover <nl> 0 ops and hence not commit again . <nl> this would lead to the logic in <nl> not seeing the latest local checkpoint when it reload the safe commit from the store <nl> and thus cause inefficient recoveries because the recoveries would work from a <nl> lower than possible local checkpoint .,0.8618918657302856
Alluxio_alluxio/12394,work <cm-sep> work <cm-sep> checkstyle <para-sep> it provides handling for submitting multiple jobs and handling retries of them . <nl> waits for at least one job to complete . <nl> wait remaining jobs to complete . <nl> wait one job to complete .,"few changes : . <nl> 0. distributedmv is now distributedcp + delete ( the async_through writetype safe guard for persisted file is now removed ) <nl> 0. distributedcp now pre-creates all of the folders from the client <nl> 0. distributedcp now submits the request one file at a time . <nl> 0. removed checkmigratevalid because once you submit files one at a time , checkmigratevalid calls getstatus on a missing file each time which is very expensive . <nl> 0. the behavior of file overwriting another file used to be broken and is still broken in this implementation",1603750265,"recall that in the future , we will only use local fs for integration tests and leave ufs part to ufs contract tests",0.9715041518211365
apache_pulsar/9312,"lazily init pulsaradmin in pulsaradmintool <cm-sep> remove debug <para-sep> other mode , all components are initialized . <nl> we are using halt and not system.exit , we do not mind about shutdown hooks they are only slowing down the tool","this initialisation process triggers lot of resource loading ( like ssl/restapi classes .... ) that slows down the jvm even for stuff that is not needed . <nl> also there are shutdown hooks that are useless by they are executed while existing from the command . <nl> removing initialisation of useless stuff helps in having a better bootstrap time , especially in case that you are not performing api calls , like when you are learning the tool and you make lots of syntax errors .",1611582973,"currently , in functions internal code , temporary files are created for purposes of downloading function packages locally . these files care never cleaned up and may linger around for a long time . in the best case , this will only cause storage to be unnecessarily wasted but in the worst case this can cause memory issues ( which usually is going to be a lot smaller than storage ) especially for brokers/workers running in containers since the whole filesystem is just in memory . <nl> clean up the temporary files that are created . to do this i",0.9447325468063354
Alluxio_alluxio/11268,cherry-pick inherit owner fix <para-sep> only set owner if not empty <nl> only set group if not empty <nl> do not call setowner/group after inheriting from parent if empty,"this pr includes 0 changes : . <nl> for s3 , when inherit_acl=false any inodes created during loadmetadata should inherit owner/group from the parent directory in alluxio instead of being empty . this was broken because setowner was called after inheritownerandgroupifempty in inodetree : :createpath <nl> when syncing metadata with s3 , an updatemetadata sync plan could lead to setting the owner and group to _ in defaultfilesystemmaster : :setattributesinglefile . the fix is to not set the options in setattributepoptions to avoid setting to an empty string or _ . <nl> this can be reproduced when a directory is",1586563762,"when doing , it outputs to console messages unnecessary . this pr removes these logs . <nl> especially , the metrics config file is optional .",0.9142109751701355
apache_druid/10186,append test <cm-sep> add append it <cm-sep> fix checkstyle <cm-sep> fix checkstyle <para-sep> ... compacted into 0 new segment for 0 day . 0 day compacted and 0 day skipped/remains uncompacted . ( 0 total ) <nl> ... compacted into 0 new segment for the remaining one day . 0 day compacted and 0 day uncompacted . ( 0 total ) <nl> ... compacted into 0 new segments across 0 days . 0 new segments each day ( 0 total ) <nl> set compactiontaskslotratio to 0 to prevent any compaction <nl> one day compacted ( 0 new segment ) and one day remains uncompacted . ( 0 total ) <nl> remaining day compacted ( 0 new segment ) . now both days compacted ( 0 total ) <nl> this query file is for the initial ingestion which is one complete dataset with roll up <nl> this query file is for the initial ingestion plus the append ingestion which are two complete dataset with roll up within each dataset ( roll up within the initial ingestion and roll up within the append ingestion but not roll up across both dataset ) . <nl> this query file is for the initial ingestion plus the append ingestion plus a compaction task after the two ingestions . this is two complete dataset with perfect roll up across both dataset . <nl> first index with dynamically-partitioned then append dynamically-partitioned <nl> first index with hash-partitioned then append dynamically-partitioned <nl> first index with range-partitioned then append dynamically-partitioned <nl> submit initial ingestion task <nl> submit append ingestion task <nl> submit compaction task <nl> verification post compaction,add integration tests for appends . <nl> the native batch ingestion currently allows appending dynamically partitioned segments regardless of the original partitioning scheme . the new integration tests include the followings : . <nl> - append dynamically-partitioned segments to a dynamically-partitioned datasource <nl> - append dynamically-partitioned segments to a hash-partitioned datasource . compact hash-partitioned segments and dynamically-partitioned segments after append . <nl> - append dynamically-partitioned segments to a range-partitioned datasource . compact range-partitioned segments and dynamically-partitioned segments after append . <nl> some notes on the tests : <nl> - note that the intervals of the appended segment overlap with those,1594789351,"opentsdb emitter sends metric names to opentsdb verbatim as what druid <nl> names them , for example ' query.count ' , this does n't fit well with a <nl> central opentsdb server which might have namespaced metrics , for example <nl> ' druid.query.count ' . this adds support for adding an optional prefix . <nl> the prefix also gets a trailing dot ( . ) , after it , so the metric name <nl> becomes . <nl> configureable as ' druid.emitter.opentsdb.namespaceprefix ' , as <nl> documented",0.9718398451805115
grpc_grpc-java/7243,"added incompletedata interface in java cel library stub <para-sep> this is a java stub for evaluating common expression language ( cel ) . once java cel has been open-sourced , this stub will be removed .",this pr added interface into the mock cel library in grpc-java . <nl> cel function will return an object if there are missing attributes .,1595461303,"this is a small property to set when testing to ensure that status matching is done correctly . calling equals on status is not well defined , and makes test flaky when adding error messages . i expect to turn this on in our unit tests , but not in production code .",0.8324648141860962
apache_shardingsphere/9371,add sqlserver with clause for update statement . <cm-sep> add sqlserver with clause for update statement . <cm-sep> add sqlserver test case for delete with clause . <cm-sep> fix sqlserver test case for update with clause . <para-sep> get with segment .,changes proposed in this pull request : <nl> - add sqlserver with clause for update statement . <nl> - add sqlserver test case for update with clause .,1612692937,changes proposed in this pull request : <nl> - fix sql test case select_with_expression <nl> - fix sql test case select_pagination_with_offset_fetch .,0.8880982398986816
elastic_elasticsearch/71882,javadoc for . <nl> this adds some javadoc for and some <nl> related classes . <para-sep> collect results for this leaf . it happens to run in constant time in some cases . this is fairly common for aggregations that have these fast paths because most of these fast paths are only possible when the aggregation is at the root of the tree . either is fine . collect results for this leaf . collects results for a particular segment .,this adds some javadoc for and some <nl> related classes .,1618864734,idp related functionality should only be available for enterprise <nl> licenses .,0.9310057163238525
apache_flink/14410,support row-based operation to accept user-defined function directly <para-sep> whether the udf takes row as input instead of each columns of a row <nl> whether the udf takes row as input instead of each columns of a row <nl> returns whether the python function takes row as input instead of each columns of a row .,"this pull request will support row-based operation to accept user-defined function directly . <nl> this change added tests and can be verified as follows : . <nl> - it test in . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager (",1608175509,"this commit adds an option in the sql api to set the auto-commit flag . <nl> for postgres , this is required to be set to false for streaming to work properly . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",0.9154942631721497
vespa-engine_vespa/16050,track requested sni servername in connection log <cm-sep> close client when closing testdriver <cm-sep> add skeleton for connection log unit test . <nl> test will be expanded once connection log contains more details,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610637109,the canary spit out lots of warnings on failure to delete directories under <nl> /home/y/var for the different containers . this commit simplifies the code and <nl> actually deletes it .,0.9360041618347168
grpc_grpc-java/7555,document thread safety of clientloadcounter properly . <para-sep> introduced for testing . interface for client side load stats store . only load stats for tracked localities will be included in generated load reports . load stats for removed localities will no longer be included in future generated load reports after this method must be thread-safe . <nl> load stats for endpoints are aggregated in locality granularity while the numbers of dropped calls are aggregated in cluster : cluster_service granularity . <nl> cluster level dropped request counts for each category decision .,"a instance will be used for tracking stats for a global cluster , and multiple client channel may retrieve the same instance for recording loads sent to the same global cluster . <nl> is already thread-safe for recording loads , mostly are just document improvements .",1603757031,"this is needed for internal issue b/0 . <nl> a particular test that runs grpc android build in a non-android <nl> environment failed because roundrobinloadbalancerprovider was deleted <nl> by proguard but the service-loader meta-inf file still referred to it , <nl> causing a loading failure . <nl> this could be fixed by adding roundrobinloadbalancerprovider to the <nl> hard-coded list , which is recognized by proguard then it will keep the <nl> class . <nl> however , we do n't expect anyone to use roundrobinloadbalancerprovider <nl> on android , including the class on android would increase code size , <nl> which",0.9120053052902222
elastic_elasticsearch/71105,"this commit adds a script parameter to long and double fields that makes <nl> it possible to calculate a value for these fields at index time . it uses the same <nl> script context as the equivalent runtime fields , and allows for multiple index-time <nl> scripted fields to cross-refer while still checking for indirection loops . <para-sep> it also supports stored fields where memoryindex does not . it is used to back index-time scripts that reference field data and stored fields from a document that has not yet been indexed . <nl> this means that a mapper script is referring to another calculated field ; in which case we need to execute that field first . we also check for loops here <nl> we ca n't just pass field.binaryvalue ( ) .bytes here as there may be offset/length considerations <nl> our storedfieldsvisitor implementations only check the name of the passed-in fieldinfo , so that 's the only value we need to set here . <nl> field scripts can be called both by the loop at the end of this method and via the document reader , so to ensure that we do n't run them multiple times we guard them with an 'executed ' boolean <nl> call the index script on all field mappers configured with one","this commit adds a script parameter to long and double fields that makes <nl> it possible to calculate a value for these fields at index time . it uses the same <nl> script context as the equivalent runtime fields , and allows for multiple index-time <nl> scripted fields to cross-refer while still checking for indirection loops .",1617187073,"moving inference to the java side can reduce overall native memory utilization and opens the door for further improvements when it comes to separating test vs training data . <nl> the model is stored first from the native process . then when all results have been read , the analytics process enters an ' inference ' phase . <nl> this inference phase loads the model via the modelloadingservice , scrolls through all the data not used for training , and infers against the model .",0.9786952137947083
elastic_elasticsearch/71080,"vector tiles : start refactoring rest layer . <nl> this is the first iteration that just extracts most obvious <nl> shared parts of vector tile and aggregated vector tile . besides <nl> removing code repetition this common basis will simplify dealing <nl> with async and other aspects of search api later on . <para-sep> base class for rest actions that performs a search and translates it into a protobuf response <nl> todo : how do we handle cancellations ? <nl> todo : of there is no hits , should we return an empty tile with no layers or a tile with empty layers ? <nl> create geometry commands <nl> add count as key value pair <nl> todo : error processing",this is the first iteration that just extracts most obvious <nl> shared parts of vector tile and aggregated vector tile . besides <nl> removing code repetition this common basis will simplify dealing <nl> with async and other aspects of search api later on .,1617133038,"make it possible to reuse the cluster state update of rollover for <nl> simulation purposes by extracting it . also now run the full rollover in <nl> the pre-rollover phase and the actual rollover phase , allowing a <nl> dedicated exception in case of concurrent rollovers as well as a more <nl> thorough pre-check .",0.9737609624862671
hazelcast_hazelcast/18047,"improve sql query cancellation . <para-sep> tests for a race condition between ' execute ' and ' close ' requests . <nl> send ' execute ' <nl> send ' close ' <nl> send ' close ' <nl> send ' execute ' <nl> no-op . <nl> no-op . <nl> starts execution of an sql query ( as of version ) . <nl> hex : 0x210400 <nl> hex : 0x210401 <nl> schema name . <nl> the expected result type . possible values are : any ( 0 ) rows ( 0 ) update_count ( 0 ) <nl> query id . <nl> this file is auto-generated by the hazelcast client protocol code generator . <nl> this message is no longer used but kept for backward compatibility tests starts execution of an sql query . <nl> hex : 0x210100 <nl> hex : 0x210101 <nl> query string . <nl> query parameters . <nl> timeout in milliseconds . <nl> cursor buffer size . <nl> query id . <nl> row metadata . <nl> row page . <nl> whether the row page is the last . <nl> the number of updated rows . <nl> error object . <nl> whether the result is possibly infinite , i.e . it may have an infinite number of rows , and creation of the next row may take infinite time . <nl> a wrapper around the normal client result that tracks the first response , and manages close requests . mutex to synchronize access between operations . * / <nl> the current result state . * / <nl> whether the iterator has already been requested . * / <nl> whether the result is closed . / fetch descriptor . available when the fetch operation is in progress . / <nl> the result is already closed , ignore the response . <nl> do nothing if the result is already closed . <nl> if the cancellation is initiated before the first response is received , then throw cancellation errors on the dependent methods ( update count , row metadata , iterator ) . <nl> make sure that all subsequent fetches will fail . <nl> send the close request . <nl> set the closed flag to avoid multiple close requests . <nl> mark result as closed . invoked when we received an update count or the last page . <nl> fetches the next page . <nl> re-throw previously logged error on successive fetch attempts .","this pr adds the ability to cancel the query while there is an active request to the server . goals : <nl> 0. allow for query cancellation before the response is received . this is important for jet queries and long-running imdg queries because otherwise , users can not cancel these queries <nl> 0. allow for query cancellation while the request is in progress , which will be used by the jdbc driver in the future . <nl> 0. facilitate the future implementation of a non-blocking sql client handler . <nl> the following changes are introduced : <nl> 0. query",1610349868,"- current in-flight migration detection mechanism is racy . <nl> observed at the beginning of query execution can be the already updated . <nl> so , any change of may not be noticed . <nl> there 's no ordering between / and update of , because we can apply promotion commits and source migration commits in batches to increase availability . that 's why / and update of can be executed concurrently . <nl> instead of comparing and counting in-flight migrations , map service now uses two counters ; one for started migrations and one for completed migrations . we",0.9743878245353699
grpc_grpc-java/7740,"bump android sdk version for grpc-cronet ; migrate to androidx . <cm-sep> bump android sdk version for grpc-android , suppressed warnings for using deprecated networkinfo api , which is intended for supporting old api version ; migrate to androidx . <cm-sep> bump android sdk version for android-interop-testing , migrate to androidx , bump its corresponding dependency versions .","- migrated to , which is required for android q . <nl> - is deprecated in sdk 0 , suppressed compiler warnings as it is needed for supporting old android versions . <nl> - robolectric requires java 0+ for android 0 , which causes unit tests in grpc-cronet fail . added annotation to emulate android 0 for grpc-cronet 's test . <nl> - upgraded android dependencies accordingly in android-interop-testing . <nl> also , android examples are not updated .",1608538284,"this is needed for internal issue b/0 . <nl> a particular test that runs grpc android build in a non-android <nl> environment failed because roundrobinloadbalancerprovider was deleted <nl> by proguard but the service-loader meta-inf file still referred to it , <nl> causing a loading failure . <nl> this could be fixed by adding roundrobinloadbalancerprovider to the <nl> hard-coded list , which is recognized by proguard then it will keep the <nl> class . <nl> however , we do n't expect anyone to use roundrobinloadbalancerprovider <nl> on android , including the class on android would increase code size , <nl> which",0.9239698052406311
Alluxio_alluxio/11299,"improve performance of sasl authentication . <nl> before this pr , the impersonationauthenticator class could effectively <nl> bottleneck the amount of concurrent channels that a worker could handle . <nl> the for the impersonationauthenticator class required iterating <nl> over <nl> all keys within an alluxio configuration , not only doing key lookups , <nl> but also <nl> performing regex matching . for some keys this could be especially <nl> expensive <nl> ( i.e , default supplier which calls <nl> runtime.getruntime ( ) .availableprocessors ( ) ) . <nl> on top of that , performing regex matching is also quite expensive for a <nl> few <nl> hundred keys . <nl> after taking a quick peek at the code it seems that it 's entirely <nl> unnecessary to <nl> instantiate the impersonation authenticator for every new handler that <nl> we <nl> create . instead , it can just be a field within the <nl> defaultauthenticationserver . <nl> then , it only ever needs to be instantiated once . <para-sep> note the constructor for this object is expensive . take care with how many of these are instantiated .","before this pr , the impersonationauthenticator class could effectively <nl> bottleneck the amount of concurrent channels that a worker could handle . <nl> the for the impersonationauthenticator class required iterating over <nl> all keys within an alluxio configuration , not only doing key lookups , but also <nl> performing regex matching . for some keys this could be especially expensive <nl> ( i.e , default supplier which calls runtime.getruntime ( ) .availableprocessors ( ) ) . <nl> on top of that , performing regex matching is also quite expensive for afew <nl> hundred keys . <nl> after taking a quick",1586934747,this pr updates the metrics documentation and adds corresponding support for ufs writes,0.8928717970848083
apache_incubator-pinot/5687,adding zookeeper resource to browse zk data via controller api <cm-sep> fixing api documentation <cm-sep> fixing api documentation <cm-sep> fixing api documentation,"this can be used to view the contents of zk without having to start zooinspector . <nl> this is a precursor to provide a ui component in the controller to explore zk contents . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1594535791,implements the runner that generates data sla anomalies . data_missing anomalies are created if the data is not available for the sla detection window within the configured sla . <nl> also inclues : <nl> * logic to merge sla anomaly with existing and mark them as parent-child . <nl> * unit tests covering various data missing use-cases,0.979773223400116
pentaho_pentaho-kettle/7479,"pdi-core is not sending any extensionpoint events if there are any failure during transformation preparation step <nl> trans.java is throwing a kettleexception when there is any error in the transformation <nl> preparation step but it is not sending any kettle extensionpointevents <nl> to indicate that the transformation had finished with errors . this makes <nl> it impossible for the plugins that are relying on the <nl> extensionpointevents to track the status of the execution . <nl> added code in pancommandexecutor to send transformationfinish event in <nl> case there is any error in transformation preparation <para-sep> this method test a valid ktr and make sure the callextensionpoint is never called , as this method is called if the ktr fails in preparation step <nl> execute a sample ktr <nl> this method test a ktr that fails in preparation step and and checks to make sure the callextensionpoint is called once . <nl> execute a sample ktr",pdi-core is not sending any extensionpoint events if there are any failure during transformation preparation step . <nl> trans.java is throwing a kettleexception when there is any error in the transformation <nl> preparation step but it is not sending any kettle extensionpointevents <nl> to indicate that the transformation had finished with errors . this makes <nl> it impossible for the plugins that are relying on the <nl> extensionpointevents to track the status of the execution . <nl> added code in pancommandexecutor to send transformationfinish event in <nl> case there is any error in transformation preparation,1590517851,- backport of - udjc can not read fields from table input info step ( version suite ) .,0.8663148880004883
apache_druid/10248,"fix bug with realtime expressions on sparse string columns <para-sep> merge logic for the state capabilities will be in after incremental index is persisted <nl> name lookup is possible in advance if we explicitly process a value for every row , or if we 've encountered an actual null value and it is present in our dictionary . otherwise the dictionary will be missing ids for implicit null values <nl> strings are opportunistically multi-valued , but the capabilities are initialized as 'unknown ' , since a multi-valued row might be processed at any point during ingestion . we only explicitly set multiple values if we are certain that there are multiple values , otherwise , a race condition might occur where this indexer might process a multi-valued row in the period between obtaining the capabilities , and actually processing the rows with a selector . leaving as unknown allows the caller to decide how to handle this . <nl> likewise , only set dictionaryencoded if explicitly if true for a similar reason as multi-valued handling . the dictionary is populated as rows are processed , but there might be implicit default values not accounted for in the dictionary yet . we can be certain that the dictionary has an entry for every value if either of a ) we have already processed an explitic default ( null ) valued row for this column b ) the processing was not 'sparse ' , meaning that this indexer has processed an explict value for every row is true . <nl> this interface is used to expose information about columns that is interesting to know for all matters dealing with reading from columns , including query planning and optimization , creating readers to merge segments at ingestion time , and probably nearly anything else you can imagine . column type , good to know so caller can know what to expect and which optimal selector to use <nl> is the column dictionary encoded ? if so , a dimensiondictionaryselector may be used instead of using a value selector , allowing algorithms to operate on primitive integer dictionary ids rather than the looked up dictionary values <nl> if the column is dictionary encoded , are those values sorted ? useful to know for optimizations that can defer looking up values and allowing sorting with the dictionary ids directly <nl> if the column is dictionary","in the code there is a gentleman 's agreement that if is true then is also true , and appears to be checked primarily in cases where this should also be true . <nl> to fix this , a method has been added to , to allow the thing processing all the column values to be the single state of truth about the details of the column . it also frees from having to track and evolve changes to the capabilities , since it can now be handled within the indexers , though it still maintains a map of static",1596708837,* the default timeout is 0 which was previously . <nl> * 0 timeout means no timeout which previously means no wait .,0.9838464856147766
apache_beam/12874,"use dense json responses for bigqueryio interactions . <nl> this updates requests made by the bigquery io connector to include the underlying <nl> get param to use dense json encoding . <nl> without it , bigqueryio receives pretty-printed json responses from the <nl> bigquery service , which represent a significant inflation in <nl> unneccessary whitespace bytes .","this updates requests made by the bigquery io connector to specify the underlying prettyprint=false <nl> get param to have bigquery return dense json responses . <nl> without it , bigqueryio receives pretty-printed json responses from the <nl> bigquery service , which represent a potentially significant inflation in <nl> unnecessary whitespace bytes",1600464005,"motivation . <nl> - cleanup the code of on register process boundle descriptor . <nl> - correct the implementation of fn api , i.e. , would be better to cater to the asynchronous design principles of the beam api . <nl> changes <nl> - 0 : <nl> update the client side implementation of fn api to make sure registration is executed successfully before executing process_bundle . personally i think that the client side implementation of fn api should not assume that the implementation of registration in sdk harness is synchronous . the registration api itself is asynchronous and the client",0.9122836589813232
apache_kafka/10059,": saslchannelbuilder - avoid dns lookup while building underlying ssltransportlayer . <para-sep> prefer if a instance is available . if using this overload , avoid reverse dns resolution in the computation of . returns host/ip address of remote host without reverse dns lookup to be used as the host for creating ssl engine . this is used as a hint for session reuse strategy and also for hostname verification of server hostnames . scenarios : server-side server accepts connection from a client . server knows only client ip address . we want to avoid reverse dns lookup of the client ip address since the server does not verify or use client hostname . the ip address can be used directly . client-side client connects to server using hostname . no lookup is necessary and the hostname should be used to create the ssl engine . this hostname is validated against the hostname in subjectaltname ( dns ) or commonname in the certificate if hostname verification is enabled . authentication fails if hostname does not match . client connects to server using ip address , but certificate contains only subjectaltname ( dns ) . use of reverse dns lookup to determine hostname introduces a security vulnerability since authentication would be reliant on a secure dns . hence hostname verification should fail in this case . client connects to server using ip address and certificate contains subjectaltname ( ipaddress ) . this could be used when kafka is on a private network . if reverse dns lookup is used , authentication would succeed using ip address if lookup fails and ip address is used , but authentication would fail if lookup succeeds and dns name is used . for consistency and to avoid dependency on a potentially insecure dns , reverse dns lookup should be avoided and the ip address specified by the client for connection should be used to create the ssl engine .","how the problem was manifested : <nl> when clients or other brokers are connecting to a broker using sasl_ssl , a broker was doing ( reverse ) dns lookup and if there is no ptr record , the lookup could last several seconds , which in the end caused big latencies on several parts of the system ... replication , consume requests and produce requests . <nl> here you can see a recorded sample : . <nl> also , here is a wireshark packet capture for dns requests , and in this case you can see that it lasted more",1612476042,"since generation is private in abstractcoordinator , i need to modify the generation ( ) to let it return the object directly .",0.9139381647109985
neo4j_neo4j/11391,"internal byte [ ] reuse in stringschemakey . <nl> which should lower garbage churn during range results <nl> as well as improve performance . <para-sep> bytes , grows on demand . actual length is dictated by byteslength field . <nl> set to true when the internal byte [ ] have been handed out to an utf8value , so that the next call to setbyteslength will be forced to allocate a new array . the byte [ ] is n't cleared with null since this key still logically contains those bytes . <nl> dereference our bytes so that we wo n't overwrite it on next read <nl> allocate a bit more than required so that there 's a higher chance that this byte [ ] instance can be used for more keys than just this one <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then",which should lower garbage churn during range results <nl> as well as improve performance .,1522093353,where changing processor count frequently back and forth could potentially <nl> result in processor threads staying alive longer than expected and could <nl> affect the result of the processed units . this in turn could result in a <nl> deadlock where the completedbatchsender could forever observe some <nl> batches as incomplete whereas they actually were .,0.9486478567123413
ballerina-platform_ballerina-lang/25021,add missing contexts for resumeparsing . <nl> added missing contexts for resumepasing and added tests to verify those . <para-sep> parse object visibility . visibility can be public or private .,"split resumeparsing method . <nl> resolve conflicts in resumeparsing . fix parsetypedbindingpatternorexprrhs . <nl> split the resumeparsing method as top level nodes , statements , keywords , expresssionsandactions and others . <nl> resolved conflicts in the resumeparsing method . <nl> fixed how parsetypedbindingpatternorexprrhs handles syntaxkind.none returned by the error handler .",1596024241,"- to fix the compiler and cpu level issues due to the latest language changes . <nl> - fixes to stream test cases to align with the latest language changes <nl> - add initial implementation of patterns in streaming for logical patterns . <nl> logical patterns match events that arrive in temporal order and correlate them with logical relationships such as and , or and not . this pr contains the implementation of ' or ' along with a test case . with this , users can define streaming queries containing logical patterns with relationships made using ' or '",0.9760099649429321
ballerina-platform_ballerina-lang/24613,"use original caller request as the cache validation request <para-sep> a cache must not generate a stale response if it is prohibited by an explicit in-protocol directive <nl> no need to worry about no-store directive here since we do n't cache responses with no-store directives . <nl> set the precondition headers only if the user has n't explicitly set them . <nl> have to remove the precondition headers from the request if they were n't user provided . <nl> since this request gets served straight from the cache , the value of ' x-caller-req-header ' does n't change .","previously , a brand new http request was made to the backend as a validation request , with the necessary precondition headers . with this pr , this is changed to use the original caller request itself as the validation request , with the precondition headers added , if they are n't there .",1594060421,"however this may not be ideal with commands other than the run command , such as the build command which takes the -o option as the output file name . <nl> the following should both work : . <nl> this pr changes the behaviour to enforce ordering only with the run command .",0.9144865870475769
jenkinsci_jenkins/5012,tcpslaveagentlistener.connectionhandler.run : move allocation of output writer to error method <cm-sep> tcpslaveagentlistener.connectionhandler.error : replace printwriter to dataoutputstream <cm-sep> tcpslaveagentlistener.connectionhandler.respondhello : replace outputstreamwriter by dataoutputstream to avoid allocation of big buffer <cm-sep> tcpslaveagentlistener.connectionhandler.run : replace charsets to standardcharsets <cm-sep> tcpslaveagentlistener.connectionhandler : fix encoding of response <cm-sep> remove unused imports,optimizations of input and output streams creation in tcpslaveagentlistener . <nl> reduce allocation of 8kb at each request ( allocated in only if error ) <nl> * entry 0 : reduce allocation of 8kb at each http get ( monitoring ) request,1602944056,"proposed changelog entries : . <nl> if you have the authorize project plugin installed and configured , its configuration will now be treated as final with respect to the behavior of job/build checks from build other projects and build after other projects are built . formerly , if a per-project configurable build authorization was enabled globally but some projects did not specify an authorization , the two aforementioned checks would automatically fall back to checking as anonymous ( typically denying build permission ) . to restore the former behavior , explicitly configure a project default build authorization to be run",0.9089133739471436
neo4j_neo4j/11441,"introduces 'additive ' property of store capability . <nl> so that it can be checked when comparing capabilities of two formats <nl> purely additive capability additions can be seen as compatible too . <cm-sep> fixes an accidental counts store delete on no-op migration <para-sep> if they have the same capabilities then of course they are compatible <nl> even if capabilities of the two are n't the same then there 's a special case where if the additional capabilities of the other format are all additive then they are also compatible because no data in the existing store needs to be migrated . <nl> whether or not this capability is additive . a capability is additive if data regarding this capability will not change any existing store and therefore not require migration of existing data . <nl> delete any current count files in the store directory . <nl> move the migrated ones into the store directory <nl> allow to skip non existent source files <nl> we do not need to move files with the page cache , as the count files always reside on the normal file system . <nl> given <nl> then <nl> given <nl> then <nl> given <nl> then <nl> given <nl> then <nl> given <nl> when <nl> then","when checking their list of capabilities . this was useful to add for version since the added capabilities ( temporal/spatial property types ) does n't require the data in the existing store to be migrated . <nl> there was also a counts store migrator issue where the counts store were accidentally and unnecessarily rebuilt after a migration ( due to them accidentally being deleted ) even if no counts store migration was required . <nl> with this change version - > version migration only changes the file , tagging it with the new store version , nothing more .",1522756922,to make sure it is possible to specify as well as in <nl> setting . <nl> changelog : made possible to allow node id reuse using 'dbms.ids.reuse.types.override ' setting .,0.9734044671058655
apache_pulsar/9064,"( if this pr fixes a github issue , please add ) . <nl> fixes # . <nl> ( or if this pr is one task of a github issue , please add <nl> to link to the master issue ) . <nl> master issue : # . <nl> motivation . <nl> describe here the context , and why you 're making that change . <nl> what is the problem you 're trying to solve . <nl> modifications . <nl> describe the modifications you 've done . <nl> verify this change . <nl> please pick either of following options . <nl> - this change is a trivial rework / code cleanup without any test coverage . <nl> - this change is already covered by existing tests , such as ( please describe tests ) . <nl> - this change added tests and can be verified as follows : <nl> ( example : ) <nl> - added integration tests for end-to-end deployment <nl> - extended integration test for recovery after broker failure <para-sep> the auth provider will call this method to initiate the refresh process . <nl> test rest by admin <nl> acknowledge the consumption of all messages at once <nl> get the first connection stats <nl> the token expire duration is 0 seconds , so we need to wait for the authenticationdata refreshed <nl> get the lastdisconnecttime , it should be same with the before , because the connection should n't disconnect <nl> acknowledge the consumption of all messages at once",motivation . <nl> some authentication provider is using cached authentication data . until <nl> redoing the 'getauthdata ' then it will provide the new auth data . so <nl> i add a refresh command and do the refresh authentication data provider <nl> when received the command . <nl> verify this change . <nl> - existent tests can pass .,1608891487,"when using a multi-broker service url to create a producer , if the connection to the first broker failed , the creation will fail . <nl> add backoff retries when getting partitioned metadata from brokers .",0.9630325436592102
netty_netty/10814,iovarray should support when there is no unsafe present . <nl> motivation : . <nl> in some enviroments sun.misc.unsafe is not present . we should support these as well . <nl> modifications : . <nl> fallback to jni if we ca n't directly access the memoryaddress of the buffer . <nl> result : . <para-sep> fallback to using jni as we were not be able to access the address otherwise .,motivation : . <nl> in some enviroments sun.misc.unsafe is not present . we should support these as well . <nl> modifications : . <nl> fallback to jni if we ca n't directly access the memoryaddress of the buffer . <nl> result : .,1606117910,"abstractdiskhttpdata # getchunk closes filechannel only if everything was read or an exception is thrown . <nl> motivation : . <nl> abstractdiskhttpdata # getchunk opens and closes filechannel every time when it is invoked , <nl> as a result the uploaded file is corrupted . <nl> modifications : . <nl> - close the filechannel only if everything was read or an exception is thrown <nl> - add unit test . <nl> result : . <nl> abstractdiskhttpdata # getchunk closes filechannel only if everything was read or an exception is thrown",0.9499343037605286
ballerina-platform_ballerina-lang/26822,fix org.ballerinalang.test.balo.constant.simpleconstantbalonegativetests <cm-sep> fix org.ballerinalang.test.balo.constant.mapconstantpanicinbalotest <cm-sep> fix io.ballerina.semantic.api.test.symbolbirtest <cm-sep> fix org.ballerinalang.test.balo.types.nevertypebalotest <cm-sep> remove redundant afterclass method in unit test,- org.ballerinalang.test.balo.constant.simpleconstantbalonegativetest <nl> - org.ballerinalang.test.balo.constant.mapconstantpanicinbalotest <nl> - io.ballerina.semantic.api.test.symbolbirtest <nl> - org.ballerinalang.test.balo.types.nevertypebalotest .,1604913521,example : . <nl> in such cases the blangerrortype does not have reason or detail . this caused a null pointer exception . <nl> fix 0 : error types are not supported for api docs . as of now this is skipped .,0.9055895805358887
apache_kafka/9998,"add metadata record serde for <para-sep> an apimessage and an associated version . <nl> serde interface for records written to the raft log . this class assumes a two-pass serialization , with the first pass used to compute the size of the serialized record , and the second pass to write the object . get the size of a record . <nl> write the record to the output stream .",this patch adds a implementation for the metadata record format expected by .,1611899938,"jira ticket <nl> jira ticket . <nl> the changes here are simple : <nl> • : a few checks to ensure that constructor parameters in the and classes are non-null and non-empty are fixed . the current logic erroneously ensures that they are either null or empty . <nl> • : a bug in how the connect framework instantiates objects for use by rest extensions ( specifically , incorrect order in arguments provided to a constructor ) is fixed . the current logic , while erroneous , should never have arisen in the past by rest extension developers , as",0.9706723093986511
OpenAPITools_openapi-generator/7604,respects multiple responses during typespec generation <cm-sep> generate samples,"this pr fixes the wrong typespec for mutiple return types . <nl> it does first building and generating a list for every return type defined . those are saved in a hashlist to ensures that every defintion will only be present once . <nl> after that , the list will be added to the existing stringbuffer and adding the at the end of the typespec .",1601895966,"summary <nl> - generators without runtime models conversion use ' original ' property naming by default . it 's still possible to change it via cli options - might be helpful when used together with customized templates . the cli option description has been modified to provide some more context . <nl> - generators with runtime conversion ( typescript-fetch , typescript-node , typescript-reduxquery ) keep using ' camelcase ' . <nl> implementation notes <nl> - i decoupled from . former respects the , while latter keeps always using camelcase . <nl> - refactoring : use an enum instead of string",0.9025868773460388
apache_beam/13161,fix split ( ) logic for pubsubliteio to split to groups instead of groups of size,pubsubliteio should split to groups instead of groups of size,1603303722,splitting cassandraio source into multiple sources works fast as it uses one connection pool to cassandra cluster but after that dataflow.worker.workercustomsources is calling cassandrasource.getestimatedsizebytes for each source which setups and tears down connection to cassandra cluster to calculate same size of table . this optimization introduces caching of size internally just to avoid additional queries,0.8527308106422424
vespa-engine_vespa/15985,add possibility to select a subset of groups and apply random selection among them . <para-sep> pick any working group <nl> an asterisk or forward slash or an empty string followed by a comma or the end of the string,add possibility to select a subset of groups and apply random selection among them .,1610364192,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9650656580924988
netty_netty/10997,enable stateless resumption for tlsv1.0 by default when using openssl / boringssl . <nl> motivation : . <nl> at the moment we always set ssl_op_no_ticket when building our context . the problem with this is that this also disables resumption for tlsv1.0 in boringssl as it only supports stateless resumption for tlsv1.0 which uses tickets . <nl> we should better clear this option when tlsv1.0 is enabled to be able to resume sessions . this is also inline with the openjdk which enables this for tlsv1.0 by default as well . <nl> modifications : . <nl> check for enabled protocols and if tlsv1.0 is set clear ssl_op_no_ticket . <nl> result : . <nl> be able to resume sessions for tlsv1.0 when using boringssl . <para-sep> we should enable session tickets for stateless resumption when tlsv1.0 is enabled .,enable stateless resumption for tlsv1.0 by default when using openssl / boringssl . <nl> motivation : . <nl> at the moment we always set ssl_op_no_ticket when building our context . the problem with this is that this also disables resumption for tlsv1.0 in boringssl as it only supports stateless resumption for tlsv1.0 which uses tickets . <nl> we should better clear this option when tlsv1.0 is enabled to be able to resume sessions . this is also inline with the openjdk which enables this for tlsv1.0 by default as well . <nl> modifications : . <nl> check for enabled protocols,1612534338,"fix issue when ssl is used on top of the multipat , specially when using post of a file , since it can change the overall size and therefore giving a real chunk message while it was supposed to not be chunked . <nl> proposal is to allow the user to force chunk mode . <nl> specially usefull when the user know that his code will be using ssl . then it creates the encoder with the chunkeforce set to true .",0.909127950668335
gocd_gocd/8222,update notification filters api v2 to allow a default value for which is false . <nl> this is inline with v1 api ( rails based ) as well as our api docs which does not say that this attribute 'must ' be provided . <cm-sep> updated the preferences page wrt to changes of api v2 responses .,description : <nl> - set a default value to as . this is inline with our api docs which does not mention for this attribute . <nl> - updated the preferences page to respond to response data wrt v2 api .,1591852001,noticed the following validation notification in the email settings : . <nl> fixing a couple of old spelling mistakes . should not have an all too large of an impact,0.732306718826294
hazelcast_hazelcast/18431,"fix handling of user-provided default schema . <para-sep> if some of objects used in the plan have changed , then the plan should be re-created .","the pr lacks a test because it 's not possible to test it in imdg because imdg currently uses only a single schema ( ) and any value here is ignored . <nl> a test could be added to jet , but on the other hand , jet does n't yet depend on imdg version . but i tested it locally . ¯\_ ( ツ ) _/¯",1616505354,this backport differs just in configuration part . instead of xml+java config model support the behavior is controlled by a new hazelcast group property . <nl> allowed values remain the same : <nl> * ( default ) <nl> * <nl> *,0.875843346118927
apache_pulsar/9321,"add expired token alert . <para-sep> get token <nl> parse token by validating <nl> expected , token was expired","currently , pulsar-broker does not provide additional alerts about expired and expiring soon tokens . <nl> * add additional alerts metrics for expired tokens . <nl> * add histogram metrics for expiring tokens , and record the remaining time in minutes . <nl> * has the following buckets with different remaining time periods : 0 mins , 0 mins , 0 hour , 0 hours . <nl> this change is already covered by existing tests , such as testexpiredtokenmetrics and testexpiringtokenmetrics . <nl> when authenticating tokens whose remaining time is 0 mins , 0 mins , 0 mins , 0",1611649540,"added option to limit the size of http requests made to broker . this can prevent users from triggering exceptions such as objects too big on zk and , in general , abnormal mem usage on brokers . <nl> by default , no limit is applied .",0.9689034819602966
Alluxio_alluxio/11016,fix ' in alluxio ' calculation for ducommand <para-sep> matches the output of the du command using a regex pattern . the input string to the,"previously , we were always using the ' inmemorypercentage ' to calculate the <nl> total amount in alluxio . this is incorrect . we will now use the proper value",1582670781,add integration tests for using uris with connect details in authorities to connect to <nl> alluxio cluster through hadoop filesystem,0.939043402671814
elastic_elasticsearch/70543,"basic working auth for service account <cm-sep> working on tests <cm-sep> fix token service <para-sep> let the javaresttest see the classpath of main <nl> because http.ssl.enabled = true <nl> intentionally ignore the returned exception ; we call this primarily for the auditing as we already have a purpose built exception <nl> if the token is non-null , then it is validated , which might include authenticated decryption and verification that the token has not been revoked or is expired . <nl> typically this means that the index is unavailable , so _probably_ the token is invalid but the only this we can say for certain is that we could n't validate it . the logs will be more explicit . <nl> same wrong token <nl> in case of failure , evict the cache entry and notify all listeners <nl> package private for testing <nl> this is done on the current thread instead of using a dedicated thread pool like api key does because it is not expected to have a large number of service tokens . <nl> pkg private for testing <nl> 1st auth with the right token1 <nl> 2nd auth with the right token1 should use cache <nl> 3rd auth with the wrong token1 that has the same qualified name should use cache <nl> 4th auth with the wrong token2 <nl> 5th auth with the wrong token2 again should use cache <nl> 6th auth with the right token2 <nl> invalidate token1 in the cache <nl> 7th auth with the right token1 <nl> invalidate all items in the cache <nl> authenticate should still work <nl> less than 0 bytes <nl> prefix mismatch <nl> no colon <nl> invalid delimiter for qualified name <nl> invalid token name <nl> everything is good <nl> serialise and de-serialise service account token <nl> invalid magic byte <nl> no colon <nl> invalid qualified name <nl> invalid token name <nl> everything is fine <nl> valid token <nl> non-elastic service account <nl> unknown elastic service name <nl> success based on credential store",this the 3rd pr for service accounts . it adds support for authentication with file tokens . it also adds a cache for performance so that expensive pbkdf2 hashing does not have to be performed on every request . adding a cache comes with its own housekeeping work around invalidation . this pr ensures that cache gets invalidated when underlying token file is changed . it does not implement apis for active invalidation . i plan to have them as a separate pr ( after the api token is in place ) .,1616060047,"the searchable snapshots cache implemented in version is <nl> not persisted across node restarts , forcing data nodes to <nl> download files from the snapshot repository again once <nl> the node is restarted . <nl> this commit introduces a new lucene index that is used <nl> to store information about cache files . <nl> since data nodes can have one or more data paths , this <nl> change introduces a lucene index per data path . information <nl> about cache files are updated in the lucene index located <nl> on the same data path of the cache files .",0.9844003319740295
jenkinsci_jenkins/4967,"performance issue , string concatenation in loop <cm-sep> java 0 migration . replace statements with lambda <cm-sep> revert ' performance issue , string concatenation in loop ' . <nl> this reverts commit sha .",* no changelog for internal code transformations,1601742149,"plugins that may affect the view , eg via transientviewactionfactory <nl> that get installed _after_ a has been initally viewed <nl> will not be able to add anything to the view if the results <nl> of getactions ( ) are cached . <nl> * entry 0 : removed caching in views - plugins that affected the view , but are installed _after_ the initial rendering/viewing of the will not be called again and do not contribute to the . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8005596399307251
apache_kafka/10072,": throw taskcorruptedexception instead of timeoutexception when tx commit times out . <nl> instead , we will throw a taskcorruptedexception <nl> to retry the tx if the commit failed .","instead , we will throw a taskcorruptedexception <nl> to retry the tx if the commit failed .",1612568690,"this is a general change and is re-requisite to allow streams benchmark test with different streams tests . for the streams benchmark itself i will have a separate pr for switching configs . details : . <nl> 0. create a ' streams.properties ' file under persistent_root before all the streams test . for now it will only contain a single config of state.dir pointing to persistent_root . <nl> 0. for all the system test related code , replace the main function parameter of state.dir with propsfilename , then inside the function load the props from the file and apply overrides",0.9579536318778992
elastic_elasticsearch/71264,"fix search states of ccs requests in mixed cluster <cm-sep> adjust bwc <para-sep> we execute tests 0 times . - the local cluster is unchanged and it consists of an old version node and a new version node . - nodes in the remote cluster are upgraded one by one in three steps . - only and of the remote cluster can accept remote connections . this can creates a test scenario where a query request and fetch request are sent via proxy nodes that have different version . <nl> this test ensure that we keep the search states of a ccs request correctly when the local and remote clusters have different but compatible versions . see searchservice # createandputreadercontext <nl> previously , the search states are stored in readercontext on data nodes . since version , they are now sent to the coordinating node in querysearchresult and the coordinating node then sends them back in shardfetchsearchrequest . we must keep the search states in readercontext unless the coordinating node is guaranteed to send them back in the fetch phase . three cases that we have to keep the search states in readercontext : 0. scroll requests 0. the coordinating node or a proxy node ( i.e . ccs ) is on the old version . the of shardsearchrequest , which is the minimum version of nodes that the request has been passed , can be used to determine this . 0. any node on the cluster is on the old version . this extra check is to avoid a situation where a shardsearchrequest is sent via a new proxy node , but a shardfetchsearchrequest on an old proxy node . note that it 's ok to keep the search states in readercontext even when the coordinating node also sends them back in the fetch phase and it only happens in a mixed cluster . <nl> returns the minimum version of the channel that the request has been passed . <nl> todo : add the context <nl> new version <nl> old version <nl> any version","previously , the search states are stored in readercontext on data nodes . since version , we send them to the coordinating node in a querysearchresult of a ` shardsearchrequest and the coordinating node then sends them back in shardfetchsearchrequest . we must keep the search states in data nodes unless they are sent back in the fetch phase . we used the channel version to determine this guarantee . however , it 's not correct in ccs requests in mixed clusters . <nl> 0. the coordinating node of the local cluster on the old version sends a shardsearchrequest to",1617402281,( cherry picked from commit sha ),0.9824643731117249
vespa-engine_vespa/15367,support default request/response filters per connector . <nl> filter requests using default request/response filter if no other filters matches the request uri . <cm-sep> allow extra dimensions for request based metric dimensions . <nl> remove metric context cache . i doubt it will have any significant impact on performance . <cm-sep> move metricconsumermock to separate class <cm-sep> add metrics for request filtering <para-sep> todo ( gjoranv ) : remove,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605619430,"this changes the waiting for federation target completion such that targets are not allowed to increase the latency after they have timed out . <nl> i suggest you skip the refactor commits and look at the last one . <nl> this test now depends on progress against system time and blocks a thread for about version seconds total . the problem with avoiding it is that the waitforall method owns the thread until everything has happened . i guess i could advance a manual clock when the mockresult is called instead , but it seems messy/hard . let me know",0.9839288592338562
ballerina-platform_ballerina-lang/24225,"disallow modifying langlib methods on immutable values <cm-sep> add tests for disallowing modifying langlib methods on immutable values <para-sep> lang.array - array , tuple . <nl> lang.map - map , record . <nl> lang.table <nl> lang.value <nl> lang.xml",this pr also fixes org.wso2.ballerinalang.compiler.semantics.analyzer.types # gettableconstraintfield not considering intersection types .,1592328347,"is a map containing namespace p1 , p2 and attribute . <nl> returns true as nonsingleton is a xml sequence .",0.9712725281715393
apache_druid/10340,"fix variance aggregator comparator . <nl> the comparator for the variance aggregator used to compare values using the <nl> count . this is now fixed to compare values using the variance . if the variance <nl> is equal , the count and sum are used as tie breakers .","the comparator for the variance aggregator used to compare values using the <nl> count . this is now fixed to compare values using the variance . if the variance <nl> is equal , the count and sum are used as tie breakers . <nl> this patch also fixes a bug where we assumed that the aggregator could not <nl> return null because druid did not support sql compatible mode . it appears that <nl> this extension was written in 0 before sql compatible mode was introduced <nl> ~ 0",1599004589,"this pr adds a timeout to the future.get method call in used with if is set on the query context of the query , to plug up a potential hole which would allow the broker to overshoot query timeout . <nl> using does mean that ( as far as i can tell ) this currently only works with the used by , since otherwise we would need to pass in request start time in order to set the correct timeout of the remaining timeout on the future . and do not seem to have direct access to any sort of",0.9617065191268921
elastic_elasticsearch/71233,add ability for monitoring_user role to read from metricbeat- *,the stack monitoring ui will soon read from indices and needs to adjust the reserved role to allow permission to this index .,1617372069,"access the common versions map is done in a lot of places . while it can <nl> be access through an import of versionproperties , the vast majority of <nl> places use it through the provided convenience property added by <nl> buildplugin . this commit moves that convenience property to the base <nl> java plugin , so further reduce dependence on the buildplugin .",0.9052197337150574
apache_pulsar/9486,do not use a static map of listeners in topicpoliciesservice,"maybe ci jobs are failing with oom in the brokers unit tests . the surefire worker is configured with 0 processes , each with xmx of 1g . <nl> that makes that map to contain all the instances created during the tests execution and keeping references to everything else . <nl> the map should instead be scoped to the specific instance .",1612476958,this pr enables spotbugs for module,0.8718933463096619
elastic_elasticsearch/72094,"adjust geoip downloader . <nl> instead of doing a refresh as part of each index request , perform <nl> this separately after all chunks have been indexed . <nl> also perform a flush , so that the translog is trimmed and <nl> does n't contain all these large write operations ( 1mb ) until <nl> an automatic refresh happens ( which may take a while since <nl> no other indexing will take place for a while ) . <para-sep> may take some time before automatic flush kicks in : ( otherwise the translog will contain large documents for some time without good reason ) <nl> ensure that the chunk documents are visible :","instead of doing a refresh as part of each index request , perform <nl> this separately after all chunks have been indexed . <nl> also perform a flush , so that the translog is trimmed and <nl> does n't contain all these large write operations ( 1mb ) until <nl> an automatic refresh happens ( which may take a while since <nl> no other indexing will take place for a while ) .",1619102766,it is possible that a developer accidentally declares two parsers for the <nl> same field name . <nl> this commit introduces a validation to prevent that from happening .,0.9189907908439636
ballerina-platform_ballerina-lang/26827,add syntax tree changes for error constructor <cm-sep> align error constructor with swan lake spec <cm-sep> update/add error constructor parser tests <cm-sep> fix arg-list recovery and update error-constructor recovery tests <para-sep> parse arg list starting open parenthesis .,- align error-constructor-expr parsing with swan lake spec version <nl> - fix issues with arg-list error recovery <nl> - fix issues with type-reference parsing <nl> - fix few issues with error-binding-pattern parsing .,1604929559,"this functionality is required for the new formatter implementation . <nl> these two methods return an instance of minutiaelist class , which can be used to query minutiae nodes . <nl> at the moment , minutiaelist api provides a readonly api . i will send a separate pr with methods to mutate this list .",0.9838745594024658
crate_crate/10291,debounce computations in tablehealthservice . <nl> makes sure that there is only a single active computation at a time . <nl> improves the performance in case of concurrent queries : . <nl> before : . <nl> cr8 timeit -s ' select * from sys.health ' -w 0 -r 0 -c 0 <nl> runtime ( in ms ) : <nl> mean : version ± version <nl> min/max : version → version <nl> percentile : <nl> 0 : version ± version ( stdev ) <nl> 0 : version <nl> version : version . <nl> after : . <nl> cr8 timeit -s ' select * from sys.health ' -w 0 -r 0 -c 0 <nl> runtime ( in ms ) : <nl> mean : version ± version <nl> min/max : version → version <nl> percentile : <nl> 0 : version ± version ( stdev ) <nl> 0 : version <nl> version : version <cm-sep> remove logging on errors in tablehealthservice . <nl> the error is propagated to a client querying already . no <nl> need to log it separately .,makes sure that there is only a single active computation at a time . <nl> improves the performance in case of concurrent queries : . <nl> before : . <nl> cr8 timeit -s ' select * from sys.health ' -w 0 -r 0 -c 0 <nl> runtime ( in ms ) : <nl> mean : version ± version <nl> min/max : version → version <nl> percentile : <nl> 0 : version ± version ( stdev ) <nl> 0 : version <nl> version : version . <nl> after : . <nl> cr8 timeit -s ' select * from sys.health ' -w,1596027157,see the individual commits for details .,0.8140549659729004
vespa-engine_vespa/15528,"generate correct zookeeper server config and fix setup of components . <nl> copmonents need to created so that they will subscribe with a config id <nl> that is unique per container ( since config is different for each container ) . <nl> also make sure to to only generate needed ´myid´ in config for each container <para-sep> this is useful to allow applications to find out in which zone they are running by having the zone <nl> these need to be setup so that they will use the container 's config id , since each container have different config ( id of zookeeper server ) <nl> only myid is set for container <nl> the rest ( e.g . servers ) is set for cluster",copmonents need to created so that they will subscribe with a config id <nl> that is unique per container ( since config is different for each container ) . <nl> also make sure to to only generate needed ´myid´ in config for each container .,1606728506,"up until now every lookup of a flag on zookeeperflagsource would hit zookeeper . <nl> flags are ideal for caching : changes seldom , little data , clients should handle <nl> short-lived inconsistencies at the time it is changed ( flag-flips must be reversible ) . <nl> this pr will make the backing flagsdbimpl cache the /flags/v1 zk directory and <nl> completes the optimization of configserverflagsource .",0.936924397945404
apache_kafka/9708,initial kip implementation <cm-sep> remove caching option and add testing <cm-sep> cleanup <para-sep> configures logging for both state stores . the changelog will be created with the provided configs . note : any unrecognized configs will be ignored <nl> disable change logging for both state stores .,adds and for to give the same flexibility as,1607364191,"during the implementation and verification , we neglected to test the code path for falling back to default serdes if none are given in the topology .",0.95420241355896
Alluxio_alluxio/11491,clear temp file if upload failed <para-sep> delete the temporary file on the local machine if the cos client completed the upload or if the upload failed . <nl> delete the temporary file on the local machine if the gcs client completed the upload or if the upload failed . <nl> delete the temporary file on the local machine if the kodo client completed the upload or if the upload failed . <nl> delete the temporary file on the local machine if the oss client completed the upload or if the upload failed . <nl> generate the put request and wait for the transfer manager to complete the upload <nl> delete the temporary file on the local machine if the transfer manager completed the upload or if the upload failed .,the temp files should be removed if the upload failed .,1590990621,"another round of tracing improvements for grpc authentication . <nl> basically , long polling makes the code more prone to receive cancelled events .",0.9048248529434204
vespa-engine_vespa/15574,add helper for combining multiple completable futures <cm-sep> add helper method to rethrow checked as unchecked <cm-sep> move serialized value definition to state enum <cm-sep> fetch cluster reindexing status from cluster controllers,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606842386,adding docker allocation metrics . most of the metrics will only makes sense once we start to dynamically allocate docker containers .,0.9861641526222229
elastic_elasticsearch/71621,forbid setting copy_to on scripted field mappers,"is currently implemented at document parse time , and does not <nl> work with values generated from index-time scripts . we may want to add <nl> this functionality in future , but for now this commit ensures that we throw <nl> an exception if and are both set on a field mapper .",1618311980,"if the recovery source is on an old node ( before version ) , then the recovery target wo n't have the safe commit after phase1 because the recovery source does not send the global checkpoint in the clean_files step . and if the recovery fails and retries , then the recovery stage wo n't transition properly . if a sync_id is used in peer recovery , then the clean_files step wo n't be executed to move the stage to translog . <nl> i think we should do it as this issue can occur in version . ( requires a",0.9023747444152832
apache_beam/12625,use testpubsubsignal in pubsubtobigqueryit <para-sep> wait for pipeline to start before publishing data <nl> wait for pipeline to start before publishing data,"see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1597796974,"i wish to be able to write bytes type fields to bigquery . <nl> in bigqueryutils ( sdks/io/google-cloud-platform ) when serialising a bytes type beam field for bq there is a faulty cast to java.nio.bytebuffer while the value will always be a primitive byte array ( see org.apache.beam.sdk.values.row.builder # verifyprimitivetype ) . <nl> trying to use bigqueryutils when writing a bytes field to biqquery will cause <nl> ` <nl> java.lang.classcastexception : [ b can not be cast to java.nio.bytebuffer at org.apache.beam.sdk.io.gcp.bigquery.bigqueryutils.frombeamfield ( bigqueryutils.java:0 ) <nl> ` <nl> and the added tests in bigqueryutilstest will trigger this , and the changes",0.9020222425460815
runelite_runelite/11924,add toggle to remove spellbook tooltips,adding a config option to disable spell book tooltips .,1592502218,fix null pointer exceptions when trying to draw null names on screen .,0.8980893492698669
apache_druid/10387,"add combining inputsource <para-sep> inputsource that combines data from multiple inputsources . the delegate inputsources must be splittable . <nl> this is called only when parallelindexingestionspec needs to decide if either inputformat vs parserspec is required . so if at least one of the delegate inputsources needsformat , we set this to true . all other needsformat calls will be made against the delegate inputsources .",the tutorial ingestion spec has been modified to use this inputsource as well,1599863257,it works by keeping and and in the end spitting as mean . <nl> that could be added in future as a optional strategy in this aggregation type,0.9885500073432922
vespa-engine_vespa/15920,remove unnecessary and misleading method call <cm-sep> simplify adding and deleting tenant . <nl> also make sure to call close on tenant before removing node from zookeeper,"discovered when trying to use curator version 0 , this should work for all versions of curator .",1609865615,- simplified docker network test by checking reachability from host through instead of making system call to . <nl> - check if docker daemon is running and delete any remaining containers in a method instead of inside every test . <nl> - rewritten to not test any networking as it is covered by another test .,0.9431286454200745
hazelcast_hazelcast/18348,revert ' make nearcacheconfig equal before and after it is used ' . <nl> this reverts commit sha . <para-sep> create copy of eviction config <nl> create copy of nearcache config and set eviction config,this reverts commit sha . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used .,1614785563,"added the property to the hot restart persistence config . <nl> eventually , i would like to have this option on the data structure specific but there are potential compatibility issues with that . first , this is a patch-level release so i do n't think it is safe to meddle with the config serialization format . second , is included in which is a - which i understand essentially means that the class is set in stone and can not change without breaking client compatibility etc . and lastly , the map and cache configs are persisted in the",0.9380028247833252
elastic_elasticsearch/71211,"docs + setting name <para-sep> if the { es } { security-features } are enabled , you must have the or <nl> if > is <nl> > to create or update a pipeline > to retrieve a pipeline configuration > to test a pipeline <nl> > to get download statistics for geoip2 databases used with <nl> > > > <nl> use a proxy endpoint * <nl> use a custom endpoint * <nl> manually update your geoip2 databases * <nl> also bootstraps geoip download task on clean cluster and handles changes to the 'ingest.geoip.downloader.enabled ' setting",this pr adds documentation for geoipv2 auto-update feature . <nl> it also changes related settings names from to to have the same convention as current setting .,1617320315,this api incorrectly had set to false in the default options for the <nl> request . this changes it from to and enhances a test to exercise the functionality .,0.9111953377723694
ballerina-platform_ballerina-lang/26529,"fix metadata issue <cm-sep> fix the order of metadata node <cm-sep> fix spaces between inline braces , implicit new and remote method calls <cm-sep> change back the record type descriptor <cm-sep> fix the parser source files <cm-sep> fix formatter test sources <cm-sep> minor formatting fixes <cm-sep> fix the parser assert files",* makes the following formatting behavioural changes : <nl> * changed to in <nl> * spaces around removed in <nl> * spaces after and before are removed in inline braces .,1603376385,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.8441309928894043
apache_pulsar/9659,try to fix flaky test replicatortest.testreplicatoronpartitionedtopic . <nl> try to make the test stable by append system.nanotime to namespace it creates to avoid ' namespace already exists ' exception . <para-sep> holds util methods used in test . <nl> generate unique name for different test run .,this seems working fine for other test cases in the same test .,1613894989,"in some case , user wants to use a custom subscription position . <nl> add for sink .",0.9110285043716431
elastic_elasticsearch/71079,"case-insensitive handling of http header names in http client stats <para-sep> the listener code above should never throw <nl> will always return a non-null value when httpchannel is non-null <nl> due to non-deterministic ordering in map iteration , the second client may not be the second entry in the list",as this improves a not-yet-released feature .,1617132605,"if a shard is reassigned to a node , but it has open searches ( could be <nl> scrolls even ) , the current behavior is to throw a <nl> shardlockobtainfailedexception . this commit changes the behavior to <nl> close the search contexts , likely failing some of the searches . the <nl> sentiment is to prefer restoring availability over trying to complete <nl> those searches . a situation where this can happen is when master ( s ) are <nl> restarted , which is likely to cause similar search issues anyway .",0.9622035026550293
trinodb_trino/7554,upgrade coral to version . <nl> this brings no user-visible changes .,this brings no user-visible changes .,1618159824,the refactoring was done automatically with intellij .,0.8219137787818909
OpenAPITools_openapi-generator/7375,"use tab in comment , remove withgocodegencomment <cm-sep> deprecated option <para-sep> { { operationid } } { { # summary } } { { { . } } } { { /summary } } { { ^summary } } method for { { operationid } } { { /summary } } <nl> { { { unescapednotes } } }",- use tab instead of 0 spaces in function docstring <nl> - deprecate ' withgocodegencomment ' option ( now enable by default ) .,1599633461,"derives the generated api class name from the pub name , rather than the generic name .",0.844403862953186
apache_flink/14958,"use tableresult # collect to get select result for sql client <cm-sep> some minor improvements <cm-sep> remove useless code about deployment in sql client . however , we still keep the deploymententry , which is able to use cli options . <cm-sep> use rowkind instead of tuple2 to represent changes in sql client <cm-sep> fix data loss in changelogcollectresult <para-sep> do nothing <nl> this operator will also stop flink job <nl> store the result under the jobid <nl> collects results and returns them as a changelog . * / <nl> prepare for changelog <nl> retrieval thread is alive return a record if available but the program must not have failed <nl> retrieval thread is dead but there is still a record to be delivered <nl> no results can be returned anymore <nl> wait if the buffer is full <nl> ignore <nl> a result that is represented as a changelog consisting of insert and delete records . * / <nl> * / <nl> start listener thread <nl> we assume that a bounded job finished <nl> no result anymore either the job is done or an error occurred <nl> collects results and returns them as table snapshots . * / <nl> limit the materialized table <nl> perform clean up in batches <nl> base class to collect results and returns them as table snapshots . * / <nl> maximum initial capacity of the materialized table . * / <nl> maximum overcommitment of the materialized table . * / <nl> factor for the initial capacity of the materialized table . * / <nl> factor for cleaning up deleted rows in the materialized table . * / <nl> maximum number of materialized rows to be stored . after the count is reached , oldest rows are dropped . <nl> threshold for cleaning up deleted rows in the materialized table . * / <nl> materialized table that is continuously updated by inserts and deletes . deletes at the beginning are lazily cleaned up when the threshold is reached . <nl> counter for deleted rows to be deleted at the beginning of the materialized table . * / <nl> current snapshot of the materialized table . * / <nl> page count of the snapshot ( always > = 0 ) . * / <nl> page size of the snapshot ( always > = 0 ) . * / <nl> indicator that this is the last snapshot possible","this pr aims to use tableresult # collect to get select result instead of using user defined sink . which could reduce a lot of code . <nl> - use tableresult # collect to get select result for sql client <nl> - remove useless code about deployment in sql client <nl> - use rowkind instead of tuple2 to represent changes in sql client <nl> - fix data loss in changelogcollectresult . <nl> this change is already covered by existing tests , such as localexecutoritcase , and add some new test to verify the change , such as materializedcollectbatchresulttest , changelogcollectresulttest",1613630097,"reduce dependency on hive runner for tests , so that tests will be more stable and faster . besides , tests with hive runner are difficult to debug due to an idea issue . therefore this change also makes debugging a little easier . <nl> - add to test with embedded metastore . is not removed but not actually used any more . <nl> - add to run with . all other test classes are now hive-runner-free . <nl> - refactor and clean up of test code . <nl> existing test cases . <nl> na . <nl> na",0.977700412273407
elastic_elasticsearch/71413,"manage fleet system indices within elasticsearch . <nl> this commit moves the management of seven system indices that are used <nl> by fleet to an elasticsearch plugin . the mappings were taken largely <nl> untouched from the fleet server project , with the exception of adding <nl> a _meta field with a version key to enable the system indices <nl> infrastructure to manage these indices .","this commit moves the management of seven system indices that are used <nl> by fleet to an elasticsearch plugin . the mappings were taken largely <nl> untouched from the fleet server project , with the exception of adding <nl> a _meta field with a version key to enable the system indices <nl> infrastructure to manage these indices .",1617806808,when in upgrade mode the stats service should not write to the stats index . <nl> the change is simple - do n't persist the stats and works nicely as new stats increment the existing stats so there is n't an accumulation of objects in memory . unfortunately upgrade mode means the node has either been upgraded already or is about to be taken down in which case some stat updates will be lost,0.9513913989067078
elastic_elasticsearch/71989,bump minimum compiler version to java 0,"now that we 've upgrade to gradle version we can bump the minimum compiler version to java 0 to be in line with the bundled jdk and put us back on a supported version ( java 0 is eol ) . <nl> i 've also relaxed the jdk requirement for builds run via intellij . the idea here being that the jdk is set by the build , but the build in turn requires a certain jdk . to avoid this awkward chicken/egg situation we just ignore the requirement when running in the ide . we still fail on the",1618960352,the usual update to the latest gradle release .,0.8362000584602356
jenkinsci_jenkins/4603,"delete confidentialstorerule <cm-sep> also delete mocksecretrule so secret.fromstring works <para-sep> for testing only . <nl> todo consider promoting to public , and offering a default implementation of randombytes ( via the usual util.isoverridden binary compat trick )","found it frustrating that i could not , for example , call any method on from because does not work without . simpler to introduce an in-memory mock for such cases . ( already has its own test coverage . <nl> * developer : and implementations can now be used from unit tests without .",1585239950,"loading the last 0 successful builds may be very expensive in certain rare , but possible situations ( all newer builds failed , only some very old builds were successful ) . <nl> go only up to 0 build into the past for calculating the estimated duration . <nl> also take failed builds into account , if we do n't find any successful ones .",0.9627145528793335
elastic_elasticsearch/70474,"improve the test coverage of the verifier . <nl> the reason for increasing the test coverage on the verifier <nl> is to gain extra confidence that later moving rules between the <nl> analyzer and optimizer wo n't break any current functionality , <nl> wo n't turn current checks effectively noop . <para-sep> make sure that score is only used as a ' top level ' function","increases the already high line coverage to 0 % + ( couple of trivial checks and <nl> failure reporting methods will be left out ) . <nl> the reason for increasing the test coverage on the verifier <nl> is to gain extra confidence that later moving rules between the <nl> analyzer and optimizer wo n't break any current functionality , <nl> wo n't turn current checks effectively no-op .",1615926193,"this pull request is to enable the resthighlevelclient and lowlevelrestclient to automatically handle an elasticsearch response which has compressed content . compression can enabled within a node configuration with the following property : compression can be triggered by a request from a client . therefor you also need to provide additional information within the header of the request to elasticsearch if a client really wants to enable it . that is possible with the following requestoptions : . <nl> requestoptions.builder requestoptions = requestoptions.default.tobuilder ( ) <nl> .addheader ( ' accept-encoding ' , ' gzip ' ) . <nl> with these",0.8918710350990295
elastic_elasticsearch/72431,"get service account token <cm-sep> get service accounts <cm-sep> delete service account token <cm-sep> get service account credentials <cm-sep> clear service token cache <cm-sep> authentication <cm-sep> tweak <para-sep> clears the service account token cache for the specified namespace , service-name and list of token names . see the docs for more . <nl> clears the service account token cache for the specified namespace , service-name and list of token names asynchronously . see the docs for more . <nl> get a service account , or list of service accounts synchronously . see the docs for more information . <nl> get a service account , or list of service accounts asynchronously . see the docs for more information . <nl> create a service account token . see the docs for more . <nl> asynchronously creates a service account token . see the docs for more . <nl> delete a service account token . see the docs for more . <nl> asynchronously deletes a service account token . see the docs for more . <nl> get credentials for a service account synchronously . see the docs for more information . <nl> get credentials for a service account asynchronously . see the docs for more information . <nl> the request used to clear the service account token cache .",this pr adds corresponding components in high level rest client for the new apis related to the service accounts feature .,1619654382,"getting the api key document form the security index is the most time consuing part <nl> of the api key authentication flow ( > 0 % if index is local and > 0 % if index is remote ) . <nl> this traffic is now avoided by caching added with this pr . <nl> additionally , we add a cache invalidator registry so that clearing of different caches will <nl> be managed in a single place ( requires follow-up prs ) .",0.9841086864471436
confluentinc_ksql/6257,drop support for executing legacy ddl/dml <para-sep> given : <nl> when <nl> then <nl> given : <nl> when <nl> then <nl> given : <nl> when <nl> then <nl> reset state from collecting commands above,"after query execution plans were introduced by klip 0 , we required users to migrate existing statements rather than performing in-place upgrades when upgrading from ksqldb version to ksqldb version , and also when migrating from confluent platform ksql version to ksqldb version . <nl> as a result , the engine no longer needs to support legacy , , , and source commands that do not have execution plans in the command topic . <nl> new unit tests + existing tests pass .",1600457411,"another prep pr for the implicit fields clean up pr . <nl> move into the only place its used : . <nl> - refactor so its a unit test . ( it was previously incorrectly passing a as the source node , which is never the case in prod and does n't work as the schema is aliased . )",0.9642322063446045
apache_beam/13062,"add bit_and back into calcite sql . <nl> the incorrect behavior when mixing null and non-null values is still present . <nl> bit_and is still excluded from zetasql . <para-sep> bitwise and function implementation . note : null values are ignored when mixed with non-null values . <nl> indicate if input only contains null value . <nl> when inputs contain both null and non-null values , the output should be null . * /",the incorrect behavior when mixing null and non-null values is still present . <nl> bit_and is still excluded from zetasql,1602271247,this pr also adds some zetasql unit tests that expose the previous bug .,0.9574660658836365
Alluxio_alluxio/11436,fix hashcode ( ) for sortedblockset <cm-sep> handle equal sorted-fields during swap list generation <para-sep> simulate swapping until both ends of the list are aligned . <nl> this is achieved by using a sequentially increasing change-index field which helps to differentiate between unique fields with identical sort-field .,lrfu can generate sorted-fields with equal value . <nl> this pr fixes bugs related to this edge case .,1589516022,leverage to remove the ufs dependency of persist shell command . <nl> this pr fixes the ancestor permission propagation in asyncpersist . <nl> it also enables deprecation the persist bit in .,0.885572612285614
apache_druid/10388,"allow vectorized query engines to utilize vectorized virtual column implementations <para-sep> broker merge , for example with an 'inline ' datasource subquery . <nl> now check column capabilities , which must be present and explicitly not multi-valued <nl> group by on multi value dimensions are not currently supported dimensionspecs that decorate may turn singly-valued columns into multi-valued selectors . to be safe , we must return false here . <nl> now check column capabilities . <nl> null here currently means the column does not exist , nil columns can be vectorized <nl> strings must be single valued , dictionary encoded , and have unique dictionary entries <nl> basecolumnselectorfactory using baseoffset is the column selector for filtering . <nl> basecolumnselectorfactory using baseoffset is the column selector for filtering . <nl> vector cursors ca n't iterate backwards yet <nl> they can potentially draw from multiple underlying columns , although they always present themselves as if they were a single column . users of this interface must ensure to first call this method whenever possible . typically this can not be called in query paths on top of incrementalindex which does n't have columns as in persisted segments . <nl> users of this interface must ensure to first call this method whenever possible . typically this can not be called in query paths on top of incrementalindex which does n't have columns as in persisted segments . <nl> users of this interface must ensure to first call this method whenever possible . <nl> users of this interface must ensure to first call this method whenever possible . <nl> also provides the name that the virtual column was referenced with , which is useful if this column uses dot notation . <nl> users of this interface must ensure to first call this method whenever possible . <nl> also provides the name that the virtual column was referenced with , which is useful if this column uses dot notation . <nl> users of this interface must ensure to first call this method whenever possible . <nl> create a column value selector . <nl> create a single value dimension vector ( string ) selector . <nl> create a multi value dimension vector ( string ) selector . <nl> create a column vector value selector . <nl> create a column vector object selector . <nl> dictionaryencodedcolumn is not null because of holder null check above <nl> we","# # # description <nl> this pr adds support for vectorized virtual columns to be used by vectorized timeseries and group by query engines . this just wires everything up to query engines , a follow-up pr will add a vectorization support to . <nl> tests have been added using a fake and implementation to ensure that vectorized virtual columns using any of the added vector selector functions work with both group by and timeseries queries",1599875004,add sql inputsource support for ingesting events from rdbms using parallel indexing,0.9885343313217163
elastic_elasticsearch/71165,service accounts - delete index backed service account token <para-sep> cache is populated after authenticate <nl> cache is cleared after token deletion <nl> todo : wildcard support ? <nl> non-exist token name <nl> invalid service account <nl> index not exists <nl> index exists but not available,this pr adds a new api to delete service account tokens that are backed by the security index . it also fixes a few oversights from previous prs .,1617243964,"getting the api key document form the security index is the most time consuing part <nl> of the api key authentication flow ( > 0 % if index is local and > 0 % if index is remote ) . <nl> this traffic is now avoided by caching added with this pr . <nl> additionally , we add a cache invalidator registry so that clearing of different caches will <nl> be managed in a single place ( requires follow-up prs ) .",0.976561963558197
apache_shardingsphere/10214,support alter database grammar <cm-sep> fix <cm-sep> add testcase <cm-sep> add end line <para-sep> alter database statement . <nl> oracle alter database statement .,changes proposed in this pull request : <nl> - support oracle alter database grammar <nl> - add test case,1619621170,"changes proposed in this pull request : <nl> - support mysql store procedure create , alter , drop , call statement parse",0.9434571862220764
apache_kafka/10049,"new metadatacache from branch <para-sep> return topic metadata for a given set of topics and listener . see kafkaapis # handletopicmetadatarequest for details on the use of the two boolean flags . <nl> get a partition leader 's endpoint <nl> update the metadata cache with a given updatemetadatarequest . <nl> this is the cache state . every metadataimage instance is immutable , and updates ( performed under a lock ) replace the value with a completely new one . this means reads ( which are not under any lock ) need to grab the value of this var ( into a val ) once and retain that read copy for the duration of their operation . multiple reads of this value risk getting different snapshots . <nl> this method is the main hotspot when it comes to the performance of metadata requests , we should be careful about adding additional logic here . relatedly , is instead of to avoid a collection copy . filterunavailableendpoints exists to support v0 metadataresponses <nl> errorunavailableendpoints exists to support v0 metadataresponses if errorunavailablelisteners=true , return listener_not_found if listener is missing on the broker . otherwise , return leader_not_available for broker unavailable and missing listener ( metadata response v5 and below ) . <nl> check whether a broker is alive and has a registered listener matching the provided name . this method was added to avoid unnecessary allocations in [ ] , which is a hotspot in metadata handling . <nl> get the endpoint matching the provided listener if the broker is alive . note that listeners can be added dynamically , so a broker with a missing listener could be a transient error . <nl> errorunavailableendpoints exists to support v0 metadataresponses <nl> if the leader is not known , return none ; if the leader is known and corresponding node is available , return some ( node ) if the leader is known but corresponding node with the listener name is not available , return some ( no_node ) <nl> this method returns the deleted topicpartitions received from updatemetadatarequest <nl> compare the new brokers with the existing ones .","for version we will keep the existing metadatacache implementation intact . instead of replacing it with the changes needed for raft , we will extract an interface for both implementations to use . kafkaserver ( zk-backed clusters ) will only pick the zk metadata cache impl . <nl> the only real change to production code here will be the use of metadatabroker instead of broker for metadatacache # getalivebroker and metadatacache # getalivebrokers . this was done to eliminate unnecessary divergence between the two implementations .",1612404539,"when upgrading from version before version probing , the parameter is set and forces the used subscription version to stay at the associated older version until everyone is on the new . <nl> this means we might get a mix of new and old versions < as we go through the second rolling bounce and remove the config . so we should just not do version probing if the version is too old , rather than throw an exception",0.8418737649917603
apache_shardingsphere/9589,add refresher fro create user <para-sep> user configuration cached event . <nl> create user event . <nl> create user statement auth refresher .,changes proposed in this pull request : <nl> - add refresher for create user,1614844082,changes proposed in this pull request : <nl> - add encryptinsertonduplicatekeyupdatevalueparameterrewriter for insert into .... on duplicate key update . <nl> - add the encrypt insert unit case .,0.9622920155525208
apache_incubator-pinot/6017,"adding validation for table indexing config to check for valid column names <para-sep> 0. indexing config todo : add more validations for each section ( e.g . validate conditions are met for aggregatemetrics ) <nl> validates the indexing config ensures that every referred column name exists in the corresponding schema <nl> dimension split order can not be null <nl> function column pairs can not be null <nl> validates the field config list in the given tableconfig ensures that every referred column name exists in the corresponding schema <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected <nl> although this config makes no sense , it should pass the validation phase <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected",it exists in the corresponding schema ) . also checking for space in the table name . <nl> no <nl> no . <nl> no .,1600144912,reusing the code path from offline side entirely,0.9754512906074524
quarkusio_quarkus/14995,disable flaky tests on windows . <nl> ( cherry picked from commit sha ) <cm-sep> improve config console and moved console configs to runtime init . <nl> ( cherry picked from commit sha ) <cm-sep> allow config editor to unset a property . <nl> ( cherry picked from commit sha ) <cm-sep> remove jcenter repository references . <nl> ( cherry picked from commit sha ) <cm-sep> add quarkus-smallrye-opentracing to an integration test without undertow . <nl> this is done in order to ensure that opentracing works in native <nl> when a servlet container is not present . <nl> ( cherry picked from commit sha ) <para-sep> in the current project only,"please do n't merge , i will merge it myself .",1613042566,"better reviewed commit per commit as i cleaned up a few things . <nl> to start the docker containers , you now need to use . <nl> mariadb and postgresql examples are built by default but not tested . you need to use and to enable testing ( + if you want to rely on the docker containers ) . <nl> the strict example is executed with h2 by default but can be executed with postgresql using . that 's what is done on ci . <nl> i added a annotation to be able to declare test resources . the",0.9737045168876648
confluentinc_ksql/6084,add serialization exceptions to processing logger <cm-sep> more informative error on non-optional schema <para-sep> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : throws <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"two changes in this pr ( corresponding to the first two commits ) : <nl> - add serialization exceptions to the processing log : currently deserialization exceptions are logged but serialization exceptions are n't <nl> - throw a more informative error message in the event that serialization exceptions are caused by udfs with return types with non-optional schemas , since the error message from connect ( ) is n't particularly actionable by users . <nl> added unit tests . manual testing underway .",1598280743,"this pr explicitly adds the ssl config names to the ksql configuration , extends the prefix to allow ssl overrides specific to the sr to be supplied , and then wires this all up to configure the used by the sr client . <nl> for example , where the same ssl configuration is needed from the schema registry as for the kafka brokers , then config like this can be used : . <nl> where sr requires different configuration , it also supports overrides : . <nl> still to do ... .",0.9901806712150574
netty_netty/10760,change true to false in addhttp2tohttpheaders,"motivation : <nl> translates to . it uses to do so . however , field is set to instead of . it should be set to because we 're doing conversion of response not request . <nl> modification : <nl> changed to . <nl> result : <nl> correctly translates to .",1604169481,motivation : . <nl> if a read triggers a abstracthttp2streamchannel to close we can <nl> get an npe in the read loop . <nl> modifications : . <nl> make sure that the inboundbuffer is n't null before attempting to <nl> continue the loop . <nl> result : . <nl> no npe .,0.9458585381507874
ballerina-platform_ballerina-lang/23995,"add syntaxtree compilation capability to the compiler . <cm-sep> migrate language server into new parser . <cm-sep> fix package imports not visible with new parser . <cm-sep> fix extended doc manager to override gettree and settree <cm-sep> avoid null pointer exception due to invalid ws usage <cm-sep> remove ws dep from incompatibletypes code-action . <cm-sep> fix auto-import not suggested for createvariable . <cm-sep> fix returntype test failure . <cm-sep> fix cce thrown transforming stream nodes with sql : error . <cm-sep> add let clause tranformer method . <cm-sep> fix code action tests . <cm-sep> sync master branch <cm-sep> fix code-action issue due to syntax-tree api change . <cm-sep> fix check style issue . <cm-sep> temporary disable lang-server tests . <para-sep> returns the syntax tree this source entry represents . <nl> todo : get hash and length from tree <nl> returns a syntax tree . <nl> set the new tree . <nl> todo : fix this , each time creates a new tree <nl> todo : removed check , need to find another way to skip streaming imports <nl> todo : find a better approach along with the new parser implementation else if ( funcnode.flagset.contains ( flag.worker ) & & completionvisitorutil .iswithinworkerreturncontext ( this.symbolenv , this.lscontext , this , funcnode ) ) { return ; }",this branch contains the initial phase migration of the language server into new parser . temporary disabled all language server tests . need to enable them one-by-one as we go .,1591946256,now there are child buckets with values in both internal and external syntax tree nodes . but the public api does not expose those null values due to the usage of optional .,0.956851065158844
apache_incubator-pinot/6150,"adding grpcport in controller instance api response <para-sep> } , ' grpcport ' : 0","so external services can get the grpc port used for the given pinot server . <nl> the default grpc port is 0 if enabled , for non-enabled server instances , will put 0 there .",1602867213,see issue and corresponding design doc for more details . <nl> testing done : <nl> * instrumented internal kafka stream implementation to include ingestion time in rowmetadata . <nl> * verified the logging for cases where there was no delay ; also manually induced delay in consumption across segments and verified that the logging and metric reported the right values .,0.9330515265464783
Alluxio_alluxio/10963,"cache the getworkerinfolist results and refresh periodically <para-sep> faster refresh <nl> * / <nl> a loading cache for worker info list , refresh periodically .","getworkerinfolist ( ) is fast by itself , but it requires all the live worker locks and may introduce contention . <nl> our clients and job servers need to use getworkerinfolist ( ) to select job executor , find local hostnames or know which worker to read from/write to . a large amount of call may be triggered . cache the worker info list and refresh periodically can help prevent those heavy load and lock contention",1582238640,"calling incurs some costs , such as querying ufs for available space . also , this gets call on each heartbeat which can be very frequent . instead , do this on a best effort basis periodically .",0.945410966873169
confluentinc_ksql/5989,add serde options to qtt sourcenode <cm-sep> write all sources into qtt historic plan post conditions <cm-sep> fix plannedtestloader to properly filter on whitelist <cm-sep> fix model tester to properly catch serialization errors <cm-sep> fix error exposed from newly failing test after previous commit <cm-sep> update historical plan specs <cm-sep> checkstyle,"qtt historic plans currently capture value schemas for sources in the ' schemas ' field of the saved specs , but key schemas are not captured ( unless part of the post conditions in the test itself ) . this pr captures key schemas by adding all sources into the post conditions in the saved spec , and also adding serde options into sourcenode in order to capture not just the logical schema but also how schemas are serialized . <nl> review commit by commit : <nl> - ' add serde options to qtt sourcenode ' : qtt tests can",1597244243,note : this pr is based of the qtt blacklist pr - review that first . <nl> while investigating recent rqtt build failures i noticed that the queries that involved a were going through a repartition topic - which is unnecessary and costly . <nl> this pr fixes the issue and adds a new compatibility breaking config to ensure old queries continue to maintain the repartition step to avoid data loss . <nl> tests added .,0.9687323570251465
apache_druid/10312,"optimize large indimfilters . <nl> for large indimfilters , in default mode , the filter does a linear check of the <nl> set to see if it contains either an empty or null . if it does , the empties are <nl> converted to nulls by passing through the entire list again . <nl> instead of this , in default mode , we attempt to remove an empty string from the <nl> values that are passed to the indimfilter . if an empty string was removed , we <nl> add null to the set <para-sep> in non sql compatible mode , empty strings should be converted to nulls for the filter . in sql compatible mode , empty strings and nulls should be treated differently","for large indimfilters , in default mode , the filter does a linear check of the <nl> set to see if it contains either an empty or null . if it does , the empties are <nl> converted to nulls by passing through the entire list again . <nl> instead of this , in default mode , we attempt to remove an empty string from the <nl> values that are passed to the indimfilter . if an empty string was removed , we <nl> add null to the set . <nl> this flame graph shows that ~0 % of query",1598246176,"query metrics should only be used within a single thread . because results for jdbc queries can be paginated into multiple jdbc frames ( each frame being processed by a potentially different thread ) , the final frame thread that closes the yielder ( which results in a querymetrics emit ( ) call ) may not be the same as the first frame thread that created the yielder ( which initializes querymetrics with the current thread as the owner ) creates and closes the yielder for jdbc results with a single-thread executor to prevent this from happening",0.9031769633293152
confluentinc_ksql/6366,"fix topic info cache <nl> the is used by qtt to retrieve info about the topics being used by the test case . specifically , its used to get at the schema , key and value formats of the topic , and potentially use this information to build appropriate serde . <nl> the implementation was n't correctly handling internal topics . when building information about internal topics it was using the key and value formats of the sink topic . this is often incorrect . for example , consider a windowed group by where the source needs to be repartitioned , i.e . the is not on the key . in such a situation the repartition topic does n't have a windowed key , which the sink topic does . <nl> to get the correct key format , the now gets the information from the query itself . mainly the , which holds the logical schema plus the key and value formats used when creating the serde passed to kafka streams . <cm-sep> historical plans <para-sep> system property to turn on tracking of serde operations . must never be turned on in production code as it will kill performance . required by querytranslationtest . <nl> pojo for holding data about the schemas and formats in use at the different stages within a topology of a query . contains an map of 'logger name prefix ' to the schema and formats used when creating a serde . these two combined can determine the schema and formats per topic . maps logger name prefixes - > schema info <nl> maps topic name - > ( map of key/value flag - > set of logger name prefixes ) <nl> called when creating a key serde . associates a logger name with a schema and key format . <nl> called when creating a value serde . associates a logger name with a schema and value format . <nl> called when a serializer or deserializer does its thing . associates a topic name with a logger name .","the is used by qtt to retrieve info about the topics being used by the test case . specifically , its used to get at the schema , key and value formats of the topic , and potentially use this information to build appropriate serde . <nl> the implementation was n't correctly handling internal topics . when building information about internal topics it was using the key and value formats of the sink topic . this is often incorrect . for example , consider a windowed group by where the source needs to be repartitioned , i.e . the is",1602018502,"while the command topic is being initialized/replayed , ksql requests <nl> will return an error indicating that the server is initializing . <nl> as part of this change , i 've consolidated this initializing state and <nl> the terminating state ( entered when a terminate request is received ) <nl> into a single state machine tracked under the package <nl> io.confluent.ksql.rest.server.state . this package also has a request <nl> filter that ensures that requests are only served when the server is <nl> in ready state . <nl> finally , this patch adds support for checking preconditions before <nl> initializing the",0.9883779883384705
elastic_elasticsearch/70606,"if a search after request targets multiple indices and some of its sort <nl> field has type in one index but in other indices , <nl> then elasticsearch wo n't interpret the search_after parameter correctly <nl> in every target index . the sort value of a date field by default is a <nl> long of milliseconds since the epoch while a date_nanos field is a long <nl> of nanoseconds . <nl> this commit introduces the parameter in the sort field so a <nl> sort value of a date or date_nanos will be formatted using a date format <nl> in a search response . <nl> the below example illustrates how to use this new parameter . <cm-sep> adjust wire compact version <cm-sep> fix test <para-sep> test <nl> formats a value of a sort field in a search response . <nl> specifies a format specification that will be used to format the output value of this sort field . currently , only ' date ' and ' data_nanos ' date types support this external format ( i.e. , date format ) .","if a search after request targets multiple indices and some of its sort <nl> field has type in one index but in other indices , <nl> then elasticsearch wo n't interpret the search_after parameter correctly <nl> in every target index . the sort value of a date field by default is a <nl> long of milliseconds since the epoch while a date_nanos field is a long <nl> of nanoseconds . <nl> this commit introduces the parameter in the sort field so a <nl> sort value of a date or date_nanos will be formatted using a date format <nl> in a",1616200661,"this commit adds a new metadata field mapper that validates , <nl> that a document has exactly a single timestamp value in the data stream timestamp field . <nl> the metadatacreateindexservice inserts a data stream timestamp field mapper whenever <nl> a new backing index of a data stream is created .",0.9562945365905762
crate_crate/10602,"fix integer overflow at the reservoir sampling . <nl> as the reservoir sampling implementation is shared across shards and <nl> partitions , it may process more documents than an integer value can hold . <nl> it must be protected against integer overflows to not add more that <nl> the defined maximum samples to the list ( this limit is also in the <nl> integer range and such supporting sample sizes > integer is not needed ) . <nl> the integer overflow results in bypassing the maximum samples boundary <nl> and can lead to node crashes due to outofmemory exceptions . <nl> ( cherry picked from commit sha )","cherry-pick of sha has failed : . <nl> to fixup this pull request , you can check out it locally . <nl> mergify commands and options . <nl> you can also trigger mergify actions by commenting on this pull request : . <nl> - will re-evaluate the rules <nl> - will rebase this pr on its base branch <nl> - will merge the base branch into this pr <nl> - will backport this pr on branch . <nl> - look at your merge queues <nl> - generate the mergify configuration with the simulator .",1601281161,this pr contains several commits which move components around . the goal is to <nl> group related components closer together . navigating the packages should feel more sensible and it should be possible to write meaningful files later on . <nl> some components that i intend to move have n't been moved yet . but this should <nl> serve as a starting point .,0.6960103511810303
confluentinc_ksql/6135,"wrong value schema being registered for unwrapped primitives . <nl> fixes an issue where the wrong schema is registered for unwrapped primitive values . the registered schema incorrectly still has the value column wrapping in a record . <cm-sep> qtt test cases <cm-sep> historic plans <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> catch block allows negative tests to fail in the correct place , later .","fixes an issue where the wrong schema is registered for unwrapped primitive values . the registered schema incorrectly still has the value column wrapping in a record . <nl> as part of this work is now package private , and is used in its place in the code . <nl> usual .",1599056178,"like others , i spend a lot of time opening and searching through qtt & rqtt test files for the right test when a test fails , sometimes getting the wrong one and wasting time . enter this change ... this change adds clickable links to the output of th tests . <nl> for example , if the test fails in the file then you 'll get a link like : . <nl> clicking this link in intellij will take you to the right line in the file . <nl> if a historic test fails , you 'll get a",0.9720911979675293
apache_pulsar/9552,fix dead letter topic hangs <cm-sep> fix test,"async the dlq process . currently , the dlq process is a synchronous process . since we process the dlq in the timer and the timer will acquire a write lock during writing the data to the dlq , the data writing process will use the io thread and the messages that add to the unackedmessagetracker also use the io thread and if also acquire the same write lock . so this will result in a dead lock . <nl> make the dlq process async . <nl> the deadlettertopictest and the retrytopictest can cover this change . <nl> if was",1612937677,"this pr unifies all request logic for pulsaradmin in the async path . <nl> for pulsaradmin request , it will retry until we get a success response , fail if we exhausted retry count , or fail if we reach the read timeout .",0.9389815330505371
Alluxio_alluxio/11851,update shaded client and hdfs version in main pom <cm-sep> modify default ufs and hadoop version <cm-sep> change hms version to compile under jdk 0 <para-sep> assumes that hdfs is the ufs and version is version,tested to compile locally under jdk11,1595977159,"description <nl> the exception message ' active syncing is not supported on this ufs type ' + ufsresource.get ( ) .getunderfstype ( ) will get the result ' active syncing is not supported on this ufs types3 ' for s3 . <nl> improvement <nl> append : space for the message : ' active syncing is not supported on this ufs type : ' , and the result will be ' active syncing is not supported on this ufs type : s3 ' for s3 .",1.0
neo4j_neo4j/11394,"allow lucenerecoverit shutdown db even in case of failure . <nl> also add execution timeout of 0 minutes . <para-sep> on some machines and during some circumstances a lucene index may become corrupted during a crash . this is out of our control and since this test is about an explicit ( a.k.a . legacy/manual ) index the db can not just re-populate the index automatically . we have to consider this an ok scenario and we can not verify the index any further if it happens . <nl> this was another unknown exception , throw it so that the test fails with it <nl> added due to a recovery issue where the lucene data source write was n't released properly after recovery .",also add execution timeout of 0 minutes .,1522149460,"if the page cache eviction thread encounters an exception during eviction , such <nl> as running out of storage space , then that exception will be stored in a field <nl> an delivered to the next unfortunate passersby accessing the page cache . <nl> if this is the gbptree in the process of shutting down , then the exception <nl> would bubble out without any attempt at recovering the situation . <nl> this behaviour was different from how the record stores shut down , and it would <nl> prevent shut down even after the fault had been corrected , such",0.9122146964073181
elastic_elasticsearch/72539,fix oom when using geohashgrid with bounds <para-sep> max size of the solution space * /,"currently when declaring bounds with geohashtiler , we do not limit the amount of bucket we can create . this change prevents over allocating in such cases .",1619777381,"when computing the number of tiles a bounding box might touch , we perform the calculation in integers which can overflow . in addition when calculating such value during rasterisation , we do not have into account the bounds in the bounded case , therefore we might overestimate the number of cells we might be touching . <nl> this pr uses longs to compute the number of tiles touching a bounding box and bounds the value in the bounded case .",0.9490723013877869
apache_druid/10278,do n't log the entire task spec <para-sep> this method is only visible to outside only for testing .,"prints the entire task spec when it fails to issue a task , which could be huge especially in parallel task when lots of segments are shuffled . this could end up causing oom error in the supervisor task . this pr fixes it by logging only task id . i also cleaned up some wrong logging in . <nl> this pr also changes the id pattern of compaction/kill tasks when they are submitted by the coordinator . after this pr , the id of compaction and kill tasks will be prefixed by if they are submitted by coordinator .",1597360754,"this pull request introduces support for random sharding by estimating cardinality of input data set using hyperloglog and distributing the rows in shards on the basis on hashcode , random sharding has two major improvements over singledimension sharding - <nl> 0 ) better distribution of data resulting in almost equal sized partitions , thus achieving better query parallelism . <nl> 0 ) the mapper job for cardinality estimation does very less hadoop io and thus is much more efficient than single dimension sharding . <nl> changes - <nl> 0 ) support for random sharding <nl> 0 ) new partitionspec type",0.9802926182746887
elastic_elasticsearch/71315,service accounts - get service account api,"this pr adds a new api endpoint to retrieve service accounts . depends on the request parameter , it returns either all accounts , accounts belong to a namespace , a specific account , or an empty map if nothing is found .",1617680163,"searchable snapshot allocator that reaches out to all data nodes to get the cached size of for a shard , similar to how it 's done for normal shard s but simpler since we only care about the exact byte size for now , are not injecting the size into disk threshold allocators and leave out a few more tricks ( see todos ) that we do for normal allocation .",0.9901344776153564
elastic_elasticsearch/71192,"improve the optimization of null conditionals . <nl> enhance the existing rules so that <nl> coalesce ( ex ) - > ex <nl> nullif ( a , a ) - > null <nl> nullif ( null , a ) - > null <nl> nullif ( a , null ) - > a <para-sep> optimize nullif <nl> there 's no need for a conditional if all the children are the same ( this includes the case of just one value ) <nl> exclude any nulls found <nl> for coalesce find the first non-null foldable child ( if any ) and break early <nl> works even if the expressions are not foldable","enhance the existing rules so that <nl> coalesce ( ex ) - > ex <nl> nullif ( a , a ) - > null <nl> nullif ( null , a ) - > null <nl> nullif ( a , null ) - > a",1617294637,"add scripting , unmapped , supported-type tests to medianabsolutedeviationaggregator tests .",0.9621601700782776
apache_flink/15170,"cleanup test <cm-sep> prevent npe <cm-sep> do not attempt to cancel the job . <nl> the cancellation of the job may fail if the job termination finishes so quickly that the job has been cleaned up before the cancellation has been processed . <nl> the cancellation is unnecessary anyway because the tm failure causes the job to fail and we explicitly forbid restarts . <nl> as such we can just remove the cancel call . <para-sep> the job should fail within a few seconds due to heartbeat timeouts since the ci environment is often slow , we conservatively give it up to 0 minutes",the cancellation of the job may fail if the job termination finishes so quickly that the job has been cleaned up before the cancellation has been processed . <nl> the cancellation is unnecessary anyway because the tm failure causes the job to fail and we explicitly forbid restarts . <nl> as such we can just remove the cancel call .,1615551839,"fix changelog source ca n't be insert into upsert sink . currently , it will throw the following exception : . <nl> - in , we should catch the exception when satisfying update_kind trait . because we will may have multiple trait to required . if one of them can'be satisfied , we can fallback to the next one . <nl> - added serveral it cases to verifying reading from changelog source and insert into upsert sink . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public",0.9209500551223755
apache_incubator-pinot/5657,"using dictionary based aggregation operator when there is no filter/group by <para-sep> aggregations supported : min , max , minmaxrange , distinctcount <nl> without filter , we should be using dictionary for distinctcount <nl> without filter , distinctcount must be solved using dictionary . expectednumentriesscannedpostfilter is 0l","using dictionary based aggregation operator when there is no filter/group by . <nl> this query can be answered by going over the dictionary instead of scanning the entire forward index . <nl> we already have the code to check if a query can be answered just based on the dictionary for min/max . enhanced it to support distinctcount as well . <nl> before . <nl> after this change . <nl> > before : ' numentriesscannedpostfilter ' : 0 , <nl> > after : ' numentriesscannedpostfilter ' : 0 , <nl> > . <nl> if you have a series of commits",1593730727,"fileuploadutils.sendsegmenturiimpl ( ... ) has issue sending segment file uri to pinot controller . in the recent pinot controller changes , we enforced the checking of ' content-type ' of the requests and reject ( by returning 0 ) the caller if it does n't contain a valid information . this is usually fine in other java request code section as apache http libs can infer and generate the content type from the entity provided to it . however , when the entity is empty ( like the case we have here ) , it will not generate a proper",0.9358798265457153
hazelcast_hazelcast/18360,revert ' make nearcacheconfig equal before and after it is used ' . <nl> this reverts commit sha . <cm-sep> copy nearcacheconfig when it needs to be changed . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used . <nl> ( cherry picked from commit sha ) <para-sep> create copy of eviction config <nl> create copy of nearcache config and set eviction config,this reverts commit sha . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used .,1614858510,"added the property to the hot restart persistence config . <nl> eventually , i would like to have this option on the data structure specific but there are potential compatibility issues with that . first , this is a patch-level release so i do n't think it is safe to meddle with the config serialization format . second , is included in which is a - which i understand essentially means that the class is set in stone and can not change without breaking client compatibility etc . and lastly , the map and cache configs are persisted in the",0.9376399517059326
elastic_elasticsearch/70956,this pr adds metadata support for api keys . metadata are of type <nl> map and can be optionally provided at api key creation time . <nl> it is returned as part of getapikey response . it is also stored as part of <nl> the authentication object to transfer throw the wire . <nl> note that it is not yet searchable and not exposed to any ingest processors . <nl> they will be handled by separate prs .,this pr adds metadata support for api keys . metadata are of type <nl> map and can be optionally provided at api key creation time . <nl> it is returned as part of getapikey response . it is also stored as part of <nl> the authentication object to transfer throw the wire . <nl> note that it is not yet searchable and not exposed to any ingest processors . <nl> they will be handled by separate prs .,1616975089,"this pr adds metadata support for api keys . metadata are of type and can be optionally provided at api key creation time . it is returned as part of getapikey response . it is also stored as part of the authentication object . <nl> also updated docs and hlrc along with its tests and docs . <nl> note : storing the api key metadata in the authentication object makes it possible to be exposed in ingestion processors , e.g . but this pr intentionaly leaves it out because : <nl> 0. it is not the core part of the",0.9975339770317078
Alluxio_alluxio/10901,fix rocks block store iteration <cm-sep> add unit tests <cm-sep> add integration tests <para-sep> parses and return next element . <nl> it seeks given iterator to first entry before returning the iterator . <nl> masters become primary faster <nl> masters become primary faster <nl> directory for backups . <nl> needs workers to be up before the test . <nl> acquire clients . <nl> create single test file . <nl> create file through . <nl> delete it from alluxio namespace . <nl> list status on root to bring the file 's meta back . <nl> verify that file 's meta is in alluxio . <nl> take a backup . <nl> restart with backup . <nl> verify that file and its blocks are in alluxio after restore .,"this is to get rocks db out of prefix seek mode , under which iterators seektofirst/last apis are ineffective .",1581553213,"in a containerized env such as k8s , the worker and client hostname may not match . to determine if a worker is local , file system inspection is used instead when property is set . <nl> in this pr : <nl> - update the method to choose a local worker for blockinstream/outstream <nl> - if client container does not mount domain socket dir but has the same hostname as worker , do not attempt to open local file short circuit stream if worker supports domain socket ( as /dev/shm is not accessible ) <nl> - unmount as part of",0.9617908000946045
apache_pulsar/9195,transaction buffer stable position and lowwatermark implementation .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( yes ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1610466180,"currently the function world relies on serde concept to handle byte [ ] messages from pulsar . now that pulsar has schema registry , this pr allows functions to discover schema on the fly as well as have users provide schema hints while using functions . <nl> this pr supersedes 0 <nl> # # # modifications . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9741281270980835
apache_pulsar/8985,"<para-sep> for security reasons , oss supports only virtual hosted style access .","support tiered storage by aliyun oss . <nl> aliyun oss is compatible with the s3 api . <nl> for security reasons , oss supports only virtual hosted style access . <nl> so i use to connect , and set . <nl> test with local . <nl> - does this pull request introduce a new feature ? yes <nl> - if yes , how is the feature documented ? more tiered-storage provider <nl> - if a feature is not documented yet in this pr , please create a followup issue for adding the documentation",1608190647,serializes the message id and passes through the payload and metadata <nl> of the raw message .,0.9295052886009216
apache_kafka/10040,use raw config to infer connector type when returnning connect status response . <para-sep> retrieves raw config map by connector name .,"problem : when calling the connect status endpoint , a 0 error is returned , e.g . <nl> when any of the connector 's has an exception from the config provider . this is because the is trying to use resolved config . however , only the is needed from the config to infer if this connector is of source or sink type . the endpoint should still return the status of the connector instead of a 0 error . <nl> this change uses raw config from the config backing store to retrieve the connector class to avoid any variable",1612375204,"the static method is missing a . <nl> this pr globally fixes the typo and keeps the code indentation consistent . <nl> i have not yet run the unit tests , because looks like it is going to take upwards of an hour to download : sleeping : . <nl> i did confirm that the misspelling does not occur anywhere else in the sources or tests . it seems that it would only break a dependent library if that library is using the implementation classes directly .",0.892195999622345
ballerina-platform_ballerina-lang/26403,add a formatting test for parser test cases <cm-sep> fix the formatting of some parser test cases <para-sep> test the formatting functionality for parser test cases . <nl> test the formatting of parser test cases .,* fix formatting in some parser test cases .,1603081721,"this pr add the support for default values for annotations . currently , only basic literals are allowed as default values .",0.9438493847846985
elastic_elasticsearch/71162,"integrate node shutdown api with cluster metadata . <nl> this commit hooks up the node shutdown api to the node shutdown cluster <nl> metadata , so using the api will result in the appropriate writes to the <nl> cluster state .","this commit hooks up the node shutdown api to the node shutdown cluster <nl> metadata , so using the api will result in the appropriate writes to the <nl> cluster state .",1617234049,"this pr enables stats on inference to be gathered and stored in the indices . <nl> each node + model_id will have its own running stats document and these will later be summed together when returning _stats to the user . <nl> is ilm managed ( when possible ) . so , at any point the underlying index could change . this means that a stats document that is read in and then later updated will actually be a new doc in a new index . this complicates matters as this means that having a running knowledge of seq_no and",0.9884507060050964
neo4j_neo4j/11129,do n't use methodhandle # invokewitharguments for udf <cm-sep> naming <cm-sep> no methodhandle # invokewitharguments for procedures <cm-sep> no methodhandle # invokewitharguments for userdefinedaggregation,"turns out that is a lot slower than normal reflection . <nl> these are numbers from calling a simple udf directly , first case is with this change and the latter one is after applying change . <nl> i think there are more improvements to be done here but after applying this fix it looks like the usage of a hashmap in in the is a bigger bottleneck than the reflection .",1519826799,o serialize stack trace for internal errors . <nl> o reorganised error codes . <nl> o renamed neo4jerror subclasses to match statuscode names . <nl> o renamed neo4jerror.code to statuscode . <nl> o stop neo4jerror extending java.lang.exception . <nl> o explicit functional test for response format for cypher syntax errors .,0.8954094052314758
elastic_elasticsearch/71219,"output script stats for indexed fields . <nl> we have recently introduced the ability to associate an indexed field with a script . this commit updates the existing mappings stats to output stats about the script , similar to what we already do for runtime fields . <para-sep> holds stats about the content of a script <nl> holds stats about a mapped field .","we have recently introduced the ability to associate an indexed field with a script . this commit updates the existing mappings stats to output stats about the script , similar to what we already do for runtime fields .",1617365514,"adds support for fetching and fields in . <nl> this only works if we can get global ordinals for those fields so we <nl> ca n't support the entire family , but this gets us somewhere .",0.984499454498291
apache_shardingsphere/9983,add oracle privilege loader <para-sep> oracle privilege loader . <nl> todo other privilege,changes proposed in this pull request : <nl> - add oracle privilege loader,1617804685,changes proposed in this pull request : <nl> - add test cases for datanode,0.9876847267150879
elastic_elasticsearch/72519,wip <cm-sep> service accounts - runtime enforcement for min length of service token secret <para-sep> length of secret value is too short <nl> success based on credential store,"the secret value of a service account token generated using either the cli or api is a time-based uuid of length 0 which provides sufficient entropy . but file-based service account tokens can be created with external tools . it is therefore possible that a token is created with too short secret value . since there is no way to detect it at the token creation or load ( from the file ) time , this pr adds a check at authentication time to reject such tokens , i.e . it returns an error if the service token ( decoded",1619765058,"today will wait <nl> indefinitely for the master to process the pending cluster health task , <nl> ignoring the specified timeout . this could take a very long time if the master <nl> is overloaded . this commit fixes this by adding a timeout to the pending <nl> cluster health task .",0.9323384165763855
vespa-engine_vespa/16979,revert ' revert ' lesters/cell cast java ' ' . <nl> this reverts commit sha . <cm-sep> add missing pipe to cell_cast parsing <para-sep> the cell_cast tensor function creates a new tensor with the specified cell value type .,testing is great : there was a missing character in line 0 .,1615900082,this is the final piece to allow users to retrieve metrics via their application 's containers .,0.9742986559867859
grpc_grpc-java/7458,"create a resourceupdate facade to tracking all types of resources under subscription . <cm-sep> introduce resourcesubscriber , which encapsulates the whole tracking logic ( initial subscription timeout , data cache , watchers , etc ) for a single subscribed resource . <cm-sep> fixed the way of verifying scheduled resource fetching timer in tests . <para-sep> currently in retry backoff . <nl> tracks a single subscribed resource . <nl> resource states : - present : data ! = null ; data is the cached data for the resource - absent : absent == true - unknown : anything else note absent - > data == null , but not vice versa . <nl> todo ( chengyuanzhang ) : delete me . todo ( chengyuanzhang ) : delete me . todo ( chengyuanzhang ) : delete me .","this would be a great maintainability improvement for xdsclientimpl . <nl> should have no behavior change . <nl> currently for each type of resources , there are multiple pieces : watchers , cached entries , initial fetch timer , etc . every time newly subscribing to a new resource or receiving a response , these pieces of state need to be updated individually . this is complicated to maintain and there is a lot of duplicated code . this pr groups status of a subscribed resource into . you can think of it for tracking the state of a single",1601011077,"this add perfmark annotations in some key places , notably on transport/application boundaries , and thread hop locations . perfmark records to a thread-local buffer the events that happen in each thread . perfmark is disabled by default , and will compile to a noop unless is invoked . this should make it free when disable , and pretty fast when it is enabled . <nl> it is important that started tasks are ended , so several places in our code are moved to either try-finally blocks , or moved into a private method . i realize this is ugly",0.9733365178108215
apache_druid/10233,"add ' offset ' parameter to the scan query . <nl> it works by doing the query as normal and then throwing away the first <nl> ' offset ' number of rows on the broker . <para-sep> returns the number of elements currently in the sorter . <nl> offset for this query ; behaves like sql ' offset ' . zero means no offset . negative values are invalid . <nl> limit for this query ; behaves like sql ' limit ' . will always be positive . <nl> returns whether this query is limited or not . <nl> this api works by ' creative ' use of equals . it requires warnings to be suppressed and also requires spotbugs exclusions ( see spotbugs-exclude.xml ) . <nl> a sequence that wraps the results of a scanquery and skips a given number of rows . it is used to implement the ' offset ' feature . <nl> skip everything . <nl> skip partially . <nl> also , remove ' offset ' and add it to the ' limit ' ( we wo n't push the offset down , just apply it here , at the merge at the top of the stack ) . <nl> unlimited stays unlimited . <nl> materializes the full sequence in memory before returning it . <nl> getnumrows is only used by tests and by segmentmetadataquery ( which would be odd to call on inline datasources ) so no big deal if it does n't always work . <nl> simulate results back from 0 historicals <nl> somewhere inside the first scanresultvalue . <nl> somewhere inside the second scanresultvalue . <nl> past the second scanresultvalue . <nl> tests the order in which scan query results come back . ensures that we have run-to-run stability of result order , which is important for offset-based pagination . <nl> set number of server equal to number of segments , then try all possible distributions of segments to servers . <nl> try every limit up to one past the total number of rows . <nl> try various batch sizes . <nl> simulates what the historical servers would do . <nl> simulates what the broker would do . <nl> finally : run the query .","it works by doing the query as normal and then throwing away the first ' offset ' number of rows on the broker . <nl> also includes some logic to skip writing the field in json if it 's ( internally this is used to signify ' unlimited ' ) . <nl> edit : now also includes changes geared towards stabilizing scan query result ordering , which is required for offset-based pagination to be useful .",1596474834,"several bugs are found in the overshadowablemanager . it could happen in various cases , but it was essentially the contract of the of the atomicupdategroup was not respected properly . i updated its javadoc as below to make it more clear : . <nl> the main bug fixes have been fixed in and . <nl> in , it should consider the following cases : . <nl> 0 ) the latest standby group should be visible if there is no full group . <nl> 0 ) if an overshadowed group becomes full , it could be promoted to visible if",0.9817430973052979
apache_pulsar/8924,"support namespace-level maxsubscriptionspertopic <para-sep> create a client that can fail quickly <nl> after removing the restriction , it should be able to create normally <nl> create a client that can fail quickly <nl> we can only create 0 consumers <nl> set namespace-level policy , the limit should up to 0 <nl> after removing the restriction , it should fail again <nl> get the maxsubscriptionspertopic for a namespace . <nl> get the maxsubscriptionspertopic for a namespace asynchronously . <nl> set the maxsubscriptionspertopic for a namespace . <nl> set the maxsubscriptionspertopic for a namespace asynchronously . <nl> remove the maxsubscriptionspertopic for a namespace . <nl> remove the maxsubscriptionspertopic for a namespace asynchronously .",0 ) verify that the basic api is correct <nl> 0 ) verify that the restriction is in effect <nl> 0 ) verify the priority of namespace level and broker level,1607698242,support set/get/remove maxproducers on a topic level .,0.9931429028511047
Graylog2_graylog2-server/9394,make sure to use the oss es container for tests . <nl> due to the version constraint of ' ^version ' we only used the oss container <nl> for es 0.x . <nl> adjust clientes7 # existingtemplates to not use a wildcard ( ' * ' ) argument <nl> when creating the getindextemplatesrequest object . <nl> using the wildcard argument with no existing index templates returns a <nl> 0 from es and throws an exception . <nl> this fixes the indicesgetallmessagefieldses7it test when switching to <nl> the oss container . the regular es container is automatically creating <nl> indices for x-pack features so there are always existing indices and <nl> index templates . the oss container does n't create any indices and <nl> templates by default and so the # existingtemplates call failed with a <nl> 0 . <cm-sep> disable es container reuse on jenkins . <nl> this prevents a warning on every container startup . <para-sep> avoids reuse warning on jenkins ( we do n't want reuse in our ci environment ),due to the version constraint of ' ^version ' we only used the oss container <nl> for es 0.x . <nl> adjust clientes7 # existingtemplates to not use a wildcard ( ' * ' ) argument <nl> when creating the getindextemplatesrequest object . <nl> using the wildcard argument with no existing index templates returns a <nl> 0 from es and throws an exception . <nl> this fixes the indicesgetallmessagefieldses7it test when switching to <nl> the oss container . the regular es container is automatically creating <nl> indices for x-pack features so there are always existing indices and <nl> index templates,1604739944,"prior to these changes using the widget pagination requested messages within a time range which relates to the query . in the context of a dashboard , where each widget has its own time range , this results in a wrong behaviour . <nl> with this pr , the always relates to the effective time range of the related search type .",0.8680903315544128
elastic_elasticsearch/71240,"reset api should fail fast when there is an error <para-sep> this class represents the response of the feature state reset api . it is a list containing the response of every feature whose state can be reset . the response from each feature will indicate success or failure . in the case of a failure , the cause will be returned as well . <nl> create a new resetfeaturesresponse <nl> a class representing the status of an attempt to reset a feature 's state . the attempt to reset either succeeds and we return the name of the feature and a success flag ; or it fails and we return the name of the feature , a status flag , and the exception thrown during the attempt to reset the feature . <nl> create a resetfeaturestatestatus .","previously , the reset api returned a list of which feature states it tried to reset , along with success and failure messages . however , the overall return status was always success ( ) , even if an individual feature state failed . <nl> this pr changes the reset api so that it uses different response codes for different situations : if all reset operations succeed , if some operations succeed and others fail , and if all of the reset operations fail . clients should check the response code from this api . <nl> the api response now",1617378857,"this commit moves away from the static rollup index <nl> naming strategy and moves towards a randomized rollup index name scheme . <nl> this will reduce the complications that exist if the rollupstep fails and retries <nl> in any way . a separate cleanup will still be required for failed temporary indices , <nl> but at least there will not be a conflict . <nl> this commit generates the new rollup index name in the lifecycleexecutionstate so <nl> that it can be used in rollupstep and updaterollupindexpolicystep on a per-index <nl> basis .",0.9790998697280884
elastic_elasticsearch/71461,"when we added scripts to long and double mapped fields , we added tests <nl> for the general scripting infrastructure , and also specific tests for those two <nl> field types . this commit extracts those type-specific tests out into a new base <nl> test class that we can use when adding scripts to more field mappers .","when we added scripts to long and double mapped fields , we added tests <nl> for the general scripting infrastructure , and also specific tests for those two <nl> field types . this commit extracts those type-specific tests out into a new base <nl> test class that we can use when adding scripts to more field mappers .",1617876613,> bucket aggregations compute bucket doc_count values by incrementing the doc_count by 0 for every document collected in the bucket . <nl> > <nl> > when using summary fields ( such as aggregate_metric_double ) one field may represent more than one document . to provide this functionality we have implemented a new field mapper ( named doc_count field mapper ) . this field is a positive integer representing the number of documents aggregated in a single summary field . <nl> > <nl> > bucket aggregations will check if a field of type doc_count exists in a document and will take,0.9574592113494873
hazelcast_hazelcast/18356,revert ' make nearcacheconfig equal before and after it is used ' . <nl> this reverts commit sha . <cm-sep> copy nearcacheconfig when it needs to be changed . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used . <nl> ( cherry picked from commit sha ) <para-sep> create copy of eviction config <nl> create copy of nearcache config and set eviction config,this reverts commit sha . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used .,1614852558,"added the property to the hot restart persistence config . <nl> eventually , i would like to have this option on the data structure specific but there are potential compatibility issues with that . first , this is a patch-level release so i do n't think it is safe to meddle with the config serialization format . second , is included in which is a - which i understand essentially means that the class is set in stone and can not change without breaking client compatibility etc . and lastly , the map and cache configs are persisted in the",0.9380027651786804
apache_pulsar/9612,schema comparison logic change . <cm-sep> add the test logic,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1613633682,support nested fields in pojos to be able to be queried by sql,0.9592685699462891
apache_shardingsphere/9992,remove unnecessary annotation and related processor <cm-sep> fix,changes proposed in this pull request : <nl> - remove unnecessary annotation and related processor ( it engine module ) <nl> - remove the dependency of actualdatasourcebuilder in h2container,1617873435,changes proposed in this pull request : <nl> - extract scaling job service . <nl> - distributed scaling job service impl . <nl> - standalone scaling job service impl . <nl> - fixes javadoc exception .,0.9707375764846802
prestodb_presto/15431,support different concurrency settings for table writer . <nl> if tablewriter input is fixed distributed ( e.g . : aggregation or join ) <nl> the actual aggregation or join concurrency will be set to the <nl> table writer concurrency <cm-sep> prefer default parallelism to avoid adding extra local exchange . <nl> for partitioned writes the shuffle is added unconditionally . there 's <nl> no reason to additionally prefer the fixed streams .,if tablewriter input is fixed distributed ( e.g . : aggregation or join ) the actual aggregation or join concurrency will be set to the table writer concurrency .,1605197678,reusing node ids simplifies tracking of plan nodes throughout the planning phase,0.8774574398994446
apache_incubator-pinot/5903,[ te ] anomalies page - fix feedback is not populated if retrived by the method findbyids,previously the anomaly feedback is not populated if retrieved by the method . this pr fixes the issue so that the feedbacks can be shown on the anomalies page .,1597946768,"in the case when the tabular view has a ratio metric ( say a/b ) and another metric which is part of the ratio ( say a ) , the metric a is generating twice the number of cells",0.7979637980461121
apache_druid/10567,add timeout metric <para-sep> query timeout metric is not relevant here and this metric is already being tracked in the broker and the data nodes using queryresource <nl> returns the number of successful queries processed during the emission period . returns the number of failed queries during the emission period . returns the number of queries interrupted due to cancellation during the emission period . <nl> returns the number of timed out queries during the emission period . <nl> trigger metric emission,this pr adds a new query metric that represents the number of timed out queries during the emission period . timed out query counts were previously clubbed under . having a separate metric for timed out queries can make it a little easier for cluster operators to diagnose query issues better . <nl> marking this as as no longer represents timed out query counts and user defined alerting/reports may need to be adjusted to factor in along with . <nl> it would be useful to add metricsmonitors to integration tests so that it provides better testing for prs such as,1604948168,fix class cast exception while trying to recover a batch . the fix is straightforward just changed check for a batch number to recover into <nl> for reviewers : the key changed/added classes in this pr are and . <nl> ( add this section in big prs to ease navigation in them for reviewers . ),0.953434944152832
OpenAPITools_openapi-generator/7456,"replace tab with 0-space <cm-sep> add space after if <para-sep> / httpsigning configuration / <nl> / gets and sets the httpsigningconfiuration / <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key / <nl> / / gets the http signing header / <nl> / / gets the hash algorithm sha256 or sha512 / <nl> / / gets the signing algorithm / <nl> / / gets the signature validaty period in seconds / <nl> / / gets the headers for httpsigning / / / / / <nl> the time when the http signature expires . the api server should reject http requests that have expired . <nl> the 'date ' header . <nl> the 'host ' header . <nl> the time when the http signature was generated . <nl> when the 'digest ' header is included in the http signature , the client automatically computes the digest of the http request body , per rfc 0 . <nl> the 'authorization ' header is automatically generated by the client . it includes the list of signed headers and a base64-encoded signature . <nl> hash table to store singed headers <nl> get the body <nl> concatinate headers value separated by new line <nl> / / gets the ecdsa signature / / / <nl> last readbyte was n't a removed zero , so back up a byte <nl> / / detect the key type from the pem file . / / key file path in pem format / <nl> this type of key can hold many type different types of private key , but here due lack of pem header <nl> todo : - update the key based on oid <nl> / gets the httpsigning configuration / <nl> / httpsigning configuration / <nl> / gets and sets the httpsigningconfiuration / <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key / <nl> / / gets the http signing header /",- replace tabs with 0-space <nl> - add a condition to generate httpsigningconfiguration.cs only if the spec contains http signing authentication .,1600585283,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) .",0.8326889872550964
apache_beam/13225,"check coder proto to avoid registering same coder under different name in step translation phase <para-sep> unlike structuredcoder , custom coders may not have proper implementation of hashcode ( ) and equals ( ) , this lead to unnecessary duplications . in order to avoid this we examine already registered coders and see if we can find a matching proto , and consider them same coder .",check coder proto to avoid registering same coder under different name in step translation phase .,1604003839,"adds a counter to tell dataflow if the worker is spending too much time garbage collecting so that we can avoid autoscaling to small worker numbers if memory pressure is too high . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9007622003555298
apache_druid/10605,"adding bitwise expressions <cm-sep> double handling and vectorization <cm-sep> move conversion to evals <cm-sep> revert unintended changes <para-sep> this is a copy of the logic of bivariatemathfunction for string handling , which itself is a remix of binaryevalopexprbase.eval modified so that string inputs are always null outputs <nl> doubles are cast <nl> but can be converted to be double-like","finally , i 've added vectorization support so these expressions can be utilized in vectorized query engines , as well as tests . <nl> i 'll save adding sql support as a follow-up pr",1606300036,it works by keeping and and in the end spitting as mean . <nl> that could be added in future as a optional strategy in this aggregation type,0.9611498713493347
OpenAPITools_openapi-generator/8004,first commit of api key feature . <cm-sep> added multi key and url query key support <para-sep> automatically generated by the openapi generator * <nl> configure http basic authorization : { { { name } } } <nl> configure http bearer authorization : { { { name } } } <nl> configure api key authorization : { { { name } } } <nl> oauth authentication supported right now { { /isoauth } } { { # ishttpsignature } } no http signature authentication supported right now { { /ishttpsignature } } <nl> api.setusername ( ' testname ' ) ; api.setpassword ( ' testpassword ' ) ; <nl> automatically generated by the openapi generator * <nl> oauth authentication supported right now <nl> pfxpetapi | addpet | post /pet | add a new pet to the store pfxpetapi | deletepet | delete /pet/ { petid } | deletes a pet pfxpetapi | findpetsbystatus | get /pet/findbystatus | finds pets by status pfxpetapi | findpetsbytags | get /pet/findbytags | finds pets by tags pfxpetapi | getpetbyid | get /pet/ { petid } | find pet by id pfxpetapi | updatepet | put /pet | update an existing pet pfxpetapi | updatepetwithform | post /pet/ { petid } | updates a pet in the store with form data pfxpetapi | uploadfile | post /pet/ { petid } /uploadimage | uploads an image pfxstoreapi | deleteorder | delete /store/order/ { orderid } | delete purchase order by id pfxstoreapi | getinventory | get /store/inventory | returns pet inventories by status pfxstoreapi | getorderbyid | get /store/order/ { orderid } | find purchase order by id pfxstoreapi | placeorder | post /store/order | place an order for a pet pfxuserapi | createuser | post /user | create user pfxuserapi | createuserswitharrayinput | post /user/createwitharray | creates list of users with given input array pfxuserapi | createuserswithlistinput | post /user/createwithlist | creates list of users with given input array pfxuserapi | deleteuser | delete /user/ { username } | delete user pfxuserapi | getuserbyname | get /user/ { username } | get user by user name pfxuserapi | loginuser | get /user/login | logs user into the system pfxuserapi | logoutuser | get /user/logout | logs out current logged in user session pfxuserapi | updateuser | put /user/ { username } | updated user,"since the qt5 generator did not support any security features , i added basic api key authentication . it supports multiple keys as well as key in http header or key as url query . <nl> edit : added basic authentication with username and password as well . <nl> edit2 : updated readme and added basic bearer token authentication . <nl> sample headers for verification : . <nl> with key in http header : . <nl> -- > post /pet http/version <nl> -- > host : localhost:0 <nl> -- > user-agent : openapi-generator/version/cpp-qt5 <nl> -- > api_key : special-key <nl>",1606134331,"ps : after running ./run/ { lang } -petstore.sh , i got change on the version and unrelated stuff like . should i revert this change ?",0.9150993227958679
apache_druid/10135,new average aggregator <cm-sep> method to create count aggregator factory <cm-sep> test everything <cm-sep> update other usages <cm-sep> fix style <para-sep> do n't expect this to happen .,this pr fixes a bug with where it would count nulls toward the average even with . <nl> introduced a new helper method in the called . this method returns a in the case where the column is nullable and a regular otherwise . <nl> this new helper method is then used in to get the correct null respecting count in the denominator . in order to implement this i 've replaced the parent class of from to a regular because does n't expose all the information we need . <nl> some areas i would like focus and feedback on,1593804739,"- adds an optional resolution parameter to approx_quantile . <nl> - fixes a bug where unfiltered approximate histogram aggregators could get reused improperly by filtered aggregators . <nl> - rename quantile to approx_quantile , which is probably a better name , in keeping with approx_count_distinct . <nl> - includes some slight refactoring to allow tests to make druidtables that include complex columns .",0.9307451844215393
ballerina-platform_ballerina-lang/26003,capture dependencies of global variables <para-sep> get the global variable dependency map . <nl> means no dependencies for this node . means the current node has dependencies . lets analyze its dependencies further . <nl> hold global variable dependencies identified in dataflowanalyzer .,"hence , when we optimize ballerina locks , we miss the information regarding shared references to a single value . <nl> > this pr will fix the bug . <nl> > if any dependencies found , irrespective of whether a code branch will use or modify the reference , we use that info in the optimisation phase .",1600758483,add support for delay serverconnector startup at the service deployment time,0.968108057975769
apache_beam/12983,add hotkeyloggingenabled to the java dataflowpipelineoptions . <nl> this will ultimately control whether or not the literal hot key content <nl> is logged to cloud logging . <para-sep> if enabled then the literal key will be logged to cloud logging if a hot key is detected . * /,this will ultimately control whether or not the literal hot key content is logged to cloud logging,1601510862,the configuration setting [ 0 ] is available in flink to allow a grace period when checkpoints runtime is > checkpoint interval . <nl> this should be exposed in and to allow users to configure this . <nl> the default for this value in flink is 0ms [ 0 ] . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.8692458271980286
OpenAPITools_openapi-generator/7873,"fix a few issues with go examples generation . <nl> this fixes a bunch of issues seen when generating go examples , namely <nl> - numbers are n't casted to the right type <nl> - the time import is missing <nl> - enums are treated as regular models <para-sep> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> enumheaderstringarray | [ ] string | header parameter enum test ( string array ) | enumquerystringarray | [ ] string | query parameter enum test ( string array ) | enumformstringarray | [ ] string * | form parameter enum test ( string array ) | [ default to & quot ; $ & quot ; ] <nl> param | mapstring | request body | pipe | [ ] string | | ioutil | [ ] string | | http | [ ] string | | url | [ ] string | | context | [ ] string | | <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> status | [ ] string | status values that need to be considered for filter | tags | [ ] string | tags to filter by | <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> enumheaderstringarray | [ ] string | header parameter enum test ( string array ) | enumquerystringarray | [ ] string | query parameter enum test ( string array ) | enumformstringarray | [ ] string * | form parameter enum test ( string array ) | [ default to & quot ; $ & quot ; ] <nl> requestbody | mapstring | request body | pipe | [ ] string | | ioutil | [ ] string | | http | [ ] string | | url | [ ] string | | context | [ ] string | | <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> ( value : ) <nl> status | [ ] string | status values that need to","this fixes a bunch of issues seen when generating go examples , namely <nl> - numbers are n't casted to the right type <nl> - the time import is missing <nl> - enums are treated as regular models <nl> - example values are used correctly .",1604482950,"- i 've run both the rust server changes , and the asp.net scripts . <nl> - tests are added to rust server codegen examples to check that the generated code is correct . <nl> any bugs are mine , any credit is mark 's : smile : .",0.9265276193618774
apache_camel/4783,support google service account authentication <cm-sep> commit changes to generated files <para-sep> the emailaddress of the google service account . <nl> the name of the p12 file which has the private key to use with the google service account . <nl> the email address of the user the application is trying to impersonate in the service account flow . <nl> the emailaddress of the google service account . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer <nl> the name of the p12 file which has the private key to use with the google service account . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer <nl> the email address of the user the application is trying to impersonate in the service account flow . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer <nl> the emailaddress of the google service account . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer <nl> the name of the p12 file which has the private key to use with the google service account . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer <nl> the email address of the user the application is trying to impersonate in the service account flow . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : consumer,service account authentication support for google-calendar-stream component .,1608148726,- fix ( ) : propagate inline count in camel-olingo2 component . <nl> add result count ( coming from system query option $ inlinecount ) to odata entries when using splitresults . <nl> - fix ( ) : configure entity provider properties on camel-olingo2 . <nl> add uri param configuration settings for read/write entity provider properties . the entity provider properties are used for each read/write operation and specify the way to serialize odata entries as json/xml/atom data . <nl> - fix ( ) : fix merge operation in camel-olingo2 . <nl> merge operation must enable isdatabasedpropertyserialization setting in the,0.9761584997177124
vespa-engine_vespa/15589,"subclass quorumpeermain to be able to use initializeandrun ( ) . <nl> can not use main ( ) , since it calls system.exit ( ) and will not work <nl> when running unit tests , so subclass and use initializeandrun ( ) <para-sep> extends quoroumpeermain to be able to call initializeandrun ( )","can not use , since it calls and will not work <nl> when running unit tests , so subclass and use .",1606906893,should fix remaining issues in system tests,0.9298781752586365
apache_pulsar/9900,use orderedexecutor to ensure all modification are in a single thread <para-sep> use clone and cas zk to ensure thread safety <nl> use clone and cas zk to ensure thread safety <nl> init cache <nl> the original object should not be modified <nl> init cache <nl> the original object should not be modified,"the policies object also contains non-thread-safe collections such as hashmap and hashset . concurrent operations on these objects also have thread-safety issues . <nl> the cached object in caffeine will be immediately visible to other threads <nl> atomicity : modification refers to the replacement of the entire cloned object . there will be no intermediate state where some attribute values are modified , so it is atomic <nl> orderliness : guaranteed by the implementation class of metadatacache . now the cached object corresponds to a version number . use cas to write back . if the writeback fails , it",1615603808,"when we are trimming the ledgers we are saving the but as soon as your restart the broker the currentledger is not containing the lastmessageid ( because it is a fresh new ledger ) . <nl> changes : <nl> - add test case on pulsar-broker that reproduces the issue reported but the user <nl> - log a message when we are trimming the ledger at lastaddconfirmedentry <nl> - add test case that prevent changes in the future on managedledgerimpl <nl> - fix a minor issue in persistenttopic # getlastmessageid , a return keyword was missing and we continued with a",0.957897424697876
apache_kafka/10100,moved creation of file to write to prevent unnecessary creation of files . <cm-sep> now will delete partition.metadata if ibp is too low . <cm-sep> minor tweak for efficiency <cm-sep> addressing comments . <cm-sep> added comment to explain keeppartitionmetadatafile flag,"currently the partition.metadata file is created when the log is created . however , clusters with older inter-broker protocols will never use this file . this pr moves the creation of the file to when we write to the file . <nl> this pr also deletes the partition.metadata file on startup if the ibp version is lower than version .",1612980038,this pr avoids generating unnecessary topicchange events during the topic validation . it does so by adding a field in the request . this allows to not register the watch when topics are queried from the topic validation logic .,0.9999999403953552
ballerina-platform_ballerina-lang/25778,"add parser changes for isolated objects <para-sep> can not have the same qualifier twice <nl> can not apply a particular qualifier in a certain context <nl> clones the last node in list with the invalid node as minutiae and update the list if the nodelist is not empty . otherwise adds the invalid node as minutiae to the next consumed token . <nl> note that following top level nodes can have the isolated qualifier . funcdef , functype , classdef , objecttype <nl> else fall through <nl> class-type-quals : = ( distinct | client | readonly | isolated ) * <nl> null indicates the end of qualifiers <nl> ( client | isolated ) object { object-member-descriptor } <nl> parse object constructor qualifiers . object-constructor-qualifier : = <nl> null indicates the end of qualifiers <nl> parse object type descriptor qualifiers . object-type-descriptor-qualifiers : = ( client | isolated ) * <nl> here we allow parsing of old object type qualifiers ( and ) and then log an error <nl> null indicates the end of qualifiers <nl> else fall through",- add isolated qualifier support for module-class-defn and object-type-descriptor .,1600089990,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9724323153495789
OpenAPITools_openapi-generator/7459,bump sonar action to use java 0 <cm-sep> add some exclusions for maven/online projects <cm-sep> fix a couple sonar warnings in confighelp.java <cm-sep> remove sonar branch name <cm-sep> hardcode master branch <cm-sep> add some sonar exclusions <cm-sep> mvn install,"minor adjustments to sonar scanning… . <nl> * exclude maven plugin from test coverage reporting <nl> * exclude online project from test coverage reporting <nl> * use to prevent scanner from pulling the artifact from last master build , and use jars published locally <nl> * update to use java 0 as sonar will stop supporting publishing reports built via java 0 soon .",1600632081,"- add outputtype <nl> - fix nullable array <nl> - put tests in different folders ( api , model ) .",0.8402009010314941
confluentinc_ksql/6718,update processing log exists msg from info to warn ( minor ) <para-sep> whether the kafka topic exists with an unexpected number of either partitions or replicas .,"the number of partitions for the processing log topic is configurable via the config . however , if the processing log topic already exists with a different number of partitions , the existing topic is left untouched and the ksqldb server continues to start up after logging a message indicating that topic exists and the number of partitions was not as expected . ( the same behavior is true as well for number of replicas . ) this log message is currently logged at level info . this pr changes the log message to level warn instead . <nl> manual",1607064614,this pr reflect the changes to the base class .,0.8651176691055298
apache_beam/13166,allow to specify coder for hadoopformatio.read <para-sep> transforms the keys read from the source using the given key translation function . * / <nl> transforms the values read from the source using the given value translation function . * / <nl> set key-translation again without coder should reset back to type-descriptor only <nl> set value-translation again without coder should reset back to type-descriptor only,allow to specify coder for hadoopformatio.read,1603360311,"added test cases for implementation for in . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9591366052627563
apache_flink/15174,migrate module related tests in localexecutoritcase to the new integration test framework,"this pr migrates the tests in to , and removes and in since they are not needed anymore . <nl> this change added a script under dir and can be verified by running . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes",1615606462,"support syntax as following through tableenvironment in sql client : . <nl> alter table [ [ catalogname . ] databasesname ] .tablename rename to newtablename . <nl> alter table [ [ catalogname . ] databasesname ] .tablename set ( name=value [ , name=value ] * ) . <nl> this change added tests and can be verified as follows : <nl> - added integration tests localexecutoritcase # testaltertable <nl> - added sqlparsertest in sqlcommandparsertest # testcommands . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. ,",0.8425366878509521
Graylog2_graylog2-server/9409,add roles users to the context of the roles list response <cm-sep> read new user context into store <cm-sep> display users of a role from user context,so the user expects to see the users of a role on the roles overviewpage .,1604925294,"do n't try to parse asa acl ids . <nl> improve parsing of strings : <nl> empty strings are received as a byte array full of zeros . <nl> properly convert them to empty strings . <nl> at some point cisco decided to stop including packet and byte counters <nl> in their netflow data . expected them to always be <nl> there and would trigger an npe . <nl> try to fallback on ciscos flow delta counters , so we have at least <nl> something meaningful in the message field .",0.9108902215957642
vespa-engine_vespa/16846,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> check for zero minutes <cm-sep> add target to scaling message <para-sep> the predicted duration of a rescaling of this cluster * / <nl> todo : remove when we have reliable completion for content clusters <nl> what cost difference is worth a reallocation ? / what resource difference is worth a reallocation ? / <nl> cluster level metrics . these are aggregated at fetch time over the nodes in the cluster at that point in time . <nl> queries per second * / <nl> a series of metric snapshots for the nodes of a cluster used to compute load <nl> the measurements for all nodes in this snapshot * / <nl> the cluster this is a timeseries for * / <nl> the nodes of the cluster this is a timeseries for * / <nl> returns the average number of measurements per node * / <nl> returns the number of nodes measured in this * / <nl> returns the average load of this resource in this * / <nl> a list of metric snapshots from a cluster , sorted by increasing time ( newest last ) . <nl> the max query growth rate we can predict from this time-series as a fraction of the current traffic per minute * / <nl> find the period having the highest growth rate , where total growth exceeds 0 % increase <nl> the current query rate as a fraction of the peak rate in this timeseries * / <nl> metric time series by node ( hostname ) . each list of metric snapshots is sorted by increasing timestamp * / <nl> adds node snapshots to this . * / <nl> returns all cluster level metric snapshots for a given cluster * / <nl> node level metrics * / <nl> cluster level metrics . must be aggregated at fetch time to avoid issues with nodes and nodes joining/leaving the cluster over time . <nl> a single measurement of all values we measure for one node . <nl> queries per second * / <nl> the configuration generation at the time of this measurement , or 0 if not known * / <nl> ( 0 is timestamp ) <nl> this error seems non-recoverable <nl> ( 0 is timestamp ) <nl> we remove full days at once and we want to see at least three days to",( the autoscaling test attempts to scale but it does n't work out so i need to see to what . ) <nl> please review but do n't merge . i 'll do it when we have a release .,1615236598,"the changes brought each other on , and got jumbled together 😭 . <nl> the changes are : . <nl> 0. logs are stored as objects . <nl> 0. the log for an active run is stored with a curator , in chunks of reasonable sizes . <nl> 0. log entries is written through immediately upon logging , and are given a ( new ) sequence id as counted per run . <nl> 0. when a run finishes , its log chunks are aggregated and moved to long-term storage . <nl> 0. logs are served as log objects in the",0.9829549193382263
Alluxio_alluxio/11257,reorder inherit when empty <cm-sep> update comment <cm-sep> do not set empty owner/group on sync <para-sep> only set owner if not empty <nl> only set group if not empty <nl> do not call setowner/group after inheriting from parent if empty <nl> do not call setowner/group after inheriting from parent if empty <nl> resets global state after each test run . <nl> create parent of mount point <nl> mock ufs mount <nl> mock dir1 ufs path <nl> mock nested ufs path <nl> mount <nl> create directory in alluxio only <nl> mock creating the same directory and nested file in ufs out of band <nl> list with sync.interval=0 <nl> verify owner/group is not empty,"this pr includes 0 changes : <nl> - for s3 , when any inodes created during loadmetadata should inherit owner/group from the parent directory in alluxio instead of being empty . this was broken because was called after in <nl> - when syncing metadata with s3 , an sync plan could lead to setting the owner and group to in . the fix is to not set the options in to avoid setting to an empty string or . <nl> this can be reproduced when a directory is created in alluxio only , the same directory is then later created",1586494002,"this fixes a bug where concurrent creation operations can lead to invalid inodes . the race condition looks like : . <nl> initial state : only inode in alluxio is ' / ' , ufs contains ' /a/b/c ' <nl> thread a : begins to create /a/b <nl> thread b : tries to create /a/b/c <nl> thread a : begins to create /a <nl> thread a : takes a write lock on /a <nl> thread a : creates a new inode for /a <nl> thread a : adds /a to the children list of ' / ' <nl> thread a",0.9036608338356018
apache_kafka/9800,": fix commit-timeoutexception handling for eos . <nl> if eos is enabled and the tx commit fails with a timeout , <nl> we should not process more messages ( what is ok for non-eos ) <nl> because we do n't really know the status of the tx . <nl> if the commit was indeed successful , we wo n't have an open tx <nl> can calling send ( ) would fail with an fatal error . <nl> instead , we should retry the ( idempotent ) commit of the tx , <nl> and start a new tx afterwards . <para-sep> if the task has a pending tx commit , we should just retry the commit but not process any records thus , the task is not processable , even if there is available data in the record queue","if eos is enabled and the tx commit fails with a timeout , <nl> we should not process more messages ( what is ok for non-eos ) <nl> because we do n't really know the status of the tx . <nl> if the commit was indeed successful , we wo n't have an open tx <nl> and calling send ( ) would fail with a fatal error . <nl> instead , we should retry the ( idempotent ) commit of the tx , <nl> and start a new tx afterwards .",1609364299,"this patch changes maybesendtransactionalrequest to handle both sending and polling transactional requests ( and renames it to maybesendandpolltransactionalrequest ) , and skips the call to poll if no request is actually sent . it also removes the inner loop inside maybesendandpolltransactionalrequest and relies on the main sender loop for retries .",0.8000435829162598
elastic_elasticsearch/71386,"include node roles in cluster state json response . <nl> today the response to does not include the roles of <nl> the nodes in the cluster . in the past this made sense , roles were <nl> relatively unchanging things that could be determined from elsewhere . <nl> these days we have an increasingly rich collection of roles , with <nl> nontrivial bwc implications , so it is important for debugging to be able <nl> to see the specific roles as viewed by the master . this commit adds the <nl> role names to the cluster state api output . <para-sep> testresponse [ s/ ' roles ' : \ [ [ ^ ] ] * \ ] / ' roles ' : $ body. $ _path/ ]","today the response to does not include the roles of <nl> the nodes in the cluster . in the past this made sense , roles were <nl> relatively unchanging things that could be determined from elsewhere . <nl> these days we have an increasingly rich collection of roles , with <nl> nontrivial bwc implications , so it is important for debugging to be able <nl> to see the specific roles as viewed by the master . this commit adds the <nl> role names to the cluster state api output .",1617781582,report anonymous roles in response to ' get _security/_authenticate ' api call when : . <nl> * anonymous role is enabled <nl> * user is not the anonymous user <nl> * credentials is not an api key,0.9562652111053467
apache_druid/10592,allow missing intervals for parallel task <para-sep> 0. need to determine intervals and numshards by scanning the data <nl> numshards will be determined in partialhashsegmentgeneratetask <nl> determine numshards based on maxrowspersegment and the cardinality <nl> this interval must exist since it passed the rowfilter <nl> this interval must exist since it passed the rowfilter <nl> some intervals populated from granularityspec can be missing in intervaltonumshardsoverride because intervaltonumshardsoverride contains only the intervals which exist in input data . we only care about the intervals in intervaltonumshardsoverride here . <nl> sorted input intervals,"this pr allows parallel task to run without explicit intervals in granularityspec . if intervals are missing , the parallel task executes an extra step for input sampling which collects the intervals to index . <nl> this pr additionally fixes a bug when is missing in hash partitioning . when is missing , the parallel task computes it by scanning the whole input . however , the computed numshards was ignored when it 's serialized into json . to fix it , this pr adds another field which stores the computed numshards per interval so that we can handle data",1605666376,"- expressionobjectselector able to read from string columns , and able to <nl> return strings . <nl> - expressionvirtualcolumn able to offer string ( and long for that matter ) <nl> as its native type . <nl> - expressionpostaggregator able to return strings . <nl> - groupby , topn : allow post-aggregators to accept dimensions as inputs , <nl> making expressionpostaggregator more useful . <nl> - topn : use dimextractiontopnalgorithm for string columns that do not <nl> have dictionaries , allowing it to work with string-type expression <nl> virtual columns . <nl> - adjusts null handling to better match the",0.9818122982978821
apache_camel/5166,allow endpoint to override prefetchcount from component <para-sep> tell the broker how many messages to send in a single request . often this can be set quite high to improve throughput . the option is a : & lt ; code & gt ; int & lt ; /code & gt ; type . group : consumer ( advanced ) <nl> tell the broker how many messages to send in a single request . often this can be set quite high to improve throughput . the option will be converted to a & lt ; code & gt ; int & lt ; /code & gt ; type . group : consumer ( advanced ),endpoint can override the component option prefetchcount to allow more customisation .,1614850410,added support of socks proxy to telegram component by adding proxytype query parameter . <nl> proxytype supported values are : <nl> - http <nl> - socks4 <nl> - socks5 . <nl> because of asynchttpclient use there is a clear distinguish between socks versions now unlike in .version version .,0.9372802972793579
apache_druid/10518,"first draft of grouping_id function <para-sep> grouping aggregator <nl> different result rows for a query could have different grouping columns when subtotals are used . this argument can not be passed by the user . it is set by druid engine when a particular subtotal spec is being processed . since grouping has to be calculated only once , it could have been implemented as a virtual function or post-aggregator etc . we modelled it as an aggregation operator so that its output can be used in a post-aggregator . calcite too models grouping function as an aggregation operator . since it is a non-trivial special aggregation , implementing it required changes in core druid engine to work . there were few approaches . we chose the approach that required least changes in core druid . we could have removed these aggregators on data servers but that would result in a signature mismatch on broker and data nodes . that requires extra handling and is error-prone . - on brokers - results from data node is already being re-processed for each subtotal spec . we made modifications in this path to update the grouping id for each row . <nl> the aggregator does n't need to read any fields . <nl> given the list of grouping dimensions , returns a long value where each bit at position x in the returned value corresponds to the dimension in groupings at same position x. x is the position relative to the right end . if keydimensions contain the grouping dimension at position x , the bit is set to 0 at position x , otherwise it is set to 0. groupings keydimensions value ( 0 least significant bits ) value ( long ) a , b , c [ a ] 0 0 a , b , c [ b ] 0 0 a , b , c [ c ] 0 0 a , b , c [ a , b ] 0 0 a , b , c [ a , c ] 0 0 a , b , c [ b , c ] 0 0 a , b , c [ a , b , c ] 0 0 a , b , c [ ] 0 0 // none included a , b , c 0 0 // all included <nl> ( long.size - 0 ) is","this pr adds grouping_id function in both sql and native query layer . the function is modeled as an aggregate function , similar to how it is done in calcite . unlike regular aggregate functions , this one takes the grouping dimensions as arguments . <nl> there were different ways , the aggregator result could have materialized for a particular subtotal spec . i initially tried putting the logic in the merge function inside . that did n't work though since many input rows do not need merging if the grouping key is seen only once . so i have",1603107685,add sql inputsource support for ingesting events from rdbms using parallel indexing,0.981626033782959
ballerina-platform_ballerina-lang/23963,"fix string variable presentation in idea plugin <cm-sep> disable code fragment evaluation view in idea plugin <cm-sep> add add support for arithmetic expression evaluation <cm-sep> add support for braced expressions <cm-sep> fix nested variables of bstring type <cm-sep> enable evaluation failures on unsupported tokens <cm-sep> add minor improvements <cm-sep> sync with master branch <para-sep> evaluates a given ballerina expression w.r.t . the provided debug state ( stack frame ) . <nl> a simple ballerina expression-specific parsing implementation , used to validate , parse and transform ballerina expressions into corresponding java expressions . <nl> validate , parse a given ballerina expression and returns the parsed syntax node for to the expression . <nl> validates for empty inputs . <nl> as single expressions can not be parsed standalone , coverts into a parsable unit . <nl> validates for syntactical correctness . <nl> extracts expression node from the parsed syntax-tree . <nl> returns expression input in a parsable format . <nl> adds missing semicolon , if required . <nl> as expressions can not be parsed standalone , wraps it inside a function template , as the return value ; <nl> error type definition for debug expression evaluation related exceptions . <nl> ballerina expression evaluation related exception kinds . <nl> supported expression types . ( language specification v2020r1 ) x + y x - y x * y x / y x x > y x x > = y to be implemented . x % y x.k x. : y x ? y : z ( x ) = > y let x = y in z <nl> expressions <nl> arithmetic operators <nl> relational operators <nl> variable identifiers <nl> numeric literals <nl> misc <nl> parses a given ballerina expression and transforms into its corresponding java expression . <nl> validates and converts the expression into a parsed syntax-tree node . <nl> transforms the parsed ballerina expression into a java expression using a node transformer implementation . <nl> trims leading and trailing double quotes , if presents . <nl> trims leading and trailing double quotes , if presents .",- arithmetic expressions <nl> - x + y <nl> - x - y <nl> - x * y <nl> - x / y <nl> - relational expressions <nl> - x < y <nl> - x > y <nl> - x < = y <nl> - x > = y . <nl> the proposed implementation approach can be divided into 0 phases as shown below .,1591882553,` . <nl> serversocket sample <nl> ` . <nl> client socket syntax <nl> ` . <nl> serversocket implementation currently supports new client socket accept in a nonblocking manner . non blocking reading and writing still pending .,0.9854663610458374
apache_druid/10510,"add docs and it for auto-compaction snapshot status api <para-sep> : name of the datasource for this status information : auto compaction scheduling status . possible values are and . returns if the datasource has an active auto compaction config submitted otherwise , : total bytes of this datasource waiting to be compacted by the auto compaction ( only consider intervals/segments that are eligible for auto compaction ) : total bytes of this datasource that are already compacted with the spec set in the auto compaction config . : total bytes of this datasource that are skipped ( not eligible for auto compaction ) by the auto compaction . : total number of segments of this datasource waiting to be compacted by the auto compaction ( only consider intervals/segments that are eligible for auto compaction ) : total number of segments of this datasource that are already compacted with the spec set in the auto compaction config . : total number of segments of this datasource that are skipped ( not eligible for auto compaction ) by the auto compaction . : total number of intervals of this datasource waiting to be compacted by the auto compaction ( only consider intervals/segments that are eligible for auto compaction ) : total number of intervals of this datasource that are already compacted with the spec set in the auto compaction config . : total number of intervals of this datasource that are skipped ( not eligible for auto compaction ) by the auto compaction .",add docs and integration tests for auto-compaction snapshot status api,1602578021,"i 'm unsure if this causes any issues in practice , but could be an issue if closing a yielder early . closing the yielder and stopping processing would potentially cause running pool tasks associated with the query to managed block until the offer/poll timeouts on the blocking queue , at which point they would fully die . <nl> amusingly , prior to the change in this pr , you could continue to use the ' closed ' yielder to get the complete set of results assuming no exceptions occur inside of the parallel merge processing itself , however the",0.9256104230880737
elastic_elasticsearch/70850,disallow creating geo_shape mappings with deprecated parameters <para-sep> check that only geo-shape queries on legacy prefixtree based geo shapes are disallowed .,"from version , it will not be allowed to create new mappings using deprecated parameters , and therefore all new mappings will be using the bkd indexing strategy .",1616660365,"* use mapping source directly instead of using mapper service to extract the relevant mapping details <nl> * moved assertion to timestampfield class and added helper method for tests <nl> * improved logic that inserts timestamp field mapping into an mapping . <nl> if the timestamp field path consisted out of object fields and <nl> if the final mapping did not contain the parent field then an error <nl> occurred , because the prior logic assumed that the object field existed .",0.9716018438339233
apache_camel/5090,change smpp default enquirelinktimer from 0 seconds to 0 seconds . <para-sep> default : 0 default : 0 default : 0 default : 0 default : 0 default : 0 default : 0 default : 0,change the default smpp enquirelinktime from 0 to 0 seconds . the default of 0 seconds is too aggressive for default connections not specifying an other value .,1613397036,"] make sure there is a [ jira issue filed for the change ( usually before you start working on it ) . trivial changes like typos do not require a jira issue . your pull request should address just this issue , without pulling in other changes . <nl> [ ] each commit in the pull request should have a meaningful subject line and body . <nl> [ ] if you 're unsure , you can format the pull request title like , where you replace with the appropriate jira issue . <nl> [ ] write a pull request",0.8526435494422913
gocd_gocd/8105,"* this is a replacement for the existing rails api , which <nl> will be removed eventually .","* this is a replacement for the existing rails api , which will be removed eventually .",1588716169,description : introduced scm api v3 . <nl> - deprecated v1 and v2 <nl> - add an usages api for a given scm material . <nl> response .,0.98720383644104
vespa-engine_vespa/15951,"disable topk optimisation on dispatch when content distribution is severly skewed . <nl> when the skew is too large the assumption that docs are evenly and randomly distributed hold . <nl> the impact and is larger on smaller systems . in large systems the where this optimisation is more important , <nl> the probabilitity of large skew will be less . <para-sep> returns the active documents on this group . if unknown , 0 is returned . * /","disable topk optimisation on dispatch when content distribution is severly skewed . <nl> when the skew is too large the assumption that docs are evenly and randomly distributed hold . <nl> the impact and is larger on smaller systems . in large systems the where this optimisation is more important , <nl> the probabilitity of large skew will be less .",1610032459,adds immediate task completion for failures and configurable task completion deadlines to avoid hanging request threads in case of a non-converging cluster .,0.9471331834793091
hazelcast_hazelcast/18444,"enable usage of expressionevalcontext while evaluating values <para-sep> representation of the values clause data , see subclasses . <nl> union rules","refactored values , so the evaluation is performed in a and uses - it 's an enabler for future work on dynamic parameters .",1617344766,removed the server and client version dependent compatibility codes .,0.9571385979652405
gocd_gocd/8339,"* revoke personal access token when the auth config id changed by modifying <nl> the cruise-config.xml from ui or directly editing the config on disk . <nl> * revoke the personal access tokens when the auth config is deleted from the <nl> ui or using api . <nl> * revoke the personal access tokens which belongs to the auth config which <nl> is not anymore in the config after a restart . <nl> steps : <nl> - create an auth config . <nl> - create a personal access token . <nl> - stop the server . <nl> - rename the auth config id to a new value by directly modifying the <nl> cruise-config.xml <nl> - start the server . <nl> on server startup , the created personal access token must be revoked .",description : . <nl> * revoke personal access token when the auth config id changed by modifying <nl> the cruise-config.xml from ui or directly editing the config on disk . <nl> * revoke the personal access tokens when the auth config is deleted from the <nl> ui or using api . <nl> * revoke the personal access tokens which belongs to the auth config which <nl> is not anymore in the config after a restart . <nl> steps : <nl> - create an auth config . <nl> - create a personal access token . <nl> - stop the server .,1594635753,introduces an internal api that represents the pipeline structure : .,0.8913413286209106
apache_kafka/9881,"initialize quorumstate lazily in raftclient.initialize ( ) . <nl> - there are cases where the quorum voters connect string is not ready <nl> up until after the controller starts . <nl> eg : if the controller is configured to choose a free port , we need to <nl> wait until after the controller starts to configure the right <nl> host : port connect string for the raftclient to connect to <para-sep> initialize the client with the given raft configuration . this should only be called once on startup . <nl> package-private for testing <nl> package-private for testing","- there are cases where the quorum voters connect string is not ready <nl> up until after the controller starts . <nl> eg : if the controller is configured to choose a free port , we need to <nl> wait until after the controller starts to configure the right <nl> host : port connect string for the raftclient to connect to .",1610573345,remember the of the last update to metadata so we can avoid unnecessarily checking each partition for leader epoch changes on every call to,0.9587728381156921
apache_druid/10315,"handle internal kinesis sequence numbers when reporting lag <para-sep> this flag is used to indicate either end_of_shard_marker , no_end_sequence_number or expired_marker so that they can be properly compared <nl> checks whether the sequence number is recognized by kinesis client library <nl> verify that kinesis apis are not called for custom sequence numbers","handles a scenario in which the result from has expired shards . in such a case , the sequence for a shard can be ' expired ' . the lag reporter calls the aws api with this offset and runs into an exception since ' expired ' string is not a valid sequence number",1598278817,i think eventually registererers will become the endpoint for plugins in druid . ideally i hope to be able to register an object like a complex metric or a query type and also register some information about how to serde the object . <nl> i deprecated basenode and renamed it to queryablenode because i found it a bit confusing that many new nodes i was creating could not extend basenode ( the name implies something a bit more extendable ) . queryablenode implements registeringnode because i was thinking that we can create new node interfaces and new concrete node classes,0.9459797143936157
elastic_elasticsearch/71705,"fleet server needs an api to access up to date global checkpoints for <nl> indices . additionally , it requires a mode of operation when fleet can <nl> provide its current knowledge about the global checkpoints and poll for <nl> advancements . this commit introduces this api in the fleet plugin . <cm-sep> fixes <para-sep> > <nl> top-level <nl> > <nl> test clusters run with security disabled <nl> esintegtestcase randomizes durability settings . the global checkpoint only advances after a fsync , hence we must run with request durability <nl> index not found","fleet server needs an api to access up to date global checkpoints for <nl> indices . additionally , it requires a mode of operation when fleet can <nl> provide its current knowledge about the global checkpoints and poll for <nl> advancements . this commit introduces this api in the fleet plugin .",1618421888,the primary shards of follower indices during the bootstrap need to be <nl> on nodes with the remote cluster client role as those nodes reach out to <nl> the corresponding leader shards on the remote cluster to copy lucene <nl> segment files and renew the retention leases . this commit introduces a <nl> new allocation decider that ensures bootstrapping follower primaries are <nl> allocated to nodes with the remote cluster client role .,0.9832032322883606
Alluxio_alluxio/11924,fix loginmoduletest <para-sep> logout twice should be no-op in java 0 logout more than once is not allowed in java 0,jdk 0 does n't support logout twice,1596751119,"we do n't reset master state when backup masters read checkpoints . this gets us into trouble if a checkpoint is read after startup . for us to read a checkpoint after startup , the following needs to happen : . <nl> 0. master a starts <nl> 0. a reads the latest checkpoint . <nl> 0. an edit log is completed by the primary master <nl> 0. another edit log is completed by the primary master <nl> 0. before a reads the first new log , another backup master reads both logs and writes a checkpoint . <nl> 0. a",0.8410354852676392
vespa-engine_vespa/16411,added searcher to replace oritems <cm-sep> updated documentation <para-sep> recursively replaces all instances of oritems with weakanditems if the query property weakand.replace is true . otherwise a noop searcher . <nl> extracts the querytree root and the wand.hits property to send to the recursive replacement function <nl> recursively iterates over an item to replace all instances of oritems with weakanditems,"i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> if there is a preferable name for the searcher or activating property , let me know and i will change it to whatever is asked . <nl> i am not incredibly familiar with adding a searcher to the local chain so i will wait for some guidance on that aspect . <nl> thank you for any feedback",1612518632,also a common bundle containing just the interface . <nl> use version bundle by default,0.9764262437820435
netty_netty/10944,make native loading logging less confusing . <nl> motivation : . <nl> we produced a lot of noise during loading native libraries as we always included the stacktrace if we could not load by one mechanism . we should better just not include the stacktrace in the debugging logging if one mechanism fails . we will log all the stacks anyway when all of the mechanisms fail . <nl> modifications : . <nl> make logging less aggressive . <nl> result : . <nl> less confusing behaviour for the end-user,motivation : . <nl> we produced a lot of noise during loading native libraries as we always included the stacktrace if we could not load by one mechanism . we should better just not include the stacktrace in the debugging logging if one mechanism fails . we will log all the stacks anyway when all of the mechanisms fail . <nl> modifications : . <nl> make logging less aggressive . <nl> result : . <nl> less confusing behaviour for the end-user,1610717064,this pull request includes following bug fixes <nl> 0. properly handled sctp association shutdown event <nl> 0. supported sctp unordered packets <nl> 0. corrected written bytes count in sctpsendbufferpool,0.8684074878692627
runelite_runelite/12663,"add nightmare zone boss ' dad ' and ' arrg ' for the trolls slayer task <nl> add nightmare zone boss ' elvarg ' to targetnames for the green dragons slayer task . <cm-sep> ' black heather ' , ' donny the lad ' , ' speedy keith ' added to bandits task . <cm-sep> ' death wing ' added to bats and ghosts task . <cm-sep> ' tortured gorilla ' added to monkeys task . <nl> ' vulture ' added to birds task . <cm-sep> ' black guard ' added to dwarves task . <cm-sep> ' icelord ' added to ice warriors task .","some tasks given additional targetnames for possible alternative monsters to kill . <nl> nightmare zone : <nl> green dragons < ' elvarg ' <nl> trolls < ' dad ' and ' arrg ' . <nl> other : <nl> bandits < ' black heather ' , ' donny the lad ' , and ' speedy keith ' <nl> bats < ' death wing ' <nl> birds < ' vulture ' <nl> dwarves < ' black guard ' <nl> ghosts < ' death wing ' <nl> ice warriors < ' icelord ' <nl> monkeys < ' tortured gorilla '",1603014834,clue text : . <nl> ' a general who sets a 'shining ' example . ',0.7674257755279541
jenkinsci_jenkins/4965,make the groovy script source customizable,"~wip , i need to test some more use cases and would like to add some tests ... opening for early discussion.~ . <nl> * developer : make the root source paths of groovyhookscript customizable with . <nl> - ~ [ ] for dependency updates : links to external changelogs and , if possible , full diffs~",1601732272,"* , - bug - reliably close build log file when using chained build listeners .",0.9028618931770325
apache_beam/13234,fetch missing projectid from options . <nl> in bigquery load jobs built with write.to ( valueprovider ) .,"in bigquery load jobs built with write.to ( valueprovider ) . <nl> i 've also added a test case , but it may not be the most elegant",1604090733,this pr updates snowflake jdbc and adds ' application=beam ' string to url when building snowflake jdbc connection,0.9112106561660767
apache_pulsar/9840,log stacktraces of threads that failed to terminate on shutdown within timeout in executorprovider <cm-sep> cleaning up,log stacktraces of threads that failed to terminate on shutdown within timeout in executorprovider so that we have more insights on where threads are getting stuck especially for message listener threads that run user code . <nl> example of output when an executor failed to shutdown within timeout .,1615248024,"the following entry points provided by pulsar proxy does not work properly . <nl> they always return an 0 error . <nl> ~~added to the proxy configuration in order to acquire a url for proxying the http requests from configuration store servers.~~ . <nl> modified adminproxyhandler to get the list of active brokers from zookeeper and route http request to one of them in round-robin . <nl> if or is specified in proxy.conf , proxy always routes request to that url . <nl> the value of the existing can not be used , because it should be a url that",0.9538694024085999
apache_incubator-pinot/5575,"function to round a time value <para-sep> round the given time value to nearest multiple <nl> round epoch millis to nearest 0 minutes <nl> round to 0 minutes , but keep in milliseconds : fri jan 0 0 0:0:0 becomes fri jan 0 0 0:0:0","adding a basic function to round any time value . <nl> for example , to round millis to nearest 0 minutes bucket use <nl> ' transformfunction ' : ' round ( timestamp , 0 ) '",1592334467,eliminate quantile and median function side-effects on series value order,0.8618344664573669
vespa-engine_vespa/16481,"exit if reconmfiguration fails . <nl> when going from 0 to 0 zookeeper servers ( after going from 0 to 0 nodes <nl> because a node is about to be retired ) , reconfiguration will fail <nl> if the second node is removed before reconfiguration has happened . <nl> reconfiguration will never work in these cases , since 0 nodes is <nl> needed to have zookeepere quorum . just exit if this happens , new <nl> config will be used in this case and zookeeper should work fine again . <para-sep> reconfiguration failed","when going from 0 to 0 zookeeper servers ( after going from 0 to 0 nodes <nl> because a node is about to be retired ) , reconfiguration will fail <nl> if the second node is removed before reconfiguration has happened . <nl> reconfiguration will never work in these cases , since 0 nodes is <nl> needed to have zookeeper quorum . just exit if this happens , new <nl> config will be used in this case and zookeeper should work fine again .",1613039296,"the semantic changes are in sha , sha , sha and sha",0.9217366576194763
apache_pulsar/9191,fix admin-api-brokers list failed <cm-sep> move code <cm-sep> change unit test <para-sep> init clusterdata <nl> restore configuration,current address resolution does not support multiple addresses . <nl> such as .,1610449851,"when the producer callback is triggered , the exception needs to be null if there are no errors and we do n't have to wrap it in a new exception in that case .",0.9280132055282593
neo4j_neo4j/11317,do n't do tolower in hot path <cm-sep> remove hashmap lookups in hot path <cm-sep> remove unused hashmap,found some inefficiencies for spatial lookups,1521556007,this will act as a convenient utility when redirecting store copy to use pagecache directly for store files instead of using the file system .,0.9639531373977661
runelite_runelite/11938,widget-overlay : make encounter health bar moveable,"allows the new toggleable health bar widget used for various boss encounters ( nightmare , cox ) to be moveable .",1592594114,"i do not own these items , but these should be the animations for them .",0.9084194898605347
ballerina-platform_ballerina-lang/25551,add diagnostic codes for errors . <cm-sep> change int array in blangarraytype to blangexpression array . <cm-sep> update blangnodetransformer to preserve const expression . <cm-sep> update symbolresolver to resolve const expression . <cm-sep> add error messages in compiler properties . <para-sep> array size definition test .,scenario 0 . <nl> expected : size mismatch error <nl> given : no error . <nl> scenario 0 . <nl> expected : error on invalid size reference type <nl> given : no error . <nl> scenario 0 . <nl> expected : error on const array size reference data type <nl> given : no error . <nl> scenario 0 . <nl> expected : error on undefined size reference <nl> given : no error . <nl> these spec deviations are fixed in this pull request .,1598989723,"e.g. , . <nl> additionally it will also <nl> - allow passing args for the rest param as both individual args and a vararg . <nl> - remove adding parameter defaults when there 's a rest param . <nl> the following will result in a compilation error now . <nl> if the vararg list provided as the first member a type compatible with the defaultable parameter , that member would be used as the arg for the relevant defaultable parameter . <nl> - this pr also fixes two bugs .",0.9601972699165344
vespa-engine_vespa/15242,rewrite configconvergencechecker to use apache instead of jersey client . <nl> the effective exception handling for some confiserver apis may have changed as webapplicationexception leaked out with old jersey-based implementation . <nl> connections will now be reused for a short duration . <cm-sep> do n't use private inner class in return type of public methods <cm-sep> deprecate vespaclientbuilderfactory + vespajerseyjaxrsclientfactory <cm-sep> do n't use shared fork join pool <cm-sep> do n't reuse connections . <nl> disable connection reuse . increase max simultaneous connections . <nl> remove default request config . <cm-sep> stabilize unit test . <nl> use linkedhashmap for consistent iteration ordering . <nl> use jsontesthelper for proper semantic json comparison .,same as previous pr except last commit,1604934733,"refreshing routing policies and performing the necessary dns updates are <nl> somewhat time sensitive , especially in manually deployed environments , hence it <nl> makes sense that this should be done as early as possible . <nl> because name service requests are now executed asynchronously by <nl> default , we can refresh policies during deployment ( de ) activation without <nl> worrying about dns service failures or rate limits . <nl> benefits of this change : . <nl> - reduces worst-case dns propagation time by 0 minutes . <nl> - we no longer need to update all routing policies in",0.978499174118042
neo4j_neo4j/11402,"backport changes that remove dependency on sleep for timing test <cm-sep> circumvent race in transactionhandleregistry . <nl> there was a race between the transaction being rollbacked and the rollback http request . in terminate method , the async ' handle.terminate ( ) ' ' could run before the acquire , thus removing the handler from the map before it could be retrieved again . this was very evident on windows , most likely due to a different scheduling . <para-sep> we could not acquire the transaction . let the other request clean up .","there was a race between the transaction being rollbacked and the rollback http request . in the method , the async could run before the , thus removing the handler from the map before it could be retrieved again . this was very evident on windows 0 , most likely due to a different scheduling strategy .",1522166420,"always use latest available lucene index commit for snapshot operations <nl> to avoid cases when older snapshot is reused in backup/store copying <nl> that can cause index corruption since only transaction from the backup start will be replayed <nl> on top of commit , while older snapshot can represent index state way before that point . <nl> example scenario : <nl> 0. store copy starts on master . <nl> 0. snapshot ( 0 ) of indexes taken . <nl> 0. some transaction closed on master . <nl> 0. another store copy starts from master <nl> 0. snapshot ( 0 )",0.9427763223648071
apache_shardingsphere/10163,throw exception rather than write response in many places <cm-sep> remove unused exception handling <para-sep> postgresql message severity level . <nl> todo implement postgresqlserverinfo like mysqlserverinfo <nl> invalid authorization specification exception . <nl> postgresql authentication exception . <nl> postgresql protocol violation exception . <nl> todo consider what severity to use,throw exception rather than write response in many places .,1619188228,changes proposed in this pull request : <nl> - add all related apis,0.9606655240058899
vespa-engine_vespa/16046,"revert ' use reference counting to avoid relying on gc to drop threads . ' <nl> this reverts commit sha . <cm-sep> revert ' use a single reloader per tls config file , and not one per instance . ' <nl> this reverts commit sha . <cm-sep> use a single , shared tlscontext instance . <nl> the configuration is based on environment variables , which are effectively fixed through the life of the jvm instance . <nl> this simplifaction removes the need for complex cleanup logic based on manual reference counting and weak references . <para-sep> wrapped methods from tlscontext",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610628882,"rewrite and simplify to use slime and a regular handler instead of jersey , <nl> so it 's not necessary to manually update handler when config changes <nl> ( which had not been done in years )",0.958304762840271
confluentinc_ksql/6548,"removes the streams cache for window stores since this hurts pull query performance <cm-sep> checkpoint that kina works , added session too <cm-sep> changes to new methodology <cm-sep> removes old code and gets style validated <cm-sep> adds more tests <para-sep> returns the first non-empty iterator <nl> unwrap state stores until we get to the last sessionstore , which is past the caching layer . <nl> a rocksdbsessionstore wraps a segmentedbytesstore , which is n't a sessionstore , so we just store there . <nl> now we have the innermost layer of the store . <nl> returns the first non-empty iterator <nl> unwrap state stores until we get to the last windowstore , which is past the caching layer . <nl> a rocksdbwindowstore wraps a segmentedbytesstore , which is n't a sessionstore , so we just store there . <nl> now we have the innermost layer of the store .","after lots of investigation , it was clear that this was due to the use of the streams cache . we experimented with disabling the cache , and performance is good for pull queries . the issue is that if we did this , then other areas such as persistent queries suffer in their performance . <nl> this pr aims to disable the use of the streams cache for only windowed pull queries . there was a lot of discussion over whether a public api should be exposed in streams to bypass the cache during a state store lookup .",1604015919,"adds basic auth support to the new api server . enable the feature with the following server properties : . <nl> one difference between the new and existing basic auth implementations is a reinterpretation of the meaning of as a jaas role for the config : the existing implementation is jetty-based and therefore means to use the config in the associated web.xml file , and this was the default if the config was unspecified . as far as i can tell , ksql has never had a file so this default amounted to not allowing access for any roles .",0.9847331047058105
apache_kafka/9960,remove and methods from generated protocol classes . <nl> update few classes that were still using the removed methods ( including <nl> tests that are no longer required ) .,update few classes that were still using the removed methods ( including <nl> tests that are no longer required ) .,1611546262,"after a number of last minute bugs were found stemming from the incremental closing of lost tasks in streamsrebalancelistener # onpartitionslost , a safer approach to this edge case seems warranted . we initially wanted to be as ' future-proof ' as possible , and avoid baking further protocol assumptions into the code that may be broken as the protocol evolves . this meant that rather than simply closing all active tasks and clearing all associated state in we would loop through the lostpartitions/lost tasks and remove them one by one from the various data structures/assignments , then verify that",0.9356349110603333
ballerina-platform_ballerina-lang/24743,fix : ballerina-lang : array : createbalo task issue <cm-sep> remove unwanted comments,> this fix is only tested within the compile time . it needs to be tested and verified in the runtime as well . <nl> > tested with the command on ubuntu version . <nl> fixes # .,1594793622,"return type change <nl> current batchupdate function returns int [ ] |error . but even for error scenarios , we need to return the int [ ] . <nl> - if all commands in the batch have successfully executed , we need to return the int [ ] only which contains the updated row counts . <nl> - if one or more commands in the batch has failed , we need to return the int [ ] along with the error . in this case , the values in int arrays are used to find which commands have executed successfully",0.9462811350822449
Alluxio_alluxio/11082,remove trailing spaces from underfs_web_titles <cm-sep> do n't use rawvalue for configreports . <nl> this is required or else the config check will compare non-resolved <nl> configuration properties $ { alluxio.home.dir } with resolved ones <nl> ( /opt/alluxio ),"this pr aims to fix the configuration check in the alluxio ui when running locally and all values are not configured except for set to . <nl> by default this should be passing , or else the user may think they have configured something incorrectly . <nl> there are two main changes . <nl> 0. fix a failing check from a pk with that gets it 's trailing spaces trimmed when the pk is sent over the wire . i just removed the extra trailing spaces as the usage did n't seem to require it . <nl> 0. use the",1583130736,"this is to deflake leader command integration test . <nl> the reason for failure is that error output contains some netty error trace that we ca n't control . when netty receives a command for a stream that is closed or being closed , such traces are written to sys : :err . in this case , it 's the latter , that some stream is about to be closed when leader command hits the server . this flake is introduced by grpc long polling . reason for that is now that servers keep an open stream , closing a",0.8216712474822998
elastic_elasticsearch/71030,allow closing a write index of a data stream . <nl> prior to this commit when attempting to close a data stream a validation error is returned indicating that it is forbidden to close a write index of a data stream . the idea behind that is to ensure that a data stream always can accept writes . for the same reason deleting a write index is not allowed ( the write index can only be deleted when deleting the entire data stream ) . <nl> however closing an index is n't as destructive as deleting an index ( an open index request makes the write index available again ) and there are other cases where a data stream ca n't accept writes . for example when primary shards of the write index are not available . so the original reasoning for not allowing to close a write index is n't that strong . <nl> on top of this is that this also avoids certain administrative operations from being performed . for example restoring a snapshot containing data streams that already exist in the cluster ( in place restore ) . <para-sep> close all indices : <nl> a rollover after taking snapshot . the new backing index should be a standalone index after restoring and not part of the data stream : <nl> close all backing indices of ds data stream : <nl> the backing index created as part of rollover should still exist ( but just not part of the data stream ) <nl> an additional rollover should create a new backing index ( 3th generation ) and leave .ds-ds- ... 0 index as is :,prior to this commit when attempting to close a data stream a validation error is returned indicating that it is forbidden to close a write index of a data stream . the idea behind that is to ensure that a data stream always can accept writes . for the same reason deleting a write index is not allowed ( the write index can only be deleted when deleting the entire data stream ) . <nl> however closing an index is n't as destructive as deleting an index ( an open index request makes the write index available again ) and,1617093184,"this adds validation to make sure alias operations ( add , remove , remove index ) <nl> do n't target data streams or the backing indices .",0.9504532814025879
elastic_elasticsearch/71841,"rename on_script_error options to fail or continue . <nl> as we started thinking about applying on_script_error to runtime fields , to handle script errors at search time , we would like to use the same parameter that was recently introduced for indexed fields . we decided that continue or fail gives a better indication of the behaviour compared to the current ignore or reject which is too specific to indexing documents . <nl> this commit applies such rename .","as we started thinking about applying on_script_error to runtime fields , to handle script errors at search time , we would like to use the same parameter that was recently introduced for indexed fields . we decided that continue or fail gives a better indication of the behaviour compared to the current ignore or reject which is too specific to indexing documents . <nl> this commit applies such rename .",1618838838,this api incorrectly had set to false in the default options for the <nl> request . this changes it from to and enhances a test to exercise the functionality .,0.9078863263130188
apache_kafka/10063,": add support for splitting appending records <para-sep> in this case , we are able to save the original record objects , which saves the need to read them back from disk . this is a nice optimization for the leader which is typically doing more work than all of the followers . the raft implementation is free to batch together the records from multiple append calls provided that batch boundaries are respected . the log and eventually committed . while the order of the records is preserve , they can be appended to the log using one or more batches . each record may be committed independently . if a record is committed , then all records scheduled for append during this epoch and prior to this record are also committed . the state machine is expected to discard all uncommitted entries after observing an epoch change . <nl> append a list of records to the log . the write will be scheduled for some time in the future . there is no guarantee that appended records will be written to <nl> append a list of records into as many batches as necessary . the order of the elements in the records argument will match the order in the batches . this method will use as many batches as necessary to serialize all of the records . since this method can split the records into multiple batches it is possible that some of the records will get committed while other will not when the leader fails . <nl> append a list of records into an atomic batch . we guarantee all records are included in the same underlying record batch so that either all of the records become committed or none of them do . <nl> buffer that was allocated by the memorypool ( pool ) . this may not be the buffer used in the memoryrecords ( data ) object . <nl> once the field compressiontype must be set before calculating the batch header size <nl> check whether the batch has enough room for all the record values . otherwise it returns the expected number of bytes needed for a batch to contain these records . <nl> append entries until we have 0 batches to drain ( 0 completed , 0 building ) <nl> ceilingdiv ( records.size ( ) , recordsperbatch )","0. type . add support for appending records into one or more batches . <nl> 0. type . rename to . <nl> 0. type . add a new method which appends records to the log using as many batches as necessary . <nl> 0. increase the batch size from 1mb to 8mb . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale",1612490359,"this pr adds a new consumebenchspec field - ' consumercount ' . ' consumercount ' will be spawned over ' consumercount ' threads in the consumebenchworker . <nl> since ' consumercount ' will be 0 by default , these changes are backwards compatible . <nl> it 's now questionable how existing fields such as ' targetmessagespersec ' , ' maxmessages ' , ' consumergroup ' and ' activetopics ' should work . <nl> with ' activetopics ' , we need to decide whether they should be split over the consumers or not . <nl> i see 0 cases which i",0.9777376055717468
jenkinsci_jenkins/4829,"add api to simplebuildstep . <nl> two new methods are added : <nl> - requiresworkspace ( ) , defaulted to returning true <nl> - an overload of perform ( ) that only takes a run , envvars and listener <nl> - the ' full-fat ' perform ( ) delegates to this one when requiresworkspace ( ) returns false . <nl> this enables steps to declare they do not need a workspace context . <nl> buildstepcompatibilitylayer honors this and wo n't try to get a workspace when one is not required . <cm-sep> add api to simplebuildwrapper . <nl> these changes mirror those in simplebuildstep . <nl> disposer has the same changes applied except that the choice of requiring a workspace is made as part of the constructor , based on a wrapper instance . <nl> alternatively , it could choose this on its own , the way the step and wrapper do . <para-sep> this method must be overridden when this step requires a workspace context . <nl> if we get here , this must be an implementer of the previous api , in which case we call that , discarding <nl> run this step , without a workspace context . this method must be overridden when this step does not require a workspace context , and will not be called when such a context is required . <nl> if this step requires a workspace , this is the wrong method to call . <nl> otherwise , this method must have an implementation . <nl> determines whether or not this step requires a workspace context ( working directory and launcher ) . <nl> determines whether or not this wrapper requires a workspace context ( working directory and launcher ) . <nl> this method must be overridden when this wrapper requires a workspace context . <nl> if this does not require a workspace , defer to the version that does not take a workspace and launcher . <nl> called when a segment of a build is started that is to be enhanced with this wrapper . this method must be overridden when this wrapper does not require a workspace context , and will not be called when such a context is required . <nl> if this wrapper requires a workspace , this is the wrong method to call . <nl> otherwise , this method must have an implementation . <nl> creates","instead of keeping the existing api , allowing some parameters to be null , this adds new methods to handle that case . <nl> to avoid needing multiple new methods , this removes the separate choice for requiring a workspace and/or launcher . <nl> * : a or can now choose not to require a workspace context ( working directory and launcher ) . <nl> reference implementation :",1593953687,"for now it retains the traditional behavior by default , especially as tool metadata like hudson.tasks.maven.maveninstaller.json bears no signature . ( the equivalent does , and the for update centers does too , so this looks like an oversight ; would i think currently break tool download from browsers without support . )",0.9722743034362793
apache_incubator-pinot/5368,timecolumnname in mutablesegmentimpl <para-sep> todo : clean up this constructor . most of these things can be extracted from tableconfig .,"this time column name is used to decide which column should be used to record mintime and maxtime for realtimesegment . <nl> the current way was incorrect . it would 've broken when we started using multiple time columns - the min/max comparison would have incorrectly been done for every time column , not just the primary .",1589246239,- detection stage wrapper injects metric urn to stage specs <nl> - rename info map to detection registry singleton,0.8667361736297607
elastic_elasticsearch/71515,"this pr adds a new api endpoint to retrieve service accounts . depends on the <nl> request parameters , it returns either all accounts , accounts belong to a <nl> namespace , a specific account , or an empty map if nothing is found .","this pr adds a new api endpoint to retrieve service accounts . depends on the <nl> request parameters , it returns either all accounts , accounts belong to a <nl> namespace , a specific account , or an empty map if nothing is found .",1617929056,"in addition to creating and re-assigning model aliases , users should be able to delete existing and unused model aliases .",0.990278959274292
ballerina-platform_ballerina-lang/24478,"update cache internals to java concurrenthashmap <cm-sep> fix http-cache invalidating non existing key <cm-sep> update cache key string concatenation with string template <cm-sep> update remove api <cm-sep> update internal cache error functions <para-sep> resource function ontrigger ( map entries , linkedlist list , abstractevictionpolicy evictionpolicy ) { <nl> if the current cache is full ( i.e . size = capacity ) , evict cache . <nl> calculate the of the cache entry based on the property and property . <nl> check whether the cache entry is already expired . even though the cache cleaning task is configured and runs in predefined intervals , sometimes the cache entry might not have been removed at this point even though it is expired . so this check guarantees that the expired cache entries will not be returned . <nl> foreach node node in entries { <nl> ballerina function to cache with java.util.concurrent.concurrenthashmap .","this improves the tps dropped due to enabling of http caching . <nl> also , removes the error count introduced in performance tests due to usage in ballerina cache , in order to solve the concurrency issues . <nl> please refer to the below issue for more details on the approach in detail .",1593397927,extract from the spec . <nl> fixes # .,0.9433783888816833
hazelcast_hazelcast/18172,use cached deserialized values in sql when possible <para-sep> an index may change the behavior due to mapcontainer.isusecacheddeserializedvaluesenabled . <nl> no-op <nl> no-op <nl> if index exists then cached value is already set - > let 's use it,"this pr ensures that the sql engine attempts to re-use already deserialized values stored in an index , similarly to predicate api . this substantially improves map scan operations performance when there is at least one index on an . <nl> in addition to this , the pr ensures that we move both serialized and deserialized representations to the sql engine to avoid serialization of entries that already have a representation . this improves the performance of index lookups by ~0-0 % .",1612851906,async methods in follow the -suffix naming convention ; -prefixed methods will be removed once is also removed .,0.9760259389877319
apache_pulsar/9226,"fix unit test <para-sep> zk update takes some time <nl> the first time , use topic-leve policies , 0 second delay + 0 second interval <nl> remove topic-level policies , namespace-level should be used , interval becomes 0 seconds zk update time + 0 second interval time <nl> 0 remove namespace-level policies , broker-level should be used , interval becomes 0 seconds <nl> broker-level interval is 0 seconds , so 0 seconds will not take a snapshot","topicduplicationtest.testtopicpolicytakesnapshot : the interval of this unit test has been increased <nl> . if the interval is too short , it can not be completed within the specified interval when the broker is busy . after the modification , call the test 0 times without any exception . <nl> consumedledgerstrimtest : did not clean up .",1610870237,"current function metrics system is convoluted , incorrect , confusing . refactor metrics to use prometheus . <nl> this is the beginning of a series of prs . in the future , i plan . <nl> 0. deprecate prometheusmetrics server and function instance will expose metrics <nl> 0. deprecate metricsdata and metrics grpc calls in favor of prometheus format .",0.9223088622093201
ballerina-platform_ballerina-lang/24091,add typed raw template support to sql <para-sep> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation . <nl> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation . <nl> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation . <nl> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation . <nl> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation . <nl> this test class verifies the behaviour of the parameterizedquery passed into the testquery operation .,execute a batch of command .,1592117963,- fix calling init multiple times when services are used <nl> - refactor suite initializing logic and update bal files <nl> - update tests and fix broken tests .,0.9366032481193542
ballerina-platform_ballerina-lang/26650,introduce a seperate compileandcachebalo method in bcompileutil . <nl> this method is added for tests that require to build an cache balo <nl> from the package that is needed for subsequest test cases .,this also introduces a separate compileandcachebalo method in bcompileutil . this method is added for tests that require to build an cache balo from the package that is needed for subsequent test cases .,1603870511,"there was feature to sanitize outbound request uri . however , doing so is wrong . we only should sanitize inbound request request uri . this pr fixes this issue . <nl> moreover , in addition to that , i have refactored the code a bit to make it more readable .",0.9451385736465454
elastic_elasticsearch/70626,rollup action uses generateuniqueindexnamestep <cm-sep> use correct step name,this refactors the to use the which <nl> performs a few extra validations and retries if the generated name already exists .,1616411171,"runtime fields usage is currently reported as part of the xpack feature usage api . now that runtime fields are part of server , their corresponding stats can be moved to be part of the ordinary mapping stats exposed by the cluster stats api . <nl> this is the last bit of functionality left in the xpack runtime-fields plugin , hence we can remove the plugin as part of this change too . <nl> this pr removes the runtime-fields feature from the xpack/usage and xpack/info output , in favour of reporting runtime_field_types stats as part of the output of the",0.9425709247589111
elastic_elasticsearch/70524,"when we disable access to system indices , plugins will still need <nl> a way to erase their state . the obvious and most pressing use <nl> case for this is in tests , which need to be able to clean up the <nl> state of a cluster in between groups of tests . <nl> * use a handledtransportaction for reset action . <nl> my initial cut used a transportmasternodeaction , which requires code <nl> that carefully manipulates cluster state . at least for the first cut and <nl> testing , it seems like it will be much easier to use a client within a <nl> handledtransportaction , which effectively makes the <nl> transportresetfeaturestateaction a class that dispatches other transport <nl> actions to do the real work . <nl> * clean up code by using a groupedactionlistener . <nl> * ml feature state cleaner . <nl> * implement transform feature state reset . <nl> * change _features/reset path to _features/_reset . <nl> out of an abundance of caution , i think the ' reset ' part of this path <nl> should have a leading underscore , so that if there 's ever a reason to <nl> implement ' get _features/ ' we wo n't have to worry about <nl> distinguishing ' reset ' from a feature name . <para-sep> reset the state of elasticsearch features , deleting system indices and performing other cleanup operations . see rest features api on elastic.co <nl> asynchronously reset the state of elasticsearch features , deleting system indices and performing other cleanup operations . see get snapshottable features api on elastic.co <nl> check that the reset method cleans up a feature * / <nl> put a document in a system index <nl> put a document in a second system index <nl> put a document in associated index <nl> put a document in a normal index <nl> call the reset api <nl> verify that both indices are gone <nl> a test plugin with patterns for system indices and associated indices . <nl> a second test plugin with a patterns for system indices . <nl> action for resetting feature states , mostly meaning system indices * / <nl> request for resetting feature state * / <nl> response to a feature state reset request . * / <nl> create a response showing which features have had state reset and success or failure status . <nl> an object with","when we disable access to system indices , plugins will still need <nl> a way to erase their state . the obvious and most pressing use <nl> case for this is in tests , which need to be able to clean up the <nl> state of a cluster in between groups of tests . <nl> * use a handledtransportaction for reset action . <nl> my initial cut used a transportmasternodeaction , which requires code <nl> that carefully manipulates cluster state . at least for the first cut and <nl> testing , it seems like it will be much easier to",1616014001,"introduce eql search status api , <nl> that reports the status of eql stored or async search . <nl> get _eql/search/status/ . <nl> the api is restricted to the monitoring_user role . <nl> for a running eql search , a response has the following format : . <nl> for a completed eql search , a response has the following format : .",0.9889385104179382
apache_pulsar/9630,[ pulsar client ] enable spotbugs in module pulsar-client .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1613740910,"# # # motivation . <nl> when writing a connector reading from a list of sources , it is hard for the connector implementation to decide how <nl> to distribute the list of sources across the function instances . because there is no way to tell how many function <nl> instances is running . <nl> - change instance id from string to integer ( since the implementation is already assuming instance id is an integer ) <nl> - add getnuminstances in the context <nl> - expose both interfaces in source and sink connector context .",0.9155656099319458
grpc_grpc-java/7733,"bump versions for lots of dependencies . <nl> i did n't touch protobuf and netty ; we upgrade those individually . below <nl> are issues i encountered that caused me to not upgrade ( further ) . <nl> guava version-android fails to build with android without enabling <nl> desugaring . <nl> robolectric version breaks androidchannelbuildertest . <nl> opencensus version+ is incompatible with grpc . <nl> truth now defines the asm dependency as ' compile ' although it is still <nl> optional . but asm appears to have accidentally included incorrect gradle <nl> module metadata in their release ( i see they 've disabled the metadata on <nl> master ) which make gradle think it requires java 0. we could asm <nl> everywhere , but that 's is annoying . it seems likely this will resolve <nl> itself . <nl> mockito can be upgraded to version , but it deprecates initmocks , which <nl> causes more code churn than i wanted in this commit . i still <nl> synchronized the example versions on version , though , as it was already <nl> being used in some examples and the examples do n't use initmocks .",i did n't touch protobuf and netty ; we upgrade those individually . below <nl> are issues i encountered that caused me to not upgrade ( further ) . <nl> guava version-android fails to build with android without enabling <nl> desugaring . <nl> robolectric version breaks androidchannelbuildertest . <nl> opencensus version+ is incompatible with grpc . <nl> truth now defines the asm dependency as ' compile ' although it is still <nl> optional . but asm appears to have accidentally included incorrect gradle <nl> module metadata in their release ( i see they 've disabled the metadata on <nl> master,1608147669,these are subtley differently named but distinct fields .,1.0
apache_beam/13410,"replace charset.defaultcharset ( ) with standardcharsets.utf_8 <para-sep> string outputstr = new string ( baos.tobytearray ( ) , standardcharsets.utf_8 ) ;",. <nl> replace charset.defaultcharset ( ) with standardcharsets.utf_8 so that reliance on encoding set in is not used . <nl> the defaultcharset ( ) ) method relies on underlying os system default . <nl> files that are not test files that are being changed : <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> *,1606181014,"thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.8832519054412842
Alluxio_alluxio/11801,use long sizes and positions <cm-sep> use positive random offsets,using longs supports larger file sizes .,1595380007,change property key <nl> master_connection_timeout_ms <nl> master_journal_flush_batch_time_ms . <nl> to support time unit transformation,0.8101686835289001
elastic_elasticsearch/72553,service account - disallow oauth2 creation . <nl> service accounts must be authenticate with their service tokens . we <nl> intentionally do not support other authentication schemes ( other than <nl> api keys ) . hence we should not allow service account to create oauth2 <nl> tokens . <nl> note this is not an issue now because the only elastic/fleet-server <nl> service account does not have permission to create oauth2 token anyway .,service accounts must be authenticate with their service tokens . we <nl> intentionally do not support other authentication schemes ( other than <nl> api keys ) . hence we should not allow service account to create oauth2 <nl> tokens . <nl> note this is not an issue now because the only elastic/fleet-server <nl> service account does not have permission to create oauth2 token anyway .,1619786198,"under specific circumstances we would call onresponse twice , which <nl> led to unexpected behavior .",0.9413779377937317
apache_shardingsphere/9808,add postgresqltablemetadataloader <cm-sep> add test case for postgresqltablemetadataloader <cm-sep> merge from apache/master <para-sep> table meta data loader for postgresql . <nl> todo user defined collation which deterministic is false,changes proposed in this pull request : <nl> - add postgresqltablemetadataloader,1616602896,changes proposed in this pull request : <nl> - add test cases for datanode,0.9835623502731323
elastic_elasticsearch/71884,disable geoip downloader in packaging tests,this change disables geoip downloader in install command of packaging tests to catch all usage .,1618869227,"having fail when the configured memory limit is too low can be frustrating . <nl> we should instead warn the user that their job might not run properly if their configured limit is too low . <nl> it might be that our estimate is too high , and their configured limit works just fine .",0.9080635905265808
neo4j_neo4j/11375,"allow index clean jobs that are added after the start to be executed . <nl> so far spatial and temporal indexes created in lazy fashion and <nl> their clean jobs will gon na be added after all other indexes clean jobs <nl> and even after group cleaner component start . <nl> current pr allow that kind of jobs to be executed to unblock index shutdown . <nl> also makes a run of a group of jobs more resilient to failure . <para-sep> tree is only clean if <nl> expected <nl> nothing to close <nl> can be configured to create archive with content of index directories for future analysis . <nl> deletes the index directory and everything in it , as last part of dropping an index .",clean up all of the left-overs from previous index populations when new index population starts . <nl> also makes a run of a group of jobs more resilient to failure .,1521913632,o serialize stack trace for internal errors . <nl> o reorganised error codes . <nl> o renamed neo4jerror subclasses to match statuscode names . <nl> o renamed neo4jerror.code to statuscode . <nl> o stop neo4jerror extending java.lang.exception . <nl> o explicit functional test for response format for cypher syntax errors .,0.9807937145233154
elastic_elasticsearch/71917,"rename get service tokens to get service credentials <cm-sep> rename serviceaccountstokenstore to serviceaccounttokenstore <para-sep> same wrong token <nl> do not cache failed attempt <nl> in case of failure , evict the cache entry and notify all listeners <nl> invalidate cache entries with keys matching to the specified qualified token names . <nl> wildcard case of invalidating all tokens for a service account , e.g . ' elastic/fleet-server/ ' <nl> package private for testing <nl> todo : optimize store order based on auth result ? <nl> this is done on the current thread instead of using a dedicated thread pool like api key does because it is not expected to have a large number of service tokens . <nl> package private for testing <nl> todo : validate against known service accounts ? <nl> todo : wildcard support ? <nl> prefix is service_account_token_doc_type + ' - ' + accountid.asprincipal ( ) + ' / ' <nl> the interface should be implemented by credential stores of different backends . <nl> verify the given token for encapsulated service account and credential <nl> get all tokens belong to the given service account id <nl> noinspection unchecked <nl> 1st auth with the right token1 <nl> 2nd auth with the right token1 should use cache <nl> 3rd auth with the wrong token1 that has the same qualified name should use cache <nl> 4th auth with the wrong token2 <nl> 5th auth with the wrong token2 again does not use cache <nl> 6th auth with the right token2 <nl> invalidate token1 in the cache <nl> 7th auth with the right token1 <nl> invalidate all items in the cache <nl> authenticate should still work <nl> invalidate a single entry <nl> invalidate all entries <nl> auth everything again <nl> token name shares the hashing algorithm name for convenience <nl> a blank line should not trigger update <nl> add a new entry <nl> remove the new entry <nl> write a mal-formatted line <nl> writing in utf_16 should cause a parsing error as we try to read the file in utf_8 <nl> restore to original file again <nl> duplicate entry <nl> success <nl> token mismatch <nl> token document not found <nl> created <nl> failure <nl> non-exist token name <nl> invalid service account <nl> index not exists <nl> index exists but not available",this pr renames classes relevant to the following names for accuracy and consistency : <nl> * rename getserviceaccounttokens to getserviceaccountcredentials <nl> * rename serviceaccountstokenstore to serviceaccounttokenstore,1618918059,this change renames reader context to search context in the rest layer .,0.9807350635528564
apache_pulsar/9401,"support disable shared subscription type . <para-sep> all subtype this namespace support <nl> remove shared subtype for this namespace and sub with shared subscription type fail <nl> add shared subtype for this namespace and sub with shared subscription type success <nl> remove failover subtype for this namespace and sub with failover subscription type fail <nl> clear all namespace subtype enabled , add failover to broker.conf and sub with shared will fail <nl> add shared to broker.conf and sub with shared will success <nl> use broker.conf <nl> set enable failover sub type <nl> add shared type <nl> test namespace and topic policy <nl> sets the subscriptiontypesenabled policy for a given namespace , overriding broker settings . request example : { ' subscriptiontypesenabled ' : { ' shared ' , ' failover ' } } <nl> sets the subscriptiontypesenabled policy for a given namespace , overriding broker settings . request example : { ' subscriptiontypesenabled ' : { ' shared ' , ' failover ' } } <nl> get the subscriptiontypesenabled policy for a given namespace , overriding broker settings . <nl> get the subscriptiontypesenabled policy for a given namespace , overriding broker settings . <nl> set is enable sub types . <nl> set is enable sub types asynchronously . <nl> get is enable sub types . <nl> get is enable sub types asynchronously .","in broker/namespace/topic <nl> # # # verifying this change <nl> and the test <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : (",1612185437,subscribers will be able to access subscribe admin-api .,0.9837455749511719
apache_incubator-pinot/5724,enable/disable query quotas per broker <para-sep> return true if query quota is disabled in the current broker . <nl> process query quota state change when instance config gets changed <nl> it 's a brand new broker . skip checking instance config . <nl> update the instance config given the broker instance id,"this is helpful to test out the capacity of a given broker without affecting other brokers in production . higher load can be routed to this dedicated host to find out the capacity , which can give us better insights on the current provisioning of the cluster . linkedin currently has one service that has been testing in this way . <nl> the query quotas are all enabled/disabled together within a broker . once the broker gets restarted , query quotas would all be re-enabled again whatever the previous states were before . <nl> broker log : . <nl> make",1595355988,this pr adds limited support for ' is null ' and ' is not null ' filter predicates . currently this only works for leaf filter predicates .,0.9773088097572327
vespa-engine_vespa/15338,"add instance , plan and planname to api response",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605271519,this makes it easier to create additional instances for testing <nl> other services against it .,0.8883415460586548
Graylog2_graylog2-server/9035,implementing compression for elasticsearch 0 . <nl> this change is implementing request/response compression for <nl> elasticsearch 0 . <cm-sep> adjusting constructor . <cm-sep> bump es client library version to version .,"this change is implementing request/response compression for elasticsearch 0. it also requires an update of the client library to version , as it now includes transparent decompression for both the high- and the low-level-client . <nl> has been set to in the config file . basic indexing/search/cluster management functionality has been tested after server restart .",1600953952,"we can not run a query with an empty stream list , because it will <nl> be executed against all known indices in elastic search <nl> and never yield a result . <nl> thus , like we already do in moresearch : if no streams are provided , <nl> use all streams instead .",0.8885474801063538
apache_pulsar/9383,fix issue 0 <para-sep> ack receipt default batch receive policy . <nl> only receive timeout limitation . <nl> only number of messages in a single batch receive limitation . <nl> number of messages and timeout limitation <nl> size of messages and timeout limitation <nl> default batch receive policy . <nl> only receive timeout limitation . <nl> only number of messages in a single batch receive limitation . <nl> number of messages and timeout limitation <nl> size of messages and timeout limitation <nl> number of message limitation exceed receiverqueue size <nl> number of message limitation exceed receiverqueue size and timeout limitation <nl> number of message limitation is negative and timeout limitation <nl> size of message limitation is negative and timeout limitation <nl> number of message limitation and size of message limitation are both negative and timeout limitation <nl> number of message limitation exceed receiverqueue size <nl> number of message limitation exceed receiverqueue size and timeout limitation <nl> number of message limitation is negative and timeout limitation <nl> size of message limitation is negative and timeout limitation <nl> number of message limitation and size of message limitation are both negative and timeout limitation <nl> only timeout present <nl> only timeout present,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1612106503,"currently , pulsar only supports produce transaction messages in no batch mode . <nl> add transaction id in the batch message container , if the newly added message has a different transaction id with the container , it will be added in the next batch . <nl> add a new unit test . <nl> org.apache.pulsar.client.impl.transactionendtoendtest # batchproducecommittest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no",0.8952928185462952
ballerina-platform_ballerina-lang/23490,"add a new util class for syntax node list instances <cm-sep> add a method to generate the json from the stnode <cm-sep> update test apis to find the source file from the java.util.path <cm-sep> add methods to create empty stnodelist instances <cm-sep> refactor the implementation with nodelistutil <cm-sep> move syntaxutils to internal.syntax package <cm-sep> update nodefactory to create empty nodelist and minutiaelist instances <cm-sep> update minutiaelist with nodelistutils <cm-sep> add methods to update nodelist instances <cm-sep> add cases to test nodelist api methods <para-sep> contains utility methods works with both internal and external node lists instances . <nl> contains utility methods works with both internal and external syntax trees . <nl> todo find a syntaxkind based approach to check <nl> todo find a syntaxkind based approach to check <nl> todo find a syntaxkind based approach to check <nl> todo find a syntaxkind based approach to check <nl> positional access methods <nl> modification methods <nl> query methods <nl> here we are using the childbuckets arrays instead of the childinbucket ( ) method . if the particular child is not loaded , then childbuckets will be null . that means the given child is not equal to what is stored in the childbuckets array . <nl> positional access methods <nl> modification methods <nl> separator related methods <nl> compares the actualtree with the given json . <nl> read the assertion file <nl> validate the tree against the assertion file <nl> if you invoke the get ( 0 ) again , you should get the same instance external tree nodes are created on-demand and only once . <nl> test getting the first member <nl> test getting a middle member <nl> test getting the last member <nl> test adding a node to the 0th index of the list <nl> test adding a node to an index in the middle of the list <nl> test adding a node to the last index of the list <nl> test adding to a empty list <nl> create new typename with the same formatting as the original one <nl> create a variable name token","recently , i 've come across use cases where i need to modify an existing nodelist instance . look at the following code snippet . often we need to add/delete/replace nodes in the list .",1590433593,> - remove onclose <nl> > - rename onaccept - > onconnect .,0.9811784625053406
Alluxio_alluxio/10953,"move bytes ( ) and pages ( ) to metastore <cm-sep> futher refactor <para-sep> resets the evictor . <nl> the default implementation of a metadata store for pages stored in cache . this implementation is not thread safe and requires synchronizations on external callers . the number of logical bytes used . * / <nl> the number of pages stored . * / <nl> restores a page store a the configured location , updating meta store and evictor .","this pr has two major changes : <nl> - instead of querying pagestore for size to make eviction decisions , querying metastore <nl> - update & simplify restoring logic accordingly . now only one pass is needed",1582160741,"this pr addresses the following : <nl> - listrecursive is now an option to list . all variants of list now return a status object instead of just a name . this has the additional information identifying the name as a file or a directory , used to remove the extra rpc on a follow up call . <nl> - openatposition is merged into open options . swift and oss implementations are added to open stream at given position instead of using skip . localufs and hdfs get implementations using skip internally . <nl> - createdirect is removed from the",0.979929506778717
apache_pulsar/8959,"motivation . <nl> for keeping the compatibility of the setup metadata command . <nl> we should avoid delete the existing arguments . if we need to <nl> change it , it 's better to keep the old arguments and mark it <nl> deprecate and hide it . <para-sep> hide and marked as deprecated this flag because we use the new name ' -- existing-bk-metadata-service-uri ' to pass the service url . for compatibility of the command , we should keep both to avoid the exceptions . <nl> expected not exist","motivation . <nl> for keeping the compatibility of the setup metadata command , <nl> we should avoid deleting the existing arguments . if we need to <nl> change it , it 's better to keep the old arguments and mark it <nl> deprecates and hide them .",1608013042,add a way to validate new schema before try to check compatibility and add stacktrace printing on parsing schema error .,0.9033574461936951
apache_druid/10219,"add isnullable to columncapabilities , columnanalysis <cm-sep> better builder <para-sep> estimated total segment byte size in if it was stored in a 'flat format ' ( e.g . a csv file ) is the segment rolled up detailed per column information such as : <nl> does this column contain null values ? if so , callers , especially for primitive numeric columns , will need to check for null value rows and act accordingly <nl> we start out as not having multiple values , but this might change as we encounter them <nl> we do n't currently know if complex column can have nulls ( or can be multi-valued , but not making that change since it is n't supported anywhere in the query engines ) longer term this needs to be captured by making the serde provide this information , and then this should no longer be set to true but rather the actual values <nl> incremental index time does not have nulls <nl> segment index <nl> multi-value is unknown unless explicitly set to 'true ' <nl> at index merge or query time we 'complete ' the capabilities to take a snapshot of the current state , coercing any 'unknown ' values to false <nl> results for this complex are n't different , we only know that nullability is unknown <nl> check ismaybetrue because incremental index uses unknown <nl> hasnulls and isfilterable are computed , these should not be set <nl> hasnulls and isfilterable are computed , these should not be set <nl> missing 'dim3 ' because makedefaultschemarow does not expect to set it ... <nl> 'rowbasedwithouttypesignature ' does not handle numeric null default values correctly , is equivalent to druid.generic.usedefaultvaluefornull being set to false , regardless of how it is actually set . in other words , numeric null values will be treated as nulls instead of the default value","this pr also fixes a bug with filtering numeric null values on the numeric dimension indexers , where the null values were being treated as nulls rather than default values in default null handling mode , meaning a query against an incremental index would not produce results consistent with after it was persisted into a segment . this bug was being masked by the way was creating its test data , which would automatically turn all rows into default values to handle the finisher , but is now actually how the incremental index handles null valued rows . i 've",1595937271,"can save space for columns where bitmap indexes are pointless ( like <nl> free-form text ) . <nl> requires adding a new flag and version code to dictionary encoded string <nl> columns . so , segments written with this option will not be backwards <nl> compatible with older versions of druid .",0.9666663408279419
vespa-engine_vespa/16910,expose more cluster data in nodes/v2 <cm-sep> add more cluster data to node repo client and application/v4,we can use the type to filter out clusters with type=admin from the resources view . <nl> the other numbers i 'm not sure about but i suspect we 'll want to look at them at some point .,1615487428,"originally , i was planning to control the maintainers using the and api , but since these maintainers are currently not started ( because is still empty ) , there is no way to disable them now , so i wired in the same feature flag i use in .",0.9602661728858948
apache_pulsar/9561,"indicate error when expire message request is not executed . <para-sep> my-sub1 has no msg backlog , so expire message wo n't be issued on that subscription <nl> update policy to trigger message expiry check . <nl> my-sub1 has no msg backlog , so expire message wo n't be issued on that subscription <nl> not calling findentrycomplete to clear expirationcheckinprogress condition , so following call to expire message should n't issue . <nl> my-sub1 has no msg backlog , so expire message wo n't be issued on that subscription <nl> my-sub1 has no msg backlog , so expire message wo n't be issued on that subscription",this change added tests and can be verified as follows : <nl> - add test case for new change .,1613028103,"decompression payload if needed in keyshared subscription . <nl> unit test added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no ) <nl> - anything that affects",0.9624940156936646
netty_netty/10866,do n't catch throwable in internalloggerfactory . <nl> motivation : . <nl> we shouldnt catch throwable in internalloggerfactory as this may hide oome etc . <nl> modifications : . <nl> only catch linkageerror and exception . <nl> result : . <para-sep> we catch exception and not reflectiveoperationexception as we still support java 0 <nl> we catch exception and not reflectiveoperationexception as we still support java 0 <nl> we catch exception and not reflectiveoperationexception as we still support java 0,motivation : . <nl> we shouldnt catch throwable in internalloggerfactory as this may hide oome etc . <nl> modifications : . <nl> only catch linkageerror and exception . <nl> result : .,1608039236,motivation : . <nl> we need to detect cname loops during lookup the dnscnamecache as otherwise we may try to follow cnames forever . <nl> modifications : . <nl> - correctly detect cname loops in the cache <nl> - add unit test . <nl> result : .,0.942712128162384
hazelcast_hazelcast/18349,"make portablegenericrecords queryable when the inmemoryformat is object . <nl> we were not handling the case in which the target object we want to <nl> extract attributes from is portablegenericrecord in our query system . <nl> due to that , when the inmemoryformat is object , queries on the <nl> objects were throwing exceptions since it was trying to use generic <nl> reflection-based attribute getter . <nl> now , we are handling this case . <para-sep> will be initialised a couple of times in the worst case <nl> verifies that the member can handle queries on portablegenericrecords when it does not have the necessary portablefactory in its config .","we were not handling the case in which the target object we want to <nl> extract attributes from is portablegenericrecord in our query system . <nl> due to that , when the inmemoryformat is object , queries on the <nl> objects were throwing exceptions since it was trying to use generic <nl> reflection-based attribute getter . <nl> now , we are handling this case .",1614788627,this pr introduces two thread pools that are used for sql execution . the design document [ 0 ] explains why the engine is organized in that way .,0.980745255947113
apache_pulsar/9667,"fix bytebuffer allocate error in the airliftutils . <nl> the compressed data may be bigger than original data , use the capacity of the bytebuffer instead of the uncompressed length as the allocate legnth .","the compressed data length may be bigger than the original data length ( e.g . the source text is not repeated , such as ' abcde ' ) , so we ca n't use the uncompressed length as the allocated length to initial the bytebuffer . <nl> use the capacity of the bytebuffer instead of the uncompressed length as the allocated length . <nl> update the existing tests . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api",1613965182,"fix deduplication cursor does not delete after disabling message deduplication . the issue occurs when enabling the message deduplication at the broker.conf and then disable it and restart the broker . the dedup cursor will not be deleted . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : (",0.8888752460479736
OpenAPITools_openapi-generator/7397,"feature ( template ) add response with status code generation <cm-sep> generate samples <para-sep> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> response return a implresponse struct filled <nl> implementation response defines an error code with the associated body <nl> todo : uncomment the next line to return response response ( { { code } } , { { datatype } } { } ) or use other options such as http.ok ... return response ( { { code } } , { { datatype } } { } ) , nil <nl> todo : uncomment the next line to return response response ( { { code } } , { { datatype } } { } ) or use other options such as http.ok ... return response ( { { code } } , nil ) , nil <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> if an error occured , encode the error with the status code <nl> if no error , encode the body and the result code <nl> todo : uncomment the next line to return response response ( 0 , pet { } ) or use other options such as http.ok ... return response ( 0 , pet { } ) , nil <nl> todo : uncomment the next line",this pr implement the possibility to return custom response code .,1599835112,"ps : after running ./run/ { lang } -petstore.sh , i got change on the version and unrelated stuff like . should i revert this change ?",0.9442519545555115
apache_incubator-pinot/5486,"changed the segment commit protocol to send/receive streampartitionmsgoffset . <nl> updated the segment commit protocol so that new element streampartitionmsgoffset <nl> is populated in requests ( as request parameters ) and in response ( as json string element ) . <nl> the server side has been modified to send the 'streampartitionmsgoffset ' as well as we the <nl> 'offset ' parameters to the controller . the controller looks for and prefers streampartitionmsgoffset <nl> but falls back to offset if the streampartitionmsgoffset is not there . <nl> the controller side , in the repsonse message , populates both of the elements , and the server on <nl> the receiver side does likewise -- preferring streampartitionmsgoffset . <nl> all callers into the protocol module have been modified to not set the offset field . instead , <nl> only set the streampartitionmsgoffset field . the 'offset ' value will be derived from <nl> streampartitionmsgoffset . <nl> added a test to make sure that the controller always generates both elements . such a test was not <nl> possible in the server side at this time , so verified manually . <nl> manually ran llcclusterintergrationtest by disabling populating on the <nl> server side ( old server/new controller ) and on the controller respons side ( new server/old controller ) . <para-sep> try to populate the offset if possible . todo remove this code once we have both sides be able to live without _offset . <nl> ignore , if the recipient excepts _offset , it will return an error to the sender . <nl> this method is called in the server when the controller responds with catch_up response to segmentconsumed ( ) api . <nl> todo remove the block below once we have both parties be fine without _offset being present . <nl> ignore . if the received expects _offset , it will return an error to the sender . <nl> if the sender sent us a stream partition message offset , use it . if not , the sender is still old version , so pick up the old offset from it . todo remove this backup use of offset when server and controller are upgraded . <nl> compatibility test : the controller must always respond with both fields -- 'offset ' as well as 'streampartitionmsgoffset ' , and they should be the same value . <nl> this constructor will go away when this","changed the segment commit protocol to send/receive streampartitionmsgoffset . <nl> updated the segment commit protocol so that new element streampartitionmsgoffset <nl> is populated in requests ( as request parameters ) and in response ( as json string element ) . <nl> the server side has been modified to send the 'streampartitionmsgoffset ' as well as we the <nl> 'offset ' parameters to the controller . the controller looks for and prefers streampartitionmsgoffset <nl> but falls back to offset if the streampartitionmsgoffset is not there . <nl> the controller side , in the repsonse message , populates both of the elements",1591131482,te : enabling application start <nl> - previous code had missing hibernate bundle .,0.9321597814559937
apache_druid/10144,address comments ; use guice instead of query context <para-sep> make sure to close yielder if anything happened before starting to serialize the response .,will add them in a separate pr . this pr also modifies how to check the flag ; now query servers and the broker use different config initialized by guice . i think this way is more stable and less error-prone than using query context,1594077184,"enables joins where the right-hand side is a lookup . includes an <nl> integration test . <nl> also , includes changes to lookupextractorfactorycontainerprovider : . <nl> 0 ) add ' getalllookupnames ' , which will be needed to eventually connect <nl> lookups to druid 's sql catalog . <nl> 0 ) convert ' get ' from nullable to optional return . <nl> 0 ) swap out most usages of lookupreferencesmanager in favor of the <nl> simpler lookupextractorfactorycontainerprovider interface .",0.970824122428894
elastic_elasticsearch/71620,"cleanup snapshotsinprogress for readability . <nl> * formatting in a more reasonable way instead of mixing nested class , fields and methods . <nl> * removing pointless constants for the x-content serialization . <nl> * cleaning up double wrapping in . <nl> * removing unused and incorrectly documented constructor from <para-sep> checks if all shards in the list have completed <nl> make sure in-flight-shard-states can be built cleanly for the entries without tripping assertions <nl> shard snapshot is waiting for the primary to snapshot to become available . <nl> shard snapshot is waiting for another shard snapshot for the same shard and to the same repository to finish . <nl> shard snapshot status for shards that are waiting for another operation to finish before they can be assigned to a node . <nl> shard snapshot status for shards that could not be snapshotted because their index was deleted from before the shard snapshot started . <nl> if the state is failed we have to have a reason for this failure <nl> checks if this shard snapshot is actively executing .","* formatting in a more reasonable way instead of mixing nested class , fields and methods . <nl> * removing pointless constants for the x-content serialization . <nl> * cleaning up double wrapping in . <nl> * removing unused and incorrectly documented constructor from . <nl> no functional changes otherwise .",1618311441,"runtime fields usage is currently reported as part of the xpack feature usage api . now that runtime fields are part of server , their corresponding stats can be moved to be part of the ordinary mapping stats exposed by the cluster stats api . <nl> this is the last bit of functionality left in the xpack runtime-fields plugin , hence we can remove the plugin as part of this change too . <nl> this pr removes the runtime-fields feature from the xpack/usage and xpack/info output , in favour of reporting runtime_field_types stats as part of the output of the",0.9468633532524109
apache_kafka/10041,moved creation of file to write to prevent unnecessary creation of files .,"currently the partition.metadata file is created when the log is created . however , clusters with older inter-broker protocols will never use this file . this pr moves the creation of the file to when we write to the file . <nl> this pr also deletes the partition.metadata file on startup if the ibp version is lower than version . <nl> i will be looking at benchmarks to see how these changes affect lisr request processing .",1612376119,this pr avoids generating unnecessary topicchange events during the topic validation . it does so by adding a field in the request . this allows to not register the watch when topics are queried from the topic validation logic .,0.9999999403953552
elastic_elasticsearch/72490,latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated . <para-sep> list of ignored timezones .,latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated .,1619709137,"relies on the resource watcher to detect the cert file overwriting . <nl> resource watcher detects changes by only inspecting the file size on disk and the last access timestamp . <nl> for the last access timestamp , the resolution can be as low as one second depending on the jdk and the fs type . <nl> it is thus preferable to rely on file size differences in tests .",0.8938605785369873
grpc_grpc-java/7548,support keep-open on the server side .,sending out server changes separately to unblock other languages ' test client .,1603392611,this allows rls or any lb to configure oobchannel such as service config .,0.8981145620346069
confluentinc_ksql/6550,support joins on key formats with different default serde features,"added qtt . looked into adding a unit test in schemakstreamtest but could n't find a good way to do it ( existing coverage for the changed block of code is missing as well , probably for the same reason ) .",1604038066,this pr adds it ! <nl> test only change .,0.8280432224273682
ballerina-platform_ballerina-lang/26469,"update for recent compiler api changes <cm-sep> add comparison expression evaluation support for decimal variables <cm-sep> add support for xml concatenation <cm-sep> add tests for decimal comparison and xml concatenation <cm-sep> add support for string template expressions <cm-sep> sync with master and resolve conflicts <cm-sep> refactor to use ballerina runtime utils for bstring concatenation scenarios <para-sep> concatenates multiple bstring values and returns the result an instance of bstring . <nl> returns the human-readable string value of a given ballerina value in direct style . <nl> todo - throw an error instead ? <nl> can not use foreach or lambda , until the classcastexception is fixed from the compiler side . <nl> prepares to invoke the jvm runtime util function which is responsible for xml concatenation . <nl> jvm generated instance method representation of a ballerina function . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> removes injected arguments added during the jvm method gen phase . <nl> todo - important : add remaining steps to validate and match named , defaultable and rest args todo - verify here we use the existing strand instance to execute the function invocation expression . <nl> jvm generated static method representation of a ballerina function . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> removes injected arguments added during the jvm method gen phase . <nl> todo - important : add remaining steps to validate and match named , defaultable and rest args todo - verify here we use the existing strand instance to execute the function invocation expression . <nl> ballerina jvm runtime instance method representation . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> string template expression evaluator implementation . <nl> a string-template-expr interpolates the results of evaluating expressions into a literal string . the static type of the expression in each interpolation must be a simple type and must not be nil . a string-template-expr is evaluated by evaluating the expression in each interpolation in the order in which they occur , and converting the result of the each evaluation to a string using the tostring abstract operation with the direct style . <nl> interpolation expression results can only be ( int|float|decimal|string|boolean ) . <nl> incompatible result types",this pr also adds integration test scenarios for the added expression types .,1603276401,"- configurations to enable/disable : <nl> 0. requiring registration of topics prior to publishing/accepting subscriptions <nl> 0. allowing registering a topic with a secret , to allow authenticated content distribution between the publisher and hub <nl> 0. allowing remote publishing to a hub ( if disabled publishers can not publish to a hub via network calls ) . <nl> - support to subscribe by resource url - a get would happen to the resource url initially to identify hub and topic urls , after which a subscription request would be sent to the identified hub for the topic identified .",0.9811150431632996
confluentinc_ksql/6594,add flag to ksqlstructureddataoutputnode <cm-sep> new createsourcefactory method that accepts an outputnode <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when <nl> then <nl> when <nl> then,"this pr moves the code from the to the to re-use part of the code there . <nl> right now , the pr does n't re-use code .",1605027127,"this pr adds some additional test coverage for the java client . the four new commits , in order : <nl> * add tests for tls mutual auth . cleans up existing tls test to avoid use of . <nl> more test coverage coming in a future pr . <nl> tests pass .",0.9694895148277283
elastic_elasticsearch/72061,"fix privileges for predefined roles . <nl> this change adds a missing application privilege to <nl> these roles . this is only needed in 0.x as the behavior has changed <nl> in kibana , starting version and this extra privilege is not necessary .","this change adds a missing application privilege to <nl> these roles . this is only needed in 0.x as the behavior has changed <nl> in kibana , starting version and this extra privilege is not necessary . <nl> marking as non-issue as this is not yet released .",1619069819,besides unmuting the test i added debug-level logging to facilitate finding the root cause of the test failure .,0.9023217558860779
gocd_gocd/8027,remove deprecated agent job run history api <cm-sep> remove deprecated pipeline groups config listing api,description : . <nl> * remove deprecated agent job run history api <nl> * remove deprecated pipeline groups config listing api .,1587393575,"perhaps to get some user feedback ? but this seems more like a ui decision rather than a feature toggle to have . besides , it is disabled for 0 months now . feel free to close the pr if you want to keep this around .",0.7258234024047852
vespa-engine_vespa/16580,"fail safe maintenance if other nodes are not up <para-sep> this method verifies both storage nodes and distributors are up ( or retired ) . the complicated part is making a summary error message . <nl> create a content cluster with 0 nodes , and storage node with index 0 down . <nl> we should then be denied setting storage node 0 safely to maintenance . <nl> because 0 is in maintenance , even though user wanted state is up , trying to set 0 to maintenance will fail .","the test_upgrade_of_downed_node system test fails with group-suspension enabled because the cluster controller allows the suspension of a node even if another node is down . disabled , the orchestrator blocks the suspension . <nl> it used to be that : <nl> 0. the cc disallowed suspension if any other node ( outside the hierarchical group if any ) were in maintenance or user wanted state maintenance . <nl> 0. the cc would disallow suspension if the minstoragenodesup or minratiofstoragenodesup thresholds were already violated . <nl> the pr changes these to : <nl> - if any other storage node or distributor",1613697485,"you can now provide ' recursive=true ' at the paths : . <nl> 0 . <nl> 0 . <nl> 0. . <nl> at the application level , this lists full information about all deployments of the application , with deployment instance ( argh ) , region and environment . <nl> at the tenant level , this lists all applications for the tenant , as above , with application name . <nl> at the root level , this lists all tenants , as above , with tenant name . <nl> obviously , examples are found in the test responses , like",0.9628825187683105
apache_kafka/9609,"refactor nodes , fix up tests","will leave the ability to create multiple ktables from the same source topic as followup work . similarly , creating a kstream and a ktable from the same topic can be tackled later if need be",1605675460,"as decided in , the uuid class has been named uuid . this pr changes all instances of org.apache.kafka.common.uuid to org.apache.kafka.common.uuid . <nl> it also modifies the uuid class so that it no longer wraps a java.util.uuid object . now it simply stores two longs .",0.9676576256752014
apache_incubator-pinot/6037,add whitelist for emitting table level metrics <para-sep> table level metrics are still emitted for allowed tables even if emitting table level metrics is disabled <nl> some metrics use raw table name and some use table name with type . this method adds all variations of the table name to the allowed entries to make sure that all metrics are checked against the allowed tables .,"for big clusters , let 's say the ones with a few thousands tables , this is problematic as one might need to set up alerts/monitoring on some the tables that have higher priority than others in the cluster . this pr introduces a config for whitelisted tables to address this problem . table level metrics are still emitted for whitelisted tables even if emitting table level metrics is disabled for the whole cluster . <nl> 0 ) and added to the whitelist . <nl> 0 ) and empty whitelist . <nl> 0 ) .",1600479839,"- add detection health in the alert list endpoint . <nl> - store the detection of health in detection config dto and periodically update it in the monitoring tasks . so that when a user opens the page , it will avoid the time to generate the detection health . <nl> - minor change to the frontend to move away from the legacy endpoints .",0.9646850824356079
elastic_elasticsearch/71144,"system index descriptors support mixed versions . <nl> system index descriptors are used to describe a system index , which are <nl> expected to change as new versions are developed . as part of this , the <nl> descriptors had a minimum supported version field so that the contents <nl> within that descriptor would not be applied if there were nodes older <nl> than that version . however , this falls short of being able to <nl> accurately describe what a system index should look like in a given <nl> cluster where there are mixed node versions . <nl> this change moves us towards being able to accurately describe and <nl> know what the system index should look like . a system index is now <nl> able to accept a list of the prior system index descriptor objects <nl> so that clusters with mixed versions can select the appropriate <nl> descriptor and ensure the index is created properly . as the node <nl> versions change during a rolling upgrade , the cluster will then be <nl> able to adapt the system index to the most recent version once all <nl> master and data nodes have been upgraded . <para-sep> the minimum cluster node version required for this descriptor / mapping version from the descriptor / <nl> a list of prior system index descriptors that can be used when one or more data/master nodes is on a version lower than the minimum supported version for this descriptor","system index descriptors are used to describe a system index , which are <nl> expected to change as new versions are developed . as part of this , the <nl> descriptors had a minimum supported version field so that the contents <nl> within that descriptor would not be applied if there were nodes older <nl> than that version . however , this falls short of being able to <nl> accurately describe what a system index should look like in a given <nl> cluster where there are mixed node versions . <nl> this change moves us towards being able to accurately",1617218975,"add a new operatordynamic enum to differentiate between operator-only and <nl> regular dynamic cluster settings . the setting constructor validates that dynamic <nl> and operatordynamic can not be both specified . operator-only settings behave <nl> as the follows : . <nl> * when the feature is enabled , operator-only settings can not be updated with <nl> put cluster settings api unless the user is an operator . <nl> * the restore behaviour for operator-only settings will be identical for either <nl> operator or non-operator user . that is , when operator privileges are enabled , <nl> operator-only settings will not",0.9779309630393982
elastic_elasticsearch/72439,"this pr ensures setsecurityuserprocessor adds the api key metadata <nl> inside the existing api_key object if the metadata is not null or empty . <para-sep> tbd : it 's unclear why we 're putting users in an index here . <nl> this qa project tests the security plugin when security is explicitly disabled . if the authentication has type of api_key , returns the metadata associated to the api key .",this pr ensures setsecurityuserprocessor adds the api key metadata <nl> inside the existing api_key object if the metadata is not null or empty .,1619673079,saving some cycles here and there on the io loop : . <nl> * do n't instantiate new to execute on in a few spots <nl> * do n't instantiate complicated wrapped stream for empty messages <nl> * stop instantiating almost never used in two spots <nl> * some minor cleanup and preventing pointless instantiation in transport master node action,0.9348289370536804
confluentinc_ksql/6204,make sure unclean leader election is set to false,"if the topic already exists and the configs do n't match . <nl> was n't being set to false in the event the topic is already present . <nl> note : is n't being set if the topic already exists , only when the server creates the internal topic , should we add code to also set this value ? <nl> start up server .",1600201390,internal topics include or . <nl> the docs are updated accordingly .,0.8054770827293396
neo4j_neo4j/11401,"obsfucate the ldap system password in tostring and debug.log <para-sep> used to define a configuration setting as secret , which means we should not show the value in logs . it is supported in configs set using loadableconfig , but not for group settings , like connectors and ssl policies .",changelog : fixed visibility of ldap system password in debug.log through new annotation . <nl> marking config settings as will cause them to be printed as in debug.log as well as the output of .,1522166253,"changelog : improved ldap authorization support : <nl> * augment to show the active role set for the current user , regardless of the configured auth providers . <nl> * fix a bug in the ldap auth provider that causes authorization failures when ldap authentication is disabled .",0.970842182636261
OpenAPITools_openapi-generator/8251,update cpp-qt5-client.md . <nl> added missing security feature support in the documentation,added missing security feature support in the documentation . <nl> added missing security feature support for the cpp-qt5-generator .,1608553760,"- minor improvements to doc generator ( such as copyright note , mark as beta , use oas 0 , etc ) .",0.8077399134635925
apache_druid/10517,fix flaky it compaction test <cm-sep> fix flaky it compaction test <cm-sep> test <cm-sep> test <cm-sep> test <cm-sep> test <cm-sep> fix compaction integration test ci timeout <para-sep> set comapction slot to 0 <nl> get all failed task logs,"fix compaction integration test ci timeout . <nl> compaction integration test intermittently timeout ( travis job stuck until timeout of 0 minutes and/or travis job terminates after 0 mins of not receiving new output ) due to one of the test submitting/running too many tasks at the same time . specifically , the test submits range partitioning compaction tasks with 0 subtasks each ( for a total of 0 tasks ) . this causes the cluster to intermittently fails . i am not sure what is the _real_ maximum number of tasks the druid cluster running in travis can handle",1603000809,"authentication for jdbc requests should use credentials stored in the jdbc connection context instead of the http headers . <nl> on the broker , druidavaticahandler handles jdbc requests separately from the normal authentication checking filters . <nl> on the router , jdbc requests currently go through the normal authentication checking filter which is extraneous/incorrect sets the avatica path as ' unsecured ' on the router , deferring the authentication check to the broker where authentication will occur using the jdbc connection context",0.9328607320785522
apache_pulsar/9519,call the corresponding restart according to the componenttype .,"add judgment on component type，call the corresponding restart according to the componenttype . <nl> the reason for the problem is that the corresponding functionadmin is not found according to the componenttype , which leads to the restart of sink or source using the functionadmin of function - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue",1612692032,since we mocked classlayout.parseclass ( ) because we need to exclude org.openjdk.jol for license issues . lets come up with another way to estimate class size,0.8707393407821655
apache_beam/12993,"this reverts commit sha . <nl> there is a bug in this commit that causes deleted timers to not clear their <nl> watermark holds , resulting in stuck pipelines . <para-sep> lazily initialized",this change is a serious regression in version so should be cherrypicked back to version,1601593697,this change reverts the following changes since they break dataflow tests : . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9489811658859253
grpc_grpc-java/7560,replace lock with synchronizationcontext . <para-sep> do not shutdown channel as it is not owned by lrsclient .,loadreportclient is a subcomponent of xdsclient . we can pass this synchronizationcontext to loadreportclient for its synchronization usages as well .,1603829510,"when deadline expires , both the client and the server try to cancel the stream . there is a race between server receiving the cancellation from the client and the server cancelling the stream , which changes the final status of the stream from the server 's perspective . if the former wins , server sees cancelled . if the latter wins , server sees deadline_exceeded . <nl> because does n't pass the final status to the server-side application , this ambiguity is n't a problem in most cases . however , the status is passed to , and thus",0.9405566453933716
apache_pulsar/10008,"proto for usage reports <cm-sep> change to proto2 and use lightproto <cm-sep> add task to publish/consume resource-usage info to pulsar topic . <para-sep> start the task to publish resource usage , if necessary <nl> interface that a resource owner ( tenant , namespace or topic ) needs to implement . <nl> get the unique identifier for the owner <nl> listener for resource usage published by other brokers <nl> interface that a resource owner ( tenant , namespace or topic ) needs to implement . <nl> get the unique identifier for the owner <nl> fill the resource usage object that is passed in <nl> resource usage transport manager module to exchange usage information with other brokers . implements a task to periodically . publish the usage as well as handlers to process the usage info from other brokers . <nl> create a public tenant and default namespace <nl> register a resource owner ( resource-group , tenant , namespace , topic etc ) . <nl> unregister a resource owner ( resource-group , tenant , namespace , topic etc ) . <nl> register a resource owner ( resource-group , tenant , namespace , topic etc ) . <nl> unregister a resource owner ( resource-group , tenant , namespace , topic etc ) . <nl> owner is the key ( id ) of the entity that reports the usage it could be a resource-group or tenant , namespace or a topic <nl> name of the broker","adds support for distributed resource quota enforcement at a tenant , namespace or topic level . <nl> - proto definition for publishing resource usage . <nl> - use lightproto <nl> - add a task to publish the resource usage . <nl> - added unit tests . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( lightproto ) added to pulsar-broker <nl> # # # documentation . <nl> - does this pull request introduce a new feature ? ( yes ) <nl> - the configuration and documentation of the same will be added in a subsequent",1616432529,added an aws kinesis source connector to the existing kinesis module . <nl> modifications . <nl> added an aws kinesis source connector and associated configuration class <nl> added test class for aws kinesis source connector <nl> refactored configuration hierarchy to promote code reused between the sink and source configurations . <nl> added test cases to confirm the above refactoring did not break anything in the sink <nl> verifying this change . <nl> make sure that the change passes the ci checks . <nl> ( please pick either of the following options ) . <nl> this change added tests and can,0.9826762676239014
gocd_gocd/8035,"always render the new pipeline config spa . <nl> * regardless of the pipeline config spa toggle , serve the new pipeline <nl> config spa . <nl> * always show the 'quick edit ' button to go to the pipelines and templates <nl> spa from the old rails pages , regardless of the toggle value . <cm-sep> redirect to new pipeline config spa and templates spa when spa toggle is enabled","* show the 'quick edit ' button to go to the pipelines and templates <nl> spa from the old rails pages , regardless of the toggle value . <nl> ( can not toggle back to the rails page as a redirect is setup from rails url to spa url ) <nl> - render template config spa . ( can not toggle back to the rails page as a redirect is setup from rails url to spa url ) . <nl> 0. when toggle is enabled , following redirect is added : <nl> - = > <nl> - = > .",1587566089,"description : moving the new agents spa behind a toggle . default is . <nl> to turn it on : . <nl> also , updated the new agents spa to utilise .",0.8610427379608154
ballerina-platform_ballerina-lang/26708,disable errorvariabledefinitiontest . <nl> disabling the test due to spec deviation .,disabling the test due to spec deviation . <nl> need to revisit and fix the test .,1604345277,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.8237542510032654
quarkusio_quarkus/14920,"avoid using as it 's forbidden from the event loop . <nl> ( cherry picked from commit sha ) <cm-sep> support k8s secret/configmaps as smallrye config locations . <nl> ( cherry picked from commit sha ) <cm-sep> bump kubernetes-client-bom from version to version . <nl> ( cherry picked from commit sha ) <cm-sep> if jackson is present , make sure the objectmapper producer is not removed . <nl> the issue is that the jackson serde access the mapper using the arc api directly ( as serde are not beans ) , so arc does know that the mapper is used . <nl> ( cherry picked from commit sha ) <cm-sep> upgrade to hibernate orm version.sp1 . <nl> ( cherry picked from commit sha ) <cm-sep> micrometer match pattern . <nl> ( cherry picked from commit sha ) <cm-sep> set the default min-level for logs to debug . <nl> per discussion with max . <nl> note that the related its might need some tweaks as the default value <nl> has changed but they will need to be changed later . <nl> ( cherry picked from commit sha ) <para-sep> by default all categories are configured with debug minimum level . to get runtime logging below debug , e.g . trace , <nl> make the bean can not be removed . <nl> if set , the secret will mounted to the application container and its contents will be used for application configuration . <nl> if set , the config amp will mounted to the application container and its contents will be used for application configuration . <nl> if set , the secret will mounted to the application container and its contents will be used for application configuration . <nl> if set , the config amp will mounted to the application container and its contents will be used for application configuration . <nl> if set , the secret will mounted to the application container and its contents will be used for application configuration . <nl> if set , the config amp will mounted to the application container and its contents will be used for application configuration . <nl> we can safely cast , as we know that the results are strings . <nl> it can not be referenced during build or static initialization . <nl> extract the path out of the uri . return null if the path should be ignored . <nl>","please do n't merge , i will merge it myself .",1612826825,"please do n't merge , i will merge it myself .",0.9715885519981384
confluentinc_ksql/6239,"improve error message on invalid avro identifier . <nl> fixes issue where using a column name in ksqldb that was incompatible with avro , e.g . one that starts with a numeric , either was n't detected at the time the statement was issued ( in the case of c statements ) , or returned a ambiguous error message ( in the case of cas statements ) . <para-sep> ensure schema is compatible by converting to avro schema : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","fixes issue where using a column name in ksqldb that was incompatible with avro , e.g . one that starts with a numeric , either was n't detected at the time the statement was issued ( in the case of c statements ) , or returned a ambiguous error message ( in the case of cas statements ) . <nl> usual .",1600287172,error message is no longer : . <nl> it is now : . <nl> usual .,0.9751825928688049
Graylog2_graylog2-server/9877,consolidating backend-agnostic query parsing/metadata creation . <cm-sep> fixing test . <cm-sep> adding test cases for bug . <cm-sep> adjusting regex for query string parser .,"note : this pr needs to be backported to and . <nl> before this change , a user could write or generate a query string that contains two characters in unrelated places ( e.g . because a field name or value contains it ) , leading to an undeclared parameter being incorrectly identified . an example for this is a query string of . <nl> this pr is fixing the regex used to identify parameters in query strings . the regex is now checking for two enclosing a group of alphanumerical ( , , & ) characters instead of a",1610354506,"previously the lookup of indices for streams and time range was done <nl> in by loading indices , streams , and then finding <nl> matches . it was impossible to reuse this logic elsewhere . <nl> furthermore this made harder to test , because <nl> a lot of setup was required to make sure that proper index ranges and <nl> streams are loaded during the test . <nl> both prs should be merged at the same time . <nl> local unit and integration tests .",0.9520583748817444
apache_flink/14961,"fix decimal parquet logical type mapping with flink type information . <cm-sep> add a test for decimal parquet logical type mapping with flink type information . <cm-sep> spotless apply <cm-sep> support decimal parquet logical type in rowconverter <para-sep> point ) < = 0 , the int32 stores the unscaled value <nl> point ) < = 0 , the int64 stores the unscaled value",support decimal parquet logical type when parquet primitive type is int32 . <nl> the support for int64 was already done ( matching _int64/decimal_ to _basictypeinfo.int_type_info_ ) <nl> simply added support for int32 ( matching _int32/decimal_ to _basictypeinfo.int_type_info_ ) . <nl> this change added tests and can be verified as follows : <nl> parquetschemaconvertertest # testdecimalparquetlogicaltype . <nl> - does this pull request introduce a new feature ? no .,1613647014,"this pull request set to be false if was not specified . <nl> add unit case to cover . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos , zookeeper : ( no",0.8605577945709229
Alluxio_alluxio/10921,"fix updatechecktest <para-sep> when no user data in this ec2 , null is returned",avoid npe thrown in updatechecktest by mocking all the methods called .,1581714015,"we 've had a series of flaky tests in our build lately . this pr aims to make it easier to determine the root cause of these flakes . <nl> - make logs more useful for debugging . previously all tests would dump their logs into the same file , making it difficult to find the relevant logs from jenkins test failures . this pr changes the behavior so that we reset the logs after each test , and save the logs for failed tests under a classname-mathodname.log file . note that this change does n't play well with running",0.8815866112709045
apache_pulsar/9472,fix injection factory cast error in presto worker,"fix master ci problem . <nl> error log . <nl> 0. set thread context classloader . <nl> 0. remove useless dependencies . <nl> this change is already covered by existing tests . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints",1612418614,"config will not appear null when create tenant use pulsar-admin create foo3 , but use the following command , config is null . <nl> handle config is null when create tenant use curl .",0.8875171542167664
vespa-engine_vespa/15740,use exponential backoff for reconfig retries . <nl> combined with connecting to localhost this should reduce the time it takes for <nl> all nodes to complete reconfig . <cm-sep> add missing author,combined with nodes connecting to localhost this should reduce the time it takes <nl> for all nodes to complete reconfig .,1607432283,adds to . <nl> must be merged with the corresponding change in .,0.9569252729415894
apache_shardingsphere/10193,fix bad rewritten result for foreign key sql when user config single data node sharding config <para-sep> sharding alter table statement validator .,changes proposed in this pull request : <nl> - fix bad rewritten result for foreign key sql when user config single data node sharding config <nl> - refactor shardingtablebroadcastroutingengine to support different table combination <nl> - add some test cases for table rewrite with different table combination,1619407344,- add shadow-core-common <nl> - add shadow-core-route <nl> - update order for shadow rule,0.982427716255188
confluentinc_ksql/6701,makes response codes rate limited as well as prints a message when it is hit <cm-sep> fix test name <para-sep> given : <nl> given : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> print ' you hit a rate limit ' every 0 seconds <nl> rate limiters for printing the ' you hit a rate limit ' message <nl> already validated as all ints <nl> given : <nl> when : <nl> then :,also prints a message when rate limit is hit .,1606876312,"in the version branch it is valid/supported to either or , but this currently results in an error in the master branch . <nl> this pr looks to fix the regression . <nl> the problem is that the for a source must exist in the value schema of the source , that 's the _true_ value schema of the source , so or are not valid values for the key field . ( remember , the key field is the field in the _value_ schema that matches the key , hence it must be in the value schema ) .",0.958672046661377
apache_incubator-pinot/5917,"starts broker and server in parallel when using servicemanager . <para-sep> multiple instances allowed per role for testing many minions <nl> starts a controller synchronously unless the cluster already exists . other services start in parallel . <nl> start controller ( s ) synchronously so that other services do n't fail note : technically , we do n't need to do this if the cluster already exists , but checking the cluster takes time and clutters logs with errors when it does n't exist . <nl> true is when everything succeeded <nl> unhandled exceptions are likely logged , so we do n't need to re-log here <nl> block until service startup completes <nl> creates millis precision unit of seconds . ex version * /",0. pinotservicemanager <nl> 0. bootstrap services in role servicerole.controller <nl> 0. all remaining bootstrap services in parallel . <nl> no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? no . <nl> does this pr otherwise need attention when creating release notes ? yes . <nl> 0. pinotservicemanager <nl> 0. bootstrap services in role servicerole.controller <nl> 0. all remaining bootstrap services in parallel .,1598361128,"currently related metrics and entities are defined on a per-metric basis . while the entity mapping pipeline supports convex hull exploration , this is has side-effects that are hard understand for our users . instead , they fall back to repetitive entry of similar entity relationships . <nl> this pr introduces a datasetentity that logically groups together multiple metrics . common relationships of a group of metrics can now explicitly be expressed on the dataset level , as well as on an individual per-metric level as before . <nl> * introduced datasetentity . <nl> * refactored metricdatasetpipeline . <nl> *",0.9767274260520935
quarkusio_quarkus/15948,"remove duplicate code in agroal 's datasources class . <nl> logging a warning is the default behavior of agroalconnectionconfigurer , <nl> so we can take advantage of that . <para-sep> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them : we 're only interested in agroal here . <nl> this is just to get meaningful error messages , as logrecord does n't have a tostring ( ) <nl> ignore these particular warnings : they are not relevant to this test . <nl> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them : we 're only interested in agroal here . <nl> this is just to get meaningful error messages , as logrecord does n't have a tostring ( ) <nl> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them : we 're only interested in agroal here . <nl> this is just to get meaningful error messages , as logrecord does n't have a tostring ( ) <nl> do not log a warning : we do n't have an exception sorter for derby , but there is nothing the user can do about it . <nl> do not log a warning : we do n't have an exception sorter for h2 , but there is nothing the user can do about it . <nl> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them : we 're only interested in agroal here . <nl> this is just to get meaningful error messages , as logrecord does n't have a tostring ( ) <nl> this exception sorter is apparently valid for mariadb too . <nl> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them : we 're only interested in agroal here . <nl> this is just to get meaningful error messages , as logrecord does n't have a tostring ( ) <nl> expect no warnings ( in particular from agroal ) <nl> there are other warnings : jdk8 , testcontainers , drivers , ... ignore them","addresses this comment , but i think we need more in order to close that ticket . <nl> since it 's a bit hard to artificially trigger fatal jdbc exceptions , i ended up trusting agroal to do the right thing , and only testing that we configure agroal correctly . <nl> ~the one thing i 'm not sure of is what to do for derby and h2 . there is no built-in for those , so we have to rely on defaults . currently i 'm logging a warning because of that , but there is nothing users can",1616484672,"please do n't merge , i will merge it myself .",0.9501999616622925
apache_druid/10203,"support unit suffix on byte-related properties <cm-sep> add doc <cm-sep> change default value of byte-related properites in example files <cm-sep> fix coding style <para-sep> parse the case-insensitive string number , which is either : a number string or a number string with a suffix which indicates the unit the of number the unit must be one of following k - kilobyte = 0 m - megabyte = 0,0,0 g - gigabyte = 0,0,0,0 t - terabyte = 0,0,0,0,0 p - petabyte = 0,0,0,0,0,0 kib - kilo binary byte = 0 mib - mega binary byte = 00 gib - giga binary byte = 000 tib - tera binary byte = 0000 pib - peta binary byte = 00000 <nl> unit ends with ' b ' must be format of kib/mib/gib/tib/pib , so at least 0 extra characters are required <nl> lastdigitindex here holds the index which is prior to current digit move backward so that it 's at the right place <nl> for base == 0 , overflow has been checked in parselong <nl> for example , class size { <nl> inclusive <nl> inclusive <nl> constraintvalidator requires <nl> constraintvalidator requires <nl> constraintvalidator requires","in druid , there 're lots of byte-related properties . in the world of big data , the value of these properties are usually very large . <nl> for example , . <nl> ` . <nl> at first glance of this configuration , it 's hard to tell how many bytes hold . user have to count the number digit by digit to know it 's 300_000_000_000 . changing its value is also error-prone . <nl> so this pr adds support of unit suffix to the value of these properties , like how we specify the value of or properties",1595396694,"part of like .. being responsible and stuff , before adding this documentation i first wanted to collect some data to determine if it _was a good idea to in fact document it at this time_ . the place i was specifically worried about was the check , so i added a benchmark , , and ran some experiments to see what to expect as well as if we could do better . <nl> the nature of selectors lends itself to using a bitmap iterator as an alternative to calling bitmap.get for every check , so i first tested vs",0.9702975749969482
elastic_elasticsearch/71119,remove the requirement for default distro <cm-sep> enable bwc for ci -- > will revert this commit,"originally much of the rest api compatibility code was to live in <nl> x-pack . however , some design changes has removed this requirements <nl> and there is no longer a need to explicitly use the default distribution <nl> for rest api compatibility testing . <nl> if we had kept with the original design we would need to figure out how to conditionally add modules ... but now we can simply remove this special requirement .",1617199833,remove unused cluster name in environment.java .,0.8971480131149292
Alluxio_alluxio/10918,"misc improvements to collectinfo command <cm-sep> metrics catch all exceptions <para-sep> do not break the loop since the http failure can be due to many reasons return the error message instead <nl> if the http request fails , return the error content instead of throwing an exception .","various improvements to command : <nl> 0. scp now does n't hardcode ' localhost ' . specifying works on mac but not on a centos machine . <nl> 0. if the command is invalid like , early reject before distributing the command and find out it 's invalid locally . <nl> 0. catch metrics collection errors when metrics are unavailable , instead of failing the command and subsequently skips collecting tarballs . <nl> 0. misc bash command fixes .",1581701708,buffers on the server side before sending to the client .,0.8954862952232361
apache_beam/13558,"fileio stops overwriting files on retries <para-sep> if the source is not found , and we are ignoring found source files , then we skip it . <nl> if the destination exists , and we are skipping when destinations exist , then we skip . <nl> an optional checksum to identify the contents of a file . * / <nl> todo ( ) : support file checksum in this method .","in this case , the default behavior for fileio changes slightly : <nl> - before this change , fileio copies temp files into destination locations without checking whether destinations exist . <nl> - with the new change , if the destination file exists already , nothing will be copied",1608078537,"adds a to so that actually runs . since this test has n't been running it has a few issues , which i 've also attempted to resolve here . a summary of the changes to that end : <nl> - when testing a sub-class use the components list as the expected components , rather than the usual arguments list . <nl> - add to list of dataflow known coders . <nl> - now only validates that dataflow known coders do n't have a rather than _all_ model coders . <nl> - add equals and hashcode for schemacoder and rowcoder",0.9684317111968994
apache_kafka/10107,improve confusing admin client shutdown logging,"if the admin client is shutdown with some unfinished calls , we see messages such as the following in the log : . <nl> the problem is that we are using passing as the current time in in order to ensure the call is timed out and we are discarding the original cause . the patch fixes the problem by setting instead and preserving the original exception message .",1613010283,use the last actual restored offset for the method . probably should update the docs to inform users this could include gaps in sequence due to commit markers . <nl> updated existing tests .,0.8665311336517334
apache_shardingsphere/9259,add single table rule loader test,changes proposed in this pull request : <nl> - add singletableruleloadertest <nl> - <nl> -,1612193243,changes proposed in this pull request : <nl> -add sqlloggertest to test sqllogger,0.9634054899215698
elastic_elasticsearch/71018,"tool <cm-sep> tar header <cm-sep> delete <cm-sep> support relative paths <cm-sep> tool <cm-sep> spotless <cm-sep> forbiddenapis and spotless <cm-sep> setup <para-sep> visible for testing <nl> relative url , add it after last slash ( i.e resolve sibling ) or at the end if there 's no slash after http [ s ] : //","air-gapped environments ca n't simply use geoip database service provided by infra , so they have to either use proxy or recreate similar service themselves . <nl> this pr adds tool to make this process easier . basic workflow is : . <nl> - download databases from maxmind site to single directory ( either files or gzipped tarballs with suffix ) <nl> - run the tool with <nl> - serve static files from that directory ( for example with <nl> - use server above as endpoint for ( setting ) <nl> - to update new databases simply put new files",1617059375,add support for distance_feature query for runtime geo_point field . this was an oversight when initially added the field .,0.9849607944488525
apache_kafka/10106,"add the metaloglistener , locallogmanager , etc . <nl> add metaloglistener , locallogmanager , and related classes . these <nl> classes are used by the controller to interface with the raft <nl> log . <para-sep> change the in-sync replica sets for some partitions . <nl> create a batch of topics . <nl> unregister a broker . <nl> describe the current configuration of various resources . <nl> elect new partition leaders . <nl> get the current finalized feature ranges for each feature . <nl> perform some incremental configuration changes . <nl> perform some configuration changes using the legacy api . <nl> process a heartbeat from a broker . <nl> attempt to register the given broker . <nl> wait for the given number of brokers to be registered and unfenced . this is for testing . <nl> perform some client quota changes <nl> begin shutting down , but do n't block . you must still call close to clean up all resources . <nl> if this controller is active , this is the non-negative controller epoch . otherwise , this is 0 . <nl> blocks until we have shut down and freed all resources . <nl> true if the heartbeat reply should tell the broker that it has caught up . <nl> true if the heartbeat reply should tell the broker that it is fenced . <nl> true if the heartbeat reply should tell the broker that it should shut down . <nl> an immutable class which represents broker registrations . <nl> a map of feature names to their supported versions . <nl> a map of feature names to their supported versions . <nl> the current leader of the metalog . <nl> listeners receive notifications from the metalogmanager . <nl> called when the metalogmanager commits some messages . <nl> called when a new leader is elected . <nl> called when the metalogmanager has renounced the leadership . <nl> called when the metalogmanager has finished shutting down , and wants to tell its listener that it is safe to shut down as well . <nl> the metalogmanager handles storing metadata and electing leaders . <nl> start this meta log manager . the manager must be ready to accept incoming calls after this function returns . it is an error to initialize a metalogmanager more than once . <nl> register the listener . the manager must be initialized already . the listener must be","add metaloglistener , locallogmanager , and related classes . these <nl> classes are used by the controller and broker to interface with the <nl> raft log . <nl> also add the controller interface . the implementation will be added in a separate pr .",1612998677,all comments in that pr should be addressed here . <nl> i will attempt to break the prs for the topology optimization effort into 0 prs total and will follow this general plan : . <nl> 0. this pr only adds the graph nodes and graph . the graph nodes will hold the information used to make calls to the when using the dsl . graph nodes are stored in the until the final topology needs building then the graph is traversed and optimizations are made at that point . there are no tests in this pr relying on the,0.9699863195419312
OpenAPITools_openapi-generator/7840,"add support for bearer auth . <nl> as far as i can tell , the bulk of the work to support bearer auth was already implemented to support oauth , but never explicitly turned on . i 've added a new sample which appears to be working correcltly , but i may have unwittingly overlooked something . <nl> changes : <nl> - added bearer auth to the security features for rust server <nl> - supplemented the basic auth condition in the context template to handled basic auth and bearer auth separately . <nl> - repurpose an exising sample to confirm the code generation works as expected . <nl> the new sample builds without problems , so the only possibly issue is that the underlying crate did n't implement this . however , there 's already bearer support in the client and it 's also used in the oauth support in the server , so i don ; t see why it would n't work . <cm-sep> update docs <cm-sep> update readme for bearer tokens <para-sep> an trait defining the api in rust . data types representing the underlying data model . a type which implements and issues http requests for each operation . a router which accepts http requests and invokes the appropriate method for each operation . <nl> the example server starts up a web server using the <nl> the example client provides a cli which lets you invoke <nl> this defaults to enabled and creates the basic skeleton of a server implementation based on hyper to create the server stack you 'll need to provide an implementation of the api trait to provide the server function . this defaults to enabled and creates the basic skeleton of a client implementation based on hyper the constructed client implements the api trait by making remote api call . this defaults to disabled and creates extra derives on models to allow ' transmogrification ' between objects of structurally similar types . <nl> pingget ] ( default_api.md # pingget ) | get * /ping | <nl> swagger : :has may be unused if there are no examples <nl> rt may be unused if there are no examples <nl> using simple https <nl> using http <nl> ! main binary entry point for ping_bearer_auth implementation . <nl> / create custom server , wire it to the autogenerated router , / and pass it to","as far as i can tell , the bulk of the work to support bearer tokens was already implemented to support oauth , but never explicitly turned on . this was unexpectedly simple , so i susect i may have missed something . <nl> changes : <nl> - added bearer token to the security features for rust server . <nl> - supplemented the basic auth condition in the context template to handled basic auth and bearer token separately . <nl> - repurpose an exising sample to confirm the code generation works as expected . <nl> the new sample builds without",1603970966,test scala akka petstore client in ci .,0.8191781640052795
ballerina-platform_ballerina-lang/26303,add runtime dependencies to runteststask <cm-sep> add testerina runtime jars to lib folder <para-sep> coverage dependencies,reference the jars directly when adding dependencies for the code coverage .,1602481770,this pr will include ballerina runtime jar ( ballerina-core ) jar content into the generated jar with jvmtarget and make it a standalone executable .,0.8966971635818481
OpenAPITools_openapi-generator/7517,add server url without variables to the test spec <para-sep> test host settings with invalid values,- add server url without variables to the test spec to ensure the code works without variables defined . <nl> fyi .,1601194311,"for java 's jersey2 , http response headers map is made case insensitive . <nl> jersey2 is using common apiexception mustache file and had to make a copy of it inside jersey2 directory so that other java clients are not effected with this change .",0.7929859757423401
elastic_elasticsearch/72136,vector tiles : add support for array serialization in meta layer . <nl> adds support for array serialization in meta layer <para-sep> the same max and min values are present in all buckets so min and max aggs return all buckets as max and mins as an array at the moment hence 0 additional values and 0 0 0 additional keys,adds support for array serialization in meta layer,1619140604,"if possible , improve search by looking for the already determined keys . <nl> change field extraction to use exact fields to handle text fields .",0.9627533555030823
Graylog2_graylog2-server/9220,add /authz/grants-overview endpoint . <nl> this will be helpful for debugging permission issues .,this will be helpful for debugging permission issues .,1603211780,exposes the existing cancellation of system jobs via the rest api and in the ui component for system jobs .,0.9200089573860168
vespa-engine_vespa/15450,"support marking configs as apply on restart <para-sep> returns true if this instance should be applied on restart , false if it should be applied immediately * / <nl> if some fields on the builder are null now , set them from the def . do recursively . if the targetdef has some schema incompatibilities , they are not handled here ( except logging in some cases ) , but in configinstance.serialize ( ) . <nl> is there a private field on the builder that matches this inner node in the def ? <nl> inner array ? check that list elems are configbuilder <nl> struct perhaps <nl> likely a config value mismatch . that is handled in configinstance.serialize ( ) ( error message , omit from response . ) <nl> not set on builder , if the leaf node has a default value , try the private setter that takes string",this replaces the hack using restartondeploy to defer config changes until restart when appropriate with a proper mechanism . <nl> next i want to remove internalredeploy as that distinction has become outdated by autoscaling .,1606255949,"implements the retrieval using the method with protobuf messages . the older docsum retriever over jrt+slime is not removed in this change set . when it is removed , can drop protobuf from its name .",0.9793327450752258
apache_flink/14944,"support 'load/unload module ' syntax in sql parser <cm-sep> support 'load/unload module ' operation in tableenvironment <cm-sep> support 'load/unload module ' syntax in sqlcli <para-sep> load module with module name as identifier <nl> load module with module name as reversed keyword <nl> load module with module name as literal <nl> unload module <nl> only blink planner supports load module syntax <nl> only blink planner supports unload module syntax <nl> only blink planner supports load module syntax <nl> can not use hive built-in function without loading hive module <nl> parses a load module statement . load module module_name [ with ( property_name=property_value , ... ) ] ; <nl> parses an unload module statement . unload module module_name ; <nl> parses a load module statement . load module module_name [ with ( property_name=property_value , ... ) ] ; <nl> parses an unload module statement . unload module module_name ; <nl> load module sql call . * / <nl> unload module sql call . * / <nl> find module by name <nl> operation to describe a load module statement . * / <nl> operation to describe an unload module statement . * / <nl> * / <nl> * / <nl> convert load module statement . * / <nl> convert unload module statement . * /","this pull request supports loading/unloading modules by syntax . <nl> this pr contains 0 commits <nl> - sha support syntax in both flink and hive parser . <nl> - sha support operation transformation in both old and blink planner . <nl> - sha support syntax in sqlcli . <nl> this change added tests and can be verified as follows : . <nl> - sha added tests in and to verify syntax support . <nl> - sha added tests in to verify operation transforming behaves correctly , and added tests in to verify module discovery and module loading/unloading behave corrrectly .",1613403974,"# # what is the purpose of the change . <nl> integrate file compaction to hive connector . <nl> - introduce <nl> - introduce hivecompactreader.java <nl> - integrate file compaction to hivetablesink and refactor it . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components )",0.9792218804359436
ballerina-platform_ballerina-lang/26418,fix the remotemethodcallactionnode <cm-sep> fix some formatting issues <cm-sep> fix preserve lines in workers <cm-sep> fix formatting issues and modify the parser tests class <cm-sep> fix the formatting in parser test assert files <cm-sep> update the json files <cm-sep> remove an unintended change <para-sep> b ; <nl> a ; <nl> b ; <nl> a ; <nl> more statements <nl> set indentation for braces . <nl> set the indentation for statements starting with query expression nodes . <nl> set indentation for braces . <nl> // uncomment to run a subset of test cases . <nl> the following tests need to be skipped since these contain intended extra minutiaes <nl> the following tests need to be enabled in the future,* fix formatting issues in the formatter core .,1603159197,fixes # . <nl> bir will keep referance to that function .,0.915926992893219
OpenAPITools_openapi-generator/7630,"rename httpsigningconfiguration.cs to httpsigningconfiguration.cs <para-sep> / httpsigning configuration <nl> / gets and sets the httpsigningconfiuration <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key / <nl> / / gets the http signing header / <nl> / / gets the hash algorithm sha256 or sha512 / <nl> / / gets the signing algorithm / <nl> / / gets the signature validaty period in seconds / <nl> / / gets the headers for httpsigning / / / / / <nl> the time when the http signature expires . the api server should reject http requests that have expired . <nl> the 'date ' header . <nl> the 'host ' header . <nl> the time when the http signature was generated . <nl> when the 'digest ' header is included in the http signature , the client automatically computes the digest of the http request body , per rfc 0 . <nl> the 'authorization ' header is automatically generated by the client . it includes the list of signed headers and a base64-encoded signature . <nl> hash table to store singed headers <nl> get the body <nl> concatinate headers value separated by new line <nl> / / gets the ecdsa signature / / / <nl> last readbyte was n't a removed zero , so back up a byte <nl> / / detect the key type from the pem file . / / key file path in pem format / <nl> this type of key can hold many type different types of private key , but here due lack of pem header <nl> todo : - update the key based on oid <nl> / gets the httpsigning configuration <nl> / httpsigning configuration <nl> / gets and sets the httpsigningconfiuration <nl> / class for httpsigning auth related parameter and methods <nl> / gets the headers for httpsigning / / / <nl> / / class for httpsigning auth related parameter and methods / <nl> / / initailize the hashalgorithm and signingalgorithm to default value / <nl> / /gets the api keyid / <nl> / / gets the key file path / <nl> / / gets the key pass phrase for password protected key","rename httpsigningconfiguration.cs to httpsigningconfiguration.cs to conform to naming convention , e.g .",1602213860,# # # pr checklist .,1.0
jenkinsci_jenkins/4618,"added a null check on the entrylist so that if the schema <nl> is not as expected , there is no nullpointerexception caused . <nl> ( cherry picked from commit sha ) <cm-sep> fix proxy form validation . <nl> ( cherry picked from commit sha ) <cm-sep> load build discarder configuration after restart . <nl> ( cherry picked from commit sha ) <cm-sep> * correct symptom of missing instance . <nl> * apply daniel 's proposal . <cm-sep> make checkanypermission work on non-accesscontrolled . <nl> ( cherry picked from commit sha ) <cm-sep> restrict newly introduced api <para-sep> otherwise it will perform no check and that problem is hard to notice . <nl> as this filter could be called during restart , this corrects at least the symptoms","backporting has started and the rc is scheduled for 0-0-0 . <nl> this is for the first time we do backporting review in github , partially to see how practical it will be . we are expected to learn and reflect back on the process as we go . <nl> please have look at the change proposed and rejected so we have a consensus of what goes in by 0-0-0 . <nl> - initially , i propose to backport : . <nl> - what remains to be discussed is the troika of issues introducing and fixing the read only config",1585905403,"as usual , for the pr build only . so do not merge .",0.9642637372016907
apache_beam/12661,"add export fhir resources to gcs method for healthcareapiclient . <para-sep> export resources to gcs . intended for use on non-empty fhir stores <nl> export resources to gcs . intended for use on non-empty fhir stores <nl> export fhir resources from a fhir store to new line delimited json files on gcs . * / <nl> represents the result of an export , including both the successful parsed messages , and invalid ones . <nl> a function that schedules an export operation and monitors the status . * / <nl> execute bundles to populate some data .",add export fhir resources to gcs io connector .,1598030827,this change also includes utilities to perform bq export jobs that do/do not flatten the output .,0.9809679388999939
elastic_elasticsearch/71008,fix geoip tests with windowsfs <cm-sep> unmute,in we tried to replace file that was still open . this is not a problem under linux and macos but windows does n't like it . <nl> it was caught by our ci with reproducible failures when was set up by lucene . <nl> now we skip one temp file and use directly which fixes this problem . <nl> marking as non-issue since the code was not released yet .,1617044094,"the retention run goes through a number of steps and can randomly take more than 10s . <nl> = > increased timeout to 30s like we did in other spots in this test . <nl> also , noticed that we had a hard wait of 10s in this test , removed it and adjusted following <nl> busy assert in a way that can deal with a missing snapshot ( from when the assert runs before <nl> the snapshot was put into the cs ) .",0.8746471405029297
netty_netty/10860,workaround possible jdk bug in sslengineimpl when using tlsv1.0 that lead to multiple notifications . <nl> motivation : . <nl> when using the jdks sslengineimpl with tlsv1.0 it sometimes returns handshakeresult.finished multiple times . this can lead to have sslhandshakecompletionevents to be fired multiple times . <nl> modifications : . <nl> - keep track of if we notified before and if so not do so again if we use tlsv1.0 <nl> - add unit test . <nl> result : . <nl> consistent usage of events <para-sep> there seems to be a bug in the sslengineimpl that is part of the openjdk that results in returning handshakestatus.finished multiple times which is not expected . this only happens in tlsv1.0 so lets ensure we only notify once in this case . this is safe as tlsv1.0 does not support renegotiation and so we should never see two handshake events . <nl> we expect 0 events as we have 0 connections and for each connection there should be one event on the server-side and one on the client-side .,workaround possible jdk bug in sslengineimpl when using tlsv1.0 that lead to multiple notifications . <nl> motivation : . <nl> when using the jdks sslengineimpl with tlsv1.0 it sometimes returns handshakeresult.finished multiple times . this can lead to have sslhandshakecompletionevents to be fired multiple times . <nl> modifications : . <nl> - keep track of if we notified before and if so not do so again if we use tlsv1.0 <nl> - add unit test . <nl> result : . <nl> consistent usage of events,1607700890,correctly report back when we fail to select the key material and ensure we wrap ( ... ) until everything was produced . <nl> motivation : . <nl> we need to let openssl know that we failed to find the key material so it will produce an alert for the remote peer to consume . beside this we also need to ensure we wrap ( ... ) until we produced everything as otherwise the remote peer may see partial data when an alert is produced in multiple steps . <nl> modifications : . <nl> - correctly throw if we could,0.974428653717041
elastic_elasticsearch/71781,"fix mount frozen index during rolling upgrade . <nl> if master ends up on a newer version than other cluster members , we <nl> can not apply the new index setting for shard limits . we skip doing so <nl> for now . <cm-sep> move experimental frozen to frozen shard limit . <nl> frozen indices created on version would not belong to the frozen shard <nl> limit group , now we convert them when last node is upgraded . <para-sep> this class upgrades frozen indices to apply the index.shard_limit.group=frozen setting after all nodes have been upgraded to version+ <nl> only want one doing this at a time , assume it succeeds and reset if not . <nl> 0 % of the time , this will be a noop , so precheck that before adding a cluster state update . <nl> let us try again later .","frozen indices created on version would not belong to the frozen shard <nl> limit group , now we convert them when last node is upgraded .",1618595944,"add a new boolean setting . <nl> that indicates the behavior of searchable snapshots when the generic <nl> setting is set to . <nl> defaults to false , meaning that when , <nl> searchable snapshots are not allocated.this ensures existing rolling restart procedures <nl> do not reallocate searchable snapshot shards to other nodes .",0.9781291484832764
elastic_elasticsearch/71998,only load one uk dictionary per jvm,"this commit makes the plugin use a fixed version of the <nl> ukrainianmorfologikanalyzer , until we merge a version of lucene that <nl> contains the upstream fix .",1618995626,"if an api name ( or components of a name ) overlaps with a reserved word in the programming language for an es client , then it 's possible that the code that is generated from the api will not compile . this pr adds validation to check for such overlaps . <nl> when i implemented this with the keywords from the above issue , some apis were immediately flagged , and this highlighted a subtlety with this check . some keywords are actually perfectly fine to use , depending on the context , and so i removed and from",0.9728302359580994
netty_netty/10981,introduce sslcontextoption which can be used for ' optional ' features in sslcontext implementations . <nl> motivation : . <nl> some of the features we want to support can only be supported by some of the sslcontext implementations . we should allow to configure these in a consistent way the same way as we do it with channel / channeloption . <nl> modifications : . <nl> - add sslcontextoption and add builder methods that take these <nl> - add opensslcontextoption and define two options there which are specific to openssl . <nl> result : . <nl> more flexible configuration and implementation of sslcontext <para-sep> if enabled tls false start will be enabled if supported . <nl> this allows to offload private-key operations if needed .,introduce sslcontextoption which can be used for ' optional ' features in sslcontext implementations . <nl> motivation : . <nl> some of the features we want to support can only be supported by some of the sslcontext implementations . we should allow to configure these in a consistent way the same way as we do it with channel / channeloption . <nl> modifications : . <nl> - add sslcontextoption and add builder methods that take these <nl> - add opensslcontextoption and define two options there which are specific to openssl . <nl> result : . <nl> more flexible configuration and,1611953867,motivation : <nl> the http/0 codec will synchronously respond to a settings frame with a settings <nl> ack before the application sees the settings frame . the application may need to <nl> adjust its state depending upon what is in the settings frame before applying <nl> the remote settings and responding with an ack ( e.g . to adjust for max <nl> concurrent streams ) . in order to accomplish this the http/0 codec should allow <nl> for the application to opt-in to sending the settings ack . <nl> modifications : <nl> - defaulthttp2connectiondecoder should support a mode where settings,0.9711032509803772
elastic_elasticsearch/72096,"we have recently split documentmapper creation from parsing mapping . there was one method leftover that exposed parsing mapping into documentmapper , which is generally not needed . either you only need to parse into a mapping instance , which is more lightweight , or like in some tests you need to apply a mapping update for which you merge new mappings and get the resulting document mapper . this commit addresses this and removes the method . <cm-sep> fix type","we have recently split documentmapper creation from parsing mapping . there was one method leftover that exposed parsing mapping into documentmapper , which is generally not needed . either you only need to parse into a mapping instance , which is more lightweight , or like in some tests you need to apply a mapping update for which you merge new mappings and get the resulting document mapper . this commit addresses this and removes the method .",1619102972,"almost every outbound message is serialized to buffers of 16k pagesize . <nl> we were serializing these messages off the io loop ( and retaining the concrete message <nl> instance as well ) and would then enqueue it on the io loop to be dealt with as soon as the <nl> channel is ready . <nl> 0. this would cause buffers to be held onto for longer than necessary , causing less reuse on average . <nl> 0. if a channel was slow for some reason , not only would concrete message instances queue up for it , but also",0.9647334218025208
elastic_elasticsearch/71856,this change exposes the newly introduced parameter <nl> in ingest . this parameter can be set by a set processor or a script processor .,this change exposes the newly introduced parameter <nl> in ingest . this parameter can be set by a set processor or a script processor .,1618847184,"this does not detect slowness in individual transport handler logic , <nl> this is done via the inbound handler logging already , but instead <nl> warns if it takes a long time to hand off the message to the relevant <nl> transport thread and then transfer the message over the wire . <nl> this gives some visibility into the stability of the network <nl> connection itself and into the reasons for slow network <nl> responses ( if they are the result of slow networking on the sender ) . <nl> example log lines : .",0.956135094165802
apache_shardingsphere/9857,refactor it engine <cm-sep> fix <para-sep> create or get container compose . <nl> get container compose . <nl> set container compose . <nl> checkstyle : off <nl> checkstyle : on,changes proposed in this pull request : <nl> - use more junit components/features instead of customization .,1616939963,"- add literal sql in xml driver file <nl> - remove sqlcaseid and sqlcaseloader <nl> - decouple with databasetypeenvironment , only init available database case . <nl> after refactor , integrate-test-case look like this .",0.9815189242362976
OpenAPITools_openapi-generator/8103,<para-sep> readformfilestotempfiles reads files array data from a request form and writes it to a temporary files <nl> readfileheadertotempfile reads multipart.fileheader and writes it to a temporary file <nl> readformfilestotempfiles reads files array data from a request form and writes it to a temporary files <nl> readfileheadertotempfile reads multipart.fileheader and writes it to a temporary file,"in addition to existing function a new one introduced returning a slice of . <nl> to avoid code duplication , common part related to reading and storing in temporary file moved to new function . <nl> updated to invoke corresponding function , depending on either single or multiple files are in a request . <nl> condition verifying the package import extended in with a slice of files type . <nl> replaced a temporary directory path with in call to make using the default directory . <nl> existing automated tests passed . no new tests added . <nl> built project locally",1607165468,- support when unmarshalling/marshalling json <nl> - add tests .,0.7709209322929382
elastic_elasticsearch/71808,"this pr adds the service account token name to a new top level field , ' token ' , <nl> to the authenticate response . for now , this field will not show unless the <nl> authenticating credential is a service account . <cm-sep> fix for 0.x quirks","this pr adds the service account token name in a new top level field , , to the authenticate response . for now , this new field is only shown when the authentication is for a service account .",1618807759,"date processor was incorrectly parsing week based dates as when a <nl> weekbased year was provided ingest module was thinking year was not <nl> on a date and was trying to applying the logic for type of <nl> dates . <nl> for testing ingest has to have access to isocalendardataprovider in <nl> order to correctly calculate week based dates with iso rules . <nl> date processor is also allowing users to specify locale parameter . it <nl> should be taken into account when parsing dates - currently only used <nl> for formatting . if someone specifies 'en-us ' locale ,",0.9483703970909119
confluentinc_ksql/6661,"add support for windowed sr-key joins <para-sep> where we know that the key will be semantically equivalent , but may be serialized differently ( thus ensuring all keys are routed to the same partitions ) <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :",this also fixes an issue where forced repartition allowed arbitrary repartitioning of tables . <nl> qtt .,1606165858,"ksql uses a statement rewritter to convert struct field dereferences into function calls . the rewrite is done for , and statements , but was missing . <nl> it is valid to execute on a query string , e.g . it is therefore important that the query within the statement has the same rewrites applied to it as would be applied should the statement be executed directly . <nl> suitable unit tests added .",0.9409953355789185
hazelcast_hazelcast/18357,revert ' make nearcacheconfig equal before and after it is used ' . <nl> this reverts commit sha . <para-sep> create copy of eviction config <nl> create copy of nearcache config and set eviction config,this reverts commit sha . <nl> copies nearcacheconfig and evictionconfig when they needs <nl> to be changed by nearcacheconfigaccessor so that the object <nl> on clientconfig/config does not change when used .,1614853771,"recent change removed that was responsible for <nl> providing metrics for . this changed to unconditionally <nl> register the implementer services in , which failed if the <nl> cache was not initialized ( if the is not present ) . therefore , <nl> all services made self-registering . they register themselves in <nl> if the datastructure metrics are enabled . there are two exceptions : the <nl> and that <nl> does n't check the value of the datastructure flag . <nl> also , an is fixed in 's <nl> provider method by checking if the distributed data structure counters are",0.9327006936073303
Graylog2_graylog2-server/9379,extend migration test with view and event definition entity permissions <cm-sep> fix view type detection for user permission migration . <nl> previously we created ' search ' grants for view permissions in users . <nl> this was not correct because a view can also be a dashboard . <nl> the migration is now lookin up the view in the database and creates a <nl> grant based on the view type . <para-sep> for views we need to load the database object to be able to determine if it 's a search or a dashboard .,previously we created ' search ' grants for view permissions in users . <nl> this was not correct because a view can also be a dashboard . <nl> the migration is now lookin up the view in the database and creates a <nl> grant based on the view type .,1604602483,"up until now , trying to generate a field chart on a non-numeric value failed , as the server did only try to calculate statistical aggregations for the field and that is not possible . anyway , we could still calculate the total and cardinality functions for those fields , as we do in the statistics analyzer . <nl> this pr changes how we treat non-numeric field charts , enabling users to generate graphs for cardinality and total . it is as well possible to stack them to other field charts , and add them to dashboards , just as",0.9443971514701843
pentaho_pentaho-kettle/7507,fixed issue with creating report using streaming html output and updated copyright data . <nl> this commit is a cherry-pick from master sha,fixed issue with creating report using streaming html output and updated copyright data . <nl> this commit is a cherry-pick from master sha,1593199378,new implementation of and for apache vfs 's would load resource of type .,0.8546913862228394
neo4j_neo4j/11239,"prefix index search via core api <cm-sep> fix bug in index suffix and contains queries with in-tx modified nodes <cm-sep> implement index exact , suffix and contains queries over core api <cm-sep> test string findnodes with and without a backing index . <cm-sep> implemented composite findnodes in core api <para-sep> other 0 numbers , regardless of whether they are encoded as integer , long , float , short , byte or double . returns all nodes having the label , and the wanted property values . if an online index is found , it will be used to look up the requested nodes . if no indexes exist for the label with all provided properties , the database will scan all labeled nodes looking for matching nodes . note that equality for values do not follow the rules of java . this means that the number 0 is equals to all other 0 numbers , regardless of whether they are encoded as integer , long , float , short , byte or double . same rules follow character and string - the character ' a ' is equal to the string ' a ' . finally - arrays also follow these rules . <nl> returns all nodes having the label , and the wanted property values . if an online index is found , it will be used to look up the requested nodes . if no indexes exist for the label with all provided properties , the database will scan all labeled nodes looking for matching nodes . note that equality for values do not follow the rules of java . this means that the number 0 is equals to all other 0 numbers , regardless of whether they are encoded as integer , long , float , short , byte or double . same rules follow character and string - the character ' a ' is equal to the string ' a ' . finally - arrays also follow these rules . <nl> returns all nodes having the label , and the wanted property values . if an online index is found , it will be used to look up the requested nodes . if no indexes exist for the label with all provided properties , the database will scan all labeled nodes looking for matching nodes . note that equality for values do not follow the rules","this pr bring core api up to date with underlying index capabilities . the added methods only rely on functionality which is anyway required by cypher , so it should not constrain future product development . <nl> changelog : extended core api with more variants of findnodes : string prefix , suffix and contains queries on single property indexes , and exact seeks in composite indexes .",1520956939,"following procedures and user-defined functions we are still missing the ability for users to create there own aggregation functions . this pr attempts to fill in that gap . <nl> proposed syntax . <nl> - user-defined aggregation functions are called just like normal aggregation functions , e.g . <nl> - just like user-defined functions , aggregate functions are also read only but can have access to a read-only etc . <nl> - compiled runtime support is in progress but not part of this pr",0.9876538515090942
jenkinsci_jenkins/4724,user with manage permissions can access node monitoring . <nl> and submit its configuration . <para-sep> read access <nl> read and manage <nl> jenkins.read can access /computer but not /computer/configure <nl> the ' node monitoring ' link in the sidepanel is not visible <nl> jenkins.manager can access /computer and /computer/configure <nl> the ' node monitoring ' link in the sidepanel is visible <nl> and the ok ( save ) button is visible,* : users with manage permission can configure node monitoring,1589376726,"example : . <nl> it seems that users occasionally wonder why their installers ' do n't work ' . i 'd also print the label expression to be extra helpful , but this may be misleading as can be overridden .",0.9250286817550659
vespa-engine_vespa/16239,buffer file output <cm-sep> drop buffered pages for old and compressed file <cm-sep> close log handler on component graph deconstruction <para-sep> file output stream that signals to kernel to drop previous pages after write * /,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1611689306,i plan to use a feature flag so we can switch between these versions with shorter turnaround and without breaking builds for such a long time,0.9645722508430481
OpenAPITools_openapi-generator/8048,"implemented the psdata property for module manifest file ( tags , licenseuri , projecturi , iconuri , releasenotes )","implemented the psdata property for generated module manifest file . user can specify the following property in config file , <nl> tags <nl> licenseuri <nl> projecturi <nl> iconuri <nl> releasenotes .",1606717671,0. added comments for better understanding to the deserialize method raised in the previous pr .,0.9360339641571045
jenkinsci_jenkins/4950,"allow manage to restart and safe-restart jenkins . <para-sep> given a jenkins with 0 users : administer , manage and read <nl> when asking for restart or safe-restart then manage and administer are allowed but not read <nl> we should assert that cli result is 0 but as restart is not allowed in jenkinsrule , we assert that it has tried to restart .",allow user with jenkins.manage permission to restart and safe restart jenkins,1601297248,"- avoid numberformatexception when a symlink is used as artifact <nl> - display a ' 0 b ' instead of nothing + exception thrown <nl> - the page was displayed ' correctly ' before , just the console log that was flooded . <nl> * internal : prevent an stacktrace to be displayed in log when a symlink is archived as artifact . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . ) <nl> - [ n/a ] appropriate autotests or explanation to why this change has no tests",0.9420849084854126
apache_druid/10422,add light weight version /druid/coordinator/v1/lookups/nodestatus <para-sep> lookups to load per host by version,using will instead just include the 'version ' string instead of the complete lookup json spec : . <nl> the new parameter defaults to true if not set to preserve existing behavior,1600857072,"i noticed this looking into the , after noticing if i set a breakpoint at a particular place that an underlying s3 file stream was not being closed when the timeout occurred . looking closer , this also occurs with the last inner iterator of the call to , which is also not closed . the test has been modified to ensure that close is called on all closeable iterators , and fails prior to the changes of this pr . the added test also covers the case when the outer iterator is closed early",0.9634178876876831
OpenAPITools_openapi-generator/7271,"files is now path relative with no prefixes . <nl> some java implementations do n't honor .relativize documentation fully . <nl> when outdir is /a/b and the input is /a/b/c/d , the result should be c/d . <nl> some implementations make the output ./c/d which seems to mix the logic <nl> as documented for symlinks . so we need to trim any / or ./ from the start , <nl> as nobody should be generating into system root and our expectation is no ./ . <nl> this resolves regeneration issues for those on such java <nl> implementations , although we 've not been able to track down the exact <nl> vendor or configurations which might lead to these differences . <para-sep> some java implementations do n't honor .relativize documentation fully . when outdir is /a/b and the input is /a/b/c/d , the result should be c/d . some implementations make the output ./c/d which seems to mix the logic as documented for symlinks . so we need to trim any / or ./ from the start , as nobody should be generating into system root and our expectation is no ./ <nl> ensure that windows outputs same files format","some java implementations do n't honor .relativize documentation fully . <nl> when outdir is /a/b and the input is /a/b/c/d , the result should be c/d . <nl> some implementations make the output ./c/d which seems to mix the logic <nl> as documented for symlinks . so we need to trim any / or ./ from the start , <nl> as nobody should be generating into system root and our expectation is no ./ . <nl> this resolves regeneration issues for those on such java <nl> implementations , although we 've not been able to track down the exact <nl>",1598109645,"add error output to the log so that we can make sure why the error occured , when the command passed via ruby_post_process_file failed . <nl> before : . <nl> after : <nl> the error output shows why rubocop resulted in error .",0.9103752374649048
OpenAPITools_openapi-generator/8049,fix port missingin oas 0 spec <cm-sep> update samples,todo : will add a test case shortly .,1606742649,"0 . ) apiclient already defines and configures an objectmapper to not fail on unknown properties , but it is not used when parsing the response . the fix uses the pre-configured object mapper instead of the vertx default one . <nl> 0 . ) when an operation has no response ( or just ones without content ) , the accept array passed to apiclient is emtpy . this makes the null check in apiclient useless , as it still tries to set a null accept header , which is refused with an npe . amend the check with .length",0.8414278626441956
elastic_elasticsearch/71380,add delete and list sub-commands for file token cli <para-sep> invalid principal <nl> invalid token name <nl> non-exist token <nl> the file should not be created if not exists in the first place <nl> invalid principal <nl> delete all tokens <nl> list should not create the file,this pr adds the implementations for deleting and listing file tokens using the cli tool .,1617749153,"this commit changes how cache files synchronization interacts with <nl> the persistent cacge in searchable snapshots . before this change it <nl> was possible that synchronization reintroduces information about <nl> an evicted cache file in the persistent cache lucene index . <nl> this commit introduces an queue of cache file events that are <nl> periodically processed by the cache synchronization method . the <nl> events refer to a specific cache file and a type of event ( deletion or <nl> fsync needed ) that must be processed by the cache synchronization <nl> method , which in turn applies the appropriate",0.9773625731468201
ballerina-platform_ballerina-lang/25966,"fix merge conflict <cm-sep> remove method scope from function type symbol <cm-sep> suport object method delegation <para-sep> process nodes that are not lambdas <nl> can we cache this ? <nl> when we are supporting non var ref exprs we need to create a def , assign , get the ref and use it here . <nl> this is used to keep the tempary var def , when the receiver is a expression we need to have a vardef in encl invocable and we can cosider that receiver is taken as a closure var . <nl> env.enclpkg.lambdafunctions.add ( lambdafunction ) ; <nl> todo : check and remove this bit here <nl> object member functions are inherently final <nl> object final field updates will be analyzed at dataflow analysis .","with this change , we can extract out object methods as standalone functions , the receiver will be stored as a closure variable .",1600674582,this pr introduces the following changes : <nl> - invokes the user specified module function after the synthesized init function <nl> - updates module and function return types to . <nl> to dos : .,0.9712940454483032
jenkinsci_jenkins/4922,add cloudstate to be passed to cloud # provision and cloud # canprovision methods . <nl> this gives more insight to the cloud implementation to ongoing <nl> provisioning operations and helps implement better control on the number <nl> of nodes provisioned when provisioning limits are defined . <para-sep> calls the given supplier if the method defined on the base type with the given arguments is overridden in the given derived type .,this gives more insight to the cloud implementation to ongoing <nl> provisioning operations and helps implement better control on the number <nl> of nodes provisioned when provisioning limits are defined . <nl> * cloud implementations are given more context about ongoing planned nodes,1598949951,"since jenkins version we can enable remoting work directories . <nl> * on : all jnlplauncher implementations use the default constructor , we are safe . <nl> config : . <nl> main page : . <nl> * entry 0 : enable remoting work directories by default for newly created agents with jnlp ( java web start launcher ) . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9678922891616821
OpenAPITools_openapi-generator/7611,fix default value for referenced schemas and enums <cm-sep> generate samples,default values for referenced schemas were n't being set . this fixes it . also uses the constant definition for enum default values instead of the plain value .,1601974645,-added readme file <nl> -add parsefromjson function in mustache <nl> -modified variable generation for boolean and enum type <nl> -changed data type array to list <nl> -some minor fixes in api header body and model header body .,0.8917357921600342
ballerina-platform_ballerina-lang/24242,fail-safe mechanism for the error recorvery . <nl> add a limit for the number of times parser tries to recover staying on the same token index . <nl> this will prevent parser going to infinite loops . <para-sep> limit for the number of times parser tries to recover staying on the same token index . this will prevent parser going to infinite loops . <nl> else fall through,this pr introduces an initial approach fail-safe mechanism for such cases until those invalid logics are fixed .,1592371915,"this commit will fix hover , goto definition and find all references issues for object .",0.9164836406707764
apache_pulsar/9306,prevent ledgers info change without write to zk succeed . <cm-sep> add unit test to prevent fake positive when offload failed . <para-sep> should not set complete when,"in our current code , in offloading context may set true even sync metadata to zookeeper failed , which may lead to more fatal error like data in bookkeeper will be deleted but other managed ledger will see data not offloaded and try to read from bookkeeper . <nl> this pr make sure local ledger info will be updated after zookeeper updated .",1611564382,topicpatternsubscription is not supported on proxy . <nl> - add gettopicsofnamespace support at the proxy <nl> - add a unit test to proxytest to cover regex subscription . <nl> regex subscription is supported at the proxy .,0.9470202922821045
apache_incubator-pinot/5870,"adding integration test for null handling from realtime source <para-sep> integration test that creates a kafka broker , creates a pinot cluster that consumes from kafka and queries pinot . the data pushed to kafka includes null values . <nl> start the pinot cluster <nl> start kafka <nl> unpack the avro files <nl> create and upload the schema and table config <nl> push data into kafka <nl> set up the h2 connection <nl> initialize the query generator <nl> wait for all documents loaded",no <nl> no . <nl> no,1597461615,"this pull request is a part of the alert redesign . this feed aggregates the candidates from anomaly fetchers , applying filters and output the anomaly results to the next alert component , e.g . grouper . there are several alternative feeds can be designed . the basic one is the union feed . more complicated feed can realize the requirements like anomaly re-alert if anomaly gets more severe , and so on .",0.976872980594635
elastic_elasticsearch/71180,"remove test skip after backport . <cm-sep> optimize lone single bucket . <nl> this optimizes the agg when there is a single bucket <nl> and no sub-aggregations . we expect this to happen from time to time when <nl> the buckets are larger than a day because folks often use ' daily ' <nl> indices . <nl> this was already fairly fast , but using the metadata makes it 10x <nl> faster . something like 98ms becomes versionms . nice if you can get it ! <cm-sep> more tests <para-sep> add a sub-agg so we do n't get to use metadata . that 's great and all , but it outputs less debugging info for us to verify . <nl> unwrap constant score because it gets in the way of us understanding what the queries are trying to do and we do n't use the score at all anyway . effectively we always run in constant score mode . <nl> if we do n't have any info then there are n't any values anyway . <nl> range query covering all values in the index is rewritten to exists <nl> exists queries convert to matchnone if this is n't defined <nl> exists queries convert to matchnone if this is n't defined <nl> exists queries convert to matchnone if this is n't defined","this optimizes the agg when there is a single bucket <nl> and no sub-aggregations . we expect this to happen from time to time when <nl> the buckets are larger than a day because folks often use ' daily ' <nl> indices . <nl> this was already fairly fast , but using the metadata makes it 10x <nl> faster . something like 98ms becomes versionms . nice if you can get it !",1617282051,"this allows pipeline aggregations to participate in the up-front rewrite <nl> phase for searches , in particular , it allows them to load data that they <nl> need asynchronously .",0.9538445472717285
confluentinc_ksql/6292,"first pass of json key support . <nl> first pass of adding qtt tests around the json key format , including adding tests for and types , which is the first time they 've been used as a key column type . <nl> the test around a json key is currently disabled , due to a limitation of qtt which reads doubles as . code works , just need to enhance qtt to do the right thing . <nl> commit includes a fix in to ensure no key unwrapping is set if there is no key , plus refactored , combining the two public methods . <cm-sep> historical plans <para-sep> given : <nl> when : <nl> then ( did not throw ) : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","first pass of adding qtt tests around the json key format , including adding tests for and types , which is the first time they 've been used as a key column type . <nl> commit includes a fix in to ensure no key unwrapping is set if there is no key , plus refactored , combining the two public methods . <nl> usual .",1600942278,"add config for specifying the maximum number of persistent queries that may run simultaneously , in interactive mode . ( headless mode is unaffected . ) defaults to no limit . <nl> the added config is a compatabilitybreakingconfigdef so that each query is associated with the value of the limit at the time that the query was acknowledged . as a result , when queries are restored from the command topic ( e.g. , after a server is bounced ) , the set of previously running queries will be restored , regardless of whether the value of the newly added",0.9514225125312805
vespa-engine_vespa/16661,write nodes in correct state <cm-sep> keep allocation in dirty <para-sep> application never activates and nodes are dirtied and readied . expirer moves load balancer to inactive after timeout <nl> the surplus node is dirtied and then readied for new allocations,"in future , we probably want to require allocation for all tenant nodes , always . but that requires a lot of rewriting tests , at the moment : <nl> * 0/0 tests fail if this requirement is placed in constructor , a lot of it is due to allocation not changing allocation and state at the same time . <nl> * 0/0 tests fail if checking at the time of writing/reading from zk . most due to various testers trying to allocate non-dynamically . <nl> this change should be ok with host-admin , only notable consequence that i 've",1614177362,this avoids starvation when an upgrade takes so long that it does n't <nl> complete until the next version is released . <nl> this also removes rescheduling of upgrades which has not commpleted after 0 hours ; <nl> retrying should be on the job level only .,0.9458746910095215
ballerina-platform_ballerina-lang/24117,migrate jsonutils and xmutils to new table syntax,> add unit tests . <nl> > enable previously disabled test cases .,1592153004,"with this pr , balo constants related test cases also got fixed .",0.9543356895446777
apache_kafka/9733,": fix 0 issues in eosbetaupgradeintegrationtest <para-sep> we do n't expect any exception thrown in stop case <nl> should only have our injected exception or commit exception , and 0 exceptions for each stream <nl> the exception wo n't cause the test fail since we actually ' expected ' exception thrown and failed the stream . so , log to stderr for debugging when the exception is not what we expected , and fail in the main thread","fixed some issues : <nl> 0. test failed with the error message : . <nl> so , if we only wait for the state to be , it might enter state later , and cause that we ca n't get store successfully . <nl> 0. we setuncaughtexceptionhandler , but did n't handle it well . before , we expected the uncaught exception only got 0 , but actually , we 'll get 0 here ( 0 injected exception , 0 injected commit exception ) . so , we saw many messages in stderr output , which is not good for",1607678866,according to a parameter is passed to configprovider with syntax ' config.providers. { name } .param. { param-name } ' . currently abstractconfig allows parameters of the format ' config.providers. { name } . { param-name } ' . with this fix abstractconfig will be consistent with syntax .,0.9161384701728821
ballerina-platform_ballerina-lang/23546,add doc gen to/from json <cm-sep> add excludeindex <cm-sep> add to/from json <cm-sep> add to/from json <cm-sep> add to/from json <para-sep> validation and decide source root and source full path <nl> generating api docs through a json file <nl> disable deprecated verbose logs from docerina <nl> generate project model <nl> sort modules by module path <nl> generate index.html for the project <nl> used to convert path objects to json .,0. create a json contatining all the data required to generate documentation .. <nl> 0. generate documentation using a given json .,1590582368,the desugar phase prepares the ast for code generation and the code gen phase generates the binary . this design introduces another phase called annotation processing after the code analysis phase . <nl> please note that the test cases are pending . i will add them shortly .,0.9747878909111023
netty_netty/11036,"introduce asbytebuf interface . <nl> motivation : <nl> to make it possible to experiment with alternative buffer implementations , we need a way to abstract away the concrete buffers used throughout most of the netty pipelines , while still having a common currency for doing io in the end . <nl> modification : <nl> - introduce an asbytebuf interface , that allow arbitrary objects to convert themselves into bytebuf objects . <nl> - every place in the code , where we did an instanceof check for bytebuf , we now do an instanceof check for asbytebuf . <nl> - bytebuf itself implements asbytebuf , and returns itself from the asbytebuf method . <nl> result : <nl> it is now possible to use netty with alternative buffer implementations , as long as they can be converted to bytebuf . <nl> this has been verified elsewhere , with an alternative buffer implementation .","motivation : <nl> to make it possible to experiment with alternative buffer implementations , we need a way to abstract away the concrete buffers used throughout most of the netty pipelines , while still having a common currency for doing io in the end . <nl> modification : <nl> - introduce an asbytebuf interface , that allow arbitrary objects to convert themselves into bytebuf objects . <nl> - every place in the code , where we did an instanceof check for bytebuf , we now do an instanceof check for asbytebuf . <nl> - bytebuf itself implements asbytebuf , and",1614175751,"motivation : . <nl> modifications : . <nl> the attribute has been added to the defaultcookie class as a quick fix since adding new methods to the cookie interface would be backwards-incompatible . <nl> servercookieencoder and clientcookiedecoder have been updated accordingly to process this value . no validation for allowed values ( lax , none , strict ) has been implemented . <nl> result : <nl> response cookies with the samesite attribute set can be read or written by netty .",0.8627439737319946
ballerina-platform_ballerina-lang/26152,"add debugging support to view global variable scope <cm-sep> update variable evaluation support for global variables <cm-sep> update debugger test framework and resources <cm-sep> refactor local variable test utils <cm-sep> add variable and expression evaluation tests for global variables <cm-sep> add minor fixes <cm-sep> rectify a debugger adapter protocol violation <para-sep> creates local variable scope . <nl> creates global variable scope . <nl> if frameid = 0 , returns local variables . <nl> searches within global variable scope . <nl> if no results found , searches within local variable scope . <nl> returns full-qualified class name for a given ballerina jvm generated class name .",- updates expression evaluation engine to support global variables . <nl> - adds integration tests for global variable related contexts . <nl> please note that few of the test scenarios are currently disabled due to the following minor runtime issues which were captured while working the $ subject and should be enabled once the relevant fixes are merged to the runtime .,1601377891,e.g : ballerina grpc -- input=.proto -- mode=proxy .,0.9717243313789368
elastic_elasticsearch/71473,"move voting only role to server . <nl> this commit moves the voting only role to server , as part of the effort <nl> to remove the ability for plugins to add roles . <para-sep> validate this role against all configured roles .","this commit moves the voting only role to server , as part of the effort to remove the ability for plugins to add roles .",1617887106,"in 0.x the close indices api defaults to but <nl> from version it will default to respecting the index settings instead . this <nl> commit introduces the value for this parameter on this <nl> api allowing users to opt-in to the future behaviour today , and starts <nl> to emit a deprecation warning for users that use the default .",0.9574699997901917
apache_kafka/10136,optimize import <cm-sep> : memo : import class that used in annotations . <cm-sep> : rewind :,more detailed description of your change <nl> fix this : . <nl> summary of testing strategy ( including rationale ) <nl> none .,1613534269,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.8369210958480835
ballerina-platform_ballerina-lang/23507,add service constructor expression <cm-sep> add service constructor exression test <para-sep> parse service-constructor-expr . service-constructor-expr : = service service-body-block service-body-block : = { service-method-defn * } service-method-defn : = metadata function identifier function-signature method-defn-body <nl> this is a generated internal syntax tree node . <nl> this is a generated syntax tree node . <nl> this is a generated tree node modifier utility . <nl> test parsing service constructor expression . <nl> recovery test,add service constructor expression . <nl> service-constructor-expr : = service service-body-block <nl> service-body-block : = { service-method-defn * } <nl> service-method-defn : = <nl> metadata <nl> function identifier function-signature method-defn-body .,1590492651,add local-type-defn-stmt support for incremental parser .,0.9924895763397217
Alluxio_alluxio/12357,change the output of validation tools to an object <para-sep> a container class for the validation results . <nl> set validation results . <nl> get validation result .,change the output to a validation object so that json serialization can handle it better .,1603232454,change update check to check every 0 days instead of once when master starts .,0.9313216209411621
Alluxio_alluxio/11426,fix default metadata sync executor sizes <para-sep> sync executors should allow core threads to time out,"previously , if a machine was too small the master can fail to start up . <nl> the min pool size could have been greater than runtime.getruntime ( ) .availableprocessors ( ) which would cause an illegalstateexception to be thrown",1589330803,"changes the default metastore to heap for integration tests and multi-cluster tests . we currently do not support lifecycle management for the metastore , which causes problems when trying to reinit a rocks metastore .",0.8846024870872498
confluentinc_ksql/6635,"force repartition on joins with sr-enabled key formats <cm-sep> move common methods to new util <cm-sep> historic plans <para-sep> evaluates whether this node should repartition , based on the desired key format <nl> node is repartitioning already : <nl> parent node can handle any key format change","this pr forces repartitions on both sources of joins with sr-enabled key formats . this is in order to ensure that the same schema registry schema is used on both sides of the join , so the user will not experience unexpected join misses due to logically equivalent data being sent to different topic partitions because the serialized bytes differ ( due to differences in schema or schema id ) . by forcing repartitions , the schema generated by ksqldb is used for data on both sides of the join , which is consistent given logical schema , key format",1605644591,"currently , qtt and the historical plans we capture to ensure backwards compatibility only test internal topic names _if_ the contents of those internal topics are explicitly tested in the qtt test case . <nl> with this change , the historic plans will contain post condition that check to ensure all topics the topology produced output to remain the same on subsequent test runs . these post conditions will check : . <nl> * the name of the topic <nl> * the schema of data produced to the topic <nl> * the key and value format <nl> * the partition",0.981626033782959
apache_shardingsphere/9583,password exception message <cm-sep> can not load table exception message,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - make exception message more detail <nl> -,1614786375,0、重新加载配置时调用executorengine的关闭方法存在一定时间的空档期，导致sj无法提交新的任务修改为先重建executorengine然后再关闭 <nl> 0、修改直接调用shutdownnow来强制取消正在执行的任务为先调用shutdown等待5秒后才强制取消正在执行的任务 <nl> 0、原来close失败抛异常修改为使用线程来继续调用shutdownnow方法 .,0.9159753322601318
OpenAPITools_openapi-generator/8025,"add basic integration test pom . <nl> this basically just fetches dependencies , runs the built_value generator and empty test cases . even running empty test cases is more than is currently possible and at least finds compile errors . <nl> there are compile errors atm which need to be fixed . <cm-sep> fix missing builtset import in models that use enums <cm-sep> fix compile error when the return type is a map . <nl> * the compile error was in which needs to be <nl> * use final instead of var in response handling <para-sep> only process the following type ( or we can simply rely on the file extension to check if it 's a dart file ) <nl> enums are generated with built_value and make use of builtset <nl> / tests for { { { classname } } } <nl> { { { . } } } <nl> { { { . } } } <nl> { { # returntype } } future { { /returntype } } { { ^returntype } } future { { /returntype } } { { { operationid } } } ( { { # allparams } } { { # required } } { { { datatype } } } { { { paramname } } } { { ^-last } } , { { /-last } } { { /required } } { { /allparams } } { { # hasoptionalparams } } { { { # allparams } } { { ^required } } { { { datatype } } } { { { paramname } } } { { ^-last } } , { { /-last } } { { /required } } { { /allparams } } } { { /hasoptionalparams } } ) async <nl> todo <nl> tests for { { { classname } } } <nl> { { { description } } } <nl> { { { datatype } } } { { { name } } } { { # defaultvalue } } ( default value : { { { . } } } ) { { /defaultvalue } } <nl> todo <nl> tests for apiresponse <nl> int code ( default value : null ) <nl> todo <nl> string type ( default value : null ) <nl> todo <nl> string message ( default value : null ) <nl> todo <nl> tests for category <nl>",this pr adds a basic integration test to the dart-dio generator . <nl> there are no real tests for the moment but openapi test templates are added which generate empty test cases . running these empty test cases at least ensures that the generated code compiles . <nl> the pr also fixes 0 compile errors that are now catched due to the tests .,1606324178,make map to to make it useful in yard comment .,0.8453574776649475
Alluxio_alluxio/11069,disable trace and options on rest services <para-sep> disable specified methods on rest services,disable these methods on rest services since they 're not commonly used and they flag in network vulnerability scans,1582927501,i have tested with : mvn clean package -.0 -pspark -rf : alluxio-core-client,0.9234494566917419
elastic_elasticsearch/72443,dry up hashing bytesreference . <nl> dries up the efficient way to hash a bytes reference and makes use <nl> of it in a few other spots that were needlessly copying all bytes in <nl> the bytes reference for hashing . <para-sep> updates the given digest with the given bytes reference and the returns the result of the digest .,dries up the efficient way to hash a bytes reference and makes use <nl> of it in a few other spots that were needlessly copying all bytes in <nl> the bytes reference for hashing .,1619680815,... just a random find from working on other things : . <nl> we were not consistent in checking for node roles before adding listeners . <nl> in some cases we did check the necessity of a cs listener and in others we did not . <nl> this commit fixes a number of cases of redundant listeners that do n't apply to all node roles .,0.9353998899459839
apache_beam/13550,"backport samza runner changes . <nl> 0. samza version support <nl> 0. prepare for async pardo ( ) <nl> 0. memory usage optimization for event time timers <nl> 0. teststream support <para-sep> todo ( ) <nl> re-enable the test after samza runner supports same state id across dofn ( s ) . <nl> * / <nl> fused pipeline proto . <nl> the pipeline option coming from sdk will set the sdk specific runner which will break serialization so we need to reset the runner here to a valid java runner <nl> todo ( ) : extend jobserverdriver <nl> create services <nl> perform some bundling related validation for pipeline option . visible for testing . <nl> todo : once samza supports a better thread pool modle , e.g . thread per-task/key-range , this can be supported . <nl> todo : can we get rid of this class ? right now the samzapipelineoptionsvalidator would force the pipeline option to be the type samzapipelineoption . ideally , we should be able to keep passing samzaportablepipelineoption . alternative , we could merge portable and non-portable pipeline option . <nl> get fs token path for portable mode . * / <nl> max watermark has been reached for this reader . <nl> send an max watermark message and an end of stream message to the corresponding ssp to close windows and finish the task . <nl> send the max watermark to force completion of any open windows . <nl> some events require that we post an envelope to the queue even if the interrupt flag was set ( i.e . during a call to stop ) to ensure that the consumer properly shuts down . consequently , if we receive an interrupt here we ignore it and retry the put operation . <nl> runs on yarn am , execute planning and launches jobcoordinator . * / <nl> loader for the beam yarn container to load job model . * / <nl> factory for the beam yarn container to get loader to load job model . * / <nl> 0. propagates the watermark to downstream dag , if all the previous bundles have completed . a bundle is considered complete only when the outputs corresponding to each element in the bundle have been resolved and the watermark associated with the bundle ( if any ) is propagated downstream . the output of an element is considered resolved",0. samza version support <nl> 0. prepare for async pardo ( ) <nl> 0. memory usage optimization for event time timers <nl> 0. teststream support,1607989732,,0.0
apache_flink/15211,[ sql client ] fix unstable clitableauresultviewtest <para-sep> prevent busy loop <nl> get ctrl+c from terminal and fallback,"before explain the reason why test fails , i will just describe the logic in the test . there are 0 parts in the test : , and . the will requst the data from the and send the data to to print . when request data from , the will memorize how many times reads . for simplicty , we call this variable as . <nl> in the test , if is larger than 0 , we will cancel the . it 's possible read the data from the but the terminal have n't printed . <nl> therefore ,",1615787683,"# # what is the purpose of the change . <nl> version in yaml/hivecatalog needs to be consistent with the dependencies version . there are three places : version in metastore , version in dependencies , version in yaml/hivecatalog , users are easy to make mistakes . <nl> - add constructor without hive version to hivecatalog and hivemodule <nl> - remove hive version in document . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl>",0.8607686758041382
elastic_elasticsearch/71118,[ rest api compatibility ] add transformation for simple text replaces . <nl> this commits adds a simple textual replace transformation for rest api <nl> compatibility testing <para-sep> replaces all the values of a match assertion for all project rest tests . for example ' match ' : { ' _type ' : ' foo ' } to ' match ' : { ' _type ' : ' bar ' } replaces all the values of a is_true assertion for all project rest tests . for example ' is_true ' : ' value_to_replace ' to ' match ' : ' value_replaced ' <nl> replaces all the values of a is_true assertion for all project rest tests . for example ' is_false ' : ' value_to_replace ' to ' match ' : ' value_replaced ',this commits adds a simple textual replace transformation for rest api compatibility testing . <nl> it allows to replace simple key-value pairs . for instance used in this pr to replace and . <nl> with .,1617197397,"pulled over more tests from eql to tests that functions are folded correctly . it 's similar in approach to our integration tests , but a little simpler since we do n't have to go searching for events that match . there 's also the same case_sensitive and case_insensitive toggles for tests that only work with one configuration . if neither of those are true , then the test will be checked against both , because it 's assumed that the case already matches .",0.9806839823722839
apache_camel/4896,: add usepublisherconnection option <para-sep> use a separate connection for publishers and consumers . the option is a : & lt ; code & gt ; boolean & lt ; /code & gt ; type . default : false group : producer <nl> use a separate connection for publishers and consumers . the option will be converted to a & lt ; code & gt ; boolean & lt ; /code & gt ; type . default : false group : producer,allow developers to configure usepublisherconnection property of the underlying rabbittemplate,1610811842,"hi , . <nl> we met a condition in production where the connection factory of rabbitmq wo n't recover ( when isautomaticrecoveryenabled is set to true ) . it 's easily reproducible by calling the ' .close ( ) ' method on it . <nl> the current code would always returns the same connection , not re-establishing it , if isautomaticrecoveryenabled is enabled . <nl> our solution , based on the fact we just have ' isopen ' to check the state of the channel/connection was to re-establish the connection in the rabbitmqconsumer even if ' isautomaticrecoveryenabled ' is enabled",0.8976626992225647
ballerina-platform_ballerina-lang/26526,"add new api methods to help with unit test compilation and run <cm-sep> remove unwanted check for symbol presence <cm-sep> add orgname is annonymous check method <cm-sep> write langlib jars to jar cache <cm-sep> add projectapi based unit test build , run helper classes <cm-sep> add a temporary fix to reset build env context <cm-sep> update langlib tests to run on projectapi based compilation <cm-sep> update error message <cm-sep> use direct jar cache path <cm-sep> move langlib load and cache creation to a seperate gradle file <cm-sep> add compile a module legacy method to support existing unit tests <para-sep> def path = ' $ builddir/bir-cache ' from configurations.balxbir.files into path dependson configurations.baldoc from configurations.baldoc.files into ' $ builddir/api-docs ' exclude ' index.html ' exclude ' html-template-resources ' exclude ' syntax-highlighter ' balo configurations.distbal.files source configurations.balsource.files sourcebalx configurations.balxsource.files <nl> todo this is a temporary fix the clean compiler context instance <nl> utility methods for do result validations . <nl> assert an error . <nl> assert an error ( without error message ) . <nl> validate if given text is contained in the error message . <nl> validate if at least one in the given list of texts is contained in the error message . <nl> assert a warning . <nl> helper to drive test source compilation . <nl> utility methods for run ballerina functions . <nl> invoke a ballerina function . <nl> this is done temporarily , until blocks are added here for all possible cases . <nl> this method takes care of invocation on jballerina and the mapping of input and output values . it will use the given bvm based argument and function details to invoke on jballerina and return results as bvalues to maintain backward compatibility with existing invoke methods in brunutil . <nl> this method handles the input arguments . <nl> this method handles the input arguments and output result mapping between bvm types , values to jvm types , values . <nl> this method converts the compile time btype and the value to to jvm runtime value . <nl> this method converts the runtime time btype and the value to jvm runtime value . <nl> this methods returns the jvm type for the given compile time btype . <nl> this methods returns the jvm type for the given runtime time btype . <nl> todo : using reason type as string is just a hack to get",this also removes the old bale generation gradle references from langlib build files .,1603373120,"these changes verified with activemq , ballerina message broker . <nl> jms queue requestor : .",0.9278046488761902
Alluxio_alluxio/11396,ozone as a under file system of alluxio,"this pr introduces a new top-level ufs module for compiling an ozone-compatible ufs . the ozone client is able to use the hadoop filesystem interface , so we do n't need to write any new logic to support ozone . <nl> the reason we include this as a top-level ufs as opposed to including the ozone libraries directly in the hdfs ufs is to gain more control over the supported ozone version as well as reduce the size of the release tarball . otherwise , we would maintain many copies of the same ozone jars .",1588867014,added a new validation task for checking that root ufs is accessible . ufs modules are added as dependencies to make sure they will be registered correctly .,0.9475791454315186
apache_pulsar/9797,issue 0. add scheme type validation <para-sep> setup namespaces,"the schema should not be able to modify the type after it is first created . unless he is always compatible . <nl> when uploading a schema , it is verified that the type of the newly uploaded schema is consistent with the schema in the metadata . <nl> when checkcompatible , change the primitive type from checking only to checking all . <nl> * when a producer is created , the schema is defined , and when a producer is created again , the schema type is not always the same , otherwise an exception will be thrown .",1614844702,"when the document changes , there are often wrong contents . in order to solve this problem , we expect the commands on this page to be automatically generated . this pr is the first step . if it passes , we will add a new page on the website to show the automatically generated commands later . <nl> * add a hidden command to automatically generate command line documents <nl> * add integration tests . <nl> the following is what we expect : . <nl> integration test pass .",0.9479947686195374
apache_beam/13619,add builder parameter to allow user defined hadoop readsupport flags in hadoop configuration . <para-sep> returns a new configuration instance using provided flags . * / <nl> specify hadoop configuration for parquetreader . * / <nl> specify hadoop configuration for parquetreader . * / <nl> specify hadoop configuration for parquetreader . * / <nl> returns splittable or normal parquet file reading dofn . * / <nl> specify hadoop configuration for parquetreader . * /,"supports user provided configuration flags . with increasing number of flags in avroparquetreader options . <nl> making the configuration flags accessible to the user makes it more usable . <nl> for example , enable reading int96 data",1609146757,"more improvements for samzarunner : . <nl> - life cycle methods for the pipeline runtime <nl> - hook up samza externalcontext for linkediin use cases <nl> - support metrics reporters in pipeline options <nl> - some bug fixes for the state key in samza . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.953770101070404
apache_flink/15122,fix typo in streamexecdeduplicate <para-sep> translator to create event time deduplicate operator . * /,"fix a typo in the comment for rowtimededuplicateoperatortranslator in streamexecdeduplicate.java : ' process time ' = > ' row time ' . <nl> fix a typo in the comment for rowtimededuplicateoperatortranslator in streamexecdeduplicate.java : ' process time ' = > ' row time ' . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime",1615274059,"fix bug of distinct aggregate codegen when key type of distinct is . <nl> - btw , refine name problems of aggregate function in tests . <nl> this change added tests and can be verified as follows : . <nl> - added integration tests in . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) :",1.0
jenkinsci_jenkins/4824,cleanup workspace suffixes <para-sep> deletes all suffixes recursively .,"( description is more specific to this fix but it 's closed as a duplicate of ) . <nl> for every workspace has a copy of all pipeline libraries loaded during a build . these are never cleaned up currently and add up over time . on our instance it 's at nearly 10gb . <nl> i do n't know if this is the best fix , possibly the plugins should cleanup their directories they create but it seems ideal to me that this is managed centrally . <nl> , cleanup more workspace related directories , e.g . from pipeline",1593423969,"* plugin description links always point to the plugin site instead of the jenkins wiki . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . ) <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs",0.9623423218727112
apache_incubator-pinot/6069,[ issue 0 ] fixing the calls to helix to throw exception if zk connection is broken . <para-sep> retry interval and count for zk operations where we would rather fail than get an empty ( wrong ) result back,"[ issue 0 ] fixing the calls to helix to throw exception if zk connection is broken . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1601337639,- changing feedback type on anomaly ui <nl> - fixed failing tests after changing message template . <nl> - minor ui changes - aligning te logo,0.8685788512229919
apache_pulsar/9039,add offset for broker entry metadata <cm-sep> add managedledger interceptor <cm-sep> initialize intercptor for ml <cm-sep> interceptor entry before add to bookie to generator offset <cm-sep> add asyncfindposition method for managedledger <cm-sep> support append offset in managedinterceptor <cm-sep> interceptor pending write request <cm-sep> add offet to managedledgerinfo <cm-sep> add test for offset <cm-sep> add test for managedledgerinterceptor <para-sep> append a new entry to the end of a managed ledger . <nl> append a new entry to the end of a managed ledger .,one of the use case for broker entry metadata is providing continuous message sequence-id for messages in one topic-partition which is useful for protocol hanlder like kop . <nl> this pr enable pulsar to support continuous offset for message based on broker entry metadata . <nl> introduce a new field for broker entry metadta named ; <nl> introduce a new interceptor type which intercept entry in ； <nl> each partition will be assigned a when created ; <nl> each entry will be intercept for adding a monotone increasing offset in broker entry metadata and the offet is added by batchsize,1608710361,implemented the authentication refreshing functionality . <nl> notes : <nl> * works with mutual auth providers <nl> * works through pulsar proxy ( when client credentials are forwarded to broker ),0.9897588491439819
vespa-engine_vespa/15789,remove use of ' use-fast-value-tensor-implementation ' flag . <nl> has been default on since version ( 0- ) .,has been default on since version ( 0- ) .,1607681068,"this is for the compressed tensor constants we discussed . <nl> until it is supported in the backend , this will just fail to reload in proton , but i think that 's ok as it is undocumented . <nl> i 'll create a ticket for proton support .",0.8999527096748352
vespa-engine_vespa/16465,zk_port property has not been used for many years and is undocumented,zk_port property has not been used for many years and is undocumented,1612960953,this makes the window considered about 0 hour regardless of cluster size .,0.800138533115387
pentaho_pentaho-kettle/7548,backport of sonar cleanup . <cm-sep> backport of - modified javascript value : bignumber value incorrect in non-compatability mode ( version suite ) .,backport of - modified javascript value : bignumber value incorrect in non-compatability mode ( version suite ) .,1596099087,"refactor work on pancommandexecutor/kitchencommandexecutor to promote code reuse . <nl> this pull request holds zero changes to the logic . it 's a mere refactor work aimed at promoting code reuse . <nl> - promoted util method to , rather than being duplicated in / <nl> - was doing both the _ ' print repos ' _ , _ ' list repos ' _ , etc ... type of operations , as well as the action of loading a trans/job from the repository <nl> - decoupled the 0 : now addresses the _ ' print repos ' _ , _",0.9275009632110596
crate_crate/10519,fix flaky testaddorrenewretentionlease . <nl> we also have to enable soft deletes to make sure index is used for peer <nl> recovery .,fix flaky testaddorrenewretentionlease . <nl> we also have to enable soft deletes to make sure index is used for peer <nl> recovery . <nl> fix flaky testacquireprimaryalloperationspermits . <nl> fix testreplicaignoresolderretentionleasesversion .,1599764745,of the is called in an inner loop . <nl> avoiding the iterator allocations should reduce gc pressure a bit .,0.7681589126586914
Alluxio_alluxio/12288,fix loststorageintegrationtest failure on user 'root ' <para-sep> mock no write permission so worker storage paths can not be initialize <nl> mock no write permission so worker storage paths can not be initialize,"with this pr , root user and none-root user can pass the by exexuted . <nl> the following is the test by root user .",1602656340,"this could happen due to the context being closed ( ie . from application code ) , not catastrophic so we can just log a warning instead of crashing .",0.8688962459564209
runelite_runelite/11899,update coordinateclue.java . <nl> added ' if 0 agility ' to the bjs clue,added ' if 0 agility ' to the bjs clue .,1592166597,"the osrs wiki had the wrong text ( hope - > hopes ) . here is an image of the clue in game after correcting the text in the plugin : . <nl> found another one , wiki text was missing a comma . updated : .",1.0
OpenAPITools_openapi-generator/7955,"fixes additionalproperties , do not use cached properties for additonalproperties <para-sep> additionalproperties == true means that empty object will be used per the openapi spec , if additionalproperties is omitted it is defaulted to empty object so if we do that , set isadditionalpropertiestrue to true if an explicit schema is passed in to additionalproperties , set isadditionalpropertiestrue to false <nl> pass in null for the name to not use the schemacodegenpropertycache",do not use cached properties for additionalproperties <nl> this should fix the bug where additionalproperties tests are intermittently failing .,1605547099,- better oneof and anyof implementation ( based on java jersey2-experimental approach ) .,0.8960278630256653
elastic_elasticsearch/71181,"optimize bytesreferencestreaminput number reads . <nl> was used for all primitive reads which via the expensive <nl> which did not inline well caused slowness when reading large aggregate messages . <nl> this commit makes these reads do bulk operations on the underlying where possible <nl> instead . also , it extracts cold path from so that we get a fast bounds check <nl> branch instead of the loop with a large body for the hot case . <para-sep> slow path <nl> slow path <nl> slow path <nl> movetonextslice is intentionally extracted to another method since it 's the assumed cold-path <nl> rare corner case of a bytes reference that has a 0-length component","was used for all primitive reads which via the expensive <nl> which did not inline well caused slowness when reading large aggregate messages . <nl> this commit makes these reads do bulk operations on the underlying where possible <nl> instead . also , it extracts cold path from so that we get a fast bounds check <nl> branch instead of the loop with a large body for the hot case .",1617282846,we currently relay in the southernmost point of a polygon ring to compute the orientation of the polygon . this might lead to wrong results if the point neighbours cross the dateline . this commit changes the computation by using the signed area of the polygon ring .,0.8835567831993103
grpc_grpc-java/7399,keep deprecated checkauthority ( ) for backward compatibility,keep deprecated for backward compatibility .,1599581543,should we backport this to version ?,0.9097983241081238
OpenAPITools_openapi-generator/7273,"[ ci ] update gitattributes <cm-sep> renormalize line endings according to gitattributes <cm-sep> resolve files incorrect modification on windows <cm-sep> allow skipping docs generation to accommodate windows checks <para-sep> text=auto <nl> .vcproj text eol=crlf .bat text eol=crlf .cmd text eol=crlf <nl> .txt text eol=lf .yaml text eol=lf .yml text eol=lf .json text eol=lf .md text eol=lf .xml text eol=lf <nl> .sh text eol=lf .properties text eol=lf .java text eol=lf <nl> .mustache text eol=lf linguist-vendored=true .hbs text eol=lf linguist-vendored=true .handlebars text eol=lf linguist-vendored=true <nl> note : do n't use file.separator here as we write linux-style paths to files , and file.separator will result in incorrect match on windows machines . <nl> unit test asciidoc markup generation against ping.yaml openapi spec . * / <nl> check on some basic asciidoc markup content <nl> spec to include <nl> all _projects_ visible for the _current user_ are returned _projects_ may be active or closed","this explicitly sets gitattributes so we should no longer get mixed crlf and lf from some contributors on windows , and on our github workflow for master which verifies the integrity of the commit . <nl> as a workaround for windows , we do have to skip some doc generation . <nl> many of our generators do things like : . <nl> which would mean this location is output to documentation as on windows . there 's not really a quick and painless resolution for this as it would require one of the following : . <nl> * update all",1598148827,- add multiple server support ( oas v3 ) .,0.8675214648246765
vespa-engine_vespa/16176,"skip , do n't fail , if model ca n't be imported <para-sep> models that were not imported due to some error * /","models that are put under the directory are automatically imported , and made available for instance for stateless evaluation . this uses our ' old ' import code that converts to vespa expressions . however , a model that can be imported fine with onnx runtime , but is not supported by our code , will fail deployment if put in this directory . <nl> this logs a warning instead and skips ' global ' import of the offending model . the model can still be used for onnx runtime however . <nl> should the deploy logger be used instead",1611343498,we may need to discuss the metric names and units here .,0.9473293423652649
OpenAPITools_openapi-generator/8244,missing dart casts and analyzer issues <cm-sep> regenerate dart template files,"my changes were necessary to be able to compile my personal project and also the fake petstore generated clients . <nl> not all changes were made to fix compile errors : i 've mistakenly enabled the on the generated client and then fixed the resulting analyzer errors .. <nl> * if fixing casts 'issues ' and supporting that flag is not desired i can revert my cast changes . <nl> ( i 've only fixed the compilation error , not sure if it will work properly on runtime ) . <nl> maybe i 've fixed other issues .. but i",1608476545,"it does the same stuff as in the .travis.yml but just for gitlab ci : run nosetests . <nl> i see a but does n't use it , so i do n't know whether nosetests is the way to go here .",1.0000001192092896
confluentinc_ksql/6173,support if not exists on create type <cm-sep> fix indentation <para-sep> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"if is included in the query , then creating a type that already exists will return the following message : . <nl> if not , then this error will be thrown : .",1599698857,then to enable tests in ksql . <nl> unit and qtt tests added .,0.959583580493927
apache_druid/10287,allow the logusedsegments duty to be skippped <para-sep> log info about all used segments only if debug logging is enabled,"after more discussion . we have decided to scrap the ability to disable and instead remove the legacy code that emits alerts for segments with no size . this code is thought to be old debugging code that is safe to remove . now the logusedsegments duty gives a helpful log of # of active segments no matter what . and if debug logging is enabled , used segments are logged . this duty has no performance concerns for non-debug clusters meaning there is no reason to add complexity of new config to disable . in future , it may",1597445008,"i was trying to dump bitmaps for a segment and got this error - . <nl> so the column value for which bitmap will be output was missing so added it . not sure how was it working before , can anybody try if they are getting the same exception without this fix ?",0.8463549017906189
elastic_elasticsearch/71334,remove xpack.searchable.snapshot.cache.size setting <cm-sep> add migrating doc,the setting was introduced to limit the total size of the disk based cache on cold tier in the hope that it could be reused in a for or other for the frozen tier . then we agreed that this cache should be unbounded for the cold tier and finally we implemented the frozen tier with a different cache implementation ( yet the frozen tier uses this unbounded cache for caching some parts of metadata files ) . limiting the size of this cache is now useless for production code and can be removed . it allows to remove some,1617712156,"dry up tests that use a disruption that isolates the master from all other nodes . <nl> also , turn disruption types that have neither parameters nor state into constants <nl> to make things a little clearer .",0.9549350142478943
apache_pulsar/9975,"add get version command for pulsar rest api , pulsar-admin , pulsar-client <para-sep> pulsar version entry point . <nl> get version of broker . <nl> pulsar version test class .","( if this pr fixes a github issue , please add . ) <nl> add the version command : <nl> get broker version by rest api : . <nl> get broker version by : . <nl> get broker version by the command : . <nl> get version of pulsar admin client : . <nl> get version of pulsar client : . <nl> * add rest api for get version of broker <nl> * add getversion for the command <nl> * add getversion for the command <nl> * add getversion for the command . <nl> if was chosen , please highlight",1616159981,"support build pulsar client with serviceurlprovider method . <nl> with serviceurlprovider we can store the pulsar service url in zookeeper or any other config service . <nl> and we can watch the service url change event then control the pulsar client , such as change pulsar client serviceurl , force close client connection or re-connect with new service url . <nl> add serviceurlprovider interface . <nl> add forcecloseconnection method in pulsarclient .",0.9769474267959595
elastic_elasticsearch/71014,"auto convert shared_cache sbis to only use frozen tier . <nl> this commit converts the index metadata of searchable snapshot indices using the <nl> storage type to : . <nl> - remove all the settings <nl> - sets to automatically when the index metadata is read . <nl> this is in preperation to enforcing that the setting is always set to <nl> for shared cache sbis . <para-sep> first convert any shared_cache searchable snapshot indices to only use _tier_preference : data_frozen <nl> next we have to run this otherwise if we try to create indexsettings with broken settings it would fail in checkmappingscompatibility <nl> convert shared_cache searchable snapshot indices to only specify _tier_preference : data_frozen , removing any pre-existing tier allocation rules . <nl> only remove these settings for a shared_cache searchable snapshot <nl> clear any allocation rules other than preference for tier <nl> override the tier preference to be only on frozen nodes , regardless of its current setting <nl> a full_copy searchable snapshot ( settings should be untouched ) <nl> a shared_cache searchable snapshot with valid settings ( metadata should be untouched ) <nl> a shared_cache searchable snapshot ( should have its settings converted )",this commit converts the index metadata of searchable snapshot indices using the <nl> storage type to : . <nl> - remove all the settings <nl> - sets to automatically when the index metadata is read . <nl> this is in preperation to enforcing that the setting is always set to <nl> for shared cache sbis .,1617051634,"the ml info endpoint returns the max_model_memory_limit setting <nl> if one is configured . however , it is still possible to create <nl> a job that can not run anywhere in the current cluster because <nl> no node in the cluster has enough memory to accommodate it . <nl> this change adds an extra piece of information , <nl> limits.effective_max_model_memory_limit , to the ml info <nl> response that returns the biggest model memory limit that could <nl> be run in the current cluster assuming no other jobs were <nl> running . <nl> the idea is that the ml ui will",0.9516734480857849
elastic_elasticsearch/71068,"avoid duplicate values in mappertestcase # testfetchmany . <nl> the test currently generates a list of random values and checks whether <nl> retrieval of these values via doc values is equivallent to fetching them with a <nl> value fetcher from source . if the random value array contains a duplicate value , <nl> we will only get one back via doc values , but fetching from source will return <nl> both , which is a case we should probably avoid in this test . <para-sep> a few field types ( e.g . keyword fields ) do n't allow duplicate values , so in those cases we need to de-dup our expected values . field types where this is the case should overwrite this . the default is to not de-duplicate though .","the test currently generates a list of random values and checks whether <nl> retrieval of these values via doc values is equivallent to fetching them with a <nl> value fetcher from source . if the random value array contains a duplicate value , <nl> we will only get one back via doc values , but fetching from source will return <nl> both , which is a case we should probably avoid in this test .",1617118720,"currently we always call reduce even when we only have one internalaggregation . in some cases this is necessary but in others the reduce method is just making a copy of itself . this is normally not too expensive excepts for aggregations that hold expensive objects , for example cardinality or percentile aggregations . <nl> in order to prevent this necessary step this pr adds a new abstract method in internalaggregation that flags the framework if it needs to reduce on a single internalaggregation .",0.913707435131073
elastic_elasticsearch/71735,"currently the api fetches the root flattened field and returns it in a <nl> structured way in the response . in addition this change makes it possible to <nl> directly query subfields . however , requesting flattened subfields via wildcard <nl> patterns is not possible . <para-sep> testresponse [ s/ ' took ' : 0/ ' took ' : $ body.took/ ] testresponse [ s/ ' max_score ' : version/ ' max_score ' : $ body.hits.max_score/ ] testresponse [ s/ ' _score ' : version/ ' _score ' : $ body.hits.hits.0._score/ ] <nl> requesting via wildcard should retrieve the root field as a structured map <nl> direct retrieval of subfield is possible <nl> direct retrieval of root field and subfield is possible <nl> retrieval of subfield with wildcard is not possible <nl> retrieval of non-existing subfield returns empty result","currently the api fetches the root flattened field and returns it in a <nl> structured way in the response . in addition this change makes it possible to <nl> directly query subfields . however , requesting flattened subfields via wildcard <nl> patterns is not possible .",1618485135,limit the creation of data streams only for namespaces that have a composable template with a data stream definition . <nl> this way we ensure that mappings/settings have been specified and will be used at data stream creation and data stream rollover .,0.9696772694587708
apache_kafka/10138,: use leo for the base offset of leaderchangemessage batch <para-sep> throw exception for out of order records,"the implementation of validates that batches appended using and have an offset that matches the leo . this is enforced by and . when creating control batches for the the default base offset of was being used instead of using the leo . this is fixed by : . <nl> 0. changing the implementation for to validate against this and throw an if this invariant is violated . <nl> 0. always create a batch for with an offset equal to the leo . <nl> * more detailed description of your change , <nl> if necessary . the pr title and",1613539666,"0. split the consumer coordinator 's state into and . the first is when the join group request is sent , and the second is after the join group response is received . during the first state we should still not send hb since it shares the same socket with the join group request and the group coordinator has disabled timeout , however when we transit to the second state we should start sending hb in case leader 's takes long time . this is also for fixing . <nl> 0. when deciding , do not count in timetonextheartbeat if",0.940777063369751
apache_druid/10279,"add sql ' offset ' clause . <nl> since timeseries and topn queries do not currently <nl> have an offset feature , sql planning will switch from one of those to <nl> scan or groupby if users add an offset . <nl> includes a refactoring to harmonize offset and limit planning using an <nl> offsetlimit wrapper class . this is useful because it ensures that the <nl> various places that need to deal with offset and limit collapsing all <nl> behave the same way , using its ' andthen ' method . <para-sep> represents an offset and a limit . <nl> neither has a limit = > no limit overall . <nl> outer limit only . <nl> inner limit only . <nl> both outer and inner limit . <nl> extract limit and offset . <nl> timeseries can not handle offsets . <nl> ca n't handle zero limit ( the timeseries query engine would treat it as unlimited ) . <nl> must have group by one column , no grouping sets , order by ≤ 0 column , limit > 0 and ≤ maxtopnlimit , no offset , no having . <nl> can not handle zero or negative limits . <nl> ca n't handle zero limit ( the scan query engine would treat it as unlimited ) . <nl> returns a limitspec that encapsulates the orderbys , offset , and limit of this sorting instance . <nl> zero limit would be rejected by defaultlimitspec . <nl> query reduces to limit 0 . <nl> query reduces to limit 0 . <nl> query reduces to limit 0 . <nl> can not vectorize due to expressions . <nl> timeseries can not handle offsets , so the query morphs into a groupby .","since timeseries and topn queries do not currently <nl> have an offset feature , sql planning will switch from one of those to <nl> scan or groupby if users add an offset . <nl> includes a refactoring to harmonize offset and limit planning using an <nl> offsetlimit wrapper class . this is useful because it ensures that the <nl> various places that need to deal with offset and limit collapsing all <nl> behave the same way , using its ' andthen ' method .",1597371724,this patch properly applies the requested extractionfn to missing columns . <nl> it 's important when the extractionfn maps null to something other than null .,0.9732545018196106
vespa-engine_vespa/16018,add server config for enabling jdisc connection log <cm-sep> add featureflags ( ) to configmodelcontext <cm-sep> add feature flag for enabling jdisc connection log,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1610462834,"in order for orchestrator to remove application data from zookeeper , it must <nl> know which applications do not exist . since the duper model starts with 0 <nl> applications , always , the only way of knowing what applications do not exist is <nl> for the bootstrap code to notify the super model/duper model when bootstrap is <nl> complete . there are 0 sources of applications that must signal completeness : . <nl> - the super model , once all applications have been redeployed in <nl> configserverbootstrap . <nl> - the infrastructure application , in the infrastructureprovisioner the first",0.9429110884666443
apache_shardingsphere/9039,refactor agent tracing plugin test <para-sep> component name of shardingsphere 's open tracing tag . <nl> error log tag keys . <nl> shardingsphere tags . <nl> the tag to record the bind variables of sql . <nl> the tag to record the connection count . <nl> load them into current classloader <nl> prepare env for testing . <nl> clean up the collector . <nl> get all spans . <nl> get the first span .,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,1610651734,changes proposed in this pull request : <nl> - extract scaling job service . <nl> - distributed scaling job service impl . <nl> - standalone scaling job service impl . <nl> - fixes javadoc exception .,0.9475647211074829
ballerina-platform_ballerina-lang/23821,changed the grpc streaming handling on the server side <cm-sep> updated the integration tests and removed the proto generation functionality <para-sep> this is triggered when a new caller connection is initialized . <nl> iterate through the client stream <nl> handle the message sent from the stream here <nl> a grpc : eos is returned once the client stream is completed <nl> handle the error sent by the client here <nl> the grpc service is attached to the listener . <nl> iterate through the client stream <nl> handle the streamed messages sent from the client here <nl> a grpc : eos is returned once the client has competed streaming <nl> handle once the client has completed streaming <nl> handle the error sent by the client here <nl> you should return a { { outputtype } },"this enables adding multiple resources per service . <nl> the client stream is provided as a stream . by iterating through the stream , the server can read the client stream . at stream completion an error named grpc : eos is returned . <nl> resource function clientstream ( grpc : caller caller , stream clientstream ) { <nl> error ? e = grpcstream.foreach ( function ( messagerequest value ) { <nl> //carry out onmessage functions here <nl> } ) ; <nl> if ( e is grpc : eos ) { <nl> //carry out oncomplete functions here <nl> } else",1591649270,also updates the ' main ' function to <nl> - only accept parameters whose type is a subtype of anydata <nl> - restrict return type to a subtype of .,0.962891697883606
elastic_elasticsearch/71966,"add fleet action results system data stream . <nl> this commit adds support for system data streams and also the first use <nl> of a system data stream with the fleet action results data stream . a <nl> system data stream is one that is used to store system data that users <nl> should not interact with directly . elasticsearch will manage these data <nl> streams . rest api access is available for external system data streams <nl> so that other stack components can store system data within a system <nl> datastream . system data streams will not use the system index read and <nl> write threadpools . <para-sep> this will throw an exception if the index does not exist and creating it is prohibited <nl> the index already exists . <nl> everything other than allowed should be included in the deprecation message <nl> the backing index may have a different name or prefix than the data stream name . <nl> the index being created is for a system data stream , so the backing index will also be a system index <nl> the context is only used for validation so it 's fine to pass fake values for the shard id and the current timestamp <nl> collect the given v2 template into an ordered list of mappings . <nl> resolve the given v2 template and component templates into an ordered list of aliases <nl> the data stream will be managed by the system and also protected by the system against user modification so that system features are not broken by inadvertent user operations . <nl> creates a new descriptor for a system data descriptor <nl> checks whether the given name matches a reserved name or pattern that is intended for use by a system component . the name is checked against index names , aliases , data stream names , and the names of indices that back a system data stream . <nl> determines whether the provided name matches that of an index that backs a system data stream . <nl> this should be prevented by failing on overlapping patterns at startup time , but is here just in case . <nl> throw assertionerror if assertions are enabled , or a regular exception otherwise : <nl> contained in headers . <nl> contained in headers . <nl> determines what level of system index access should be allowed in the current",this commit adds support for system data streams and also the first use <nl> of a system data stream with the fleet action results data stream . a <nl> system data stream is one that is used to store system data that users <nl> should not interact with directly . elasticsearch will manage these data <nl> streams . rest api access is available for external system data streams <nl> so that other stack components can store system data within a system <nl> datastream . system data streams will not use the system index read and <nl> write threadpools .,1618937462,"the action toggles on the new setting that informs the cluster to tear down any previously created cluster alerts , and after that is accepted , the action immediately attempts a best-effort refresh of cluster alert resources in order to force their removal in case collection is disabled or delayed . <nl> since resources are controlled lazily by the existing monitoring exporters , extra care was taken to ensure that any in-flight resource management operations do not race against any resource actions taken by the migration action . resource installation code was updated with callbacks to report any errors instead",0.9884166121482849
quarkusio_quarkus/15419,"treat mismatchedinputexception as client error in resteasy reactive . <nl> the javadoc of mismatchedinputexception even mentions that these exceptions <nl> should be treated as client exceptions . <nl> ( cherry picked from commit sha ) <cm-sep> bump kubernetes-client-bom from version to version . <cm-sep> bring back proper timing for quarkus : dev . <nl> this seems to have been ( erroneously ) removed in <nl> sha . <cm-sep> avoid warning about indexing primitive types . <cm-sep> fix sub resource locators with no method annotations . <nl> ( cherry picked from commit sha ) <cm-sep> avoid npe in dev console when there are n't any indexed entities . <cm-sep> avoid confusion between entity instances and entity types in the hsearch devcard . <cm-sep> include quarkus-mutiny instead of vanilla mutiny in resteasy reactive . <cm-sep> fix consumes in rest score template ; add consumes in endpoints template . <nl> ( cherry picked from commit sha ) <cm-sep> make missing password and error . <nl> if the url is set but no password <nl> this is clearly a config error . <nl> ( cherry picked from commit sha ) <para-sep> sub resources can also have just a path annotation if they are 'intermediate ' sub resources <nl> meant to be used when a error occurred early in processing chain <nl> this is a valid action after suspend , in which case we must resume","please do n't merge , i will merge it myself .",1614707313,"i started on it to fix the enum values in the details being all weird and i ended up deep down in the rabbit hole . hopefully , they are all improvements over what we have : ) . <nl> commits better reviewed separately or by generating the end result .",0.9392470121383667
jenkinsci_jenkins/4768,"make plugin manager work on ie11 again . <nl> wtf are some people doing . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <para-sep> avoid any error in olddatamonitor to be catastrophic . see and the root cause is the olddatamonitor extension is not ready before a plugin triggers an error , for example when trying to load a field that was created by a new version and you downgrade to the previous one . <nl> it should be already reported , but we report with info just in case <nl> it should be already reported , but we report with info just in case <nl> list of events , one per stack trace , to send to telemetry . list of all events registered on this execution , to avoid printing an event more than once in the log . this map is not limited . on every jenkins restart is cleaned because it 's not persisted , so the cnfe is printed again . the key is the class name not found to quickly look for it on every cnfe thrown . <nl> we add the event to the list of already printed events . we used the name of the missing class instead of the full stack trace as a key to avoid filling the log with cnfe talking about the same class even though the stack traces are different . worse scenario , if we do n't put the exception on the ignored_places correctly , the administrator will see the message again and we will be able to add the new one to the ignored_places . in addition , the event is also sent to telemetry . <nl> returns true if the class name was already registered previously , during the current execution of this jenkins instance . <nl> to clean on every test execution <nl> do n't add ' java.base/ ' before sun.reflect.generics.factory.corereflectionfactory <nl> only one class miss gathered <nl> 0 log entries <nl> the stack trace of these cnfe are different but we only look at class names when printing on logs , so just one log entry <nl> the class name and also the stack trace of these cnfes are the same , so 0 log event <nl> no log <nl> only a max number of events is gathered . in this test , just",backporting has started and the rc is scheduled for 0-0-0 . <nl> please have look at the changes proposed ~and rejected~ so we have a consensus of what goes in by 0-0-0 .,1591179487,"in general it needs to do disk i/o once per session , but there is no good reason to throw away the results until either jenkins is restarted or an explicit configuration reload is requested . rechecking disk every 10s just seems wasteful . <nl> ( in principle we could try to optimize away ever loading of stored configurations but i suspect calls are more or less unavoidable in practice , so it seems simpler to just move it into the startup sequence . ) <nl> while there , i noticed that the storage of was quite wrong . generally",0.9429312944412231
hazelcast_hazelcast/18094,"set cluster connect timeout to infinite by default . <nl> after an internal discussion , we have decided to set the cluster <nl> connect timeout to infinite by default . also , the multiplier <nl> for the sleep time between consecutive connect attempts is changed <nl> to from . the new sleep times between connection <nl> attempts can be seen in the following graph . <nl> also , updated some logging statements . <nl> note that , this is a breaking change for the users who rely on the client <nl> to stop trying to connect to cluster after some time . <para-sep> default value for the cluster connection timeout . <nl> depending on failoverconfig , a client can shutdown or start trying on alternative clusters after reaching the timeout . for any other value , both the failover and non-failover client will use that as it is . clusters after reaching the timeout . for any other value , both the failover and non-failover client will use that as it is . <nl> if no value is provided , or set to 0 explicitly , use a predefined timeout value for the failover client and infinite for the normal client . <nl> : factor to multiply the backoff after a failed retry . its default value is version . <nl> : specifies by how much to randomize backoffs . its default value is 0 .","after an internal discussion , we have decided to set the cluster <nl> connect timeout to infinite by default . also , the multiplier <nl> for the sleep time between consecutive connect attempts is changed <nl> to from . the new sleep times between connection <nl> attempts can be seen in the following graph . <nl> the default value for the cluster connect timeout is set to . for this value , <nl> the client will not stop trying to connect the cluster . if the failover client is used , <nl> the default cluster connection timeout will be 0",1611656746,after discussions on the usefulness of statistics for the number of batch requests we ( most likely ) will show other statistics that require both the batch count and the number of generated ids . so i added a metric for the and changed the name form usage count to . <nl> a small extra change is the default of for the existing count instead that was not thought through .,0.9449866414070129
confluentinc_ksql/6389,rename schema to valueschema in qtts <cm-sep> change the qtt tests that need changing <cm-sep> rewrite spec nodes,simple change as listed in the description ... took a long time till i figured out a good way to rewrite the historical plans . <nl> testing-only change .,1602192477,"the naming was causing confusion when compared to the old concept of implicit fields , which included both rowtime and rowkey . meta fields only contain rowtime at this point , ( but may include others in the future , e.g . headers ... . <nl> mvn test .",0.8927316665649414
Graylog2_graylog2-server/9065,handle exception reasons without trailing semicolon . <cm-sep> add test case for primary shard not being active . <cm-sep> return retryable error if primary shard is not active for target index .,"prior to this change , when a message is tried to be ingested into elasticsearch when the primary shard of an index is unavailable , indexing will fail and the message will be turned into an indexing failure . most probably , this is not what a user wants . <nl> in most cases an unavailable primary shard is a ) affecting most , if not all indices , b ) is a temporary condition . these properties and the similarities to scenarios where a watermark threshold switches indices to read-only do justify a handling of this that attempts retries",1601562111,additionally we only render the dashboards/new page <nl> if the user has the needed permissions .,0.8726469278335571
apache_pulsar/8947,fix subscription dispatch rate does not work after the topic unload without dispatch rate limit .,"fix subscription dispatch rate does not work after the topic unload without dispatch rate limit . <nl> currently , if the subscription dispatch rate is present then update the rate limit , the subscription can be affected by the new policy . but if the subscription dispatch rate is absent , update the rate limit , the subscription can not be affected . <nl> new unitest added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api :",1607920430,"- provide a flag in , defaults to <nl> - when is disabled and the specified subscription ( ) on the topic does not exist when trying to subscribe via a consumer , the server should reject the request directly by in <nl> - create the subscription on the coordination topic if it does not exist when init",0.9442410469055176
apache_kafka/9684,"returns topic id in createtopicsresponse <cm-sep> deletetopicsrequest allows for specifying topic ids <cm-sep> fix some typos , correctly add/remove topic ids in mockadminclient , fix comments <para-sep> see the overload for more details . this operation is supported by brokers with version version or higher . <nl> delete a batch of topics . this operation is not transactional so it may succeed for some topics while fail for others . if delete.topic.enable is false on the brokers , deletetopicswithids will mark the topics for deletion , but not actually delete them . the futures will return successfully in this case . this operation is supported by brokers with version version or higher . <nl> returns a future that provides topic id for the topic when the request completes . if broker returned an error for topic configs , throw appropriate exception . <nl> return a map from topic ids to futures which can be used to check the status of individual deletions . <nl> return a future which succeeds only if all the topic deletions succeed . <nl> check for controller change <nl> handle server responses for particular topics . <nl> if there are topics to retry , retry them ; complete unrealized futures otherwise . <nl> the server should send back a response for every topic . but do a sanity check anyway . <nl> if there were any topics retries due to a quota exceeded exception , we propagate the initial error back to the caller if the request timed out . <nl> fail all the other remaining futures <nl> version 0 is the same as version 0 . <nl> version 0 returns the topic id of the newly created topic if creation is sucessful . <nl> version 0 reorganizes topics , adds topic ids and allows topic names to be null . <nl> version 0 adds topic id to responses . an unsupported_version error code will be returned when attempting to delete using topic ids when ibp < version . unknown_topic_id error code will be returned when ibp is at least version , but the topic id was not found . <nl> with topic ids <nl> with topic ids <nl> with topic ids <nl> with topic ids <nl> wait until the prepared attempts have consumed <nl> wait until the next request is sent out <nl> advance time past the default api timeout to time out the inflight","updated createtopicresponse , deletetopicsrequest/response and added some new adminclient methods and classes . now the newly created topic id will be returned in createtopicsresult and found in topicandmetadataconfig , and topics can be deleted by supplying topic ids through deletetopicswithids which will return deletetopicswithidsresult .",1607041152,"- now support ' removeall ' members in a given group <nl> - new cmdline option : -- force for streamsresetter is introduced , if -- force specified when using the streamsresetter , then all the active static/dynamic members will be removed .",0.968124508857727
OpenAPITools_openapi-generator/8203,test map with protobuf <cm-sep> fix protobuf map <cm-sep> use unescaped value <cm-sep> use string,"- fix how map is generated , e.g . <nl> map mapunderscoretest = 0 ; .",1608094298,# # # pr checklist .,1.0
quarkusio_quarkus/15230,"replace an unnecessary use of streams in panache with collection.contains . <cm-sep> move panachejparepositoryenhancer to hibernate-orm-panache . <nl> i believe it was misplaced ? <cm-sep> remove a few unnecessary generics from panacheentityenhancer/metamodelinfo/entitymodel . <cm-sep> handle field access enhancement the same way for entities and non-entities in panache . <nl> part of an effort to do this enhancement even when panache is not in <nl> use . <nl> previously we were doing something like this : . <nl> for each entity type <nl> do some entity-specific enhancement <nl> replace field access with setters/getters <nl> for every single type <nl> if it is not an entity type <nl> replace field access with setters/getters . <nl> now , we 're doing the same thing , just in a different order : . <nl> for each entity type <nl> do some entity-specific enhancement <nl> for every single type including entity types <nl> replace field access with setters/getters . <cm-sep> reuse panachejpaentityenhancer from panache-hibernate-common in reactive . <nl> the reactive implementations was virtually identical and was already <nl> using a common component . <cm-sep> move panache constants out of panacheentityenhancer . <nl> necessary if we want to split that class in two . <cm-sep> remove a few unused parameters in panache build steps . <cm-sep> separate companion enhancers from entity enhancers in panache . <nl> the whole ' metamodelinfo ' part is unnecessary for companion enhancers . <cm-sep> consistently ignore static fields in panache entity enhancement . <nl> apparently this was forgotten in some cases , but static fields <nl> definitely do n't need to be enhanced . <nl> i 'm not trying to solve a bug , but i 'll need to merge some of these <nl> methods in the next commits , so i need them to be consistent . <cm-sep> separate accessor generation visitors from operation generation visitors for panache entities . <nl> part of an effort to do this enhancement even when panache is not in <nl> use . <cm-sep> move collection of entity metadata out of panacheentityenhancer . <nl> necessary to apply accessor generation more broadly in the next commits . <cm-sep> align entity collection in panache hibernate reactive on panache hibernate orm . <nl> this is mainly so that we can merge the code of the two extensions in a <nl> later commit . <cm-sep> regroup all field-access-related code in dedicated build steps for panache hibernate . <cm-sep> apply","initiallly we considered just using the ' extended enhancement ' that hibernate orm bundles with , but the main concern was that performance would n't be great as that enhancement is performed at a higher level ( bytebuddy ) which makes it hard to integrate into quarkus . we would have had to basically load every class to convert as a , transform it , then write it , pretty much like we do in , but ... for every class in the application , since every class can potentially access public fields of entities . <nl> in the end",1613991674,now users can just add simple annotations to their classes and an initializer class to automatically generate marshaller ( s ) and proto schemas that are then automatically registered in the injected remotecachemanager .,0.9780722260475159
OpenAPITools_openapi-generator/7301,<para-sep> reuse already generated examplecode <nl> visited but no example code . circuit breaker -- > no stackoverflow,"the crash occurs in swift5 and swift4 codegeneration . <nl> swift4 has been marked as deprecated , so i only fixed the swift5codegeneration . <nl> unittest : crashswift5examplecodegenerationstackoverflowtest ( )",1598440053,"- n/a ] if contributing template-only or documentation-only changes which will change sample output , [ build the project before . <nl> - [ n/a ] run the shell script ( s ) under ( or windows batch scripts under ) to update petstore samples related to your fix . this is important , as ci jobs will verify _all_ generator outputs of your head commit , and these must match the expectations made by your contribution . you only need to run , if updating the code or mustache templates for a language ( ) ( e.g . php",0.9569690227508545
trinodb_trino/7385,simplify cleanup <cm-sep> move postgresql schema init to the server,this makes test 's remote database execution consistent with default <nl> session .,1616453802,extracted from hdp3 support pr to merge quicker & avoid conflicts .,0.6772404313087463
ballerina-platform_ballerina-lang/25882,add tobalstring ( ) support <cm-sep> add tobalstring ( ) for cycle <cm-sep> add support for tobalstring ( ) <cm-sep> refactor code <cm-sep> refactor code <cm-sep> add tests and refactor code <cm-sep> add tests and refactor code <cm-sep> remove unnecessary new lines <para-sep> returns the string value of ballerina values in expression style . <nl> todo : bstring - change to type tag check <nl> get the string value in expression style . <nl> returns expression style representation of the given value as a string .,object with tostring method . <nl> object without tostring method .,1600340416,0. migrate tableomdatasource class and enable table- > xml conversion . <nl> 0. enable table- > xml conversion tests in tabletest <nl> 0. add decimal retrieval logic in dataiterator back . i added this sometime back but this change has been dropped when merging previous jballerina branch with the master . <nl> 0. moves a table literal related test to tableliteraltest from tabletest .,0.9757760167121887
elastic_elasticsearch/71751,"fix case sensitivity rules for wildcard queries on text fields . <nl> wildcard queries on text fields should not apply the fields analyzer to the <nl> search query . this change fixes this by <nl> separating the notion of normalization and case insensitivity ( as implemented in <nl> the flag ) . this is done because we still need to maintain <nl> normalization of the query sting when the wildcard query method on the field type is <nl> requested from the query parser . wildcard queries on keyword <nl> fields should also continue to apply the fields normalizer , regardless of <nl> whether the is set , because normalization could involve <nl> something else than lowercasing ( e.g . substituting umlauts like in the <nl> germannormalizationfilter ) . <para-sep> test that wildcard queries on text fields do n't get normalized <nl> the following works not because of normalization but because of the parameter <nl> wildcard queries on keyword fields use the normalizer of the underlying field , regardless of their case sensitivity option <nl> case sensitive <nl> case insensitive <nl> we use this e.g . in query string query parser to normalize terms on text fields","wildcard queries on text fields should not apply the fields analyzer to the <nl> search query . this change fixes this by <nl> separating the notion of normalization and case insensitivity ( as implemented in <nl> the flag ) . this is done because we still need to maintain <nl> normalization of the query sting when the wildcard query method on the field type is <nl> requested from the query parser . wildcard queries on keyword <nl> fields should also continue to apply the fields normalizer , regardless of <nl> whether the is set , because normalization could involve <nl>",1618495747,"the operator fails the comparison against values , if these have a custom format ; reason being that translation of these values is unaware of the field mapping format and just use the one in a query . <nl> to overcome this limitation the pr changes the translation to a boolean of s query , which allow providing a parameter ( which still wo n't be that of the mapped field , but one that allows es to interpret the provided values of the range ) . <nl> the pr also adjusts the way converts the values in the set",0.9640896916389465
vespa-engine_vespa/15399,"use proper validationid instead of their string names in configchangeaction subclasses <cm-sep> model disallowable actions separately , and collect and throw these in validation <para-sep> throws a validationexception unless all given validation is overridden at this time * / <nl> when this is non-empty , validation may fail unless this validation id is allowed by validation overrides . * / <nl> todo jonmv : change to only wait for restarts , and remove triggering of restarts from runner .","this will fails several system and integration tests , so let me merge when i 'll be ready to watch these .",1605818337,"prevents accidental mutation of fields that are not owned by the load balancer service , <nl> such as rotations and inactive status . <nl> changes the api used by internal code so i 'll coordinate the merging myself .",0.9727446436882019
Alluxio_alluxio/11592,add a state-lock call-tracker for detecting interrupt-cycles <para-sep> whether interrupt-cycle is entered . * /,this change introduces a new fsm call-tracker that is attached to select recursive apis ( // ) in order for them to respect a pending backup and bail .,1592463473,open grpc streams prevents graceful server shutdown . this pr aims to provide infra for service implementations to provide closers to be invoked during server shutdown so they can close their active streams to allow for graceful shutdown . <nl> there are currently 0 such services : <nl> - authentication service <nl> - backup leader service,0.9626618027687073
prestodb_presto/15190,add page # extractchannel ( int ) to enable efficient single channel extraction <para-sep> add group id block,two commits : <nl> - adds helper method to allow efficient single channel page extraction <nl> - refactors more classes and operators to use application class helper methods which avoid extra allocations and copies of block arrays .,1600448773,this is part of the work to support for all data types . the goal is that any type that implements the operator can have its implementation via the parametric implementation of . <nl> what we have done : <nl> ( 0 ) support a single aggregation function to have multiple function implementations . <nl> ( 0 ) convert existing implementation of into the annotation framework . <nl> what 's next ( separate pr ) : <nl> ( 0 ) implement operators for other data types,0.9266999363899231
jenkinsci_jenkins/4774,": adjust label expression auto-completion and validation . <nl> this moves label expression auto-completion and validation from abstractproject <nl> to labelexpression . <nl> auto-completion : <nl> - abstractproject.autocompleteseerder was moved to labelexpression <nl> - test class correspondingly moved to the relevant package <nl> - added static labelexpression.autocomplete ( ) method <nl> - does what the non-static abstractproject.doautocompletelabel ( ) used to do ; that now calls the new static method . <nl> validation : <nl> - added labelexpression.labelvalidator , which is like abstractproject.labelvalidator except it takes a job instead of an abstractproject <nl> - abstractproject.labelvalidator is now deprecated <nl> - added static labelexpression.validate ( string , job ) method , which replaces abstractproject.validatelabelexpression ( string , abstractproject ) <nl> - the latter is marked as deprecated and forwards to the former <nl> - labelexpressiontest.formvalidation ( ) uses the new static method","this moves label expression auto-completion and validation from to . <nl> auto-completion : <nl> - was moved to <nl> - test class correspondingly moved to the relevant package <nl> - added static method <nl> - does what the non-static used to do ; that now calls the new static method . <nl> validation : <nl> - added , which is like except it takes a instead of an <nl> - is now deprecated <nl> - added static method , which replaces <nl> - the latter is marked as deprecated and forwards to the former <nl> - any warnings/errors reported by",1591460498,* rfe : generalize the changelog api to support non-abstractbuild run types .,0.9753534197807312
elastic_elasticsearch/71953,"* fix min , max , sum aggs data type handling . <nl> this fixes the way the min , max and sum handle the returned data types : <nl> - min and max must return the same data type as input 's . <nl> - sum must return long/bigint for integral types and double otherwise . <nl> the fix concerns both data returned in projections , as well as aggs <nl> filtering . <nl> ( cherry picked from commit sha ) <cm-sep> add bwc version-gated stream handling . <nl> ensure changes are backwards compatible . <para-sep> aggregations on date_nanos are returned as string <nl> max , min need to retain field 's data type , so that possible operations on integral types ( like division ) work correctly - > perform a cast in the aggs filtering script , the bucket selector for having . sql function classes not available in ql : filter by name <nl> sum ( integral_type ) requires returning a long value <nl> aggs filtering with integral types <nl> min and max need to return the same type as field 's and sum a long for integral types , but es returns them always as floating points - > convert them in the the select pipeline , if needed","this fixes the way the min , max and sum aggs handle the returned data types : <nl> - min and max must return the same data type as input 's . <nl> - sum must return long/bigint for integral types and double otherwise . <nl> the fix concerns both data returned in projections , as well as aggs script <nl> filtering . <nl> ( cherry picked from commit sha )",1618933468,"currently querystringqueryparser already checks if the field limit is breached <nl> at construction time , which e.g . leads to errors if the default field is set to <nl> ' * ' or the default is n't used and there are more fields than the limit , even if the <nl> query itself does not use all these fields . <nl> this change moves this check to happen after query parsing . querystringqueryparser now <nl> keeps track of the fields that are actually resolved while parsing . the size of <nl> that set is later used to check against the",0.9579965472221375
apache_incubator-pinot/5674,fixed missing registration for hadoop jobrunner . <nl> * caused by phase 0 of configuration refactor <cm-sep> fixed base configuration constructor for pinotconfiguration . <nl> * fixed the pinotconfiguration constructor that accepts a commons <nl> configuration . <nl> * full test coverage of pinotconfiguration <para-sep> asserts array properties can be read as string and array . <nl> asserts no error occurs when no configuration is provided in the spec .,this pr aims to be merged into branch to contribute on pr 0,1594307417,"* print series in insertion order . <nl> * print index series , if any , first . <nl> * trim spaces at end of line",0.914335310459137
apache_kafka/10068,stopreplicaresponsetest and stopreplicarequesttest should cover all avilaible version,more detailed description of your change <nl> accidently found that the test case in and did n't cover all versions . <nl> summary of testing strategy ( including rationale ) <nl> qa .,1612522467,the and use relatively strict timeouts of 0 seconds to check the intermediate state of the tests . the test failures observed in these two tests were not about the final output but asserting the embedded broker sent messages within the given timeframe . <nl> i ran the existing streams test suite .,0.7998386025428772
apache_kafka/9688,: fix flaky eos-beta upgrade test <para-sep> ( we do n't crash right away and write one record less ) <nl> 7a .,this pr is for and .,1607073005,"0. the retry loop of the internaltopicmanager would just be : a ) describe topics , and exclude those which already exist with the right num.partitions , b ) for the remaining topics , try to create them . remove any inner loops . <nl> 0. in createtopicresponse and metadataresponse ( for describe topic ) , handle the special error code of topicexist and unknowntopicorpartition in order to retry in the next loop . <nl> 0. do not handle timeoutexception since it should already been handled inside adminclient . <nl> add corresponding unit tests for a ) topic marked for",0.9539766311645508
ballerina-platform_ballerina-lang/24887,add fix to handle tests outside tests directory <para-sep> set testable flag for single bal file execution <nl> skip adding test suite if no tests are available in the tests path <nl> add a test suite to the registry if it does not contain one pertaining to the package name <nl> test class containing tests related to test path verification . <nl> check if this test gets executed <nl> check if this test gets executed,"- when there are tests defined outside the tests directory , a null pointer exception is thrown . <nl> - when there is at least one test defined inside the tests directory , tests outside the tests directory are also executed . <nl> thus , only tests defined inside the tests directory of a module are executed when using the command 'ballerina test ' .",1595414512,0. not showing the help page when enters only the following command . <nl> 0. not showing the help page when providing the option or to the following command . <nl> 0. not providing an error message to inform users when the command execution directory is not a ballerina project root .,0.957355797290802
grpc_grpc-java/7664,"example-xds : mirror helloworld and hostname example . <nl> -- secure was moved to front since many languages need flags to precede <nl> positional parameters , and we 'd like other languages to use the same <nl> flags when feasible . <nl> :0 was removed from xds : target in the readme , as it is n't all that <nl> useful and is confusing as xds itself provides the backend port numbers . <cm-sep> example-xds : prefix class names with xds , instead of suffix . <nl> this aligns with normal naming practice . <para-sep> construct client for accessing helloworld server using the existing channel . * / <nl> say hello to server . * / <nl> greet server . the second argument is the target server . <nl> the example defaults to the same behavior as the hello world example . to enable xds , pass an ' xds : ' -prefixed string as the target . <nl> the xds credentials use the security configured by the xds server when available . when xds is not used or when xds does not provide security configuration , the xds credentials fall back to other credentials ( in this case , insecurechannelcredentials ) . <nl> this uses the new channelcredentials api . grpc.newchannelbuilder ( ) is the same as managedchannelbuilder.fortarget ( ) , except that it is passed credentials . when using this api , you do n't use methods like , as that configuration is provided by the channelcredentials . <nl> the xds credentials use the security configured by the xds server when available . when xds is not used or when xds does not provide security configuration , the xds credentials fall back to other credentials ( in this case , insecureservercredentials ) . <nl> since the main server may be using tls , we start a second server just for plaintext health checks <nl> start graceful shutdown <nl> wait for rpcs to complete processing <nl> that was plenty of time . let 's cancel the remaining rpcs <nl> shutdownnow is n't instantaneous , so give a bit of time to clean resources up gracefully . normally this will be well under a second . <nl> this would normally be tied to the service 's dependencies . for example , if hostnamegreeter used a channel to contact a required service , then when 'channel.getstate ( ) == transient_failure '","-- secure was moved to front since many languages need flags to precede <nl> positional parameters , and we 'd like other languages to use the same <nl> flags when feasible . <nl> :0 was removed from xds : target in the readme , as it is n't all that <nl> useful and is confusing as xds itself provides the backend port numbers .",1606249103,"should not expose server stub methods , because it is wrong to call server stub methods directly .",0.80624920129776
netty_netty/10932,ensure native methods for unix-native-common are only registered once . <nl> motiviation : . <nl> we need to ensure we only register the methods for unix-native-common once as otherwise it may have strange side-effects . <nl> modifications : . <nl> - add extra method that should be called to signal that we need to register the methods . the registration will only happen once . <nl> - adjust code to make use of it . <nl> result : . <nl> no more problems due incorrect registration of these methods . <para-sep> load all c modules that we depend upon <nl> jni initialization hooks . <nl> internal method ... should never be called from the user .,motiviation : . <nl> we need to ensure we only register the methods for unix-native-common once as otherwise it may have strange side-effects . <nl> modifications : . <nl> - add extra method that should be called to signal that we need to register the methods . the registration will only happen once . <nl> - adjust code to make use of it . <nl> result : . <nl> no more problems due incorrect registration of these methods .,1610611702,"motivation : . <nl> the code for initiating a tls handshake or renegotiation process is <nl> currently difficult to reason about . <nl> modifications : . <nl> this commit introduces to clear paths for starting a handshake . the <nl> first path is a normal handshake . the handshake is started and a timeout <nl> is scheduled . <nl> the second path is renegotiation . if the first handshake is incomplete , <nl> the renegotiation promise is added as a listener to the handshake <nl> promise . otherwise , the renegotiation promise replaces the original <nl> promsie . at that",0.9356696009635925
vespa-engine_vespa/15969,"inline combination of dimensions and values to reuse knowledge ( 4x faster , versionx total ) <cm-sep> use a trie for variants , keyed on path , to look up prefix paths . <nl> this eliminates 0 % of the total run time , which was spent on path prefix considerations <cm-sep> generate all matching collections in one pass through the trie <para-sep> use this if you will create a lot of them , by appending suffixes . <nl> this is necessary because left-specified values takes precedence , and resolving [ a=a1 , b=b1 ] would otherwise lead us to the compiled profile [ a=a1 , - ] , which may contain default values for properties where <nl> visit all variant prefixes , grouped on path , and all their unique child bindings . <nl> simple trie for compoundname paths . <nl> performs action on sets of path prefixes against all their ( common ) children . * / <nl> performs action on the elements of this against all child element bindings , then returns the union of these two sets . * /","more to come , but this is a factor of more than π , so worth a merge imo .",1610104188,remove old authorization logic from controller . include as part of all based unit tests .,0.9780000448226929
runelite_runelite/12071,add ability to automatically screenshot barbarian assault high gamble rewards <para-sep> parses the barbarian assault high gamble reward dialog text into a shortened string for filename usage .,"the clan chat i 'm in has a game that requires having screenshots for ba high gambles . <nl> i thought this feature might be helpful for others , as well .",1594019373,"there are a number of things wrong with the way we do it now <nl> 0 ) there are up to 0 models in each , so we have to have a method for each of them . both models must be from the same objectcomposition , but have different rotations . <nl> 0 ) gets offset by <nl> 0 ) is not the 0-0 ' jau ' rotation , but the 0-0 type rotation <nl> 0 ) the rotation is baked into the model , and does not need to be accounted for by",0.9431546330451965
vespa-engine_vespa/15616,remove unused method <cm-sep> do not include election port in connection spec,"it seems zookeeper does not handle election port in all cases , specifically it <nl> fails when reconnecting : .",1606935944,fixes some issues with the combined user auth + athenz filter,0.8659778833389282
confluentinc_ksql/6490,"stop ( r ) qtt locking up . <nl> fixes an issue where running qtt can cause intellij and even macos to lockup for some period at the end of a test run . <nl> i 've found that intellij can lock up for over a minute after running all qtt tests . this can sometimes cause macos to also become unresponsive . <nl> well , i 've finally tracked down the cause ! the confluent class the code used to create temporary directories registers a shutdown hook for each temp directory created to ensure the directory is deleted on shutdown . ( simply calling is not enough , as this fails if the directory is not empty ) . <nl> a new directory is created for each qtt/rqtt test . this means thousands of hooks are registered , ( there 's currently over 5k qtt tests ) . when the jvm is shutting down it creates thousands of threads , each trying to delete one directly . <nl> fixed by having a single parent directory , with a single shutdown hook . <para-sep> create a temporary directory . the directory and any contents will be deleted when the test process terminates . <nl> single shutdown hook","fixes an issue where running qtt can cause intellij and even macos to lockup for some period at the end of a test run . <nl> i 've found that intellij can lock up for over a minute after running all qtt tests . this can sometimes cause macos to also become unresponsive . <nl> well , i 've finally tracked down the cause ! the confluent class the code used to create temporary directories registers a shutdown hook for each temp directory created to ensure the directory is deleted on shutdown . ( simply calling is not enough ,",1603374138,this is considered bad ux . this patch changes a setting in the underlying jline3 library we use so that we log commands which start with a space .,0.9367756247520447
apache_pulsar/9683,enable spotbugs for pulsar-io-kafka and pulsar-io-solr,enable spotbugs for the pulsar-io module . <nl> enable spotbugs for pulsar-io-kafka and pulsar-io-solr .,1614072566,"even after the synchronous close ( ) method is called on a pulsarclient , netty thread ( s ) from the eventloopgroup used in the connectionpool may still linger around for another 0 seconds afterwards due to not wait for the the graceful shutdown to complete . <nl> while this usually does n't cause any problems for a normal use case , it does cause problems in the pulsar flink sources and sinks . exceptions like the following can happen when the flink job with a pulsar source or sink gets closed : . <nl> this is because threads from",0.7536472082138062
apache_beam/13003,"more helpful error when we ca n't find a way to construct a pojo <cm-sep> more helpful error when we ca n't construct a java bean <para-sep> otherwise , we will have no way of creating instances of the class . <nl> the annotation can also be used on individual pojo fields , and java bean and autovalue getters to change the case format just for those fields . if that is not the case , we make a best effort to convert the field name but the result is not well defined . <nl> the name to use for the generated schema field . * / <nl> a bean that has no way for us to create an instance . should throw an error during schema generation . <nl> it also renames fields , which has the potential to make us misidentify setters . <nl> /","adds an annotation that can be used to control the case format used in schema field names . for example : . <nl> will produce a schema with fields ' user ' , ' age_in_years ' , and ' knowsjavascript ' . <nl> i think the primary application of this will be using for schemas that will be used across languages ( e.g . in logicaltype base types , and cross-language transform configuration objects ) , but i figured a general purpose solution based on would be more valuable . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link",1601665116,"spanner 's default commit deadline of 60mins does not give enough feedback to the pipeline when the spanner database is overloaded . <nl> using a shorter ( configurable ) commit deadline of 15secs , along with backoff/retry logic allows the dataflow pipeline to take some of the load off spanner when it gets overloaded , leading to greater overall throughput . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9760509133338928
vespa-engine_vespa/16902,skeleton api handler for changemanagement <cm-sep> add proposed sample data for assessment <para-sep> this is the main structure that might be part of something bigger later <nl> updated gives clue to if the assessement is old <nl> assessment on the cluster level <nl> assessment on the host level,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1615468118,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9795316457748413
elastic_elasticsearch/71384,"enable logging for proxy connection test . <nl> this commit enables logging for a remote proxy connection test which <nl> failed once . after observation , the test has not consistently failed and <nl> no clear explanation has been identified . this logging will add <nl> additional information in case the test were to fail again . <para-sep> this test has failed once or twice in the past . this is enabled in case it were to fail again .","this commit enables logging for a remote proxy connection test which <nl> failed once . after observation , the test has not consistently failed and <nl> no clear explanation has been identified . this logging will add <nl> additional information in case the test were to fail again .",1617766555,"this commit adds internalclustertest in xpack core to run as part of <nl> check . this was accidentally removed in a refactoring . other xpack <nl> modules already do this , but core was left out . this commit also mutes 0 <nl> tests that currently fail .",0.922713041305542
apache_pulsar/9222,fix mis-use of local and global zk,this pr fix others places of mis-use and provide different zk for global/local in .,1610815901,this pr separates the trust store used for incoming connections ( client side ) from the outgoing ( broker side ) . <nl> we have a use case where we want to trust only a specific trust store for client authentication ( eg . athens ) but our broker certs could be signed by any other ca . <nl> also created new certs with 10years expiry,0.9336815476417542
apache_pulsar/9131,issue 0 : pulsar-admin sinks create : bad error message ' java.lang.nullpointerexception : path is 'null ' . ' in case of missing ' -- name ' parameter <para-sep> unit tests <nl> this function is only about namespace and tenant,"the validation covers tenant , namespace and sinkname in all of the functions regarding sinks . <nl> we must do the validation here because we have to prevent code to pass bad values to jax-rs client .",1609845151,"the broker admin checks if the authenticated user is listed as a proxy <nl> user . if so , it checks looks for the header x-original-principal , and <nl> validates that the role is authorized to access the resource in <nl> question . <nl> there are two use cases : . <nl> 0. the proxy role is a normal role . in this case , if a resource is to <nl> be used via the proxy , the proxy user must be explicitly granted <nl> permission on the resource . so , to use the admin api for a tenant",0.9681653380393982
confluentinc_ksql/6715,"avoid extra state store when repartitioning tables for joins <para-sep> today , the information stored includes all source steps and whether each is repartitioned at any point prior to a join . if a table source is repartitioned downstream prior to a join , then we do not need to materialize the source table as the join will create a state store from the repartition topic rather than the source topic . <nl> present iff the execution step this plan info corresponds has exactly one upstream source node ( i.e. , no joins have been encountered thus far ) . if so , this tracks the single source node . else , empty . <nl> map of source steps to information including whether the source is repartitioned downstream ( prior to a join ) . <nl> if we know this table source is repartitioned later in the topology , we do not need to force a materialization at this source step since the re-partitioned topic will be used for any subsequent state stores , in lieu of the original source topic , thus avoiding the issues above . <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","this pr introduces a which traverses the execution step plan to collect needed information to be passed to the , for use when translating the execution step plan into an actual kafka streams topology . the collects information about whether sources are repartitioned downstream ( prior to any joins ) . the uses this information to decide whether or not to force materialization on source tables -- if the table is repartitioned downstream , it is not necessary to force materialization at the table source . <nl> unit + qtt .",1606971058,"like others , i spend a lot of time opening and searching through qtt & rqtt test files for the right test when a test fails , sometimes getting the wrong one and wasting time . enter this change ... this change adds clickable links to the output of th tests . <nl> for example , if the test fails in the file then you 'll get a link like : . <nl> clicking this link in intellij will take you to the right line in the file . <nl> if a historic test fails , you 'll get a",0.9756457209587097
apache_incubator-pinot/6005,"fix extract method in avrorecordextractor <para-sep> the data type got changed to integer , which will then have to trigger the convert method in datatypetransformer class .","e.g . the column1 was originally of long type . but when it was converted to json string and then parse to a json map , the type would be changed to int . thus , the actual value may be incorrect from the json map comparing to the actual value from generic record . plus , since it changes the data type , it will have to trigger the method in datatypetransformer class , which will make confusion to detect schema mismatch . <nl> this pr fixes it by fetching the actual value directly from the original generic record",1599846301,"currently , a realtime table can be added without a schema . the missing schema is detected on the server when a offline- > consuming transition is attempted . this change ensures the controller returns a 0 error when a realtime table is created without schema . <nl> changes include : <nl> - unit tests to test the realtime table creation fails if there is no schema <nl> - new method in base controllertest to add a default schema to use with realtime tables .",0.9514898061752319
grpc_grpc-java/7460,"fix wrong synchronization for picksubchannel ( ) <para-sep> rescue should be pending status although the overall channel state is ready <nl> search subchannel is down , rescue subchannel is connecting <nl> verify success . subchannel is wrapped , so checking attributes .","does not run in synchronizationcontext , but it calls which assumed running in synchronizationcontext . fixed by removing . is actually thread-safe in the sense it 's guarded by lock , and 's fields are final . <nl> was not thread-safe . fixed by making it volatile . <nl> changed the test a bit since the old test does n't really test things well .",1601073677,"one of the main motivation was trying to fix a deadlock in okhttpclienttransport . <nl> fyi . inprocesstransport.start returns runnable , so ca n't remove the runnable .",0.9472009539604187
apache_druid/10137,add kafka test configs from file for adminclient and consumer,allows passing in additional kafka consumer and admin client properties to test client from test config file . <nl> needed for running druid integration tests against secure kafka setups and passing in mandatory jaas config and other security parameters .,1594016125,"the segments that are stored in are the same as in , so we could effectively use the latter for interning . it allows to get rid of one large map of weak references which are probably bad for gc themselves . <nl> also interning does n't make sense in .",0.9040029048919678
vespa-engine_vespa/16163,make serialization of seconds significantly cheaper <cm-sep> include stack trace in log <cm-sep> remove unused members and remove unnecessary throw declaration,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1611321388,"for non-aws zones , the only change is that it now uses syntax rather than . <nl> for aws zones it will now ask for more memory to compensate for and use 0 vcpu as there is no aws instance type that we support that has 0 vcpu and 0 or 0 gb .",0.9406037926673889
OpenAPITools_openapi-generator/8012,"add basic types imports to generated examples . <nl> this adds an extension to include basic types imports to generated java <nl> examples . <cm-sep> make some fixes to example generation <cm-sep> generate offsetdatetime correctly <cm-sep> create a useful sample for enums , regenerate samples <para-sep> return the example value of the parameter . overrides the setparameterexamplevalue ( codegenparameter , parameter ) method in defaultcodegen to always call setparameterexamplevalue ( codegenparameter ) in this class , which adds single quotes around strings from the x-example property .","this fixes a bunch of issues with java examples , including : <nl> * adds imports to basic types <nl> * generate proper example for enums <nl> * generate useful default for offsetdatetime <nl> * wrap schema examples when necessary ( quotes , longs , etc ) .",1606215411,"this pr first of all adds supports for models that contain other models as properties . <nl> moreover , i added support for the generation of tests for the generated models . <nl> i had to mix template and c , since i have access to different data from the 0 environments . <nl> from c i can build a ' default ' example , and/or decorate strings with double quotes . <nl> to be able to support objects into objects ( a property of an ' external ' object is an ' internal ' object itself ) , i",0.9455656409263611
Alluxio_alluxio/10900,"enable configuration of ignored tables <para-sep> returns the input string as a list , splitting on a specified delimiter . <nl> map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_updated = 0 ; <nl> repeated string tables_updated = 0 ; <nl> repeated string tables_updated = 0 ; <nl> repeated string tables_updated = 0 ; <nl> repeated string tables_removed = 0 ; <nl> repeated string tables_removed = 0 ; <nl> repeated string tables_removed = 0 ; <nl> repeated string tables_removed = 0 ; <nl> map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; map & lt ; string , string & gt ; tables_errors = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_ignored = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ; <nl> repeated string tables_unchanged = 0 ;",this allows ignoring a certain set of tables when attaching a database .,1581548098,this pr : <nl> - merges getfileblockinfolist functionality into getstatus ( and adds list as a field of uristatus ) <nl> - fixes up publicapi annotations <nl> - change the type of ufs locations from workernetaddress to string <nl> - adds tostring method for lineage options,0.9825159907341003
elastic_elasticsearch/71412,"move machine learning roles to server . <nl> this commit moves the machine learning roles to server . we no longer <nl> need to maintain these roles outside of server since we only produce a <nl> single distribution , the default distribution , which includes all <nl> roles . therefore we can simplify the plugin architecture by removing the <nl> plugin extension point for roles . this is one step in that , by moving <nl> the machine learning roles to server . <para-sep> transform is enabled by default on any non-frozen data node","this commit moves the machine learning roles to server . we no longer need to maintain these roles outside of server since we only produce a single distribution , the default distribution , which includes all roles . therefore we can simplify the plugin architecture by removing the plugin extension point for roles . this is one step in that , by moving the machine learning roles to server .",1617806525,the json logs that elasticsearch produces are roughly in an ecs shape . this pr improves that alignment .,0.9347885251045227
apache_pulsar/9381,"websocket reach end of topic . <para-sep> let it connect <nl> send 0 message in total . <nl> send 0 permits , should receive 0 message <nl> wait till get response <nl> assert not reach end of topic yet <nl> send 0 more permits , should receive all message <nl> 0 includes previous of end of topic request . <nl> wait till get response <nl> assert not reached end of topic . <nl> wait till get response <nl> assert reached end of topic . <nl> acking the proxy <nl> check and notify consumer if reached end of topic . <nl> check and notify reader if reached end of topic . <nl> represent result of request to check if we 've reached end of topic . <nl> if reach end of topic . <nl> request * <nl> response * <nl> request * <nl> response *","add a request of type to check if consumer/reader has reached end of topic and send response based on result . <nl> - does this pull request introduce a new feature ? yes <nl> - if yes , how is the feature documented ? docs",1612078827,"if the namespace-level policy does not exist , the broker level will be used .",0.9499863982200623
jenkinsci_jenkins/4851,"fixed deprecation warnings , simplified junit assertions and removed obsolete throws exception statements","* fixed deprecation warnings , <nl> * simplified junit assertions and <nl> * removed obsolete throws exception statements <nl> * added some missing <nl> * use of standardcharsets . <nl> * n/a",1595147758,"see . <nl> details : removes references to trilead classes in jenkins core to allow the trilead jar to be split out of core at some future point . <nl> this change does not modify cli - which bundles trilead independently of the version in core - nor does it modify the sftpclient class in core as this depends on trilead 's implementation and will therefore need migrated out of core alongside the jar . <nl> change is covered under existing unit tests , no new tests added . <nl> * use the prefix if the change has no user-visible",0.9596270322799683
grpc_grpc-java/7712,"do n't leak callcredentials into oob channels . <nl> the addition of compositechannelcredentials allowed callcredentials to <nl> be passed to the managedchannel itself . but the implementation was buggy <nl> and used the call creds for out-of-band channels as well , which is <nl> inappropriate since they have a different authority . <nl> this also fixes a bug where resolving oob channels would have callcreds <nl> duplicated ; that was n't noticed or important because we do n't use <nl> callcreds in oob channels . <para-sep> callcredentials that provides a single , fixed header . <nl> verify that the normal channel has call creds , to validate configuration <nl> verify that the oob channel does not <nl> verify that resolving oob channel does not","the addition of compositechannelcredentials allowed callcredentials to <nl> be passed to the managedchannel itself . but the implementation was buggy <nl> and used the call creds for out-of-band channels as well , which is <nl> inappropriate since they have a different authority . <nl> this also fixes a bug where resolving oob channels would have callcreds <nl> duplicated ; that was n't noticed or important because we do n't use <nl> callcreds in oob channels . <nl> note that the originaltransportfactory usage vs oobtransportfactory usage is <nl> subtle . if you use the wrong one then callcreds are duplicated .",1607545765,"this allows loadbalancers to trace the activities , including the final <nl> status of the stream that is created as a result of the pick . <nl> let me know if you prefer doing the switch now .",0.9601390361785889
Alluxio_alluxio/11674,refactor fsm rpc cancellation support <cm-sep> track original calls during sync session,this pr enables fsm internal call-trackers by default for all rpcs . <nl> it also improves the overall rpc cancellation coverage by including sync sessions .,1593214824,- reduced some code duplication between the alluxio master and job master . <nl> - added serversocket arguments to ' reserve ' ports . this is useful for testing because it reduces the chance of race conditions where mulltiple processes attempt to use the same port . <nl> - added reserving sockets to integration tests which need both alluxiomaster and jobmaster .,0.9771960973739624
quarkusio_quarkus/15297,added filter and other updates to config screen in dev ui <nl> signed-off-by : phillip kruger <para-sep> propertiesconfigsource [ source=application.properties ] <nl> all other propertiesconfigsource <nl> default value <nl> null <nl> now the rest,"this pr updates the config properties screen in dev ui . <nl> here the changes : . <nl> - changed the sub header ( of all screens ) to be in the nav bar header ( space saving ) <nl> - added a way for extension pages to add javascript <nl> - added a search/filter bar for the config properties <nl> - changed the order of the config properties to first show properties from and then other quarkus properties and moved and to the bottom , the logic here is that the developer would probably change properties in and other",1614169980,"this pr adds : <nl> * a new debug symbol enable option called . <nl> * a new option has been added instead of breaking existing users that might rely on flag . this flag adds to the invocation which is a graalvm ee only flag . should it eventually deprecated ? <nl> * after creating the native image , if is found , it uses it to split the debug symbols from the binary executable . the debug symbols are put in a file called at the same level as the binary . <nl> * this new option is",0.937541663646698
ballerina-platform_ballerina-lang/25534,use boolean value to write and read boolean constants <cm-sep> update bir spec with constant value info . <nl> this also cleans the ksy file with proper names and type tags <cm-sep> add annotations and typedef test cases <para-sep> assert name <nl> assert flags <nl> assert type <nl> assert position <nl> assert name <nl> assert type <nl> assert attach points <nl> lang : listener ; <nl> test compilation for annotations with the worker attach point . <nl> do nothing,it also has few refactoring done on ksy file to avoid issues with constants .,1598847686,> add codegen and bir gen for fp call . <nl> this function invocation is wrapped within a java lambda and passed around .,0.9470562934875488
apache_pulsar/9396,"compression must be applied during deferred schema preparation and enablebatching is enabled <nl> if you do not set an initial schema to the producer the schema must be prepared at the first message with a schema . <nl> there is a bug and compression is not applied in this case , and the consumer receives an uncompressed message , failing <para-sep> initially we are not setting a schema in the producer <nl> now we send with a schema , but we have enabled compression and batching the producer will have to setup the schema and resume the send <nl> compress the payload if compression is configured <nl> in this case compression has not been applied by the caller but we have to compress the payload if compression is configured","if you do not set an initial schema to the producer the schema must be prepared at the first message with a schema . <nl> there is a bug and compression is not applied in this case , and the consumer receives an uncompressed message , failing . <nl> with enablebatching=true the compression is usually applied per batch , but in case of schema preparation the code flows down to a separate path and we have to enforce compression . <nl> basically if the schemastate is not 'ready ' the message can not be added to the batch and we",1612168457,"when using a multi-broker service url to create a producer , if the connection to the first broker failed , the creation will fail . <nl> add backoff retries when getting partitioned metadata from brokers .",0.9649335741996765
apache_incubator-pinot/5791,add new endpoint to get routing table for sql query,"api contains endpoint that get routing table for pql query . this new endpoint gets routing table for sql query . <nl> what is the required for ? <nl> - pinot is moving from pql to the sql , and would be good to get routing table for sql query . <nl> - in one use case , this was needed . thus we needs this endpoint .",1596474192,sample usage to create segments :,0.9457921385765076
elastic_elasticsearch/72407,fix clusterstaterestcancellationit . <nl> take into account that the task can be cancelled after the check has <nl> been performed and it could trip the assertion .,take into account that the task can be cancelled after the check for <nl> acceptableclusterstateorfailedpredicate has been performed and <nl> it could trip the assertion .,1619626504,"the tests involving a temporary directory ( containing the jdbc jar ) fail <nl> on windows because they ca n't be deleted , due to still being in use . <nl> this pr forces an early closing of the jar file , which mitigates <nl> the failure by giving the jvm more time to collect any open fds . <nl> ( calling the system.gc ( ) in the tests is another working alternative <nl> fix . ) <nl> the stream-based jar access is taken care by disabling the cache usage <nl> ( which has the same effect of closing the",0.846764326095581
elastic_elasticsearch/71625,option to disable device type parsing,marked as ' non-issue ' as it updates a not-yet-released feature .,1618316973,"this change is just about validating that composable templates have a or field mapping configured in the mapping section for the timestamp_field that is defined in the data stream definition . <nl> a followup change will store the timestamp_field mapping with the data stream instance in the cluster state , so that the timestamp mapping will stick with the data stream as long as it will exist . this will make sure subsequent rollover invocations always create a new backing index with consistent timestamp field mapping .",0.9504944682121277
elastic_elasticsearch/71844,"frozen default cache size . <nl> this commit adds a default cache size to frozen tier of the greater of <nl> 0 % and total disk size minus 0 gb . <nl> additionally , configuring a frozen cache is now warned against on nodes <nl> with multiple data paths . <para-sep> a 0 gb disk will result in a shared cache sized at 0 gb . 0 % of 0 gb <nl> a 0 gb disk will result in a shard cache sized at 0 gb . <nl> check if the settings are for a dedicated frozen node , i.e . has frozen role and no other data roles . <nl> returns whether or not the node is a frozen only node , i.e. , has data frozen role and no other data roles . <nl> ignore",this commit adds a default cache size to frozen tier of the greater of <nl> 0 % and total disk size minus 0 gb . <nl> will follow-up with two other items : . <nl> 0. fail nodes on startup when frozen cache has a size on multiple data paths . the tricky bit here is mainly the test framework .,1618839988,"this pull request adds the minimum , maximum and average length of files in the searchable snapshots stats api : . <nl> these information are useful in understanding why some data is still being read from the blob store when the cached blob in should have been sufficient to server all the read operations .",0.9595901966094971
elastic_elasticsearch/70687,"when multiple indices are searched and in one index the field is unmapped and <nl> in another index the field is mapped as a numeric value , it is possible to <nl> end up with numbers in the expression . this commit fixes a confusing <nl> error message that is generated in such cases . <para-sep> the value might be not string if this field is missing in this shard but present in other shards and does n't have a string type","when multiple indices are searched and in one index the field is unmapped and <nl> in another index the field is mapped as a numeric value , it is possible to <nl> end up with numbers in the expression . this commit fixes a confusing <nl> error message that is generated in such cases .",1616440693,"this commit fixes a bug on the composite aggregation when the index <nl> is sorted and the primary composite source needs to round values ( date_histo ) . <nl> in such case , we can not take into account the subsequent sources even if they <nl> match the index sort because the rounding of the primary sort value may break <nl> the original index order .",0.8597169518470764
apache_kafka/9660,added default constructor without properties in topologytestdriver <cm-sep> using constructor of topologytestdriver without properties parameter <cm-sep> using constructor of topologytestdriver without properties parameter <cm-sep> changed constructor reference to the one without properties <cm-sep> keeping default test props final <cm-sep> fixed merge conflicts <cm-sep> made changes as per style guilde <cm-sep> no need of static default properties <cm-sep> provide randomized dummy app-id if it 's not provided <cm-sep> added another constructor with initial clock time parameter <cm-sep> fixed merge conflicts <para-sep> default test properties are used to initialize the driver instance <nl> create a new test diver instance . <nl> create a new test diver instance . provide randomized dummy app-id if it 's not specified,- : topologytestdriver should not require a properties argument .,1606528231,also piggy-back a small fix to use treemap other than hashmap to preserve iteration ordering .,0.8960227966308594
Alluxio_alluxio/11037,<para-sep> prints the help message .,"improves description of command , including a better usage description and mentioning credential risks .",1582774388,add <nl> modify master web ui metrics to use and to use <nl> improve metrics system docs to include more worker metrics and have detailed description of web ui metrics .,0.9268823862075806
apache_druid/10354,working <cm-sep> add test <cm-sep> doc <cm-sep> fix test <para-sep> 0 segments published per day after compaction .,the oom killer started killing druid processes in . my recent commits are to avoid this problem . i reduced the memory of historicals from 768mb to 512mb . is now running in a separate job because of the time limit in travis,1599183543,"hi , . <nl> i use another date format for the intervals which does not contain ' : ' symbols . i also replace ' : ' characters with ' _ ' in the version string . <nl> i tested this with .version-cdh4 . the segments are now pushed to hdfs properly and loaded to compute nodes properly . <nl> thanks for accepting the modification . <nl> -- jan",0.9276823997497559
confluentinc_ksql/6349,"add none format . <nl> introduce a format , used to indicate the key data , in key-less streams , should not be deserialized . <cm-sep> historical plans <para-sep> if the inherited key format is none , and the result has key columns , use default key format : <nl> do not use none format for internal topics : <nl> format used to indicate no data . <nl> given : <nl> when : <nl> given : <nl> when : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then :","introduce a format , used to indicate the key data , in key-less streams , should not be deserialized . <nl> there 's a piece of follow up work to make joins involving key-less streams with key format work . <nl> usual .",1601635416,"this pr explicitly adds the ssl config names to the ksql configuration , extends the prefix to allow ssl overrides specific to the sr to be supplied , and then wires this all up to configure the used by the sr client . <nl> for example , where the same ssl configuration is needed from the schema registry as for the kafka brokers , then config like this can be used : . <nl> where sr requires different configuration , it also supports overrides : . <nl> still to do ... .",0.980494499206543
apache_incubator-pinot/5910,prints file name of invalid json file <para-sep> this writes temporary files into pinot-tools/target/test-classes/test_data <nl> tries creating a segment out of an invalid json file,no <nl> no . <nl> no,1598094443,- add an endpoint to allow a user to create customized events,0.9462574124336243
apache_flink/14360,"refactor verifyplan method in tabletestbase <para-sep> test base for testing table api / sql plans . creates a table with the given ddl sql string . create a [ ] with the given schema , and registers this datastream under given name into the tableenvironment 's catalog . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given select query . the plans will contain the extra [ ] s. note : an exception will be thrown if the given query ca n't be translated to exec plan . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given insert statement . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given insert statement . the plans will contain the extra [ ] s . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given [ ] . note : an exception will be thrown if the given sql ca n't be translated to exec plan . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given [ ] . the plans will contain the extra [ ] s. note : an exception will be thrown if the given sql ca n't be translated to exec plan . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given [ ] with the given sink table name . note : an exception will be thrown if the given sql ca n't be translated to exec plan . <nl> verify the ast ( abstract syntax tree ) , the optimized rel plan and the optimized exec plan for the given [ ] with the given sink table name . the plans will contain the extra [ ] s. note : an exception will be thrown if the given sql ca n't be translated to exec plan . <nl> verify the ast ( abstract syntax tree ) and the optimized rel plan and the optimized exec plan for the given [ ] . the plans will contain the extra [ ]","* refactor verifyplan method in tabletestbase as following : <nl> 0. replace planbefore with ast in xml file . ast is ' abstract syntax tree ' , corresponding to ' abstract syntax tree ' item in the explain result ; <nl> 0. remove planafter , introduce optimized rel plan and optimized exec plan . optimized rel plan is the optimized rel plan , and is similar to ' optimized physical plan ' item in the explain result . but different from ' optimized physical plan ' , optimized rel plan can represent either optimized logical rel plan ( for rule",1607633025,"this are minor changes to improve streaming runtime debuggability for the changes introduced with mailbox in branch . <nl> - set a name ( that includes task 's name ) for legacy source thread . this is a port of change that already present in the branch ; <nl> - rename s method to to better reflect method 's intent . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api ,",0.8766194581985474
hazelcast_hazelcast/18326,"enhance the client phone home metrics . <nl> formerly , we were just sending the active clients count at the time <nl> of the phone home operation . this is an attempt to enhance the metrics <nl> sent during the phone home . now , along with the active clients count <nl> at the time of the phone home operation , we are also sending the following <nl> information : . <nl> - connections opened in the last 0 hours ( connections authenticated ) <nl> - connections closed in the last 0 hours <nl> - total connection duration in the last 0 hours ( sum of the duration of the <nl> closed connections + active connections ) <nl> - client versions connected in the last 0 hours . <nl> now , during the phone home , each node will send the number of active clients <nl> in the cluster plus the local informations listed above . <nl> note that , if the phone home is not enabled , we will not collect the informations <nl> listed above .","formerly , we were just sending the active clients count at the time <nl> of the phone home operation . this is an attempt to enhance the metrics <nl> sent during the phone home . now , along with the active clients count <nl> at the time of the phone home operation , we are also sending the following <nl> information : . <nl> - connections opened in the last 0 hours ( connections authenticated ) <nl> - connections closed in the last 0 hours <nl> - total connection duration in the last 0 hours ( sum of the duration",1614684777,- return http 0 for defined endpoints . <nl> - add cluster heath data as custom headers for health check uri ( except clustersafe state ) <nl> - add tests,0.9796874523162842
vespa-engine_vespa/15817,"construct only the relevant application package <cm-sep> create application package once <para-sep> application packages are expensive to construct , and a given test typically only needs to the test in the context of a single system . construct them lazily .",shaves some seconds of controller-server tests .,1608032474,change schema for athenz-provider-service so that it will be generated per zone . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9555392861366272
Alluxio_alluxio/11942,new shell command for displays information for in-alluxio data size under the path group by worker <para-sep> file size in alluxio in memory worker host name path <nl> file size in alluxio in memory path <nl> file size in alluxio worker host name path <nl> file size in alluxio path,it is helpful for spark users to make sure specific path 's in-alluxio data distribution which usually represent a table .,1596900438,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9536952376365662
netty_netty/11077,"sslhandler flushing with tcp fast open fix . <nl> motivation : <nl> sslhandler owns the responsibility to flush non-application data <nl> ( e.g . handshake , renegotiation , etc . ) to the socket . however when <nl> tcp fast open is supported but the client_hello can not be written <nl> in the syn the client_hello may not always be flushed . sslhandler <nl> may not wrap/flush previously written/flushed data in the event <nl> it was not able to be wrapped due to need_unwrap state being <nl> encountered in wrap ( e.g . peer initiated renegotiation ) . <nl> modifications : <nl> - sslhandler to flush in channelactive ( ) if tfo is enabled and <nl> the client_hello can not be written in the syn . <nl> - sslhandler to wrap application data after non-application data <nl> wrap and handshake status is finished . <nl> - socketsslechotest only flushes when writes are done , and waits <nl> for the handshake to complete before writing . <nl> result : <nl> sslhandler flushes handshake data for tfo , and previously flushed <nl> application data after peer initiated renegotiation finishes . <para-sep> we may be here because we read data and discovered the remote peer initiated a renegotiation and this write is to complete the new handshake . the user may have previously done a writeandflush which was n't able to wrap data due to needing the pending handshake , so we attempt to wrap application data here if any is pending .","motivation : <nl> sslhandler owns the responsibility to flush non-application data <nl> ( e.g . handshake , renegotiation , etc . ) to the socket . however when <nl> tcp fast open is supported but the client_hello can not be written <nl> in the syn the client_hello may not always be flushed . sslhandler <nl> may not wrap/flush previously written/flushed data in the event <nl> it was not able to be wrapped due to need_unwrap state being <nl> encountered in wrap ( e.g . peer initiated renegotiation ) . <nl> modifications : <nl> - sslhandler to flush in channelactive (",1615512551,motivation : . <nl> pooling and re-using iovarray works for now but is not safe in its <nl> current form once sqpoll is used as we can not assume we can re-use the <nl> iovarray once we called submit . <nl> modifications : . <nl> just allocate the iovarray on the fly when needed by using the <nl> bytebufallocator . <nl> result : . <nl> code is safe even with sqpoll,0.9415444731712341
hazelcast_hazelcast/18467,"incorporate smallinstanceconfig to spring tests . <nl> most of the tests require a fixed port in the configuration <nl> which fails to create the instance if that port is not available , <nl> likely when running tests in parallel . <nl> i 've enabled port-increment and also disabled join for the tests <nl> excluding the ones needs a cluster . <nl> the spring runner was setting some system properties in a static <nl> block which persists through the rest of the test suite . moved setting <nl> them to before-class and restored them in after-class .","most of the tests require a fixed port in the configuration <nl> which fails to create the instance if that port is not available , <nl> likely when running tests in parallel . <nl> i 've enabled port-increment and also disabled join for the tests <nl> excluding the ones needs a cluster . <nl> the spring runner was setting some system properties in a static <nl> block which persists through the rest of the test suite . moved setting <nl> them to before-class and restored them in after-class . <nl> checklist : .",1617651292,"this pr introduces a feature which allows to disable ( or enable ) scripting on the member . <nl> the scripting is available from hazelcast management center . as it can access underlying system with privileges of user running the hazelcast , administrators may want to disable this feature for security reasons . <nl> the feature is controlled by a new optional attribute under the in : . <nl> default value of the attribute is in hazelcast enterprise and in hazelcast os . <nl> implementation details <nl> new check is added to the . it throws if the scripting is",0.9642152190208435
ballerina-platform_ballerina-lang/26715,add map assertion diff implementation <cm-sep> improve test cases for assertion errors <para-sep> get a list of string values by separating the lines from a string value . <nl> convert a list of string to a string value . <nl> convert a ballerina string array to a list of java strings . <nl> compare whether each key in keylist is available in comparetokeylist . return a list of keys that are not available . <nl> mark the constructor as private . get the ballerina type of an object .,sample 0 . <nl> sample 0 . <nl> sample 0 .,1604398419,add support for delay serverconnector startup at the service deployment time,0.9483400583267212
OpenAPITools_openapi-generator/8318,"- replace apache oltu with scribejava <nl> - implement the following authentication methods <nl> - apikey header <nl> - http basic authentication <nl> - oauth client credentials flow <nl> - oauth implicit flow <nl> - oauth pasword ( deprecated ) <cm-sep> create class hierarchy for oauth flows implementation <cm-sep> add instructions of how to use the apiclient to readme.md <cm-sep> update samples <para-sep> helper method to configure the username/password for basic auth <nl> helper method to configure the client credentials for oauth <nl> helper method to configure the username/password for oauth password grant <nl> set bearer token manually <nl> use api key <nl> use http basic authentication <nl> oauth password <nl> oauth client credentials flow <nl> if the request already have an authorization ( eg . basic auth ) , do nothing <nl> if first time , get the token <nl> configures the client credentials flow <nl> configures oauth password grant flow note : this flow is deprecated . <nl> todo the clientid and secret are optional according with the rfc <nl> set bearer token manually <nl> use api key <nl> use http basic authentication <nl> oauth password <nl> oauth client credentials flow <nl> helper method to configure the username/password for basic auth <nl> helper method to configure the client credentials for oauth <nl> helper method to configure the username/password for oauth password grant <nl> if the request already have an authorization ( eg . basic auth ) , do nothing <nl> if first time , get the token <nl> configures the client credentials flow <nl> configures oauth password grant flow note : this flow is deprecated . <nl> todo the clientid and secret are optional according with the rfc <nl> set bearer token manually <nl> use api key <nl> use http basic authentication <nl> oauth password <nl> oauth client credentials flow <nl> helper method to configure the username/password for basic auth <nl> helper method to configure the client credentials for oauth <nl> helper method to configure the username/password for oauth password grant <nl> if the request already have an authorization ( eg . basic auth ) , do nothing <nl> if first time , get the token <nl> configures the client credentials flow <nl> configures oauth password grant flow note : this flow is deprecated . <nl> todo the clientid and secret are optional according with the rfc","hello . <nl> to sum up this pr addresses the following issues : . <nl> - replaces apache oltu with scribejava <nl> - implements oauth client_credentials grant and password flow . <nl> i can also implement the implicit flow . but i am not sure how to handle the user redirections in this context . these changes focus more on server to server communication . i believe that the implicit flow is considered deprecated , it should be replaced by the authorization code grant . <nl> the following git repo contains the petstore client generated using the code on this",1609762286,"when building a go client with a required parameter of type , a error is countered when compiling the client . <nl> this happens because is currently only defined when a file is optional . this fix does the following : . <nl> * defines when a file is required <nl> * sets to the variable name as defined in the function call . <nl> this approach can only handle a single file , but this is also a limitation of the current go generator can as takes a single pair of and parameters . a future enhancement could support",0.9347060322761536
grpc_grpc-java/7347,"not to use insecure dsa crypto . <nl> although dsa is only used in tests so it 's totally no security concern , it 's annoying we need some workaround for internal checks to import . so removing the usage .","although dsa is only used in tests so it 's totally no security concern , it 's annoying we need some workaround for internal checks to import . so removing the usage .",1598029788,using hostandport just complicates the code .,0.7742401361465454
gocd_gocd/8411,"introduce config repo material test connection api . <nl> * introduce abstractmaterialtestcontroller which contains a controller <nl> method to verify check connection . <nl> * use the abstractmaterialtestcontroller in internalmaterialtestcontrollerv1 <nl> and configreposcontrollerv4 . <cm-sep> allow only admins and pipeline group admins to perform check connection on pipeline materials . <nl> context : . <nl> * prior to gocd release v20.version , gocd had a common material check connection <nl> api to perform material test for pipeline as well as config repo materials . <nl> * as part of gocd release v20.version , gocd added support for granular auth on <nl> config repositories . which in turn required users with granular auth on <nl> config repositories to perform material test connection . <nl> * due to implementation complexities to allow users with access to config <nl> repos to perform material test on such config repo materials , was not possible , <nl> hence , the material test connection api was made accessible for all <nl> authenticated gocd users ( in gocd release v20.version ) . <nl> changeset : . <nl> * this commit brings back the authorization check to allow only super admin <nl> and group admin users to perform material check connection .",implement permissions for config repository material test connection . <nl> * introduce config repo material test connection api <nl> * introduce abstractmaterialtestcontroller which contains a controller method to verify check connection . <nl> * use the abstractmaterialtestcontroller in internalmaterialtestcontrollerv1 and configreposcontrollerv4 . <nl> * allow only admins and pipeline group admins to perform check connection on pipeline materials . <nl> * this commit brings back the authorization check to allow only super admin and group admin users to perform material check connection . <nl> * allow users to perform config repo check connection when user can administer config repo .,1596442754,"this ignores external xml entities in : <nl> - pipeline group xml save . <nl> - shine xunit parsing . <nl> breaking change : . <nl> - if you were using the undocumented agent-side flag , it 'll no longer work . xml is no longer validated against dtd in shine , when parsing xunit reports , even with that flag . <nl> do n't think anyone was using it as .",0.9339491724967957
Alluxio_alluxio/11400,"fix npe related to blocklocations <cm-sep> add logging <cm-sep> fix logic error <cm-sep> better heurstics <cm-sep> more comments and less logging <para-sep> the input stream of hdfs as under filesystem . this input stream has two mode of operations . under sequential mode , it uses the read api and can take advantage of underlying stream 's buffering . this stream can be cached for reuse . todo ( david ) : make these parameters configurations and add diagnostic metrics . after this many number of sequential reads ( reads without large skips ) , it will switch to sequential read mode . <nl> this describes the number of bytes that we can move forward in a stream without switching to random read mode . <nl> the heuristic is that if there are certain number of sequential reads in a row , we switch to buffered read mode . in this mode , preads are serviced via pread calls , and read calls are services by read calls . a sequential read is defined as a read that is within a movement limit of the previous read . this is to guard against workloads such as read , skip ( 0 ) , read , skip ( 0 ) etc . <nl> if there has been a number of sequential reads in a row , we move to regular buffered reads . <nl> same position , use buffered reads as default <nl> no blocks exist <nl> index is larger than byte.max_value , convert to byte to compare <nl> tests the dynamic switching between pread and read calls to underlying stream . <nl> we are in sequential read mode , therefore all reads are normal reads and never preads <nl> because we skipped over more than movement_limit , we switched to pread mode , the next three reads are preads <nl> we performed more than sequential_read_limit reads without seeking beyond movement limit , thus we switch back to sequential read mode <nl> we performed seek to a far location , we should switch back to pread mode","the heuristic works as follows : <nl> 0. it starts with a pread , because a lot of times the client only does a single large read , and we want to benefit from pread in that case . <nl> 0. if there are certain number of sequential reads in a row , we switch to buffered read mode . in this mode , preads are serviced via pread calls , and read calls are services by read calls . a sequential read is defined as a read that is within a movement limit of the previous read . this",1588913457,wrap the correct portion of the byte array and consume the data on the client side properly . also a cosmetic fix in the server exception logging .,0.9660683274269104
pentaho_pentaho-kettle/7667,"performance of the ' write to log ' step when the ' print headers ' checkbox is activated 5x slower since version release <para-sep> obtaining the field name list is a heavy operation , as so , it was removed from the loop . and , as it 's only needed if the header is to be printed , i conditioned the calculation to that scenario . <nl> loop through fields <nl> run log level <nl> step log level ( lower than run 's ) <nl> let 's pretend that it 's not the first invocation <nl> it should n't have done any calculation <nl> run log level <nl> step log level ( equal to run 's ) <nl> let 's pretend that it 's not the first invocation <nl> run log level <nl> step log level ( higher than run 's ) <nl> let 's pretend that it 's not the first invocation",performance of the ' write to log ' step when the ' print headers ' checkbox is activated 5x slower since version release .,1599131748,cherry-pick of sha and sha .,0.9581016302108765
apache_druid/10309,introduce dynamicconfigprovider interface and make kafka consumer props extensible <para-sep> this is used to get configuration in various places in an extensible way . <nl> additional dynamicconfigprovider based extensible support for all consumer properties,this patch really came from need of supplying few kafka consumer properties such as using user specific extensible mechanisms similar to,1598065967,"# # # description <nl> this pr fixes an issue where the metric is double counted for ssl connections due to the way _all_ instances are wrapped in in initialization , instead of what i believe to be the correct usage of only monitoring the default for the . <nl> the tls is constructed with 0 instances : . <nl> it is my understanding ( and observation using the debugger ) that _both_ create a connection , the to un-encrypt the request connection , and the to do http stuff to the now un-encrypted connection . however , since both",0.9583927989006042
apache_shardingsphere/9133,order by primary keys ascending if simple sql without order by for mysql,"changes proposed in this pull request : <nl> - order by primary keys ascending if simple query sql without order by clause for mysql ( just support simple query sql : single table , no join tables , no subquery , no aggregation , table has primary key )",1611315181,add test case for optimizeengine ( 添加optimizeengine的测试用例 ),0.9530279636383057
vespa-engine_vespa/16850,revert ' revert ' reapply ' jonmv/new hosted apps use dedicated cluster controllers ' ' ' <cm-sep> return early if application already exists <para-sep> create the given number of hosts using the supplied versions -- the last version is repeated as needed . * /,"might be called even if application already exists , do nothing in that case ( otherwise we might end up modifying reindexing or dedicated cluster controllers setup ) .",1615278796,"this should n't have an functional changes , just some cleanup refactoring to make it easier to reuse this for future proxy api .",0.9431730508804321
apache_pulsar/9024,fix send transaction messages in order <cm-sep> fix <cm-sep> remove repeat deduplicate check <para-sep> we need to issue the request to tc to register the produced topic <nl> we need to issue the request to tc to register the acked topic,"currently , the transaction messages would be produced in the wrong order , and the deduplication check is not work well . <nl> describe the modifications you 've done . <nl> this change added tests and can be verified as follows : . <nl> - org.apache.pulsar.client.impl.transactionendtoendtest # producetxnmessageordertest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations :",1608615690,"creating a topic does not wait for creating cursor of replicators . <nl> the exists unit test can cover this change . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options",0.9620286822319031
apache_shardingsphere/9750,add sqlservertablemetadataloader <para-sep> table meta data loader for sqlserver . <nl> table meta data loader for sqlserver .,changes proposed in this pull request : <nl> - add sqlservertablemetadataloader,1616170709,changes proposed in this pull request : <nl> - add test cases for datanode,0.9862170815467834
apache_pulsar/9163,"avoid enable dlq on key_shared subscription . <cm-sep> add doc . <para-sep> should n't happen , as exception was thrown if dlq enabled for key_shared sub type , rawreader use exclusive sub type so should be fine . <nl> creates new client connection <nl> make sure message not acked sent to retry topic . <nl> make sure no message sent to dead letter topic . <nl> through builder <nl> through constructor <nl> do n't set dlq for key shared subtype since it requires msg to be ordered for key . <nl> dlq only supports non-ordered subscriptions , do n't enable dlq on key_shared subtype since it require message ordering for given key . <nl> not setting a default dlq if it 's key_shared subtype . <nl> dlq only supports non-ordered subscriptions , do n't enable dlq on key_shared subtype since it require message ordering for given key . <nl> do n't provide a default dlq to key_shared sub type as dlq ca n't guarantee order . <nl> the params are all different with the default value <nl> wo n't set dlq by default <nl> throw exception from consumer builder if client try to set dlq for key_shared sub type .","in pulsar , dlq only supports non-ordered subscriptions , but now the key_shared subscription also allowed enable dlq . <nl> should avoid enable dlq on the key_shared subscription tpye . <nl> only send message to dlq if not key_shared subscription type . <nl> this change added tests and can be verified as follows : <nl> - added unit test . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : no <nl> - the schema : no <nl> - the",1610269773,"this change introduces a new namespace policy , which will enable an override of broker settings on the namespace level . you may keep disabled for the broker and allow it on a specific namespace using this feature . <nl> - add new namespace policy : and associated api / cli interface for setting and removing . defaults to non-partitioned type , but also allows partitioned topics . <nl> - modifies brokerservice : when checking configuration , the broker first retrieves namespace policies from zookeeper . if the policy exists for that namespace then it uses those settings . if",0.9803146123886108
apache_kafka/9667,"do not print log4j for memberid required <para-sep> we do not need to log error for memberid required , since it is not really an error and is transient","for memberidrequiredexception , we would not print the exception at info with a full exception message since it may introduce more confusion that clearance .",1606848566,"background : i 've spotted tons of kafka related errors in logs , after investigation i found out that those are harmless as being retried . <nl> hence i propose to not log retriable exceptions as errors . <nl> examples of what i 've see in logs : . <nl> * offset commit failed on partition .. at offset .. : the request timed out . <nl> * offset commit failed on partition .. at offset .. : the coordinator is loading and hence ca n't process requests . <nl> * offset commit failed on partition .. at offset ..",0.8467520475387573
OpenAPITools_openapi-generator/7607,"add oneof support to c # netcore <cm-sep> add oneof support to c # netcore client <cm-sep> update samples <para-sep> add implements for serializable/parcelable to all models <nl> if oneof contains ' null ' type <nl> if anyof contains ' null ' type <nl> / / abstract base class for oneof , anyof schemas in the openapi specification / <nl> openapi generated types generally hide default constructors . <nl> / / gets or sets the actual instance / <nl> / / gets or sets isnullable to indicate whether the instance is nullable / <nl> / / gets or sets the schema type , which can be either or / <nl> / / converts the instance into json string . / <nl> / / converts the json string into the instance / <nl> the object to be serialized is an oneof/anyof schema <nl> the response is an oneof/anyof schema <nl> if the response type is oneof/anyof , call fromjson to deserialize the data <nl> if the response type is oneof/anyof , call fromjson to deserialize the data <nl> / / { { # description } } { { . } } { { /description } } { { ^description } } { { classname } } { { /description } } / <nl> / / initializes a new instance of the class . / <nl> / / initializes a new instance of the class / with the class / / an instance of { { { . } } } . <nl> / / gets or sets actualinstance / <nl> / / get the actual instance of . if the actual instanct is not , / the invalidclassexception will be thrown / / an instance of { { { . } } } <nl> / / returns the string presentation of the object / / string presentation of the object <nl> / / returns the json string presentation of the object / / json string presentation of the object <nl> / / converts the json string into the object / / json string <nl> deserialization failed , try the next one uncomment the line below for troubleshooting console.writeline ( exception.tostring ( ) ) ; <nl> deserialization is considered successful at this point if no exception has been thrown . <nl> / / returns true if objects are equal / / object to be compared / boolean <nl> / / returns true",- add oneof support to c # .net core client <nl> - add tests <nl> - tested locally with api servers supporting oneof and the result is ok for oneof response .,1601902411,"c.c . <nl> the reason for the error was that these enums were not generated as but they where being assigned and compared to . <nl> i have fixed the error by : . <nl> * adding a piece of code in the template , that adds a after parameter data types when the parameter is non-required and non-nullable . <nl> * correctly marking the and properties of operation parameters in the post-process performed in .",0.9171645045280457
elastic_elasticsearch/72465,"add warnings if timer thread is late to wake up . <nl> sometimes we encounter a node that appears simply to have frozen for a <nl> while - maybe something sent it a or maybe the underlying vm <nl> just paused . the effects of this can be pretty weird and in particular <nl> they 're hard to distinguish from other problems . <nl> the thread is supposed to wake up every 200ms or so just to <nl> update the cached time . with this commit we also look at how the clocks <nl> changed while the thread was asleep , and log a warning if it 's too far <nl> away from our expectations . <para-sep> busy-waiting is the whole point ! noinspection busywait <nl> yeah really should n't happen but at least we should log the right warning","sometimes we encounter a node that appears simply to have frozen for a <nl> while - maybe something sent it a or maybe the underlying vm <nl> just paused . the effects of this can be pretty weird and in particular <nl> they 're hard to distinguish from other problems . <nl> the thread is supposed to wake up every 200ms or so just to <nl> update the cached time . with this commit we also look at how the clocks <nl> changed while the thread was asleep , and log a warning if it 's too far <nl> away",1619697544,"this commit unmutes and fixes tests around some geolineaggregator edge <nl> cases . <nl> - mergedgeolines had a silly bug where it was accepting internalgeolines <nl> that were empty <nl> - ' complete ' is measured by the heap-mode of the bucketedsort , which is a problem <nl> since if the length of the data equals the max-size , then it is difficult to know <nl> whether any values were discarded . <nl> - geolinebucketsort had an array-resizing bug s/ > / > = .",0.9613943696022034
elastic_elasticsearch/70720,add documentation for clone api java api . <cm-sep> fix <para-sep> tag : :clone-snapshot-request <nl> end : :clone-snapshot-request <nl> tag : :clone-snapshot-request-indices <nl> end : :clone-snapshot-request-indices <nl> tag : :clone-snapshot-request-mastertimeout <nl> end : :clone-snapshot-request-mastertimeout <nl> tag : :clone-snapshot-request-index-settings <nl> end : :clone-snapshot-request-index-settings <nl> tag : :clone-snapshot-execute <nl> end : :clone-snapshot-execute <nl> tag : :clone-snapshot-response <nl> end : :clone-snapshot-response <nl> tag : :clone-snapshot-execute-listener <nl> end : :clone-snapshot-execute-listener <nl> replace the empty listener by a blocking listener in test <nl> tag : :clone-snapshot-execute-async <nl> end : :clone-snapshot-execute-async <nl> >,this commit adds some missing documentation about the clone snapshot java api .,1616497869,adds option to the . <nl> updates documentation as well to reflect the changes .,0.9445201754570007
apache_beam/12732,supporting delimiter for gcsutil.listobjects . this will allow users to not list full directory trees for limited searches .,this will allow users to avoid list full directory trees for limited searches .,1598767595,"this should be safe now , after a dataflow worker release that is more correctly shaded and picks up fresh versions of this code .",0.8514470458030701
ballerina-platform_ballerina-lang/26358,implement classdefinitiondeclarationnode transformation in formatter <para-sep> todo : fix formatting issue when the function is within a class definition declaration . <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar,> - implementation of and methods <nl> > - fix some failing formatter related test cases .,1602702986,"the last parameter of resource signature represents the payload . adding body annotation with the payload parameter name is essential . <nl> > consume payload at thin layer and handover it to ballerina as a bvalue . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9132060408592224
vespa-engine_vespa/15637,introduce trial tenant limit . <nl> create a feature flag that has the max nr . of tenants with the trial <nl> plan . if the number is exceeded we fail creation of new tenants ( who <nl> are implicitly in the trial plan ) . <cm-sep> expose create trial limit in user api . <nl> - exposed the create trial tenant limit in the user api <nl> - changed the interface to the billingcontroller to be something that returns the <nl> tenants with a given plan instead of a full map tenant - > plan . <para-sep> tests that exceeding the limit throws a forbiddenexception,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1607000064,- expose the maximum quota usage rate in the configuration server <nl> - query for the quota usage rate right after deploy in the controller <nl> - store the quota usage rate together with the deployment information in zk,0.970768928527832
Alluxio_alluxio/11224,change checking for job completions in distributedloadcommand to be done in parallel <para-sep> waits for at least one job to complete .,"after submitting a large number of jobs to the jobservice , the code previously checked if some of the jobs are complete in serial , this code changes that to be done in parallel so that new jobs can be scheduled more quickly .",1585671890,"we usually retry all journal operations in case of temporary journal unavailability , but the journal reads in slipped through the cracks , allowing the master to crash if the journal is unavailable during startup or failover .",0.8631938695907593
apache_kafka/9848,": extract setup of repartition topics from the streams partition assignor . <nl> to implement the explicit user initialization of kafka streams as <nl> described in , we first need to extract the code for the <nl> setup of the repartition topics from the streams partition assignor <nl> so that it can also be called outside of a rebalance . <para-sep> ensure the co-partitioning topics within the group have the same number of partitions , and enforce the number of partitions for those repartition topics to be the same if they are co-partitioned as well . <nl> make sure the repartition source topics exist with the right number of partitions , create these topics if necessary <nl> augment the metadata with the newly computed number of partitions for all the repartition source topics <nl> computes the number of partitions and sets it for each repartition topic in repartitiontopicmetadata <nl> try set the number of partitions for this repartition topic if it is not set yet <nl> if this topic is one of the sink topics of this topology , use the maximum of all its source topic partitions as the number of partitions <nl> it is possible the sourcetopic is another internal topic , i.e , map ( ) .join ( ) .join ( map ( ) )","to implement the explicit user initialization of kafka streams as <nl> described in , we first need to extract the code for the <nl> setup of the repartition topics from the streams partition assignor <nl> so that it can also be called outside of a rebalance .",1610132290,adding timewindowedcogroupedkstream options to the cogroup operator .,0.9687554240226746
vespa-engine_vespa/16494,"also deny maintenance when another node is in maintenance . <nl> the cluster controller today already denies setting a node x safely to <nl> maintenance m , if there is another node y in another group that has wanted <nl> state m. which means that if y is in m but wanted state is not m , x is allowed <nl> to be set in m. this is an edge case which is rare . <para-sep> because 0 is in a different group maintenance should be denied <nl> because 0 and 0 are in the same group as 0 , these should be ok <nl> set all to up <nl> now we should be allowed to upgrade second group , while the first group will be denied <nl> and set second group up again <nl> sets up 0 groups : [ 0 , 0 , 0 ] and [ 0 , 0 , 0 ] , with 0 being in maintenance","the cluster controller today already denies setting a node x safely to <nl> maintenance m , if there is another node y in another group that has wanted <nl> state m. which means that if y is in m but wanted state is not m , x is allowed <nl> to be set in m. this is an edge case which is rare .",1613131837,"the test bundle has been expanded with three new defs that have package , package in the filename and both package and namespace . <nl> when both are present , package is used as namespace .",0.9091314673423767
confluentinc_ksql/6287,remove feature flag in processing log statement <cm-sep> clean up other uses of feature flag <cm-sep> do not require feature flag for default formats <cm-sep> qtt historic plans <cm-sep> qtt for missing value format,"this pr updates the feature flag to only guard the latter and not the former . in other words , is not longer a required property . an error is thrown if is not provided and is not set . <nl> this pr also cleans up a few unnecessary usages of the feature flag , in light of the decision to allow the use of and even when the feature flag is not enabled . <nl> if we feel strongly about keeping the docs in sync , we can either hold on this pr until version or split the docs",1600880326,"this pr now just contains some tidy up and test changes . <nl> we will flip the default , to favour the new impl , in a future release .",0.9219080805778503
apache_kafka/9747,: alterisr should be a cluster action . <nl> this ensures it wo n't get throttled . <para-sep> newer protocol apis include throttle time ms even for cluster actions,set it as a cluster action and update the handler in kafkaapis . we keep the throttletimems field <nl> since we intend to enable throttling in the future ( especially relevant when we switch to the <nl> built-in quorum mode ) .,1607958098,"* in checkpoint.write ( ) , if the offset map passed in is empty , skip the writing of the file which would only contain version number and the empty size . from the reading pov , it is the same as no file existed . <nl> * add related unit tests . <nl> * minor fixes on log4j messages .",0.8765597343444824
vespa-engine_vespa/15706,"revert ' revert ' add convenience functions for transformer models ' ' . <nl> this reverts commit sha . <cm-sep> do n't transform feature if it has wrong arity <para-sep> convenience feature transforms for inputs to transformer type models . replaces features of the form token_input_ids token_type_ids token_attention_mask to tensor generation expressions that generate the required input . in general , these models expect input of the form : cls + arg1 + sep + arg2 + sep + 0 's <nl> transforms a feature of the form token_input_ids ( 0 , a , b , ... ) to an expression that concatenates the arguments a , b , ... using the special transformers sequences of cls and sep , up to length 0 , so that the sequence becomes cls + a + sep + b + sep + 0 's concretely , transforms to a tensor generation expression : tensor ( d0 [ 0 ] , d1 ) ( if ( d1 < 0 , 0 , if ( d1 < 0 + length_a , a { d0 : ( d1 - ( 0 ) } , if ( d1 < 0 + length_a + 0 , 0 , if ( d1 < 0 + length_a + 0 + length_b , b { d0 : ( d1 - ( 0 + length_a + 0 ) ) } , if ( d1 < 0 + length_a + 0 + length_b + 0 , 0 , version ) ) ) ) ) ) functions calculating lengths of arguments are added to the rank profile . <nl> we need to add functions calculating the token lengths of the arguments <nl> create token sequence : cls + arg1 + sep + arg2 + sep + .... <nl> transforms a feature of the form token_type_ids ( 0 , a , ... ) to an expression that generates a tensor that has values 0 for ' a ' ( including cls and sep tokens ) and 0 for the rest of the sequence . concretely , transforms to a tensor generation expression : tensor ( d0 [ 0 ] , d1 ) ( if ( d1 < length_a + 0 , 0 , 0 ) ) <nl> we need to add functions calculating the token lengths of the arguments <nl> transforms a feature of the form token_attention_mask ( 0 , a , b ,","performance test broke because of a global rank profile was generated from an imported onnx model , and the input name was the same as the name for one of these functions . the solution is to not transform the feature if it has a different arity than expected , thus referring to something else .",1607328958,"i have not connected this to any build mechanism yet . also , while it built successfully in its previous location , i have n't tested it for building here yet .",0.9834043979644775
runelite_runelite/12168,update itemstats plugin to check for two handed interactions <para-sep> used if switching into a 0 handed weapon to store off-hand stats <nl> check if this is a shield and there 's a two-handed weapon equipped <nl> account for speed change when two handed weapon gets removed shield - ( 2h - unarmed ) == shield - 2h + unarmed <nl> get offhand 's stats to be removed from equipping a 2h weapon,"adds some logic to account for two handed weapon interactions when hovering over items to get stat changes with the itemstats plugin . requires runelite/runelite-wiki-scrapper to be updated with this pull request to have the functionality work properly . without this , the old behaviour remains . <nl> examples : . <nl> switching to 2h accounts for shield removal : . <nl> switching to shield accounts for main hand being two handed : . <nl> equipping a 2h with only a shield :",1594932543,this allows players to select from a number of positions where they <nl> would like highlighted player 's names to be drawn relative to the <nl> player 's model .,0.9133697748184204
confluentinc_ksql/6380,"rename schema_id to value_schema_id <cm-sep> support getting key schemas from supplier <cm-sep> support key schema inference in injector <para-sep> safe to cast as we know is <nl> key columns are only injected if : the statement does not defined any key columns . the key format of the statement supports schema inference . and similarly for value columns . if key and/or value columns are present , then they are passed through unchanged . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> given : <nl> given : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> then : <nl> when : <nl> when : <nl> then :","this pr adds support for reading key schemas from schema registry . as part of doing so , the undocumented feature has been renamed to and a separate has been added . whether we want to document these features and make them officially supported or not is a separate conversation from this pr , though this pr does wire up the new config . <nl> three commits : <nl> - rename to and add <nl> - enhance to support fetching key schemas from schema registry <nl> - enhance to support key schema inference . <nl> added unit tests . waiting",1602111129,"pull queries can now reference windowend in their where clause , ( assuming the source is windowed ) : . <nl> usual .",0.977605402469635
apache_shardingsphere/10077,rename composablesqltoken <cm-sep> refactor ownertoken <para-sep> composable sql token . <nl> add sql token . <nl> todo need to clear the quotecharacter 's owner <nl> get quote character .,changes proposed in this pull request : <nl> - rename composablesqltoken <nl> - for code format <nl> - add todo for clear the quotecharacter 's owner,1618319042,- inline xid broadcast <nl> - clear xid of sub thread when sql executed <nl> - revise unit test,0.9312620759010315
vespa-engine_vespa/15299,set state for session instead of deleting it when deleting an application . <nl> simplify by just setting the state of the active session belonging to an <nl> application that is deleted . this is more in line with what we do for other <nl> transitions . <nl> inactive sessions will be deleted nby maintainers in config server after <nl> some time <para-sep> delete app and verify that it has been deleted from repos and provisioner and no application set exists,set state for session instead of deleting it when deleting an application . <nl> simplify by just setting the state of the active session belonging to an <nl> application that is deleted . this is more in line with what we do for other <nl> transitions . <nl> inactive sessions will be deleted by maintainers in config server after <nl> some time .,1605120364,follow the same policy as non-docker nodes : test for the active state before asking the orchestrator for permission to suspend .,0.9105631113052368
apache_shardingsphere/9913,bugfix <para-sep> execution initializer one time after container started .,changes proposed in this pull request : <nl> - repeatedly initialize ( fill data ) due to incorrect state . <nl> - simplify the process .,1617347288,changes proposed in this pull request : <nl> - perfect start symbol <nl> - fix setnames <nl> - add support of <nl> - add support of <nl> - add testcase of <nl> - add testcase of,0.9246608018875122
Graylog2_graylog2-server/8948,add phone number to free enterprise license request,add phone number to free enterprise license form .,1599758156,"installing a dashboard through a content pack will reuse old widget ids , ensuring references from other installed entities can still be used . <nl> this is needed because dashboard widgets do n't have their own , making it impossible to find the referenced widget during install . as widget ids are embedded inside the dashboard document , potentially duplicating widget ids should not be a problem .",0.8795420527458191
apache_pulsar/9671,abstract repetitive code and add unit tests . <para-sep> restart the entire function or restart a single instance of the function <nl> only restart single instance <nl> mock pulsaradmin sources sinks functions <nl> build three types of functionmetadata <nl> verify restart function/source/sink using different assignment <nl> mock pulsaradmin sources sinks functions <nl> build three types of functionmetadata <nl> verify restart function/source/sink using different assignment,"- adding a unit test for the method . <nl> and i am a newcomer to the pulsar community , do i need to recreate an issue ?",1613995871,"# # # motivation . <nl> for externally managed functions , there is really no point in stopping and starting a function instance if there is no change to the metadata of the function but the function instance got rescheduled to other worker .",0.9615351557731628
Graylog2_graylog2-server/9109,"update ldap auth service configuration . <nl> replace the ' server_urls ' field with a ' servers ' field . <nl> the new field contains a list of objects including ' host ' and ' port ' . <nl> example : <nl> { ' servers ' : [ { ' host ' : ' version ' , ' port ' : 0 } ] }","this pr replaces the auth backend ' server_urls ' field with a ' servers ' field . <nl> the new field contains a list of objects including ' host ' and ' port ' . <nl> example : . <nl> if you 've already configured an authentication service with the new idp ui , you need to drop the collection .",1602085230,the cluster state can turn red even though the current write index is green . this might happen when running rotation/retention during an es maintenance window where not all nodes are present . <nl> for index related tasks we are now checking the state of the current write index ( deflector ) instead of the state for all graylog managed indices . <nl> the logs and ui are still showing the red cluster state to make sure the admin will be notified .,0.9135314226150513
hazelcast_hazelcast/18238,"make cachedqueryentry to implement ids . <nl> the fix is not straightforward , there is some extra complexity <nl> so recording here for future generations : . <nl> this changeset makes cachedqueryentry to use the same class id <nl> as lazymapentry which already is serializable . this means why you <nl> serialize cachedqueryentry and deserialize again you will get <nl> an instance of lazymapentry . this is already confusing enough , <nl> but it gets worst : lazymapentry is subclass of cachedqueryentry ! <nl> so you might be asking : what is going on ? <nl> the explanation is not simple , but i will try anyway : . <nl> i could make the cachedqueryentry to use a separate class id . but this means <nl> all clients would have to be updated as well . as they would not know this new id . <nl> still , this on its own would not justify using a class id belonging to <nl> a different class . this is the contract of lazymapentry : ' when you serialize <nl> and deserialize lazymapentry it loses its ' lazy ' properties . ' after deserialize <nl> it behaves as if it was a plain simplemapentry and that 's exactly what we need . <nl> todo : write sed-de test for cachequeryentry <para-sep> we are intentionally deserializing cachedqueryentry as lazymapentry lazymapentry is actually a subclass of cachequeryentry . if this sounds surprising , convoluted or just plain wrong then you are not wrong . please see commit message for reasoning . <nl> we skip combinations where ( format= , parallel= , postfix= * , useindex=true , usepredicate=false ) because it 's pointless to create an index when a predicate is not used","cachedqueryentry is an output of maxby/minby aggregations <nl> when aggregating entries matching a predicate which was <nl> evaluated by using an index . <nl> the fix is not straightforward , there is some extra complexity <nl> so recording here for future generations : . <nl> this changeset makes cachedqueryentry to use the same class id <nl> as lazymapentry which already is serializable . this means why you <nl> serialize cachedqueryentry and deserialize again you will get <nl> an instance of lazymapentry . this is already confusing enough , <nl> but it gets worst : lazymapentry is subclass of cachedqueryentry !",1613663891,to enable s for auto-discovered maps on jet side .,0.9287064075469971
apache_pulsar/9221,": coordinationservice <para-sep> represent the caching layer access for a specific type of objects . <nl> tries to fetch one item from the cache or fallback to the store if not present . <nl> check if an object is present in cache without triggering a load from the metadata store . <nl> return all the nodes ( lexicographically sorted ) that are children to the specific path . if the path itself does not exist , it will return an empty list . <nl> read whether a specific path exists . note : in case of keys with multiple levels ( eg : '/a/b/c ' ) , checking the existence of a parent ( eg . '/a ' ) might not necessarily return true , unless the key had been explicitly created . <nl> perform an atomic read-modify-update of the value . the modify function can potentially be called multiple times if there are concurrent updates happening . <nl> perform an atomic read-modify-update of the value . the modify function can potentially be called multiple times if there are concurrent updates happening . <nl> create a new object in the metadata store . this operation will make sure to keep the cache consistent . <nl> delete an object from the metadata store . this operation will make sure to keep the cache consistent . <nl> implementation is invalid <nl> a resource lock is already taken by a different instance . <nl> the store was already closed . <nl> the path of the value <nl> interface for the coordination service . provides abstraction for distributed locks and leader election . <nl> increment a counter identified by the specified path and return the current value . the counter value will be guaranteed to be unique within the context of the path . <nl> leader election controller . <nl> try to become the leader . warning : because of the distributed nature of the leader election , having been promoted to ' leader ' status will never provide a strong guarantee that no one else also thinks it 's the leader . the caller will have to deal with these race conditions when using the resource itself ( eg . using compareandset ( ) or fencing mechanisms ) . <nl> get the current leader election state <nl> get the value set by the elected leader , or empty if there 's currently no",added abstraction implemented on top of . <nl> coordinationservice provides : <nl> * locks management <nl> * leader election <nl> * unique numbers generator,1610741896,add a sample/usable schema implementation .,0.9895492196083069
elastic_elasticsearch/71938,treat all string values as nullable,"in rare cases , some string values in http client stats can be null so they should all be treated as optional .",1618926020,"we were n't originally going to backport this , but then the vs refactor landed in 0.x sooner than expected , so this should come too . but it got held up by other parts that had to be backported / fixed first . : )",0.8616206645965576
runelite_runelite/12479,add a porcine of interest and daddy 's home to quest enum <cm-sep> add a porcine of interest quest start location <cm-sep> add sourhog cave dungeon location,adds a porcine of interest and daddy 's home to quest enum . <nl> adds worldmap location for a porcine of interest quest start . <nl> adds worldmap location for sourhog cave dungeon entrance,1599756580,adds two entries to the miningsitelocation enumeration so that the proper labels appear on the ' prifddinas ' map and are consistent with those shown on the ' runescape surface ' map .,0.8901477456092834
elastic_elasticsearch/70518,"accept any type in after in composite aggs if the field is unmapped . <nl> when multiple indices are searched and in one index the field is unmapped and <nl> in another index the field is mapped as a numeric value , it is possible to <nl> end up with numbers in the expression . this commit fixes a confusing <nl> error message that is generated in such cases . <para-sep> the value might be not string if this field is missing in this shard but present in other shards and does n't have a string type","when multiple indices are searched and in one index the field is unmapped and <nl> in another index the field is mapped as a numeric value , it is possible to <nl> end up with numbers in the expression . this commit fixes a confusing <nl> error message that is generated in such cases .",1616007940,"this commit fixes a bug on the composite aggregation when the index <nl> is sorted and the primary composite source needs to round values ( date_histo ) . <nl> in such case , we can not take into account the subsequent sources even if they <nl> match the index sort because the rounding of the primary sort value may break <nl> the original index order .",0.8587497472763062
grpc_grpc-java/7356,eliminate logic for receiving updated cds config with cluster name changed . this should never be the use case . <cm-sep> reimplement tests . <para-sep> load balancer for cds_experimental lb policy . one instance per cluster . <nl> no-op <nl> no-op,reviewer may just want to read the whole file instead of diffs .,1598348909,"a lot of locs here are whitespace changes or removals . <nl> function changes after vs before : . <nl> after <nl> ===== . <nl> binarylog.java is the class that is responsible for intercepting <nl> client and server calls . it now requires a callid to be passed <nl> in . the binarylogprovider is responsible for generating a <nl> callid . <nl> censusbinarylogprovider will generate a callid based on census <nl> info . for the server callid , my intention is to read the census <nl> info from the context . for the client callid , the census span is",0.9671967625617981
Alluxio_alluxio/11310,"clean resources properly within readhandler . <nl> by cleaning up the resources in the correct way , we avoid one major <nl> issue , which is forgetting to unlock a block when the call fails . <para-sep> handle any exception which should abort the client 's read request . <nl> once we get the data buffer , the lock on the block has been acquired . if there are any stream errors during this time , we must unlock the block before exiting .","before this change , it was possible for workers to get into a state where all reader threads were starved because locks were taken for a certain block , but never released , so every time a new reader thread would attempt to acquire a lock on that block , it would hang the thread forever . eventually all reads would fail . <nl> this pr attempts to fix the issue by making some more guarantees about the serialized task executor , as well as cleaning up resources and sending a proper response back to the client whenever an error",1587119771,"this pr improves the gcs ufs similar to our previous improvements to s3a ufs . <nl> ( 0 ) move all permission related code to and memorize the permission ( only get the permission for once and remember it ) . this change mocks what s3a ufs does . <nl> ( 0 ) in , mainly reorganize the codes . move create related codes in the other than in the constructor . the constructor suppose to not throw exceptions . use and similar to what s3a ufs does . <nl> ( 0 ) remove the in since its super class",0.9663349390029907
elastic_elasticsearch/71605,"service accounts - add rest api for service account cache invalidation <cm-sep> do not cache failed auth result <para-sep> do not cache failed attempt <nl> invalidate cache entries with keys matching to the specified qualified token names . <nl> wildcard case of invalidating all tokens for a service account , e.g . ' elastic/fleet-server/ ' <nl> this is the wildcard case for tokennames <nl> 5th auth with the wrong token2 again does not use cache <nl> invalidate a single entry <nl> invalidate all entries <nl> auth everything again <nl> validation should pass",this pr adds a new rest endpoint to clear caches used by service account authentication .,1618274385,"currently a failed peer recovery action will fail an recovery . this <nl> includes when the recovery fails due to potentially short lived <nl> transient issues such as rejected exceptions or circuit breaking <nl> errors . <nl> this commit adds the concept of a retryable action . a retryable action <nl> will be retryed in face of certain errors . the action will be retried <nl> after an exponentially increasing backoff period . after defined time , <nl> the action will timeout . <nl> this commit only implements retries for responses that indicate the <nl> target node has not executed",0.9712398648262024
runelite_runelite/11901,add new darkmeyer master step . <cm-sep> center some location spots . <nl> center some hot-cold locations as reported and verified from the mega <nl> issue .,center some hot-cold locations as reported and verified from the mega <nl> issue .,1592207497,"the locations for these two hot-cold clue spots were not fully accurate ( digging on the spot marked did not advance to the next clue step ) , so i 've updated them with spots which will work when digging on them .",0.8215691447257996
neo4j_neo4j/11138,"simplified boltrequestmessagehandler interface . <nl> by removing exception type parameter . it was always <nl> for production code . only test code used checked . <nl> this commit makes type simpler and converts exceptions to unchecked <nl> in tests . <cm-sep> support for temporal types in bolt . <nl> this commit makes bolt version 0 aware of six new temporal types : <nl> datetime , localdatetime , date , time , localtime and duration . bolt <nl> server will now be able to serialize and deserialize these types . <nl> datetime type contains time zone information either as an offset or <nl> as a zone name . that is why it is presented as two distinct types <nl> in bolt . first contains offset as integer and second contains zone <nl> name as string . <para-sep> interface defining simple handler methods for each defined bolt request message .","this pr makes bolt version 0 aware of six new temporal types : datetime , localdatetime , date , time , localtime and duration . bolt server will now be able to serialize and deserialize these types . <nl> datetime type contains time zone information either as an offset or as a zone name . that is why it is presented as two distinct types in bolt . first contains offset as integer and second contains zone name as string .",1519914434,o added test that verifies database does not block writes while populating constraint index . <nl> o verifies that constraint deletion works in ha clusters . <nl> o added test to verify new slave joining cluster properly initializes constraints <nl> o added before/after records for schema commands to allow deleting schema rules from <nl> logical log .,0.9689494371414185
jenkinsci_jenkins/4833,"demonstrating that util.isoverridden is broken on final overrides <cm-sep> make errorcollector actually work <cm-sep> improve util.isoverridden . <nl> it will now deal with final/abstract methods appropriately . <nl> it will also clearly report bad arguments ( base not base of derived , or base does not declare the method ) . <nl> added a unit test for interface cases . <nl> small gap to be looked into : overrides provided via default implementation of a ( derived ) interface . <para-sep> checks whether the method defined on the base type with the given arguments is overridden in the given derived type . <nl> if derived is not a subclass or implementor of base , it ca n't override any method technically this should also be triggered when base == derived , because it ca n't override its own method , but the unit tests explicitly test for that as working . <nl> the lookup will either return null or the base method when no override has been found ( depending on whether the base is an interface ) <nl> private and static methods are never ok , and end the search <nl> when looking for the base/declaring method , final is not ok <nl> when looking for the overriding method , abstract is not ok <nl> if the base is an interface , the implementation may come from a default implementation on a derived interface . so look at interfaces too . <nl> method not found in clazz , let 's search in superclasses <nl> if the superclass does n't derive from base anymore ( or is base ) , stop looking <nl> trying to check for a method which does not exist in the hierarchy . specifying a base class that is not a base class should result in an error . * / <nl> normal case : classes implementing interface methods <nl> special case : interfaces providing default implementation of base interface",* : fix error caused by misbehaviour in ( regression in version ),1594152705,"saw some slow request stack traces that included threads apparently running inside , for example , . <nl> this patch <nl> - avoids copying the mutable into a new unless it is actually being extended <nl> - caches the s applicable to a given type .",0.9169765114784241
elastic_elasticsearch/71643,enhanced segment files sizes information in nodes stats/indices stats apis,"this pull request adds a bit more information about file sizes like the number of files ( ) , the , and average file sizes in bytes that share the same extension . here is a sample : . <nl> i think that these information give a better view of the segment files and are useful in many cases , specially with searchable snapshots whose segment stats can now be introspected thanks to the parameter .",1618327510,"this commit changes how cache files synchronization interacts with <nl> the persistent cacge in searchable snapshots . before this change it <nl> was possible that synchronization reintroduces information about <nl> an evicted cache file in the persistent cache lucene index . <nl> this commit introduces an queue of cache file events that are <nl> periodically processed by the cache synchronization method . the <nl> events refer to a specific cache file and a type of event ( deletion or <nl> fsync needed ) that must be processed by the cache synchronization <nl> method , which in turn applies the appropriate",0.9770278334617615
elastic_elasticsearch/71482,"<para-sep> enables or disables collection of http client stats . <nl> when disabling , immediately clear client stats <nl> the listener code above should never throw <nl> http client stats should default to enabled <nl> after disabling , http client stats should be cleared immediately <nl> after disabling , http client stats should not track new clients <nl> after re-enabling , http client stats should now track new clients","in scenarios with high http client churn , it could be beneficial to disable collection of http client stats to reduce load . <nl> as this improves a not-yet-released feature .",1617896254,"the rollover action would perform a datastream rollover irrespective if the <nl> managed index was the write index or not . this could lead to multiple rollovers <nl> being executed eg . a manual call rolls over the datastream and later an ilm <nl> managed index , the previous write index , will do so too . there are similar <nl> scenarios possible if the step failed ( due to various reasons including <nl> ) and succeded when retried . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan .",0.962701141834259
apache_kafka/9816,": integrate snapshot id with raft 's fetch response <cm-sep> add tests for kafka metadata log <para-sep> to the follower . if the message is a duplicate message the segment base offset and relative position in segment will be unknown . <nl> before appending update the first offset metadata to include segment information <nl> if the log start offset changed , then this method also update a few key offset such that . the leader epoch cache is also updated such that all of offsets referenced in that component point to valid offset in this log . <nl> this object needs to be thread-safe because it is used by the snapshotting thread to notify the polling thread when snapshots are created . <nl> the oldest snapshot id is the snapshot at the log start offset . since the kafkametadatalog does n't currently delete snapshots , it is possible for the oldest snapshot id to not be the smallest snapshot id in the snapshotids set . <nl> assume that a new segment was created if the relative position is 0 <nl> return the epoch of the snapshot when the log is empty <nl> the epoch is smaller thant the smallest epoch on the log . overide the diverging epoch to the oldest snapshot which should be the snapshot at the log start offset <nl> truncate the log fully if the latest snapshot is greater than the log end offset <nl> do not let the state machine create snapshots older than the latest snapshot <nl> since snapshots are less than the high-watermark absolute offset comparison is okay . <nl> scan the log directory ; deleting partial snapshots and remembering immutable snapshots <nl> when recovering , truncate fully if the latest snapshot is after the log end offset . this can happen to a follower when the follower crashes after downloading a snapshot from the leader but before it could truncate the log fully . <nl> start offset should not change since a new snapshot was not generated <nl> create a few partial snapshots <nl> assert that the log dir does n't contain any partial snapshots <nl> re-read the expected offset in case the snapshot had to be reloaded <nl> this api is used when the listener needs to be notified of a new snapshot . this happens when the context last acked end offset is less that then log start offset .",adds support for nonzero log start offsets . <nl> changes to : <nl> 0. add a new ' reason ' for increasing the log start offset . this is used by when a snapshot is generated . <nl> 0. should return if it was rolled because of an records append . a log is rolled when a new segment is created . this is used by to in some cases delete the created segment based on the log start offset . <nl> changes to : <nl> 0. update both append functions to delete old segments based on the log start,1609637293,"0. add new fields of subscription / assignment and bump up consumer protocol to v2 . <nl> 0. update tests to make sure old versioned protocol can be successfully deserialized , and new versioned protocol can be deserialized by old byte code .",0.9758000373840332
elastic_elasticsearch/71525,"fix min , max , sum aggs data type handling . <nl> this fixes the way the min , max and sum handle the returned data types : <nl> - min and max must return the same data type as input 's . <nl> - sum must return long/bigint for integral types and double otherwise . <nl> the fix concerns both data returned in projections , as well as aggs <nl> filtering . <para-sep> aggregations on date_nanos are returned as string <nl> max , min need to retain field 's data type , so that possible operations on integral types ( like division ) work correctly - > perform a cast in the aggs filtering script , the bucket selector for having . sql function classes not available in ql : filter by name <nl> sum ( integral_type ) requires returning a long value <nl> aggs filtering with integral types <nl> min and max need to return the same type as field 's and sum a long for integral types , but es returns them always as floating points - > convert them in the the select pipeline , if needed","this fixes the way the min , max and sum aggs handle the returned data types : <nl> - min and max must return the same data type as input 's . <nl> - sum must return long/bigint for integral types and double otherwise . <nl> the fix concerns both data returned in projections , as well as aggs script <nl> filtering .",1617957285,the complexity of removing a timeout listener was which <nl> means that in case of many queued up cs update tasks ( such as in the <nl> case of an avalance of dynamic mapping updates ) we 're dealing with <nl> quadratic complexity for timing out n tasks which was observed to be <nl> an issue in practice . <nl> this pr makes the complexity of timing out a task and generally <nl> simplifies the iteration logic of listeners and applies to be a little <nl> more efficient and inline better .,0.9572699666023254
OpenAPITools_openapi-generator/7879,"introduce petstore sample for jaxrs-cxf-client with additional property jackson ( preparational commit ) . <nl> generated using : ./bin/generate-samples.sh ./bin/configs/other/jaxrs-cxf-client-jackson.yaml <cm-sep> generate missing jackson annotations in inner enum . <nl> fix for generators jaxrs-cxf and jaxrs-cxf-client <para-sep> add imports for jackson when model has inner enum <nl> add imports for jackson when model has inner enum <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> add a new pet to the store <nl> deletes a pet <nl> finds pets by status multiple status values can be provided with comma separated strings <nl> finds pets by tags multiple tags can be provided with comma separated strings . use tag1 , tag2 , tag3 for testing . <nl> find pet by id returns a single pet <nl> update an existing pet <nl> updates a pet in the store with form data <nl> uploads an image <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> delete purchase order by id for valid response try integer ids with value & lt ; 0. anything above 0 or nonintegers will generate api errors <nl> returns pet inventories by status returns a map of status codes to quantities <nl> find purchase order by id for valid response try integer ids with value & lt ; & # x3d ; 0 or & gt ; 0. other values will generated exceptions <nl> place an order for a pet <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> create user this can only be done by the logged in user . <nl> creates list of users with given input array <nl> creates list of users with given input array <nl> delete user this can only be done by the logged in user . <nl> get user by user name <nl> logs user into the system <nl> logs out current logged in user session <nl> updated user this can only be done by the logged in user . <nl> a category for a pet * / <nl> get id <nl> get name <nl> convert the given object to string with each line","for inner enum classes , the generators and do not properly annotate the generated methods ( missing ) and ( missing ) , when the additional property is set . <nl> this bug is only present in responsible for inner enum classes . it is not present in , which is responsible for regular enum classes . <nl> this bug is resolved by this pr . <nl> hint for the reviewer : the first commit of this pr introduces a new petstore sample for with additional property set to . the second commit provides the actual fix .",1604525540,"when building a go client with a required parameter of type , a error is countered when compiling the client . <nl> this happens because is currently only defined when a file is optional . this fix does the following : . <nl> * defines when a file is required <nl> * sets to the variable name as defined in the function call . <nl> this approach can only handle a single file , but this is also a limitation of the current go generator can as takes a single pair of and parameters . a future enhancement could support",0.9836827516555786
apache_shardingsphere/9603,[ sql definition collation ] collate the sql definition of set role <para-sep> set role statement . <nl> oracle set role statement .,changes proposed in this pull request : <nl> - collated the sql definition of,1615051291,changes proposed in this pull request : <nl> - perfect start symbol <nl> - fix setnames <nl> - add support of <nl> - add support of <nl> - add testcase of <nl> - add testcase of,0.9141030311584473
eclipse-openj9_openj9/10420,"correctly set invocationcount in valhalla tests . <nl> in order to ensure the jit is adequately exercised , some tests have to <nl> be run at least twice so that more compilations of key methods are <nl> triggered . <nl> this commit removes the invocationcount <nl> parameter from the class annotation and adds it to individual test <nl> methods that can be safely invoked more than once . certain tests can not <nl> be safely run more than once because they are stateful . in this commit , <nl> only tests that are obviously safe are set to be invoked twice . other <nl> tests will require closer investigation and possibly some refactoring <nl> and are not addressed in this commit to avoid delaying the progression <nl> of other work . <cm-sep> split valhalla tests so they can be run multiple times . <nl> this commit splits some valhalla tests into testcreate and test <nl> methods . the testcreate * methods materialize value types for use by the <nl> test * methods . materializing value types requires dynamically loading a <nl> class , which can only be done once per class loader , which prevents the <nl> tests from being executed more than once . separating the creation of <nl> value types from the actual test logic allows the latter to be invoked <nl> multiple times , ensuring the jit is adequately exercised . <cm-sep> refactor some valhalla tests so they can better exercise the jit . <nl> some valhalla tests combine some setup code and the actual test code in <nl> single test methods . when the setup code prevents the test from being <nl> run more than once , the jit does not have a chance to compile as many <nl> methods and is not well exercised . this commit refactors some tests so <nl> that the setup and test code can be separated into two methods . unlike <nl> other similar tests that have already been split , some extra refactoring <nl> was needed to allow the setup ( testcreate * ) methods to share data with <nl> the actual tests methods ( test * ) . <para-sep> assortedrefwithobjectalignment * / <nl> assortedrefwithsinglealignment * /","previously , the valhalla tests attempted to run tests twice by passing to the annotation on the test class . however , testng only handles that parameter when it 's passed to the annotation on test methods . this change removes the from the class annotation and adds it to test methods where safe . some tests can not be executed more than once because they are stateful . a few tests were also refactored to allow the core test routine to be executed twice while only executing the setup ( the stateful part of the original test ) once",1597843214,com.ibm.oti.reflect . * is mostly unused except for the <nl> annotation parsers . delete the unused method/field/ <nl> constructor implementations and leave the annotation <nl> forwarders . <nl> further cleanup here may be possible .,0.8438939452171326
hazelcast_hazelcast/18233,wait for cache size to be 0 . <nl> the waiting will prevent the events originated from previous <nl> statements to be processed in the client side while recreating <nl> happens . <para-sep> make sure that all events are processed before calling querycache # recreate,the waiting will prevent the events originated from previous <nl> statements to be processed in the client side while recreating <nl> happens .,1613643035,"this simple fix adds backward compatibility to data eviction algorithm for cache sizes , smaller than number of partitions . this can be extremely useful especially after introducing dynamic map configuration feature .",0.8466013669967651
hazelcast_hazelcast/18474,"remove regular-test execution , produces duplicate test runs <cm-sep> re-enable cdc tests , they pass perfectly fine locally , so must be an environment issue on jenkins","removes the execution , produces duplicates . <nl> re-enables cdc tests , because they pass fine locally , if they fail , then it 's a jenkins issue .",1617702227,"- fixes hazelcasttestsupport.assertjoinable , expects milliseconds timeout , not nanoseconds . <nl> - threadleaktestutils initializes logger factory . log4j2 creates its own shutdown hook threads , by initializing logger initially we force them to be created beforehand . this is required to be able to detect thread leaks . <nl> - add explicit thread names to test connection managers .",0.8974280953407288
apache_druid/10288,"store hash partition function in datasegment and allow segment pruning only when hash partition function is provided <cm-sep> query context <para-sep> a hash function to use for both hash partitioning at ingestion time and pruning segments at query time . this is because the default hash function used to create segments at ingestion time can change over time , but we do n't guarantee the changed hash function is backwards-compatible . the query will process all segments if this function is null . <nl> partitionfunction can be null when you read a shardspec of a segment created in an old version of druid . the current version of druid will always specify a partitionfunction on newly created segments . <nl> partitionfunction should be used instead of hashpartitioner at query time . we should process all segments if partitionfunction is null because we do n't know what hash function was used to create segments at ingestion time .","0 ) we need a flag to disable segment pruning just in case where some unknown bugs exist in pruning hash-partitioned segments . <nl> 0 ) the hash function used to create segments at ingestion time can change over time . i 'm not sure whether or not we have ever changed it . if we have ever done , the segment pruning can lead to incorrect query results for those segments partitioned with a different hash function . <nl> to address these issues , this pr adds 0 flags , a new query context , , and a new",1597464373,"this pr adds a new method to the interface , which should be noted in the release notes .",0.9857931137084961
OpenAPITools_openapi-generator/7274,"adds generator specific unaliasschema method <cm-sep> adds unaliasschema and hasvalidation methods in python-experimental generator <cm-sep> removes primitive models with no validations , docs , tests , and models <cm-sep> uses unaliasschema in getschematype and adds todos <cm-sep> deletes handlemethodresponse and fromresponse <cm-sep> simplifies fromrequestbody <cm-sep> removes unneeded handlemethodresponse <cm-sep> updates javadoc <cm-sep> updates frommodel <para-sep> skip the warning as the spec can have no model defined logger.warn ( ' allschemas can not be null/empty in unaliasschema . returned 'schema ' ' ) ; <nl> top-level enum class <nl> treat it as a typical map <nl> non object non array non map schemas that have validations are returned so we can generate those schemas as models we do this to : - preserve the validations in that model class in python - use those validations when we use this schema in composed oneof schemas <nl> * we have a custom version of this method to : - remove any primitive models that do not contain validations these models are unaliased as inline definitions wherever the spec has them as refs this means that the generated client does not use these models because they are not used we do not write them - fix the model imports , go from model name to the full import string with tomodelimport + globalimportfixer <nl> we have a custom version of this method to always set allowablevalues.enumvars on all enum variables together with unaliasschema this sets primitive types with validations as models this method is used by fromresponse <nl> * we have a custom version of this method to produce links to models when they are primitive type ( not map , not array , not object ) and include validations or are enums <nl> * adds the body model schema to the body parameter we have a custom version of this method so we can flip forcesimpleref to true based upon the results of unaliasschema with this customization , we ensure that when schemas are passed to getschematype - if they have ref in them they are a model - if they do not have ref in them they are not a model <nl> return the sanitized variable name for enum <nl> sets regex values <nl> use cases for default values / enums of length one 0. no default exists schema does not contain default cm.defaultvalue unset , cm.hasrequired = true 0. server has",this refactor : <nl> - simplifies that feature 's implementation <nl> - makes it easier to maintain python-experimental .,1598157256,major refactoring of the elm generator . see this new guide for more background . <nl> and would it be possible to merge this without squashing ?,0.9638575315475464
vespa-engine_vespa/16577,"add traffic fraction maintainer <cm-sep> pass and store traffic fractions <cm-sep> consider global read taffic share in vcpu target <cm-sep> better names <para-sep> patchable data under application <nl> this computes , for every application deployment - the current fraction of the application 's global traffic it receives - the max fraction it can possibly receive , assuming traffic is evenly distributed over regions and max one region is down at any time . ( we can let deployment.xml override these assumptions later ) . these two numbers are sent to a config server of each region where it is ultimately consumed by autoscaling . it depends on the traffic metrics collected by deploymentmetricsmaintainer . <nl> tests the traffic fraction updater . this also tests its dependency on deploymentmetricsmaintainer . <nl> single zone <nl> two zones <nl> - one cold <nl> - both hot <nl> three zones <nl> - one cold <nl> - all hot <nl> do not use * / <nl> returns the application with the given id , or throws illegalargumentexception if it does not exist * / <nl> an application 's status <nl> do not use * / <nl> returns the current fraction of the global traffic to this application that is received by the deployment in this zone . <nl> returns an estimate of the max fraction of the global traffic to this application that may possibly be received by the deployment in this zone . <nl> ideal cpu load must take the application traffic fraction into account * / <nl> todo : move to applications <nl> a class which can take a partial json node/v2 application json structure and apply it to an application object . this is a one-time use object . <nl> applies the json to the application and returns it . * / <nl> returns the application in its current state ( patch applied or not ) * / <nl> ( no read share stored )",the point of this is the change in the third last commit .,1613667554,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9873575568199158
OpenAPITools_openapi-generator/7585,"updated dart2 template . <cm-sep> generated petstore client code for dart2 . <para-sep> not set , use to be passed to template <nl> not set , use to be passed to template <nl> not set , use to be passed to template <nl> / { { { summary } } } <nl> / <nl> / { { { notes } } } / / note : this method returns the http . <nl> / / note : this method returns the http . <nl> / performs an http ' { { { httpmethod } } } { { { path } } } ' operation and returns the . <nl> / <nl> / <nl> / parameters : / <nl> / * [ { { { datatype } } } ] { { { paramname } } } { { # required } } ( required ) { { /required } } { { # optional } } ( optional ) { { /optional } } : <nl> / { { { description } } } <nl> / <nl> verify required params are set . <nl> / { { { summary } } } <nl> / { { { notes } } } <nl> / <nl> / <nl> / parameters : / <nl> / * [ { { { datatype } } } ] { { { paramname } } } { { # required } } ( required ) { { /required } } { { # optional } } ( optional ) { { /optional } } : <nl> / { { { description } } } <nl> / <nl> / returns the current http instance to use in this class . / / the return value is guaranteed to never be null . <nl> / requests to use a new http in this class . / / if the is null , an is thrown . <nl> remove all spaces . necessary for reg expressions as well . <nl> we don ’ t use a map for queryparams . if collectionformat is 'multi ' , a key might appear multiple times . <nl> ported from the java version . <nl> get the collection format , default : csv <nl> / format the given parameter object into a . <nl> / returns the decoded body as if the given headers indicate an 'application/json ' / content type . otherwise","this upgrades the dart2 template to advertised best-practices by the dart team and most importantly , use to reference variables instead of since the latter is for escaping values . it happened to me that occasionally the generated code would include and escape characters for some reason or another . <nl> few additions were added too : . <nl> * allow users to decide whether an invalid enum throws an error or not -- handy since in the old case , when an api changes , outdated apps would crash . <nl> * added to most calls that returns a",1601736070,"instead of asserting that any key access returns a valid property , force <nl> the consumer to check that the value is defined . <nl> when declaring an object with additional properties . <nl> the generated interface is unsafe , because it asserts that _any_ property access on the response returns a value . in reality , a property access can return undefined , which will cause a runtime failure . <nl> if the compiler is running with strict null checking , we can avoid the problem by declaring that property access _can_ return undefined , forcing the consumer to",0.9304224252700806
apache_druid/10460,"fix array types from escaping into wider query engine <cm-sep> oops <cm-sep> adjust <para-sep> overridden by things that are null literals . <nl> infer the output type of a list of possible 'conditional ' expression outputs ( where any of these could be the output expression if the corresponding case matching expression evaluates to true ) <nl> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if both arguments are a string , type becomes a string <nl> otherwise a decimal or integer number <nl> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if either argument is a string , type becomes a string <nl> can not auto conversion unknown types <nl> arrays can not be auto converted <nl> if either argument is a string , type becomes a string <nl> any number is long <nl> default best effort numeric type conversion . <nl> all numbers win over longs <nl> floats vs doubles would be handled here , but we currently only support doubles ... <nl> no instantiation <nl> add else <nl> add else <nl> if analysis predicts output , or inferred output type is array , output will be multi-valued <nl> single input mappable may not produce array output explicitly , only through implicit mapping <nl> if implicit mapping is in play , output will be multi-valued but may still use single_input_mappable optimization <nl> array types must not currently escape from the expression system",it also fixes an bug where expressions with explicitly array typed output could incorrectly set resulting in an incorrect dimension selector being used,1601598253,"this works provided a few conditions are met : <nl> * the expression _does not_ operate on the multi-value input as an array <nl> * the expression _does not_ produce an array <nl> * the single multi-value column is used _at most once_ in the expression . <nl> to achieve this , functions and apply functions now also report if they have array inputs or outputs which is collected on , which is already used to analyze the expression in in order to determine the correct type of selector to create . <nl> this change also allows multi-value expressions that",0.9593291282653809
elastic_elasticsearch/71265,fix search states of ccs requests in mixed cluster <para-sep> we execute tests 0 times . - the local cluster is unchanged and it consists of an old version node and a new version node . - nodes in the remote cluster are upgraded one by one in three steps . - only and of the remote cluster can accept remote connections . this can creates a test scenario where a query request and fetch request are sent via proxy nodes that have different version . <nl> this test ensure that we keep the search states of a ccs request correctly when the local and remote clusters have different but compatible versions . see searchservice # createandputreadercontext <nl> returns the minimum version of the channel that the request has been passed . <nl> new version,"previously , the search states are stored in readercontext on data nodes . since version , we send them to the coordinating node in a querysearchresult of a ` shardsearchrequest and the coordinating node then sends them back in shardfetchsearchrequest . we must keep the search states in data nodes unless they are sent back in the fetch phase . we used the channel version to determine this guarantee . however , it 's not correct in ccs requests in mixed clusters . <nl> 0. the coordinating node of the local cluster on the old version sends a shardsearchrequest to",1617404030,"today we empty the searchable snapshots cache when cleanly closing a <nl> shard , but leak cache files in some cases involving an unclean shutdown . <nl> such leaks are not permanent , they are cleaned up on shard relocation or <nl> deletion , but they still might last for arbitrarily long until that <nl> happens . this commit introduces a cleanup process that runs during node <nl> startup to catch such leaks sooner . <nl> also , today we permit searchable snapshots to be held on custom data <nl> paths , and store the corresponding cache files within the",0.9657922983169556
grpc_grpc-java/7677,migrate to interceptor based config selector <cm-sep> move configselectingclientcall to inner class <para-sep> a client call for a given channel that applies a given config selector when it starts . <nl> * / <nl> verify the raw service config contains a single method config for method with the specified timeout . <nl> calloptions actually received from the channel when the call is created .,it could be easier to review the 0 commits separately . the 2nd just moves configselectingclientcall to inner class of managedchannelimpl .,1606778942,"this pr performs some pre-work for integrating client side load reporting with xds load balancer . ( this pr ) <nl> 0. integrate load reporting with xds load balancer , with tests verifying load reporting apis are invoked by xds load balancer properly . ( next pr ) . <nl> main changes in this pr : <nl> - put self-defined class into a separate file and rename it to . it is used both in load reporting and xds load balancer . <nl> - deleted delegation calls of , , and in . eds response handler in xds load balancer",0.9702560305595398
apache_incubator-pinot/5491,add optional rng seed to pinot-tools for deterministic data generator patterns <cm-sep> table name support in generator.sh,"any added options come with sensible defaults that mimic legacy behavior . additionally , these changes only affect future walkthroughs and tutorials yet to be written .",1591226098,"* implement basic access control permissions ( read , read/write ) - not exposed to the ui yet . <nl> * show copy button to allow copy-on-write workflow for read-only sessions",0.9241427183151245
apache_incubator-pinot/5700,"first commit to enable by passing segment store in llc . <para-sep> always return a uri string even if the segment upload fails and returns a null uri . if the segment upload fails , put peer : ///segment_name in the segment location to notify the controller it is a peer download scheme . <nl> todo instead of using a peer segment download scheme to control how the servers do split commit , we should use other configs such as server or controller configs or controller responses to the servers . <nl> return null iff the segment upload fails .","if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1594681571,separated out the ssl context class so that it can be re-used for realtime segment upload as well . <nl> added configurations to set preferred controller port and protocol for the server to communicate <nl> with the controller .,0.9656662940979004
OpenAPITools_openapi-generator/8338,create enum documentation in model <cm-sep> add newline to fix layout when a markdown table follows a markdown list <cm-sep> avoid escaping of attributes to make sure documentation is displayed as in the spec <para-sep> chomp tailing newline because it breaks the tables and keep all other sign to show documentation properly <nl> add one enum property to the parent <nl> add two enums to the subtype model ; one of which is identical to the one in parent class,i recognized that enums are not documented well in confluence wiki markup . therefore i created this pr which renders the enum values as a table in the model section . additionaly i removed the escaping of values to make sure the text is displayed correctly in wiki ( i. e. ' instead of \ ' or with multiline comments ) . <nl> input : . <nl> output : .,1609866495,"has two options . <nl> - timemachine : time_machine . <nl> if is , . <nl> input . <nl> output . <nl> -- .",0.9832431674003601
elastic_elasticsearch/70893,"user tree toxcontent <cm-sep> user tree rest of nodes <cm-sep> use arrays in for visitor <cm-sep> wip decorations <cm-sep> start/end , more reflects <cm-sep> refactor , annotations <cm-sep> pull out common names , relocate helpers <cm-sep> integrate in debug compiler <cm-sep> printer package - > toxcontent package <cm-sep> wrapper and driver <cm-sep> rename wrapper <para-sep> runs the two-pass compiler to generate a painless script with option visitors for each major phase . <nl> represents a function reference for creating a new array ( eg double [ ] : :new ) <nl> serialize user tree decorations from org.elasticsearch.painless.symbol.decorations <nl> todo ( stu ) : expand this <nl> lookup <nl> ignoring methodtype as that 's handled under methodhandle <nl> symbol <nl> annotations <nl> asm <nl> java.lang.invoke <nl> java.lang.reflect <nl> helpers <nl> serialize the user tree <nl> todo ( stu ) : why would operation be null ? <nl> this does not serialize the flags <nl> compiles to bytecode , and returns debugging output * /","adds ability to serialize the user tree to an <nl> xcontent builder , handling all user tree decorations . <nl> to avoid creating a tight dependency , the <nl> implementation is kept outside the relevant nodes . <nl> uses a wrapper around the to change <nl> checked into runtime exceptions to conform <nl> to usertreevisitor api contract . <nl> adds new debugger method , which <nl> allows the caller to attach visitors at the three main phases <nl> of painless compilation .",1616708442,"run time field that emits geo points from lat/lon values . for example , given a mapping like : . <nl> a geo_point runtime field can be declared as : . <nl> where the emit function takes two arguments , the first argument is the latitude and the second argument the longitude .",0.9743894338607788
OpenAPITools_openapi-generator/7491,add option to set recursion limit <para-sep> check to see if setrecursionlimit is set and whether it 's an integer,- add an option to in <nl> - tested locally in api and model tests to confirm the recursion limit is set correctly to the new value provided in the option .,1600858946,"as defined in guide of contributing , php templates should meet coding style . <nl> i 've added php codesniffer package to check source code on violations against user defined standard . user can change coding standard with config option . is default ( checks against and ) . <nl> i think it 's perfect time to add linters and code formatters while generator is small like slim now . it will be easier to update templates and check them automatically every next pr .",0.9182065725326538
jenkinsci_jenkins/4683,"add build step environment filters . <para-sep> build the environment filter rules that will be applied on the environment variables <nl> represent the build step , either from legacy build process or from pipeline one <nl> specify the build step that want to run the command to enable the environment filters","this pr adds new extension points to filter or change environment variables passed to build steps that support this feature . <nl> they can be configured globally ( for which this pr only prepares the infrastructure , no implementations are provided ) and for specific build steps . one such filter is provided to filter environment variables . batch and shell build steps support this feature . <nl> there are several use cases for this system , for example exercising fine-grained control over environment variables to get more easily reproducible builds , or filtering out extremely long or otherwise broken",1587578759,"since jenkins version we can enable remoting work directories . <nl> * on : all jnlplauncher implementations use the default constructor , we are safe . <nl> config : . <nl> main page : . <nl> * entry 0 : enable remoting work directories by default for newly created agents with jnlp ( java web start launcher ) . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9874728918075562
trinodb_trino/6895,"fix union of two low-unbounded domains . <nl> before the change , union of and would incorrectly <nl> return as the result . <para-sep> both are low-unbounded <nl> two low-unbounded , first shorter <nl> two low-unbounded , second shorter <nl> two high-unbounded , first shorter <nl> two high-unbounded , second shorter <nl> two low-unbounded , first shorter <nl> two low-unbounded , second shorter <nl> two high-unbounded , first shorter <nl> two high-unbounded , second shorter","before the change , union of and would incorrectly <nl> return as the result .",1613383817,"queries that involve an outer join or are pure non-equi joins get planned <nl> as regular lookup joins . if the right side does n't contain any columns ( i.e. , <nl> due to column pruning ) , calls to pagesindex.compact ( ) will fail with <nl> arrayindexoutofbounds -- this can happen if there 's not enough local memory <nl> available and the operator attempts to optimize the organization of the <nl> pagesindex .",0.7858641147613525
grpc_grpc-java/7748,"channelcredentials.withoutbearertokens ( ) and loadbalancer.helper.createresolvingoobchannelbuilder ( ) <para-sep> returns the channelcredentials stripped of its callcredentials . in the future , this may strip only some of the callcredentials , preserving call credentials that are safe from replay attacks ( e.g. , if the token is bound to the channel 's certificate ) . <nl> creates an out-of-band channel builder for loadbalancer 's own rpc needs , e.g. , talking to an external load-balancer service , that is specified by a target string and credentials . <nl> returns the channelcredentials used to construct the channel , without bearer tokens . <nl> returns the authority string of the channel , which is derived from the dns-style target name . <nl> * / <nl> * / <nl> * / <nl> * / <nl> * / <nl> * /","api change ( see go/grpc-rls-callcreds-to-server ) : . <nl> - add <nl> - add , and for . <nl> this pr does not include the implementation of .",1608663475,"is the interface that extends . is the one that loads the providers through service loader , and allows users to access providers through their names . <nl> pick_first and round_robin balancer factories , which are experimental public api are now deprecated . their providers are internal , as they are accessible by policy name . <nl> is modified to access implementations purely by their names , thus hard-coded class names are no longer needed , and it can support arbitrary policy selected by service config .",0.9699618816375732
neo4j_neo4j/11192,updated java driver dependency . <nl> from version to version and improved the periodic commit query <nl> termination test .,from version to version and improved the periodic commit query termination test .,1520436717,by using the same mechanisms to figure that out as neo4j <nl> does otherwise .,0.9241296648979187
vespa-engine_vespa/16576,simplify by extending slimejsonresponse <cm-sep> expose flagsource in noderepository <cm-sep> fix todo <cm-sep> expose nodearchiveurl in nodes response <para-sep> returns the time keeper of this system * / <nl> returns the zone of this system * / <nl> todo ( freva ) : store this in application or node,"this exposes a remote url ( for now a path in an s3 bucket ) where the node should upload their logs ( for now , in future maybe core dumps , heaps , etc . ) to . <nl> currently this just backed by a feature flag , but in future the config server will create at least 0 bucket ( maybe more if there are many applications in zone ) , and keep track of which applications ( and thereby nodes ) should sync to where .",1613662291,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9708797931671143
elastic_elasticsearch/71013,remove frozen cache setting leniency . <nl> we previously allowed but deprecated the ability for the shared cache to <nl> be positively sized on nodes without the frozen role . this is because we <nl> only allocate shared_cache searchable snapshots to nodes with the frozen <nl> role . this commit completes our intention to deprecate/remove this <nl> ability . <para-sep> details * + <nl> impact * + <nl> use an unbound cache so we can recover the searchable snapshot completely all the times <nl> have a shared cache of reasonable size available on each node because tests randomize over frozen and cold allocation,we previously allowed but deprecated the ability for the shared cache to be positively sized on nodes without the frozen role . this is because we only allocate shared_cache searchable snapshots to nodes with the frozen role . this commit completes our intention to deprecate/remove this ability .,1617050000,return a 0 http status code when attempting to delete a non existing data stream . <nl> however only return a 0 when targeting a data stream without any wildcards .,0.9494603276252747
OpenAPITools_openapi-generator/7747,"changes lingering ismapcontainer to ismap <para-sep> this can never happen , as we make sure above that the value is present <nl> this can never happen , as we make sure above that the value is present",this pr <nl> - changes ismapcontainer to ismap .,1603066145,"add full oauth2 support to jersey2-experimental codegen . <nl> the scribejava lib is used ( instead of oltu for other generators which is deprecated ) . <nl> features : <nl> - client credentials , authorization code , password flows <nl> - automatic refresh using the refresh token if possible <nl> - automatic renewal of access token <nl> - helper methods to configure the client .",0.9381076693534851
apache_druid/10630,scan query : more accurate error message when segment per time chunk limit is exceeded .,"resourcelimitexceededexception is a type that makes more sense , and the message is edited to refer to the properties that would need to be updated in order to get different behavior .",1607057491,fix latest / earliest buffer aggregator does not work on string column . <nl> the latest / earliest buffer aggregator was not working on string column because of incorrectly set limit on the buffer when storing the string . the limit did not take into account the offset position of the start of position to write the string,0.9156808853149414
jenkinsci_jenkins/4766,"add perform ( ) taking envvars to simplebuildstep . <nl> provides a default implementation for both overloads : <nl> - if the old method is called , it forwards to the new method , passing <nl> the environment specified for the run <nl> - this means that when a new implementer ( who has overridden the new <nl> overload ) gets called by an old client , they get the run <nl> environment only ( fine for freestyle , only the initial environment <nl> in a pipeline ) <nl> - if the new method is called , it forwards to the old method , ignoring <nl> the passed environment <nl> - in this case , the old method must be overridden <nl> - this handles the case of an old implementer getting called by a <nl> new client <nl> - no change in functionality ; implementer still gets the same <nl> environment to work with ( via the run ) . <nl> buildstepcompatibilitylayer has _not_ been changed yet to call the new <nl> overload , mainly because it would just get the environment to pass the <nl> same way the default implementation in simplebuildstep does ( i.e . <nl> passing the result of calling getenvironment ( ) on the run ) . <nl> implementers of simplebuildstep ( like artifactarchiver and <nl> fingerprinter ) similarly have _not_ been changed . this is mainly <nl> because they get run 's environment to apply substitution , and that <nl> should not be done using an environment passed in from a pipeline <nl> step . so if they switch to the new signature , their code should also <nl> be adjusted to only expand environment variables when the run is an <nl> abstractbuild . <nl> with this change , a pr can be made to workflow-basic-steps-plugin , <nl> to extend corestep to pass in the environment variables from the <nl> step context . the combination of both prs should then fix <nl> and allow the creation of builders that are <nl> automatically available as pipeline steps with proper honoring of <nl> things like withenv and global tools . <cm-sep> add a test for the simplebuildstep changes . <nl> this currently just checks for a slave-level environment variable ; <nl> not sure if that is enough .","this extends with an overload of that takes an . <nl> uses default implementation of both ( as is done in other places ) to deal with both old-implementer-called-by-new-client and new-implemented-called-by-old-client . <nl> this change on its own does very little , by design . <nl> the main fix for the ticket would come from a corresponding change in , in the , to make that pass the from the step context . <nl> in particular , i did not make a change to or any other users of . <nl> this is mainly because they would then need to",1591050638,proposed changelog entries : . <nl> * entry 0 : ] - prevent npe when a non-existent default view is specified in the global configuration <nl> * .. .,0.9773868322372437
elastic_elasticsearch/71356,adds to eql and sql requests allowing users to <nl> define search time runtime fields which will be used in queries <para-sep> top level objects are fields <nl> add the runtime fields <nl> define the runtime field <nl> perform a superficial check for runtime_mappings structure . the full check can not happen until the actual search request <nl> top level objects are fields <nl> an optional list of runtime fields that can be added to the request similar to the way it is done in query dsl search requests <nl> set runtime mappings,the request element will allow eql and sql users to define search time runtime fields which can later be used in queries .,1617724438,this adds a way to specify the on a search request <nl> which are always ' runtime ' fields . it looks like : . <nl> note : <nl> if we have to send a search request with runtime mappings to a node that <nl> does n't support runtime mappings at all then we 'll fail the search <nl> request entirely . the alternative would be to not send those runtime <nl> mappings and let the node fail the search request with an ' unknown field ' <nl> error . i believe this is would be hard to surprising because,0.9851151704788208
apache_incubator-pinot/5335,add transformfunction to fieldspec equality check and hashcode <cm-sep> add transformfunction to tojsonobject,"transformfunction was not added to equals , hashcode , tojsonobject . probably unintentionally left out ? <nl> now that we 've started using transformfunctions actively , we should have this in the fieldspec equality check .",1588706058,* do n't purge segment unless there are records to be purged or modified,0.9005793333053589
elastic_elasticsearch/71370,"system index descriptors support mixed versions . <nl> system index descriptors are used to describe a system index , which are <nl> expected to change as new versions are developed . as part of this , the <nl> descriptors had a minimum supported version field so that the contents <nl> within that descriptor would not be applied if there were nodes older <nl> than that version . however , this falls short of being able to <nl> accurately describe what a system index should look like in a given <nl> cluster where there are mixed node versions . <nl> this change moves us towards being able to accurately describe and <nl> know what the system index should look like . a system index is now <nl> able to accept a list of the prior system index descriptor objects <nl> so that clusters with mixed versions can select the appropriate <nl> descriptor and ensure the index is created properly . as the node <nl> versions change during a rolling upgrade , the cluster will then be <nl> able to adapt the system index to the most recent version once all <nl> master and data nodes have been upgraded . <para-sep> the minimum cluster node version required for this descriptor / mapping version from the descriptor / <nl> a list of prior system index descriptors that can be used when one or more data/master nodes is on a version lower than the minimum supported version for this descriptor","system index descriptors are used to describe a system index , which are <nl> expected to change as new versions are developed . as part of this , the <nl> descriptors had a minimum supported version field so that the contents <nl> within that descriptor would not be applied if there were nodes older <nl> than that version . however , this falls short of being able to <nl> accurately describe what a system index should look like in a given <nl> cluster where there are mixed node versions . <nl> this change moves us towards being able to accurately",1617740027,fixed storage autoscaling to also calculate a capacity in the case where <nl> the policy governs no nodes currently ( 0-0 case ) .,0.9756152629852295
apache_kafka/9884,remove unused flag 'hasidempotentrecords ' <para-sep> find a flag from all records of a produce request .,sha removed the usage of so we do n't need to find out it from produce request . this pr includes following changes . <nl> 0. remove <nl> 0. avoid creating unused map.entry <nl> 0. move testing-only code ( ) from to .,1610596700,- introduces taskmetrics class <nl> - introduces dropped-records <nl> - replaces skipped-records with dropped-records with latest built-in <nl> metrics version <nl> - does not add standby-process-ratio and active-process-ratio <nl> - does not refactor parent sensors for processor node metrics .,0.9362028241157532
vespa-engine_vespa/16948,"require 0 active config servers/controllers when allowing removal <para-sep> avoid eventual expiry of configserver-like nodes <nl> scenario : all 0 config servers want to retire . say retiredexpirer runs on cfg1 and gives cfg2 permission to be removed ( permanently_down in zk ) . the consequent redeployment moves cfg2 to inactive , removing cfg2 from the application , and permanently_down for cfg2 is cleaned up . if the retiredexpirer on cfg3 now runs before its infrastructureprovisioner , then a. the duper model still contains cfg2 b. the service model still monitors cfg2 for health and it is up c. the orchestrator has no host status ( like permanently_down ) for cfg2 , which is equivalent to no_remarks therefore , from the point of view of the orchestrator invoked below , any cfg will be allowed to be removed , say cfg1 . in the subsequent redeployment , both cfg2 and cfg1 are now inactive . a proper solution would be to ensure the duper model is changed atomically with node states across all config servers . as this would require some work , we will instead verify here that there are 0 active config servers before allowing the removal of any config server . <nl> set wanttoretire on all 0 config servers <nl> redeploy to retire all 0 config servers <nl> only 0 config server is allowed to retire at any given point in time <nl> allow retirednodehostname to be removed <nl> retiredexpirer should remove cfg1 from application <nl> no changes while 0 cfg is inactive <nl> the node will eventually expire from inactive , and be removed by dynamicprovisioningmaintainer ( depending on its host ) , and these events should not affect the 0 active config servers . <nl> provision and ready new config server <nl> no changes while replacement config server is ready <nl> activate replacement config server <nl> another config server should now have retired",makes the following changes to the completion of retirement of a config server or controller node : <nl> - require all 0 nodes to be active <nl> - disallow automatic expiry after 0 days,1615803153,"emit metrics on job starts and ends , with status as name and job id as dim .",0.9624110460281372
apache_beam/12867,"pub/sub lite getsplitbacklog implementation . <nl> add an implementation of getsplitbacklog to the pub/sub lite io . this <nl> implementation depends on the pub/sub lite topicstats api <para-sep> we use the cache because it allows us to coalesce request , periodically refresh the value and expire the value after a maximum staleness , but there is only ever one key . <nl> the class used to read backlog for the subscription described by subscriptionpath ( ) . * / <nl> used in unit tests used for implementing build ( ) ; <nl> the topicbacklogreader is intended for clients who would like to use the topicstats api to aggregate the backlog , or the distance between the current cursor and head across multiple partitions within a subscription . <nl> create a topicbacklogreader from settings . * / <nl> compute and aggregate message statistics for message between the provided start offset and head for each partition . <nl> the topic path for this backlog reader . either topicpath or subscriptionpath must be set . if both are set , subscriptionpath will be ignored . <nl> optional parameters <nl> required parameters .",add an implementation of getsplitbacklog to the pub/sub lite unbounded reader . this <nl> implementation depends on the pub/sub lite topicstats api,1600376030,follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9814441800117493
elastic_elasticsearch/72406,"allow disabling ignore_malformed on data stream 's timestamp field . <nl> if has been set to then <nl> here is no way to overwrite that to for a data stream 's <nl> timestamp field . <nl> before this commit , validation would fail that disallow the usage <nl> of attribute on a data stream 's timestamp field . <nl> this commit allows the usage of attribute , <nl> so that can be disabled for a <nl> data stream 's timestamp field . the attribute <nl> can only be set to false . <nl> this allows the following index template : . <para-sep> ignoring malformed values is disallowed ( see previous check ) , however if has been set to true then there is no way to disable ignore_malformed for the timestamp field mapper , other then not using 'index.mapping.ignore_malformed ' at all . so by ignoring the ignore_malformed here , we allow index.mapping.ignore_malformed index setting to be set to true and then turned off for the timestamp field mapper . ( ignore_malformed will here always be false , otherwise previous check would have failed )","if has been set to then <nl> here is no way to overwrite that to for a data stream 's <nl> timestamp field . <nl> before this commit , validation would fail that disallow the usage <nl> of attribute on a data stream 's timestamp field . <nl> this commit allows the usage of attribute , <nl> so that can be disabled for a <nl> data stream 's timestamp field . the attribute <nl> can only be set to false . <nl> this allows the following index template : .",1619626450,"if node does n't support maxprimaryshardsize then serialize maxprimaryshardsize as maxsize . <nl> this should fix a problematic situation if an older node does n't support maxprimaryshardsize <nl> and this is the only condition specified then the older node ends up with a instance without <nl> any conditions . this could lead to upgrade failures , new nodes not able to start because <nl> local cluster state ca n't be read .",0.9146105051040649
ballerina-platform_ballerina-lang/25952,fix the do statement <cm-sep> fix query expressions <cm-sep> fix fork statements <cm-sep> fix panic statements <cm-sep> fix continue statements <cm-sep> fix break statements <cm-sep> fix enum declarations <cm-sep> fix compound assignment statements <cm-sep> fix let expressions <cm-sep> fix the call statement <cm-sep> fix the if else statements,* do statement . <nl> * query expressions . <nl> * fork statements . <nl> * panic statements . <nl> * continue statements . <nl> * break statements . <nl> * enum declarations . <nl> * compound assignment statements . <nl> * let expression . <nl> * call statements . <nl> * if-else statements .,1600657926,"improvements : <nl> * add a new array util function for retrieving a handle from a ballerina object array which is representing a java object array . <nl> * create empty dependency ballerina objects to represent failed class generations . <nl> * remove the implementation generation of dependent ballerina objects . this would prevent the chain generation of dependent ballerina objects . if a user requires the implementation of one of these classes , it should be explicitly generated using the command . <nl> * automatically update the existing constants file when re-running the command . <nl> * delete the",0.9582709074020386
apache_druid/10578,"add context dimension to defaultquerymetrics <para-sep> note : query ( ) , datasource ( ) , querytype ( ) , interval ( ) , hasfilters ( ) , duration ( ) , queryid ( ) , sqlqueryid ( ) , and context ( ) methods or any ' pre-query-execution-time ' methods should either have a empty body or throw exception .","is now a default dimension emitted for all query metrics . is a formatted string containing the query context that is tied to the query that the emitted metric refers to . this will alter some of the metrics that are emitted by druid ( adding a dimension that was not previously there ) . clients should plan to handle this new dimension in their metrics pipeline . since the dimension is a formatted string , it is common for clients to parse the dimension and either flatten it or extract the bits they want and discard the full formatted",1605231273,made a change so that setandverifycontextqueryrunner will set query fail time after the default query timeout is set in the query context .,0.8893576264381409
ballerina-platform_ballerina-lang/24060,fix scheduler.getstrand ( ) call order to avoid unwanted contention . <nl> this was changed so that the call can be completely avoided . <para-sep> adding initializing instructions for all compile time known constants,this was changed so that the call can be completely avoided .,1592042374,some fixes was done to dynamically get the sub type and use it instead of the referred type . <nl> this is accessed when a method in the object is invoked and used in the generated observability data .,0.9381693005561829
OpenAPITools_openapi-generator/7497,"fixing java : s3599 - avoid double brace initializer . <nl> because double brace initialization ( dbi ) creates an anonymous class with a <nl> reference to the instance of the owning object , its use can lead to memory <nl> leaks if the anonymous inner class is returned and held by other objects . even <nl> when there 's no leak , dbi is so obscure that it 's bound to confuse most <nl> maintainers . <cm-sep> fix incorrect list.contains typed check <cm-sep> avoid potential npe in defaultcodegen <cm-sep> remove unused boolean and log <cm-sep> fix potential npe in haskell http client <cm-sep> fix potential bugs in javacxfextservercodegen , found by static analysis <para-sep> hack : avoid infinite loop on potential self-references in event our checks fail .",this fixes a handful of potential bugs as documented in sonar .,1600915274,~~this pr makes the stub server returns status code defined at response object instead of 0 ( not implemented ) .~~ . <nl> this pr adds an option to make the stub server return success code .,0.9395785927772522
apache_pulsar/9893,allow to run powermock on jdk11 and upgrade mockito to version <cm-sep> more fixes <cm-sep> fix build,"this patch includes a list of minor fixes that can be grouped . <nl> tests must still run successfully on jdk8 . <nl> once all tests are known to run on jdk11 we will switch ci tests runner to jdk11 , this can not be done in this pr .",1615531226,"motivation . <nl> there are bunch of fixes in version regarding dns cache , ledger storage flushes . <nl> version is a minor release of version , so it is safe to upgrade and included in version release .",0.8437429666519165
apache_incubator-pinot/5478,"add a new table config field for peer segment download . <para-sep> peersegmentdownloadscheme in validationconfig must be http or https <nl> with segmentsvalidationandretentionconfig <nl> todo validate other fields of segmentsvalidationandretentionconfig . <nl> possible values can be http or https . if this field is set , a pinot server can download segments from peer servers using the specified download scheme . both realtime tables and offline tables can set this field .","the value can be http or https . <nl> the field will enable download of segments for both realtime and offline table segments from peer servers . in the beginning , only realtime table segments download will be supported . the design details can be found in this section of the cwiki doc . <nl> the value can be http or https . <nl> the field will enable download of segments for both realtime and offline table segments from peer servers . currently , only realtime table segment download during llc segment completion protocol will be supported . for more",1591049573,"make time column name available from table/user config in places where primary time column is needed , in order to be able to support migration of single time column to multiple datetime columns",0.9514273405075073
Alluxio_alluxio/12099,"enable new master to join an existing quorum <para-sep> give snapshot manager a chance to handle snapshot related requests snapshot manager returned null indicating the request is not handled . check and handle other type of requests . <nl> send a request to join the quorum . if the server is already part of the quorum , this operation is a noop . <nl> adds a server to the quorum . <nl> create entries on the leader journal context . these will be replicated to follower journal context . <nl> create a counting master implementation that counts how many journal entries it processed . <nl> write more entries and validate they are replicated to follower . <nl> creates list of raft journal systems in a clustered mode . <nl> create a separate working dir for the new master .","this change implements the quorum join process for new master . <nl> ratis provides an api for update quorum member list . to implement an automatic join comparable with what we did with copycat , the new master will send a join request to the quorum leader after it initialized the journal . the leader will atomically convert the request to a raft configuration change and apply it to the quorum . <nl> this operation is a noop for a master that is already in the quorum .",1599777479,"load libraries from the lib/ directory , instead of hard coding the dependency in the pom files .",0.9299770593643188
grpc_grpc-java/7396,make channel_creds required in bootstrap file .,"this pr only adds validation to the bootstrap file to require users specify at least one channel creds configuration . <nl> in a following up pr , creating the xds channel will select the first supported channel creds and fail ( e.g. , an exception thrown ) to create the channel if none is supported ( instead of failing back to use parent channel 's channel creds ) . need to clean up the interfaces for creating xdsclient/channel . <nl> also , ideally i am thinking about having a . using is not accurate here .",1599180375,"also log every subchannel state change that is affected by health-checking , i.e. , the state changes when the raw subchannel state is ready and health-check is running .",0.9148845076560974
elastic_elasticsearch/72203,"remove 'external value ' parsing , and replace with swapped out xcontentparsers <para-sep> filters an existing xcontentparser by using a delegate","the majority of field mappers read a single value from their positioned <nl> xcontentparser , and do not need to call . there is a general <nl> assumption that the same holds for any multifields defined on them , and <nl> so the xcontentparser is passed down to their multifields builder as-is . <nl> this assumption does not hold for mappers that accept json objects , <nl> and so we have a second mechanism for passing values around called <nl> 'external values ' , where a mapper can set a specific value on its context <nl> and child mappers can",1619424006,"this commit refactors some of the rest test transformations unit tests . <nl> specifically , this refactor introduces a common parent that the ' match ' <nl> tests ( and other future tests ) can consume . also , the example tests <nl> have been simplified to better illustrate the change . <nl> there should no functional changes , just refactoring . this will help with <nl> future commits to allow focus only for the relevant changes .",0.9701569676399231
Graylog2_graylog2-server/9211,"start new active directory authentication service backend <cm-sep> fix url query handling for initialstepkey on authenticationbackendeditpage <cm-sep> add initial step key to auth backend edit route inside routes , by providing step key as an argument <cm-sep> add useruniqueidattribute input for user sync step <cm-sep> improve help texts for ldap and active directory backend wizard <cm-sep> adjust handling of group sync specific backend wizard configuration <cm-sep> fix handling of excluded fields <cm-sep> revert code structure change <para-sep> try both to avoid the need to configure the usersearchpattern setting <nl> we need to bind against ad using the userprincipalname <nl> if the system user password should be deleted , use an unset value <nl> if the system user password should be kept , use the value from the existing config <nl> if the existing password should be kept and we got an existing config , use the password of the existing config for the connection check . this is needed to make connection tests of existing backends work because the ui does n't have access to the existing password . <nl> active directory useraccountcontrol flags . <nl> the user account is disabled . <nl> this is a default account type that represents a typical user . ( not a computer , for example ) <nl> server config help <nl> user sync help <nl> clean up created auth backend if",this pr implements all necessary api and directory service wizard changes for active directory backends . <nl> it also improves the wizard help texts for active directory and ldap .,1603131174,backport dns lookup adapter to version version . <nl> add/update dependencies to allow backport : <nl> - add netty version.final dependency <nl> - upgrade google guava from 0 to version-jre .,0.9781196713447571
ballerina-platform_ballerina-lang/24236,"update diagnostic codes with message keys . <nl> this is requred to get proper error messages for syntax errors <cm-sep> update with diagnostic code changes <cm-sep> add a helper class to get formatter syntax error messages <cm-sep> add the initial syntax error messages for the new parser <cm-sep> add temporary methods to current diagnostic collector classes . <nl> these methods are required to push syntax diagnostics coming from the new parser <cm-sep> capture syntax diagnostics in the diagnostic collector <cm-sep> update test cases to match with latest syntax errors <cm-sep> disable tests cases due to syntax error level changes <para-sep> additionally code.length is considered to avoid hash collision . <nl> todo this is the temporary mechanism we need to merge the diagnostic reporting mechanisms of the new parser and the semantic analyzer <nl> please node that , this method exist only to report syntax errors coming from the new parser we will remove this method once we merge diagnostic reporting approaches in the new parser and semantic analyzer <nl> please node that , this method exist only to report syntax errors coming from the new parser we will remove this method once we merge diagnostic reporting approaches in the new parser and semantic analyzer <nl> contains utility methods to generate diagnostic messages . <nl> this is not a must because this expression is validated in the semantic analyzer . <nl> { ' workerdeclarationcontext5.json ' , ' function ' } , { ' completionwithininvocationargs8.json ' , ' function ' } ,","i will be doing that from now on and will send another pr soon . <nl> the syntax errors generated by the new parser are much more descriptive than the old antlr-based parser . however , we can improve the error messages and diagnostic positions gradually .",1592358295,0. migrate tableomdatasource class and enable table- > xml conversion . <nl> 0. enable table- > xml conversion tests in tabletest <nl> 0. add decimal retrieval logic in dataiterator back . i added this sometime back but this change has been dropped when merging previous jballerina branch with the master . <nl> 0. moves a table literal related test to tableliteraltest from tabletest .,0.9710280895233154
apache_kafka/9805,remove outdated comment . <nl> connect supports multiple assignment strategies now .,connect supports multiple assignment strategies now .,1609435851,"unsubscribe / resubscribe a rebalance upon task migration ( either false positive or not ) to enforce a rebalance , also to refresh on log end offset .",0.8719695806503296
quarkusio_quarkus/15676,"ensure a stable processing order of the orm entities <cm-sep> the orm scanner only needs to discover actual entities <cm-sep> introduce a mapping affected by the issue of generics narrowing <para-sep> this strange mapping is useful to verify that hibernate orm can actually boot , which implies to successfully narrow down the t generics of the two superclass types . see also for details ; the reason this directly impacts quarkus is that the issue can be triggered by enlisting the parent classes ( mapped with mappedsuperclass ) among the discovered entities - which is not necessary and actually triggers the problem . so this is a regression test to check that quarkus is not passing such abstract types as mapped entities to the orm bootstrap . no actual test is necessary : hibernate orm will fail to boot ( likely but not guaranteed as this is dependent on the order of entity discovery ) simply because these entities exist on the same classpath .",this was super tricky to identify ; the actual fix is the one liner in sha . <nl> the other commits to prevent similar regressions in the future .,1615560397,"but also simplifies the bootstrap process , and further moves some bootstrap work into the augmentation phase . <nl> this should also make the feedback loop better , as quarkus would fail at buildtime ( rather than runtime ) on a larger cathegory of fatal mapping issues .",0.9703306555747986
apache_kafka/10179,"tune configurations . <nl> since we expect controller failovers to be fairly cheap , tune <nl> the default raft configuration parameters so that we detect node <nl> failures more quickly . <nl> reduce the broker session timeout as well so that broker failures are <nl> detected more quickly . <para-sep> the default raft timeouts are relatively low compared to some other timeouts such as request.timeout.ms . this is part of a general design philosophy where we see changing the leader of a raft cluster as a relatively quick operation . for example , the controller should be able to transition from standby to active without reloading all of the metadata . the standby is a ' hot ' standby , not a ' cold ' one .","since we expect controller failovers to be fairly cheap , tune <nl> the default raft configuration parameters so that we detect node <nl> failures more quickly . <nl> reduce the broker session timeout as well so that broker failures are <nl> detected more quickly .",1614032677,the and use relatively strict timeouts of 0 seconds to check the intermediate state of the tests . the test failures observed in these two tests were not about the final output but asserting the embedded broker sent messages within the given timeframe . <nl> i ran the existing streams test suite .,0.8251004815101624
grpc_grpc-java/7713,"on unexpected eos , mention whether the frame was empty . <nl> empty data frames with eos tell a stronger tale as to where the server <nl> may have its bug .",empty data frames with eos tell a stronger tale as to where the server <nl> may have its bug .,1607561883,"this brings cronet client 's stats reporting inline with inprocess , netty , and okhttp . <nl> this was caught by abstractinteroptest # assertclientstatstrace when running the interop tests with a cronet transport .",0.8251517415046692
ballerina-platform_ballerina-lang/26316,"fix review comments of pr26161 <cm-sep> generate the overriden methods <cm-sep> add several node implementations . <nl> nilliteralnode , startactionnode , flushactionnode , failstatementnode , continuestatementnode , trapexpressionnode , letexpressionnode , letvariabledeclarationnode , fromclausenode , whereclausenode , letclausenode , querypipelinenode , wildcardbindingpatternnode , asyncsendactionnode , syncsendactionnode , receiveactionnode , receivefieldsnode , waitactionnode , queryactionnode , transactionstatementnode , rollbackstatementnode , retrystatementnode , commitactionnode , limitclausenode , joinclausenode , breakstatementnode <cm-sep> add several node implementations . <nl> xmlnamespacedeclarationnode , modulexmlnamespacedeclarationnode , xmlsimplenamenode , xmlemptyelementnode , xmltextnode , xmlcomment , xmlprocessinginstruction , localtypedefinitionstatementnode , forkstatementnode , unaryexpressionnode , defaultableparameternode , annotationdeclarationnode , keyspecifiernode , streamtypedescriptornode , streamtypeparamsnode , interpolationnode , methoddeclarationnode , doublegttokennode , tripplegttokennode , orderkeynode <para-sep> check whether a mapping constructor expression needs to be expanded in to multiple lines .","nilliteralnode , startactionnode , flushactionnode , failstatementnode , continuestatementnode , trapexpressionnode , letexpressionnode , letvariabledeclarationnode , fromclausenode , whereclausenode , letclausenode , querypipelinenode , wildcardbindingpatternnode , asyncsendactionnode , syncsendactionnode , receiveactionnode , receivefieldsnode , waitactionnode , queryactionnode , transactionstatementnode , rollbackstatementnode , retrystatementnode , commitactionnode , limitclausenode , joinclausenode , breakstatementnode , xmlnamespacedeclarationnode , modulexmlnamespacedeclarationnode , xmlsimplenamenode , xmlemptyelementnode , xmltextnode , xmlcomment , xmlprocessinginstruction , localtypedefinitionstatementnode , forkstatementnode , unaryexpressionnode , defaultableparameternode , annotationdeclarationnode , keyspecifiernode , streamtypedescriptornode , streamtypeparamsnode , interpolationnode , methoddeclarationnode , doublegttokennode , tripplegttokennode , orderkeynode .",1602503917,e.g : ballerina grpc -- input=.proto -- mode=proxy .,0.9557417631149292
apache_kafka/9957,update zstd-jni to version-0 . <nl> more details tbd . <para-sep> in cases where the caller passes a small number of bytes to write ( potentially a single byte ) . it 's ok to reference since it does n't load any native libraries <nl> in cases where the caller reads a small number of bytes ( potentially a single byte ) . it 's ok to reference since it does n't load any native libraries . <nl> it 's ok to reference since it does n't load any native libraries,"* the latest version zstd-jni does n't use by default , so we <nl> pass it via the relevant constructors to maintain the behavior before this <nl> change . <nl> * zstd version includes several months of improvements across many axis , <nl> from performance to various fixes .",1611521287,"reading the configuration field names from producerconfig class and taking the key and value serializer names from class name directly instead of hardcoding . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger",0.7998558282852173
apache_druid/10623,"fix string byte calculation <para-sep> 0 ( timestamp + dims array + dimensiondesclist ) + 0 ( ' a ' ) + 0 ( ' b ' ) <nl> 0 ( timestamp + dims array + dimensiondesclist ) + 0 ( ' a ' ) + 0 ( ' a ' , ' b ' ) <nl> 0 ( timestamp + dims array + dimensiondesclist ) + 0 ( ' nelson ' ) + 0 ( ' 0 ' , ' abcdef ' ) <nl> 0 ( timestamp + dims array + dimensiondesclist ) + 0 or 0 depending on nullhandling.sqlcompatible ( ) <nl> expectedsizeinbytes = 0 ( map overhead ) + 0 ( timeanddims overhead ) + 0 ( aggregator metrics ) + 0 ( dimskeysize ) = 0 + 0 byte when null handling is enabled <nl> expectedsizeinbytes = 0 ( map overhead ) + 0 ( timeanddims overhead ) + 0 ( aggregator metrics ) + 0 ( dimskeysize ) = 0","fix string byte calculation in stringdimensionindexer . <nl> druid ingestion has a guardrail of maxbytesinmemory . the default value of maxbytesinmemory is 0/0 of max java memory which should prevent the ingestion task ( peon ) from oom . however , for this to work correctly , it relies on accurate calculation of bytes in memory from the in of the . when raw data has a lot of string dimension , the ingestion task ( peon ) can still oom with default value of maxbytesinmemory . this is because the calculation of in stringdimensionindexer is underestimating the memory footprint",1606953104,"was not actually testing sync behavior disabled , and had the incorrect url specified in the mock expect , causing it to just spin forever in retry utils instead of test the behavior . <nl> was doing the correct thing , but a hard coded 0 second timeout in was causing it to spin for an extra minute each retry loop . i refactored the hard coded value to be a property on that defaults to 0 seconds ( mainly so that tests could override , but also just to not be hard coded ) .",0.8935983180999756
vespa-engine_vespa/15226,bound the test quota to the tenant quota,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1604913390,prepare for removing unused/unnecessary options payloadcompressiontype and numparalleltenantloaders,0.8573323488235474
elastic_elasticsearch/72327,"make environment.datafiles singular . <nl> the path.data setting is now a singular string , but the method <nl> datafiles ( ) that gives access to the path is still an array . this commit <nl> renames the method and makes the return type a single path . <para-sep> we have to do this after adding the path because a side effect of that is that the directory is created ; the path # torealpath invocation will fail if the directory does not already exist . we use path # torealpath to follow symlinks and handle issues like unicode normalization or case-insensitivity on some filesystems ( e.g. , the case-insensitive variant of hfs+ on macos ) . <nl> release all the ones that were obtained up until now","the path.data setting is now a singular string , but the method <nl> datafiles ( ) that gives access to the path is still an array . this commit <nl> renames the method and makes the return type a single path .",1619550079,"this pr removes the public method . now , the <nl> index version is always checked through , <nl> except in rare lower-level cases where the setting is accessed directly . <nl> this makes it easier to understand what logic depends on the index version . <nl> it 's a step towards the goal of streamlining how/ where index versions are <nl> accessed .",0.9503594636917114
elastic_elasticsearch/70879,prevent aliases from being used as index sort fields,we currently have no check that prevents an alias field being used to <nl> define an index sort . this can lead to exceptions when opening indexes <nl> or when merging segments if the alias field has been updated . <nl> this commit adds a check to indexsortconfig that the name of the <nl> requested index sort field is the same as the name of the resolved <nl> field type being used as a fielddata source .,1616689449,it is possible that a developer accidentally declares two parsers for the <nl> same field name . <nl> this commit introduces a validation to prevent that from happening .,0.9362961053848267
grpc_grpc-java/7764,"select channel credentials for xds servers during bootstrap . <cm-sep> eliminate xdschannel , pass plain managedchannel and useprotocolv3 as arguements for xdsclient creations . <cm-sep> fix usages of bootstrapinfo . <cm-sep> decouple bootstrapping and xds channel creation . fix the lifecycle issue of xds channel . <para-sep> todo ( chengyuanzhang ) : require at least one server uri . <nl> data class containing xds server information , such as server uri and channel credentials to be used for communication .",the singleton xdsclient objectpool is cached for the entire process . the bootstrap file is read at the time this objectpool is created . the shared xdsclient instance has a much shorter lifecycle than the objectpool as the instance is only created upon the first call of and is destroyed when its reference count reaches zero . the objectpool creates a new xdsclient instance after the previous one was destroyed . <nl> the ownership and lifecycle of the xds channel is wrong . currently the singleton xdsclient objectpool owns the xds channel and it uses the same xds channel even,1609184768,"in this pr , the xds resolver generates a raw service config with load balancing config that supports all matchers in xds_routing config . this converts xdsclient 's data structure to json format . then the xdsroutingconfig parser parses the json-format config back to a java object . note this convert-and-parse-back step is tedious and seemingly unnecessary , but this is how it works now as discussed in the design doc . in the future , we might eliminate this . since and is somewhat similar in terms of its structure , we move the definition of matchers to a",0.970648467540741
elastic_elasticsearch/71760,"frozen indices ( partial searchable snapshots ) require less heap per <nl> shard and the limit can therefore be raised for those . we pick 0 <nl> frozen shards per frozen data node , since we think 0 is reasonable <nl> to use in production .","frozen indices ( partial searchable snapshots ) require less heap per <nl> shard and the limit can therefore be raised for those . we pick 0 <nl> frozen shards per frozen data node , since we think 0 is reasonable <nl> to use in production .",1618509741,fixed storage autoscaling to also calculate a capacity in the case where <nl> the policy governs no nodes currently ( 0-0 case ) .,0.9817991852760315
keycloak_keycloak/7122,added fix that considers content-type for data encoding and added corresponding test,"added fix that considers content-type for data encoding and added corresponding test . <nl> a unit test was added because creating a suitable integration test would cause a non corresponding effort . the test was aligned with the existing test for this class which addresses a similar issue with encoding . the modifications to the pom are needed because surefire by default does not pick up the tests in inner classes . this prevented the existing test from being executed in maven builds . additionally surefire has problems picking up the encoding in the forked jvm , even though the",1590751102,note that we are upgrading freemarker to version ' version-incubating ' . this only denotes that the project is moved to the apache incubator . it is the official version release .,0.8234151601791382
Alluxio_alluxio/11226,get service version out of retryrpc loop <para-sep> calling directly as this method is subject to an encompassing retry loop .,"is a simple unauthenticated code , that is called after a successful connection . <nl> calling it with utility opens a way for some allowed exceptions to fuel an infinite loop .",1585722889,"' ) ; <nl> with <nl> log.error ( ' failed after { } retries . ' , retrypolicy.getretrycount ( ) ) ;",0.7936111688613892
Alluxio_alluxio/11728,"npe resolving <para-sep> glue database location , description and parameters could be null <nl> database name is not required for glue table , use mgluedbname",add null value check for glue fields .,1594164433,cleans up the listener so long living netty readers do not have an infinitely growing set of listeners .,0.918812096118927
elastic_elasticsearch/71541,"frozen autoscaling should not use local storage . <nl> the reactive decider no longer applies to the frozen tier , since it <nl> could grossly over-estimate the amount of storage for unassigned frozen <nl> shards . <para-sep> verify that the list of roles includes all data roles except frozen to ensure we consider adding future data roles .","the reactive decider no longer applies to the frozen tier , since it <nl> could grossly over-estimate the amount of storage for unassigned frozen <nl> shards . <nl> in principle this is a breaking change since existing decider configurations of <nl> reactive on purely frozen tiers would no longer be legal . however , since <nl> frozen tier was experimental in version , frozen searchable snapshots likewise and reactive storage decider has no configuration elements , it is highly unlikely to affect anyone and only users having opt'ed in to experimental functionality . <nl> alternatively , we can make the",1618125733,this pr fixes two bugs that can arise when _source is disabled and we fetch nested documents : <nl> * fix indexoutofboundsexception in nested with disabled _source . <nl> * fix nullpointerexception in nested with disabled _source . <nl> * add more tests for highlighting .,0.8672847151756287
vespa-engine_vespa/15684,log the total time taken to reconfigure,"... is what i meant initially , but missed it in the previous review .",1607091860,"this fixes . <nl> most of this code is to generate a helpful error message by printing ( the start of ) of the offending document . <nl> also removed a case where could be : i 'm not quite sure how this is possible , as long as we find a document id , should be ?",0.9315621256828308
elastic_elasticsearch/71656,"[ ml ] fix machine learning job close/kill race condition <para-sep> it is possible that a request came in before the communicator was set this means that the kill was not handled appropriately and we continued down this execution path <nl> stop the running job and mark it as finished . <nl> do n't remove the process context immediately , because we need to ensure it is reachable to enable killing a job while it is closing","if a machine learning job is killed while it is attempting to open , there is a race condition that may cause it to not close . <nl> this is most evident during the api call . the reset feature api will kill the jobs , then call close quickly to wait for the persistent tasks to complete . <nl> but , if this is called while a job is attempting to be assigned to a node , there is a window where the process continues to start even though we attempted to kill and close it . <nl> this",1618345575,"currently we add translog operation bytes to an array list and flush <nl> them on the next write . unfortunately , this does not currently play well <nl> with our byte pooling which means each operation is backed , at minimum , <nl> by a 16kb array . this commit improves memory efficiency for small <nl> operations by serializing the operations to an output stream .",0.9528144598007202
OpenAPITools_openapi-generator/7415,support server configuration per operation <para-sep> .gem .rbc <nl> dynamicservers : :usageapi | custom_server | get /custom | use custom server dynamicservers : :usageapi | default_server | get /default | use default server <nl> object * <nl> object *,adds support for configurable servers per operation .,1600094413,"- fix using basename instead of paramname <nl> - re-enable elm in ensure-up-to-date script <nl> - minor code formatting ( java class ) . <nl> to repeat the issue , run .",0.8282549381256104
elastic_elasticsearch/72180,"add deprecation for single valued list of data path . <nl> multiple data paths are deprecated , but because path.data is a <nl> listsetting , it still allows a single value . this will change to a <nl> string setting in version . this commit adds detection for the single valued <nl> list case and adds a deprecation warning to the node log . <para-sep> returns true if the data path is a list , false otherwise * / <nl> already checked for multiple values above , so if this is a list it is a single valued list","multiple data paths are deprecated , but because path.data is a <nl> listsetting , it still allows a single value . this will change to a <nl> string setting in version . this commit adds detection for the single valued <nl> list case and adds a deprecation warning to the node log .",1619205135,"it was an undocumented setting , but enough users relied on it that its absence is causing problems during upgrades . this commit adds a message to the deprecation log if this setting is present at startup . <nl> i looked at putting the warning in the java options parser , but it was hard to be sure that a check there was catching all the possible ways that a java setting could be passed to the runtime es jvm . by putting the check in the bootstrap class , we can check the setting in the same way that",0.923886239528656
elastic_elasticsearch/71628,map data tiers roles onto data legacy role for < version <para-sep> a pre version node will only understand legacy roles so let 's test a custom data containing node role is mapped onto the role,"a rolling upgrade from < version to ≥version would fail to map the data <nl> tiers node roles to the role . this pr adjusts the logic to <nl> correctly map the data tier node roles ( or rather , all node roles <nl> that can contain data ) onto the role .",1618317836,"when master shuts down it 's cluster service , a waiting health request <nl> would fail rather than fail over to a new master .",0.8873204588890076
apache_kafka/9773,"kafka streams updates for version release <para-sep> min <nl> max <nl> sum <nl> cnt <nl> dif <nl> avg <nl> test repartition <nl> we want to randomize the order of data to test not completely predictable processing order however , values are also use as a timestamp of the record . ( todo : separate data and timestamp ) we keep some correlation of time and order . thus , the shuffling is done with a sliding window <nl> now that we 've sent everything , we 'll send some final records with a timestamp high enough to flush out all suppressed records . <nl> we shuffle data within windowsize <nl> swap <nl> give it one more try if it 's not already passing . <nl> generate expected answer <nl> check the result <nl> args : := kafka propfilename command disableautoterminate command : = ' run ' | ' process ' <nl> this starts the driver ( data generation and result verification ) <nl> slow down data production to span 0 seconds so that system tests have time to do their bounces , etc . <nl> this starts the stream processing app","added module , updated and for the new module , added the latest release to the . <nl> for testing , i ran locally and everything passed .",1608576070,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.9772456884384155
ballerina-platform_ballerina-lang/23720,fix breakpoint path issue due to new module versioning <cm-sep> fix potential npes when mapping jvm types to ballerina variables <cm-sep> add support for bstrings and jvm integer types <para-sep> extracts relative path of the source file location from jdi class-reference mappings . <nl> removes module version part from the jdi reference source path . <nl> removes module version part from the jdi reference source path .,- adds support for bstrings and jvm integer types .,1591252395,- fix calling init multiple times when services are used <nl> - refactor suite initializing logic and update bal files <nl> - update tests and fix broken tests .,0.9554257988929749
elastic_elasticsearch/71734,[ ml ] improve wording of data frame analytics audit messages . <nl> improves wording for two data frame analytics audit messages : . <nl> ' created analytics with analysis type ' becomes <nl> ' created analytics with type ' . <nl> ' estimated memory usage for this analytics to be ' becomes <nl> ' estimated memoery usage ' .,improves wording for two data frame analytics audit messages : . <nl> ' created analytics with analysis type ' becomes <nl> ' created analytics with type ' . <nl> ' estimated memory usage for this analytics to be ' becomes <nl> ' estimated memory usage ' .,1618484893,"renames and moves the cross validation splitter package . <nl> first , the package and classes are renamed from using <nl> ' cross validation splitter ' to ' train test splitter ' . <nl> cross validation as a term is overloaded and encompasses <nl> more concepts than what we are trying to do here . <nl> second , the package used to be under but it does <nl> not make sense to be there , it can be a top level package <nl> under .",0.8581950664520264
Graylog2_graylog2-server/9372,"* add is_cloud flag , and suppress input not running warning . <nl> ( cherry picked from commit sha ) <cm-sep> add support for multipart file uploads . <nl> this is needed for cloud file uploads . <nl> ( cherry picked from commit sha ) <cm-sep> hide csv adapter in cloud instances . <nl> using csv adapters in cloud will have different requirements , so this <nl> plugin should not be available . <nl> ( cherry picked from commit sha ) <cm-sep> * expose to frontend . <nl> still needs cleaning up and will probably fail if the cloud plugin is <nl> not loaded . <nl> * do n't use environment variable to transport value for iscloud . <nl> * new approach : do n't use template but webpack define plugin instead . <nl> * fix eslint warnings . <nl> * add ' cloud ' to dev badge also for narrow screens . <nl> * add missing parentheses . <nl> * remove extra space from badge . <nl> * simplify expression . <nl> * remove parentheses . <cm-sep> * hoc to hide hide ui elements when cloud . <nl> * allow filtering menu items . <nl> * add tests for iscloud . <nl> * add comments to withhideoncloud . <nl> * add test for filter menu items . <nl> * use iscloud directly . <nl> * refactor filtermenuitems . <nl> ( cherry picked from commit sha ) <para-sep> the is_cloud variable will be set by webpack via the defineplugin . eslint-disable-next-line no-undef","cherry-picks of all changes made to which have to be ported to . <nl> of the following commits which were in but not in : . <nl> i 've cherry picked the following : . <nl> we made some changes directly to which were not backports from . we 'll have to port those to , otherwise they will be lost . <nl> todo : .",1604586565,0. create a user ( web interface ) <nl> 0. create multiple access tokens for the new user ( web interface ) <nl> 0. delete the user ( web interface ) <nl> 0. verify the user and the access tokens are deleted from the mongo db .,0.9222997426986694
jenkinsci_jenkins/4939,"combobox improvements . <nl> * support default value <nl> * support readonly mode <nl> * align markup with textbox <para-sep> no additional h1 , meaning the ' payload ' is not interpreted",* developer : improve the combobox component : support default value and readonly mode,1600354565,"this pull request just corrects a method name mix up ( should be iscaseinsensitive ( ) instead of iscasesensitive ( ) ) , removes redundant imports and adds the right jira ticket number in the commit message and in the changelog .",0.8233608603477478
vespa-engine_vespa/16102,add zstd support to compressor . <nl> introduce zstandard compression using airlift aircompressor - a pure java implementation . <cm-sep> extend zstdcompressor with more low-level api methods <cm-sep> implement an output stream compressing with zstd <cm-sep> document pitfall with decompress ( ),i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1611069301,required to support some transformer models .,0.9258261919021606
elastic_elasticsearch/70697,"add rest scaffolding for node shutdown api . <nl> this commit adds the rest endpoints for the node shutdown api . these apis are behind the <nl> feature flag for now , as development is ongoing . <nl> currently these apis do not do anything , returning immediately . we plan to implement them for real <nl> in subsequent work . <para-sep> todo : implement me ! <nl> todo : implement me ! <nl> todo : implement me ! <nl> todo : implement tests","this commit adds the rest endpoints for the node shutdown api . these apis are behind the <nl> feature flag for now , as development is ongoing . <nl> currently these apis do not do anything , returning immediately . we plan to implement them for real <nl> in subsequent work .",1616451037,"this commits adds a data stream feature flag , initial definition of a data stream and <nl> the stubs for the data stream create , delete and get apis . also simple serialization <nl> tests are added and a rest test to thest the data stream api stubs . <nl> this is a large amount of code and mainly mechanical , but this commit should be <nl> straightforward to review , because there is n't any real logic . <nl> the data stream transport and rest action are behind the data stream feature flag and <nl> are only intialized if",0.9909773468971252
hazelcast_hazelcast/18480,wip <para-sep> intended to put an upper bound to sampling . used in evictions . <nl> evict expired keys among sampled ones .,"previously , temporarily created arraylist can grow , at worst , to the number of keys in a partition while sampling keys , in an aggressive expiry configuration this can cause problems like increasing gc pressure and cpu usage spikes . now we use a thread local fixed size array and doing sampling in a loop to prevent uncontrolled growth of this queue .",1617717142,fixes serializationservice 0-byte support when serializing and de-serializing strings . the new format uses number of bytes for the length field instead of number of java characters in the string . the fix enables string data type serialization to follow standard ( rfc 0 ) . <nl> the fix is for prd .,0.9507322311401367
apache_flink/14890,task failure will not trigger master hook 's reset ( ) <para-sep> set up the coordinator <nl> add a master hook,"- always reset the master hooks at the restore . <nl> this change is already covered by existing tests , such as the test case in pravega flink connector . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its",1612674774,"implement insert for hive dialect . <nl> to implement insert for hive dialect . <nl> - implement syntax . <nl> - add test cases . <nl> existing and added tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos ,",0.9585393667221069
apache_kafka/9613,"ensures invalid_producer_epoch recognizable from client side , and ensure the produceresponse always uses the old error code as invalid_producer_epoch . <nl> reviewers : guozhang wang <para-sep> invalidproducerepochexception <nl> this exception indicates that the produce request sent to the partition leader contains a non-matching producer epoch . when encountering this exception , user should abort the ongoing transaction by calling kafkaproducer # aborttransaction which would try to send initpidrequest and reinitialize the producer under the hood . <nl> first we will get an endtxn for abort . starting from version , we replaced producerfenced error with invalidproducerepoch in the producer send response callback to differentiate from the former fatal exception , letting client abort the ongoing transaction and retry .","ensures invalid_producer_epoch recognizable from client side , and ensure the produceresponse always uses the old error code as invalid_producer_epoch . <nl> reviewers : guozhang wang . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered",1605718777,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.8949130773544312
OpenAPITools_openapi-generator/7979,set generatealiasasmodel false in tests <para-sep> make sure isgeneratealiasasmodel is false <nl> make sure isgeneratealiasasmodel is false <nl> make sure isgeneratealiasasmodel is false,- set generatealiasasmodel to false in tests to fix github action 's failure .,1605778452,add the option disallowadditionalpropertiesifnotpresent to support ' additonalproperties : true ' by default .,0.8752396106719971
apache_incubator-pinot/5729,adding support for ingestion job spec as json,both table and schema are currently taken as json so it makes sense to have ingestion job spec also in json format rather than currently supported yaml format . <nl> the yaml format has been kept as default to maintain backward compatibility .,1595428366,"taking inputs such as replication , retention , inverted index columns , no dictionary columns from the table config",0.9482753276824951
Graylog2_graylog2-server/9735,"to make sure that if the object is injected , it is actually the same <nl> object as bound via the service binder . <cm-sep> remove explicit shutdown for messagequeuereader . <nl> originally , this shutdown did n't have any effect anyways , because the <nl> object it was called upon was not the running service . <nl> during shutdown , the message queue reader will stop processing because <nl> it listens to lifecycle events . at least the kafka version does . <nl> there is no need to change the behaviour now . <cm-sep> fix comment . <nl> interrupting the thread wo n't help , so just document the issue for now <cm-sep> extract lifecycle handling and share for kafka and pulsar readers <cm-sep> simplify lifecycle switch <para-sep> do n't care , keep processing journal <nl> indicates if the reader should read from the message queue or if it should currently pause reading . the returned value is affected by lifecycle changes , e.g . during server startup or when processing has stopped it will be false , during normal operation mode it will be true . <nl> fixme : on a full process buffer , where not a single entry is ever taken out again , this call will block ( obviously ) forever . but it ca n't even be unblocked by interrupting the thread , e.g . for shutting down the server . this will inhibit server shutdown when elastic search is down .",extracts lifecycle handling for message queue readers into abstract class . <nl> adds lifecycle handling of pulsar message queue reader .,1607518686,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.9431135654449463
apache_pulsar/9789,"allow broker to discover and unblock stuck dispatcher <cm-sep> add documentation <para-sep> checks if read position changed since this method was called last time . <nl> keeps sample of last read-position for validation and monitoring if read-position is not moving forward . <nl> check empty ledger <nl> read-position has not been moved <nl> ok <nl> read-position is moved <nl> read-position has not been moved since last read <nl> recover cursor <nl> ok <nl> returns true because read-position is on tail <nl> checks if dispatcher is stuck and unblocks the dispatch if needed . <nl> consider dispatch is stuck if : dispatcher has backlog , available-permits and there is no pending read <nl> consider dispatch is stuck if : dispatcher has backlog , available-permits and there is no pending read <nl> check stuck subscription <nl> test validates if topic 's dispatcher is stuck then broker can doscover and unblock it . <nl> build backlog <nl> block sub to read messages <nl> allow reads but dispatchers are still blocked <nl> run task to unblock stuck dispatcher : first iteration sets the lastreadposition and next iteration will unblock the dispatcher read because read-position has not been moved since last iteration .","it can happen due to regression bug or unknown issue when expiry runs .. one of the workarounds is manually unload the topic and reload it which is not feasible if this happens frequently to many topics . or broker should have the capability to discover such stuck subscriptions and unblock them . <nl> below example shows that : <nl> subscription has available-permit > 0 , there is no pending reads , cursor 's read-position is not moving forward and that builds the backlog until we unload the topic . it happens frequently due to unknown reason : . <nl>",1614820494,"if the topic has relatively low traffic , the de-duplication cursor will not move . this can cause messages that are not able to be deleted based on the retention policy . we should add a policy to take de-duplication snapshots based on time .",0.9712178707122803
eclipse-openj9_openj9/10888,remove references to 'com.ibm.oti.vm.library.version ' . <nl> * do n't use preprocessor macro or system property . <cm-sep> do n't define unused preprocessor macro 'com.ibm.oti.vm.library.version ' . <nl> * it 's no longer used in any jcl code .,* do n't use preprocessor macro or system property in <nl> - upcoming changes to the extension repos will remove unnecessary read permission for the system property <nl> * stop defining preprocessor macro - it 's no longer used in any jcl code,1602701201,init system property via native . <nl> there is a need to retrieve the system property via in an early phase before java code running . <nl> removed the java code ( java 0+ ) setting the property ; <nl> get the property value via and set it within ; . <nl> verified that the system property has correct value .,0.8209766149520874
quarkusio_quarkus/15990,improved execution of grouped assertions .,"problem : <nl> a test method with many individual assertions stops being executed on the first failed assertion , which prevents the remaining ones ' execution . <nl> solution : <nl> using junit 's grouped assertions feature , all assertions are executed , and all failures will be reported together . in this refactoring , no original assertion was changed . <nl> result : <nl> _before : _ . <nl> _after : _",1616586350,i tested this with a file system path that had both spaces and greek characters and it worked fine,0.7856521606445312
ballerina-platform_ballerina-lang/26416,add support for value : frombalstring ( ) <cm-sep> add tests for value : frombalstring ( ) <para-sep> common utility methods used for ballerina expression syntax manipulation . <nl> create an array from string literal . <nl> create a map from string literal . <nl> create a table from string literal . <nl> create a tuple from string literal . <nl> create an xml from string literal . <nl> identify elements of an array or map from a string . <nl> returns the ballerina value represented by ballerina expression syntax . <nl> returns the result of evaluating a ballerina expression syntax .,"return the result of evaluating the parsed expression , or an error if the string can not be parsed . <nl> the subset of ballerina expression syntax supported is that produced by tobalstring when applied to an value .",1603134112,"we can provide a context aware code action to auto-generate the function for the user . thus , will give the 'undefined function error ' . still we can make a code action suggestion to auto-generate the function createint ( ) that returns an int . <nl> > <nl> > <nl> > # # # sample 0 <nl> > in this case ; there 's a constrained map of the person object . person object has a contructor where age and address fields are required parameters . thus , code action will generate a function that returns a person object",0.9809278845787048
apache_pulsar/9228,"handle web application exception to redirect request . <nl> motivation . <nl> throws a web application exception with <nl> to redirect the request to the owner broker . but the web application exception is a runtime exception . if you do n't <nl> handle and propagate it correctly , it will cause web request to be hang . <nl> it causes <nl> with non-persistent topics to be hang . <nl> this pull request make sure the callers of catch and propagate the exceptions to <nl> web response .","motivation . <nl> throws a web application exception with <nl> to redirect the request to the owner broker . but the web application exception is a runtime exception . if you do n't <nl> handle and propagate it correctly , it will cause web request to be hang . <nl> it causes <nl> with non-persistent topics to be hang . <nl> this pull request make sure the callers of catch and propagate the exceptions to <nl> web response .",1610956724,"unlike pulsar client configuration builder where it 's possible to either enable or disable the tls hostname verifcation of the commonname to match with broker address , on it 's not possible to configure it . <nl> the default in jersey client is to have that enabled , and with a verifier that does n't properly expand wildcards in the cn string .",0.8999543786048889
confluentinc_ksql/6238,scale of round ( ) return value . <nl> fixes the scale of the decimals values returned by the variant of the method that takes a decimal and a required number of decimal places to round to . <nl> this fixes a bug where the output could not be serialized to avro . <cm-sep> delimited format should write decimals in a format it can read . <nl> breaking change <nl> this changes the format the form writes decimals from to <para-sep> avoid scientific notation for now : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,breaking change <nl> this changes the format the form writes decimals from to . <nl> usual .,1600281888,this patch <nl> updates astbuilder to instead choose the appropriately sized literal type based on the <nl> value .,0.9331082105636597
vespa-engine_vespa/16900,add shared zk client config generator for zkfacade and vespa-zkcli <para-sep> builder for zk client configuration <nl> todo ( bjorncs ) remove handling of temporary feature flag,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1615467166,"all mutable requests to the following paths will be written to the audit log : . <nl> * <nl> * <nl> * . <nl> those paths cover the most important operator actions , such as : . <nl> * ( de ) activation of maintenance jobs on controller <nl> * version confidence overrides <nl> * scheduling os or firmware upgrades <nl> * proxied calls to config servers : feature flag changes , ( de ) activation of <nl> node repository maintenance jobs , node state changes , scheduling of node reboots etc . <nl> we can also consider adding node",0.9700635671615601
apache_incubator-pinot/5927,support for local.directory.sequence.id <para-sep> assign sequence ids to input files based at each local directory level,there is support for the same using pinotsparkjoblauncher . but not using the launchdataingestionjobcommand .,1598446135,add support for ' none ' baseline which hides baseline timeseries in the chart .,0.9083458781242371
hazelcast_hazelcast/18499,limit the number of parallel partition reads for map/cache . <nl> reading from all of the partitions in parallel can cause oom on the <nl> server side . we limit the parallel reads to a constant value ( 0 ) and <nl> decrease the max fetch size ( 0 ) .,reading from all of the partitions in parallel can cause oom on the <nl> server side . we limit the parallel reads to a constant value ( 0 ) and <nl> decrease the max fetch size ( 0 ) .,1617890739,this is just a best effort attempt to early catch potential issues with mostly dev environments when not internet connected .,0.7636697292327881
apache_kafka/9987,": gracefully handle invalid jaas configs <para-sep> we have to be careful not to throw anything here as this static block gets executed during plugin scanning and any exceptions will cause the worker to fail during startup , even if it 's not configured to use the basic auth extension . <nl> for testing <nl> if we failed to retrieve a jaas configuration during startup , throw that exception now","if an invalid jaas config is present on the worker , invoking throws an exception . <nl> this follow-up handles invalid jaas configurations more gracefully , and only throws them if the worker is actually configured to use the basic auth extension , at the time that the extension is instantiated and configured . <nl> two unit tests are added to test the green-path and red-path behavior of the extension when it encounters well-formed and ill-formed jaas configurations , respectively .",1611785773,"fix the following situations , where pending members ( one that has a member-id , and has requested to join a group ) can cause rebalance operations to fail : . <nl> - in abstractcoordinator , a pending consumer should be allowed to leave . <nl> - a rebalance operation must successfully complete if a pending member either joins or times out . <nl> - during a rebalance operation , a pending member must be able to leave a group .",0.9440842270851135
hazelcast_hazelcast/18207,<para-sep> right input is over . <nl> left input is over .,this pr improves so that now it checks the actual and expected entries returned from the index scan operator .,1613154797,"when metric dictionary word was longer than 0 characters , incorrect <nl> compressed stream was produced . this pr pushes the limit to 0 <nl> characters and fails fast if exceeded . <nl> also removes unnused from .",0.9582037925720215
apache_pulsar/9412,"handle bad-version in metadata-store if broker updates zk-metadata from zk-client <para-sep> if resource is updated by other than metadata-cache then metadata-cache will get bad-version exception . so , try to invalidate the cache and try one more time . <nl> this test validates that metadata-cache can handle badversion failure if other cache/metadata-source updates the data with different version .","metadata-store reads the metadata , caches the data and version in metadata-cache . now , if metadata-znode gets updated by zk-client directly then next update by metadata-cache on that znode will fail with badversion-error as metadata-cache does n't have the latest version . <nl> to address this issue , broker should use metadata-store from every component until then metadata-cache should handle badversion exception , invalidate cache and retry once to handle such issue .",1612219342,"right now , while creating producer/consumer , broker tries to authorize them by fetching namespace policies using zkcache . but sometimes , zkcache times-out while getting zk-node into cache and zk-cache keeps pending key for 0 mins . because of that client ca n't create producer/consumer on that topic for 0 mins . <nl> fix : broker should invalidate key if it receives timeout while accessing zk-cache so , subsequent requests can successfully fetch it .",0.9283170700073242
grpc_grpc-java/7720,check pending stream completion at delayed transport lifecycle <cm-sep> rename <para-sep> provides the place to define actions at the point when transfer is done . call this method to trigger those transfer completion activities . <nl> 0 - 0 ( runduetask with start ),"the real stream done set to the delayed stream which completes the delegation . because it does not track the completion , shutdown prematurely goes through and then executor was destroyed . <nl> the inflight work that has been scheduled happen to use the same executor , causing .",1607646014,"- subclasses of include remote address in insight if available . <nl> - adds buffered time , and the insight of real stream if it 's set . <nl> - insights outputs of substreams . <nl> - ~~ adds channel state . other information , like last error status , would need api changes to ~~ . <nl> example error message : . <nl> or .",0.9475042223930359
ballerina-platform_ballerina-lang/23533,add to/from json <cm-sep> add to/from json <cm-sep> add to/from json <cm-sep> add excludeindex <para-sep> validation and decide source root and source full path <nl> generating api docs through a json file <nl> disable deprecated verbose logs from docerina <nl> generate project model <nl> sort modules by module path <nl> generate index.html for the project <nl> used to convert path objects to json .,0. move templates used for documentation generation to lib/templates <nl> 0. exclude generation of project index.html .,1590567543,the desugar phase prepares the ast for code generation and the code gen phase generates the binary . this design introduces another phase called annotation processing after the code analysis phase . <nl> please note that the test cases are pending . i will add them shortly .,0.9750937223434448
vespa-engine_vespa/15448,do n't use private inner class in return type of public methods <cm-sep> deprecate vespaclientbuilderfactory + vespajerseyjaxrsclientfactory <cm-sep> stabilize unit test . <nl> use jsontesthelper for proper semantic json comparison . <cm-sep> implement vespa http client builder for apache http async client 0 <para-sep> async http client builder for internal vespa communications over http/https . configures vespa mtls and handles tls mixed mode automatically . client should only be used for requests to vespa services .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606234971,"we want metadata to be able to find unused tenants , there is no way of <nl> tracking this today without tracking all sessions for a tenant and we allow <nl> sessions some lifetime , so this makes it impossible to find out in systems <nl> where there are a lot of short-lived deployments ( test systems ) . <nl> writing metadata is guarded by a feture flag .",0.9739639163017273
vespa-engine_vespa/16807,"consider growth rate vs. scaling time , part 0 <para-sep> the predicted duration of a rescaling of this cluster * / <nl> todo : remove when we have reliable completion for content clusters <nl> what cost difference is worth a reallocation ? / what resource difference is worth a reallocation ? / <nl> cluster level metrics . these are aggregated at fetch time over the nodes in the cluster at that point in time . <nl> queries per second * / <nl> a series of metric snapshots for the nodes of a cluster used to compute load <nl> the measurements for all nodes in this snapshot * / <nl> the cluster this is a timeseries for * / <nl> the nodes of the cluster this is a timeseries for * / <nl> returns the average number of measurements per node * / <nl> returns the number of nodes measured in this * / <nl> returns the average load of this resource in this * / <nl> a list of metric snapshots from a cluster , sorted by increasing time ( newest last ) . <nl> the max query growth rate we can predict from this time-series as a fraction of the current traffic per minute * / <nl> find the period having the highest growth rate , where total growth exceeds 0 % increase <nl> the current query rate as a fraction of the peak rate in this timeseries * / <nl> metric time series by node ( hostname ) . each list of metric snapshots is sorted by increasing timestamp * / <nl> adds node snapshots to this . * / <nl> returns all cluster level metric snapshots for a given cluster * / <nl> node level metrics * / <nl> cluster level metrics . must be aggregated at fetch time to avoid issues with nodes and nodes joining/leaving the cluster over time . <nl> a single measurement of all values we measure for one node . <nl> queries per second * / <nl> the configuration generation at the time of this measurement , or 0 if not known * / <nl> ( 0 is timestamp ) <nl> this error seems non-recoverable <nl> ( 0 is timestamp ) <nl> we remove full days at once and we want to see at least three days to not every only see weekend data <nl> we should do this if we get","this adds a query rate timeseries per cluster , finds the max rate of significant ( > 0 % ) growth on it and uses that plus the predicted rescaling time to determine the cpu headroom needed to handle similar growth in the future .",1614892369,"the changes brought each other on , and got jumbled together 😭 . <nl> the changes are : . <nl> 0. logs are stored as objects . <nl> 0. the log for an active run is stored with a curator , in chunks of reasonable sizes . <nl> 0. log entries is written through immediately upon logging , and are given a ( new ) sequence id as counted per run . <nl> 0. when a run finishes , its log chunks are aggregated and moved to long-term storage . <nl> 0. logs are served as log objects in the",0.9829280376434326
vespa-engine_vespa/16327,run tests for lb services config on hosted vespa . <nl> test now runs with hosted vespa setup as it does in the real world <para-sep> creates this with a set of host names of the flavor 'default ' * /,test now runs with hosted vespa setup as it does in the real world,1612257387,"we have seen 0 deployments running at the same time , which is more than the config servers can handle .",0.9402512311935425
elastic_elasticsearch/71627,"the frozen tier only holds shared cache searchable snapshots . this <nl> commit adds an autoscaling decider that scales the total memory on <nl> the tier adequately to hold the shards . a frozen shard is assigned <nl> a memory size of 64gb/0 , i.e. , each 64gb node can hold 0 shards <nl> before scaling further . <para-sep> randomly set the setting to verify it can be set . <nl> this decider enforces that on a 64gb memory node ( 31gb heap ) we can max have 0 shards . we arrive at 0 because our current limit is 0 but frozen tier uses the ' frozen engine ' , which is much more efficient . we scale the total tier memory accordingly . the decider relies on frozen tier being used exclusively for frozen shards . <nl> we assume that nodes do not grow beyond 64gb here . <nl> pass setting validator .","the frozen tier only holds shared cache searchable snapshots . this <nl> commit adds an autoscaling decider that scales the total memory on <nl> the tier adequately to hold the shards . a frozen shard is assigned <nl> a memory size of 64gb/0 , i.e. , each 64gb node can hold 0 shards <nl> before scaling further .",1618317621,the primary shards of follower indices during the bootstrap need to be <nl> on nodes with the remote cluster client role as those nodes reach out to <nl> the corresponding leader shards on the remote cluster to copy lucene <nl> segment files and renew the retention leases . this commit introduces a <nl> new allocation decider that ensures bootstrapping follower primaries are <nl> allocated to nodes with the remote cluster client role .,0.9850477576255798
jenkinsci_jenkins/4874,"removed deprecated processtreekiller <para-sep> this contains a maven project with a single test that sleeps 5s . <nl> build the project , wait until tests are running , then cancel . <nl> will fail ( at least on windows ) if test process is still running <nl> on some platforms where we fail to list any processes , this test will just not work <nl> kick off a process we ( should n't ) kill <nl> means the process is still running <nl> on some platforms where we fail to list any processes , this test will just not work <nl> define a process we ( should n't ) kill <nl> create an agent so we can tell it to kill the process <nl> start the process <nl> call killall ( somewhat roundabout though ) to ( not ) kill it <nl> means the process is still running",* internal : removed deprecated and unused class,1595625013,setup wizard did n't restrict access to all unnecessary paths prior to authentication .,0.9359608292579651
apache_incubator-pinot/5375,handling a no-arg function in query parsing and expression tree,fails since we expect arguments . this pr fixes the parsing in calcite sql and transform expression tree .,1589298298,add upper/lower bounds to timeseries .,0.9415740966796875
keycloak_keycloak/6997,allow deleting permission tickets with the authz client <para-sep> deletes a permission ticket by id .,this allows deleting permission tickets with the authz client .,1587564824,"since it 's just 0 lines of code , i 've put them into single pr .",0.8524714708328247
apache_pulsar/9010,motivation . <nl> using await until for retrying the condition check .,motivation . <nl> using await until for retrying the condition check .,1608515727,"this test was flaking due to the pulsar client being reused . the test <nl> starts a proxy service , subscribes to a topic , stops the proxy , starts <nl> a new proxy and tries to subscribe again . <nl> if using the same client for both connections , the client will have an <nl> open connection to the first proxy , which , when the proxy is stopped , <nl> will be closed by netty asynchronously . this can race with the second <nl> subscription attempt , and cause it to fail with <nl> connectionclosedexception . specifically ,",0.8041121959686279
confluentinc_ksql/6118,"adds support for 0x , x ' , x ' type hex in udf : encode <para-sep> strip away ' ox ' from front or ' x\ ' ' + ' \ ' ' from front or back of hex if present <nl> strip away ' ox ' from front or ' x\ ' ' + ' \ ' ' from front and back of hex if present <nl> strip away ' ox ' from front or ' x\ ' ' + ' \ ' ' from front and back of hex if present <nl> matches with things like ' 0x ' and ' 0x .... ' <nl> add an extra ' 0 ' to the front if there are odd number of digits <nl> matches with things like ' x ' ' , ' x ' ' , ' x ' .... ' ' and ' x ' .... ' '","earlier , the encode udf would not recognize hex strings of types belong to { 0x , x ' ... ' , x ' ... ' } while converting to ascii , utf8 and base 0 and would give nulls . now it recognizes them and converts them accordingly from hex to other formats .",1598559864,"specifically , the following shortcut commands can now be entered as the first text of a new command line with the following effects : . <nl> - - rerun the most recent command <nl> - - rerun the command with index 0 , as printed by the command <nl> - - reverse history reference , here rerunning the third most recent command <nl> - - reverse search through the history of commands and rerun the first one containing <nl> - - rerun the most recent command but with all occurrences of within it replaced by . <nl> could use some",0.8546667098999023
ballerina-platform_ballerina-lang/23748,"align runtime error type representation <cm-sep> fix null pointer exception in pkg builder <para-sep> bassertutil.validateerror ( resultnegative , ++i , ' incompatible types : expected 'any ' , found ' ( anydata|readonly ) ' ' , 0 , 0 ) ;",and disable and fix failing unit tests . <nl> after this pr all jballerina-unit-tests should pass when breaking modules are disabled in the build . <nl> fixes # .,1591333979,so this pr syncs the code between two repos .,0.9025447368621826
elastic_elasticsearch/70759,"add descriptions parameter for listing tasks <para-sep> the list tasks action itself is filtered out via this description filter <nl> the list tasks action itself is kept via this description filter which matches everything <nl> description patters on which to match . if other matching criteria are set , descriptions are matched last once other criteria are satisfied matching on descriptions is only available if is . <nl> should the task match specific descriptions .",this commit adds a new parameter for listing tasks in the transport layer . <nl> this allows tasks to be filtered by and so that matching specific tasks <nl> within a particular action is possible . <nl> note : this is not available as a rest parameter yet . the only way to use this parameter is through the transport client within the cluster .,1616512225,"adds and support to fields , <nl> specifically those with the of . others <nl> s will return an error if provided with those parameters .",0.9565451741218567
apache_beam/12794,"support for kafka deserialization api with headers ( since kafka api version ) <para-sep> testing kafka clients api version onwards ( deserialization with headers suppport ) <nl> consumerspel to handle multiple of versions of consumer api between kafka version and version onwards . it auto detects the input type list/collection/varargs , to eliminate the method definition differences . <nl> it is supported by kafka client version onwards . <nl> kafka api version onwards <nl> kafka api version onwards <nl> assert we have the default deserializer with headers api in the stack trace for kafka api version onwards <nl> assert we have the default deserializer with headers api in the stack trace for kafka api version onwards <nl> to assert that we continue to prefer the deserializer api with headers in kafka api version onwards","tldr let kafkaio support the deserializer api with headers . <nl> references mailing list posts : . <nl> the reason for spel is because with kafka-clients api < version as dependency , compilation fails with : . <nl> i opted for and as api to ensure forward looking consistency for both and as both already depended on an instance thereof . <nl> using the spel for kafka-client api version onwards effectively turns the deserialization path into a more expensive indirection by calling the deserializer methods using reflection ( 2x per record , 0 x key , 0 x value )",1599645682,"this adds pipelineoptions , boundedwindow , paneinfo and the elements timestamp as additional valid parameters to splittabledofns getinitialrestriction/splitrestriction/newtracker methods . <nl> note that this is not intended to be the full set of allowed optional parameters",0.9627024531364441
neo4j_neo4j/11420,"revert ' fix test ' . <nl> this reverts commit sha . <cm-sep> fix infinity in pointvalues for good . <nl> this reverts this <nl> nonsense and also fixes the uncovered failure . <para-sep> after a failure , do this to reproduce with the actual values that caused the error : place a single call to testoperator after the for-loop . as an example { { { testoperator ( ' = ' , valuesetup ( ' datetimes ' , gen.oneof ( seq ( datetimevalue.parse ( ' 0-0-13t20:0:52z ' , null ) , datetimevalue.parse ( ' 0-0-13t20:0:52z [ europe/brussels ] ' , null ) ) ) , x = > x.sub ( oneday ) , x = > x.add ( oneday ) ) ) } } } <nl> do not turn this into ? -operator <nl> this return integer ( null possible ! ) <nl> this returns int",this reverts this <nl> nonsense and also fixes the uncovered failure .,1522316157,unify hazelcast configuration among core and edges .,0.8178583979606628
apache_incubator-pinot/6076,[ te ] upgrade dropwizard-swagger dependency,upgrade dropwizard-swagger to version-0 so that it pulls the latest version of io.dropwizard .,1601419778,set default daily detection to generic spline .,0.7403610348701477
confluentinc_ksql/6655,"fix error categorization on npe from streams . <nl> fixes error categorization when streams exits due to an internal npe <nl> - fixes the regex categorizer to correctly handle npes . npes have null <nl> descriptions , so this patch changes the categorizer to ignore the <nl> description if its null . <nl> - fixes the uncaught handler to categorize errors as unknown if the <nl> categorizer throws <para-sep> if error classification throws then we consider the error to be an unknown error . we notify listeners and add the error to the errors queue in the finally block to ensure all listeners and consumers of the error queue ( e.g . the api ) can see the error . similarly , log in finally block to make sure that if there 's ever an error in the classification we still get this in our logs . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","fixes error categorization when streams exits due to an internal npe <nl> - fixes the regex categorizer to correctly handle npes . npes have null <nl> descriptions , so this patch changes the categorizer to ignore the <nl> description if its null . <nl> - fixes the uncaught handler to categorize errors as unknown if the <nl> categorizer throws",1605923854,unit and integration tests are expected for any behavior changes._ .,0.9570611715316772
apache_camel/4613,: migrate camel-couchbase integration tests to use testcontainers <cm-sep> camel-couchbase : add switch to consumer to return either full document or view result <nl> add connecttimeout <para-sep> connection fine tuning parameters <nl> if true consumer will return complete document instead data defined in view <nl> define the timeoutconnect in milliseconds <nl> if true consumer will return complete document instead data defined in view . the option is a : boolean type . default : false group : consumer <nl> if true consumer will return complete document instead data defined in view . the option will be converted to a boolean type . default : false group : consumer <nl> define the timeoutconnect in milliseconds . the option is a : long type . default : 0 group : advanced <nl> define the timeoutconnect in milliseconds . the option will be converted to a long type . default : 0 group : advanced <nl> define the timeoutconnect in milliseconds . the option is a : long type . default : 0 group : advanced <nl> define the timeoutconnect in milliseconds . the option will be converted to a long type . default : 0 group : advanced <nl> define the timeoutconnect in milliseconds . the option is a : long type . default : 0 group : advanced <nl> define the timeoutconnect in milliseconds . the option will be converted to a long type . default : 0 group : advanced,"this pr migrates existing integration tests to use test-infra and test-containers . also small polishing was done , such as added parameters such as and . <nl> if enabled then in consumer is returned full document instead of result defined in view . this was default behavior before . so it was n't possible to get view result .",1605522414,"should we not backport this to 0.x ? if not , please just ignore and close it unmerged . thanks .",0.9701453447341919
apache_incubator-pinot/5310,"move expressionevaluators and schemafieldextractor from pinot-spi to pinot-core <para-sep> performs time transformation <nl> interface for evaluators of transform function expressions of schema field specs they transformfunction follows the convention : ' transformfunction ' : ' functiontype ( { function } , argument1 , argument2 , ... argumentn ) ' for example , ' transformfunction ' : ' groovy ( { firstname + ' ' + lastname } , firstname , lastname ) ' <nl> get the arguments of the function <nl> evaluate the function on the generic row and return the result <nl> if transform function expression present , use it to generate function evaluator <nl> for backward compatible handling of time field conversion <nl> for backward compatible handling of map type ( currently only in avro ) <nl> for backward compatible handling of map type in avro ( currently only in avro ) <nl> groovyshell is used to execute expressions . the transform expression must follow the convention groovy ( { expression } , arguments1 , argument2 ... ) for example : ' dimensionfieldspecs ' : [ { ' name ' : ' fullname ' , ' datatype ' : ' string ' , ' transformfunction ' : ' groovy ( { firstname+ ' '+lastname } , firstname , lastname ) ' } ] <nl> fixme : if any param is null a ) exit or b ) assume function handles it ? <nl> schema utils fixme : merge this schemautils with the schemautils from pinot-common when merging of modules happens <nl> extracts the source fields and destination fields from the schema for field specs with a transform expression defined , use the arguments provided to the function by default , add the field spec name todo : for now , we assume that arguments to transform function are in the source i.e . there 's no columns which are derived from transformed columns <nl> validates that for a field spec with transform function , the source column name and destination column name are exclusive i.e . do not allow using source column name for destination column <nl> validates the following : 0 ) for a field spec with transform function , the source column name and destination column name are exclusive i.e . do not allow using source column name for destination column 0 ) basic schema validations <nl> output column used as input <nl> different incoming and","moving the expressionevaluators to pinot-core , so that it can be alongside the functionexpressionevaluators related code . <nl> also moved schemafieldextractorutils to pinot-core , and renamed it to schemautils . this schemautils ( which contains validate ) and the schemautils in pinot-common ( which contains from/to znrecord ) , should be merged into 0 eventually . can be done when pinot-core and pinot-common modules get merged .",1588023058,"- create a new package com.linkedin.pinot.core.realtime.stream in pinot-core . <nl> - move kafkastreammetadata to com.linkedin.pinot.core.realtime.stream , renaming it to streammetadata <nl> - get rid of ( unused ) streammetadata <nl> - move ( and rename ) classes to be kafka-agnostic ( which they are for most parts ) <nl> - add todo in a couple of places where classes are kafka-specific",0.9376073479652405
crate_crate/10522,add clusterblocktests back to es test suite,"this ports back some elasticsearch testcases , which worked out of the box . it is taken from the state of elasticsearch . see commits for details .",1599820431,"cherry-pick of sha have failed : . <nl> to fixup this pull request , you can check out it locally .",0.8537606596946716
apache_pulsar/8816,implement the packages management administration opeartions . <nl> motivation . <nl> introduce the pulsar admin operations with packages management service . <nl> modifications . <nl> - add the admin api for packages management service . <nl> this is only have client-side code . will add integration tests when <nl> server-side code is merged . <para-sep> administration operations of the packages management service . <nl> get a package metadata information . <nl> get a package metadata information asynchronously . <nl> update a package metadata information . <nl> update a package metadata information asynchronously . <nl> upload a package to the package management service . <nl> upload a package to the package management service asynchronously . <nl> download a package from the package management service . <nl> download a package from the package management service asynchronously . <nl> delete the specified package . <nl> delete the specified package asynchronously . <nl> list all the versions of a package . <nl> list all the versions of a package asynchronously . <nl> list all the packages with the given type in a namespace . <nl> list all the packages with the given type in a namespace asynchronously . <nl> the implementation of the packages management service administration operations .,motivation . <nl> introduce the pulsar admin operations with packages management service . <nl> modifications . <nl> - add the admin api for packages management service . <nl> this only has client-side code . will add integration tests when <nl> server-side code is merged .,1606996903,"this reader reads message from the pulsar topic in the same format <nl> that they are stored in persistent storage . <nl> this is a requirement for topic compaction , as the compactor will need <nl> to be able to read from a topic and store the read messaging somewhere <nl> else in a format that can then be easily read back by the broker . if <nl> the compactor were to decrypt , decompress and decode the messages , it <nl> would complicate things on the client side , as it would then need to <nl> have access to",0.9777324199676514
ballerina-platform_ballerina-lang/26339,"implement namedworkerdeclarationnode for new formatter <cm-sep> implement basics of arraytypedescriptornode in new formatting tree modifier <cm-sep> fix arraytypedescriptornode formatting issue <cm-sep> implement xml element , xml start tag , and xml end tag in new formatting tree modifier <cm-sep> fix method re-declaration error in new formatting tree modifier <cm-sep> implement xmlattribute and xmlattributevalue methods in newformattingtreemodifier",- namedworkerdeclarationnode <nl> - arraytypedescriptornode <nl> - xmlelementnode <nl> - xmlstarttagnode <nl> - xmlendtagnode <nl> - xmltypedescriptornode <nl> - xmlattributenode <nl> - xmlattributevalue .,1602621529,( dot ) . <nl> as expression ending character in the presence of child nodes . <nl> > update template parser logic to handle .,0.9132094383239746
apache_incubator-pinot/5922,"add max qps bucket count <para-sep> a stateful version of hit counter . similar to the default hit counter , it maintains a list of buckets . whereas it maintains an extra variable called _lastaccesstimestamp which tracks the last access time . if the stateful hit counter gets queried , it firstly compares the current timestamp and the last access timestamp , calculating the start index and end index among the buckets . then , it traverses through all the valid candidate buckets . if the current timestamp has exceeded the current time range of all the buckets , this hit counter will use the current timestamp minus the default time queried time range to calculate the start time index . <nl> get the maximum count among the buckets <nl> update the last access timestamp if the hit counter did n't get queried for more than _maxtimerangems . <nl> skipping the end index here as its bucket has n't fully gathered all the hits yet . <nl> update the last access timestamp <nl> 0 seconds have passed , the hit counter should return 0 as well since the count in the last bucket could increase . <nl> this time it should return 0 as the internal lastaccesstimestamp has already been updated and there is no more hits between the gap . <nl> increment the hit in this second and we should see the result becomes 0 . <nl> more than a time range period has passed and the hit counter should return 0 as there is no hits . <nl> similar to addcallbackgauge method . this method may be called multiple times , while it will be registered to callback function only once .","in some monitoring system , metrics are emitted in some certain frequency , e.g . every 0 minute . so if there is a burst of qps hitting to the cluster , there is no way to reflect on the metrics . <nl> this pr introduces a counter to get the maximum counts among all the seconds within a minute , so that we always know the real circumstances of the cluster .",1598394565,"in installations where each server may host 1000s of tabls , and 10s of <nl> thousands of segments , it is useful in practice to declare a server <nl> as started when ' most ' segments of ' most ' of the tables are ready ( i.e . <nl> externalview and idealstate match , as do currentstate and idealstate ) . <nl> this pr makes an attempt at defining ' most ' ( on an experimental basis ) . <nl> for now , we disregard the number of ( helix ) partitions within each resource . <nl> instead , we",0.9749823808670044
Alluxio_alluxio/11194,"try register with worker node hostname <cm-sep> do the translation <cm-sep> change to worker_node_hostname <cm-sep> getoutstream translation <para-sep> : if the worker is in a container , use the container hostname to establish the connection .","this removes the need of hostnetwork in k8s environment . the worker still registers with master using the node ip ( this can be retrieved using k8s downward api , no need for hostnetwork ) . but the client now finds the worker using container virtual ip . <nl> in this way , locality-aware scheduling is preserved ( by workers using node ip ) , but the client side can find the worker using its virtual ip . the need for escalated network access like and are removed .",1584684083,"failure to close resources that has grpc channels will cause abrupt channel termination , thus annoying exception in the master logs .",0.9146992564201355
apache_flink/14777,delete temporary jars <para-sep> ignore jar files which throw an error upon creating a packagedprogram,modifies the jar ( run|plan ) handler to call once we are done with the job submission / plan generation . <nl> this is not covered by tests ; i do n't see a good way to do that since from the outside it is neither obvious which files are supposed to ( not ) exist nor where the temporary files would be located ( by virtue of packagedprogram not respecting the option ) .,1611749913,"this pr removes , as should be used for creating temporary folders during tests . <nl> as such all usages were replaced with . <nl> this change is already covered by existing tests .",0.9255937337875366
runelite_runelite/11710,add teleport icons for arceuus portals,adds all the portal icons for the arceuus spellbook portals when in poh .,1590552346,new teleport icons now show inside player owned houses which have the portals .,0.885499894618988
elastic_elasticsearch/71292,adapted logic from cidrutils to create a new class for cidr processing . <cm-sep> use future array <para-sep> the intent of this class is to provide a more efficient way of matching multiple ip addresses against a single cidr . the logic comes from cidrutils .,adapted logic from cidrutils to create a new class for cidr processing .,1617641547,adapted logic from cidrutils to create a new class for cidr processing .,0.9997216463088989
apache_druid/10353,ignore cves from htrace and ambari transitive deps . <nl> htrace cves are suppressed for now as addressing them requires updating <nl> the hadoop version . <nl> ambari cves are suppressed for now since ambari is updated to the latest <nl> version and is no longer actively maintained .,"htrace cves are suppressed for now as addressing them requires updating the hadoop version . <nl> ambari cves are suppressed for now since ambari is updated to the latest version and is no longer actively maintained . <nl> after these suppressions , the security scan passes",1599177088,"use case - <nl> in active directory environment , spnego token in the authorization header includes pac ( privilege access certificate ) information , which includes all security groups the user belongs to which in this case is the header to grow beyond 0 kb what druid can handle by default . <nl> changes - <nl> this patch adds new configuration and allows user to configure the max header size for druid jetty server . default value is 0 kb which is same as jetty default .",0.9383031725883484
elastic_elasticsearch/72085,make slm tasks use infinite timeout for master requests . <nl> no point in failing slm tasks on slow masters . using 30s timeouts <nl> likely leads to many needless slm run failures when master is busy <nl> temporarily which is less than ideal especially when snapshot <nl> or retention task frequencies are low . <para-sep> do n't time out on this request to not produce failed slm runs in case of a temporarily slow master node <nl> do n't time out on this request to not produce failed slm runs in case of a temporarily slow master node <nl> do n't time out on this request to not produce failed slm runs in case of a temporarily slow master node,no point in failing slm tasks on slow masters . using 30s timeouts <nl> likely leads to many needless slm task failures when master is busy <nl> temporarily which is less than ideal especially when snapshot <nl> or retention task frequencies are low .,1619094205,"we have been using a zero timeout in the case that df analytics <nl> is stopped . this may cause a timeout when we cancel , for example , <nl> the reindex task . <nl> this commit fixes this by using the default timeout instead .",0.8559408187866211
apache_flink/14793,fix fields visibility in keygrouppartitioner <para-sep> this represents the result of key-group partitioning . * / <nl> key group range . / <nl> partitioningresultimpl } . <nl> test with 0 key-groups .,"in order to implement an iterator for a unified savepoint we need a way <nl> to iterate over all entries in a priority queue snapshot . <nl> added tests in . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no /",1611827171,"with unaligned checkpoints enabled , channel state is written to the file system . if the underlying state handle is shared between multiple handles , they should report their size according to offsets . <nl> currently , each handle reports the size of the underlying handle , therefore multiplying total state size in reports . <nl> this pr stores state size explicitly in each handle . <nl> this change added tests and can be verified as follows : added . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api ,",0.9692690968513489
apache_shardingsphere/9176,fix issue 0 <cm-sep> fix 0 <cm-sep> fix backend schema null <para-sep> get backend mysql datasource .,changes proposed in this pull request : <nl> - mysql default version from version to version <nl> - catch exception in jdbcqueryresultmetadata issigned method . <nl> - modify backenddatatype in textprotocolbackendhandlerfactory .,1611668821,changes proposed in this pull request : <nl> - fix sql parser test case <nl> - simplify sql parser test frame <nl> - check createtablestatement <nl> - fix constraintdefinition assert,0.9517815709114075
grpc_grpc-java/7445,"sync envoy proto to commit sha ( 0-0-0 ) . <para-sep> todo ( sanjaypujare ) : eliminate usage of listening_addresses field . <nl> todo ( sanjaypujare ) : eliminate usage of listening_addresses . <nl> common configuration for all consistent hashing load balancers ( maglevlb , ringhashlb , etc . ) indicates that prefix/path matching should be case sensitive . the default <nl> custom configuration that depends on the access log being instantiated . built-in configurations include : [ # next-free-field : 0 ] <nl> metadata filter <nl> runtime key to get an optional overridden numerator for use in the percent_sampled field . if found in runtime , this value will replace the default numerator . the default sampling percentage . if not specified , defaults to 0 % with denominator of 0. : ref : being present . if : ref : is present , the filter will consistently sample across multiple hosts based on the runtime key value and the value extracted from : ref : . if it is missing , or use_independent_randomness is set to true , the filter will randomly sample based on the runtime key value alone . use_independent_randomness can be used for logging kill switches within complex nested : ref : blocks that are easier to reason about from a probability perspective ( i.e. , setting to true will cause the filter to behave like an independent random variable when composed within logical operator filters ) . only requests with a header which matches the specified headermatcher will pass the filter check . in the access log formatter : ref : . only responses with the any of the flags listed in this field will be logged . this field is optional . if it is not specified , then any response flag will pass the filter check . filters grpc requests based on their response status . if a grpc status is not provided , the filter will infer the status from the http status code . if included and set to true , the filter will instead block all responses with a grpc status or inferred grpc status enumerated in statuses , and allow all other responses . filters based on matching dynamic metadata . if the matcher path and key correspond to an existing key in dynamic metadata , the request is logged only if the matcher value is equal to",internal envoy import cl : cl/0 .,1600728458,"in grpc-android , they are used for supporting legacy sdk connectivity state monitoring ( and its unit tests ) . they work as intended for legacy sdk versions . so we suppress those warnings for the target sdk version 0 .",1.0
elastic_elasticsearch/71392,"introduce separate shard limit for frozen shards . <nl> frozen indices ( partial searchable snapshots ) require less heap per <nl> shard and the limit can therefore be raised for those . we pick 0 <nl> frozen shards per frozen data node , since we think 0 is reasonable <nl> to use in production .","frozen indices ( partial searchable snapshots ) require less heap per <nl> shard and the limit can therefore be raised for those . we pick 0 <nl> frozen shards per frozen data node , since we think 0 is reasonable <nl> to use in production .",1617790604,fixed storage autoscaling to also calculate a capacity in the case where <nl> the policy governs no nodes currently ( 0-0 case ) .,0.9824511408805847
ballerina-platform_ballerina-lang/26718,"update signature help parameter detection by range <para-sep> rest arg type sometimes appear as array [ ] , sometimes not eg . 'error ( ) ' <nl> logic goes here <nl> logic goes here <nl> logic goes here <nl> logic goes here <nl> logic goes here <nl> logic goes here <nl> logic goes here <nl> logic goes here","this lead us to a point where we can not specifically identify the parameters without the names ( for the function type descriptors ) . with this change , instead of relying on the sub-strings in the signature label to identify the parameter range to underline , we moved to the start and end positions .",1604402702,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.946539044380188
apache_flink/14987,"extract checkpointsubsumehelper . <nl> this is a pre-requisite refactoring for a subsequent bug fix . <cm-sep> do n't subsume last checkpoint . <nl> when a savepoint is added to completedcheckpointstore <nl> all previous checkpoints will be removed if number to <nl> retain is 0 . <nl> this makes future incremental checkpoints invalid since <nl> they can refer to the discarded state . <cm-sep> remove mock from testaddcheckpointwithfailedremove . <nl> additionally , remove dead code and check that an <nl> exception was thrown . <para-sep> should fail despite the exception <nl> tests that the checkpoint does not exist in the store when we fail to add it into the store ( i.e. , there exists an exception thrown by the method ) . <nl> should n't fail despite the exception","added unit tests for the ( , , , ) . <nl> i test and not the to verify their integration . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos , zookeeper : yes <nl> - the s3 file system",1614005836,"instead of failing the executiongraph with a generic timeoutexception if a slot request times out , <nl> this commit changes the exception to a more meaningful noresourceavailableexception . <nl> - added and tested it manually . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or",0.9062818288803101
apache_druid/10614,"cache expression selector results by associating vector expression bindings to underlying vector offset <para-sep> returns an integer that uniquely identifies the current position of the underlying vector offset , if this binding is backed by a segment . this is useful for caching : it is safe to assume nothing has changed in the offset so long as the id remains the same . see also : readablevectoroffset ( in druid-processing ) <nl> never cache , this is just for tests anyway <nl> vector inspector that can supply a unique identifier of the vector to use with caching in addition to sizing information <nl> a marker value that will never be returned by ' getid ' . <nl> returns an integer that uniquely identifies the current vector . this is useful for caching : it is safe to assume nothing has changed in the vector so long as the id remains the same . <nl> special case to test floats just to get coverage on getfloatvector","while i have n't measured this at all , it makes a relatively big difference when just because the previous behavior meant that the expression was evaluated twice for numeric primitive expressions : once to get the value vector and again to get the null vector . i was aware of this issue but did n't get to it in the first round of additions i did for the vectorized expression stuffs and sort of forgot about it until now 😅 . <nl> it works by expanding to further mimic : . <nl> which allows slightly modifying the backing of",1606528316,"document unsupported join on multi-value column . <nl> moreover , we should fail query that tries to join on multi-value column rather than silently ignoring multi-valued column and returning results back to user . this is because user may not be aware that druid actually do not support join on multi-value column and thinking that the result is because nothing match join condition",0.9674545526504517
Graylog2_graylog2-server/9832,add usesearchconfiguration custom hook <cm-sep> add configuredrelativetimerangeselector . <nl> - the base is the replaced relativetimerangeselector <nl> - refactored and updated to use usesearchconfiguration hook <nl> - onchange passe new value to parent ( relativetimerangeselector ) <cm-sep> use configuredrelativetimerangeselector . <nl> - display configured time range <nl> - extract fromvalue to a function <cm-sep> update snapshoot <para-sep> the ' search in all messages ' option should be the last one .,these changes add back and adapt the admin configured relative time range selector to the search time range selector . it allows users to select an existing time range instead of entering it manually .,1608274376,this would lead to errors in the addeventindexsetsmigration .,0.815784215927124
neo4j_neo4j/11349,"improve semanticindexacceptancetest with better error message <cm-sep> fix bug in datetime . <nl> fix bug that two datetimes with same localtime and offset but different <nl> time zone were equal . <para-sep> after a failure , do this to reproduce with the actual values that caused the error : place a single call to testoperator after the for-loop . as an example { { { testoperator ( ' = ' , valuesetup ( ' datetimes ' , gen.oneof ( seq ( datetimevalue.parse ( ' 0-0-13t20:0:52z ' , null ) , datetimevalue.parse ( ' 0-0-13t20:0:52z [ europe/brussels ] ' , null ) ) ) , x = > x.sub ( oneday ) , x = > x.add ( oneday ) ) ) } } }",fix bug that two datetimes with same localtime and offset but different <nl> time zone were equal . <nl> remember to unmute test in teamcity . see trello card,1521724235,"there is no need to directly convert string values coming from <nl> bolt to directly , we can preserve it as a <nl> until we actually need the value . currently <nl> this will not give much in performance except for queries like <nl> , since most string operations currently <nl> requires an actual string instance . however going forward we can <nl> be smarter about preserving the .",0.9242028594017029
Alluxio_alluxio/12181,"migrate state machine to ratis . <nl> initial changes for hooking up embedded journal state machine with ratis <nl> api . implemented leader election , journal application and taking <nl> snapshot on followers . <cm-sep> remove the catalyst dependencies in backup transport . <cm-sep> move copycat dependency to catalyst . <nl> remove the copycat dependency and change it to a much smaller catalyst <nl> dependency . <nl> catalyst dependency is needed for grpc messaging serialization and <nl> deserialization . <cm-sep> implement snapshot replication for embedded journal . <nl> this change implements snapshot replication workflows for embedded <nl> journal : . <nl> - when a raft leader needs a snapshot , instead of taking snapshot <nl> locally it copies a recent snapshot from one of the followers . <nl> - when a raft follower receives a notification to download a snapshot , <nl> it downloads the latest snapshot from the leader . <cm-sep> avoid taking snapshot during journal suspension . <nl> when journal is suspended , snapshot should not be taken because some <nl> entries included up to the snapshot index might not have been applied by <nl> the suspended journal applier . <cm-sep> enable new master to join an existing quorum . <nl> this change implements the quorum join process for new master . <nl> ratis provides an api for update quorum member list . to implement an <nl> automatic join comparable with what we did with copycat , the new master <nl> will send a join request to the quorum leader after it initialized the <nl> journal . the leader will atomically convert the request to a raft <nl> configuration change and apply it to the quorum . <nl> this operation is a noop for a master that is already in the quorum . <cm-sep> before solving conflicts <cm-sep> solve conflicts <cm-sep> merge master into ratis-journal <cm-sep> make polling client timeout properly on unresponsive masters . <nl> added a deadline for master ping requests . <cm-sep> make master try harder when joininig a quorum . <nl> sometimes a master attempts to join a quorum during leader election . <nl> this change extends the retry period so the retry can extends pass an <nl> election . also lower the log severity given its best effort nature . <cm-sep> make it more restrictive when a snapshot can be taken . <nl> sometimes a snapshot is ordered when the journal log is",this pr contains the following changes that implement a raft based journal system and snapshot management using ratis framework : . <nl> - updated embedded journal state machine to use ratis framework <nl> - removed dependency on copycat <nl> - implemented a snapshot management system that periodically takes snapshots of master metadata on secondary masters and replicates them to the primary master <nl> - added proper timeouts when clients and workers attempt to ping masters,1601941229,,0.0
gocd_gocd/8441,add package and scm related details in the internal api - no need for the page to fetch these details separately <cm-sep> update material spa related models <cm-sep> remove the call to get all package and scms . <nl> - instead use the info from the internal materials call itself <nl> - do n't show the link to scm/package if user is neither admin nor group admin,description : <nl> currently the materials spa makes a call to fetch all packages and scms available . but this api is available only to admins/group admins . this caused the page to not render . <nl> added the required info in the internal materials api and utilized the same .,1597056864,description : <nl> - allow users with permission to perform crud on elastic agent profiles <nl> - fix elastic profiles usage api <nl> - always enable 'add elastic profiles ' button for a user <nl> - show errors on the elastic agent profiles wizard step <nl> - show errors on the elastic agent profiles modal <nl> - fix ui alignment on the roles page,0.8136312961578369
vespa-engine_vespa/15934,"remove unused variable <cm-sep> read target major version once <cm-sep> make field final <cm-sep> remove unused method <cm-sep> remove unused imports <cm-sep> make fields final <cm-sep> remove unused testers <para-sep> for each job id ( path ) , store the zk node version and its deserialised data - update when version changes .",minor cleanup done while reading some code .,1609943399,test and staging nodes are recycled very often and rebooting each time <nl> cuts the test throughput in half .,0.9229761958122253
vespa-engine_vespa/15209,us locale <cm-sep> add debug logging,"autoscale decisions are hard to debug when no autoscale happens - is it running , why does it not autoscale ? i suggest we add debug logging for now . <nl> should maybe add a 'reason ' enum to advice and log on outside of autoscale instead ?",1604660252,"0 - if another thread is already in progress dumping threads just make a note of it and continue . <nl> 0 - if another thread has already started shuttdown process , just make a note of it .",0.8750031590461731
elastic_elasticsearch/71900,"as we started thinking about applying on_script_error to runtime fields , to handle script errors at search time , we would like to use the same parameter that was recently introduced for indexed fields . we decided that continue or fail gives a better indication of the behaviour compared to the current ignore or reject which is too specific to indexing documents . <nl> this commit applies such rename .","as we started thinking about applying on_script_error to runtime fields , to handle script errors at search time , we would like to use the same parameter that was recently introduced for indexed fields . we decided that continue or fail gives a better indication of the behaviour compared to the current ignore or reject which is too specific to indexing documents . <nl> this commit applies such rename .",1618906781,this api incorrectly had set to false in the default options for the <nl> request . this changes it from to and enhances a test to exercise the functionality .,0.9028245806694031
elastic_elasticsearch/71967,"this commit adds a default cache size to frozen tier of the greater of <nl> 0 % and total disk size minus 0 gb . <para-sep> a 0 gb disk will result in a shared cache sized at 0 gb . 0 % of 0 gb <nl> a 0 gb disk will result in a shard cache sized at 0 gb . <nl> check if the settings are for a dedicated frozen node , i.e . has frozen role and no other data roles . <nl> returns whether or not the node is a frozen only node , i.e. , has data frozen role and no other data roles . <nl> ignore",this commit adds a default cache size to frozen tier of the greater of <nl> 0 % and total disk size minus 0 gb .,1618937786,"* use mapping source directly instead of using mapper service to extract the relevant mapping details <nl> * moved assertion to timestampfield class and added helper method for tests <nl> * improved logic that inserts timestamp field mapping into an mapping . <nl> if the timestamp field path consisted out of object fields and <nl> if the final mapping did not contain the parent field then an error <nl> occurred , because the prior logic assumed that the object field existed .",0.9595712423324585
quarkusio_quarkus/14817,"test that warnings are logged for unaffected jpa entities . <cm-sep> add a test module to hibernate-reactive-deployment . <cm-sep> use transactions in hibernate reactive ' unit ' tests . <cm-sep> disable stage ' unit ' test for hibernate reactive . <cm-sep> disable jta in hibernate reactive persistence units . <cm-sep> test that jta is disabled for hibernate reactive persistence units . <cm-sep> disable jdbc connections completely in hibernate reactive persistence units . <nl> i think they were exposed accidentally ? anyway , in current tests we <nl> do n't have any jdbc connection available because we simply do n't have a <nl> jdbc datasource , and we ultimately end up with unclear errors . <nl> let 's revisit this later if we decide to actually provide a jdbc driver <nl> to hibernate reactive in some cases . <para-sep> expect a warning on startup <nl> when having no entities , we should still be able to start the application . <nl> two assertions are necessary , because these values are influenced by separate configuration <nl> quick test to make sure hrx works","because hibernate reactive only supports resource-local transactions . <nl> the first few commits just add basic unit tests to . <nl> next we actually disable jta and test it . <nl> the final commit is somewhat unrelated to jta , but it has the same purpose as disabling jta : making error messages clearer when something wrong happens . not great , but imo better .",1612435387,"please do n't merge it , i will merge it myself .",0.9749892950057983
jenkinsci_jenkins/4762,moved test class closer to class and added a test,"this is just a minor refactoring of tests . i moved a testclass from core to cli , because the class under test is in cli package . i converted the testclass to junit5 and added a small test . this allows a better view on the coverage of the cli project . <nl> * n/a : internal",1590916081,"* fix the diskmonitorspacedescriptor tostring ( ) message . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8807360529899597
elastic_elasticsearch/70916,"support fetching flattened subfields . <nl> currently the api fetches the root flattened field and returns it in a <nl> structured way in the response . in addition this change makes it possible to <nl> directly query subfields . however , requesting flattened subfields via wildcard <nl> patterns is not possible . <para-sep> testresponse [ s/ ' took ' : 0/ ' took ' : $ body.took/ ] testresponse [ s/ ' max_score ' : version/ ' max_score ' : $ body.hits.max_score/ ] testresponse [ s/ ' _score ' : version/ ' _score ' : $ body.hits.hits.0._score/ ] <nl> requesting via wildcard should retrieve the root field as a structured map <nl> direct retrieval of subfield is possible <nl> direct retrieval of root field and subfield is possible <nl> retrieval of subfield with wildcard is not possible <nl> retrieval of non-existing subfield returns empty result","currently the api fetches the root flattened field and returns it in a <nl> structured way in the response . in addition this change makes it possible to <nl> directly query subfields . however , requesting flattened subfields via wildcard <nl> patterns is not possible .",1616766855,limit the creation of data streams only for namespaces that have a composable template with a data stream definition . <nl> this way we ensure that mappings/settings have been specified and will be used at data stream creation and data stream rollover .,0.9714174866676331
vespa-engine_vespa/16168,"support delegating content node suspension to cluster controller . <nl> this pr introduces a new flag group-suspension , which if true , enables : <nl> - instead of allowing at most one storagenode to suspend at any given time , it <nl> will now ignore storagenode , searchnode , and distributor service clusters , <nl> and rely on the cluster controller to allow or deny the request to suspend . <nl> this will increase the load on the cluster controllers . <nl> combined with earlier changes to the cluster controller , this new flag <nl> effectively guard the feature of allowing all nodes within a hierarchical group <nl> to suspend concurrently . <nl> i also took the opportunity to tune related policies : . <nl> - allow at most one config server and controller to be down at any given time . <nl> this is actually a no-op , since it was effectivelly equal to the older <nl> policy of 0 % down . <nl> - allows 0 % of all host-admins to be down , not just tenant host-admins . this <nl> is effectively equal to the old policy of 0 % except that it may allow 0 <nl> proxy host-admins to go down at the same time . should be fine .","this pr introduces a new flag group-suspension , which if true , enables : <nl> - instead of allowing at most one storagenode to suspend at any given time , it <nl> will now ignore storagenode , searchnode , and distributor service clusters , <nl> and rely on the cluster controller to allow or deny the request to suspend . <nl> this will increase the load on the cluster controllers . <nl> combined with earlier changes to the cluster controller , this new flag <nl> effectively guard the feature of allowing all nodes within a hierarchical group <nl> to suspend",1611327288,"docker hosts are not resolvable when they are provisioned , so <nl> we make ip resolution a part of the transition to ready . <nl> note the folling consequences of this : <nl> - only active proxy nodes will be allowed access <nl> - nodes in ' provisioned ' will receive an empty json map as response if asking for their acl .",0.9627629518508911
Graylog2_graylog2-server/9852,"retry read timeouts for elasticsearch . <nl> before this change , the retry strategy used for es requests did not <nl> retry for instances of , raised in case of read <nl> timeouts . this resulted in exceptions being raised when individual nodes <nl> were not responding and node discovery was not used . this was e.g . being <nl> noticable when performing searches and 0 of 0 nodes was failing , so <nl> every 3rd search request was timing out and returning an error instead <nl> of being retried and successful and just taking longer . <nl> this change is adding this class to the exceptions being retried , so any <nl> request that goes out to a node which is not responding on time is <nl> retried .","before this change , the retry strategy used for es requests did not retry for instances of , raised in case of read timeouts . this resulted in exceptions being raised when individual nodes were not responding and node discovery was not used . this was e.g . being noticable when performing searches and 0 of 0 nodes was failing , so every 3rd search request was timing out and returning an error instead of being retried and successful and just taking longer . <nl> this change is adding this class to the exceptions being retried , so any request",1609246129,returns an empty string if none found .,0.9089917540550232
apache_pulsar/9828,support get applied blacklogquota <para-sep> get applied backlog quota map for a topic .,add applied api and fix default value in unit test <nl> # # # verifying this change <nl> verify the applied api and cmd <nl> verify the default value in namespace-level,1615085848,# # # motivation . <nl> the functionauthprovider is an interface responsible for distributing authentication data to functions . currently the implementation used is hard coded and not pluggable . <nl> make functionauthprovider pluggable so uses can choose implementations .,0.9444723129272461
Graylog2_graylog2-server/9759,"silence log messages <cm-sep> send to pulsar in batches . <nl> use sendasync ( ) instead of send ( ) . <nl> sending each message synchronously has obviously a huge performance impact . <nl> instead of ~0 msg/s we can now produce ~50k msg/s <para-sep> temp files should automatically be deleted on exit of the jvm <nl> if the resource is located inside a jar file , we need to write it to a temporary file to make it accessible in the file system . ( e.g . to mount it into a docker container ) <nl> we need to define the theme interface here and ca n't use relative paths , because otherwise the paths do not get resolved properly when importing core components which are using the theme , in plugins . <nl> eslint-disable-next-line import/order <nl> forward declarations <nl> tslint : disable-next-line : no-empty-interface <nl> any prop that has a default prop becomes optional , but its type is unchanged undeclared default props are augmented into the resulting allowable attributes if declared props have indexed properties , ignore default props entirely as keyof gets widened wrap in an outer-level conditional type to allow distribution over props that are unions <nl> the component from whose props are derived <nl> the theme from the current context <nl> the other props added by the template <nl> the props that are made optional by .attrs <nl> distribute o if o is a union type <nl> because of react typing quirks , when getting props from a react.componentclass , we need to manually add a field . <nl> remove the call signature from styledcomponent so interpolation can still infer interpolationfunction <nl> abuse pick to strip the call signature from forwardrefexoticcomponent <nl> config to be used with withconfig <nl> todo : add all types from the original styledcomponentwrapperproperties <nl> extracts react defaultprops <nl> any does n't count as assignable to never in the extends clause , and we default a to never <nl> i really want to avoid this if possible but it 's the only way to use nesting with object styles ... <nl> add our own fake call signature to implement the polymorphic 'as ' prop <nl> fun thing : 'attrs ' can also provide a polymorphic 'as ' prop my head already hurts enough so maybe later ... <nl> unfortunately using a conditional type to validate that it can receive a",use instead of . <nl> sending each message synchronously has obviously a huge performance impact . <nl> instead of ~0 msg/s we can now produce ~50k msg/s,1607600969,"this change is now throwing a instead of a generic <nl> again , when search requests try to aggregate on <nl> a non-numeric field . this allows us to retry getting non-numeric <nl> statistics or show a more accurate error message when trying to generate <nl> charts .",0.9351592063903809
ballerina-platform_ballerina-lang/25186,"add wrapper class for non-blocking payload build <cm-sep> refactor mimedatasourcebuilder <cm-sep> set input stream for getbytechannel ( ) at http level <cm-sep> write mime header functions in ballerina <cm-sep> add header handler class and refactor utils <cm-sep> remove transport dependency from mime <cm-sep> move entity header class to http module <cm-sep> add header extern function to req/resp <cm-sep> fix test cases <para-sep> non-blocking payload retrieval common external functions <nl> gets the from the request without the body and headers . this function is exposed only to be used internally . <nl> gets the from the request with the body , but without headers . this function is used for http level functions . <nl> http header related external functions <nl> gets the from the response without the entity body . this function is exposed only to be used internally . <nl> gets the from the response with the body , but without headers . this function is used for http level functions . <nl> http header related external functions","> the ballerina-mime module has a direct dependency on transport code as it manipulates the entity body and the headers . <nl> since the ballerina-http module also has a dependency with the ballerina-mime module , if we take the transport code into the http module , that will induce cyclic dependency . <nl> > if an entity needs the same apis for header manipulation , a ballerina map is be maintained and provided the same methods written in ballerina in mime module . <nl> > as per spec headers are case insensitive , but ballerina does n't . hence header",1597039619,this pr is to support passing custom headers with grpc message and handle in both client and server side . following changes are done to support custom headers . following will be supported from this fix . <nl> server side header support <nl> ` . <nl> client side header support <nl> `,0.988065242767334
Alluxio_alluxio/12047,"azure datalake gen1 support <cm-sep> add file permission override <para-sep> table of contents <nl> constant for the adl uri scheme . * / <nl> constant for the adls uri scheme . * / <nl> prepares the configuration for this adl as an hdfs configuration . <nl> adl is an object store , so use the default block size , like other object stores . <nl> adl is backed by an object store but always claims its block size to be 512mb . reset the block size in ufsfilestatus according to getblocksizebyte <nl> no op <nl> no op <nl> not supported <nl> not supported",adds adl gen1 ufs extension as a hdfs extension .,1598641776,added apis for intercepting grpc client and server with custom data serialization/deserialization . <nl> also made the worker send read response asynchronously to improve throughput for single read request .,0.9870606064796448
jenkinsci_jenkins/4653,"fix git not in path for git plugin global config <nl> git client plugin global configuration allows addition of git implementations using gittool <nl> the field path was not able to identify git executable . the fix involves changing prefix with <nl> file.seperator instead of file.pathseperator . this allows jenkins to find the git exec at the <nl> already existing path . <cm-sep> tests added to validate fix <para-sep> global tool configuration is able to find git executable in system environment at path . <nl> without fix , git installations under global tool configuration is not able to find git executable at system path despite git exec existing at the path .",bugfix : a fix in to allow the user to define git implementations which are then used as tools . <nl> proposed changelog entries : . <nl> * fix input field hints for tools that search the path for their executable ( like the git plugin ) ( regression in version and version ) . <nl> issue introduced in sha as part of a refactoring effort,1586888262,"apparently java 0 ( and later ) do not count windows junctions as <nl> symlinks . when you drill down into the basicfileattributes structure , <nl> reparse points are only counted under isother . so , since we already <nl> have code that properly detects windows junctions , let 's use that first <nl> and then fallback to the java 0 code .",0.9409148693084717
vespa-engine_vespa/15369,"introduce node ip address pool . <nl> a host that is supposed to run containers has a non-empty ip pool : a set of <nl> ipv4 and/or ipv6 addresses that can be assigned to containers . <nl> this pr adds a list of hostnames to this pool . the intent is that the <nl> hostnames and ips match through resolving , but resolution may not yet be <nl> available ( until dns changes propagate ) . <nl> for now , only a list of hostnames are specified . we may want to specify <nl> ( hostname , ip address ) pairs or ( hostname , ipv4 , ipv6 ) triplets later , and the <nl> serialization format allows for that by storing the hsotnames in an array of <nl> objects , the object having a ' hostname ' field . <nl> however the rest api is kept simpler for now : it exposes and allows patching of <nl> an array of strings of a ' additionalhostnames ' field . <para-sep> address info about a container that might run on a host . <nl> legacy test constructor - use of ( ) variants and/or the with- methods . * / <nl> do not use : public for nodeserializer . * / <nl> a pool of addresses from which an allocation can be made . <nl> creates an empty pool . * / <nl> create a new pool containing given ipaddresses * / <nl> when/if address becomes richer : add another field ( e.g . ' addresses ' ) and expand to array of objects <nl> test round-trip with address pool <nl> test round-trip without address pool ( handle empty pool )","a host that is supposed to run containers has a non-empty ip pool : a set of <nl> ipv4 and/or ipv6 addresses that can be assigned to containers . <nl> this pr adds a list of hostnames to this pool . the intent is that the <nl> hostnames and ips match through resolving , but resolution may not yet be <nl> available ( until dns changes propagate ) . <nl> for now , only a list of hostnames are specified . we may want to specify <nl> ( hostname , ip address ) pairs or ( hostname , ipv4 ,",1605621959,this may be different from assigned resources e.g in that requested <nl> resources may specify diskspeed.any while assigned resources <nl> always have a definite disk speed .,0.9801186323165894
apache_druid/10390,wip vectorize <cm-sep> close but not quite <para-sep> nothing to close . <nl> nothing to close . <nl> nothing to close . <nl> nothing to close .,vectorize the variance aggregators . calculating variance of rows in batches is ~ 0-4x faster than calculating the variance one value at a time . this is on top of the other benefits of reading values in batches . <nl> |benchmark| ( vectorsize ) |mode|cnt|score|error|units <nl> | -- | -- | -- | -- | -- | -- | -- | <nl> |variancebenchmark.collectvarianceinbatch|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceonebyone|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceinbatch|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceonebyone|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceinbatch|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceonebyone|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceinbatch|0|avgt|0|version|± version|ns/op| <nl> |variancebenchmark.collectvarianceonebyone|0|avgt|0|version|± version|ns/op|,1599980470,"when joining on index tables with string keys , caching the computation of row id to row numbers improves performance on the * benchmarks by about 0 % if the column cache is enabled an by about 0 % if the column cache is disabled",0.9746968150138855
apache_pulsar/8848,"add provided jclouds . <cm-sep> make broker-style gradually conform checkstyle . <cm-sep> make broker-style gradually conform checkstyle . <cm-sep> make broker-style gradually conform checkstyle . <cm-sep> make broker-style gradually conform checkstyle . <para-sep> map support missing <nl> it validates that peer-clusters ca n't coexist in replication-clusters . <nl> producer or it might have been deleted earlier , so we ignore the 0 error . for all other exception , we fail the delete partition method even if a single <nl> get the subscriptions only from the 1st partition since all the other partitions will have the same <nl> fail the operation on unknown exception or if all the partitioned failed due to <nl> since we ca n't read the message from the storage layer , it might be an already delete message id or an invalid message id <nl> get the topic object reference from the pulsar broker . <nl> get the subscription object reference from the topic reference . <nl> get the replicator object reference from the topic reference . it creates subscriptions for new partitions of existing partitioned-topics . <nl> skip partition of partitioned topic by making sure the numeric suffix greater than old partition number .",this pr contains code format changes only .,1607337362,"sha is the commit for review in this pr . <nl> - rename to , because this module is used by functions only to avoid protobuf conflicts <nl> - move protobuf3 references to utils , so it wo n't be referenced out side of pulsar-functions <nl> - integrate function cli into pulsar-admin cli <nl> sha",0.8782890439033508
Alluxio_alluxio/12123,add time series for throughput <para-sep> bytes read <nl> bytes written,add time series for read and write throughput,1600737956,"this fix the case when underlying blockinstream is actually shorter than expected . e.g. , the files are out of sync . in this case , this pr improves the client to throw an exception indicating the inconsistency . otherwise , the client is returning meaningless data .",0.836797833442688
grpc_grpc-java/7299,"introduce loadstatsmanager for managing stats for all clusters . <cm-sep> use loadstatsmanager as the source of getting stats for load reporting . <cm-sep> change the xdsclient api for initiating load reporting . <cm-sep> clean up <para-sep> generates a snapshot for load stats recorded in this counter for the interval between calls of this method . <nl> manages all stats for client side load . <nl> adds and retrieves the stats object for tracking loads for the given cluster : cluster_service . <nl> discards stats object used for tracking loads for the given cluster : cluster_service . <nl> a cluster may send loads to more than one cluster_service , they are included in separate stats reports . todo ( chengyuanzhang ) : do not use proto type directly . <nl> each report includes stats for one cluster : cluster_service . todo ( chengyuanzhang ) : do not use proto type directly . <nl> interface for client side load stats store . load stats for endpoints are aggregated in locality granularity while the numbers of dropped calls are aggregated in cluster : cluster_service granularity . <nl> generates a report based on recorded load stats ( including rpc counts , backend metrics and dropped calls ) for the interval since the previous call of this method . todo ( chengyuanzhang ) : do not use proto type directly . <nl> track load stats for endpoints in the provided locality . only load stats for endpoints in tracked localities will be included in generated load reports . <nl> drop tracking load stats for endpoints in the provided locality . load stats for endpoints in removed localities will no longer be included in future generated load reports after their currently recording stats have been fully reported . <nl> records a drop decision . this method is thread-safe . <nl> a reference count wrapper for objects . this class does not take the ownership for the object , but only provides usage counting . the real owner of the wrapped object is responsible for managing the lifecycle of the object . intended for a container class to keep track of lifecycle for elements it contains . this wrapper itself should never be returned to the consumers of the elements to avoid reference counts being leaked . <nl> starts client side load reporting via lrs . all clusters report load through one lrs stream , only the","mostly an extensive refactoring work , might be awful to review ( sorry about that 😢 ) . <nl> currently we are having an issue for xds routing : . <nl> for example , if we have two routes with each of them routing some rpcs to the same cluster , say clustera . our current architecture will create two identical cds policy instances for clustera ( as well as the whole lb subtree ) . then each of these two cds policies ' child eds policy will create its own stats object and pass it to the xdsclient for",1596776473,loadbalancers that call the old will get implicitly called with a listener that passes updates to the deprecated . those who call the new will have to call explicitly . <nl> this pr has 0 commits : <nl> 0. roll forward the original change . <nl> 0. revert grpclb back to the old api . see commit message for the reason . <nl> 0. the revision . <nl> nothing new is introduced in commits 0 and 0. reviewers should only need to review commit 0 .,0.9845052361488342
apache_shardingsphere/10006,' show processlist ' query <cm-sep> ' show processlist ' unit test <cm-sep> checkstyle <para-sep> show process list request event . <nl> show process list response event . <nl> load show process list data . <nl> get execution nodes path . <nl> get execution path . <nl> show process list executor . <nl> receive and handle response event . <nl> todo show original sql <nl> execute process context for yaml . <nl> execute process unit for yaml . <nl> mysql show process list statement .,"changes proposed in this pull request : <nl> - add show processlist statement , adjust mysqladminexecutorfactory <nl> - prepare registryrepository in proxycontext , add node path in registercenternode , for fetching data from register center <nl> - adjust executeprocesscontext for starttimemillis and add related model for yaml , adjust executiongroupcontext for executionid <nl> - add showprocesslistexecutor",1617955849,changes proposed in this pull request : <nl> - add orchestrationencryptdatasource <nl> - add yaml configuring method for orchestrationencryptdatasource,0.9874405860900879
Alluxio_alluxio/11750,fix object ufs edge case again,adding / to the keys was not a good idea .,1594412840,"i tried running hibench-spark with both and . neither worked because the prepare phases uses hadoop , while the run phase uses spark . using a comma breaks spark because it tries to split on the comma . using a semicolon breaks hadoop because it splits on semicolon . they both seem happy with though , so it 's nice if we could support it as a third option . <nl> if everyone is on board with supporting , i 'll update the docs in a followup pr",0.908240020275116
jenkinsci_jenkins/4918,"* replacing text references of slave with agent in japanese documentation and messages . <nl> * replacing text references of slave with agent in japanese documentation <cm-sep> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> run all tests <cm-sep> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <para-sep> if the build is pending delete . <nl> avoid concurrent delete . <nl> but all attempts to fix this have ended in disaster ( ) : <nl> todo merge into causetest after release <nl> for the build on agent <nl> for the build on master <nl> for the stored build <nl> just to trigger data-is-master-slave-enabled = true <nl> before the correction , if there was an agent and the build was not inheriting from abstractbuild , we got uncaught typeerror : can not read property 'escapehtml ' of undefined <nl> for the stored build <nl> with the correction , the last cell is just empty instead of throwing the typeerror <nl> escaped twice , once per new h.xmlescape then once per jelly . but as the tooltip lib interprets html , it 's fine , the tooltip displays the original values without interpreting them <nl> now it 's a regular title , but without the correction , the tooltip will be triggered <nl> title field is modified by yahoo tooltip , title attribute is set by the new code <nl> mac ( command + enter ) <nl> windows , linux ( ctrl + enter )","please have look at the changes proposed , so we have a consensus of what goes in . i suggest to backport all the candidates .",1598339740,- this occur when the securityrealm potentially already grants that role ( like in github-oauth-plugin ) .,0.9823582172393799
ballerina-platform_ballerina-lang/24953,fix statement starts with parenthesis <cm-sep> make func-call name a namereferencenode in the syntax tree,$ subject . used to be a generic ' node ' .,1595834992,- remove spaces from swagger operationids <nl> - improve swagger command error reporting <nl> - set default title when swagger title is missing <nl> - skip adding empty swagger annotation attributes,0.8958310484886169
apache_pulsar/9886,"make the broswer javascript websocket client support the token authentication . <para-sep> websocket httpservletrequest wrapper . <nl> the browser javascript websocket client could n't add the auth param to the request header , use the query param to transport the auth token for the browser javascript websocket client .","currently , the websocket client uses the http request header to transport the authentication params , but the browser javascript websocket client could n't add new headers . <nl> use the query param to transport the authentication token for the browser javascript websocket client . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl>",1615489190,"motivation . <nl> bytebuffer is a variant of . so it should be , not . <nl> changes . <nl> - fix bytebuffer schema type <nl> - add bytebuf schema",0.9412103891372681
apache_flink/15218,increase time out for the checkpointfailuremanageritcase <cm-sep> use classrule for miniclusterresource in the checkpointfailuremanageritcase,"the logs show that the cluster ( task managers ) can not start in time and the test fails occasionally . you can see in the logs that the job switches to running just before the test times out . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes",1615820560,"the recently added cachedthreadpool does not behave as expected . a comprehensive solution would take more time , so we use a fixed thread pool instead .",0.8584378957748413
apache_pulsar/9300,"add json annotation for the class . <cm-sep> fix <para-sep> test presto query from tiered storage . <nl> wait until presto worker started <nl> check presto follow workers start finish . <nl> test predicate pushdown <nl> for example : total size 0 , the right receive number is 0 , so 0 + 0 == 0 / 0 <nl> for example : total size 0 , the right receive number is 0 , so 0 == ( 0 - 0 ) / 0 <nl> try with a predicate that has a earlier time than any entry should return all rows <nl> try with a predicate that has a latter time than any entry should return no rows <nl> start workers that have been initialized <nl> used to query from tiered storage","0. the class could n't be serialized to json bytes array in pulsar sql . <nl> 0. the pulsarsplitmanager ca n't split data in the tiered storage . <nl> serialization error log . <nl> 0. add annotation for config fields . <nl> 0. set the right ledgeroffloader for the split manager to read data from tiered storage . <nl> 0. add a new to set new configs with a specific prefix to config files . <nl> this change can be verified as follows : . <nl> - org.apache.pulsar.tests.integration.presto.testprestoquerytieredstorage . <nl> if was chosen , please highlight the changes . <nl>",1611499573,"we do n't know if it is disabled or using broker-level configuration . <nl> the ttl of the namespace-level can be set to null , which means it does not exist . it is consistent with topic-level ttl .",0.969097375869751
Alluxio_alluxio/11966,fix jvmpausemonitortest # interruptonstop test . <nl> mockito was recently upgraded which includes a new feature that allows us to mock final methods and classes . i rewrote the test to be simpler using one of mockito 's spy classes .,mockito was recently upgraded which includes a new feature that allows us to mock final methods and classes . i rewrote the test to be simpler using one of mockito 's spy classes .,1597164276,changes the semantic of to return both the explicitly pinned inodes and inodes which are in state . inodes in that state should not be evicted or users can experience data loss .,0.8484361171722412
elastic_elasticsearch/71920,"this commit adds the necessary plumbing to expose this api <nl> in the high level rest client . <cm-sep> fix <para-sep> executes the cache stats api , which provides statistics about searchable snapshot cache . see the docs for more information . <nl> asynchronously executes the cache stats api , which provides statistics about searchable snapshot cache . <nl> tag : :searchable-snapshots-caches-stats-request <nl> end : :searchable-snapshots-caches-stats-request <nl> tag : :searchable-snapshots-caches-stats-execute <nl> end : :searchable-snapshots-caches-stats-execute <nl> tag : :searchable-snapshots-caches-stats-response <nl> end : :searchable-snapshots-caches-stats-response <nl> tag : :searchable-snapshots-caches-stats-execute-listener <nl> end : :searchable-snapshots-caches-stats-execute-listener <nl> tag : :searchable-snapshots-caches-stats-execute-async <nl> end : :searchable-snapshots-caches-stats-execute-async <nl> > >",this commit adds the necessary plumbing to expose this api <nl> in the high level rest client .,1618920754,this adds support for ' grant api key ' to the java high level rest <nl> client . <nl> this api was added in elasticsearch version but did not have explicit support <nl> in the hlrc .,0.9780613780021667
ballerina-platform_ballerina-lang/25439,"add support for object method invocations <cm-sep> add support for field access expressions <cm-sep> fix variable evaluation support for json objects <cm-sep> improve error handling <cm-sep> sync with master and resolve merge conflicts <para-sep> method call expression <nl> field access expression <nl> todo - should we disable gc like intellij expression evaluator does ? <nl> visits object expression . <nl> visits object method arguments . <nl> removes argument separator nodes from the args list . <nl> todo - should we disable gc like intellij expression evaluator does ? <nl> visits object expression . <nl> evaluator implementation for basic literals . evaluator implementation for binary expressions . <nl> evaluator implementation for field access expressions . <nl> evaluator implementation for function invocation expressions . <nl> java instance method representation . <nl> jdi based java method representation for a given ballerina function . <nl> invokes the underlying jvm method with given args . <nl> evaluates all function argument expressions at first . <nl> assuming all the arguments are positional args . <nl> removes injected arguments added during the jvm method gen phase . <nl> todo - important : add remaining steps to validate and match named , defaultable and rest args todo - verify here we use the parent strand instance to execute the function invocation expression . <nl> returns the jdi value of the strand instance that is being used , by visiting visible variables of the given debug context . <nl> java static method representation . <nl> evaluator implementation for method call invocation expressions . <nl> returns the corresponding jvm runtime value of this ballerina variable instance , as a jdi value .",- x.k - field access expressions <nl> - objects <nl> - records <nl> - json <nl> - x.f ( x ) - method call expressions <nl> - objects . <nl> this pr also adds the integration tests for the above scenarios .,1598440765,this pr improves the existing annotation support in ballerina . this also adds the support to create new user-defined annotations and use them in constructs .,0.9793206453323364
apache_pulsar/9274,: implement distributed id generator using coordination service,refactored the distributed id generator ( used to generated unique producer names ) to be implemented on top of coordinationservice .,1611293674,"this pr removes functions-util dependency from pulsar-client-admin . with this change , the admin is only dependent on pulsar-common . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9320716857910156
apache_incubator-pinot/5946,return datatypes along with column names,"currently , jdbc connector does n't return data types along with the column names in the result metadata . <nl> this causes issues in certain integrations such as tableau .",1598716168,"fileuploadutils.sendsegmenturiimpl ( ... ) has issue sending segment file uri to pinot controller . in the recent pinot controller changes , we enforced the checking of ' content-type ' of the requests and reject ( by returning 0 ) the caller if it does n't contain a valid information . this is usually fine in other java request code section as apache http libs can infer and generate the content type from the entity provided to it . however , when the entity is empty ( like the case we have here ) , it will not generate a proper",0.9052092432975769
Alluxio_alluxio/12269,fix backup worker crashing master on interruption,"when a backup is interrupted , there is a chance that the resume callback can not be canceled and thus happens after the server is already resumed by the journal reload process . while it makes sense for backup to crash the master if resume fails to complete and master can not accept new journal entries , it is completely fine for master to continue if backup tries to resume an already resumed journal . this change updates the journal to not throw if someone attempts to resume after the journal is already resumed .",1602618942,"when reading an empty file , opening an existing file at pos = 0 would through an exception .",0.906150758266449
OpenAPITools_openapi-generator/7854,add isrange <cm-sep> undo changes to spec <para-sep> boolean value indicating whether the status code is a range,"add isrange in codegenresponse , which returns true if the status code is a range ( e.g . 2xx ) .",1604282560,renamed the environment variable to . <nl> e.g .,0.8456096053123474
ballerina-platform_ballerina-lang/24499,add project api to compiler context <para-sep> invalid module is provided as input . <nl> defines functionality of the project . <nl> returns true if the module exists in the project . <nl> returns the .balo path . <nl> we will add the source directory manager as the project api to the context this has to be further refactored with projectapi implementation <nl> load manifest only once <nl> get the version of the project . <nl> identify the platform version <nl> { module } - { lang spec version } - { platform } - { version } .balo + ' 2019r2 ' + projectdirconstants.file_name_delimiter <nl> valid module <nl> valid module with a diffrent platform <nl> invalid module <nl> invalid valid module <nl> catch works,this can be use by compiler plugins and other components to retrieve information about the project .,1593480424,standard library sources will be read from the distribution and will copy to a temporary location . these will be compiled and the top-level nodes are cached . <nl> - a special configuration option is provided to enable and disable this particular support . users can access the vscode user settings and disable the support .,0.9590086340904236
netty_netty/10751,"allow and skip null handlers when adding a vararg list of handlers . <nl> motivation . <nl> allowing null handlers allows for more convenient idioms in <nl> conditionally adding handlers , e.g. , . <nl> ch.pipeline ( ) .addlast ( <nl> new foohandler ( ) , <nl> condition ? new barhandler ( ) : null , <nl> new bazhandler ( ) <nl> ) ; . <nl> modifications . <nl> * change addfirst ( .. ) and addlast ( .. ) to skip null handlers , rather than <nl> break or short-circuit . <nl> * add new unit tests . <nl> result .","allowing null handlers allows for more convenient idioms in <nl> conditionally adding handlers , e.g. , . <nl> * change addfirst ( .. ) and addlast ( .. ) to skip null handlers , rather than <nl> break or short-circuit . <nl> * add new unit tests .",1603995196,motivation : <nl> while iterating values it is often desirable to be able to remove individual <nl> entries . the existing mechanism to do this involves removal of all entries and <nl> conditional re-insertion which is heavy weight in order to remove a single <nl> value . <nl> modifications : <nl> - defaultheaders $ valueiterator supports removal . <nl> result : <nl> it is possible to remove entries while iterating the values in defaultheaders .,0.8866588473320007
Graylog2_graylog2-server/9042,"add ' keep_value ' and ' delete_value ' operations to encryptedvalue <cm-sep> add exception mapper for jsonmappingexception . <nl> avoids a text/plain response for this exception . <cm-sep> allow auth service backends to modify the config before saving an update . <nl> the ldap backend needs to check if the system user password value should <nl> be kept or deleted . <para-sep> it 's not an update <nl> call authservicebackend # prepareconfigupdate to give the backend implementation a chance to modify it ( e.g . handling password updates via encryptedvalue ) <nl> if the system user password should be deleted , use an unset value <nl> if the system user password should be kept , use the value from the existing config <nl> // setting a new password // alternative to set a new password ( pass a string instead of an object ) ' set a new password ' // keep existing value { ' keep_value ' : true } // delete existing value { ' delete_value ' : true } <nl> if the database type is enable , we want to read the value from the database and so we parse the encrypted value and the salt . <nl> the node is a new password , no need to validate <nl> only one of the keys can be used at a time to make sure we do n't have to need a priority for them <nl> keep_value=false is not allowed <nl> delete_value=false is not allowed",previously we did n't actually save the updated configuration in the api resource . <nl> also add to allow backends to modify the configuration before it 's being updated in the database . ( e.g . to check what needs to happen with the system user password in ldap ) .,1601029544,"* add notification test resource . <nl> make jobtrigger optional for the eventnotificationcontext , <nl> to avoid having to create a huge dummy instance to execute <nl> the test . <nl> * add another notification test resource . <nl> this one accepts notificationdtos directly , <nl> which allows us to live test notifications , while we are editing them . <nl> * add frontend for notification tests . <nl> - the teststate is held in the eventnotificationsstore <nl> - the handletest wrapper is needed to render validation errors . <nl> * keep test notification message on screen . <nl> before",0.9687219858169556
apache_camel/5317,: split unit and integration tests for camel-aws2-cw <cm-sep> : split unit and integration tests for camel-aws2-ec2 <cm-sep> : split unit and integration tests for camel-aws2-eventbridge <cm-sep> : split unit and integration tests for camel-aws2-iam <cm-sep> : split unit and integration tests for camel-aws2-kms <cm-sep> : split unit and integration tests for camel-aws2-lambda <cm-sep> : split unit and integration tests for camel-aws2-s3 <cm-sep> : split unit and integration tests for camel-aws2-sns <cm-sep> : split unit and integration tests for camel-aws2-sts <para-sep> put a compressed element to the bucket <nl> retrieve it from a producer <nl> retrieve it from a polling consumer <nl> delete the content <nl> no-op,"this splits the unit and integration tests for the remainder of the aws2 components . <nl> please note : in a few cases ( mostly in s3 ) there were duplicated manual tests that had the same feature as provided by the test-infra . in those cases , they were removed to avoid confusion after reorganizing the tests .",1617894943,: make hystrix eip general as circuit breaker eip and allow to plugin other implementations,0.8616014719009399
netty_netty/11144,"fix streambufferingencoder goaway bug <para-sep> using getbytes ( ... , false ) is safe here as goawaydetail ( ... ) will clone the byte [ ] .","motivation : . <nl> there is a bug in such that when client receives goway while there are pending streams due to max_concurrent_streams , we see the following error : . <nl> the bug should come from the way that handles the condition . the current behavior is to delegate to and let the stream fail , but this will end up with with the message ' maximum active streams violated for this endpoint ' which is horrible . <nl> modification : . <nl> abort new stream immediately if goaway received and max_concurrent_stream reached in rather than delegating to the",1617749556,correctly take length of bytebufinputstream into account for readline ( ) / readbyte ( ) . <nl> motivation : . <nl> bytebufinputstream did not correctly take the length into account when validate bounds for readline ( ) / readbyte ( ) which could lead to read more then allowed . <nl> modifications : . <nl> - correctly take length into account <nl> - add unit tests <nl> - fix existing unit test . <nl> result : . <nl> correctly take length of bytebufinputstream into account .,0.9437044262886047
elastic_elasticsearch/72055,"reenable systemdatastreamit . <cm-sep> this reverts commit sha . <para-sep> notified of a response or exception in a runnable submitted to the executorservice provided . <nl> notified of a response or exception in a runnable submitted to the executorservice provided . <nl> release references to any listeners as we no longer need them and will live much longer than the listeners in most cases <nl> call get in a non-blocking fashion as we could be on a network thread or another thread like the scheduler , which we should never block !","they 're currently causing test failures that are hard <nl> to scope and mute . for now we 'll revert this commit , with the plan to <nl> reintroduce it along with the bug fixes .",1619041666,"this commit introduces aarch64 packaging , including bundling an aarch64 <nl> jdk distribution . we had to make some interesting choices here : <nl> - ml binaries are not compiled for aarch64 , so for now we disable ml on <nl> aarch64 <nl> - depending on underlying page sizes , we have to disable class data <nl> sharing .",0.9463853240013123
apache_pulsar/8945,support deliverat and deliverafter attribute for websocket producer . <para-sep> the params are all different with the default value,"# # # motivation . <nl> support deliverat and deliverafter attribute for websocket producer . <nl> apply deliverat and deliverafter to message builder for websocket message build if not negative . <nl> added unit test to verify attributes set on message builder . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : no <nl> - the schema : no <nl> - the default values of configurations : no <nl> - the wire protocol : no <nl> - the rest",1607888660,"client hangs forever when all brokers stop and then restart . <nl> there are several steps need to be finished before the broker can be fully started , as illustrated in the pseudo code below : . <nl> if a lookup request gets in between step 0 and step 0 , a npe would be thrown , which will block all other coming requests from getting processed properly . <nl> client can only connect to the broker after the election service started successfully . <nl> this change added tests and can be verified as follows : <nl> - * added",0.9615397453308105
apache_kafka/9950,"cast smt transformation for bytes - > string . <nl> without this fix , the conversion becomes . <nl> bytebuffer.tostring ( ) , which always gives this useless result : <nl> ' java.nio.heapbytebuffer [ pos=0 lim=0 cap=0 ] ' . <nl> with this change , the byte array is converted into a hex string of the <nl> byte buffer content , for example . <nl> ' sha ' . <nl> completed with test case and successfully tried out in a <nl> real database conversion . <cm-sep> fix cast byte array - > string for byte [ ] . <nl> it turns out that not all connectors produce a heapbuffer to store bytes . <nl> sap hana , specifically , just stores a simple byte array that was not <nl> captured by the cast transformer . <nl> completed with test case .","cast smt transformation for bytes - > string . <nl> without this fix , the conversion becomes . <nl> with this change , the byte array is converted into a hex string of the <nl> byte buffer content , for example . <nl> ' sha ' . <nl> completed with test case and successfully tried out in a <nl> real database conversion .",1611320536,"while processing connection set up timeouts , we are iterating through the connecting nodes to process timeouts and we disconnect within the loop , removing the entry from the set in the loop that it iterating over the set . that raises an exception . the current unit test did not catch this because it was using only one node .",0.898644745349884
elastic_elasticsearch/71754,track index details in snapshotinfo . <nl> this commit adds some per-index statistics to the blob : . <nl> - number of shards <nl> - total size in bytes <nl> - maximum number of segments per shard . <nl> it also exposes these statistics in the get snapshot api . <para-sep> the details of a successful shard-level snapshot that are used to build the overall snapshot during finalization .,this commit adds some per-index statistics to the blob : . <nl> - number of shards <nl> - total size in bytes <nl> - maximum number of segments per shard . <nl> it also exposes these statistics in the get snapshot api .,1618502361,this commit adds a dedicated threadpool for system index write <nl> operations . the dedicated resources for system index writes serves as <nl> a means to ensure that user activity does not block important system <nl> operations from occurring such as the management of users and roles .,0.9808810949325562
ballerina-platform_ballerina-lang/24251,check tests runtime exceptions from ballerina <cm-sep> override getimmutabletype for bfunctiontype <cm-sep> add annotation readonly types test case <para-sep> dummy ; <nl> lang : listener ;,"this issue is created to add unit test cases for other scenarios . <nl> we have override copy , freezedirect like methods to allow abstract objects for clonereadonly . <nl> there was a crash which also gets fixed by this .",1592378350,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.8795338273048401
elastic_elasticsearch/72498,"move the mdp error check into environment . <nl> the path.data setting could previously be configured as either a yaml <nl> string , or a list . when a list , it appears internally to settings as a <nl> list object . however , now that path.data is a string setting , it gets <nl> munged into a string representation of a list , beginning with . that <nl> works if checking the original version of the setting , but there are <nl> several settings and environment objects creating during node <nl> initialization , and the error check would not occur until after the path <nl> was made absolute . this would make the string beginning with bracket <nl> relative to the current directory , so the check for a list string would <nl> just not work . <nl> this commit moves the check into environment , so that the first reading <nl> of settings can error if a list is found . <para-sep> also check as if the data was munged into a string already in settings","the path.data setting could previously be configured as either a yaml <nl> string , or a list . when a list , it appears internally to settings as a <nl> list object . however , now that path.data is a string setting , it gets <nl> munged into a string representation of a list , beginning with . that <nl> works if checking the original version of the setting , but there are <nl> several settings and environment objects creating during node <nl> initialization , and the error check would not occur until after the path <nl> was made absolute",1619719429,"our handling for concurrent refresh of access tokens suffered from <nl> a race condition where : . <nl> 0. thread a has just finished with updating the existing token <nl> document , but has n't stored the new tokens in a new document <nl> yet <nl> 0. thread b attempts to refresh the same token and since the <nl> original token document is marked as refreshed , it decrypts and <nl> gets the new access token and refresh token and returns that to <nl> the caller of the api . <nl> 0. the caller attempts to use the newly refreshed",0.933172881603241
apache_pulsar/9284,[ pulsar admin ] expose schema ledger in <cm-sep> modify the doc <para-sep> schema store ledgers,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1611321553,"add properties for managed-ledger . we can use properties to store some metadata such as some metadata that protocol handler need to persistent . <nl> new unit tests added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : (",0.9611708521842957
confluentinc_ksql/6327,"ensure cli works with other key formats . <nl> updates a few places in the rest api , cli and the new java client to specify the key format as well as the value format . <nl> unfortunately , the value format was called . this change introduces a and to hold the two formats , but both the cli and new java client are backwards compatible with the old json schema . <nl> also in this commit , streams also indicate if there key is windowed . this means the key is serialized using the windowed serializer . it is possible to have a stream over a topic with a windowed key . now the cli and java client expose this info . <nl> main change was to and response . previously , these returned . <nl> and now return : .","updates a few places in the rest api , cli and the new java client to specify the key format as well as the value format . <nl> unfortunately , the value format was called . this change introduces a and to hold the two formats , but both the cli and new java client are backwards compatible with the old json schema . <nl> also in this commit , streams also indicate if there key is windowed . this means the key is serialized using the windowed serializer . it is possible to have a stream over a topic",1601490553,"was recently enhanced to support any expression , rather than just column references . if the expression expression results in an error , e.g . a udf that throws an exception , this exception was not being handled - resulting in the query being terminated . <nl> udtfs were recently introduced . if a udtf throws an exception , or an exception occurs extracting a udtfs parameters , e.g . if a parameter is a udf that throws , then the exception was not being handled - resulting in the query being terminated . <nl> all these exceptions are now",0.9804590344429016
apache_kafka/10163,: extract setup of changelog from streams partition assignor <para-sep> add tasks to state change log topic subscribers <nl> the expected number of partitions is the max value of taskid.partition + 0,"to implement the explicit user initialization of kafka streams as <nl> described in , we first need to extract the code for the <nl> setup of the changelog topics from the streams partition assignor <nl> so that it can also be called outside of a rebalance .",1613753643,implements for the test-utils module : <nl> * adds mocks of the new processorcontext and statestorecontext <nl> * adds tests that all stores and store builders are usable with the new mock <nl> * adds tests that the new processor api is usable with the new mock <nl> * updates the demonstration processor to the new api .,0.9653358459472656
Graylog2_graylog2-server/9596,adding tests for missing host field in response . <cm-sep> gracefully handle missing field in nodes response .,"in some es implementations , the nodes api response is missing the <nl> field . before this change , parsing it resulted in an npe . <nl> this change is now handling the absence of this field gracefully and <nl> returns an empty optional .",1606216187,this led to an 0 server error <nl> and the api endpoint could not be used .,0.9618477821350098
apache_beam/13567,"add partition increase handling to pubsubliteio <para-sep> a set of partitions . if empty , continuously poll the set of partitions using an admin client .",this allows for handling when topics have partitions added to them once the backend supports this,1608143106,follow this checklist to help us incorporate your contribution quickly and easily : .,0.9753510355949402
ballerina-platform_ballerina-lang/25889,fix the issue with comments <cm-sep> add object constructor node <cm-sep> support isolated functions <cm-sep> add do and on fail nodes <cm-sep> enable the match statement <cm-sep> enable on fail for match statements <cm-sep> enable on fail for foreach statements <cm-sep> enable foreach statements <cm-sep> enable on fail for while statements <cm-sep> enable lock statements <cm-sep> enable on fail for lock statements <cm-sep> fix the anonymous object variable declaration <para-sep> test the formatting of assignment statements . <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two check actions fails type of e will be union of the error types that can be returned by foo and bar <nl> this will be executed if the block-stmt following do fails which will happen if and only if one of the two,0. enables formatting support for the following . <nl> * object constructor expressions ( abstract objects and anon objects ) <nl> * do statement <nl> * on fail clause : <nl> * do statements <nl> * match statements <nl> * foreach statements <nl> * while statements <nl> * lock statements <nl> * isolated functions . <nl> 0. fix some formatting issues . <nl> 0. handle comments in the source code .,1600349337,"this pr will add the fork-join support with improvements to worker implementation in ballerina . with this pr , fork join statement changed slightly along the lines of returning results to the join block . here is a sample ballerina program with fork-join statement .",0.9759566783905029
Graylog2_graylog2-server/9404,"request session creation when authentication for trusted header suceeded . <nl> when a subject is authenticated via a trusted header , we have to signal <nl> to the session resource to create a session . this way , the initial <nl> session validation request from the frontend will lead to the creation <nl> of a session which can then be used for further requests . <cm-sep> return username instead of user id in session . <nl> the main principal of the subject has been changed to the user id . the <nl> response to the session validation request should however contain the <nl> username so we have to load the user explicitly and get the name . <para-sep> there 's no valid session , but the authenticator would like us to create one . this is the ' trusted header authentication ' scenario , where the browser performs this request to check if a session exists , with a trusted header identifying the user . the authentication filter will authenticate the user based on the trusted header and request a session to be created transparently . the ui will take the session information from the response to perform subsequent requests to the backend using this session . <nl> setting this , will let the sessionresource know , that when a non-existing session is validated , it should in fact create a session .","with this change , we will implicitly create a session , when no session exists yet , but the user has been authenticated based on a trusted header . <nl> this pr also fixes a wrong response to the session validation request .",1604917081,- disable the stacked field form in quickvalues configuration when elasticsearch version is < 0 <nl> - reset loading state in case of an error so the user can change settings and try again <nl> - reset quickvalues visualization config to defaults when analyzing a new field . <nl> note : this needs to go into the version branch as well,0.9058008790016174
apache_pulsar/9443,try to fix flaky leaderelection test . <para-sep> check if the all active pulsar see a new leader . <nl> check leader a pulsar see is not empty and not the old leader . <nl> make sure all brokers see the same leader,"so update to wait for leader changed for all pulsar , then verify they 're all see same leader .",1612335670,"therefore , the policy data in the cache is still old . when listeners are triggered , they can not get the policies directly through the cache . they have to modify the existing interface and pass the policies through parameters . <nl> 0 ) when the broker restarts , some topic-level policies will no longer take effect , because they rely on the method to take effect . <nl> topicpoliciestest # testrestart",0.9148594737052917
ballerina-platform_ballerina-lang/26546,add the initial version of the compilationoptions class <cm-sep> expose the compilationoptions via the project api <cm-sep> add some temporary changes for testing langlib tests <cm-sep> improve the temporary fix with checkstyle and spotbug issues <para-sep> merge the given compilation options by favoring theirs if there are conflicts .,this pr includes the following changes : <nl> - load the bpackagesymbol from bir binary <nl> - load langlib modules during the construction of the .,1603397756,standard library sources will be read from the distribution and will copy to a temporary location . these will be compiled and the top-level nodes are cached . <nl> - a special configuration option is provided to enable and disable this particular support . users can access the vscode user settings and disable the support .,0.98487389087677
apache_pulsar/9322,add the test for topic replicated and create producer . <para-sep> persistent topic <nl> non-persistent topic,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1611651132,"motivation . <nl> currently producers uses as publish timestamp by default . <nl> however at some use cases , producers would like to a different way for generating publish timestamp . <nl> e.g . in a database use case , a producer might be use hlc ( hybrid logic clock ) as publish timestamp ; <nl> in integration tests , it might require the producer to use a deterministic way to generate publish timestamp . <nl> changes . <nl> this pr introduces a in building the client . this allows applications to override the system clock <nl> with its own",0.941321849822998
elastic_elasticsearch/72052,update joda dependency to latest version . <nl> latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated . <para-sep> list of ignored timezones .,latest jdks are shipping with timezone data 2021a which is also included <nl> in latest joda . in order to have the timezone information consistent in <nl> both joda and java.time joda dependnecy has to be updated .,1619034461,"relies on the resource watcher to detect the cert file overwriting . <nl> resource watcher detects changes by only inspecting the file size on disk and the last access timestamp . <nl> for the last access timestamp , the resolution can be as low as one second depending on the jdk and the fs type . <nl> it is thus preferable to rely on file size differences in tests .",0.8968686461448669
vespa-engine_vespa/16464,"use feature flag for max heap size for cluster controller . <nl> feature flag default is 0 , so no change of default value <para-sep> taken from containercluster <nl> overridden values from clustercontrollercontainercluster","feature flag default is 0 , so no change of default value",1612960799,this adds a new config which includes all <nl> document type to bucket space mappings across all configured content <nl> clusters . inject this config into to ensure all changes <nl> to the mapping is observed . this also removes the remaining per-request <nl> config fetching during document v1 visit ops .,0.9689841270446777
vespa-engine_vespa/15598,allow list of owners <cm-sep> specify owner and expected time-to-leave for feature flags . <nl> actual owners will be specified in upcoming pr <para-sep> definition for permanent feature flags,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1606914281,"guarded by feature flag , per application .",0.9544363021850586
neo4j_neo4j/11288,"rename and remove duration.between functionality . <nl> duration.years ( a , b ) .years was not needed , since it is equivalent to <nl> duration.months ( a , b ) .years . the same is true for quarters , weeks , hours , <nl> minutes . these have been removed and the remaining functions have been <nl> prefixed with an ' in ' . <cm-sep> support truncate to weekyear . <nl> this will return the monday of week 0 of the week based year . <cm-sep> epochseconds , offsetminutes . <nl> also support epochseconds during creation . rename epoch to epochmillis . <para-sep> be aware that the text file ' userdefinedfunctions ' must end with two newlines",this pr encapsulates three small changes in the spec that need to be reflected in the implementation . <nl> for once commits are nicely split and i recommend a commit-by-commit review .,1521196451,update ephemeral file system to use 1kb buffer for new file by default . <nl> in case if file data size over exceed available buffer capacity it will be doubled till enough space will be available .,0.9344878792762756
apache_pulsar/9980,"make the pulsar sql support query upper case topic . <para-sep> use a short live cache to make sure one query not get matched the topic many times and prevent get the wrong cache due to the topic changes in the pulsar . <nl> the show tables query return lowercase table names , so ignore case","when querying the uppercase topic ( e.g . ) by the pulsar sql , it will throw the error ' topic not found ' because of the class , in the pulsar sql , we could n't get the exact table name ( e.g . , ) but only lowercase table name ( e.g . ) , this is the presto behavior . <nl> refer to the presto class . <nl> if there are topics , , the query will return one result , this behavior is determined by the presto spi . <nl> there is a precondition for querying",1616173406,motivation . <nl> currently keyvalue schema does n't support using auto_consume . <nl> this pr is to add this support . <nl> changes . <nl> - refactor a bit on schema interface to support fetching schema info for both autoconsumeschema and keyvalueschema before subscribing <nl> - add auto_consume support to keyvalueschema <nl> - add tests,0.9621815085411072
apache_flink/14679,"fix idle source does n't work when pushing watermark into the source <para-sep> we always use a different topic name for each parameterized topic , in order to make sure the topic can be created . <nl> only two partitions have elements and others are idle . when idle timer triggers , the watermarkoutputmultiplexer will use the minimum watermark among active partitions as the output watermark . therefore , we need to make sure the watermark in the each partition is large enough to trigger the window .","fix idle source does n't work when pushing watermark strategy into table source . <nl> - fix the bug . <nl> this change added tests and can be verified as follows : . <nl> - idle source plan test . <nl> - idle source it cases . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl>",1610958292,"hive acid table configures tblproperties with 'transactional=true ' . currently hive connector could n't support to read and write on acid tables . therefore , hive connector should throw a meaningful exception to users for reading or writing acid tables . <nl> - adds to check whether the tblproperties of the hive source table is true . if the tblproperties is true , this should throw to prompt user meaningful exception . <nl> - adds to check whether the tblproperties of the hive sink table is true . if the tblproperties is true , this should throw to prompt user",0.9207459688186646
apache_kafka/9894,migrate connect : mirror module to junit 0,this pr consists of following changes . <nl> 0. replace junit 0 apis by junit 0 <nl> 0. remove the dependencies of junit 0 from .,1610641987,"however , follow on prs have now moved the name type fields to new and classes . this means the old name is no longer valid and may be confusing . the pr looks to rename the class to a more intuitive . <nl> currently causes to bring back all acls that would affect the supplied resource , i.e . it brings back literal , wildcard acls , and also does pattern matching to work out which prefix acls would affect the resource . this is very different from the behaviour of , which just means the filter ignores the",0.9442523717880249
apache_flink/14748,"introduce supportsaggregatepushdown interface <para-sep> by default , if this interface is not implemented , local aggregates are applied in a subsequent operation after the source . the passed aggregate functions and grouping sets are in the order defined by the query . the source can directly return the aggregated values if the underlying database or storage system has aggregation capability . due to the complexity of aggregate , the aggregate push down does not support a number of more complex statements at present : complex grouping operations such as rollup , cube , or grouping sets . expressions inside the aggregation function call : such as sum ( a b ) . aggregations with ordering . aggregations with filter . and the optimized plan as shown below . the local aggregate will not be pushed down in this scenario . regardless if this interface is implemented or not , a final aggregation is always applied in a subsequent operation after the source . <nl> provides a list of aggregate expressions and the grouping keys . the source should pick all the aggregates or nothing and return whether all the aggregates have been pushed down into the source . the projection of grouping keys and aggregate values is already considered in the given output data type . <nl> resolved and validated expression for calling an aggregate function .","this pull request introduces a new tablesourceability interface for supporting aggregation push down . <nl> - a new interface of supportsaggregatepushdown <nl> - a new implementation of resolvedexpression which is aggregateexpression <nl> - implement the new supportsaggregatepushdown interface for testvaluesscantablesource . <nl> this change is only introduced a few new interfaces , and implemented for a test class , which already covered by existing tests , such as tablesourceitcase . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no",1611566149,"resourcerequirement ( s ) describe the resource requirements for a single job , and will be used for on both the jm and rm side for resource management as well as rpc messages . <nl> front-loading this change because it is used by multiple processes and essentially locked in code-wise .",0.9909701943397522
apache_beam/13075,"applying difference <cm-sep> update new dependencies <cm-sep> add bom dependency <cm-sep> update category attribute <para-sep> try to keep grpc_version consistent with grpc version in google_cloud_platform_libraries_bom <nl> google-http-client 's version is explicitly declared for sdks/java/maven-archetypes/examples this version should be in line with the one in com.google.cloud : libraries-bom . <nl> boms , declared with 'platform ' or 'enforced-platform ' , appear in section <nl> filtering versionless coordinates that depend on bom . beam project needs to set the versions for only handful libraries when building the project ( ) .",use gcp libraries bom to set versions for gcp related libraries,1602528102,"- upgrading bigtable-client-core to the latest version <nl> - the exposed api surface reduced . the associated test is updated . <nl> checked beam-sdks-java-core , beam-sdks-java-io-google-cloud-platform , beam-runners-google-cloud-dataflow-java and beam-sdks-java-io-hadoop-format . <nl> for beam-sdks-java-io-google-cloud-platform and beam-runners-google-cloud-dataflow-java <nl> - this pr removes linkage errors on gax-.version.jar <nl> - this pr upgrades the version of appengine-.0-sdk in the errors . these are irrelevant to beam",0.84483402967453
vespa-engine_vespa/15376,support default request/response filter chain per connector,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1605699472,also verify that you only add clustercontrollercontainer to a clustercontroller cluster .,0.9629007577896118
confluentinc_ksql/6144,"stabilise tlstest . <nl> fixes an issue where the tlstest was failing because the file watcher was n't detecting the change of the tls cert from valid to invalid . this was because of a limitation of jdk 0 , which has only second resolution for , meaning the can miss updated made to files that existed before the watch was registered , if the update happened after the watch was started and the updated did n't change the last modified time , i.e . the last modified time both before and after the update was in the second second . <nl> the fix is to insert a sleep to ensure at least one whole second has elapsed . <nl> in production code , this one second window of bad behaviour is highly unlikely to be hit , and there 's no real way to solve it , except upgrading to jdk 0 . <para-sep> wait for server to pick up valid cert to ensure other tests are not affected : <nl> this can mean the watcher 'misses ' an update to a file that was created before the watcher was started and updated after , if the update results in the same last modified time . to ensure we stable test we must therefore wait for a second to ensure a different last modified time . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> this can mean the watcher 'misses ' an update to a file that was created before the watcher was started and updated after , if the update results in the same last modified time . to ensure we stable test we must therefore wait for a second to ensure a different last modified time .","fixes an issue where the tlstest was failing because the file watcher was n't detecting the change of the tls cert from valid to invalid . this was because of a limitation of jdk 0 , which has only second resolution for , meaning the can miss updated made to files that existed before the watch was registered , if the update happened after the watch was started and the updated did n't change the last modified time , i.e . the last modified time both before and after the update was in the second second . <nl> the fix",1599082835,": dont block on socket read . <nl> avoid blocking on socket reads from the cli when <nl> streaming a query response . the read can not be interrupted , <nl> so the user can not abort the query via ctl-c until then next <nl> response chunk arrives . instead , have read poll the input <nl> stream periodically and sleep interruptably between poll <nl> attempts .",0.9652539491653442
elastic_elasticsearch/71710,"add new predefined roles . <nl> this change adds two new reserved roles in elasticsearch , viewer <nl> and editor <nl> solutions will use these roles in order to provide , out of the box , <nl> a role for full access to data and configuration with no access to <nl> cluster management ( editor ) and a role for read only access to data <nl> again with no access to cluster management ( viewer ) . <para-sep> stack <nl> security <nl> stack <nl> observability <nl> security <nl> no cluster privileges <nl> check index privileges <nl> check application privileges <nl> no cluster privileges <nl> check index privileges <nl> check application privileges","this change adds two new reserved roles in elasticsearch , <nl> and <nl> solutions will use these roles in order to provide , out of the box , <nl> a role for full access to data and configuration with no access to <nl> cluster management ( editor ) and a role for read only access to data <nl> again with no access to cluster management ( viewer ) .",1618433227,"the current implicit behaviour is that when an api keys is used to create another api key , <nl> the child key is created without any privilege . this implicit behaviour is surprising and is <nl> a source of confusion for users . this change makes that behaviour explicit .",0.9386529326438904
elastic_elasticsearch/72288,"( cherry picked from commit sha ) <para-sep> implicit tiebreake , present only in the response and which does n't have a corresponding field <nl> returns the implicit elasticsearch tiebreaker value associated with a pit request for every search hit against which it is run . <nl> except the first request , the rest should have the previous response 's search_after _shard_doc value <nl> for desc ( tail ) sequences only the first criterion is descending the rest are asc , so flip it after the first query",( cherry picked from commit sha ),1619506709,"this commit adds a new api that allows opening reader contexts in a separate step before using them in subsequent search requests . some advantages of this api over the previous approach : <nl> - the flow is clearer : open readers - > use readers in search requests - > close readers <nl> - opening readers separately is faster than with a search request <nl> - better error handling : opening readers requires all shards available , and both and must be provided in search requests .",0.9785143733024597
eclipse-openj9_openj9/10858,"rename methodhandlehelper to methodhandleresolver . <nl> this is required to avoid name conflicts with openjdk tests which <nl> inject a java.lang.invoke.methodhandlehelper class during the test . <para-sep> [ if sidecar19-se ] <nl> * / <nl> * / <nl> static methods for the methodhandle class . <nl> return the result of j9_cp_type ( j9class- > romclass- > cpshapedescription , index ) <nl> sun.reflect.constantpool does n't have a getmethodtypeat method . this is the equivalent for methodtype . <nl> sun.reflect.constantpool does n't have a getmethodhandleat method . this is the equivalent for methodhandle . <nl> get the class name from a constant pool class element , which is located at the specified index in clazz 's constant pool . <nl> [ if java11 ] * / sun.reflect.constantpool does n't have a getconstantdynamicat method . this is the equivalent for constantdynamic . <nl> [ msg ' k05cd ' , ' unable to resolve 'bootstrap_method_ref ' in ' { 0 } ' at index { 0 } ' ] * / <nl> mandatory arguments * / <nl> static optional arguments * / <nl> jvms jdk11 version dynamically-computed constant and call site resolution requires the first parameter of the bootstrap method to be java.lang.invoke.methodhandles.lookup else fail resolution with bootstrapmethoderror <nl> [ msg ' k0a01 ' , ' constant_dynamic references bootstrap method ' { 0 } ' does not have java.lang.invoke.methodhandles.lookup as first parameter . ' ] * / <nl> jvms jdk11 version dynamically-computed constant and call site resolution requires that exceptions from bsm invocation be wrapped in a bootstrapmethoderror unless the exception thrown is a sub-class of error . exceptions thrown before invocation should be passed through unwrapped . <nl> result validation * / <nl> [ msg ' k0a00 ' , ' failed to resolve constant dynamic entry with j9class : { 0 } , name : { 0 } , descriptor : { 0 } , bsmdata : { 0 } ' ] * / <nl> java11 * / <nl> [ if ] / used to preserve the new objectref on the stack when avoiding the call-in for constructorhandles . must return 'this ' so stackmapper will keep the object alive . / <nl> invoke bootstrap method with its static arguments <nl> take advantage of the per-mh astype cache * / <nl> [ if ! java11 ] * / <nl> * / <nl> [ msg ' k05cd ' , ' unable to resolve 'bootstrap_method_ref",this is required to avoid name conflicts with openjdk tests which <nl> inject a java.lang.invoke.methodhandlehelper class during the test .,1602252093,"this pr should be purely comment changes for words ( or families of words ) that start w/ . <nl> to make my life easier , these initial comment focused prs will have 0 commits : <nl> * one which is the fixes <nl> * and one which is the copyright bumping .",0.8759475946426392
apache_flink/14474,"clean useless codes : never push calcprogram to correlate <para-sep> output all fields of left and right in case of left outer join and the returned row of table function is empty , fill all fields of row with null","# # what is the purpose of the change . <nl> projectprogram in streamphysicalcorrelatebase never be used . we should remove the codes . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : ( no <nl> - the runtime per-record code paths ( performance sensitive ) : ( no <nl> - anything that affects deployment or recovery : jobmanager",1608713550,"currently the already uses off-heap memory directly . but the for still uses heap memory by default . it should keep the same behavior with and it may get benefit for reusing this off-heap memory in netty stack during transporting . <nl> - use off-heap memory directly for in . <nl> this change is already covered by existing tests , such as spillablesubpartitiontest . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> -",0.8594942092895508
runelite_runelite/12134,change name of poison ivy in produce enum from ' poison ' to ' poison ivy ' . <cm-sep> changed capitalization of poison ivy and dwarf weed to be consistent with other produce,"on farming contracts and the time tracker plugin , the poison ivy bush simply shows up as ' poison ' . this pr simply changes the name to ' poison ivy ' . <nl> ' dwarf weed ' is also changed to ' dwarf weed ' for consistency with other produce such as ' snape grass ' and ' celastrus tree ' .",1594692749,"the osrs wiki had the wrong text ( hope - > hopes ) . here is an image of the clue in game after correcting the text in the plugin : . <nl> found another one , wiki text was missing a comma . updated : .",0.9999999403953552
elastic_elasticsearch/72503,"fix path.data list deprecation to work in all cases . <nl> path.data can appear as a list , or a string . on node startup , several <nl> environment and setting objects are created . the environment propagates <nl> the path.data setting , but needs to choose whether it is propagated as a <nl> list or a string . this commit adjusts how it is propagated so that if <nl> the path.data is originally a string , it will stay a string , so that the <nl> deprecation message for path.data as a list can properly detect a list <nl> case .","path.data can appear as a list , or a string . on node startup , several <nl> environment and setting objects are created . the environment propagates <nl> the path.data setting , but needs to choose whether it is propagated as a <nl> list or a string . this commit adjusts how it is propagated so that if <nl> the path.data is originally a string , it will stay a string , so that the <nl> deprecation message for path.data as a list can properly detect a list <nl> case .",1619722414,this fixes the case where a valid composable template overrides/shadows a <nl> legacy template that defines the rollover alias . this is a valid configuration <nl> and rollover should not fail .,0.9470998048782349
