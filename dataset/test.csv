id,article,abstract,created_at,exemplar,similarity
elastic_elasticsearch/72953,adjust get aliases api for aliases that point to data streams . <nl> the get alias api should take into account the aliases parameter when <nl> returning aliases that refer to data streams . <para-sep> return all all data streams with aliases <nl> filter by alias name <nl> filter by data stream :,the get alias api should take into account the aliases parameter when <nl> returning aliases that refer to data streams and do n't return entries <nl> for data streams that do n't have any aliases pointing to it .,1620758628,"this took me a bit of time so i 'll try to describe what happened . the test failed twice this year ( 0 , 0 ) with a ' resource not exception ' indicating that a task was not correctly created ( the task is a reindexing task ) . <nl> the elasticsearch logs show the following warning messages for both builds failures : <nl> > warn ] [ o.e.t.loggingtasklistener ] 0 failed with exception <nl> > org.elasticsearch.index.mapper.mapperexception : the parameter ca n't be updated for the object mapping . <nl> it indicates that the index was already created",0.9053248167037964
ballerina-platform_ballerina-lang/28306,handle endoffile exception to exit with ctrl+d <cm-sep> pass handling of shell exit to outer handler <para-sep> exception to signify that shell wants to exit . after this is called no new input/output can be done on shell .,it will now print there and exit . <nl> can exit by pressing ctrl+d .,1612013667,this pr provides swagger to ballerina support for this extension . this pr also include several minor fixes for bal-swagger code generator . <nl> - add support for x-multi path extension <nl> - update default codegen server bindings <nl> - add inverse support for equals helper <nl> - update errors after httpconnectorerror changes,0.95756596326828
apache_shardingsphere/10658,fix select lost subquery projection <para-sep> subquery projection .,changes proposed in this pull request : <nl> - fix select lost subquery projection <nl> - add parse test case,1622804023,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - add proxy meta data <nl> - fix some problems <nl> -,0.9719845056533813
apache_incubator-pinot/6273,"[ te ] web-api - endpoint for getting performance metrics of detection over time range <cm-sep> [ te ] web-api - endpoint for getting performance metrics <para-sep> the performance metrics of a detection based on the given anomalies <nl> builder for performance metrics <nl> * builds the performance given a list of anomalies . when calculating entity anomalies , it counts the total number of anomalies only on the parent level but includes children anomalies when calculating the performance <nl> note : includes user-created anomaly without feedback as false negative by default",[ te ] rest-api enhance implementation to calculate alert performance <nl> slightly modified harley 's implementation,1605659169,"in order to allocate memory efficiently for dictionary for a column , we can attempt to use <nl> the statistics gathered from previously completed segments . <nl> added a class to keep track of statistics for n previously completed segments for a table on local disk <nl> of each server . for now , we have code to store average size ( in case of a string column ) and cardinality <nl> ( for all columns ) . these can be used when initializing a dictionary for the next segment . <nl> some methods are synchronized since we expect that",0.9757689833641052
apache_pulsar/10850,"maxtopicspernamespace check should exclude system topic . <para-sep> new create check <nl> exclude created system topic <nl> new create check <nl> exclude created system topic <nl> event topic <nl> transaction pending ack topic <nl> check first create normal topic , then system topics , unlimited even setmaxtopicspernamespace <nl> check first create system topics , then normal topic , unlimited even setmaxtopicspernamespace <nl> local topic name for the transaction buffer snapshot .","the current maxtopicspernamespace check logic contains system topics , but it should be excluded . as the even if we turn off , the systemtopic will auto creation too . <nl> 0. exclude the system topics for the maxtopicspernamespace logic . <nl> 0. systemtopic add the missed logic , such as 、start with the end with the . <nl> in addition , why is mytopic-partition-0 is a partitioned topic（with -- ） ? which version of us uses this logic ?",1623057513,"this is very bad because we 're calling that from io threads which are used for critical publish tasks . <nl> several internal methods introduced in that commit are async on the surface , though are blocking in practice . <nl> additionally , the logic for checking that a topic exists is unnecessarily expensive : fetching the list of topics in a namespace and then iterating through the list to compare with the current topic . <nl> refactored the handling of partitionmetadatarequest to ensure everything is end-to-end async .",0.9435685873031616
apache_incubator-pinot/6890,adding a new controller api to retrieve ingestion status for realtime table <para-sep> todo : support table status for offline table . currently only supported for realtime . <nl> utility function to return set of servers corresponding to a given segment . <nl> utility method to derive ingestion status from consuming segment info . status is healthy if consuming segment info specifies consuming state for all active segments across all servers including replicas . <nl> check if any responses are missing <nl> container object to encapsulate table status which contains - ingestion status : specifies if the table is ingesting properly or not <nl> the state of the consumer for a given segment,adding a new controller api to retrieve ingestion status for realtime table . <nl> this pr provides an overall ingestion status for pinot realtime table . the status is healthy if all consuming segments are in the consuming state . unhealthy otherwise . <nl> part 0 ( in another pr ) will cover retrieving detailed stack trace for consuming segments in error state . <nl> no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no . <nl> does this pr otherwise need attention when creating release notes ? <nl> no,1620360206,"0. move the anomalies ' time based merge logic to timebasedanomalymerger.java . the merger will be shut down and change to a grouper in the next pr . <nl> 0. refactor anomaly detection flow : <nl> 0-a . move all data fetching/persistence to the begin/end of anomaly detection task . <nl> 0-b . anomaly detection method , analyze , and update merged anomaly method now only return raw anomalies and updated merged anomalies without storing them to db . <nl> tested by comparing the anomalies results from pre-refactored code and this refactored code : two sets of anomalies are exactly",0.970697820186615
apache_beam/14265,"create separate merge rules for different calc implementations . <nl> once we implement calc splitting , calcmergerule will attempt to merge calcs back together , which defeats the purpose of splitting them in the first place . we will need to narrow the merge conditions , to prevent incompatible calcs from being merged . <para-sep> rules to merge matching calcs together .","create separate merge rules for different calc implementations . <nl> once we implement calc splitting , calcmergerule will attempt to merge calcs back together , which defeats the purpose of splitting them in the first place . we will need to narrow the merge conditions , to prevent incompatible calcs from being merged",1616024747,this pr adds : <nl> 0. external transform registrar for snowflakeio.write for cross-language usage <nl> 0. python wrapper for 0 ) <nl> 0. integration test for snowflakeio python wrappers,0.9533284306526184
apache_incubator-pinot/6878,"json column datatype support . <para-sep> base64 encoding is the commonly used mechanism for encoding binary data in json documents . note that tojson function converts byte [ ] into a base64 encoded json string value . <nl> note : override toint ( ) , tolong ( ) , tofloat ( ) , todouble ( ) , toboolean ( ) , totimestamp ( ) , tostring ( ) , and tobytes ( ) for single-value types . <nl> single-value json type dimension field with max length and default null value . <nl> test cases verifying query evaluation against column of type json . <nl> verify result column type of a simple select query against json column * / <nl> test filtering on string value associated with json key * / <nl> test filtering on number value associated with json key * / <nl> test filtering on float value associated with json key * / <nl> query to retrieve result as int <nl> query to retrieve result as double <nl> retrieve json array after filtering on string value associated with json key * / <nl> test filtering on string value within a json array * / <nl> todo : update these test cases to : 0 ) use v2 json_match function , 0 ) use multi-dimensional json array addressing , 0 ) do json_extract_scalar on a column other than the json_match column , 0 ) query deeper levels of nesting , and 0 ) add test cases for group by on json_extract_scalar or path expressions . mode non_metric - use all dimensions and time columns <nl> commons configuration version does not support file path containing ' % ' . explicitly providing the output stream for the file bypasses the problem .",column type can contain only valid jsonobject . column type supports conversion to and from . columns of type can be indexed using . queries using and functions can run against a column type . test cases in are used to validate functionality .,1620194345,this pr adds limited support for ' is null ' and ' is not null ' filter predicates . currently this only works for leaf filter predicates .,0.9728932976722717
jenkinsci_jenkins/5156,"remove any tests that refer to mavenmoduleset or mavenmodulesetbuild <cm-sep> eliminate dependency on tasks.jpi , which depends on an older version of maven-plugin <cm-sep> fix erroneous import of a transitive dependency of maven-plugin <cm-sep> remove maven-plugin from test/pom.xml <para-sep> sites use the same wiki url for html publisher - > use it","the tests in jenkins core depend on an old version of maven integration ( i.e. , ) . this pollutes the dependency tree for the tests in jenkins core , causing issues and complicating maintenance . <nl> the tests in jenkins core depend on an old version of for three reasons : . <nl> 0. a number of tests in jenkins core depend on or . these classes were previously in jenkins core before they were extracted to . however , the corresponding tests were never moved to . as a result , the tests are no longer in the",1610133914,"very confusing to have a test which sets up security , only to see no trace of that in the next session , because you forgot to . <nl> of course already s , in a , so it should be unaffected ; this is for isolated api calls .",0.9473833441734314
apache_pulsar/10803,use zookeeper prometheus metric provider to export zookeeper metric <para-sep> start the regular zookeeper server,"due to zookeeper version+ has add internal prometheus metric provider , so we can turn on by default in pulsar . <nl> 0. update reference-metric.md doc",1622708173,# # # motivation . <nl> improving the method in which we retrieve the version and git properties . <nl> just use a template file and substitute properties for literals . <nl> get rid of properties files that is not necessary . <nl> move code to pulsar-common so other modules have access to the code as well .,0.854299783706665
vespa-engine_vespa/17163,revert ' revert ' avoid safe mutations in master moratorium and increase first cluster state broadcast deadline ' ',this pr will <nl> - impose a master cc moratorium until it has broadcast its first cluster state <nl> - deny the safe setting of node states in moratorium <nl> - increase the default time to the first cluster state broadcast from 5s to 120s .,1616596052,"add support for serializing and compressing once , instead of once per backend node .",0.9432751536369324
Alluxio_alluxio/12886,"minimal changes on the loglevel <para-sep> todo ( jiacheng ) : make this support ha master todo ( jiacheng ) : support all other roles , not just worker",added todos for further prs to resolve .,1613719280,is no longer recommended . updates the properties template to use the root mount point property .,0.9083282947540283
apache_flink/16029,add unit test for cliutils . <cm-sep> fix bug : create directory based symbolic link throws exception . <para-sep> * /,"this pull request fixs sql-client can not create .flink-sql-history file when parent directory is a symbolic link . <nl> - add unit test for cliutils . <nl> - fix bug : create directory based symbolic link throws exception . <nl> this change added tests and can be verified as follows : <nl> - added unit test for cliutils . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no",1622455392,"( please pick either of the following options ) <nl> this change is a trivial work without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos , zookeeper :",0.9482656121253967
apache_pulsar/10087,"bugfix for wrong timeunit in updating lastledgercreationinitiationtimestamp <para-sep> may need to update the cursor position <nl> may need to update the cursor position <nl> we have 0 ledgers at the beginning [ { entries=0 } , { entries=0 } ] <nl> managed-ledger restart <nl> then we have one more empty ledger after managed-ledger initialization and now ledgers are [ { entries=0 } , { entries=0 } , { entries=0 } ] <nl> now we update the cursors that are still subscribing to ledgers that has been consumed completely <nl> we only have one empty ledger at last [ { entries=0 } ]","respectively . however , when we close and open a managed-ledger ( such like brokers shutdown unexpectedly or topics unload due to rebalance ) , the managed-ledger will create an empty ledger after initialization causing the current cleanup logic failed to take effect . therefore i think we need a more unified entrance to solve the cursor update problem , and then further solve the problem of clearing expired ledgers . <nl> 0. able to cleanup expired data after managed-ledger re-open <nl> 0. a more unified entrance to implement cursor update . <nl> 0. move the cursor update logic to",1617101030,"if the namespace-level policy does not exist , the broker level will be used .",0.9528377056121826
apache_beam/14365,- adding tests to pubsubtableproviderit to test the proto support implemented in . <nl> three new protos were added to the payload_messages.proto file . those are used by the new inner class pubsubprotoobjectprovider,this pr adds a new class pubsubprotoobjectprovider to pubsubtableproviderit in order to test the support of protbufs in the pubsubtableprovider . <nl> can you take a look at this and let me know if this would be enough to test the functionality ? thanks !,1617050219,"add a sink to avroio that takes generic data ( usually genericrecords ) . the current method sinkviagenericrecords ( ) has been deprecated . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9414344429969788
apache_shardingsphere/10544,fix sqlserver table metadata load exception,changes proposed in this pull request : <nl> - fix execute sql exception <nl> - fix nullpoint exception,1622281868,changes proposed in this pull request : <nl> -change a todo in pathtree <nl> -checkstyle <nl> -,0.885479748249054
Alluxio_alluxio/12825,replace lock to double check to reduce heap memory cost . <para-sep> fileinstream is not thread safe,"for the existing code of , it use a readwrite lock pool as the guards for each fd , there are 0 reason why i purpose to remove it by a double check . <nl> - reduce the heap memory for the , now the constant is , so the reason seems too weak . <nl> - we can only have 0 lock in the same time , if there are more other unrelated files operation , they will hang for waiting lock resource other then acquire lock . <nl> - is a hard code here , and we can",1612846767,this pr fixes the race conditions mentioned in the ticket by adding reference counting to the clientrwlock .,0.9002480506896973
ballerina-platform_ballerina-lang/30989,fix isolation analyzer to consider implicit finalness of params <cm-sep> add tests,this pr also adds tests for accessing other implicitly-final variables .,1622742675,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.905842661857605
prestodb_presto/15975,"only set join operators count if running with spill . <nl> previously this value was set anytime it was present , even if spill was <nl> disabled , or for outer joins or probe only grouped execution .","test plan - unit test , ci . <nl> spilledlookupsourcehandle needs to be disposed immediately when join operators finished processing probe data . otherwise spilledlookupsourcehandle is never disposed as it 's not registered in partitionedconsumption . this prevents hashbuilderoperator from finishing . <nl> this was causing some tests to hang in testdistributedspilledqueries .",1618958215,reusing node ids simplifies tracking of plan nodes throughout the planning phase,0.9697351455688477
pentaho_pentaho-kettle/7925,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) <para-sep> fileobject.isreadable wrongly returns true in windows file system even if not readable <nl> fileobject.isreadable wrongly returns true in windows file system even if not readable,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) .,1617984611,adding new pdi client type ' other ' with a configurable client id,0.8294548988342285
elastic_elasticsearch/73610,"osstats must be lenient with bad data from older nodes <para-sep> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here . <nl> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here .","we 've had a series of bug fixes for cases where an gives negative values , most often just , to the class . we added assertions to catch cases where we were initializing with bad values . unfortunately , these fixes turned to not be backwards-compatible . in this commit , we simply coerce bad values to 0 when data is coming from nodes that do n't have the relevant bug fixes .",1622558206,"the encrypted repository is usable to the extent that the feature can greatly benefit from testing as part of snapshot builds on cloud . <nl> after this pr is merged to the feature branch , my plan is to raise the pr that merges the feature branch to master , without asking for any other reviews .",0.8907040953636169
ballerina-platform_ballerina-lang/30655,use the cast type to type-check the expression <cm-sep> fix tests <cm-sep> add tests <para-sep> forcefully clone the expression since it may clash with the clone of type cast expression type checking . <nl> test cases for dependently typed function signatures derived from contextual type .,"tried fixing the deviations with type cast expressions too , but ran into issues since does n't cover all cases yet .",1621367764,same visibility is enforced for interface method and it 's implementation in non-abstract objects . <nl> visibility modifiers are allowed for object-outer functions .,0.9453253149986267
netty_netty/11197,re-enable running openssl ( shared ) tests on ci . <nl> motivation : . <nl> it turned out we didnt run the openssl tests on the ci when we used the non-static version of netty-tcnative . <nl> modifications : . <nl> - upgrade netty-tcnative to fix segfault when using shared openssl <nl> - adjust tests to only run session cache tests when openssl supports it <nl> - fix some more tests to only depend on keymanager if the underlying openssl version supports it . <nl> result : . <nl> run all openssl test on the ci even when shared library is used <para-sep> ensure we support tlsv1.0 <nl> this only really works when the keymanagerfactory is supported as otherwise we not really know when we need to provide a cert . <nl> this only really works when the keymanagerfactory is supported as otherwise we not really know when we need to provide a cert . <nl> this only really works when the keymanagerfactory is supported as otherwise we not really know when we need to provide a cert . <nl> this only really works when the keymanagerfactory is supported as otherwise we not really know when we need to provide a cert .,motivation : . <nl> it turned out we didnt run the openssl tests on the ci when we used the non-static version of netty-tcnative . <nl> modifications : . <nl> - upgrade netty-tcnative to fix segfault when using shared openssl <nl> - adjust tests to only run session cache tests when openssl supports it <nl> - fix some more tests to only depend on keymanager if the underlying openssl version supports it . <nl> result : . <nl> run all openssl test on the ci even when shared library is used,1619511866,opensslsession.getlocalcertificates ( ) and getlocalprincipal ( ) must return null on client side if mtls is not used . <nl> motivation : . <nl> opensslsession.getlocalcertificates ( ) and getlocalprincipal ( ) must return null on client side if mtls is not used as stated in the api documentation . at the moment this is not always the case . <nl> modifications : . <nl> - ensure we only return non-null if mtls is used <nl> - add unit tests . <nl> result : . <nl> follow sslsession api contract,0.9483129382133484
confluentinc_ksql/6979,fix tests after streams change <cm-sep> fix create or replace <cm-sep> fix more things in the build <para-sep> initialize the first kafkastreams <nl> initialize the first kafkastreams,fixes the build to make sure that state dirs are properly closed . <nl> ran locally .,1612895795,when using schema registry for avro format we need to clean up the schemas for the internal topics when a query is terminated . also we need to delete the schema for dropped stream/tables .,0.907446026802063
ballerina-platform_ballerina-lang/29790,"refactor binary expression evaluation utils and runtime helpers <cm-sep> refactor relational expression support for array types <cm-sep> add integration tests for new ordered types <para-sep> tests the relative order of two values . there must be an ordered type to which the static type of both operands belong . the static type of the result is boolean . orderedtype : := ( ) |boolean|int|float|decimal|string|orderedtype [ ] <nl> debugger runtime helper classes <nl> ballerina runtime helper classes <nl> java runtime helper classes <nl> todo - add proper syntax for for int and float , after fixing runtime exception . <nl> comparison between int and string comparison between int and float ( disallowed by the latest spec ) <nl> nil - nil <nl> boolean - boolean <nl> string - string <nl> boolean [ ] - boolean [ ] <nl> int [ ] - int [ ] <nl> float [ ] - float [ ] <nl> decimal [ ] - decimal [ ] <nl> string [ ] - string [ ] <nl> nil - nil <nl> boolean - boolean <nl> string - string <nl> boolean [ ] - boolean [ ] <nl> int [ ] - int [ ] <nl> float [ ] - float [ ] <nl> decimal [ ] - decimal [ ] <nl> string [ ] - string [ ] <nl> expression > expression note : := not required to test all the possibilities in here , as ' x > y ' is processed as ' ! ( x < = y ) ' by the evaluation engine . int - int <nl> note : := not required to test all the possibilities in here , as is processed as ' ! ( x < y ) ' by the evaluation engine .",- adds integration tests to cover new spec changes .,1617342835,"- added http status code as a tag for http metrics . <nl> - add counters http status code ranges : 1xx , 2xx , 3xx , 4xx and 5xx . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9505320191383362
vespa-engine_vespa/16986,"add archive access role to tenant <para-sep> an iam role which is allowed to access the s3 ( log , dump ) archive ) * /",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1615906843,- expose the maximum quota usage rate in the configuration server <nl> - query for the quota usage rate right after deploy in the controller <nl> - store the quota usage rate together with the deployment information in zk,0.9628267288208008
netty_netty/11261,ensure we fail if native lib can not be loaded on macos . <nl> motivation : . <nl> sha fixed a regression which caused the native resolver code to not be loaded but this was not reported by the tests . <nl> modifications : . <nl> adjust tests to actually fail the build if we cant load the native lib . <nl> result : . <nl> ensure we do n't introduce another regression in the future,motivation : . <nl> sha fixed a regression which caused the native resolver code to not be loaded but this was not reported by the tests . <nl> modifications : . <nl> adjust tests to actually fail the build if we cant load the native lib . <nl> result : . <nl> ensure we do n't introduce another regression in the future,1621275991,"those who need 'origin ' or 'sec-websocket-origin ' headers should provide them explicitly , like it is stated in websocket specs . <nl> e.g . through custom headers : . <nl> * remove enforced origin headers . <nl> * update tests .",0.8052061796188354
apache_incubator-pinot/6880,fix validation logic for distinct queries,"for distinct queries , broker will verify that all order-by columns ( if exist ) should be included in the distinct columns . however the existing logic is wrong : it verify that , should be . <nl> this bug was not caught by unit test since the unit test only test invalid queries . i add some valid query cases .",1620243758,this flag will be used to recognize a mode in the adapter to handle these kind of metrics . added the flag in the admin ui .,0.9072839021682739
eclipse-openj9_openj9/12676,ddr code generators : add support for optional fields . <nl> * add option to limit available methods . <cm-sep> update ddr code to handle exceptions for optional fields . <para-sep> this file lists fields used in hand-written ddr_vm java source code . those that have not always been defined must provide their type here . non-comment lines must have this form : type.field = required | <nl> no required or optional fields for this structure . <nl> mark required fields and remove corresponding entries from infomap . <nl> no auxilliary information for this field . <nl> remaining entries in infomap are for missing fields . <nl> extend fileimageinputstream to avoid loading the awt shared library . <nl> write the beginning of a method . the return value indicates whether the caller should produce the body of the method . <nl> accessors for idata and udata already return objects <nl> this option was specified or has a default * / <nl> a value is not required for this option * / <nl> the 'realheaptop ' field should exist given the earlier algorithm version check <nl> j9shroffset did n't exist in the vm that created this core file even though it appears to support a multi-layer cache . <nl> j9shroffset did n't exist in the vm that created this core file even though it appears to support a multi-layer cache . <nl> return the same as sh_cachemap : :getdatafrombytedatawrapper ( const bytedatawrapper bdw ) / <nl> j9shroffset did n't exist in the vm that created this core file return ( ( u_8 ) ( bdw ) ) + sizeof ( bytedatawrapper ) / <nl> j9shroffset did n't exist in the vm that created this core file even though it appears to support a multi-layer cache . <nl> j9shroffset did n't exist in the vm that created this core file even though it appears to support a multi-layer cache . <nl> j9vtableheader should have the 'size ' field given the algorithm version check above <nl> the 'size ' field should be present in a vm that supports mixed reference mode <nl> the 'size ' field should be present in a vm that supports mixed reference mode <nl> the 'extendedruntimeflags2 ' field should be present in a vm that supports mixed reference mode <nl> the 'clazz ' field should be present in a vm that supports mixed reference mode <nl> j9shroffset did n't,"a new file is introduced which must mention any field accessed in hand-written ddr code . fields which have always been present are marked as 'required ' , for others , their type must be provided . the generated methods for optional fields may throw which must be caught and dealt with appropriately . <nl> the updated build process compiles that hand-written ddr code with only those fields so using a new field will require updating . no new , required fields should be listed there . if a field is removed from vm code , it must be then",1620839647,* provide object names ( as strings ) to <nl> * defer creation of objects <nl> * refactor notifications through <nl> * remove useless class <nl> * defer loading of the <nl> * replace lambdas with anonymous classes <nl> * do n't force loading unnecessarily <nl> * do n't start prematurely <nl> * use where appropriate <nl> * do n't pre-allocate a memoryusage instance in .,0.9712216258049011
apache_kafka/10676,"do the renaming <para-sep> the name of the topology this builder belongs to , or null if none <nl> todo : the topologymetadata class is filled in by pt .","renames the existing class + interface to , since that more closely matches what it is/is used for . then introduces a new class which includes basic metadata such as the topic group id and the namedtopology that this subtopology belongs to , if any . <nl> also adds an internal class to expose the of a taskid outside the package . i realized taskid is part of the public api , so we ca n't just add a public getter method . i made the field protected and removed the getter/moved it to the namedtaskid class . <nl> there",1620790889,"this is a general change and is re-requisite to allow streams benchmark test with different streams tests . for the streams benchmark itself i will have a separate pr for switching configs . details : . <nl> 0. create a ' streams.properties ' file under persistent_root before all the streams test . for now it will only contain a single config of state.dir pointing to persistent_root . <nl> 0. for all the system test related code , replace the main function parameter of state.dir with propsfilename , then inside the function load the props from the file and apply overrides",0.9613519906997681
apache_kafka/10217,: ensure mm2 creates topics with source topic configs <para-sep> get source and target topics with respective partition counts <nl> compute existing and new source topics <nl> create new topics <nl> compute topics with new partitions <nl> create new partitions,"mm2 creates new topics on the destination cluster with default configurations . it has an async periodic task to refresh topic configurations from the source to destination . however , this opens up a window where the destination cluster has data produced to it with default configurations . in the worst case , this could cause data loss if the destination topic is created without the right . <nl> this patch fixes the above issue by ensuring that the right configurations are supplied to when mm2 creates topics on the destination cluster .",1614316848,add log4j entry summarizing the assignment ( prev owned and assigned ) at the consumer level .,0.941927433013916
ballerina-platform_ballerina-lang/28463,fix spec deviation in table member access,"according to the spec , .",1612691556,"> * fix the issue of functions not invoking in function , and enable the tests .",0.9391942620277405
apache_druid/10884,"reload segment usage when starting the process <cm-sep> doc <para-sep> if the segment is already downloaded on disk , we just update the current usage <nl> reserves space to store the given segment , only if it has not been done already . this can be used when segment is already downloaded on the disk . we also account for segment usage even if available size dips below 0. such a situation indicates a configuration problem or a bug and we do n't let segment loading fail because of this . <nl> already reserved <nl> this class includes tests that cover the storage location layer as well . <nl> write some segments to file bypassing loaddrophandler <nl> start the load drop handler <nl> verify the expected announcements <nl> make sure adding segments beyond allowed size fails <nl> clearing some segment should allow for new segments","when a historical process is restarted , we lose the accounting being kept by the class . this implies that could reserve space for a segment even if the cache is completely full . since after restart , thinks that current usage is zero",1613126846,initializing a is not cheap ; it includes parsing an expression . the should be reused in stream indexing rather than recreating it for every stream chunk . batch ingestion does n't have this issue since it decorates an with a which is a reader for the entire input data . <nl> also fixed json serde of,0.979000449180603
Alluxio_alluxio/12875,"add mergejournalcontext <cm-sep> add merge function <para-sep> context for merging journal entries together for a wrapped journal context . this is used so that we can combine several journal entries into one using a merge function . this prevents partial writes of these journal entries causing system to be left in an inconsistent state . for example , createfile without completing the file . note that these journal entries are not persisted and they will only be persisted when close is called on them . closing the mergejournalcontext will also not close the enclosed journal context . <nl> it will log a warning if the number of buffered journal entries exceed 0 <nl> note that we do not close the enclosing journal context here <nl> merge inode entry with subsequent update inode and update inode file entries . <nl> file id : index in the newentries , inodefileentry <nl> use the old entry as a placeholder , to be replaced later <nl> replace the old entry place holder with the new entry , to create the file in the same place in the journal <nl> we do not want to close this wraprpccontext because it uses elements from another context","before this change , syncmetadata writes an inode journal entry and then two additional updateinode entries to complete the file . this combines three entries into one so that we do not have a failure mode where the first inode entry is inserted and incomplete files are left behind .",1613659142,sometimes user wants to preserve the original attributes of files and directories when using command . this change add a new option to the command to enable such functionality . note that user will need to have the required permissions to perform the operation .,0.9585756063461304
neo4j_neo4j/11658,log crash pointer cleanup only once per subindex and include part name . <nl> on recovery every native index do internal cleanup and report result to logger . <nl> logger for lucene+.0 and lucene+.0 where registered with the <nl> same tag and so the same line was logged twice for every sub index . <nl> now also include which sub index the report is for .,log crash pointer cleanup only once per subindex and include part name . <nl> on recovery every native index do internal cleanup and report result to logger . <nl> logger for lucene+.0 and lucene+.0 where registered with the <nl> same tag and so the same line was logged twice for every sub index . <nl> now also include which sub index the report is for .,1524729355,changelog : now reports different error codes : <nl> - code : backup failed to run <nl> - code : backup succeeded but consistency check failed to run <nl> - code : backup succeeded but consistency check found inconsistencies,0.9456048011779785
ballerina-platform_ballerina-lang/29114,set default load value for decimal,this pr fixes the spec violation on loading default value for decimal .,1615406042,this pr changes this behavior to ensure that the tests are not compiled when the _ -- skip-tests_ flag is used . <nl> the existing implementation compiles the tests in the run command as well . this is also removed through this pr . <nl> an integration test is added to check if the compilation of tests is skipped when the _ -- skip-tests_ flag is used in the build command . <nl> - build command - compiles test cases when _ -- skip-tests_ flag is not used <nl> - build command - does not compile test cases when _,0.9243785738945007
confluentinc_ksql/7601,drop stream for persistent query does n't always drop underlying query <para-sep> nothing to do with unknown query types <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given <nl> when/then <nl> given <nl> when/then,i.e . <nl> the should have been terminated automatically with drop stream . <nl> the problem was in that was removing query references from both and mapping variables . this pr now removes the references from the right map variable . <nl> unit and integration tests are expected for any behavior changes._ .,1622128347,"add config for specifying the maximum number of persistent queries that may run simultaneously , in interactive mode . ( headless mode is unaffected . ) defaults to no limit . <nl> the added config is a compatabilitybreakingconfigdef so that each query is associated with the value of the limit at the time that the query was acknowledged . as a result , when queries are restored from the command topic ( e.g. , after a server is bounced ) , the set of previously running queries will be restored , regardless of whether the value of the newly added",0.9522898197174072
elastic_elasticsearch/73837,"the recent upgrade of the azure sdk has caused a few test failures that <nl> have been difficult to debug and do not yet have a fix . we need to wait <nl> for a fix for that issue , so this reverts commit <nl> sha . <para-sep> we have to rewrite the service classes to make them public to avoid granting the permission ' java.lang.reflect.reflectpermission ' ' newproxyinpackage ' to this plugin . <nl> eclipse ca n't pick up the shadow dependency so we point it at something so it can compile things . <nl> from com.ctc.wstx.shaded.msv_core.driver.textui.driver ( woodstox-core )","the recent upgrade of the azure sdk has caused a few test failures that <nl> have been difficult to debug and do not yet have a fix . we need to wait <nl> for a fix for that issue , so this reverts commit <nl> sha .",1623071411,"this change adds an extra piece of information , <nl> limits.total_ml_memory , to the ml info response . <nl> this returns the total amount of memory that ml <nl> is permitted to use for native processes across <nl> all ml nodes in the cluster . some of this may <nl> already be in use ; the value returned is total , <nl> not available ml memory .",0.8960719108581543
Alluxio_alluxio/13175,add rocksdb.open retry logic <para-sep> sometimes the previous terminated process 's lock may not have been fully cleared yet retry until timeout to make sure that is n't the case,"when doing a quick restart of an alluxio master process with rocksdb , the previous rocksdb may not have been fully cleared yet if the previous process did n't terminate gracefully . add a timeout around connection so the previous connection lock times out before .",1617642614,create extensions directory if does not exist,0.8781768679618835
elastic_elasticsearch/73344,minor refactor so uri_parts can be exposed in painless,adds a method similar to the one in the lowercase processor so that the uri parts processor functionality can be exposed in painless .,1621886646,this pr allows a datafeed to be assigned to a node if only one index pattern has concrete indices .,0.8284164667129517
apache_druid/10869,"allow for empty keys in hash map <para-sep> a map can have empty string keys e.g . by returning empty ignored list for map , we can allow for empty string keys in a map . <nl> we will allow serialization on empty properties .","there is also an alternate implementation as follows where we add following method to and remove . <nl> though , it will throw an exception if the user tries to pass input with values for properties that were annotated with jacksoninject . as opposed to the current world , where such erroneous input is silently ignored",1612876661,"expands the behavior of the archiver to handle when things do n't actually move . in such a scenario metadata segment update actions are not attempted . <nl> if an archiver implementation does not honor the new interface contract , then the prior behavior is still preserved .",0.9794329404830933
apache_flink/16128,rank ttl should use enabletimetolive of state instead of timer <para-sep> do n't flush values to state if cause is ttl expired,"rank ttl should use enabletimetolive of state instead of timer . <nl> we should get rid of . <nl> - use guava lru cache in rank functions for expire ttl . <nl> - use enabletimetolive of state instead of timer . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) no <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) no <nl> - the serializers",1623309096,"for multi-gate inputs , there existed inconsistent offset handling of barrierhandlers and checkpointedinputgates for unaligned checkpoints . this pr unifies the creation of barrierhandlers and checkpointedinputgate . <nl> - use the non-unioned ( indexed ) inputgates as the main information source that is needed to create handlers . <nl> - unioned input gates are only used to create the checkpointedinputgate . <nl> covered by existing ( modified ) tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class",0.9608414173126221
jenkinsci_jenkins/5377,fix the 'new view ' link to correctly work with folders <para-sep> do not show the action if the viewgroup is not modifiable <nl> geturl returns the path from the root ( without the context and no leading slash ) we need to add the slash so that this is not relative to the current url but to the context,the new view link was always pointing to the root newview and so could not create new views in folders . <nl> * ' new view ' link takes into account the current folder when creating new views,1616702176,( correspondingly for vs . . ),0.9498283863067627
apache_pulsar/10708,"on multi-topic consumer , we should n't keep checking the partitioned metadata <para-sep> the topic was initially partitioned but then it was deleted . we keep it in the topics <nl> remove the consumers that belong to the deleted partitioned topic <nl> simulate non partitioned topics <nl> getpartitionedtopicmetadata should have been called only the first time , for each of the 0 topics , but not anymore since the topics are not partitioned . <nl> a topic with ' 0 ' partitions is treated like non-partitioned topic .","when using a multi-topic consumer , either through the regex or by passing a list of topics , we are ending up checking the partitioned topic metadata every 0 min , even if the topics are not partitioned . <nl> we do n't need to re-check that information if the topics are not partitioned . also , this can be causing a lot of read traffic on zk since we keep checking that ' partitioned-metadata ' that these topics do n't have and , in version , this information is not cached in brokers when the metadata is not found",1622003100,"the default in testcontainers does n't include the exit code of running a command in a test container . <nl> - add a class to represent the result of executing a command in a container , including exitcode , stdout and stderr <nl> - improve the existing util method in to return <nl> - improve all the integration tests on validating exit codes before validating outputs",0.9429202675819397
Graylog2_graylog2-server/10119,"adding test case to check if index optimization throws npe . <cm-sep> if request config is , create new one instead of copying . <cm-sep> check it is .","this made things much worse , by trying to copy a instance that is in this situation . this results in an npe and is aborting the index optimization job before it can perform any action . <nl> this change is now checking if the instance is and instantiates a new one in this case instead of trying to copy it .",1614015035,"before this change , any alert conditions associated with a stream were <nl> cloned identically ( including using the same id ) when cloning a stream . <nl> this was leading to a bug , where the alert condition was shown as being <nl> associated with the source of the clone process instead of the target . <nl> with this change , the alert condition is recreated during cloning , <nl> including generating a new id for it . <nl> ( cherry picked from commit sha )",0.8780240416526794
pentaho_pentaho-kettle/7719,"performance of the ' write to log ' step when the ' print headers ' checkbox is activated 5x slower since version release <para-sep> sometimes there 're so many lines to log at one time that the application goes unresponsive until all log entries are handled ... let 's limit the lines handled , leaving the rest for the next time the timer fires ... <nl> the formatting may have change the original text and its length <nl> the maximum size of the log buffer",performance of the ' write to log ' step when the ' print headers ' checkbox is activated 5x slower since version release . <nl> these changes are to improve the performance and responsiveness of the logging tab .,1602232753,"verified and tested locally , works as expected . pdi-service 's endpoint now takes two new parameters and .",0.9126940369606018
vespa-engine_vespa/17305,"fix todo <cm-sep> extract method <cm-sep> use supplied config <cm-sep> log at lower level <cm-sep> fix typo in class name <cm-sep> cleanup tests a bit <para-sep> let one node have a different release tag . <nl> 0 distribution nodes should have green tag on release1 . <nl> 0 distribution node should have warning on release1bad . <nl> 0 storage node should should have warning on release ' not set ' . <nl> this should not show up , as it is down <nl> this should show up , as down nodes can be turned to maintenance <nl> this should not show up , as we can not turn a down node retired <nl> this should not show up , as it is down <nl> note : different semantics than fleetcontrollertest.setwantedstate",minor cleanups while reading code . no functional changes .,1617865077,"this should n't have an functional changes , just some cleanup refactoring to make it easier to reuse this for future proxy api .",0.9221104383468628
apache_incubator-pinot/6846,fix issue - no authentication is required for get table endpoint <para-sep> validate if user has permission to change the table state,this pr fixes this issue and validate permission only for update case and for there wo n't be any authentication when it 's used for getting table config .,1619485637,deleting temp files before loading the segment,0.8587578535079956
OpenAPITools_openapi-generator/8817,create python abstract base class <cm-sep> refactor abstractpythonconnexionservercodegen <para-sep> local variable name used in api methods ( endpoints ),- create python abstract class <nl> - minor code format change ( java files ) <nl> - only change in the samples ( output ) is the addition of in the model 's properties .,1614137819,major refactoring of the elm generator . see this new guide for more background . <nl> and would it be possible to merge this without squashing ?,0.9507967233657837
quarkusio_quarkus/17165,introduce uberjarmergedresourcebuilditem and uberjarignoredresourcebuilditem . <nl> ( cherry picked from commit sha ) <cm-sep> : new is deprecated . <nl> ( cherry picked from commit sha ) <cm-sep> fix last modified and cl for memory resources . <nl> ( cherry picked from commit sha ) <para-sep> ignore resources when building an uber jar <nl> merge duplicate resources from multiple jars when building an uber jar <nl> todo : handle merging of xmls <nl> used in uberjarmergedresourcebuilditemtest <nl> meta-inf/cxf/cxf.fixml should be present in the cxf-rt-transports-http and cxf-core jars <nl> meta-inf/cxf/bus-extensions.txt should be present in the cxf-rt-transports-http and cxf-core jars,"please do n't merge , i will merge it myself .",1620807742,"please do n't merge , i will merge it myself .",0.974432647228241
apache_druid/11056,"add paramter to loadstatus api to compute underdeplication against cluster view . <nl> this change adds a query parameter to loadstatus apis <nl> that if specified have the coordinator compute undereplication for segments based <nl> on the number of services available within cluster that the segment can be replicated <nl> on , instead of the configured replication count configured in load rule . a default <nl> load rule is created in all clusters that specified that all segments should be <nl> replicated 0 times . as replicas are forced to be on separate nodes in the cluster , <nl> this causes the loadstatus api to report that there are under-replicated segments <nl> when there is only 0 data server in the cluster . in this case , calling loadstatus <nl> api without this new query parameter will always result in a response indicating <nl> under-replication of segments","this change adds a query parameter to loadstatus apis <nl> that if specified have the coordinator compute undereplication for segments based <nl> on the number of services available within cluster that the segment can be replicated <nl> on , instead of the configured replication count configured in load rule . this query <nl> parameter is only available when also requesting full loadstatus . a default load rule is <nl> created in all clusters that specified that all segments should be replicated 0 times . as <nl> replicas are forced to be on separate nodes in the cluster , this causes",1617216406,this patch properly applies the requested extractionfn to missing columns . <nl> it 's important when the extractionfn maps null to something other than null .,0.9758670926094055
apache_flink/16271,"remove raw casts in continuousfilereaderoperator . <para-sep> nothing is owned by chainingoutput and should be closed , see <nl> * /","currently , closes the following chained operator on reaching . <nl> - make sure that everything is closed where it 's owned - not more or less . <nl> added continuousfilereaderoperatoritcase . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no",1624516961,"- register it in org.apache.flink.runtime.taskmanager.task.task . <nl> this change added a test and can be verified as follows : <nl> - org.apache.flink.runtime.taskmanager.tasktest.testbackpressuremetric . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos ,",0.947738528251648
ballerina-platform_ballerina-lang/28809,"improve variable visibility test <para-sep> todo - enable test local variable visibility test at the beginning of the main ( ) method ( should be 0 ) . assert.assertequals ( localvariables.size ( ) , 0 ) ; <nl> global variable visibility test at the beginning of the main ( ) method ( should be 0 ) . <nl> debug point variable should be visible when we go to the next line ( step_over ) . <nl> local variable visibility test inside statement . <nl> local variable visibility test inside statement . <nl> local variable visibility test inside statement . <nl> local variable visibility test inside loop . <nl> local variable visibility test inside loop . <nl> todo - enable test assert.assertequals ( localvariables.size ( ) , 0 ) ; <nl> local variable visibility test inside statement . <nl> global variable visibility test outside main ( ) method . <nl> global variable visibility at the last line of the main ( ) method . <nl> todo - enable test debugtestrunner.assertvariable ( globalvariables , ' red ' , ' red ' , ' string ' ) ; debugtestrunner.assertvariable ( globalvariables , ' blue ' , ' blue ' , ' string ' ) ; <nl> enums <nl> configurable variables <nl> variable visibility in 'if ' statement <nl> variable visibility in 'else ' statement <nl> variable visibility in 'else-if ' statement <nl> variable visibility in 'while ' loop <nl> variable visibility in 'foreach ' loop <nl> variable visibility in 'match ' statement",here we have to check variable count outside control flows . that is all variables should be visible when the debug navigator within the control flow .,1613981530,"with this pr following changes are added . <nl> - support for blob data retrieval from datatable . <nl> - support for column alias with the new datatable api . <nl> - improvements for test cases including blob support , column alias , date time out parameters etc",0.919539749622345
grpc_grpc-java/7876,implement xdsservingstatuslistener as per the new xds server grfc <para-sep> * / <nl> callback invoked when server begins serving . * / <nl> callback invoked when server is forced to be ' not serving ' due to an error . <nl> default implementation that logs at warning level . * / <nl> log calls to onserving ( ) following a call to onnotserving ( ) at warning level . * /,note that the server restart part is coming as a separate pr .,1612801464,"terminology : <nl> - : cds cluster <nl> - : eds service . maybe null . multiple clusters can point a client to the same cluster service . also named eds service . <nl> clarification on load reporting : <nl> - similar to , each channel should have at most one lrs stream based on the current design of using a single management server . that is , each channel should have a single lrs client that is responsible for reporting loads for all clusters . <nl> - in lrs protocol , the server tells the client what _clusters_ to",0.9598785638809204
OpenAPITools_openapi-generator/8584,fix auto-generated r doc <para-sep> required properties first <nl> optional properties second,fix auto-generated r doc by having required parameters first and then optional parameters second .,1612062195,this addition to the rust-server generator enables the use of text/html responses as plaintext . <nl> i 've added an html endpoint to the sample to demonstrate that this works ( and fixed the problem that that uncovered ) .,0.8750073313713074
apache_pulsar/10033,"support start from separate messageid for each topic/ partition <para-sep> get middle msg from <nl> get last msg from <nl> get first msg from <nl> the function input is topic+partition . the return value is the seek position/timestamp of the current partition . if returns null , the current partition will not do any processing . <nl> reset the subscription associated with this consumer to a specific message id asynchronously . the function input is topic+partition . the return value is the seek position/timestamp of the current partition . if returns null , the current partition will not do any processing . <nl> reset the subscription associated with this consumer to a specific message id .",currently in multitopicsconsumerimpl the api allow to ‘ setstartmessageid ’ only from single message id and this apply to all consumers in the multitopicsconsumerimpl . <nl> it is possible to add start message per partition / topic .,1616600382,"if the topic has relatively low traffic , the de-duplication cursor will not move . this can cause messages that are not able to be deleted based on the retention policy . we should add a policy to take de-duplication snapshots based on time .",0.9789384007453918
vespa-engine_vespa/17764,support all sub-classes of 'response ' in security response filters . <nl> previously security response filters were just skipped if a request <nl> handler or ( security ) request filter returned a response that was not a <nl> sub-class of httpresponse . <para-sep> helper for encoding/decoding cookies on request/response . <nl> a separate adapter is required as discfilterresponse will invoke methods from servletorjdischttpresponse parameter in its constructor,previously security response filters were just skipped if a request <nl> handler or ( security ) request filter returned a response that was not a <nl> sub-class of httpresponse . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620310307,"we have seen 0 deployments running at the same time , which is more than the config servers can handle .",0.9556704163551331
hazelcast_hazelcast/18568,remove printing the license key while starting instance with overriding config,here is the fixed version of related log :,1618915253,i have also checked yaml . it is not valid to give empty name <nl> on yaml . so there is no change made for that .,0.8435296416282654
confluentinc_ksql/7189,"rename new to new-project <cm-sep> enforce version bounds <cm-sep> support help flag as command option <cm-sep> support global help flags <cm-sep> allow specifying config file after command name <cm-sep> unit test <cm-sep> spotbugs <para-sep> throw original parse exception <nl> remove stack trace for improved readability <nl> allows users to specify config file before the name of the command <nl> allows users to specify config file after the name of the command <nl> hide this version of the config file option so only the version above appears in help text , to avoid duplication <nl> returns the source description , assuming the source exists . <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : no exception <nl> when : <nl> then : no exception <nl> use to create directory structure <nl> use to create metadata stream and table <nl> when : use to clean up metadata stream and table <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> a single query writing to the table will still be dropped , even if the stream does n't exist . we could change this in the future but it 's an unlikely ( and unexpected ) edge case that does n't seem too important . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","this pr includes various ux improvements to the tool : <nl> - and are now supported ( in addition to ) . similarly , and are now supported , in addition to . <nl> - the flag is now accepted after the command name , in addition to before . <nl> - exceptions thrown when commands fail to parse arguments no longer print stacktraces ( in order to clean up the error messages that users see ) . <nl> - three commands have been renamed in order to disambiguate and clarify their behaviors : is now , is now ,",1615356039,the idea here is that the call should make it clear what properties are at their default value . we already have a marker for . i 've added a new marker for those properties that are not set via server config or have local overrides . <nl> so you now get an output like : . <nl> not sure if we should also add a tag too ... ?,0.9756351113319397
elastic_elasticsearch/73239,"run checkindex on metadata index before loading . <nl> the metadata index is small and important and only read at startup . <nl> today we rely on lucene to spot if any of its components is corrupt , but <nl> lucene does not necesssarily verify all checksums in order to catch a <nl> corruption . with this commit we run on the metadata index <nl> first , and fail on startup if a corruption is detected . <para-sep> loads the available on-disk cluster state .","the metadata index is small and important and only read at startup . <nl> today we rely on lucene to spot if any of its components is corrupt , but <nl> lucene does not necesssarily verify all checksums in order to catch a <nl> corruption . with this commit we run on the metadata index <nl> first , and fail on startup if a corruption is detected .",1621430982,this pr ensures that api key role descriptors are always rewritten to a target node compatible format before a request is sent .,0.9378299713134766
apache_pulsar/10586,fix npe when ack grouping tracker checks duplicated message id,"recently i encountered the following npe but it 's hard to reproduce . <nl> from the stack we can see npe was thrown when an ack grouping tracker checks duplicated message id . the tracker maintains a field that has a type field . however , could be null after or just was created with a null . we should check null here . <nl> - check null in and returns false if it 's null , then the tracker will do nothing in . <nl> - check null in and throw if the compared object is null . <nl>",1620978313,"however , in workergroup.shutdowngracefully ( ) , it will call servercnx # channelinactive method . the code with bug as follow . <nl> it does n't check whether is null and call may cause nullpointerexception . <nl> 0. in servercnx # channelinactive , check whether is null before call onconnectionclosed method .",0.8964544534683228
confluentinc_ksql/6762,"set internal key serde features when necessary <para-sep> if none exist , assume non-windowed since that would mean that both sources were of none format , which does n't support windowed operations <nl> specifically , we want to ensure that the key format is ( 0 ) not none and ( 0 ) explicitly sets the wrapping if it contains only a single column . this method ensures that both of these are eagerly set . note that while it is safe to call this method multiple times ( it is idempotent ) , it should be called before we build the execution steps to make sure that we never serialize an execution step with a single key column and no wrapping serde features . to achieve this , we 've audited the schemakstream , schemaktable and schemagroupedkstream classes to ensure that anytime a key is changed we properly set the key format . <nl> it is possible that the source format was either multi-key or no-key , in which case there would not have been a wrapping configuration specified - we should specify one here <nl> use sanitizekeyformat ( true ) because we do n't yet support partition by or join on multi-column keys <nl> we do n't yet support ' real ' multi-column group bys so passing in true here to sanitizekeyformat <nl> use sanitizekeyformat ( true ) because we do n't yet support partition by or join on multi-column keys <nl> since tables must have a key , we know that the keyformat is both not none and has at least one column ; this allows us to inherit the key format directly ( as opposed to the logic in schemakstream ) <nl> when : <nl> then : <nl> given :","pipe the key format that is determined from the repartition step into the select key , instead of creating it with empty serde features . this means that we will ensure that the serde features ( wrapping/unwrapping ) behave the way we want them to . <nl> this is also a minor breaking change . joins across different window types will no longer work . i think this is a good thing because the previous logic was somewhat insane and allowed you to join windows if they were semantically different but byte-equivalent . <nl> qtt testing/unit testing . i also",1607704651,"at present and udafs are special cased . this special casing was not being applied to pull queries . this change corrects this . <nl> consider : . <nl> before this change the pull query would return values for and , even though the data was correctly populated in the topic . with this change the correct values for and are returned . <nl> the main fix is in , which now applies a suitable call that will apply the special processing to any pull query . <nl> adding the call highlighted that the wrong key was being passed to",0.9699979424476624
apache_flink/15563,fix unstable localexecutoritcase.testbatchqueryexecutionmultipletimes [ planenr : old ] <para-sep> * / <nl> start listener thread <nl> start listener thread,"fix unstable localexecutoritcase.testbatchqueryexecutionmultipletimes [ planner : old ] . <nl> considering we have introduced new sql-client testing framework and we are going to remove old planner in the next version , it 's better to remove the unstable test . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths (",1618215902,"please note i am a current datadog employee . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",0.88801509141922
elastic_elasticsearch/74490,"the test searchablesnapshotspersistentcacheintegtests <nl> testpersistentcachecleanupafterrelocation rarely fails <nl> after the snapshot is mounted for the first time and the <nl> test waits for the persistent cache to have at least 0 doc : . <nl> if ( indicesservice.hasindex ( mountedindex ) ) { <nl> assertbusy ( ( ) - > { <nl> cacheservice cacheservice = internalcluster ( ) .getinstance ( ... ) ; <nl> cacheservice.synchronizecache ( ) ; . <nl> > > > assertthat ( cacheservice.getpersistentcache ( ) .getnumdocs ( ) , greaterthan ( 0l ) ) ; <nl> datanodes.add ( node ) ; <nl> } ) ; <nl> } . <nl> this situation happens when a low number of docs are <nl> ndexed and one ( or more ) of the 0 shards receive no <nl> documents . <nl> this commit changes the test to index more documents <nl> ( 1k+ ) so that all shards have documents , and thus <nl> cache files to synchronize and to make persistent in <nl> the persistent cache .","the test searchablesnapshotspersistentcacheintegtests <nl> testpersistentcachecleanupafterrelocation rarely fails <nl> after the snapshot is mounted for the first time and the <nl> test waits for the persistent cache to have at least 0 doc : . <nl> this situation happens when a low number of docs are <nl> ndexed and one ( or more ) of the 0 shards receive no <nl> documents . <nl> this commit changes the test to index more documents <nl> ( 1k+ ) so that all shards have documents , and thus <nl> cache files to synchronize and to make persistent in <nl> the persistent cache .",1624454828,this change fixes problem with where watcher job can be missing because of watcher reloading which leads to tests failures . <nl> fix is to use the same technique as in ( reuse existing map instead of creating new one ) .,0.8704933524131775
neo4j_neo4j/11629,"preserve step down term when old leader steps down in new term <para-sep> produces a new leaderinfo object for a step down event , setting memberid to null but maintaining the current term . <nl> allows listeners to handle a leader step down for the given term . note : actions taken as a result of a step down should typically happen before any actions taken as a result of the leader switch which has also , implicitly , taken place . <nl> standard catch-all method which delegates leader events to their appropriate handlers in the appropriate order , i.e . calls step down logic ( if necessary ) befor leader switch logic .","the reason being that there are several distinct types of step down trigger : . <nl> 0. a leader _a_ may step down because they have n't received heartbeats within a timeout . in this event , the which has the term for which _a_ was leader and is stepping down . <nl> 0. a leader _b_ may step down because they have received a heartbeat with a later term than their own . in this event , the which has that later term . <nl> the topology service was detecting step downs and writing for the given database name",1524473527,and underlying gbptree through monitors .,0.9618825912475586
apache_incubator-pinot/6251,make default operator for multi-term and phrase text <nl> index queries configurable <para-sep> test for the index configured to use and as the default conjunction operator <nl> test for the index configured to use and as the default conjunction operator <nl> test for the index configured to use and as the default conjunction operator,"multi term or phrase queries for text index like the following use implicit or operator ( lucene default ) . <nl> - where text_match ( col , 't1 t2 \ ' p1\ ' \ ' p2\ ' ) is equivalent to where text_match ( col , 't1 or t2 or \ ' p1\ ' or \ ' p2\ ' ) . <nl> minor enhancement - we need to make the default operator ( or ) configurable on a per text index basis . this was recently requested as our internal users ramp this feature .",1604975741,"this pr allows us to know how effective is our pruning strategy . the flow is as follows <nl> 0. total number of segments ( numsegments ) <nl> 0. broker side pruning ( numsegmentsprunedbybroker ) <nl> 0. broker queries all servers after pruning ( numsegmentsqueried ) <nl> 0. each server applies further pruning ( numsegmentsprunedbyserver ) <nl> 0. each server processes all segments after pruning ( numsegmentsprocessed ) <nl> 0. of these , only some segments have at least one matching row ( numsegmentsmatched ) . <nl> this pr adds _numsegmentsqueried , numsegmentsprocessed , numsegmentsmatched_ <nl> if the pruning (",0.9326374530792236
elastic_elasticsearch/74235,mount snapshots with index.shard.check_on_startup to false .,"today a searchable snapshot index inherits the index setting from the snapshot it is mounted from . <nl> note to reviewer : i do n't see this as a breaking change neither i think it should deserve a mention in the mount api as the setting is ' expert only ' , so i did not update documentation . let me know if you think i should .",1623933615,"the ml system indices now use the special functionality for <nl> applying the correct mappings on first use . this replaces <nl> the index templates that used to do this job , but were <nl> vulnerable to tampering . <nl> a number of other changes have had to be made to utilise <nl> the system index functionality : . <nl> 0. all fields previously missed out of mappings have been <nl> added to the system index mappings , with the types that <nl> would have been assigned dynamically in previous <nl> versions . this is necessary because dynamic mappings <nl>",0.9495701789855957
elastic_elasticsearch/74559,"avoid loading global ordinals in composite agg <cm-sep> fix <cm-sep> moar fix <cm-sep> nicer <cm-sep> no lookup tracking <cm-sep> cleaner <cm-sep> add breaker <cm-sep> small fix <cm-sep> simpler <para-sep> as it only needs to keep track of the top n composite buckets , and n is typically small , we can just use the segment ordinal for comparison when collecting inside a segment and remap ordinals when we go to the next segment instead of using global ordinals . as it 's possible that a previously mapped term has no corresponding ordinal on the new leafreader , we also cache the currently unmapped terms so that future remapping steps can be accurately done . the ordinal long.min_value is used to represent the missing bucket . <nl> small cache to avoid repeated lookups in tocomparable <nl> class invariant that should hold before and after every invocation of public methods on this class . <nl> the ordinal long.min_value is used to represent the missing bucket . <nl> value is cached iff ordinal is unmapped and not missing bucket <nl> ordinals and values are consistent with current lookup <nl> we need to compare actual terms to properly order <nl> the value might be not string if this field is missing in this shard but present in other shards and does n't have a string type <nl> caller of getleafcollector ensures that collection happens before requesting a new leaf collector this is important as ordinals only make sense in the context of the current lookup <nl> caller of getleafcollector ensures that collection happens before requesting a new leaf collector this is important as ordinals only make sense in the context of the current lookup <nl> remaps ordinals when switching leafreaders . it 's possible that a term is not mapped for the new leafreader , in that case remember the term so that future remapping steps can accurately be done .","composite aggregations can paginate all buckets from a multi-level aggregation efficiently . it is heavily used by the transform functionality , for example to convert existing elasticsearch indices into entity-centric indices that summarize the behavior of users or sessions . <nl> composite aggregations on fields used global ordinals ( see ' what are global ordinals ' ) to ensure fast comparisons between segments . global ordinals on high cardinality fields can however use a lot of heap memory as part of the field data cache . <nl> with this pr , composite aggregations no longer need global ordinals , reducing",1624539902,currently a translogwriter add operation is synchronized . this operation <nl> adds the bytes to the file output stream buffer and issues a write <nl> system call if the buffer is filled . this happens every 8kb which means <nl> that we routinely block other add calls on system writes . <nl> this commit modifies the add operation to simply place the operation in <nl> an array list . the array list if flushed when the sync call occurs or <nl> when 4mb is buffered .,0.9800438284873962
apache_incubator-pinot/6840,"configs apis <para-sep> this is equivalent to a list of all raw table names <nl> validates the configs before applying . <nl> in case of exception when adding any of the above configs , revert all configs added invoke delete on tables whether they exist or not , to account for metadata/segments etc . <nl> delete whether tables exist or not <nl> invalid json <nl> expected <nl> null table configs <nl> expected <nl> null schema <nl> expected <nl> empty config name <nl> expected <nl> schema name does n't match config name <nl> expected <nl> schema validation fails <nl> expected <nl> offline table name does n't match config name <nl> expected <nl> table name validation fails <nl> expected <nl> table validation fails <nl> expected <nl> realtime table name does n't match config name <nl> expected <nl> table name validation fails <nl> expected <nl> table validation fails <nl> expected <nl> hybrid config consistency check fails <nl> expected <nl> successfully created with all 0 configs <nl> successfully create with offline config <nl> successfully create with realtime config <nl> tests for creation of tableconfigs <nl> test post of existing configs fails <nl> expected <nl> replica check <nl> quota check <nl> tuner config <nl> create with 0 config <nl> list <nl> update to 0 <nl> list <nl> create new <nl> list <nl> delete 0 <nl> list 0 <nl> create with 0 <nl> put before post should fail <nl> expected <nl> list <nl> update to 0 <nl> list <nl> update existing config <nl> create with 0 config <nl> delete & check <nl> delete & check <nl> methods related to replication <nl> apply tunerconfig to the tableconfig <nl> ensure that the table config has the minimum number of replicas set as per cluster configs . if is does n't , set the required amount of replication in the table config <nl> for self-serviced cluster , ensure that the tables are created with at least min replication factor irrespective of table configuration value <nl> ensure the table config has storage quota set as per cluster configs . if it does n't , set the quota config into the table config <nl> dim tables must adhere to cluster level storage size limits <nl> set a default storage quota <nl> set a default storage quota and keep the rps value <nl> consistency checks across the offline and realtime counterparts of a hybrid table <nl> wrapper for all configs of a","these serve as a way to operate on the entire pinot config as 0 unit , consisting of pinot schema , realtime table config and offline table config . <nl> the motivation for these is that <nl> 0. we had already introduced a validation endpoint which validated config and schema together , as users wanted to validate changes of both before applying any of them . this pr is taking that effort all the way to having a completely dedicated configs wrapper . <nl> 0. treating them as separate entities is often creating confusion for users . <nl> 0. we",1619314988,adding alertv2 module for thirdeye . <nl> - added new alertconfig - configuration object / dao . <nl> - added new scheduler and job/task runner for alert2 module .,0.9710046052932739
elastic_elasticsearch/74060,"disable query cache for functionscorequery and scriptscorequery . <nl> this commit disables the query cache for the and the <nl> . these queries are not meant to be cached . if the score <nl> is not needed , we 'll now cache the sub-query and filters independently since <nl> we do n't want to keep an unused script in the cache . <para-sep> the sub-query/filters should be cached independently when the score is not needed . <nl> the sub-query should be cached independently when the score is not needed <nl> test query cache <nl> we occasionally need to update the expected request cache flag after rewrite to matchnonequerybuilder <nl> test query cache <nl> test query cache <nl> test query cache","this commit disables the query cache for the and the <nl> . these queries are not meant to be cached . if the score <nl> is not needed , we 'll now cache the sub-query and filters independently since <nl> we do n't want to keep an unused script in the cache .",1623669979,"this commit adds an id , which is composed of the ids of segment files , to elasticsearchdirectoryreader . with this id , we can retry search requests on another shard copy if its latest ' snapshot ' has the same segment files as the failing shard .",0.9167681336402893
vespa-engine_vespa/17742,skip adding logforwarder on hosts if they have membership with cluster type admin <para-sep> xxx should skip only if this.ishostedvespa is true ?,skip adding logforwarder on hosts if they have membership with cluster type admin . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620203374,the data is a 0 response with a dummy entry and should be replaced by metering data at a later stage . <nl> the new api url /application/v4/tenant/mytenant/application/myapplication/metering is not included in the parent response yet .,0.9386100769042969
apache_shardingsphere/10327,"subscribe global rule configurations changed event , persist global rule configurations into registry center . <para-sep> renew global rule configurations .",- subscribe global rule configurations changed event . <nl> - persist global rule configurations into registry center .,1620879130,"so if encryption rule use upper case logic column , the rewrite method can not get encryptor by it . and then encrypt-jdbc fail to rewrite the sql . <nl> changes proposed in this pull request : <nl> the method findplaincolumn and findshardingencryptor use the lower case logic column as parameter , and if the encryption rule use upper case logic column , it cause the problem .",0.9663524627685547
crate_crate/10925,"support iso format in timestampztype decodeutf8text . <nl> because of the fix in [ 0 ] <nl> timestamp values were no longer streamed as undefined ( text ) and then <nl> implicitly cast to timestamp using the implementation , but <nl> instead they were directly decoded using the <nl> implementation , which supported a different set of formats . <nl> this commit changes the decode implementation to first use the logic in <nl> and then as fallback the previous decode <nl> implementation . this ensures all formats we previously supported <nl> continue to work . <nl> we should eventually re-work the decode implementation to support all <nl> postgresql date/time input formats as described in their documentation : .","because of the fix in [ 0 ] <nl> timestamp values were no longer streamed as undefined ( text ) and then <nl> implicitly cast to timestamp using the implementation , but <nl> instead they were directly decoded using the <nl> implementation , which supported a different set of formats . <nl> this commit changes the decode implementation to first use the logic in <nl> and then as fallback the previous decode <nl> implementation . this ensures all formats we previously supported <nl> continue to work . <nl> we should eventually re-work the decode implementation to support all <nl> postgresql",1610976347,mergify commands and options . <nl> you can also trigger mergify actions by commenting on this pull request : . <nl> - will re-evaluate the rules <nl> - will rebase this pr <nl> - will backport this pr on branch . <nl> - look at your merge queues <nl> - generate the mergify configuration with the simulator .,0.7786353826522827
elastic_elasticsearch/74326,"simplify dynamic template parser context creation . <nl> documentparser takes care of parsing documents and applying dynamic mapping updates for each new field it encounters , if applicable , as well as applying the matching dynamic templates . <nl> to do this , it needs to be able to parse mappings , which requires a parsercontext that the parsecontext exposes given a dateformatter . so far , we have carried around a function that allows to create a new parsercontext given a date formatter , and then call a specific method that allows to wrap it to provide a special parser context that is specific for dynamic templates , which is needed to make some decisions down the line based on whether mappings come from dynamic templates or not . <nl> this commit tries to simplify this by exposing the specific dynamic template parser context only to the document parse context , as that 's all it needs . we recently ended up using the wrong context and with this change it would not be possible . the function that is passed around is the one that create a dynamictemplateparsercontext , so it can not be mistaken for the one that creates a generic parsercontext .","documentparser takes care of parsing documents and applying dynamic mapping updates for each new field it encounters , if applicable , as well as applying the matching dynamic templates . <nl> to do this , it needs to be able to parse mappings , which requires a parsercontext that the parsecontext exposes given a dateformatter . so far , we have carried around a function that allows to create a new parsercontext given a date formatter , and then call a specific method that allows to wrap it to provide a special parser context that is specific for dynamic templates",1624041580,the reaper can remove derived contexts of a point in time between query and fetch phases as their keep_alive is unset ( 0 ) .,0.8573760986328125
OpenAPITools_openapi-generator/8762,fix unique parameter naming <cm-sep> add tests,- fix bugs to ensure unique parameter names <nl> - add tests .,1613726412,allow specifying which collection type to convert to .,0.9129200577735901
neo4j_neo4j/11594,"removes duplicated parameter from test <cm-sep> corrects failedindexproxy behaviour for updates . <nl> the newly introduced method in indexproxy <nl> was implemented incorrectly in failedindexproxy . it threw exception <nl> instead of just ignore that call , just like did . <nl> this caused unexpected temporary failures for transactions touching <nl> the same label/key combination as an attempted uniqueness constraint <nl> creation did , one that failed due to constraint violations .","the newly introduced method in indexproxy <nl> was implemented incorrectly in failedindexproxy . it threw exception <nl> instead of just ignore that call , just like did . <nl> this caused unexpected temporary failures for transactions touching <nl> the same label/key combination as an attempted uniqueness constraint <nl> creation did , one that failed due to constraint violations .",1524054903,previous message was confusing and was asking people to do ' tx recovery/restart ' <nl> ' tx ' was confusing and some people tried to find those methods in a transaction <nl> objects in driver/kernel/etc api . <nl> also it can be quite problematic to do only recovery on your own . <nl> new panic message : <nl> critical error has encountered ( see database logs for more details ) . please restart the database .,0.7679857611656189
elastic_elasticsearch/73757,move pytorchresult to ml and add tests <cm-sep> pass through result processor <cm-sep> add with special tokens config <cm-sep> test to load and evaluate a torchscript model <cm-sep> adapt after rebase <para-sep> this test uses a tiny hardcoded base64 encoded pytorch torchscript model . the model was created with the following python script and returns a tensor of 1s . the simplicity of the model is not important as the aim is to test loading a model into the pytorch process and evaluating it . <nl> this procedure chooses the first available ml node that is a high enough version . todo assign models by memory this a a blocker on releasing the feature norelease assign pytorch models to nodes by memory <nl> a nlp processor that directly returns the pytorch result without any post-processing <nl> nothing to validate <nl> include cls and sep tokens,"the test contains a hardcoded pytorch torchscript model base64 encoded , details of how to recreate the model are in the javadoc . <nl> for the test a has been created . this passes the pytorch result directly back to the api caller without any extra processing . <nl> i 've changed to function to simply choose the first ml node that is of version version or above . there are 0 reasons for this , first i hit a bug in the test where it would fail periodically if the memory requirements have not be refreshed and secondly to",1622799436,"introduce eql search status api , <nl> that reports the status of eql stored or async search . <nl> get _eql/search/status/ . <nl> the api is restricted to the monitoring_user role . <nl> for a running eql search , a response has the following format : . <nl> for a completed eql search , a response has the following format : .",0.9886128902435303
elastic_elasticsearch/74211,synchronizes slowlog json keys with beats . <nl> filebeat ships with dedicated fields for elasticsearch slowlog . <nl> this updates our ecs logger to report the slowlog keys under . <nl> this prevents clashes with ecs templates,filebeat ships with dedicated fields for elasticsearch slowlog . <nl> this updates our ecs logger to report the slowlog keys under . <nl> this prevents clashes with ecs templates,1623872013,"renames and moves the cross validation splitter package . <nl> first , the package and classes are renamed from using <nl> ' cross validation splitter ' to ' train test splitter ' . <nl> cross validation as a term is overloaded and encompasses <nl> more concepts than what we are trying to do here . <nl> second , the package used to be under but it does <nl> not make sense to be there , it can be a top level package <nl> under .",0.9001430869102478
OpenAPITools_openapi-generator/8859,"add api client mustache for http client <para-sep> / / to serialize/deserialize json using our custom logic , but only when contenttype is json . / <nl> openapi generated types generally hide default constructors . <nl> / / serialize the object into a json string . / / object to be serialized . / a json string . <nl> the object to be serialized is an oneof/anyof schema <nl> / / deserialize the json string into a proper object . / / the http response . / object type . / object representation of the json string . <nl> todo : ? if ( type.isassignablefrom ( typeof ( stream ) ) ) <nl> at this point , it must be a model ( json ) <nl> / / provides a default implementation of an api client ( both synchronous and asynchronous implementatios ) , / encapsulating general rest accessor use cases . / <nl> / / specifies the settings on a object . / these settings can be adjusted to accomodate custom serialization rules . / <nl> openapi generated types generally hide default constructors . <nl> / / initializes a new instance of the , defaulting to the global configurations ' base url . / <nl> / / initializes a new instance of the / / the target service 's base path in url format . / <nl> / / provides all logic for constructing a new httprequestmessage . / at this point , all information for querying the service is known . here , it is simply / mapped into the a httprequestmessage . / / the http verb . / the target path ( or resource ) . / the additional request options . / a per-request configuration object . it is assumed that any merge with / globalconfiguration has been done before calling this method . / a new httprequestmessage instance . / <nl> in case of post or put pass query parameters in request body <nl> todo make content headers actually content headers <nl> todo provide an alternative that allows cookies per request instead of per api client <nl> if the response type is oneof/anyof , call fromjson to deserialize the data <nl> / / make a http get request ( async ) . / / the target path ( or resource ) . / the additional request options . / a per-request configuration object .",- create apiclient.mustache for httpclient <nl> - clean up apiclient.mustache <nl> - test httpclient samples in appveyor.yml .,1614503336,"rust server currently treats all headers declared in the openapi file as mandatory , when actually they default to optional . <nl> furthermore , the core code does n't pass through whether a header is mandatory or optional . <nl> this makes a small change to the defaultcodgen to pass this data through , defaulting correctly . <nl> the rust change is then fairly straightforward - we enhance rust server , using to represent non-required headers . <nl> this is breaking , because we 'll treat headers which were treated as required before as optional , and we 'll provide",0.8690915703773499
Alluxio_alluxio/13122,refactor worker interface <para-sep> a data reader that reads from a worker in the same process of this client directly . <nl> send request to local worker <nl> acquires the internal block worker as a gateway for worker internal clients to communicate with the local worker directly without going through external rpc frameworks .,- rename to be and <nl> - remove ( newly added ) and make the cleanup logic into <nl> - rename ( newly added ) to for simplicity <nl> - share the same among and <nl> - remove -- no more necessary <nl> - combine to and put cleanup logic into this block reader 's method . <nl> - put logic to the method of,1616648603,changes include : <nl> - make public method in as interface <nl> - introduce as implementation <nl> - separate a few nested classes from to their own classes to reduce its complexity,0.97549968957901
apache_flink/15256,"refactor binaryrowdatakeyselector in testing <cm-sep> minor <para-sep> utility for keyselector , in flink-table-runtime , there is no code generation , so use handwritten instead . <nl> * /","refactor binaryrowdatakeyselector in testing . <nl> we can introduce a handwrittenselectorutil to replace binaryrowdatakeyselector newinstance for reduce misunderstanding . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos ,",1616037312,"this pr removes , as should be used for creating temporary folders during tests . <nl> as such all usages were replaced with . <nl> this change is already covered by existing tests .",0.9073347449302673
netty_netty/11373,httputil.getcharset ( ) fails for charset in double-quotes . <nl> __motivation__ . <nl> __modification__ . <nl> modify to trim the double-quotes if present . <nl> __result__ . <nl> now supports quoted charsets .,__motivation__ . <nl> __modification__ . <nl> modify to trim the double-quotes if present .,1623104091,correctly propagate failures while update the flow-controller to the multiplexed channel . <nl> motivation : . <nl> we may fail to update the flow-controller and in this case need to notify the stream channel and close it . <nl> modifications : . <nl> attach a future to the write of the update frame and in case of a failure propagate it to the channel and close it . <nl> result : .,0.9163727760314941
elastic_elasticsearch/73128,"increase peerfinder verbosity on persistent failure . <nl> if a node is partitioned away from the rest of the cluster then the <nl> periodically reports that it can not <nl> discover the expected collection of nodes , but does not indicate why . to <nl> prove it 's a connectivity problem , users must today restart the node <nl> with logging on to see <nl> further details . <nl> with this commit we log messages at level if the node remains <nl> disconnected for longer than a configurable timeout , which defaults to 0 <nl> minutes . <para-sep> we do not log connection failures immediately : some failures are expected , especially if the hosts list is n't perfectly up-to-date or contains some unnecessary junk . however if the node can not find a master for an extended period of time then it is helpful to users to describe in more detail why we can not connect to the remote nodes . this setting defines how long we wait without discovering the master before we start to emit more verbose logs . <nl> attempt to resolve the configured hosts list to a list of transport addresses . <nl> log message at level warn , but since debug logging is enabled we include the full stack trace","if a node is partitioned away from the rest of the cluster then the <nl> periodically reports that it can not <nl> discover the expected collection of nodes , but does not indicate why . to <nl> prove it 's a connectivity problem , users must today restart the node <nl> with logging on to see <nl> further details . <nl> with this commit we log messages at level if the node remains <nl> disconnected for longer than a configurable timeout , which defaults to 0 <nl> minutes .",1621161178,some ccs requests would never be completed because of this bug .,0.9616678357124329
apache_incubator-pinot/6596,"always return a response from query execution . <para-sep> always return a response even when query execution throws exception ; otherwise , broker will keep waiting until timeout . <nl> put all code inside try block to catch all exceptions . <nl> parse instance request into serverqueryrequest . <nl> submit query for execution and register callback for execution results . <nl> deserialization exception <nl> send error response <nl> responsebytes contains either query results or exception . <nl> send exception response . <nl> send exception response . <nl> all exceptions should be caught and handled in channelread0 method . this is a fallback method that will only be called if for some remote reason we are unable to handle exceptions in channelread0 . <nl> send an exception back to broker as response to the query request . <nl> log query processing exception <nl> send a response ( either query results or exception ) back to broker as response to the query request . <nl> check if server returns error response quickly without timing out broker . * / <nl> set query timeout <nl> the query below will fail execution due to use of double quotes around value in in clause . <nl> remove timeout","as a result broker will wait until it times out . this causes un-necessary latency for queries on the broker side . one example of such a query is : . <nl> this pr fixes the issue by always returning a response back to the broker irrespective of whether query succeeds or fails . note that uncaught_exceptions and request_fetch_exception metrics are no longer being emitted . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release",1613768147,0. add hdfs segment fetcher support <nl> 0. make sure all segment fetcher is initialized during controller/server startup <nl> 0. fix bug in segmentfactory where it can not grab config for fetcher <nl> 0. add unit test for segment fetcher factory,0.9661178588867188
Alluxio_alluxio/13277,do not wait for web ui to be ready to be ready,i believe this is going to be greatly increase the stability of the unit tests .,1619134119,we should do a check if may have returned,0.8330427408218384
apache_druid/10837,add log message when local input 's filter does not match any files <para-sep> base dir & filter are guaranteed to be non-null here ( by construction and non-null check of basedir a few lines above ) :,"when the filter for local inputsource does not match any file a log message should be output at level indicating that ' no files matched the filter expression : . <nl> when the filter for local inputsource does not match any file there is no log message , the task report simply indicates that no rows were parsed .",1612313299,0 ) free buffers after each test <nl> 0 ) avoid mmaping past the end of a file,0.9090086221694946
apache_shardingsphere/10639,"fix group by having merge result error <cm-sep> optimize having merge code <cm-sep> fix checkstyle <para-sep> decorator merged result for having . <nl> todo support more expr scenario , like in , between and ... <nl> having column . <nl> having context . <nl> having context engine . <nl> create having context .",changes proposed in this pull request : <nl> - modify rewrite logic <nl> - add to merge result after group merge,1622716668,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9789264798164368
apache_kafka/10735,"start fresh -- clean up taskid class , return taskid <para-sep> the task id representation composed as subtopology ( aka topicgroupid ) plus the assigned partition id . the id of the subtopology , aka topicgroupid . * / <nl> experimental feature -- will return null","the kip is currently under voting so this pr ca n't be merged yet , but it is ready to be reviewed",1621479241,"this is a general change and is re-requisite to allow streams benchmark test with different streams tests . for the streams benchmark itself i will have a separate pr for switching configs . details : . <nl> 0. create a ' streams.properties ' file under persistent_root before all the streams test . for now it will only contain a single config of state.dir pointing to persistent_root . <nl> 0. for all the system test related code , replace the main function parameter of state.dir with propsfilename , then inside the function load the props from the file and apply overrides",0.9650560617446899
ballerina-platform_ballerina-lang/27464,"rename getattachefuncs to getmemberfunctiontypes <cm-sep> duplicate object ctor type at object init . <nl> this is done so that we can keep on attaching new annot <nl> values to obj type , as same object ctor can be used to <nl> create different obj instances . <para-sep> validate resource function annotation <nl> test annotation on service decl create multiple services using same service constructor expression and verify that each annotations is set correctly to each service object . <nl> test service within a service",$ title . <nl> also rename to . <nl> also allow type to be in resource path params .,1607688396,"currently , from the only the filename is obtained . changing it to the relative file path from the package root fixes the following issues . <nl> eg : consider the following package structure . <nl> 0. two files in the same package but different folders logged with the same name when printing errors . <nl> logged errors . <nl> 0. no way to distinguish the files with same name when debugging . <nl> 0. compilation units having the same file name can not be identified separately",0.9650654196739197
elastic_elasticsearch/74285,fix wildcard support in update aliases api for data stream aliases . <nl> fix update indices aliases to accept wildcard expressions as alias names <nl> in remove alias actions for aliases referring to data stream . <nl> also allow add alias actions for data stream aliases to contain multiple <nl> aliases names . both changes are inline with alias actions for indices aliases . <para-sep> for delete we expand the aliases <nl> for add and remove_index we just return the current aliases <nl> add does n't resolve wildcards : <nl> remove does resolve wildcards :,fix update indices aliases to accept wildcard expressions as alias names <nl> in remove alias actions for aliases referring to data stream . <nl> also allow add alias actions for data stream aliases to contain multiple <nl> aliases names . both changes are inline with alias actions for indices aliases .,1624008448,"previously we treated attribute filtering for -prefixed attributes a pass-through , meaning <nl> that they were essentially always treated as matching in , however , for <nl> exclude settings , this meant that the node was considered to match the node if a filter was <nl> specified . <nl> this commit prunes these attributes from the discoverynodefilters when considering the filters for <nl> so that they are only considered in .",0.9526206254959106
elastic_elasticsearch/73555,[ 0.x ] delete mounted indices after in searchable snapshots yaml tests <para-sep> returns whether to preserve searchable snapshots indices . defaults to not preserving them . only runs at all if xpack is installed on the cluster being tested . <nl> clean up searchable snapshots indices before deleting snapshots and repositories <nl> retrieves all indices with a type of store equals to ' snapshot ',"this commit adds some clean up logic to esresttestcase so that searchable snapshots indices are deleted after test case executions , before the snapshot and repositories are wipe out .",1622463705,"as requestoptions add requestconfig , users can set some request config per request , e.g sockettimeout . <nl> without requestconfig , sockettimeout can only set in restclient init . <nl> as different kind of request maybe have different request options , users can set requestconfig optional .",0.9284742474555969
elastic_elasticsearch/73636,"add extra profiling information to terms agg . <nl> i was helping some folks debug an issue with the terms agg and noticed <nl> that we did n't always have the debug information . i also <nl> noticed that we ca n't tell how many buckets we build , so i added that <nl> too as . <nl> finally , i noticed that when we 're using segment ords we count segments <nl> without any values as ' multi-valued ' . we can do better there and count <nl> them as no-valued . that will , mostly , just improve the profiling . when <nl> we collect from global ords we have no way to tell how many values are <nl> on the segment so segments without any values will , sadly , in this case <nl> still be miscounted as multi-valued . <para-sep> the total number of buckets collected by this strategy .","i was helping some folks debug an issue with the terms agg and noticed <nl> that we did n't always have the debug information . i also <nl> noticed that we ca n't tell how many buckets we build , so i added that <nl> too as . <nl> finally , i noticed that when we 're using segment ords we count segments <nl> without any values as ' multi-valued ' . we can do better there and count <nl> them as no-valued . that will , mostly , just improve the profiling . when <nl> we collect from global",1622582861,the transform internal index now uses the special <nl> functionality for protecting system indices from <nl> unwanted modification . <nl> the system index descriptor replaces the index <nl> template that was previously used with the transform <nl> internal index . in places where we used to check <nl> that the template was installed we now proactively <nl> create the index . master node actions will apply <nl> the desired mappings if the index is auto-created <nl> as a result of any indexing that they do .,0.958960235118866
netty_netty/11166,used already calculated settings frame payload length when allocating bytebuf . <nl> motivation : we have already calculated the payload length . so no need to calculate again when allocating bytebuf . <nl> modification : used payloadlength variable instead of calculating the payload length again . <nl> result : re-use the variable value and make the code cleaner,motivation : . <nl> we have already calculated the payload length . so no need to calculate again when allocating bytebuf . <nl> modification : . <nl> used payloadlength variable instead of calculating the payload length again . <nl> result : . <nl> re-use the variable value and make the code cleaner,1618769264,motivation . <nl> modification . <nl> just use alloc ( ) .heapbuffer ( ... ) for the allocation . <nl> result . <nl> no possibility of ' missing ' array allocations when bytebuf # copy is used .,0.8005121350288391
apache_shardingsphere/10401,optimize mysql alter table add foreign key parse & route logic <cm-sep> fix checkstyle,changes proposed in this pull request : <nl> - optimize mysql alter table add foreign key parse & route logic <nl> - add parse & rewrite test case,1621498207,changes proposed in this pull request : <nl> - fix format for variable . <nl> - adjust set grammar .,0.9119032621383667
elastic_elasticsearch/74666,ensure test pass with explicit counter and timer . <nl> the test fails intermittently on ci . this pr explicitly configures both <nl> the counter and timer needed for triggering the warning message so that <nl> the warning message should always fire as expected . <para-sep> package private for test <nl> calculate the last thrashing check time to ensure that the elapsed time is longer than the thrashing checking interval ( 0 seconds ) . also add another 0 seconds to counter any test flakiness . <nl> counter and timer should be reset,the likely <nl> reason is that either the counter or the timer is not the expected value when the <nl> code runs . <nl> this pr explicitly configures both the counter and timer needed for triggering <nl> the warning message so that the warning message should always fire as expected .,1624946023,"under specific circumstances we would call onresponse twice , which <nl> led to unexpected behavior .",0.8905792832374573
apache_pulsar/10322,fix transaction buffer op fail handle .,"in order to tc retry the op so return the exception . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no",1619078480,"currently , the transaction abort on partitions operation is not getting through . <nl> make the transaction abort on partitions operation get through . <nl> this change added tests and can be verified as follows : . <nl> - org.apache.pulsar.broker.transaction.transactionproducetest # produceandaborttest <nl> - org.apache.pulsar.client.transaction.endtoendtest # partitionaborttest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( yes ) <nl> - the schema : ( no ) <nl> - the default values of configurations : (",0.9606725573539734
elastic_elasticsearch/73428,"* validate that system indices are n't also hidden inidices <nl> * remove hidden from ingest geo system index <nl> * add test coverage <nl> * remove hidden setting from system index even if not upgrading <cm-sep> fix compilation for backport <para-sep> checks that the request is n't trying to add the ' hidden ' setting to a system index <nl> requests that a cluster generates itself are permitted to have a difference in settings so that rolling upgrade scenarios still work . we check this via the request 's origin . <nl> visible for testing <nl> set up a system index upgrade service <nl> when we upgrade elasticsearch versions , existing indices may be newly defined as system indices . if such indices are set to ' hidden , ' we need to remove that setting . <nl> create an initial cluster state with a hidden index that matches the system index descriptor <nl> if a system index erroneously is set to hidden , we should remedy that situation . <nl> create an initial cluster state with a hidden index that matches the system index descriptor <nl> get a metadata upgrade task and execute it on the initial cluster state",* validate that system indices are n't also hidden inidices <nl> * remove hidden from ingest geo system index <nl> * add test coverage <nl> * remove hidden setting from system index even if not upgrading,1622045763,"this commit adds a new metadata field mapper that validates , <nl> that a document has exactly a single timestamp value in the data stream timestamp field . <nl> the metadatacreateindexservice inserts a data stream timestamp field mapper whenever <nl> a new backing index of a data stream is created .",0.9743465781211853
neo4j_neo4j/11514,more logging . <nl> added log when server is bound to channel . <nl> added log when reconnectedchannel fails to connect . <cm-sep> make sure exception is always rethrown when server fails to start,ensure we always re-throw exception when server fails to bind . <nl> add logging when server has bound . <nl> add logging when reconnecting channel fails to connect . <nl> failed request during store copy are now info and not error since they are expected to happen every now and then .,1523442266,by using the same mechanisms to figure that out as neo4j <nl> does otherwise .,0.9027414917945862
neo4j_neo4j/11524,fix bug with literal null in compiled runtime . <nl> - always convert literals that are not primitives to value-type <nl> - convert literal null to no_value <para-sep> when the literal value comes from the ast it should already have been converted,- always convert literals that are not primitives to value-type <nl> - convert literal null to no_value,1523454686,remove expectation of lucene label scan store to be included into set of <nl> lucene indexes that we expect to have snapshots for . <nl> check snapshots validity based on segments file as an indicator what <nl> index commit was used for particular index snapshot .,0.8362688422203064
prestodb_presto/15515,fix broadcast memory update in rootaggregatedmemorycontext <cm-sep> set broadcast memory limit for presto on spark,"- it is not necessary to update broadcast memory bytes if the query has no broadcast join . this pr fixed it . <nl> - when a query exceeds max broadcast memory bytes , query will only be killed after verifying that the query has broadcast join , therefore , no query is badly affected , this pr only fixed unnecessary update . <nl> - max broadcast memory bytes for presto on spark is now correctly set .",1607624920,tupledomain compaction reduces a long list of well specified values to a <nl> range if the number of values threshold is crossed . <nl> the compaction has been moved as part of the sha commit . <nl> effectivepredicate is carried to a worker with a hivesplit . hivesplit <nl> must be serialized into json on the coordinator . without a compaction <nl> the serialization of large tupple domains ( 0+ values ) results in <nl> excessive cpu usage on coordinator .,0.916652262210846
apache_beam/14660,make statebackediterable serializable . <para-sep> check that the contents are the same . <nl> check that we can still iterate over it as before .,"as we 're materializing the whole thing , there 's no need to return an object of the same type . ( these are only released in the public api as iterables . )",1619567793,follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9415896534919739
apache_flink/16216,move futureutils # tojava to separate class <para-sep> utilities to convert scala types into java types . * /,small preemptive refactoring so that we can later move this method into another module more easily .,1624271949,"# # what is the purpose of the change . <nl> this pull request adds comapfunction for python datastream api . <nl> - add connect ( ) on datastream . <nl> - add comapfunction on datastream . <nl> - refactor the previous to and add a for connect . <nl> this change added tests and can be verified as follows : . <nl> - added and integration tests in test_data_stream . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated",0.8627141118049622
apache_druid/11199,"fix vectorized cardinality bug on certain string columns . <nl> cardinalityvectorprocessorfactory <nl> improperly ignored calls to ' makeobjectprocessor ' . <nl> in addition to fixing the bug , i added this detail to the javadocs for <nl> vectorcolumnprocessorfactory , to prevent others from running into the <nl> same thing in the future . they do not currently call out this case . <para-sep> handles string-as-object and complex types . <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> adds an object to a hyperloglogcollector . if the object is any other type ( including null ) then behavior depends on null-handling mode : - in sql-compatible mode , ignore non-strings and nulls . - in replace-with-default mode , treat all non-strings and nulls as empty strings . <nl> noinspection unchecked <nl> to handle all string inputs properly , processors must implement all three methods ( single-value , multi-value , object ) . to handle all string inputs properly , processors must implement all three methods ( single-value , multi-value , object ) . may also be called for string typed columns in cases where the dictionary does not exist or is not expected to be useful . <nl> cardinality aggregator on complex columns ( like hyperunique ) returns 0 . <nl> cardinality aggregator on complex columns ( like hyperunique ) returns 0 .","cardinalityvectorprocessorfactory <nl> improperly ignored calls to ' makeobjectprocessor ' . <nl> in addition to fixing the bug , i added this detail to the javadocs for <nl> vectorcolumnprocessorfactory , to prevent others from running into the <nl> same thing in the future . they do not currently call out this case .",1620178514,syntax is the same as hive/presto 's .,0.9770687222480774
neo4j_neo4j/11471,prestart core threads and update config options <cm-sep> remove histogram type metrics <cm-sep> update config naming <cm-sep> update keys in connector validation,"this pr makes some changes around how configuration keys for bolt server are named . <nl> thread pooling <nl> the new pooled thread architecture being introduced in bolt server makes it possible that idle connections do not eat up server resources . the thread pools are isolated per connector , i.e . you can have multiple bolt connectors defined at different ports with different thread pool characteristics . currently , any open transaction ( be it an explicit transaction or an auto-commit one ) will borrow a thread from the thread pool until that transaction is closed . this should",1522958656,previously the port would remain bound until the jvm was terminated .,0.9571821093559265
apache_shardingsphere/10816,support postgresql create index without index name <para-sep> get generated logic index name . <nl> create index statement handler for different dialect sql statements . <nl> get generated index start index . <nl> get generated index start index .,changes proposed in this pull request : <nl> - support postgresql create index without index name <nl> - add rewrite test case,1623750059,changes proposed in this pull request : <nl> - support insert without columns . <nl> - support insert without columns and generating generated-key . <nl> - add some tests and expected files for this usage . <nl> - modify some tests .,0.9618890285491943
runelite_runelite/13118,add gold chest tracking ( shades of mort'ton ) <cm-sep> add shades of mort'ton minigame location,adds loot tracking for new gold keys in shades of mort'ton . <nl> also adds missing minigame icon label .,1611767406,adds the following new location to the hot & cold clue scroll plugin .,0.9156082272529602
vespa-engine_vespa/17186,add test verifying request size in request log <cm-sep> remove blockingqueuerequestlog,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616688996,setup a container running on the same host as logserver when <nl> using a dedicated host in hosted vespa . this container will be used <nl> for running a handler that can retrieve logs from logserver archive .,0.9253673553466797
apache_beam/13636,add e2e test with kafka and pubsub emulators <cm-sep> add dependencies <cm-sep> add more dependencies <cm-sep> add more and more dependencies <cm-sep> - added testcontainers gcloud dependency <nl> - updated testpubsubsignal to be compatible with pubsub emulator <nl> - kafkatopubsubtest refactoring <cm-sep> - reverted unnecessary changes <nl> - changed logging to throwing errors <cm-sep> - moved runkafkacontainer to utils package <nl> - moved e2e test to separate test class <cm-sep> - reverted unnecessary changes <nl> - added newline at the end of file <para-sep> create the pipeline <nl> * / <nl> creates an instance of this rule using provided options .,e2e test for kafka to pub/sub pipeline example . <nl> after that we publish a message to kafka topic and wait for it to appear in pub/sub topic . if message is not received in 0 minutes test fails,1609340339,"i would like to add this new feature since it will allows to make a k8s example with that release . this has already been tested for couple weeks in our infrastructure and does not affect anything else , the risk of adding it to the release is very low",0.9734119176864624
OpenAPITools_openapi-generator/9748,"add go-chi generator to go-server <cm-sep> add go-chi configs <cm-sep> add go-chi generated output <cm-sep> updated docs <para-sep> name of additional property for switching routers <nl> description of additional property for switching routers <nl> list of available routers <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> petapirouter defines the required methods for binding the api requests to a responses for the petapi the petapirouter implementation should parse necessary information from the http request , pass the data to a petapiservicer to perform the required actions , then write the service results to the http response . <nl> storeapirouter defines the required methods for binding the api requests to a responses for the storeapi the storeapirouter implementation should parse necessary information from the http request , pass the data to a storeapiservicer to perform the required actions , then write the service results to the http response . <nl> userapirouter defines the required methods for binding the api requests to a responses for the userapi the userapirouter implementation should parse necessary information from the http request , pass the data to a userapiservicer to perform the required actions , then write the service results to the http response . <nl> petapiservicer defines the api actions for the petapi service this interface intended to stay up to date with the openapi yaml used to generate it , while the service implementation can ignored with the .openapi-generator-ignore file and updated with the logic required for the api . <nl> storeapiservicer defines the api actions for the storeapi service this interface intended to stay up to date with the openapi yaml used to generate it , while the service implementation can ignored with the .openapi-generator-ignore file and updated with the logic required for the api . <nl> userapiservicer defines the api actions for the userapi service this interface intended to stay up to date with the openapi yaml used to generate it , while the service implementation can ignored with the .openapi-generator-ignore file and updated with the logic required for the api . <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> a petapicontroller binds http requests to an api service and writes the service",- added option to the go-server ( mux or chi ) <nl> - updated the mustache files to add go-chi router instead of mux when is selected <nl> - fix missing dependency for mux <nl> - feature set remains the same <nl> - added to generate go-chi server <nl> - running with default options does not change the current generated files ! ( backwards compatible ) .,1623404736,"taking the samples from the sample , with this setting you could for example change the model in the file to in the file by defining the model suffix and the model file suffix . <nl> the motivation behind this change is to have a clear distincation between generated models and models that are created by a developer . having the ability to add a suffix to the generated models makes it immediatly obvious of what kind a model is . <nl> i currently see one issue and that is that the class suffix gets also appended to enumeration types",0.9081889390945435
apache_druid/11018,add protobuf inputformat <para-sep> configure parser with desc file <nl> create binary of proto test event <nl> configure parser with desc file <nl> create binary of proto test event,"because of deprecated of parsespec , i develop protobufinputformat for new interface , which supports stream ingestion for data encoded by protobuf",1616226083,"# # # description . <nl> all of the unit tests have been adapted to also run with the new . <nl> parquet can be used in native batch indexing with any , for example :",0.9780406355857849
apache_incubator-pinot/6870,add a metirc of ideal state size after gzip,"today controller emits a metric . the znode size is useful to monitor znode size is less than 1mb , otherwise helix can not process the znode . however , the reported size is before the gzip compression , not the actual size stored in zk . add a new metric of the znode size after gzip . note that the difference of the znode size before and after gzip could be significant ( e.g . > 100x~1000x ) . <nl> release-notes <nl> add a new metric to emit the idealstate znode size after gzip compression .",1619806055,"this pr adds metrics to track the number of partitions for which controller becomes leader , so that <nl> when the total number of this metric is aggregated from multiple controllers , we know every partitions have their own leader .",0.899057149887085
apache_kafka/10850,replace easymock and powermock with mockito in streams module ( metrics ),"development of easymock and powermock has stagnated while mockito continues to be actively developed . with the new java cadence , it 's a problem to depend on libraries that do bytecode generation and are not actively maintained . in addition , mockito is also easier to use .",1623231734,"this pr fixes and improves two major issues : . <nl> 0. when calling we can always get an invalidstatestoreexception , and even waiting for streams state to become running is not sufficient ( this is also how optimizedktableintegrationtest failed ) . so i wrapped all the function with a util wrapper that captures and retries on that exception . <nl> if you are sending n records with a single call , within that call it will create n producers used to send one record each , which is very slow and costly .",0.8846379518508911
elastic_elasticsearch/73647,fix ensurenowarning assertion . <nl> ensurenowarnings method should assert that there is no other warnings <nl> than the allowed ' predefined ' warnings in filteredwarnings ( ) method .,ensurenowarnings method should assert that there is no other warnings <nl> than the allowed ' predefined ' warnings in filteredwarnings ( ) method .,1622619877,this commit disables norms on these fields again .,0.8981329202651978
apache_pulsar/10457,": revalidate leader election after session is recovered <para-sep> if the value is the same as our proposed value , it means this instance was the leader at some point before . the existing value can either be for this same session or for a previous one . <nl> the value is still valid because it was created in the same session <nl> since the value was created in a different session , it might be expiring . we need to delete it and try the election again . <nl> the existing value is different but was created from the same session <nl> if the existing value is different , it means there 's already another leader <nl> there are no multiple session in local mem provider <nl> there are no multiple sessions for the local memory provider","the leader election component should revalidate the leadership ephemeral node once the session is re-established . <nl> 0. when acquiring leadership , check if the node is a left over from an older session or if it belongs to a different instance <nl> 0. re-trigger leader election on session re-establishment . if that fails , notify the listener that the mode has changed into follower .",1619816516,"this introduce inconsistency between local ownership cache and zk cluster . <nl> * in ownership checking , querying and acquiring , reestablish lost ownership in false negative releasing and false positive acquiring . <nl> i.e . this commit admits that the inconsistency between local ownership cache and zk cluster could not be avoided totally , thus performs ownership correction in checking , querying and acquiring . <nl> this change added tests and can be verified as follows : <nl> * add tests to mock zk disconnection in namespace bundle unloading and acquiring . existing code fails in these tests ,",0.9641597270965576
apache_pulsar/10312,"fix the inconsistency of advertisedaddress <para-sep> get the address of broker , first try to get it from advertisedaddress . if it is not set , try to get the address set by advertisedlistener . if it is still not set , get it through inetaddress.getlocalhost ( ) .","# # # motivation <nl> there is an in pusarservice and an in conf . when is set , the values of the two will be inconsistent . <nl> in the current code , is used in some places , and is used in other places .",1619023331,"kubernetes has troubles viewing arguments with string embedded in them . so cover the secrets_config with quotes . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9446549415588379
elastic_elasticsearch/73616,"osstats must be lenient with bad data from older nodes <para-sep> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here . <nl> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here .","we 've had a series of bug fixes for cases where an osprobe gives negative values , most often just 0 , to the osstats class . we added assertions to catch cases where we were initializing osstats with bad values . unfortunately , these fixes turned to not be backwards-compatible . in this commit , we simply coerce bad values to 0 when data is coming from nodes that do n't have the relevant bug fixes .",1622558985,"today you can mount a snapshot of a searchable snapshot index , but the <nl> shard fails to allocate since the underlying snapshot is devoid of <nl> content . doing this is a mistake , you probably meant to restore the <nl> index instead , so this commit rejects it earlier with a more helpful <nl> message .",0.8673242330551147
jenkinsci_jenkins/5314,swap expected value and actual value arguments so that they are in the correct order <cm-sep> use assertnotequals where possible <cm-sep> use assertequals where possible <cm-sep> remove unused import,"fixes a common mistake when using junit ; namely , that takes the expected value as the first argument and the actual value as the second argument , but these are often mistakenly reversed .",1614305642,* no tests <nl> * changelogs are not required .,0.8894007802009583
vespa-engine_vespa/18401,"implement dryrun in feedclient , use it from cli and hadoop feeder <para-sep> dryrun implementation that reports every request/operation as successful",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624547483,"- information about a lock attempt now includes a list of lock attempts done <nl> while holding the lock , forming a tree ( forest ) structure . <nl> - records the duration and locking attempts done as part of an external <nl> deploy , forming a tree of locks with timing info . the currently active <nl> external deploys are shown in an ' ongoing-recording ' field of <nl> /nodes/v2/locks . <nl> - the 0 longest external deploys are kept in ' recordings ' in /nodes/v2/locks . <nl> - extracts the global process-wide parts of threadlockstats into separate <nl>",0.9546545147895813
apache_druid/11358,"enrich expression cache key information to support expressions which depend on external state such as lookups <para-sep> the layout of the serialized cache key is like below . <nl> sort the byte array list to guarantee that collections of same items but in different orders make the same result <nl> add a collection of strings to the cache key . strings in the collection are concatenated with a separator of '0xff ' , and they appear in the cache key in their input order . <nl> add a collection of strings to the cache key . strings in the collection are sorted by their byte representation and concatenated with a separator of '0xff ' . <nl> add a collection of cacheables to the cache key . cacheables in the collection are concatenated without any separator , and they appear in the cache key in their input order . <nl> add a collection of cacheables to the cache key . cacheables in the collection are sorted by their byte representation and concatenated without any separator . <nl> same should have same cache key <nl> different should not have same key <nl> only check for equality if lengths are equal","this causes incorrect results if the underlying lookup has changed , as the cache key did not encode this information and so remains unchanged , despite that the expression would result in a different value with the newer lookup . <nl> this has been resolved by making extend and providing a default implementation which uses the stringified form , but is overridden by the lookup expression to form a composite key of the stringified expression and the lookup extraction functions cache key . <nl> i moved from to , which was marked with , so tagging with release notes (",1623368582,"recently i spend maybe about 0 hours trying to understand . in hopes to make it simpler for other people , i refactored this class . <nl> in order to clarify the logic , i added a separate method , that brings a secondary benefit : listeners registered with could proceed with partially initialized node view if they want , even if some node type did n't report initialization for whatever reason . although i did n't change any of those listeners yet . <nl> finally , prohibited and eliminated some suboptimal java 0 usage patterns .",0.9597302079200745
vespa-engine_vespa/17256,"resolve container-cpu-cap based on cluster type and id <para-sep> cluster type from com.yahoo.config.provision.clusterspec.type : :value , e.g . content , container , admin / cluster id from com.yahoo.config.provision.clusterspec.id : :value , e.g . cluster-controllers , logserver . / <nl> * / <nl> * /",the goal is to enable higher cap for the cluster type ' admin ' and cluster id ' cluster-controllers ' . if the cap is applied to cluster type ' admin ' it would also include ' logserver ' ( which would probably be ok ) .,1617271912,"a certificate is added to the tls configuration from the application package when there is set a tag inside the context . <nl> the configuration syntax is probably not how we want to go about it , but it was what was easy to implement for now . will update configuration once we know more about how we want to do it .",0.9295539259910583
apache_pulsar/10179,"tc recover handle committing and aborting status transaction . <cm-sep> add the doc <para-sep> this is for recover open status transaction . the key is this transaction 's sequenceid , the value is this transaction timeout time . when transaction update status to committing or aborting , it will be remove form this . when transactionmetadatastore recover complete , the transaction do n't update status , it will send all transaction to transactiontimeouttracker . <nl> update transaction to committing status . when transaction update status to committing , it will be add in . when transaction update status to committed status , the transaction will remove from it . when transactionmetadatastore recover complete , all transaction in this will endtransaction by commit action . <nl> update transaction to aborting status . when transaction update status to aborting , it will be add in . when transaction update status to aborted status , the transaction will remove from it . when transactionmetadatastore recover complete , all transaction in this will endtransaction by abort action .","does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1617953792,change jsonschema to generate a avro schema from pojo so we can standardize on using avro schema,0.9814943671226501
elastic_elasticsearch/72601,"service accounts have no roles , i.e . it is always an empty list . hence <nl> it is better to not show it in the denial error message to reduce <nl> clutter . <para-sep> also not printing roles for service accounts since they have no roles","service accounts have no roles , i.e . it is always an empty list . hence <nl> it is better to not show it in the denial error message to reduce <nl> clutter .",1620017145,"this commit adjusts the behavior when calculating the diff between two <nl> objects , so that the default values of settings <nl> whose default values depend on the values of other settings are <nl> correctly calculated . previously , when calculating the diff , the default <nl> value of a depended setting would be calculated based on the default <nl> value of the setting ( s ) it depends on , rather than the current value of <nl> those settings .",0.9290120005607605
Alluxio_alluxio/12506,"remove flakiness for table journal test <para-sep> detach any previously attached db . <nl> ignore , since the db may not have been attached previously <nl> restarts the masters ( without formatting ) and waits for the workers to re-register .",a few different fixes to remove the flakiness of these tests . <nl> - reset the cluster between tests <nl> - detach the db to cleanup <nl> - wait for workers to register,1605294662,"instead of creating temp directories in /tmp , we will create them in /tmp/alluxio-tests/ and delete this directory at the start and end of testing .",0.9085172414779663
OpenAPITools_openapi-generator/9035,"fix integer enum in csharp generators <para-sep> comment out the following as model.datatype is always the model name , eg . a better solution is to introduce islong , isinteger , etc in the defaultcodegen so that there is no need for each generator to post-process model enums . <nl> / / test outerenuminteger /",- fix integer enum in csharp generators <nl> - add a test to cover the issue moving forward <nl> - remove unused file : modules/openapi-generator/src/main/resources/csharp-netcore/enumclass.mustache .,1616406697,- better oneof and anyof implementation ( based on java jersey2-experimental approach ) .,0.7861798405647278
Graylog2_graylog2-server/10462,"some users want to use the same attribute ( e.g . ' cn ' ) for different <nl> config settings . ( e.g . name and full name ) . <nl> also do n't skip the unique id attribute when collecting user attributes . <nl> this is an issue when the same attribute is used for the unique <nl> attribute and another config setting ( note recommended ) because the <nl> attribute will be missing from user details . <nl> adjust the ldap login test output to use a special key for the unique id <nl> attribute to avoid confusion because of the base64 encoded value . <nl> ( cherry picked from commit sha ) <para-sep> use regular hashmap to allow duplicates . users might use the same attribute for name and full name . <nl> use a special key for the unique id attribute . if users use something like ' uid ' for the unique id , it might be confusing to see a base64 encoded value instead of the plain text one . <nl> use regular hashmap to allow duplicates . users might use the same attribute for name and full name . <nl> use a special key for the unique id attribute . if users use something like ' uid ' for the unique id , it might be confusing to see a base64 encoded value instead of the plain text one .",some users want to use the same attribute ( e.g . ' cn ' ) for different <nl> config settings . ( e.g . name and full name ) . <nl> also do n't skip the unique id attribute when collecting user attributes . <nl> this is an issue when the same attribute is used for the unique <nl> attribute and another config setting ( note recommended ) because the <nl> attribute will be missing from user details . <nl> adjust the ldap login test output to use a special key for the unique id <nl> attribute to avoid confusion,1618836090,"the only populated the field of the generated elasticsearch document if the field was filled , but not if the field in the map was being used . <nl> this lead to inconsistent ' exports ' of the internal representation .",0.8877629041671753
neo4j_neo4j/11555,"fix issue with cost planning index seeks . <nl> make sure we get a minimum cardinality estimate of 0 when planning <nl> leaf operators or filters , since it makes no sense to plan based on <nl> estimations of 0 . <nl> a cardinality estimation of 0 on e.g . an index seek or scan is likely <nl> to be caused by an empty label or incomplete or outdated statistics . <nl> this can lead to a bad plan that does not scale . <nl> and if the real cardinality turns out to indeed be 0 , <nl> it does n't matter what plan we chose , so we might as well plan with <nl> a safer estimate . <para-sep> these tests are similar with the tests in leafplanningintegrationtest , but instead test with an actual database to make sure they work with the whole stack including settings in the database configuration . for more light-weight testing please use [ [ org.neo4j.cypher.internal.compiler.v3_2.planner.logical.leafplanningintegrationtest ] ] <nl> this will yield 0 ^ 0 = 0 combinations def nodeswithoutlabelgen = list ( 0 , 0 , 0 , 0 ) def anodeswithoutpropgen = list ( 0 , 0 , 0 , 0 ) def bnodeswithoutpropgen = list ( 0 , 0 , 0 , 0 ) def anodeswithpropgen = list ( 0 , 0 , 0 , 0 ) def bnodeswithpropgen = list ( 0 , 0 , 0 , 0 ) <nl> this will yield 0 ^ 0 = 0 combinations","make sure we get a minimum cardinality estimate of at least 0 when planning <nl> leaf operators or filters , since it makes no sense to pick a plan based on <nl> estimations of 0 . <nl> a cardinality estimation of < 0 on e.g . an index seek or scan is likely <nl> to be caused by an empty database , incomplete or outdated statistics . <nl> this can lead to a bad plan that does not scale , especially for large import queries . <nl> if the real cardinality turns out to indeed be 0 when executing the",1523808699,"the shortest path algorithm does not work when the start and end nodes are the same . this can happen if you perform a shortestpath search after a cartesian product that might have the same start and end nodes for some of the rows passed to shortestpath . if you would rather not experience this exception , and can accept the possibility of missing results for those rows , disable this in the neo4j configuration . if you can not accept missing results , and really want the shortestpath between two common nodes , then re-write the query using a",0.9549298882484436
netty_netty/11402,"weakorderqueue should check defaulthandler.hasbeenrecycler field . <nl> motivation : . <nl> weakorderqueue would drop object that has been recycle , event there has space for it . <nl> weakorderqueue # add should check defaulthandler.hasbeenrecycler field first . <nl> modifications : . <nl> weakorderqueue test the defaulthandler.hasbeenrecycler first . <nl> result : . <nl> weakorderqueue would not drop object that has been recycled when there has has space <para-sep> drop the item to prevent from recycling too aggressively . <nl> always recycler the first object , that is ok <nl> the object should be recycled <nl> it should be the same object , right ?","weakorderqueue should check defaulthandler.hasbeenrecycled field . <nl> motivation : . <nl> weakorderqueue would drop object that has been recycle , event there has space for it . <nl> weakorderqueue # add should check defaulthandler.hasbeenrecycled field first . <nl> modifications : . <nl> weakorderqueue test the defaulthandler.hasbeenrecycled first . <nl> result : . <nl> weakorderqueue would not drop object that has been recycled when there have space",1624199441,"motivation : . <nl> the may cache the received messages in a queue in order to do the flow control . however , if this handler is manually removed from pipeline during runtime , those cached messages might not be passed to the next channel handler forever . <nl> modification : . <nl> dequeue all these cached messages and call in method . <nl> result : <nl> avoid losing the received messages .",0.9254698753356934
OpenAPITools_openapi-generator/9081,remove dart jaguar config and samples,remove dart-jaguar configs and samples in preparation for marking client generator as deprecated in version branch .,1616679099,"add hasbasicauthmethods & hastokenauthmethods methods , use to decide which authentication code to use in standard java and java+resttemplate templates .",0.8357725143432617
Alluxio_alluxio/12449,log slow remote reads and writes,"for worker remote reads and writes , if a particular read or write takes longer than expected , we log ( via the sampling logger ) a message to give a sense of the delays .",1604353580,"when the client buffer size is large ( > 2mb ) and reads are guaranteed to be somewhat sequential , the api to hdfs is not as efficient as simple . we introduce a heuristic to choose which api to use .",0.9642733335494995
vespa-engine_vespa/18258,additional fields to user - verified and lastlogin <para-sep> remove this after june 0 ( once all security filters are setting this ),i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623742784,make it possible to configure and change status code in /state/v1/health api . <nl> make inital value configurable and make it possible to get and set it <nl> in statemonitor . <nl> use this to set state to 'initalizing ' until bootstrap is done in config server,0.9241713285446167
netty_netty/11215,preload classes before calling native onload function to prevent classloader deadlock . <nl> motivation : . <nl> it turns out it is quite easy to cause a classloader deadlock in more recent java updates if you cause classloading while you are in native code . because of this we should just workaround this issue by pre-load all the classes that needs to be accessed in the onload function . <nl> modifications : . <nl> - preload all classes that would otherwise be loaded by native onload functions . <nl> result : . <para-sep> load the class and also ensure we init it which means its linked etc . <nl> ignore <nl> ignore <nl> important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update macosdnsserveraddressstreamprovider to reflect that . <nl> preload all classes that will be used in the onload ( ... ) function of jni to eliminate the possiblity of a class-loader deadlock . <nl> this needs to match all the classes that are loaded via netty_jni_util_load_class or looked up via netty_jni_util_find_class . <nl> netty_resolver_dns_macos <nl> important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update native to reflect that . important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update native to reflect that . <nl> preload all classes that will be used in the onload ( ... ) function of jni to eliminate the possiblity of a class-loader deadlock . <nl> this needs to match all the classes that are loaded via netty_jni_util_load_class or looked up via netty_jni_util_find_class . <nl> netty_epoll_linuxsocket <nl> netty_epoll_native <nl> important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update native to reflect that . important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update native to reflect that . important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update native to reflect that . <nl> preload all classes that will be used in the onload ( ... ) function of jni to eliminate the possiblity of a class-loader deadlock . <nl> this needs to match all the classes that are loaded via netty_jni_util_load_class or looked up via netty_jni_util_find_class . <nl> netty_kqueue_bsdsocket <nl> important : if you add any netty_jni_util_load_class or netty_jni_util_find_class calls you also need to update unix to reflect that . important,preload classes before calling native onload function to prevent classloader deadlock . <nl> motivation : . <nl> it turns out it is quite easy to cause a classloader deadlock in more recent java updates if you cause classloading while you are in native code . because of this we should just workaround this issue by pre-load all the classes that needs to be accessed in the onload function . <nl> modifications : . <nl> - preload all classes that would otherwise be loaded by native onload functions . <nl> result : .,1619768152,"motivation : . <nl> datagrampacket.recipient ( ) does n't return the actual destination ip , but the ip the app is bound to . <nl> modification : . <nl> - option is enabled for udp sockets , which allows retrieval of ancillary information containing the original recipient . <nl> - function from is modified such that if is set , is used instead of ; enabling the retrieval of the original recipient . <nl> - also contains a 'local ' address , representing the recipient . <nl> - is updated to return the retrieved recipient address instead of the address",0.9060053825378418
apache_druid/10743,"i put my thing down , flip it and reverse it <para-sep> the first iteration destroys the heap , but writes out the sorted array in reverse <nl> write out offset to end of heap , which is no longer used after removing min <nl> do nothing <nl> subsequent iterations just walk the buffer backwards <nl> do nothing <nl> iterate again , even though the min-max offset heap has been destroyed , it is replaced with a reverse sorted array <nl> iterate again , even though the min-max offset heap has been destroyed , it is replaced with a reverse sorted array <nl> an attempt to aggregate with a new key will explode after the grouper has been iterated <nl> can not vectorize due to virtual columns .","to fix this , we can exploit that the min-max heap is stored as a contiguous array , and the continual removal of the min element ( which is the first element of the backing array ) and subsequent rebalance of the heap that follows will leave the a newly freed space at the end of the array , allowing us to write the sorted array of offsets in reverse . subsequent iterators can then just provide the reverse ordered array . <nl> to illustrate with an example , here is how the min-max heap normally behaves ( with the",1610408009,"these did n't work before , since the top project rel was n't getting <nl> merged into the druidsemijoin rel . this patch allows that to happen .",0.9238196015357971
grpc_grpc-java/8023,"add a utility class for loading certs/keys <para-sep> contains certificate/key pem file utility method ( s ) . <nl> generates x509certificate array from a pem file . the pem file should contain one or more items in base64 encoding , each with plain-text headers and footers ( e.g . <nl> the pem file should contain one item in base64 encoding , with plain-text headers and footers ( e.g . <nl> * / <nl> checks some information on the test certificate . <nl> checks some information on the test key . <nl> checks some information on the test certificate . <nl> the error messages for openjdk 0 and 0 are different , and for windows it will generate a different exception , so we only check if a general exception is thrown . <nl> the error messages for openjdk 0 and 0 are different , and for windows it will generate a different exception , so we only check if a general exception is thrown .","this is to add a certificate/key loading class in , under the help of base64 decoding support by guava . <nl> thank you so much !",1616870096,"a dummy name resolver for target uri with scheme ' xds ' that always returns a hard-coded service config selecting lb policy with as child policy . <nl> todo : we may want to add test coverage for in , which requires test dependency on package . same for in .",0.9703738689422607
netty_netty/11351,fix ipsubnetfilterrule with ipv6 default route does not accept all ipv6 addresses .,motivation : . <nl> modification : . <nl> added support for default rule . <nl> result : .,1622602418,"motivation . <nl> it currently will succeed when the destination is larger than the source range , but the javadoc states this should be a failure , as is the case with all the other implementations . <nl> modifications . <nl> - fix logic to fail the bounds check in this case <nl> - remove explicit null check which is n't done in any equivalent method <nl> - add unit test . <nl> result . <nl> more correct/consistent behaviour",0.7654961347579956
apache_beam/14014,"add autoloadedsqltransform , which runs sql queries using the auto loading mechanisms . <para-sep> load automatic table providers before user ones so the user ones will cause a conflict if the same names are reused .","this is a simple answer to the question : ' how do i use beam sql in java ' , which does not currently exist outside of ' impl ' packages",1613659320,"since was reviewed , merged and then reviewed again , i 'm posting a follow-up pr to address the comments from the last review . <nl> we can either fix them in this or some other prs later ( if needed ) . <nl> thanks !",0.9543464779853821
neo4j_neo4j/11539,improve test name . <cm-sep> remove duplicated api mix test . <cm-sep> moved rollback-tests on kernel api level into kernel api module <cm-sep> move some kernel api tests from neo4j-lucene-index to neo4j-kernel <cm-sep> remove duplicates of nodetransactionstatetestbase.shouldseelabelchangesintransaction <cm-sep> migrate assertion to nodetransactionstatetestbase.shouldseelabelchangesintransaction <cm-sep> migrate assertion to nodewritetestbase <cm-sep> remove duplicates of nodewritetestbase tests . <cm-sep> migrate noderemovelabel result assertion <cm-sep> delete test that is no longer needed due to api changes <cm-sep> migrate node delete test in nodelabelscan to nodelabelindexcursortestbase <cm-sep> remove imports <para-sep> given <nl> when <nl> obs : not marked as tx.success ( ) ; <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> wanted <nl> then,"i found this old test-class called kernelit , which contained lot 's on test duplicates and other strange things . cleaned it up a bit .",1523565520,"due to architectural problems , most user management has been removed from neo4j-admin . the only command that remains is the . however , this command has been modified to only set an initial user on server startup .",0.9336793422698975
elastic_elasticsearch/73467,shadowed dependencies should be hidden from pom dependencies,this fixes the pom generation for projects using the shadow plugin .,1622116389,"this had <nl> the side effect of fixing the handling of for <nl> to include hidden indices . however , the tests in watcherutilstests were <nl> missed . this change updates those tests .",0.8999655842781067
apache_pulsar/10146,"fix transaction log recover problem . <cm-sep> change test name <para-sep> txnid1 have not deleted from cursor , we can recover from transaction log <nl> txnid2 have deleted from cursor .","does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1617691132,"when the subscriptions reach the max subscriptions of the topic , the broker should reject the new subscription request and reject the consumer to subscribe to this topic . <nl> 0. add limit max subscriptions per topic .",0.9192720651626587
ballerina-platform_ballerina-lang/30150,fix casting issue when using var with a table returned from a query <cm-sep> add unit tests for query expressions <cm-sep> fix cce issue with type definitions <cm-sep> add negative test for type definitions,fix following issues <nl> - fix casting issue when using var with a table returned from a query <nl> - fix cce issue with type definitions .,1619069177,those are submitted to the scheduler to be scheduled .,0.8357937932014465
runelite_runelite/13181,set up config for portal nexus entry swapping <cm-sep> set up portal nexus swaps,"this has been done by implementing a config setting in the menu entry swapper ui which , if activated , will swap any set left click teleport for the teleport menu option . <nl> not sure if this is the most efficient way to do it so happy for feedback !",1612822259,"this is intended to make the tags feature more discoverable , as people keep requesting ' plugin categories ' . putting plugins into a singular category that will make sense for most users is impossible , as many plugins will can logically be placed into multiple categories . <nl> the category tag list is intended to be a short , curated , list of tags that are helpful to a user trying to find plugins . <nl> the icon for this list only shows up when the input is empty , otherwise it shows the existing clear button .",0.8607807755470276
apache_incubator-pinot/6811,"normalize lhs and rhs numerical types for = and ! = operator . <para-sep> check if response can be send without server query evaluation . <nl> we do n't need to evaluate offline request <nl> we do n't need to evaluate realtime request <nl> send empty response since we do n't need to evaluate either offline or realtime request . <nl> drop offline request filter since it is always true <nl> drop realtime request filter since it is always true <nl> * / <nl> * / <nl> numerical expressions of form ' column = literal ' or ' column ! = literal ' can compare a column of one datatype ( say int ) with a literal of different datatype ( say double ) . these expressions can not be evaluated on the server . hence , we rewrite such expressions into an equivalent expression whose lhs and rhs are of the same datatype . simple predicate examples : 0 ) where ' intcolumn = version ' gets rewritten to ' where intcolumn = 0 ' 0 ) where ' intcolumn ! = version ' gets rewritten to ' where intcolumn ! = 0 ' 0 ) where ' intcolumn = version ' gets rewritten to ' where false ' because int values can not match version . 0 ) where ' intcolumn = 0 gets rewritten to ' where false ' because int values can not match 0 . 0 ) where ' intcolumn ! = 0 gets rewritten to ' where true ' becuase int values always not equal to 0. compound predicate examples : 0 ) where ' intcolumn1 = version and intcolumn2 = intcolumn3 ' rewrite to ' where false and intcolumn2 = intcolumn3 ' rewrite to ' where intcolumn2 = intcolumn3 ' 0 ) where ' intcolumn1 ! = version or intcolumn2 = 0 ' ( 0 is out of bounds for integer column ) rewrite to ' where true or false ' rewrite to ' where true ' rewrite to query without any where clause . when entire predicate gets rewritten to false ( example 0 above ) , the query will not return any data . hence , it is better for the broker itself to return an empty response rather than sending the query to servers for further evaluation . <nl> do n't do anything here since this is for pql queries","0 . <nl> 0 . <nl> 0 . <nl> 0. . <nl> this happens because we currently do n't support upcasting and downcasting of numerical predicates with different data types . also note that constant expressions ( ) are evaluated on the broker side and converted to double value ( ) which fail to evaluate on the server side since literal type no longer matches column type . <nl> to solve this problem , we rewrite the predicate on the broker side to an equivalent predicate whose literal type is same as the column expression type before the query is",1618705747,add a tool to create and update tables using the new table <nl> configuration format .,0.968428909778595
apache_pulsar/10190,"fix flaky-test and reader can not read data <para-sep> this situation will occur when : 0.we have n't read yet 0.the connection was reset multiple times 0.broker has pushed messages to receiverqueue , but messages were cleaned due to connection reset","start to read - > 0:0 threadid:0 <nl> after read , update read position - > 0:0 threadid:0 <nl> start to read - > 0:0 threadid:0 . <nl> warn org.apache.pulsar.client.impl.consumerimpl - [ persistent : //my-property/my-ns/my-reader-topic-with-batching-inclusivebdcf4a3c2d36-b362-sha- ] could not get connection while getlastmessageid -- will try again in 0 ms . <nl> info org.apache.pulsar.client.impl.consumerimpl - [ persistent : //my-property/my-ns/my-reader-topic-with-batching-inclusivebdcf4a3c2d36-b362-sha- ] get topic last message id . <nl> info org.apache.pulsar.client.impl.consumerimpl - [ persistent : //my-property/my-ns/ <nl> my-reader-topic-with-batching-inclusivebdcf4a3c2d36-b362-sha- ] successfully getlastmessageid 0:0 . <nl> info org.apache.pulsar.client.impl.consumerimpl - [ persistent : //my-property/my-ns/my-reader-topic-with-batching-inclusivebdcf4a3c2d36-b362-sha- ] seek subscription to the message 0:0:0:0 . <nl> brokerlastdequeuedmessageid=earliest , startmessageid=seekmessageid",1618224605,"right now , kinesissink 's credentialprovider-plugin does n't support session-token which can be used in case user access stream with iam-role instead iam-user . <nl> - made kinesissink 's credentialprovider plugin more generic which can be used by both iam user and roles . <nl> - add documentation for kinesissink usage . <nl> - add test cases for kinesis sink . <nl> - kinesissink can be used for iam roles as well .",0.9774333834648132
apache_camel/5545,: route template parameter should be able to be marked explicit as required . <cm-sep> : route template parameter should be able to be marked explicit as required . <para-sep> this is a required parameter which is missing <nl> adds a required parameter the route template uses adds an optional parameter the route template uses <nl> adds an optional parameter the route template uses <nl> adds a parameter ( will use default value if not provided ) the route template uses adds a parameter ( will use default value if not provided ) the route template uses <nl> assumed to be required if not set explicit to false <nl> the name of the parameter <nl> whether the parameter is required or not . a parameter is required unless this option is set to false or a default value has been configured .,: route template parameter should be able to be marked explicit as required .,1620799031,"two tests of reconnect logic . <nl> reconnect for producer is really simple , because it 's based on genericobjectpool capabilities . providing session validation and testonborrow is enough to seamless reconnect . <nl> consumer is much worse case and i 'm not so very proud about this solution . because objects in pool are never pooled , there is no chance to test them on borrow . i 'm catching exception on jms connection and i 'm doing a full reset of whole consumer ( stop/start on executor ) . i 'm opened for better ideas , that will",0.9545267820358276
hazelcast_hazelcast/18660,"call shutdown jobs even before setting shuttingdown to true <para-sep> called before node attempts to join to the cluster <nl> shutdowns nodeextension . called on node.shutdown ( ) right after setting the state to passive . <nl> returns the security service if security context is available . <nl> called on thread start to inject/intercept extension specific logic , like ; registering thread in some service , executing a special method before thread starts to do its own task . <nl> called when initial cluster state is received while joining the cluster . <nl> called after the cluster state change transaction has completed ( successfully or otherwise ) . called only on the member that initiated the state change . <nl> creates a uuid for local member <nl> returns a byte array processor for incoming data on the multicast joiner * / <nl> returns a byte array processor for outgoing data on the multicast joiner * / <nl> cluster version auto upgrade is done asynchronously . every call of this method creates and schedules a new auto upgrade task .","before the merge we used to call shutdownjobs in , now we 've moved it to . but it is called after setting to true and this makes some operations ( obtaining an imap proxy to store snapshots for example ) to fail when gracefully shutting down the jobs . with this change we call then continue with the shutdown . <nl> on the ee side , we shutdown hotrestart and cppersistense in . with this change we call shutdown for these services before setting the state to passive , to fix this we 've added . <nl> before the",1620659634,"is sent from a member to check ( and trigger if needed ) whether keys loading is done on the side . instead , previously reported whether . <nl> also includes a cleanup of redundant variables in .",0.945500373840332
elastic_elasticsearch/72716,disable geoip downloader <cm-sep> docs <cm-sep> actions <cm-sep> actions <cm-sep> docs/specs,we use as feature flag . <nl> this change also reverts changes to docs .,1620152390,browsers are sending media ranges with quality factors on accept header . <nl> we should ignore the value and respond with applicaiton/json .,0.9172417521476746
apache_flink/15547,"exclude is null from search operators <para-sep> copied to fix calcite version bugs , should be removed for the next calcite upgrade . changes ( line numbers are from the original rexsimplify file ) : & : line 0 , line 0 , line 0 ~ line 0 . & : line 0 ~ line 0 , line 0 ~ line 0. changed : we remove is_null here because search operator in calcite version handles unknowns incorrectly see changed : we remove is_null here because search operator in calcite version handles unknowns incorrectly see","in calcite version , expressions like will be simplified to . this is incorrect because searching for null is always false ( this is a bug , fixed in ) . <nl> this pr exclude from operators to solve this issue . <nl> - exclude is null from search operators . <nl> this change added tests and can be verified by running the added tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers",1617958110,"this pull request use current classloader to load classes which fix parameters -- library adn -- jar in sqlclient can not play correctly . <nl> - update file org/apache/flink/table/factories/tablefactoryservice.java . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl>",0.8343584537506104
apache_flink/15257,"introduce supportsanynull to binaryrowdata <cm-sep> comment <para-sep> provides null related getters . * / <nl> if no field is null , return false . returns true if one of the columns is null . * / <nl> for the input fields , if no field is null , return false . returns true if one of the columns is null .","# # what is the purpose of the change . <nl> introduce supportsanynull to binaryrowdata . <nl> we should avoid force casting to implementation . it is better to rely on interface . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) no <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) no <nl> - the serializers : ( yes / no / do n't know ) no",1616038074,"please note i am a current datadog employee . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",0.8736804127693176
jenkinsci_jenkins/5479,pass the submitter to requestsubmit ( ) <para-sep> avoid double form submission in htmlunit <nl> trying very hard to find the right button ...,"this is where i 'm at , trying to untangle this version regression with htmlunit tests on some submit buttons . <nl> what i 've understood so far : <nl> - passing the ' submitter ' parameter is indeed required in some cases with htmlunit <nl> - the ' submitter ' param has to be a or ( otherwise we get a js exception ) <nl> - it is possible to get the clicked button in yui/button function ( not sure my method is always correct , nor that it is the simplest one ) <nl> - unfortunately , this",1620686210,"on not english systems , the test will fail because the actual message is localized . so i set the locale before the test and reset it afterwards . <nl> * internal",0.8629809617996216
Alluxio_alluxio/12800,add debug log to log request size,when the worker has a large number of blocks the request can be big for worker register and block heartbeat . adding a little debug log for better traffic visibility .,1612340607,backup to root ufs by default and modify the docs,0.8989914655685425
vespa-engine_vespa/17904,throw convergenceexceptions instead <cm-sep> throw if a coredump is being written while trying to remove linux container,"when removing the linux container , throw while a coredump is being written . nodeagent will retry on the next ticks and eventually the core should finish writing and will be processed before the container is removed .",1621435243,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9226185083389282
elastic_elasticsearch/73655,"remove getmatchingfieldtypes method . <nl> fieldtypelookup and mappinglookup expose the getmatchingfieldtypes method to look up matching field type by a string pattern . we have migrated existsquerybuilder to instead rely on getmatchingfieldnames , hence we can go ahead and remove the remaining usages and the method itself . <nl> the remaining usages are to find specific field types from the mappings , specifically to eagerly load global ordinals and for the join field type . these are operations that only needs access to the index time field types , which makes it much simpler to support . we already have a specific index time lookup within mappinglookup , which we can reuse for this . <para-sep> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field","fieldtypelookup and mappinglookup expose the getmatchingfieldtypes method to look up matching field type by a string pattern . we have migrated existsquerybuilder to instead rely on getmatchingfieldnames , hence we can go ahead and remove the remaining usages and the method itself . <nl> the remaining usages are to find specific field types from the mappings , specifically to eagerly load global ordinals and for the join field type . these are operations that are performed only once when loading the mappings , and may be refactored to work differently in the future . for now , we remove getmatchingfieldtypes",1622628282,"this commit refactors some of the rest test transformations unit tests . <nl> specifically , this refactor introduces a common parent that the ' match ' <nl> tests ( and other future tests ) can consume . also , the example tests <nl> have been simplified to better illustrate the change . <nl> there should no functional changes , just refactoring . this will help with <nl> future commits to allow focus only for the relevant changes .",0.9675769805908203
vespa-engine_vespa/17958,detect and work around null records <para-sep> returns the number of times questdb has returned null records since last gc * /,i 'm asking the questdb devs about this but in the meantime this should work around the issue .,1621922840,this makes it easier to create additional instances for testing <nl> other services against it .,0.9065597653388977
vespa-engine_vespa/17520,handle retirement failure <cm-sep> increase maintainer frequency <para-sep> todo : remove try/catch once retirement is stabilized <nl> check if retirement actually failed,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1619010481,"first commit is part of a different pr , but conflicts shnomgflicst .",0.8701617121696472
apache_kafka/10282,added partitionmetadata file code to raftreplicamanager <cm-sep> check for inconsistent topic id,"introduced partition.metadata file to persist the topic id on the broker . it is created through handling the leaderandisrrequest in replicamanager . raftreplicamanager was missing the analogue code path for code . like in replicamanager , raftreplicamanager will now check the partition.metadata file when handling metadata records . <nl> however , since we know that all raft topics will have topic ids , we can simply set the id in the log upon the log 's creation . <nl> updated the replicamanager path to do the same on newly created topics . <nl> there are some tweaks to the checking",1615245291,"but enabling caching on a store that 's configured to retain duplicates is actually more than just ineffective , and currently causes incorrect results . <nl> we should just log a warning and disable caching whenever a store is retaining duplicates to avoid introducing a regression . maybe when version comes around we should consider throwing an exception instead to alert the user more aggressively .",0.9078909754753113
confluentinc_ksql/7155,allows pull query filters that are n't of the form col op literal <cm-sep> adds more cases <para-sep> first see if we can find a direct column reference,"prior to this , a comparison must have been of the form or possibly where there was a column on one side and a resolvable expression on the other . when table scans are enabled , now these can be done : <nl> - both sides are column references ( e.g . ) <nl> - neither side is a column reference ( e.g . , ) <nl> - one side is a column reference and the other is an unresolveable expression ( e.g . )",1614823688,previously a new ksqlclient instance was being created for each inter node request ( e.g . pull query forwarding ) . there is a ksqlclient constructor which takes a sharedclient instance but this was never being used in the production code path . <nl> this pr does the following : . <nl> each server now maintains a ksqlclient instance which is used for all inter node requests <nl> the server 's vert.x instance is passed to the ksqlclient instance . <nl> unit and integration tests are expected for any behavior changes._ .,0.9606298804283142
vespa-engine_vespa/17120,"require 0 config server ( and controller ) hosts . <nl> we already require 0 config server ( and controller ) nodes , but it is not <nl> sufficient to protect the hosts from being left with only 0 healthy host : say <nl> the config server host application contains 0 nodes . an upgrade of host-admin <nl> on one of those nodes is allowed , since only the host is suspended and none of <nl> the 0 nodes are down . this is fixed by handling config server hosts similar to <nl> config servers : assume 0 nodes . <para-sep> a config server application has a particularly simple applicationinstanceid .","we already require 0 config server ( and controller ) nodes , but it is not <nl> sufficient to protect the hosts from being left with only 0 healthy host : say <nl> the config server host application contains 0 nodes . an upgrade of host-admin <nl> on one of those nodes is allowed , since only the host is suspended and none of <nl> the 0 nodes are down . this is fixed by handling config server hosts similar to <nl> config servers : assume 0 nodes .",1616497558,"should status.html also be protected from stealing ? <nl> i did n't add an check before throwing when a reserved binding is used . if you try to steal a binding today , the built-in handler wins , but deployment does not fail .",0.9514145851135254
ballerina-platform_ballerina-lang/29874,"fix built-in type parsing issues in expression context <cm-sep> fix doc parsing issue and enable tests <para-sep> todo : enable assert assert ittercount == itter_limit : ' fail safe reached ' ; <nl> check if the token kind is a type descriptor in terminal expression . simple-type-in-expr : = boolean | int | byte | float | decimal | string | handle | json | anydata | any | never <nl> simple_type_desc_identifier is already included in type_reference . but added separately , in order to give ' error_missing_type_desc ' diagnostic . <nl> test parsing typed binding patterns . <nl> valid syntax <nl> recovery tests <nl> compiler should be able to compile any user input . therefore , when adding an item to the skip list , please create an issue .",- fix type descriptor as an expression parsing <nl> - fix some error handler rules <nl> - fix fail-safe mechanism issues . <nl> - boolean <nl> - int <nl> - byte <nl> - float <nl> - decimal <nl> - string <nl> - handle <nl> - json <nl> - anydata <nl> - any <nl> - never .,1617718359,additionally this will add worker formatting and assignment formatting for record literals and add fixes went only with next-release branch,0.9561761021614075
ballerina-platform_ballerina-lang/28255,"fix http service snippet <para-sep> each time we build a new completion item to make the snippet aware of the latest sources ( alias changes , etc ) <nl> whether the package is already imported in the current document . <nl> whether the package is already imported in the current document .",0. modify the http service snippet <nl> 0. add context awareness to modify the default import alias of a snippet .,1611742300,language server will no longer provide signature help based on the annotation attachments .,0.9465973973274231
elastic_elasticsearch/74683,"the sequence matching algorithm holds some structures to keep track of <nl> the matched and potentially matching sequences of events . when large <nl> amount of events , sequence stages needs to be processed but also when <nl> the requested size of the query ( number of sequences to return ) is large , <nl> those structure can potentially increase the memory footprint . <nl> add a circuitbreaker which can be configured through cluster settings , <nl> which accounts for the memory used during the execution of a sequence <nl> query . the memory accounting takes place every fetch_size number <nl> of processed events ( docs ) , to avoid significant performance overhead . <nl> ( cherry picked from commit sha ) <para-sep> index string is cached in tumblingwindow and there is no need of accounting for it <nl> the method is called at the end of match ( ) which is called for every sub query in the sequence query and for each subquery every ' fetch_size ' docs . doing ram accounting on object creation is expensive , so we just calculate the difference in bytes of the total memory that the matcher 's structure occupy for the in-flight tracking of sequences , as well as for the list of completed sequences . <nl> break on first iteration <nl> break on second iteration <nl> break on 3rd iteration with clear ( ) called in between","the sequence matching algorithm holds some structures to keep track of <nl> the matched and potentially matching sequences of events . when large <nl> amount of events , sequence stages needs to be processed but also when <nl> the requested size of the query ( number of sequences to return ) is large , <nl> those structure can potentially increase the memory footprint . <nl> add a circuitbreaker which can be configured through cluster settings , <nl> which accounts for the memory used during the execution of a sequence <nl> query . the memory accounting takes place every fetch_size number",1624967121,add hooks to enable waiting for a condition before completing the clean files step for relocating searchable snapshot shards and use them to wait for pre-warm before responding to the clean files request .,0.9665584564208984
vespa-engine_vespa/17931,"warn when specifying resource limits in hosted vespa . <nl> want to throw and fail deployments , but need to make sure nobody <nl> i doing this first , so warn for now <para-sep> todo : throw exception when we are sure nobody is using this throw new illegalargumentexception ( ' element ' + element + ' is not allowed to be set , default limits will be used ' ) ; <nl> todo : change to expect exception being thrown when no one uses this in hosted","want to throw and fail deployments , but need to make sure nobody <nl> is doing this first , so warn for now .",1621532110,take config server out of rotation ( status.html ) until it is bootstrapped . <nl> also make sure that health api status code is 'initializing ' until rpc <nl> server is actually running .,0.9560248255729675
Graylog2_graylog2-server/10637,"create proper swagger schema . <cm-sep> handle generics properly . <cm-sep> fixing corner cases and type names . <cm-sep> add visitor to replace values . <cm-sep> extract inline objects . <cm-sep> adding json annotation . <cm-sep> fixing reference naming , cleaning up unused code . <cm-sep> treat parameters identically to response types . <cm-sep> fix multiple issues , keep parameter types inline if not objects . <cm-sep> fix primitive method response types . <cm-sep> fixing enums and longs . <cm-sep> inline non-object models . <cm-sep> falling back to value when parameter name is not present . <cm-sep> use nickname over method name , if present . <cm-sep> include missing import . <para-sep> final string valuemodelid = ( string ) ( ( map ) models.get ( valuename ) ) .get ( ' id ' ) ; <nl> final objectschema s = schemaprovider.objectschema ( ) ;","this pr is aiming to improve the generated swagger specs by extracting inline models and recursively generate typings for them . before this change , there were a couple of scenarios where we did not generate a schema for a used type , but instead a string literal was used : . <nl> before : . <nl> through these changes , we can now resolve these type names and generate inline schemas which can be used to display the structure of a type : . <nl> after : . <nl> this change does not make type introspection for swagger perfect",1620990399,"before this pr , ssl/tls-encrypted ldap connections did not validate that the hostname of the remote endpoint matches the common name of the certificate presented . this change adds a hostname verifier borrowed from bouncy castle and combines it with the standard pkix path validating trust manager from jsse . <nl> this class ( defaultx509trustmanager ) can and should be reused for other cases where path validation and hostname verification is desired and the underlying client library does not offer a builtin method .",0.9599356651306152
Alluxio_alluxio/12453,"fix multi-process read perf issue . <cm-sep> fix multiple process read perf issue , by creating shared grpc data reader . <para-sep> protect the original seek logic under fuse flag to minimize and isolate the fuse related changes <nl> todo ( lu ) combine the original seek logic and the following general improvements that are helpful in both fuse and non-fuse scenarios try to read data already received but have n't processed <nl> todo ( chaowang ) introduce seek in databuffer <nl> not enough data in queue , close the data reader <nl> a grpc data reader that responsible for reading from a specific block . the current implementation cached the block data from the beginning to the largest index being read . <nl> count the number of threads that are accessing the same block together . when no thread is accessing this block , the cached data will be gced . <nl> the next pos to read . * / <nl> reads a specific chunk from the block . <nl> reads a chunk of data . <nl> nothing is done as the receipt is sent at best effort <nl> increases the reference count and return the current count . <nl> decreases the reference count and return the current count .","shareddatareader buffers blocks on the client side . it will buffer a block from index 0 to the biggest index being read . only when no processes/threads accessing this block will the block buffer being removed . <nl> 0 ) seek ( pos ) improvements . previously close and reopen datareader introduce many overheads . the improvements look like target to reduce the datareader reopen . when reading backward , shareddatareader can directly read from local cache . when reading forward , instead of doing seek ( ) , the blockinstream will try to read data already received but not",1604382919,added apis for intercepting grpc client and server with custom data serialization/deserialization . <nl> also made the worker send read response asynchronously to improve throughput for single read request .,0.9888060688972473
apache_pulsar/10389,fixed license header <para-sep> added null check to prevent test failures,"i created a new pr because it looked like the branch for that repo ( ) involved a change for a different issue , and github indicated the repo had been deleted . ( i was unable to find the original commits on that repo in a branch . ) <nl> ( in that case , i 'll delete this pr and add my commits to your branch . )",1619469906,reuse binary decoder object in avroschema to minimize the number of objects created,0.9059866666793823
apache_pulsar/10743,user token secret mounted as default 0 permission,"in the rootless docker container , function kubernetes runtime needs to read /etc/auth/token . but currently the file permission is mounted as 0 under . <nl> use the default kubernetes secret mount permission , which allows non-root user to read the auth token . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : no <nl> - the schema : no <nl> - the default values of configurations : no <nl> - the wire protocol : no <nl> - the",1622321341,# # # motivation . <nl> forcibly delete batch source intermediate topic,0.7601200938224792
apache_druid/11104,"add experimental expression aggregator <para-sep> deserialize an expression stored in a bytebuffer , e.g . for an agg . this should be refactored to be consolidated with some of the standard type handling of aggregators probably <nl> | expression type ( byte ) | expression bytes | <nl> | expression type ( byte ) | is null ( byte ) | long bytes | <nl> | expression type ( byte ) | is null ( byte ) | double bytes | <nl> | expression type ( byte ) | string length ( int ) | string bytes | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | is null ( byte ) | long bytes | <nl> | is null ( byte ) | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | is null ( byte ) | double bytes | <nl> | is null ( byte ) | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | string length ( int ) | <nl> | string length ( int ) | string bytes | <nl> primitive numeric types are not validated to be lower than max size , so it is expected to be at least 0 bytes . callers of this method should enforce this themselves ( instead of doing it here , which might be done every row ) this should be refactored to be consolidated with some of the standard type handling of aggregators probably <nl> | expression type ( byte ) | string length ( int ) | string bytes | <nl> | expression type ( byte ) | array length ( int ) | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | expression type ( byte ) | array length ( int ) | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | expression type ( byte ) | array length ( int ) | <nl> | expression type ( byte ) | array length ( int ) | array bytes | <nl> | string length ( int ) | <nl> | string length ( int ) | string bytes | <nl>","but , it turns out it was a bit _too_ powerful due to the number of exploitive things you can do with it to the host machine , so it broke my heart . additionally , it was limited to only supporting aggregations of double types , which really cuts down on the expressiveness possible . <nl> in this pr , i have re-imagined the concept of such a flexible aggregator , but sandboxed , using native druid expressions . further , this really rounds out the role of the druid expression system in the query engine . with its",1618270892,"part of like .. being responsible and stuff , before adding this documentation i first wanted to collect some data to determine if it _was a good idea to in fact document it at this time_ . the place i was specifically worried about was the check , so i added a benchmark , , and ran some experiments to see what to expect as well as if we could do better . <nl> the nature of selectors lends itself to using a bitmap iterator as an alternative to calling bitmap.get for every check , so i first tested vs",0.9828568696975708
elastic_elasticsearch/72820,"enhance error message for copy-to . <nl> we currently do n't support for fields that take the form of objects <nl> ( e.g . or certain kinds of variants ) . the current <nl> problem with objects is that when documentparser parses anything other than <nl> single values , it potentially advances the underlying parser past the value that <nl> we would need to stay on for parsing the value again . while we might want to <nl> support this in the future , for now this pr enhances the otherwise confusing <nl> mapperparsingexception with something more helpful and adds a short note in the <nl> documentation about this restriction . <para-sep> sanity check , we currently support copy-to only for value-type field , not objects <nl> in case of a hierarchy of nested documents , we need to figure out which document the field should go to <nl> copy-to works for value-type representations <nl> check failure for object/array type representations","we currently do n't support for fields that take the form of objects <nl> ( e.g . or certain kinds of variants ) . the current <nl> problem with objects is that when documentparser parses anything other than <nl> single values , it potentially advances the underlying parser past the value that <nl> we would need to stay on for parsing the value again . while we might want to <nl> support this in the future , for now this pr enhances the otherwise confusing <nl> mapperparsingexception with something more helpful and adds a short note in the <nl> documentation",1620319413,"this commit changes our behavior in 0 ways : . <nl> - when mapping claims to user properties ( principal , email , groups , <nl> name ) , we only handle string and array of string type . previously <nl> we would fail to recognize an array of other types and that would <nl> cause failures when trying to cast to string . <nl> - when adding unmapped claims to the user metadata , we only handle <nl> string , number , boolean and arrays of these . previously , we would <nl> fail to recognize an array of",0.945547878742218
jenkinsci_jenkins/5419,change indirect accesses to static members to direct accesses ( accesses through subtypes ) <cm-sep> remove unnecessary casts <cm-sep> remove unused imports,applied an automated eclipse refactoring to change indirect accesses ( through subtypes ) to static members to direct accesses . i find the code easier to read when there is a consistent way of referring to a given member .,1618449783,* no tests <nl> * changelogs are not required .,0.8695462346076965
apache_pulsar/10590,add test to ' other ' group if there 's no specified group . <cm-sep> run ' other ' group as part of broker_group_2 <para-sep> add test to ' other ' group if there 's no specified group <nl> configuration methods such as beforemethod / beforeclass methods should also be added to the ' other ' group since beforemethod/beforeclass methods get run only when the group matches or when there 's ' alwaysrun=true ',tests that do n't belong to any testng group are n't run at all in pulsar-broker module . <nl> * add logic to pulsar 's testng listener to add a test method to ' other ' group when no group has been specified . <nl> * run the ' other ' group as part of broker_group_2,1620995919,"* in is not configurable <nl> * and in and is not configurable . <nl> to use tls client authentication on websocketproxy and discoveryservice , they should be configurable . <nl> * enable to set <nl> * enable and to set and . <nl> we can use tls client authentication on websocketproxy and discoveryservice . <nl> note : <nl> i 'm going to add test codes for tls client authentication as another pull-request .",0.9251487851142883
apache_shardingsphere/10620,"fix select order by rewrite error <cm-sep> support oracle , sqlserver & sql92 <cm-sep> add sql parse test <cm-sep> add rewrite test case <para-sep> having segment . <nl> window segment . <nl> get having segment . <nl> get window segment . <nl> get window segment . <nl> get window segment . <nl> having clause assert . <nl> assert actual having segment is correct with expected having clause . <nl> expected having clause . <nl> expected window clause .","changes proposed in this pull request : <nl> - fix select with group by rewrite error <nl> - support mysql , postgresql parse having & window clause <nl> - support oracle , sqlserver & sql92 parse having clause <nl> - add sql parse test <nl> - add rewrite test case",1622618764,add data consistency check function .,0.9578238725662231
elastic_elasticsearch/73201,"improve blobstoreformattests # randomcorruption . <nl> this method today corrupts bytes until the checksum changes , but ( a ) <nl> it 's comparing the checksum vs one computed before even reading the <nl> file , and ( b ) changing a single byte will always invalidate a <nl> checksum so the loop is unnecessary as is the checksum calculation . it <nl> also does n't ever try truncating the file which is a realistic kind of <nl> corruption that we must be able to detect . <nl> this commit addresses all that . <para-sep> flipping bits in a single byte will always invalidate the file : certainly detects all eight-bit-burst errors ; we do n't checksum the last 0 bytes but we do verify that they contain the checksum preceded by 0 zero bytes so in any case this will be a detectable error : <nl> truncation will invalidate the file : the last 0 bytes should start with 0 zero bytes but by construction we wo n't have another sequence of 0 zero bytes anywhere in the file , let alone such a sequence followed by a correct checksum .","this method today corrupts bytes until the checksum changes , but ( a ) <nl> it 's comparing the checksum vs one computed before even reading the <nl> file , and ( b ) changing a single byte will always invalidate a <nl> checksum so the loop is unnecessary as is the checksum calculation . it <nl> also does n't ever try truncating the file which is a realistic kind of <nl> corruption that we must be able to detect . <nl> this commit addresses all that .",1621343229,let utility understand the scope id on ipv6 .,0.8791895508766174
vespa-engine_vespa/18284,expire trial tenants that have not logged in for 0 days <para-sep> expires unused tenants from vespa cloud .,* add maintainer that expires trial tenants that have been idle for 0 days <nl> * created feature flag to exempt some tenants from expiry <nl> * extended sytemname parameter in zoneapimack to facilitate tests . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623836298,also a common bundle containing just the interface . <nl> use version bundle by default,0.9607093334197998
vespa-engine_vespa/18234,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> clean up imports <para-sep> current state of the circuit breaker . * /","there were some leftover imports that intellij did n't complain about , but maven did . builds fine with maven too , now .",1623659358,"this is done as part of the safe rest api call to set the node state of a <nl> storage node to ensure atomicity of the state change , reduce the number of <nl> state changes , and minimize the time to complete the state changes . <nl> the right way to think about the safe-set is then : in order to safely set a <nl> storage node to ( e.g . ) maintenance , the distributor will also have to be set to <nl> down . and so on for the various permutations of state transitions .",0.9619207978248596
vespa-engine_vespa/17538,wire in tensor cell type resolving for concat in java <para-sep> specific for java,like with - i modified the rules a bit in to be conservative and fit existing behavior regarding unbound and mapped dimension .,1619076236,"after this we can remove the global lock , which should fix the lock timeout <nl> issues we occasionally see in us- during release .",0.9445001482963562
gocd_gocd/8523,"- added config migration 0 to support invertfilter for pluggable <nl> materials <cm-sep> * previously the invertfilter value was always set to false . <nl> changed it to set the appropriate value coming from the config repo . <para-sep> this is needed for the case when there are no materials defined . <nl> this representer is only for serialization . <nl> pass along options or the cruise config object . <nl> the scmmaterialrepresenter tries to do geturl , but p4 material does n't have a url .","* added support for allowlist for pluggable materials . <nl> * introduced pipelineconfig v11 , to configure pluggable materials with allowlist .",1599218033,* notify plugin settings change only for plugins which support notification . <nl> * notification plugin api v3 introduces 'go.plugin-settings.plugin-settings-changed ' message to <nl> notify plugin on plugin settings update .,0.9816701412200928
elastic_elasticsearch/74450,added dimension mapping parameter ( wip ) . <nl> added parameter to field types : <nl> - keyword <nl> - ip <nl> - number,"added the parameter to the following field types : <nl> - <nl> - <nl> - numeric field types ( , , , ) . <nl> the parameter is of type boolean ( default : ) and is used to mark that a field is a time series dimension field . <nl> example of setting param to a field can be seen here : .",1624390863,this implementation will add the warning header <nl> if the license is going to expire in less than <nl> { license_expiration_warning_period } days . <nl> the messages added : . <nl> warning : 0 .version- # # # ' your license will expire in [ n ] days . contact your administrator or update your license for continued use of features ' . <nl> or . <nl> warning : 0 .version- # # # ' your license expires today . contact your administrator or update your license for continued use of features ' . <nl> if license has expired less,0.9499648809432983
elastic_elasticsearch/73149,"deserialize blobstore metadata files in a streaming manner . <nl> we were reading the full file contents up-front here because of the complexity <nl> of verifying the footer otherwise . this commit moves the logic for reading metadata <nl> blobs ( that can become quite sizable in some cases ) in a streaming manner by <nl> manually doing the footer verification as lucene 's utility methods do n't allow for <nl> verification on top of a stream . <para-sep> drain stream fully and check whether the footer is corrupted <nl> wrapper input stream for deserializing blobs that come with a lucene header and footer in a streaming manner . it manually manages a read buffer to enable not reading into the last 0 bytes ( the footer length ) of the buffer via the standard read methods so that a parser backed by this stream will only see the blob 's body . <nl> checksum updated with all but the last 0 bytes read from the wrapped stream <nl> only the first buffer.length - 0 bytes are exposed by the read ( ) methods ; once the read position reaches 0 bytes from the end of the buffer the remaining 0 bytes are moved to the start of the buffer and the rest of the buffer is filled from the stream . <nl> the number of bytes in the buffer , in [ 0 , buffer.length ] , equal to buffer.length unless the last fill hit eof <nl> the current read position within the buffer , in [ 0 , buffercount - 0 ] <nl> nothing to read , eof <nl> not closing the wrapped stream",we were reading the full file contents up-front here because of the complexity <nl> of verifying the footer otherwise . this commit moves the logic for reading metadata <nl> blobs ( that can become quite sizable in some cases + there 's plans for larger aggregate meta blobs as well ) in a streaming manner by manually doing the footer verification as lucene 's utility methods do n't allow for <nl> verification on top of a stream . <nl> a possible follow-up to this would be to fix the write side the same way and get rid of the need,1621255041,"today we allocate a new for each document written to the <nl> cluster state . some of these documents may be quite large . we need a <nl> buffer that 's at least as large as the largest document , but there 's no <nl> need to use a fresh buffer for each document . <nl> with this commit we re-use the same much more , only allocating <nl> it afresh if we need a larger one , and using the buffer needed for one <nl> round of persistence as a hint for the size needed for the next one",0.9708942174911499
hazelcast_hazelcast/18664,"introduce upload-resources switch for jet . <nl> add uploadresources field to jetconfig . this flag is used to <nl> enable/disable uploading the resources when submitting a job . if <nl> disabled , the client does not upload the resources and on the server <nl> side jetclassloader is not used to load the resources . <nl> add enabled field to jetconfig . previously we were using a system <nl> property to disable jet , with these changes it is now moved to <nl> jetconfig , enabled by default . <para-sep> returns if jet is enabled <nl> sets if jet is enabled <nl> returns if uploading resources when submitting the job enabled <nl> sets if uploading resources when submitting the job enabled <nl> when <nl> then <nl> when <nl> then","add uploadresources field to jetconfig . this flag is used to <nl> enable/disable uploading the resources when submitting a job . if <nl> disabled , the client does not upload the resources and on the server <nl> side jetclassloader is not used to load the resources . <nl> add enabled field to jetconfig . previously we were using a system <nl> property to disable jet , with these changes it is now moved to <nl> jetconfig , enabled by default . <nl> checklist : .",1620727544,"this cleanup mostly removed warnings , moved tests to the correct package and aligns the naming schema of implementations ( cache did n't follow the map implementations here ) .",0.9408015608787537
prestodb_presto/16172,revert ' fix size calculation in mapblock ' . <nl> this reverts commit sha . <cm-sep> revert ' make hashtable computation lazy in mapblockbuilder ' . <nl> this reverts commit sha . <para-sep> directly copy instead of building hashtable if providedhashtable is not null <nl> build hash table for this map entry . <nl> add 0 maps with only one entry but the same key <nl> add 0 keys so we get some chance to get hash conflict the purpose of this test is to make sure offset is calculated correctly in mapblockbuilder.closeentrystrict ( ),the optimization causes significant regression in certain cases .,1622125652,adds two new utility methods to : <nl> - which mirrors <nl> - which creates a new page with arbitrary channel selection / reordering . <nl> the follow up commit then updates various operators and classes that explicitly created and manipulated block arrays to use equivalent page methods that avoid extra defensive copies .,0.9276884198188782
elastic_elasticsearch/74455,"set max allowed size for stored async response . <nl> add a dynamic transient cluster setting search.max_async_search_response_size <nl> that controls the maximum allowed size for a stored async search <nl> response . the default max size is 10mb . an attempt to store <nl> an async search response larger than this size will result in error . <para-sep> initial response – ok <nl> final response – with failure ; test that stored async search response is updated with this failure <nl> convert this asyncresponse to a new asyncresponse with a given failure <nl> currently for eql we do n't set limit for a stored async response todo : add limit for stored async response in eql , and instead of this method use createresponse <nl> stores the initial response with the original headers of the authenticated user and the expected expiration time . <nl> do not close the buffer or the xcontentbuilder until the indexrequest is completed ( i.e. , listener is notified ) ; otherwise , we underestimate the memory usage in case the circuit breaker does not use the real memory usage . <nl> stores the final response if the place-holder document is still present ( update ) . <nl> even if we expect updating with a failure always succeed this is just an extra precaution not to create infinite loops <nl> at end , we should report a failure to the listener <nl> update the initial stored response with a failure <nl> successfully create an initial response <nl> setting very small limit for the max size of async search response <nl> test that an update operation of the initial response fails <nl> test that the inital response is overwritten with a failure <nl> test that a create operation fails <nl> restoring limit",add a dynamic transient cluster setting search.max_async_search_response_size <nl> that controls the maximum allowed size for a stored async search <nl> response . the default max size is 10mb . an attempt to store <nl> an async search response larger than this size will result in error .,1624397606,"this pr enables stats on inference to be gathered and stored in the indices . <nl> each node + model_id will have its own running stats document and these will later be summed together when returning _stats to the user . <nl> is ilm managed ( when possible ) . so , at any point the underlying index could change . this means that a stats document that is read in and then later updated will actually be a new doc in a new index . this complicates matters as this means that having a running knowledge of seq_no and",0.9797394871711731
apache_druid/10833,update doc for query errors and add unit tests for jsonparseriterator,this pr updates the query error doc and adds unit tests for . integration tests will be added in another pr,1612259052,"the filter returned by basichttpauthenticator did not adhere to this part of the getfilter ( ) method contract in authenticator : . <nl> ' if the authentication fails ( i.e. , a filter recognized the authentication scheme of a request , but the credentials failed to authenticate successfully ) the filter should send an error response , without needing to proceed to other filters in the chain . ' <nl> this pr adjusts the basichttpauthenticator to immediately send a 0 in that situation .",0.9723410606384277
Graylog2_graylog2-server/9926,"avoid oshi warnings with overlay and none fs types . <nl> when running outside of docker , none and overlay fs types <nl> might not be stat'able without root permissions . <nl> this would create warnings like . <nl> add runtime docker detection and only ignore overlay fs when <nl> within a container . <nl> also add ' none ' fstype which oshi does n't ignore by default <para-sep> this test does n't seem to work within github runners <nl> add non-default pseudo filesystem type ( docker related ) avoids warnings like : ' warn : oshi.software.os.linux.linuxfilesystem - failed to get information to use statvfs . path : /var/lib/docker/aufs/mnt/sha , error code : 0 ' <nl> do n't let oshi filter out ' overlay ' filesystems when running within docker . otherwise we can not get proper disk statistics <nl> updating the pseudo filesystem types only here only works because the static oshi.software.common.abstractfilesystem.pseudo_fs_types only gets initialized after we update the settings . ( because the class has n't been loaded yet ) should the abstractfilesystem class at some point get loaded earlier , this setting will have no effect . a solution for this would be to create an upstream pr to make oshi config usage more dynamic .","when running outside of docker , none and overlay fs types <nl> might not be stat'able without root permissions . <nl> this would create warnings like . <nl> add runtime docker detection and only ignore overlay fs when <nl> within a container . <nl> also add ' none ' fstype which oshi does n't ignore by default .",1610990462,"extracted as an interface and renamed the implementation to . <nl> by extracting the interface of the input status service , we can bind a default implementation but provide the possibility to bind an alternative implementation in a different context . <nl> the service is not used yet . temporarily modified another service to have the inputstatusservice injected and made sure that the server did still start .",0.9184140563011169
netty_netty/11205,"give a choice for app to extend the length limitation of clientid even in mqtt v3.0 . <para-sep> default max bytes in message <nl> min client id length <nl> default max client id length , in the mqtt3.0 protocol , the default maximum client identifier length is 0","motivation : . <nl> modification : . <nl> give a choice for app to extend the length limitation of clientid even in mqtt v3.0 on the server side , thanks .",1619581460,"use a timertask to trigger handling of timeouts , so we can raise the select timeout again and so solve the problems with heavy context-switches",0.9439330697059631
apache_kafka/10572,"global-topic-count-metric-and-test <cm-sep> add-global-partition-and-topic-metrics <para-sep> a count of the number of partitions that do not have their first replica as a leader . <nl> all partitions should still be online after unregistering broker 0 <nl> three partitions should not have their preferred ( first ) replica 0 <nl> after unregistering broker 0 , 0 partition for topic foo should go offline <nl> all five partitions should not have their preferred ( first ) replica at this point <nl> after unregistering broker 0 , the last partition for topic foo should go offline and 0 partitions for topic zar should go offline <nl> after unregistering broker 0 the last partition for topic zar should go offline <nl> deleting topic foo should bring the offline partition count down to 0 <nl> deleting topic zar should bring the offline partition count down to 0","the metrics are calculated by counting records as they are replayed e.g . replay ( topicrecord ) , replay ( removetopicrecord ) . <nl> this was unit tested using mockcontrollermetrics .",1618966422,"the saslclientauthenticator incorrectly negotiates supported saslhandshakerequest version and uses the maximum version supported by the broker whether or not the client supports it . <nl> this pr rolls back the recent saslhandshake [ request , response ] bump , fixes the version negotiation , and adds a test to prevent anyone from accidentally bumping the version without a workaround such as a new apikey . the existing key will be difficult to support for clients < version due to the incorrect negotiation . <nl> tests : <nl> - prevent sasl_handshake schema version bump <nl> - add test to return apiversions",0.9585583209991455
apache_druid/10996,compactiontask throws exception on conflicting segmentgranularity,since there are 0 ways for a user to specify segmentgranularity - this change makes throws an exception if a user accidentally submits a compaction task with conflicting segmentgranularities - by using the old way and the new way at the same time,1615853136,"authentication for jdbc requests should use credentials stored in the jdbc connection context instead of the http headers . <nl> on the broker , druidavaticahandler handles jdbc requests separately from the normal authentication checking filters . <nl> on the router , jdbc requests currently go through the normal authentication checking filter which is extraneous/incorrect sets the avatica path as ' unsecured ' on the router , deferring the authentication check to the broker where authentication will occur using the jdbc connection context",0.905706524848938
runelite_runelite/13019,remove incorrect trailblazer harpoon entry . <nl> this animation is not used for harpooning . it appears to be some kind of <nl> obscure trailblazer mining animation . <cm-sep> add support for trailblazer kit rewards,"this pr also removes the incorrect entry from animationid as it is both ( a ) not a harpoon animation & mdash ; it 's some kind of mining animation , and ( b ) not used as it is some non-standard type of mining animation .",1610056711,fixes assertion failure introduced in sha .,0.8936523795127869
confluentinc_ksql/7162,prevent iob when printing key/value with an empty string,this pr fix this checking if the possible formats are not empty .,1614961385,"use the local time to assert test correctness , otherwise , tests will fail because of using utc .",0.8838275074958801
apache_flink/16264,remove netty 0 reference <para-sep> syncuninterruptibly ( ) throws checked exceptions via unsafe,replaces a netty 0 reference with our flink-shaded-netty version . this currently works on master because it uses the netty version provided by akka .,1624478921,please ignore this pr . <nl> dry travis run for next batch of commits for .,0.7659534215927124
elastic_elasticsearch/73784,"add precommit task for detecting split packages . <nl> modularization of the jdk has been ongoing for several years . recently <nl> in java 0 the jdk began enforcing module boundaries by default . <nl> before we can even begin to think about how to modularize , we must <nl> prepare the way by enforcing packages only exist in a single jar file , <nl> since the module system does not allow packages to coexist in multiple <nl> modules . <nl> this commit adds a precommit check to the build which detects split <nl> packages . the expectation is that we will add the existing split <nl> packages to the ignore list so that any new classes will not exacerbate <nl> the problem , and the work to cleanup these split packages can be <nl> parallelized . <para-sep> checks for split packages with dependencies . these are not allowed in a future modularized world . <nl> while this is done in every project , it should be cheap to calculate <nl> add classes that exist in split packages but should be ignored . <nl> first determine all the packages that exist in the dependencies . there might be split packages across the dependencies , which is ' ok ' , in that we do n't care about it for the purpose of this project , that split will be detected in the other project <nl> next read each of the source directories and find if we define any package directories that match those in our dependencies . <nl> then filter out any known split packages/classes that we want to ignore . <nl> finally , print out ( and fail ) if we have any split packages <nl> cleanup if we have ignored the last class in a package <nl> todo : want to read packages the same for src dirs and jars , but src dirs we also want the files in the src package dir <nl> the client package should be owned by the client , but server has some classes there too <nl> common.settings is owned by server , this should be keystore specifici <nl> o.e.plugins is owned by server , these shouldb be renamed to plugincli <nl> search should be owned by server , this should be renamed to aggsmatrix <nl> index is owned by server , move these to mapper specific packages <nl> index is owned","modularization of the jdk has been ongoing for several years . recently <nl> in java 0 the jdk began enforcing module boundaries by default . <nl> before we can even begin to think about how to modularize , we must <nl> prepare the way by enforcing packages only exist in a single jar file , <nl> since the module system does not allow packages to coexist in multiple <nl> modules . <nl> this commit adds a precommit check to the build which detects split <nl> packages . the expectation is that we will add the existing split <nl> packages to",1622833805,"if an api name ( or components of a name ) overlaps with a reserved word in the programming language for an es client , then it 's possible that the code that is generated from the api will not compile . this pr adds validation to check for such overlaps . <nl> when i implemented this with the keywords from the above issue , some apis were immediately flagged , and this highlighted a subtlety with this check . some keywords are actually perfectly fine to use , depending on the context , and so i removed and from",0.9627677202224731
elastic_elasticsearch/72653,"move shutdown component status out into separate classes . <nl> originally these were stored in the cluster state using a single class , however , they will need to <nl> be different objects without common parts , and they will be calculated on the fly rather than <nl> persisted into cluster state . <nl> this removes the class , as its no longer needed . <para-sep> todo : make this value calculated based on the status of all other pieces","originally these were stored in the cluster state using a single class , however , they will need to <nl> be different objects without common parts , and they will be calculated on the fly rather than <nl> persisted into cluster state . <nl> this removes the class , as its no longer needed .",1620080701,"per rest endpoint media types declaration allows to make parsing/validation more strict . <nl> if a media type was declared only in one endpoint ( for instance csv in sql endpoint ) it should not be allowed to parse that media type when using other endpoints . <nl> however , the need to be able to understand all media types supported by elasticsearch in order to parse a compatible-with=version parameter . <nl> this implies that endpoints need to declare which media type they support and how to parse them ( if introducing new media types - like sql ) .",0.9813635945320129
Graylog2_graylog2-server/10692,"add cluster-wide cache purge <para-sep> when one node updates the data store shared by other data adapter instances in a cluster , then we need to purge the caches that depend on that data adapter on each node","otherwise the non-master nodes in the cluster would still run with stale caches and report false lookup values . <nl> this change adds that capability with the event type . <nl> this has been tested in my local development environment . verified that when a data adapter sends an event on the event bus , all other nodes clear the appropriate lookup table caches .",1621868159,"added function to determine string lengths in characters or bytes , based on the encoding . <nl> overly long get requests or other user input . <nl> previously it was not possible to determine the string length of a field in graylog . <nl> unit test for the different combinations of inputs .",0.9350993633270264
hazelcast_hazelcast/18631,"make extract function work on multiple types . <nl> - extract function implicitly casts its argument to <nl> timestamp with time zone to calculate fields . therefore , <nl> the results might be wrong if the argument has local <nl> temporal type ( date , timestamp ) . <nl> - indirectly , we can conform postgres behavior by altering <nl> how field extraction works for time type . postgres does <nl> not allow extraction of fields like dow , day etc . from <nl> time type . this pr applies postgres-like behavior .","- extract function implicitly casts its argument to <nl> timestamp with time zone to calculate fields . therefore , <nl> the results might be wrong if the argument has local <nl> temporal type ( date , timestamp ) . <nl> - we can conform postgres behavior by altering <nl> how field extraction works for time type . postgres does <nl> not allow extraction of fields like dow , day etc . from <nl> time type . this pr applies postgres-like behavior .",1620130575,"this pr improves consistency checks for indexes when used from the sql service : <nl> 0. now indexes track precisely which partitions are indexed . in addition to this , we track when a partition is being indexed ( dynamic index creation , migration to the local member ) or unindexed ( migration from the local member ) <nl> 0. when the sql query is in progress , we request a stamp for the partitions that are expected to be available locally . then we validate that the stamp is still valid before returning the results . the stamp could",0.9682349562644958
elastic_elasticsearch/74052,"this commit serves two purposes . for one , we need the ability to dynamically <nl> update a repository setting for the encrypted repository work . <nl> also , this allows dynamically updating repository rate limits while snapshots are <nl> in progress . this has often been an issue in the past where a long running snapshot <nl> made progress over a long period of time already but is going too slowly with the <nl> current rate limit . this left no good options , either throw away the existing <nl> partly done snapshot 's work and recreate the repo with a higher rate limit to speed <nl> things up or wait for a long time with the current rate limit . <nl> with this change the rate limit can simply be increased while a snapshot or restore <nl> is running and will take effect imidiately . <para-sep> use a small chunk size so the rate limiter does not overshoot to far and get blocked a very long time below <nl> we only run concurrent verification when we have a large snapshot pool on the data node because otherwise the verification would deadlock since the small pool is already blocked by the snapshot on the data node <nl> this setting update will fail so we can set the verification parameter randomly even if the snapshot pool is already blocked since we will never actually get to the verification step <nl> we only run concurrent verification when we have a large snapshot pool on the data node because otherwise the verification would deadlock since the small pool is already blocked by the snapshot on the data node <nl> we 're updating in place so the updated metadata must point at the same uuid and generations <nl> repository settings that can be updated dynamically without having to create a new repository . <nl> allow updating dummy setting for test purposes","this commit serves two purposes . for one , we need the ability to dynamically <nl> update a repository setting for the encrypted repository work . <nl> also , this allows dynamically updating repository rate limits while snapshots are <nl> in progress . this has often been an issue in the past where a long running snapshot <nl> made progress over a long period of time already but is going too slowly with the <nl> current rate limit . this left no good options , either throw away the existing <nl> partly done snapshot 's work and recreate the repo",1623648214,"today the disk-based shard allocator accounts for incoming shards by <nl> subtracting the estimated size of the incoming shard from the free space on the <nl> node . this is an overly conservative estimate if the incoming shard has almost <nl> finished its recovery since in that case it is already consuming most of the <nl> disk space it needs . <nl> this change adds to the shard stats a measure of how much larger each store is <nl> expected to grow , computed from the ongoing recovery , and uses this to account <nl> for the disk usage of",0.9719036221504211
ballerina-platform_ballerina-lang/28144,"change shell cli tests to clean the inputs . <nl> shell cli tests depend on the cli output . but some terminals <nl> cause the cli output to have control characters unexpected by the test . <nl> this cause cli tests to fail . <cm-sep> fix shell cli welcome text check bug <cm-sep> improve and enable shellcommand cli test <cm-sep> reformat code and add some comments <para-sep> the response here is not testable because it can change . the first readresponse is to read and ignore all the initial output from the cli . ( header text , etc ... ) the second readresponse is to read and ignore any response to the first request . <nl> read input ( ignore till first shell prompt ) <nl> expected format : \n\n\n\n\n <nl> remove special sequences <nl> reads data from the stream specified until if finds shell prompt as the eol . <nl> send the data given to the specific stream . <nl> remove invisible characters from the string . the removed characters are ansi characters that are added by jline . <nl> remove all ansi codes <nl> disable ansi escape characters and backspace character <nl> remove any special sequences known <nl> remove new lines because new lines can vary <nl> expected format : \n\n\n\n\n <nl> remove all ansi codes","however , due to the behavior in some terminals , the output included unexpected control characters which resulted in tests failing when running via terminals . <nl> this pull request removes the control characters and fixes the tests to be more verbose on failure . <nl> however , these tests are required to test locally on different terminals before merging .",1611386840,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.9519718289375305
grpc_grpc-java/8040,"since static methods are pseudo-inherited by builder implementations but <nl> are trivially accidentally used , we re-define static methods in each <nl> builder to make them behave more like the caller would expect . however , <nl> not all the methods actually work ; some just throw because the caller <nl> was certainly not getting what they would expect . <nl> annotating with can expose the problems at compile time <nl> instead of runtime . while would also be an option , it is a <nl> bit harder to figure out the ramifications and whether we want to go <nl> that route . <nl> this change was suggested by a lint tool for xdsserverbuilder and it <nl> seems appropriate so i applied it to the other similar cases i could <nl> find .","since static methods are pseudo-inherited by builder implementations but <nl> are trivially accidentally used , we re-define static methods in each <nl> builder to make them behave more like the caller would expect . however , <nl> not all the methods actually work ; some just throw because the caller <nl> was certainly not getting what they would expect . <nl> annotating with can expose the problems at compile time <nl> instead of runtime . while would also be an option , it is a <nl> bit harder to figure out the ramifications and whether we want to go <nl>",1617302506,the deprecated fields in this import will be removed shortly . update related code,0.922443151473999
ballerina-platform_ballerina-lang/31015,add code folding for ifelse/else blocks .,> - if-else/else <nl> > - while <nl> > - foreach <nl> > - enum <nl> > - transaction statement <nl> > - external function <nl> > - match statement <nl> > - fork statement <nl> > - retry statement <nl> > - worker <nl> > - on fail <nl> > - do statement <nl> > - lock statement <nl> > - return statement .,1623050496,"with this pr , it allows to use standard datetime formatted strings ( iso 0 [ 0 ] ) as parameters in sqlconnector and datatables : getvalueasstring function . <nl> return values from datatable : <nl> . <nl> 0 ] [ iso 0 date time format",0.935443103313446
elastic_elasticsearch/74309,granting read permissions for the kbn system user to read ep policy data stream . <para-sep> endpoint / fleet policy responses . kibana requires read access to send telemetry <nl> read-only datastream for endpoint policy responses,"granting the kibana system user read access to this data stream . this will allow kibana to lift out failures , analyze them and send them home if user configurations allow so .",1624022958,"the endpoint protections team is storing diagnostic information in the indices , which kibana will read from to send the data to the remote telemetry service .",0.9999999403953552
apache_pulsar/10247,make copy of markersmessageiddata since instances are reused . <nl> - lightproto reuses thread local instances and therefore a copy must be made <cm-sep> make copy of replicatedsubscriptionssnapshot since instances are reused,lightproto reuses thread local instances and therefore a copy must be made before sharing with other threads . <nl> - make a copy of before adding it to <nl> - make a copy of before adding it to map in,1618584648,"in particular , if a namespace is being unloaded while topics for that namespace are being created and then the namespace is again assigned to the same broker , these topics seem to never recover due to an exceptional completion . <nl> when is invoked , if the future has already completed exceptionally , it is removed from the topic map . <nl> topics no longer fail to recover when unloading a namespace while being created .",0.7922583818435669
apache_pulsar/10017,process partitioned-topic messages on multiple threads . <nl> add test <para-sep> test validates that consumer of partitioned-topic utilizes threads of all partitioned-consumers and slow-listener of one of the partition does n't impact listener-processing of other partition . test starts consumer with 0 partitions where one of the partition listener gets blocked but that will not impact processing of other 0 partitions and they will be processed successfully . <nl> create partitioned topic <nl> each partition <nl> blocking one of the partition 's listener thread will not impact other topics <nl> ok <nl> unblock the listener thread <nl> start track and auto subscribe partition increment <nl> consumer if this message is received by that consumer,"so , if user creates pulsar-client with 0 listener threads and creates consumer for partitoned-topic with 0 partitions then consumer will use only 0 listener threads to serve all 0 partitions instead utilizing all 0 threads . this creates a bottleneck if one of the partition is slow , cpu spins on only one thread and there is no way to make overall process faster . <nl> therefore , consumer should use each partition 's listener-thread to process message received by that partition . this helps : <nl> - slow partition processing will not impact other partition message processing <nl>",1616520157,"bug fix . <nl> ' unackedmessagetracker ' will call ' consumerbase.redeliverunacknowledgedmessages ' . there will be 0 steps here : <nl> 0 ) filter out the messages that need to enter the dlq <nl> 0 ) the remaining messages will be re-delivered via redeliverunacknowledgedmessages request . <nl> the problem appeared in the second step , when all messages were filtered out in the first step . if the messageidslist received by the broker is empty , it will trigger the reposting of all unackedmessages under this consumer . <nl> other consumers will consume messages that exceed maxredeliverycount again , and",0.9623058438301086
apache_kafka/10234,minor ; clean up leaderandisrresponse construction in,"this patch refactors the code , which constructs the in , to improve the readability and to remove unnecessary operations .",1614606985,this pr is a further step towards the complete replacement of with . these straightforward changes were split from another pr to simplify the review process . <nl> * refactor : <nl> - kstreamwindowreducetest <nl> - ktablemapkeystest <nl> - sessionwindowedkstreamimpltest <nl> - timewindowedkstreamimpltest,0.9275344014167786
Graylog2_graylog2-server/10020,"handle multiple principals in mongodb session <para-sep> a subject can have more than one principal . if that 's the case , the user id is required to be the first one .","a shiro subject may have multiple principals , with the first principal being the ' primary principal ' and in our case that 's the user id . <nl> this changes checks if we have multiple principals in a session and returns the first principal when looking up a user id . <nl> once merged , we should forward-port this to the branch . <nl> the principals collection may be used to transport additional attributes of a subject from the authorization service into the session . treating the string representation of the principals collection as the user id is wrong",1612514451,"to support underscores ( ' _ ' ) in grok match group names , we had to modify <nl> the java-grok library to use the old regexp engine again . <nl> this also adds a test for the grok extractor to make sure that using <nl> underscores works .",0.9596991539001465
apache_beam/14991,"reject splits for previous bundles . <nl> also disallows resetting an active bundle processor , which could <nl> interfere with splitting and makes the check for the split request <nl> being for the current one meaningful . <para-sep> if the split request we received was delayed we it may be for a previous bundle . ensure we 're processing a split for this bundle . this check is done under the lock to make sure reset ( ) is not called concurrently in case the bundle processor is being released . <nl> this split should not be executed . <nl> ensure that we process the correct number of elements after not splitting .","also disallows resetting an active bundle processor , which could <nl> interfere with splitting and makes the check for the split request <nl> being for the current one meaningful",1623365795,maintain a mapping from bundle id to active bundle processor,0.9250183701515198
ballerina-platform_ballerina-lang/28344,"add the custom repl parser implementation <cm-sep> add states to wait just after operator in shell <cm-sep> add some tests to test parser complete check <cm-sep> remove unnecessary counter comment portion <cm-sep> fix bug of newlines not being fed to the parser <cm-sep> fix bug causing empty stack exception <para-sep> a parser for ballerina shell to detect incomplete lines . <nl> once we reach the cursor , set selected index . position of the selected index is current word length . <nl> add left-over from last word <nl> update indices and cursors <nl> feed additional newline to the parser to submit all data <nl> no escape characters , everything will be passed as it is provided",this will partially implement waiting on user inputs that are incomplete . <nl> ( previously line breaks would trigger submit inconsistently ) .,1612177634,this pr adds following packages . <nl> 0 ) os <nl> 0 ) runtime <nl> 0 ) user .,0.976485013961792
apache_kafka/10760,add max_timestamp spec to listoffsets api <cm-sep> updated replica fetcher to use latest listoffsets request version <para-sep> fail any unsupported futures and remove partitions from the downgraded retry <nl> used to retrieve the offset with the largest timestamp of a partition as message timestamps can be specified client side this may not match the log end offset returned by latestspec <nl> version 0 enables listing offsets by max timestamp ( ) . <nl> version 0 is the same as version 0 ( ) . <nl> listoffsets response from broker 0 <nl> listoffsets response from broker 0 <nl> ensure that no max timestamp requests are retried <nl> listoffsets response from broker 0 <nl> introduce listoffsets v7 which supports listing offsets by max timestamp ( ) <nl> cache to avoid race conditions . is faster than most alternatives and provides constant time access while being safe to use with concurrent collections unlike .,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> tested with new integration test . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1621949329,"code fix included . will add a test case asap -- hopefully today . <nl> it is possible for a java sasl/oauthbearer client ( either a non-broker producer/consumer client or a broker when acting as an inter-broker client ) to end up in a state where it can not connect to a new broker ( or , if re-authentication as implemented by and merged for v2.version were to be deployed and enabled , to be unable to re-authenticate ) . the error message looks like this : . <nl> the root cause of the problem begins at this point in",0.970224916934967
apache_incubator-pinot/6407,use unique output file names in csv mode,this fixes an issue where output files are overridden repeatedly . <nl> no <nl> no . <nl> no,1609810767,"we should not need the real one , so it is better to mock the class altogether",0.8284850120544434
jenkinsci_jenkins/5235,replaced ms_should_be_final general spotbugs exclude with individual excludes,"replaced general spotbugs exclude with individual excludes . added some comments for clarity . and specified one todo in restricted since . <nl> in case it is not useful to exclude at any point , comments are appreciated . <nl> * internal : replaced general spotbugs exclude for with individual supressions <nl> * introduced new systemproperty to define maximum entries",1612132555,"as usual , for the pr build…",0.8857035040855408
apache_kafka/10608,"clean up leftover locking and global thread locking <cm-sep> clear out old lock files <cm-sep> comment about ide warning <cm-sep> checkstyle <para-sep> required by jackson -- do not remove , your ide may be warning that this is unused but it 's lying to you <nl> we removed the task directory locking but some upgrading applications may still have old lock files on disk , we just lazily delete those in this method since it 's the only thing that would be affected by these <nl> if we hit an error deleting this just ignore it and move on , we 'll retry again at some point <nl> if it 's not a lock file then the directory is not empty , but finish up the loop in case there 's a lock file left to delete <nl> required by jackson -- do not remove , your ide may be warning that this is unused but it 's lying to you","cleans up a few things : . <nl> 0. we no longer need locking for the global state directory either , since it 's contained within the top-level state directory lock . definitely less critical than the task directory locking , since it 's less vulnerable to ioexceptions given that it 's just locked and unlocked once during the application lifetime , but nice to have nonetheless <nl> 0. clears out misc . usages of the lock_file_name that no longer apply . this has the awesome side effect of finally being able to actually delete obsolete task directories , whereas",1619667425,"0. remove mintimestamptracker and its timestamptracker interface . <nl> 0. in recordqueue , keep track of the head record ( deserialized ) while put the rest raw bytes records in the fifo queue , the head record as well as the partition timestamp will be updated accordingly .",0.9401505589485168
neo4j_neo4j/11679,rewrote clustershutdownit <para-sep> set shutdown order <nl> await locks <nl> then shutdown in given order works,the previous test had been modified to a point where it was not really testing anything . since i am not a 0 % sure what the previous test was doing i 've rewritten it to what i suspect it was trying to do .,1525098220,if writer reach a tree node with a valid successor it means that the <nl> tree is not consistent in one out of three ways : <nl> 0. tree state point to a root that is outdated ( has a successor ) <nl> 0. child pointer in parent does not point to latest successor of child . <nl> 0. sibling pointer does not point to latest successor of sibling .,0.9229045510292053
apache_incubator-pinot/7021,move kafkajsondecoder code to pinot-json and keep kafkajsondecoder class for backward compatability <para-sep> an implementation of streammessagedecoder to read json records from a stream . <nl> this class has been kept for backward compatability . this class will be removed in a later release .,"currently , jsondecoder for realtime data is present in kafkajsonmessagedecoder class . however , with new realtime integrations of kinesis and pulsar in the pipeline , it does n't make sense to import kafka-base and use this class for decoding . <nl> the pr moves the decoder to pinot-json package where it should rightfully reside . the kafkajsonmessagedecoder has been kept as an empty implementation of the new decoder so that it does n't cause any issues for devs updating the kafka plugin . <nl> move json decoder from to package . use class instead of",1622779705,- detection stage wrapper injects metric urn to stage specs <nl> - rename info map to detection registry singleton,0.8265350461006165
ballerina-platform_ballerina-lang/27648,fix context not ended issue in parsing record type desc <nl> context not properly ended after parsing record field that starts with readonly keyword .,fix context not properly ended after parsing record field that starts with keyword .,1609763580,following ballerina code was tested . <nl> converted to llvm ir using .,0.8812181353569031
apache_pulsar/10711,fix transaction log handle managed ledger writefail state .,"append fail check the managedledger state and the exception do <nl> # # # verifying this change <nl> add the tests for it . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints",1622014306,"therefore , the policy data in the cache is still old . when listeners are triggered , they can not get the policies directly through the cache . they have to modify the existing interface and pass the policies through parameters . <nl> 0 ) when the broker restarts , some topic-level policies will no longer take effect , because they rely on the method to take effect . <nl> topicpoliciestest # testrestart",0.9310528039932251
hazelcast_hazelcast/18553,"fix sink into coercion issues . <nl> - can no longer be implicitly cast to other types . <nl> - now always returns true or throws . the <nl> return value was handled by fallback code in <nl> , which allowed more implicit <nl> conversions than we wish to ( including the above one ) . it allowed some <nl> conversions we liked ( such as all types to object ) which worked before <nl> only thanks to this fallback , but in an incorrect way because the <nl> columns after the assignment we rejected were n't coerced , which caused <nl> runtime errors . <nl> - uses instead of . <nl> - : replace the value classes with shared . <nl> - disable the test cases in with null source as a <nl> column . they used null for field type , which is n't supported . the <nl> support for null in was explicitly disabled . <para-sep> do nothing . <nl> we always return true to defuse the fallback mechanism in the caller . instead , we throw the validation error ourselves above if we ca n't assign . <nl> locates the n-th expression in an insert or update query . <nl> give up <nl> give up","- can no longer be implicitly cast to other types . <nl> - now always returns true or throws . the <nl> return value was handled by fallback code in <nl> , which allowed more implicit <nl> conversions than we wish to ( including the above one ) . it allowed some <nl> conversions we liked ( such as all types to object ) which worked before <nl> only thanks to this fallback , but in an incorrect way because the <nl> columns after the assignment we rejected were n't coerced , which caused <nl> runtime errors . <nl> -",1618588784,"created implementing . <nl> this way , both imdg and jet share common interface which hopefully will help to prevent introducing breaking changes for jet without taking it into consideration . <nl> moreover , it lets to simplify & .",0.9531905651092529
ballerina-platform_ballerina-lang/28462,"remove unnecessary cast with type params . <nl> also changes a loop that assumes langlib methods are always called on a value of the same type as the langlib . <cm-sep> remove cast to anon type and add validation to disallow such casts <cm-sep> add comments explaining changes to casts to anon types <cm-sep> fix validation error <para-sep> why we dont consider whole action invocation <nl> this in intended to be a temporary validation to avoid casting to anonymous types from imported packages , because such casts can cause backward compatibility issues since anonymous type names can change per compilation . the current alternative in such a scenario is to cast to a compatible in-line type . for example , a cast to an anonymous record type can be replaced with a cast to a map type . if this is not possible due to some reason , we need to introduce an approach to uniquely identify anonymous types across compilations .",not sure if we can write a test for either change .,1612639763,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9523069262504578
ballerina-platform_ballerina-lang/27313,add request/response limit config to listener/client configs <cm-sep> populate msgsizevalidationconfig regardless of the version <cm-sep> test fallback path for both client and listener <cm-sep> upgrade transport version <para-sep> set request validation limits . <nl> set response validation limits .,"so that if either client or listener fallback , messages will be treated as per the given configs .",1606934523,"with this pr splitting would happen iterative-ly , starting from the final colon and stopping when the first half is a valid path . <nl> if no valid path is identified , splitting at a colon will not be done , and the whole arg would be passed as the source arg . <nl> e.g. , <nl> case i : . <nl> is valid -- > no splitting at a colon . <nl> case ii : . <nl> is not valid -- > split at last colon <nl> - results in and . <nl> is not valid -- > split",0.93157958984375
grpc_grpc-java/8185,"ehance delay injection error message on deadline_exceeded <para-sep> todo ( zdapeng : ) check effective deadline locally , and do the following only if the local deadline is exceeded . ( if the server sends deadline_exceeded for its own deadline , then the injected delay does not contribute to the error , because the request is only sent out after the delay . there could be a race between local and remote , but it is rather rare . ) <nl> replace trailers to prevent mixing sources of status and trailers .","when an rpc is injected with a delay and then fails with deadline_exceeded ( partially ) due to the delay , it could confuse users if the error message does not mention the existence of the delay injection , because end users normally are not the same people who configured fault injection policy in control plane .",1621354927,"this api change allows storage implementations to put some state information into the return value , giving it the ability to act as a cookie . in environments where contexts can be replaced , the current can be stashed there and be restored when is called .",0.9462011456489563
elastic_elasticsearch/73977,resurrect the removed _xpack/rollup endpoints <cm-sep> add specs for yamlrestcompattest,adds back the routes when using rest compatibility for a request .,1623273635,"we mark cluster states persisted on master-ineligible nodes as <nl> potentially-stale using the voting configuration which <nl> prevents these nodes from being elected as master if they are restarted as <nl> master-eligible . today we do not handle this special voting configuration <nl> differently in the , leading to a mysterious <nl> message if the <nl> election does not succeed . <nl> this commit adds a special case description for this situation to explain <nl> better why this node can not win an election .",0.8833070397377014
apache_kafka/10823,: kraft multi-partition placement on single broker <para-sep> but do n't reset the iteration epoch for a single unfenced broker -- otherwise we would loop forever <nl> test that we perform striped replica placement as expected for a multi-partition topic on a single unfenced broker <nl> ensure we can place n replicas on a rack when the rack has less than n brokers,"this patch refactors out some argument sanity checks and invokes those checks in both and , and it adds tests for this as well as the single broker placement issue .",1622841996,"code fix included . will add a test case asap -- hopefully today . <nl> it is possible for a java sasl/oauthbearer client ( either a non-broker producer/consumer client or a broker when acting as an inter-broker client ) to end up in a state where it can not connect to a new broker ( or , if re-authentication as implemented by and merged for v2.version were to be deployed and enabled , to be unable to re-authenticate ) . the error message looks like this : . <nl> the root cause of the problem begins at this point in",0.9280721545219421
Alluxio_alluxio/13481,add metrics for worker rpc counts <para-sep> metrics . * / <nl> metrics . * / <nl> decrement rpc counter only if the request was n't completed/canceled already,this pr aims at adding metrics for tracking the number of active rpcs handled by the alluxio worker .,1621879482,"grpc performance improves if we use a dedicated thread pool for it and experimentation have shown that forkjoin pool performs the best for in mem operations . <nl> hence , we are moving to use a forkjoin pool for grpc threads .",0.9284252524375916
apache_ignite/9092,calculation of primary flag based on tx and other precalculated properties <para-sep> empty flags . * / <nl> * / <nl> * / <nl> * / <nl> bit flags . 0 bit - primary - seted when current node is primary for entry partition . 0 bit - preload - seted when entry logged during preload ( rebalance ) . 0 bit - fromstore - seted when entry loaded from third-party store .,# # # the contribution checklist,1620764208,* add affinitycall and affinityrun overloads that take multiple cache names and partition <nl> * fix existing affinitycall and affinityrun : use proper java apis that reserve the partition instead of custom task-based implementation,0.9092439413070679
elastic_elasticsearch/73034,change the maximum digits in a year to 0 . <nl> we changed the default joda behaviour in strict_date_optional_time to <nl> max 0 digits in a year . this helps parsing epoch_millis format which is <nl> often used in a default format <nl> this change adjustes our java.time implmementation to behave the same <nl> way <cm-sep> limit the year monitoring is testing . <nl> fix test . <nl> different printer then parser . <nl> fix tests . <nl> fix sql test <para-sep> this one is considered a year <nl> this one is considered a 12345milliseconds since epoch <nl> for date_optional_time a timestamp with more than 9digits is epoch <nl> generate a random epoch millis in a range 0 to 0-0-31t23:0 : version,we changed the default joda behaviour in to <nl> max 0 digits in a year . java.time implementation should behave the same way . <nl> at the same time should have 9digits for year part .,1620892309,this commit introduce a formal role for identifying nodes that are capable of making connections to remote clusters .,0.9493532776832581
elastic_elasticsearch/74301,"that proved to be a poor choice , because the runtime section is flat , supports dots in field names , and does not really need objects . also , these end up causing unnecessary mapping conflicts . <nl> with this commit we adapt dynamic : runtime to not dynamically create objects . <para-sep> depending on the order of the documents field types may differ , but there are no mapping conflicts <nl> with dynamic : runtime all leaf fields will be runtime fields unless explicitly mapped , hence we do n't dynamically create empty objects under properties , but rather carry around an artificial object mapper <nl> fields can be mapped under properties , as concrete fields that get indexed , objects get dynamically mapped only under dynamic : true . used for sub-fields of objects that are mapped as dynamic : runtime .","that proved to be a poor choice , because the runtime section is flat , supports dots in field names , and does not really need objects . also , these end up causing unnecessary mapping conflicts . <nl> with this commit we adapt dynamic : runtime to not dynamically create objects .",1624019156,this change adds full restart test and rolling restart test that include data streams .,0.9646016955375671
Alluxio_alluxio/12847,"add tests for shareddatareader and buffercachingdatareader <para-sep> 0 threads read from the same file with the shared cache concurrently . <nl> if there are exceptions , we will store them here <nl> it helps recording the number of read operations and validates the read results are correct . <nl> no-op",add the unit tests for sharedgrpcdatareader and buffercachinggrpcdatareader,1613337675,"this also fixes an issue with recursive setreplication , where we create a write_edge locked inode path instead of a write_inode locked inode path",0.9793409705162048
apache_beam/13797,"override pubsubunboundedsource transform for dataflow runner v2 <para-sep> in both cases , the transform needs to read pubsubmessage . however , in case it needs the attributes or messageid , we supply an identity ' parse fn ' so the worker will read pubsubmessage 's from windmill and simply pass them around ; and in case it does n't need attributes , we 're already implicitly using a ' coder ' that interprets the data as a pubsubmessage 's payload .",override pubsubunboundedsource transform for dataflow runner v2 . <nl> and also include runnerv2 integration tests in post commit .,1611356795,"adds support for beam schemas in bigquery reads . <nl> direct reads are not supported yet . support for different date/time types and record types are pending as well . <nl> the largest change is the refactoring of and classes . as the schema inference has to happen at pipeline construction time , the reusable code for accessing the table/query results have been extracted out to ' source definition ' classes named and . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger",0.9745427966117859
elastic_elasticsearch/73750,we changed the default joda behaviour in strict_date_optional_time to <nl> max 0 digits in a year . java.time implementation should behave the same way . <nl> at the same time date_optional_time should have 9digits for year part . <para-sep> this one is considered a year <nl> this one is considered a 12345milliseconds since epoch <nl> for date_optional_time a timestamp with more than 9digits is epoch <nl> generate a random epoch millis in a range 0 to 0-0-31t23:0 : version,we changed the default joda behaviour in strict_date_optional_time to <nl> max 0 digits in a year . java.time implementation should behave the same way . <nl> at the same time date_optional_time should have 9digits for year part .,1622793372,this commit introduce a formal role for identifying nodes that are capable of making connections to remote clusters .,0.9493532776832581
jenkinsci_jenkins/5193,( cherry picked from commit sha ) <cm-sep> file handle leak correction . <nl> ( cherry picked from commit sha ) <cm-sep> provide default implementation for external storage .,provide a default implementation of the ' all files in zip ' download link . this is especially important for external storage plugin ( regression in version ) . <nl> * entry 0 : fix the file handle leak inside directorybrowsersupport . regression in version . <nl> * entry 0 : include root folder in downloaded zip files . regression in version . resolve an additional related zip archive root folder,1611181990,"* plugin description links always point to the plugin site instead of the jenkins wiki . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . ) <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs",0.9675952792167664
elastic_elasticsearch/74233,"improve check_on_startup docs and logging . <nl> today we do n't really describe why using <nl> is such a bad idea , or what to do instead . this commit expands the docs <nl> to clarify what it does , why it 's not really necessary and what to do <nl> instead . it also now logs a warning every time the startup checks run to <nl> encourage users to stop using this setting . <para-sep> report details in a separate message , it might contain control characters which mess up detection of the failure message","today we do n't really describe why using <nl> is such a bad idea , or what to do instead . this commit expands the docs <nl> to clarify what it does , why it 's not really necessary and what to do <nl> instead . it also now logs a warning every time the startup checks run to <nl> encourage users to stop using this setting .",1623931606,"this adds support for v2 index templates to the cat templates api . it uses the field as <nl> priority in order not to break compatibility , while adding the field to show component <nl> templates that are used from an index template .",0.925809919834137
OpenAPITools_openapi-generator/9640,standardize adapter type names <cm-sep> remove unused class <cm-sep> fix ide warning <cm-sep> improve import layout <cm-sep> update sample projects,this pr makes the following small improvements : .,1622566886,"improvement to the c client generator , driven by : <nl> openapi-generator/modules/openapi-generator/src/test/resources/3_0/petstore.yaml . <nl> in particular : <nl> - a .h and a .c to manage binary data , like it 's done for lists <nl> - correct allocation of data for binary data in the model body <nl> - encode/decode of binary data when openssl is not in use <nl> - correct creation of tests for binary data <nl> - added an ' example ' for patterns <nl> - decoration of apikeys in apiclient , needed when a yaml has got both auth_cookie and api_key . <nl> now the",0.8243710994720459
elastic_elasticsearch/74652,if a new node in a mixed cluster creates an async search response and <nl> leaves the cluster ; then an older node ca n't decode that search <nl> response . we should use the version of the oldest node in the cluster <nl> instead when storing an async response .,if a new node in a mixed cluster creates an async search response and <nl> leaves the cluster ; then an older node ca n't decode that search <nl> response . we should use the version of the oldest node in the cluster <nl> instead when storing an async response .,1624907603,"it 's possible that in a slow machine the cluster state updates <nl> take a while to be applied , the license information is published <nl> with normal priority , meaning that it can take a while for the <nl> license information to become available . this can lead to race <nl> conditions . in order to wait until the license information is <nl> available , the tests use assertbusy , but assertbusy only retries <nl> if an assertionexception is raised , for that reason we use the <nl> parameter in the http client and later check that the <nl>",0.9066072702407837
elastic_elasticsearch/73493,"this commit upgrades the azure sdk to version and jackson to version . the <nl> jackson upgrade must happen at the same time due to azure depending on <nl> this new version of jackson . <para-sep> even though we do n't use it , we need to force static init of the default resolver which reads /etc/hosts so it does n't init later <nl> needed by netty dns resolver",this commit upgrades the azure sdk to version and jackson to version . the <nl> jackson upgrade must happen at the same time due to azure depending on <nl> this new version of jackson .,1622134698,"this change adds an extra piece of information , <nl> limits.total_ml_memory , to the ml info response . <nl> this returns the total amount of memory that ml <nl> is permitted to use for native processes across <nl> all ml nodes in the cluster . some of this may <nl> already be in use ; the value returned is total , <nl> not available ml memory .",0.9135358929634094
elastic_elasticsearch/73713,"check total field limit at parse time <para-sep> ca n't use index_mapping_total_fields_limit_setting as a check here , as that is already checked at parse time , see testtotalfieldslimitfordynamicmappingsupdatecheckedatdocumentparsetime <nl> eagerly check field name limit here to avoid oom errors only check fields that are not already mapped or tracked in order to avoid hitting field limit too early via double-counting note that existing fields can also receive dynamic mapping updates ( e.g . constant_keyword to fix the value )","if dynamic mapping updates are enabled , having a crazy number of fields in a document can generate a very large dynamic mapping update that in turn can make a node go oom even before the mapping update is validated . this commit adds a pre-flight check on the total number of fields allowed in a mapping at document parse time , while the ( potentially large ) dynamic mapping update is being built .",1622716037,"our handling for concurrent refresh of access tokens suffered from <nl> a race condition where : . <nl> 0. thread a has just finished with updating the existing token <nl> document , but has n't stored the new tokens in a new document <nl> yet <nl> 0. thread b attempts to refresh the same token and since the <nl> original token document is marked as refreshed , it decrypts and <nl> gets the new access token and refresh token and returns that to <nl> the caller of the api . <nl> 0. the caller attempts to use the newly refreshed",0.9478209614753723
apache_pulsar/10095,fix nondurablecursorimpl initialposition by startcursorposition greater than lastconfirmedentry problem .,"when the reader set greater than , generate will carry a greater than lastconfirmedentry . <nl> when use will throw . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no",1617172637,fix the command tool to set infinite retention correctly . update command line description and website to reflect the fact retention size less than 1mb is treated as no retention . <nl> add an integration test to verify the cli change works .,0.8739306926727295
apache_shardingsphere/10487,create renametabledefinitionsegment to support mysql alter table rename <cm-sep> add parse test case <para-sep> rename table definition segment .,changes proposed in this pull request : <nl> - support mysql alter rename statement <nl> - refactor postgresql & mysql parse logic <nl> - add parse test case,1622018042,changes proposed in this pull request : <nl> - support local datetime,0.9660876393318176
apache_flink/16049,throw better exception when executing remote sql file in sql client,"# # what is the purpose of the change . <nl> throw better exception when executing remote sql file in sql client . <nl> add checkargs method in sqlclient.java . <nl> this change added tests and can be verified as follows : . <nl> add testexecutesqlwithhdfsfile in sqlclienttest.java . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> -",1622558025,"hive acid table configures tblproperties with 'transactional=true ' . currently hive connector could n't support to read and write on acid tables . therefore , hive connector should throw a meaningful exception to users for reading or writing acid tables . <nl> - adds to check whether the tblproperties of the hive source table is true . if the tblproperties is true , this should throw to prompt user meaningful exception . <nl> - adds to check whether the tblproperties of the hive sink table is true . if the tblproperties is true , this should throw to prompt user",0.9129757881164551
Alluxio_alluxio/12958,support to skip corrupt journal entry when recovering from backup,"support to skip corrupt journal entry when recovering from backup , similar to the implementation in . <nl> we can configure to control whether it is enabled or not .",1614530916,web ui might fail to load if anything given under prefix is required to load the under file system . <nl> this fix makes the web ui to use which takes properties with prefix when initializing the ufs . <nl> will port to version branch once approved .,0.9123461842536926
hazelcast_hazelcast/18842,add support for leading non-zeroes characters in varchar to date conversion . <para-sep> sql standard also accepts date without leading zeroes to date .,summary . <nl> this pr introduces support of leading non-zeroes characters in varchar - > date conversion . examples : . <nl> - <nl> - <nl> - .,1622810868,"is used when response wo n't be sent <nl> but backups should be replicated . <nl> it 's between and . <nl> cp subsystem 's wait/notify mechanism is different from regular <nl> hazelcast wait/notify . latter re-executes the waiting operation <nl> when it 's notified and after execution of operation its backups <nl> are replicated . <nl> in cp subsystem wait/notify , when blocked operation is notified <nl> with a response directly , operation is not re-executed . <nl> currently all blocking operations are idempotent <nl> but they do n't have to be . so , re-executing an operation may",0.8982614278793335
runelite_runelite/13245,adds the twisted slayer helmet to the list of slayer helmets that satisfy the requirement for the kill a dustdevil skill clue . <nl> note : i checked other clues that require the slayer helmet and verified <nl> the twisted slayer helmet was already in the list of helms .,adds the twisted slayer helmet to the list of slayer helmets that satisfy the requirement for the kill a dustdevil skill clue . <nl> note : i checked other clues that require the slayer helmet and verified the twisted slayer helmet was already in the list of helms .,1613845367,… the tree name in the option .,0.7937772870063782
apache_pulsar/10015,"support set property on a namespace . <para-sep> force to read the data s.t . the watch to the cache content is setup . <nl> set key value pair property for a namespace . if the property absents , a new property will added . otherwise , the new value will overwrite . example : admin.namespaces ( ) .setproperty ( ' a ' , ' a ' ) ; admin.namespaces ( ) .setproperty ( ' b ' , ' b ' ) ; <nl> set key value pair property for a namespace . if the property absents , a new property will added . otherwise , the new value will overwrite . example : admin.namespaces ( ) .setproperty ( ' a ' , ' a ' ) ; admin.namespaces ( ) .setproperty ( ' b ' , ' b ' ) ; <nl> set key value pair properties for a namespace asynchronously . if the property absents , a new property will added . otherwise , the new value will overwrite . <nl> set key value pair properties for a namespace . if the property absents , a new property will added . otherwise , the new value will overwrite . <nl> get property value for a given key . if the property absents , will return null . example : admin.namespaces ( ) .getproperty ( ' a ' ) ; admin.namespaces ( ) .getproperty ( ' b ' ) ; <nl> get property value for a given key . if the property absents , will return null . example : admin.namespaces ( ) .getproperty ( ' a ' ) ; admin.namespaces ( ) .getproperty ( ' b ' ) ; <nl> get all properties of a namespace asynchronously . example : admin.namespaces ( ) .getpropertiesasync ( ) ; <nl> get all properties of a namespace . example : admin.namespaces ( ) .getproperties ( ) ; <nl> remove a property for a given key . return value of the property if the property exists , otherwise return null . example : admin.namespaces ( ) .removeproperty ( ' a ' ) ; admin.namespaces ( ) .removeproperty ( ' b ' ) ; <nl> remove a property for a given key . return value of the property if the property exists , otherwise return null . example : admin.namespaces ( ) .removeproperty ( ' a ' ) ; admin.namespaces ( ) .removeproperty","add support for set-property/get-property/remove-property on a namespace . <nl> bin/pulsar-admin namespaces set-property <nl> bin/pulsar-admin namespaces get-property <nl> bin/pulsar-admin namespaces remove-property . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( yes ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options :",1616499886,added unit test to verify set/get/remove delayed delivery policy at topic level work as expected when topic level policy is enabled/disabled . <nl> - org.apache.pulsar.broker.admin.adminapidelayeddelivery # testenableanddisabletopicdelayeddelivery <nl> - org.apache.pulsar.broker.admin.adminapidelayeddelivery # testenabletopicdelayeddelivery .,0.9928647875785828
apache_camel/5677,update functiongraph code comments <cm-sep> update code comments <cm-sep> update code comments <para-sep> initialize and return a new functiongraph client,update code comments for huawei cloud functiongraph component to make it easier for a user to understand the code .,1623848824,prevent listing more objects than the value defined in maxmessagesperpoll during the route initialization,0.8352928161621094
apache_pulsar/10400,fix issue in reusing entrybatchindexesacks instances <para-sep> given a bitset with 0 bits set <nl> and a entrybatchindexesacks for the size of 0 <nl> when setting 0 indexes with 0/0 bits set in each ( 0 ' acked ' in each ) <nl> then the totalackedindexcount should be 0 <nl> when recycled and used again <nl> then there should be no previous state and totalackedindexcount should be 0,"the broker has a bug in calculating permits . <nl> as it can be seen from the code locations for calculating permits , it is important that returns the correct value . <nl> when reviewing the code , it was noticed that instances are reused . the problem is , that state is n't properly cleared before reusing . will include state from the previous usage in the calculation . this causes the permit calculations to get corrupted . <nl> this does n't take the case into account where the previous batch was larger than the next one . this",1619518526,"avoid using same opaddentry between different ledger handles . <nl> add state for opaddentry , if op handled by new ledger handle , the op will set to closed state , after the legacy callback happens will check the op state , only initiated can be processed . <nl> when ledger rollover happens , pendingaddentries will be processed . when process pendingaddentries , will create a new opaddentry by the old opaddentry to avoid different ledger handles use same opaddentry . <nl> added new unit test . <nl> if was chosen , please highlight the changes . <nl> - dependencies",0.9447740912437439
confluentinc_ksql/7099,apply command <para-sep> migration file <nl> this is needed to make sure that the table is fully done being created . <nl> verify foo and bar were registered <nl> verify current <nl> verify version 0 <nl> verify version 0 <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"also includes helper functions for writing metadata , loading all migration files and extracting the name of the migration from the file name , and introduces a new class , .",1614294492,"this allows us to make known backwards-compatible changes to ksql that would previously have caused an existing test to fail , e.g . changing the name of the internal topics . with this commit we can mark the old test as only valid up to the last version and create a new version of the test for , with a min version , to test versions going forward . <nl> e.g . <nl> 0. now accepts an optional . <nl> 0. , which is built from , now expects a <nl> 0. no longer takes the param , as it",0.976172685623169
apache_druid/11183,"vectorize the datasketches quantiles aggregator . <nl> extends doublessketchaggregatortest and doublessketchsqlaggregatortest <nl> to run all test cases in vectorized mode . <para-sep> a small number of sketches may run out of the given memory , request more memory on heap and move there . in that case we need to reuse the object from the cache as opposed to wrapping the new buffer . <nl> retrieves the sketch at a particular position . <nl> a small number of sketches may run out of the given memory , request more memory on heap and move there . in that case we need to reuse the object from the cache as opposed to wrapping the new buffer . <nl> retrieves the sketch at a particular position . <nl> nothing to do . nothing to do . <nl> nothing to do . <nl> nothing to do . <nl> nothing to do . <nl> nothing to do . nothing to do .",extends doublessketchaggregatortest and doublessketchsqlaggregatortest <nl> to run all test cases in vectorized mode . <nl> benchmarks from a group by query : .,1619729119,"currently , of search query uses a cost-based planner which needs to compute the exact selectivity of the filter specified in the query . according to the result of jmc profiling , i figured out the bottleneck is calling the expensive operation of bitmaps . so , i propose an alternative way to estimate filter selectivity . <nl> in this patch , i simply assumed dimension values are independent to calculate approximate selectivity . as a result , the calculated selectivity may not be exact . <nl> however , i think it 's worthwhile because the planning cost of will",0.9765716791152954
elastic_elasticsearch/74693,"this pr adds a new api for doing streaming serialization writes to a repository to enable repository metadata of arbitrary size and at bounded memory during writing . <nl> the existing write-apis require knowledge of the eventual blob size beforehand . this forced us to materialize the serialized blob in memory before writing , costing a lot of memory in case of e.g . very large ( and limiting us to max blob size ) . <nl> with this pr the requirement to fully materialize the serialized metadata goes away and the memory overhead becomes completely bounded by the outbound buffer size of the repository implementation . <nl> as we move to larger repositories this makes master node stability a lot more predictable since writing out does not take as much memory any longer ( same applies to shard level metadata ) , enables aggregating multiple metadata blobs into a single larger blobs without massive overhead and removes the 2g size limit on . <para-sep> nothing to do here , already uploaded blocks will be gced by azure after a week . <nl> at most write the default chunk size in one go to prevent allocating huge buffers in the sdk see com.google.cloud.basewritechannel # default_chunk_size <nl> we manually close the channel later to have control over whether or not we want to finalize a blob <nl> we pass create , which means it fails if a blob already exists . <nl> initiate multipart upload request <nl> upload part request <nl> complete multipart upload request <nl> sends an error back or let the request time out <nl> write a blob by providing a consumer that will write its contents to an output stream . this method allows serializing a blob 's contents directly to the blob store without having to materialize the serialized version in full before writing . <nl> this is important since some of the xcontentbuilders write bytes on close . in order to write the footer we need to prevent closing the actual index input . <nl> base class for doing chunked writes to a blob store . some blob stores require either up-front knowledge of the size of the blob that will be written or writing it in chunks that are then joined into the final blob at the end of the write . this class provides a basis on which to implement an output stream that","this pr adds a new api for doing streaming serialization writes to a repository to enable repository metadata of arbitrary size and at bounded memory during writing . <nl> the existing write-apis require knowledge of the eventual blob size beforehand . this forced us to materialize the serialized blob in memory before writing , costing a lot of memory in case of e.g . very large ( and limiting us to max blob size ) . <nl> with this pr the requirement to fully materialize the serialized metadata goes away and the memory overhead becomes completely bounded by the outbound",1624973746,"currently a network disruption will fail a peer recovery . this commit <nl> adds network errors as retryable actions for the source node . <nl> additionally , it adds sequence numbers to the recovery request to <nl> ensure that the requests are idempotent . <nl> additionally it adds a reestablish recovery action . the target node <nl> will attempt to reestablish an existing recovery after a network <nl> failure . this is necessary to ensure that the retries occurring on the <nl> source node provide value in bidirectional failures .",0.9812501072883606
elastic_elasticsearch/72709,"empty mapping to hold null meta . <nl> accidentally such mappings have been created with an empty meta map instead of null , which causes test failures in tests that compare mappings and are now finding an unexpected empty meta object which was not there before . <nl> this commit fixes the empty mapping to not hold any meta , replacing the empty map with a null argument .","accidentally such mappings have been created with an empty meta map instead of null , which causes test failures in tests that compare mappings and are now finding an unexpected empty meta object which was not there before . <nl> this commit fixes the empty mapping to not hold any meta , replacing the empty map with a null argument .",1620141667,today when upgrading from version.x or version.x version to version.x or later and <nl> if two data ( or more ) data streams exist that have a overlapping prefix and <nl> one data stream name ends with the a date suffix that matches with backing index <nl> date pattern ( uuuu.mm.dd ) then new upgraded nodes may refuse to join . essentially <nl> preventing upgrade of the cluster to continue . <nl> in this case the validation logic in confuses <nl> backing indices of one data stream as regular indices and thinks these indices <nl> collide with another data stream,0.9072545766830444
apache_pulsar/10422,transaction log low water mark optimization .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1619616616,move same hash functions for client and broker to common module .,0.9017214775085449
eclipse-openj9_openj9/11533,remove varhandle equals and hashcode . <nl> these methods were originally intended to be part of java 0 and then removed . <cm-sep> update constants api varhandle tests .,- these methods were originally intended to be part of java 0 and then removed .,1608590755,"the existing logic ( removed code in this pr ) was effectively sunk down into omr and z/os support was subsequently added . there should be no change in behavior for existing platforms , and the test coverage proves this is the case .",0.8998852372169495
neo4j_neo4j/11749,revert ' check root cause for errors ' . <nl> this reverts commit sha . <nl> the reverted commit changed external behaviour in a way that information <nl> from exceptions thrown from procedures or user-defined functions was lost . <para-sep> unwrap the wrapped exception we get from invocation by reflection,this reverts commit sha . <nl> the reverted commit changed external behaviour in a way that information <nl> from exceptions thrown from procedures or user-defined functions was lost .,1525854414,"turns out it is due to the extra checks introduced in that pr . this pr fixes that regression , plus removes some compiler warnings from the cypher codebase .",0.8930234313011169
quarkusio_quarkus/18239,"update test with mutiny for hibernate reactive . <nl> injecting the session is discouraged because quarkus will <nl> behave differently when running the test from the command line <nl> or when running it in the ide . <nl> in particular the tests will run in the wrong vert.x context <nl> when they are launched from the ide , causing a failure . <nl> this change makes it possible to run the test from the ide without <nl> errors . <cm-sep> update test with stage for hibrnate reactive . <nl> the test with the injected session is not working <nl> but i 've added another one that uses the sessionfactory <nl> instead .",injecting the session instead of the session factory is discouraged and it does n't work in the ide . <nl> i 've update them so that they use the session factory instead .,1624978353,"this pull request fixes the following : . <nl> 0. wrong permissions of native binary in the tarball entry ( fixed by bumping dekorate to version ) <nl> 0. context for native docker build is now created under ( as is the case for jvm ) <nl> 0. skip command & args when using the docker build strategy ( and use the image entrypoint ) , as there is no reliable way to figure those out for custom dockerfiles .",0.8750222325325012
elastic_elasticsearch/74411,"introduce elasticsearchjavabaseplugin . <nl> just configuring common conventions on java based projects without <nl> adding opinionated sourcesets . reduces the configuration overhead for <nl> test only projects . <para-sep> a wrapper around gradle 's java base plugin that applies our common configuration for production code . <nl> make sure the global build info plugin is applied to the root project <nl> common repositories setup <nl> convenience access to common versions used in dependencies <nl> adds compiler settings to the project <nl> -path because gradle will send in paths that do n't always exist . -serial because we do n't use java serialization . do n't even think about passing args with -j-xxx , oracle will ask you to submit a bug report : ) fail on all javac warnings . todo discuss moving compileoptions.getcompilerargs ( ) to use provider api with gradle team . <nl> either disable annotation processor completely ( default ) or allow to enable them if an annotation processor is explicitly defined <nl> also apply release flag to groovy , which is used in build-tools <nl> todo : this probably should n't apply to groovy at all ? <nl> apply runtime classpath input normalization so that changes in jar manifests do n't break build cacheability <nl> a wrapper around gradle 's java plugin that applies our common configuration for production code . <nl> we want to test compileonly deps ! <nl> we put all our distributable files under distributions <nl> fixup the jar manifest explicitly using an action interface as java lambdas are not supported by gradle up-to-date checks <nl> this dofirst is added before the info plugin , therefore it will run after the dofirst added by the info plugin , and we can override attributes <nl> replace the default ' -all ' classifier with null which will leave the classifier off of the file name . <nl> not all cases need service files merged but it is better to be safe",just configuring common conventions on java based projects without <nl> adding opinionated sourcesets . reduces the configuration overhead for <nl> yaml rest test only projects . <nl> in the end we create less tasks and configure less for test only <nl> projects .,1624360985,"in summary , this pr ensures : <nl> * does not report operator privileges because it is categorised under security <nl> * reports operator privileges status under the security section <nl> * reports last used time of operator privileges . it is up to the downstream to filter out this report if necessary . <nl> i tag this pr as because the original changes are not released yet .",0.9465928673744202
elastic_elasticsearch/73058,need toxcontent and merge on nestedfieldmapper <cm-sep> wippier <cm-sep> test compiles <cm-sep> : server : tests pass <para-sep> todo stop nestedobjectmapper extending objectmapper ?,"nested objects are implemented via a nested class directly on object mappers , <nl> even though nested and non-nested objects have quite different semantics . in <nl> addition , most call-sites that need to get an object mapper in fact need a nested <nl> object mapper . to make it clearer that nested and object mappers are different <nl> beasts with different implementations and different requirements , we should <nl> split them into different implementations .",1620924602,"this drop the ' top level ' pipeline aggregators from the aggregation <nl> result tree which should save a little memory and a few serialization <nl> bytes . perhaps more imporantly , this provides a mechanism by which we <nl> can remove all pipelines from the aggregation result tree . this will <nl> save quite a bit of space when pipelines are deep in the tree . <nl> sadly , doing this is n't simple because of backwards compatibility . nodes <nl> before version need those pipelines . we provide them by setting passing <nl> a into the root of",0.9735836386680603
Alluxio_alluxio/12510,"when hostname & bind.host not specified , local hostname is chosen as the connect host of the service , which may cause an unknownhostexception when the local service hostname can not be resolved by a remote client . this problem can be avoided by specifying alluxio .. hostname or alluxio .. bind.host using an ip address . but it is really troublesome when deploying lots of nodes . <nl> add alluxio.service.use.ip to support using ip as the connect host when enable . <para-sep> enable network ip address used true/false true/false true/false false local hostname not defined version or not defined true local ip address",this problem can be avoided by specifying alluxio .. hostname or alluxio .. bind.host using an ip address . but it is really troublesome when deploying lots of nodes with different ip addresses . <nl> add alluxio.service.use.ip to support using ip as the connect host when enable .,1605510516,added a configuration to determine the write location policy for copyfromlocal . made it use round robin by default .,0.9003354907035828
Graylog2_graylog2-server/10317,"* add permitted location where csv lookups are permitted from . <nl> change is being applied to master first , then will be ported to .0 after . <nl> * migrate implementation to use common trusted_data_file_paths . <nl> * add missing licence headers and binding . <nl> * cleanup . <nl> * use more methods to normalize path . <nl> * fix variable naming . <nl> * rename trusted - > allowed . <nl> * rename trusted - > allowed part 0 . <nl> * fix variable naming . <nl> * implement sorting for path converter . <nl> * resolve symbolic links in permitted and subject file paths . <nl> add full test coverage due to the additional exception handling resulting in more if checks . <nl> * grammar . <nl> * fix forbidden apis error . <nl> * check for allowed file location on dorefresh . <nl> * use real paths and file in tests <cm-sep> re-enable the csv file adapter in cloud <para-sep> optional allowed paths for graylog data files . if provided , certain operations in graylog will only be permitted if the data file ( s ) are located in the specified paths . all subdirectories of indicated paths are allowed by default . this provides an additional layer of security , and allows administrators to control where in the file system graylog users can select files from . it protects against the potential inspection of arbitrary files in the file system from the graylog user interface .","the csv file adapter is needed for content packs ( specifically illuminate ) . adding it back to cloud allows the content packs to be installed and used . <nl> started the app , and verified that the csv file adapter can be used .",1616661854,"with this change , an authenticating realm may throw an <nl> which will be retained if <nl> none of the realms can successfully authenticate the user . this will <nl> then be indicated to the api client with a non-successful status code <nl> and response message . <nl> when an authenticating realm is using an external service , there was no <nl> way to indicate that authentication failed in case the external service <nl> was unavailable at the moment of checking the credentials . it could only <nl> indicate that authentication was unsuccessful in general . <nl> therefore , in",0.9747653007507324
grpc_grpc-java/7826,support reading bootstrap config value directly from env var or system property . <cm-sep> fix test breakages due to exception message change . <cm-sep> add tests . <para-sep> reads and parses bootstrap config . searches the config ( or file of config ) with the following order : a filesystem path defined by environment variable ' grpc_xds_bootstrap ' a filesystem path defined by java system property ' io.grpc.xds.bootstrap ' environment variable value of ' grpc_xds_bootstrap_config ' java system property value of ' io.grpc.xds.bootstrap_value ',"currently , grpc uses the env variable to find the bootstrap file . there are use cases where file based bootstrap config is not optimal like when a file system is not mounted . we want to have an option to input bootstrap config directly via an env variable . this change supports reading the bootstrap config from the following places ( in order ) : . <nl> - if exists then use its value as the name of the bootstrap file . if the file is missing or the contents of the file are malformed , return an error",1611170743,"will load bootstrap file and populate reference to the through attributes of . this is only for demo purpose until is available , whence will populate reference to through attributes instead .",0.9470108151435852
confluentinc_ksql/7719,"fixed nondeterminism in udfindex <para-sep> if two methods exist that match given the above rules , return the method with fewer generic arguments . if two methods exist that match given the above rules , the function call is ambiguous and an exception is thrown . <nl> if none were found ( candidate is n't present ) try again with implicit casting <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","this was n't working in practice , and was leading to equally comparable methods that matched a query being selected arbitrarily . for example , when calling , several udfs could be selected : , , . <nl> to fix this , was changed to no longer consider . as this change implies we are no longer able to select a matching function if multiple exist , now throws a if there is more than one equally comparable method that would match the query . <nl> a minor change that was made on top of this is adding to the",1624463991,"current code calls but the return value has the wrong schema , so the caller has to build a new with the correct schema . this change removes the need for this by passing in the correct schema and sanity checking it . <nl> non-functional change .",0.9551903605461121
Alluxio_alluxio/12837,modify fuse code for conveninent embedded into alluxioworker <para-sep> launches fuse application . <nl> convenience class to pass around alluxio-fuse options .,is responsible for providing the fuse mount information when mounting embedded fuse and providing the existing fuse mount information to clients . <nl> interface is added for workers to unmount the running fuse applications .,1612983379,"various small improvement on . <nl> - update callbacks for and rather than using , so that if failures happens on sending the packet to channel , the states ( e.g. , will be updated rather than ignored ) . <nl> - better handle exceptions : if there are already exceptions seen by this channel , add them to suppressed . <nl> - improve exception message",0.9259567856788635
apache_pulsar/10320,use simple docker log tailing <cm-sep> refactor dockerutils <cm-sep> improve ' tail -f logfile ' efficiency in integration tests,"integration tests log /var/log/pulsar/ * .log files in an inefficient way . it buffers the output in memory beside logging . when the container terminates , the buffered content is also written to the log output . this is confusing and inefficient . <nl> building a large stringbuffer in memory causes unnecessary gc . <nl> - refactor dockerutils used in integration tests <nl> - add new method which does n't buffer to memory",1619076387,"according to , we need to support builder for topicsconsumer . <nl> - add in consumerbuilder <nl> - add test for the builder .",0.9617058038711548
apache_kafka/10755,"re-add and deprecate string constructor , replace parse and add tests <cm-sep> fix import order","quick followup to to actually deprecate this constructor , and update the upgrade guide with what we changed in . i also noticed the taskid # parse method had been modified previously , and should be re-added to the public taskid class . it had no tests , so now it does",1621895869,"deprecated streamsbuilder # addglobalstore and internalstreamsbuilder # addglobalstore <nl> add new streamsbuilder # addglobalstore and internalstreamsbuilder # addglobalstore without sourcename and processorname as parameter <nl> generate sourcename and processorname by using internalstreamsbuilder # newprocessorname . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any",0.9324250221252441
Alluxio_alluxio/13663,"fix pathtranslator to compare path prefixes <nl> by path components <para-sep> first look for an exact match <nl> otherwise match by longest prefix <nl> todo ( yuzhu ) : instead of throwing an exception , mount the path ? <nl> return ufspath if set the key and value to be same when bypass path . <nl> scheme is missing , so prefix with the scheme and authority","previously , erroneously : . <nl> 0. finds a prefix of by simply checking with . this fails to handle the case where the boundary falls within a path component . this case is now covered in the test ; <nl> 0. chooses an arbitary prefix of ( the first returned during map iteration ) even if there are multiple eligible choices . this is fixed by choosing the deepest prefix instead . <nl> it 's a bug fix . <nl> no .",1624032569,turn ob to - when data not exist . <nl> support different tiers .,0.9611408710479736
elastic_elasticsearch/72895,"adds some extra debugging information to make it clear that you are <nl> running . also adds some using timing information <nl> around the fetch and the accumulation . this lets you <nl> calculate a third useful timing number : the analysis time . it is <nl> . <nl> this also adds a half dozen extra rest tests to get a fairly <nl> comprehensive set of the operations this supports . it does n't cover all <nl> of the significance heuristic parsing , but its certainly much better <nl> than what we had . <para-sep> a description of the strategy to include in profile results . <nl> collect debug information to add to the profiling results . this will only be called if the aggregation is being profiled . <nl> build the collector . <nl> you can then subtract those timings from the overall collect time to get the analyze time . while we 're at it we count the number of values we fetch from source . <nl> only update the circuitbreaker after","adds some extra debugging information to make it clear that you are <nl> running . also adds some using timing information <nl> around the fetch and the accumulation . this lets you <nl> calculate a third useful timing number : the analysis time . it is <nl> . <nl> this also adds a half dozen extra rest tests to get a fairly <nl> comprehensive set of the operations this supports . it does n't cover all <nl> of the significance heuristic parsing , but its certainly much better <nl> than what we had .",1620665946,"clean javadoc tags and strip html . <nl> methods and constructors have an optional field . all fields under <nl> are optional but at least one will be present . <nl> fields also have optional field which , if present , is a string .",0.9716346859931946
vespa-engine_vespa/18374,add feature flag for overriding tls ciphers <cm-sep> remove leftovers from http2 feature flag <para-sep> add tls_rsa_with_aes_256_gcm_sha384 cipher to list of default allowed ciphers todo remove tls_rsa_with_aes_256_gcm_sha384 as it 's weak and incompatible with http/0,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624431905,"originally , i was planning to control the maintainers using the and api , but since these maintainers are currently not started ( because is still empty ) , there is no way to disable them now , so i wired in the same feature flag i use in .",0.958661675453186
apache_pulsar/10701,transaction admin api get slow transaction metadata . <para-sep> get slow transactions by coordinator id . <nl> get slow transactions by coordinator id . <nl> get slow transactions . <nl> get slow transactions . <nl> get the transactions witch timeout is bigger than given timeout .,/ * the txnid of this transaction . / <nl> public string txnid ; . <nl> / * the status of this transaction . / <nl> public string status ; . <nl> / * the open time of this transaction . / <nl> public long opentimestamp ; . <nl> / * the timeout of this transaction . / <nl> public long timeoutat ; . <nl> / * the producedpartitions of this transaction . / <nl> public map producedpartitions ; . <nl> / * the ackedpartitions of this transaction . / <nl> public map > ackedpartitions ; <nl> } <nl> #,1621954160,org.apache.pulsar.admin.cli.pulsaradmintooltest # topics <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivetopicapi <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivepolicyupdateandclean <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testdeletewhennosubscriptionswithtopiclevelpolicies,0.9864158034324646
elastic_elasticsearch/74770,"this change adds a new api that supports analyzing the disk usage of <nl> each field of an index . <para-sep> > <nl> test [ setup : messages ] <nl> if the { es } { security-features } are enabled , you must have the <nl> test [ setup : messages ] <nl> testresponse [ s/ : \ { \.\.\.\ } / : $ body. $ _path/ ] testresponse [ s/ : ( \- ) ? +/ : $ body. $ _path/ ] testresponse [ s/ : ' [ ^ ' ] * ' / : $ body. $ _path/ ] <nl> analyze the disk usage of each field in the index . <nl> as we already estimate the size of stored fields , we can trade off the accuracy for the speed of the estimate . here we only visit 0/0 documents instead of all documents . ideally , we should visit 0 doc then skip 0 docs to avoid missing many skew documents . but , documents are stored in chunks in compressed format and a chunk can have up to 0 docs , we need to skip a large number of docs to avoid loading/decompressing some chunks . <nl> computing the compression ratio for each chunk would provide a better estimate for each field individually . but it 's okay to do this entire segment because source and _id are the only two stored fields in es most the cases . <nl> as we track the min/max positions of read bytes , we just visit the first and last values of the docvalues iterator . here we use a binary search like to visit the right most index that has values <nl> it 's expensive to look up every term and visit every document of the postings lists of all terms . as we track the min/max positions of read bytes , we just visit the two ends of a partition containing the data . we might miss some small parts of the data , but it 's an good trade-off to speed up the process . <nl> iterate until we really access the first terms , but iterate all if the number of terms is small <nl> we are n't sure if the optimization can be applied for other implementations rather than the blocktree based implementation . hence , we just traverse every postings of all",this change adds a new api that supports analyzing the disk usage of <nl> each field of an index .,1625068781,this commit adds the get/put/delete apis for interacting with the now v2 versions of index <nl> templates . <nl> these apis are behind the existing system property feature flag .,0.9863491654396057
elastic_elasticsearch/73021,service accounts - fix delete token status code . <nl> the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,1620865452,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.9357600212097168
OpenAPITools_openapi-generator/8685,"improve prefixing of inner enums with classname . <nl> * prevent further name conflicts by correctly naming the enum , until now there could potentially occur conflicts e.g . 2x by renaming the child property <nl> * correctly set to match <para-sep> inner items e.g . enums in collections , only works for one level but same is the case for defaultcodegen <nl> plain enum property <nl> / list of all possible values in this [ { { { enumname } } } ] . <nl> / transformation class that can an instance of [ { { { enumname } } } ] to { { { datatype } } } , / and dynamic data back to [ { { { enumname } } } ] . <nl> / decodes a [ dynamic value ] to a { { { enumname } } } . <nl> / singleton [ { { { enumname } } } typetransformer ] instance . <nl> int code string type string message int id string name int id int petid int quantity datetime shipdate string status int id category category string name builtlist photourls builtlist tags string status int id string name int id string username string firstname string lastname string email string password string phone int userstatus <nl> / list of all possible values in this . <nl> / transformation class that can an instance of to string , / and dynamic data back to . <nl> / decodes a [ dynamic value ] to a maptestmapofenumstringenum . <nl> / singleton instance .","* prevent further name conflicts by correctly naming the enum , until now there could potentially occur conflicts e.g . 2x by renaming the child property <nl> * correctly set to match .",1613080901,- add petstore integration test to js es6 client ( oas3 ) <nl> - minor fix to ' servers ' by adding ' opt ' variable and correcting the index check .,0.8671430349349976
grpc_grpc-java/8169,add null reference checks in sslcontextprovidersupplier,add null checks in sslcontextprovidersupplier constructor and ( in case was never called ),1620836196,interop-testing : apply -- server_host_override regardless of flag order in the stress test client . <nl> the previous pr incorrectly failed to apply -- server_host_override unless it was set before the -- server_address flag .,0.9208200573921204
apache_druid/11373,added inspection rule to prohibit executorservice assignment to executor <cm-sep> use executorservice type variable to assign executorservice,"added inspection rules to prohibit assigning/initializing instances to variables . <nl> changed to which violates inspection rules . <nl> i looked at the concurrency checklist ( threads and executors section ) , i do n't see any violations of the checklist . <nl> please correct me if anything wrong",1624192687,* remove remaining direct references to sun.misc.unsafe <nl> * replace jdk internal exceptions with closest publicly available one .,0.8703895211219788
apache_shardingsphere/10309,add global_rule_node in registrycenternode . <nl> add global rule configurations persist and load in registrycenter . <nl> add global rule changed event and listener . <para-sep> load global rule configurations . <nl> get global rule node path . <nl> global rule configurations event . <nl> global rule changed listener .,changes proposed in this pull request : <nl> - add global rule configurations persist and load in registrycenter . <nl> - add global rule changed event and listener . <nl> - add global_rule_node in registrycenternode .,1620785563,make select for update route to master node .,0.9803622961044312
ballerina-platform_ballerina-lang/29135,fix error message for invalid org in ballerina-toml-schema.json,so changing the error message accordingly in the . <nl> fixes # .,1615460296,this pr updates tests written for structs .,1.0
ballerina-platform_ballerina-lang/27347,"allow listener to decide service path or literal <cm-sep> fix missing annotation population for services <para-sep> if annotations are already set via desugard service-decl , skip . <nl> indicates flagged node is a object constructor . <nl> annotations for object ctors are populated at object init site . <nl> add the lambda/invocation in a temporary block . <nl> path literal is provided , listener does not accept path literal <nl> absolute path is provided , listener does not accept abs path <nl> verify annotation availability <nl> validate resource function annotation",and allow listener 's method to control what to accept as service path . <nl> second param of listener.attach method can be any combination of .,1607161305,when merged this pr will add group based scheduling via strand annotation .,0.9797232151031494
quarkusio_quarkus/17039,"provide a useful error message when file upload is used incorrectly . <para-sep> this is a common enough mistake , so let 's provide a good error message <nl> do n't set a part type , use the default <nl> keep the files around so we can assert the outcome <nl> ensure that the 0 uploaded files where created on disk",* add the ability to capture all uploaded files in resteasy reactive <nl> * improve error messages when users do invalid things .,1620290220,"please do n't merge , i will merge it myself .",0.9787590503692627
apache_kafka/10396,": handle failure to write new session keys gracefully <para-sep> first tick -- after joining the group , we try to write a new session key to the config topic , and fail <nl> second tick -- we read to the end of the config topic first , then ensure we 're still active in the group then try a second time to write a new session key , then finally begin polling for group activity <nl> first tick -- after joining the group , we try to write a new session key to the config topic , and fail ( in this case , we 're trying to simulate that we 've actually written the key successfully , but have n't been able to read it back from the config topic , so to the herder it looks the same as if it 'd just failed to write the key ) <nl> second tick -- we read to the end of the config topic first , and pick up the session key that we were able to write the last time , then ensure we 're still active in the group then finally begin polling for group activity importantly , we do not try to write a new session key this time around","if a distributed worker fails to write ( or read back ) a new session key to/from the config topic , it dies . <nl> this fix softens the blow a bit by instead restarting the herder tick loop anew and forcing a read to the end of the config topic until the worker is able to successfully read to the end . <nl> at this point , if the worker was able to successfully write a new session key in its first attempt , it will have read that key back from the config topic and will not write",1616610253,"a bug was introduced in sha which was caught in system tests : <nl> the rest extensions fail if a standalone worker config is passed , <nl> which does not have a definition for rebalance timeout . <nl> the code will now check that the config is defined before parsing <nl> the value . <nl> a new unit test is added to cover standalone mode for quick testing .",0.9330713748931885
confluentinc_ksql/6800,handle objectcallbacks to fix ldap auth <cm-sep> remove extra lines <para-sep> when : <nl> then :,: . <nl> then running should work .,1608244465,fix issue with parsing sql files where there is trailing white space after command continuation character '\ ' .,0.893081784248352
elastic_elasticsearch/72805,"[ ml ] make ml_standard tokenizer the default for new categorization jobs . <nl> categorization jobs created once the entire cluster is upgraded to <nl> version version or higher will default to using the new ml_standard <nl> tokenizer rather than the previous default of the ml_classic <nl> tokenizer . <nl> the difference between the ml_classic and ml_standard tokenizers <nl> is that ml_classic splits on slashes and colons , so creates multiple <nl> tokens from urls and filesystem paths , whereas ml_standard attempts <nl> to keep urls and filesystem paths as single tokens . <nl> it is still possible to config the ml_classic tokenizer if you <nl> prefer : just provide a categorization_analyzer within your <nl> analysis_config and whichever tokenizer you choose ( which could be <nl> ml_classic or any other elasticsearch tokenizer ) will be used . <para-sep> todo : the ml_info mute can be removed from master once the ml_standard tokenizer is in 0.x <nl> create a categorization_analyzer that mimics what the tokenizer and filters built into the original ml c++ code do . this is the default analyzer for categorization to ensure that people upgrading from old versions <nl> create a categorization_analyzer that will be used for newly created jobs where no categorization analyzer is explicitly provided . this analyzer differs from the default one in that it uses the ml_standard tokenizer instead of the ml_classic tokenizer , and it only considers the first non-blank line of each message . this analyzer is not used for jobs that specify no categorization analyzer , as that would break jobs that were originally run in older versions . instead , this analyzer is explicitly added to newly created jobs once the entire cluster is upgraded to version version or above . <nl> remove these tests because they do n't call an ml endpoint and we do n't want <nl> if the user has not provided a categorization analyzer then set the standard one if categorization is being used at all and all the nodes in the cluster are running a version that will understand it . this method must only be called when a job is first created - since it applies a default if it were to be called after that it could change the meaning of a job that has already run . the validation in this method has to be done server-side ; it can not be","categorization jobs created once the entire cluster is upgraded to <nl> version version or higher will default to using the new ml_standard <nl> tokenizer rather than the previous default of the ml_classic <nl> tokenizer , and will incorporate the new first_non_blank_line char <nl> filter so that categorization is based purely on the first non-blank <nl> line of each message . <nl> the difference between the ml_classic and ml_standard tokenizers <nl> is that ml_classic splits on slashes and colons , so creates multiple <nl> tokens from urls and filesystem paths , whereas ml_standard attempts <nl> to keep urls , email addresses",1620297732,"elasticsearch currently provides only the count of http clients currently holding an open connection and the number of http connections that have been opened on the node . <nl> this change adds the following to the ' http ' section of node stats : . <nl> some notes about the fields above : <nl> - : this is pulled from the or http header if either is present . note that it would be nice if elastic products identified themselves with a user-friendly tag . the header reports the go client or the js client for beats and kibana ,",0.9773097634315491
apache_druid/11146,fix serde issues with time-min-max extension,"this extension was implementing in the base class which would create a new , instead of a or . <nl> this pr fixes this by making abstract , and implementing this method directly in the min and max agg factories . i also cleaned up equals/hashcode which were missing the format arguments , added annotations to things which looked like they could be null ( i decided this includes since uses the default time column if it is null ) , switched to using ( and added format since was missing from cache key )",1619049212,"to avoid this happening even with , i added a utility method and set of log methods to , dedicated to logging chunks of 0 at a time to ensure we will never create a gigantic string to log containing all of the segments no matter how many segments are involved because each message should be sized in the tens of kilobytes . <nl> there remain two areas that exceptions thrown in , one in the other in which could i guess create giant strings if you have absurd numbers of segments you are trying to lock , but i",0.9636374115943909
vespa-engine_vespa/17934,wire in stateless onnx runtime evaluation <para-sep> global onnx models not tied to a search definition * /,main change is is which adds the required onnx model info which is sent to model evaluation . the is the main test for this pr . there are quite a bit of small changes to continue to support the conversion to native vespa rank expressions . i think this will have to be cleaned up a bit more going forward .,1621582932,this allows applications to specify disk speed explicitly . i 'll change to any in the appropriate defaults later .,0.9765334725379944
OpenAPITools_openapi-generator/8467,add net5.0 support to csharp-netcore client gen <cm-sep> update doc <cm-sep> update samples <para-sep> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .plg <nl> .opt <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> configure oauth2 access token for authorization : petstore_auth <nl> add a new pet to the store <nl> petapi | addpet | post /pet | add a new pet to the store petapi | deletepet | delete /pet/ { petid } | deletes a pet petapi | findpetsbystatus | get /pet/findbystatus | finds pets by status petapi | findpetsbytags | get /pet/findbytags | finds pets by tags petapi | getpetbyid | get /pet/ { petid } | find pet by id petapi | updatepet | put /pet | update an existing pet petapi | updatepetwithform | post /pet/ { petid } | updates a pet in the store with form data petapi | uploadfile | post /pet/ { petid } /uploadimage | uploads an image storeapi | deleteorder | delete /store/order/ { orderid } | delete purchase order by id storeapi | getinventory | get /store/inventory | returns pet inventories by status storeapi | getorderbyid | get /store/order/ { orderid } | find purchase order by id storeapi | placeorder | post /store/order | place an order for a pet userapi | createuser | post /user | create user userapi | createuserswitharrayinput | post /user/createwitharray | creates list of users with given input array userapi | createuserswithlistinput | post,- added .net version support <nl> - added tests .,1610975967,description of the original pr <nl> > we want to able to unit test our code that uses the generated api code . <nl> in order to do that we need a virtual interface to mock away the <nl> generated api code . <nl> > <nl> > this pr introduces two new config options for the cpprest generator : <nl> > <nl> > ' generateinterfacesforapis ' will generate an abstract base class <nl> ( interface ) for all apis . <nl> > ' generategmocksforapis ' will additionally generate google mock classes <nl> for the apis . this config option of,0.786641001701355
apache_shardingsphere/10502,support pg alter index rename statement <para-sep> table meta data loader utility class . <nl> get logic index name . <nl> shardingsphere schema refresher for alter index statement . <nl> get rename index segment . <nl> get rename index segment .,changes proposed in this pull request : <nl> - support pg alter index rename statement <nl> - refresh alter index metadata <nl> - modify load index metadata logic to get logic index,1622108218,changes proposed in this pull request : <nl> - judge whether to append derived columns for 'order by ' and 'group by ' . <nl> - passthough the shardingdatameta to preparedstatementroutingengine and statementroutingengine . <nl> - add h2shardingmetadatahandler to extend shardingmetadatahandle . <nl> - modify some expected xml file because of optimazing iscontainsitem function .,0.9702956080436707
confluentinc_ksql/7734,"implement comparisons for time/date <cm-sep> rename some stuff <cm-sep> add compareutil test , reject time/timestamp comparisons <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> then : <nl> given : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","time/timestamp and time/date are not allowed , and timestamp/date converts the date to a timestamp before comparing .",1624723377,"ksql uses a statement rewritter to convert struct field dereferences into function calls . the rewrite is done for , and statements , but was missing . <nl> it is valid to execute on a query string , e.g . it is therefore important that the query within the statement has the same rewrites applied to it as would be applied should the statement be executed directly . <nl> suitable unit tests added .",0.967262864112854
jenkinsci_jenkins/5197,bump reflections from version to version .,"commits . <nl> see full diff in compare view . <nl> dependabot will resolve any conflicts with this pr as long as you do n't alter it yourself . you can also trigger a rebase manually by commenting . <nl> [ // ] : # ( dependabot-automerge-start ) <nl> [ // ] : # ( dependabot-automerge-end ) . <nl> dependabot commands and options . <nl> you can trigger dependabot actions by commenting on this pr : <nl> - will rebase this pr <nl> - will recreate this pr , overwriting any edits that have been made to it <nl> -",1611300492,"this pull request just corrects a method name mix up ( should be iscaseinsensitive ( ) instead of iscasesensitive ( ) ) , removes redundant imports and adds the right jira ticket number in the commit message and in the changelog .",0.8684698343276978
apache_flink/16202,updating to latest aws sdk for kinesis connector,"update aws sdk v1 and dynamodb streams kinesis adapter to latest version . <nl> bumped : <nl> - aws sdk v1 from to <nl> - dynamodb streams kinesis adapter from to . <nl> this change is already covered by existing unit/integration/e2e tests for kinesis connector . <nl> - dependencies ( does it add or upgrade a dependency ) : yes <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects",1624024010,"# # what is the purpose of the change . <nl> this pull request fix processfailurecancelingitcase.testcancelingonprocessfailure error by specifying a free port . <nl> - fix processfailurecancelingitcase.testcancelingonprocessfailure error by specifying a free port . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code",0.8483715653419495
apache_pulsar/10696,should not call readmoreentries ( ) recursively in the same thread <cm-sep> no need to add already acked messages to messagestoredeliver <para-sep> we should not call readmoreentries ( ) recursively in the same thread as there is a risk of stackoverflowerror <nl> we should not call readmoreentries ( ) recursively in the same thread as there is a risk of stackoverflowerror,"the other day , some of our broker servers got the following stackoverflowerror : . <nl> this phenomenon can be reproduced by the following procedure : . <nl> 0. store a large number of messages in the backlog of a topic <nl> 0. connect some shared consumers to the topic . these consumers receive messages but do not acknowledge at all <nl> 0. run skip-all to remove all messages from the backlog <nl> 0. add another consumer whose receiver queue size is small <nl> 0. close all the consumers added in step 0 <nl> 0. stackoverflowerror occurs on the broker",1621937484,"this pr adds support to that - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding the documentation",0.9310000538825989
ballerina-platform_ballerina-lang/27289,"fix bug in map constrained table to json conversion <cm-sep> refactor birvartojvmindexmap . <nl> the birvartojvmindexmap had used birnode.birvariabledcl as the input while only the type and the name are actually required . this refactors the class to only use these . <cm-sep> update release version <cm-sep> [ gradle release plugin ] - new version commit : 'v2.version-preview7-snapshot ' . <cm-sep> add first get local versions in remote repo get pkg versions <cm-sep> update init new command resources and messages <cm-sep> add package other properties to package.json of balo <cm-sep> disable the optimize import code action <cm-sep> update usage help text in build run and test commands <cm-sep> resolve pr comments <cm-sep> fix resolving java11 balos in file system repo <cm-sep> update project to package in help texts <cm-sep> add parenthesised type <cm-sep> change exception handling behavior to throw an exception when writing to jar fails <cm-sep> add check to skip if observability-included is set to false <cm-sep> format help info in cli commands <cm-sep> dump version <cm-sep> fix merge conflict <cm-sep> use encoded func name in resource func type <cm-sep> improve path param validations <para-sep> todo add package properties which is not available in the to todo we need to fix this properly later <nl> first we will check for a balo that match any platform if balo for any platform not exist check for specific platform <nl> first , get local versions <nl> if environment is offline we return the local versions <nl> add main string [ ] args param first <nl> test file system repository . <nl> { ' optimizeimports.json ' , ' optimizeimports.bal ' } , <nl> ' $ get $ . ' is encorded into ' $ gen $ $ get $ $ 0 '",$ title and improve path params . <nl> fixes # .,1606897135,also this fixed few performance <nl> issues in references and rename opration and introduce full project <nl> wide references support .,0.9642655253410339
apache_incubator-pinot/6535,json_match test cases and bug fix . <cm-sep> remove redundant file . <cm-sep> revert unncessary change . <para-sep> test cases verifying evaluation of predicate with expressions that contain numerical values of different types . <nl> test filtering on string value associated with json key * / <nl> test filtering on number value associated with json key * / <nl> test filtering on float value associated with json key * / <nl> query to retrieve result as int <nl> query to retrieve result as double <nl> retrieve json array after filtering on string value associated with json key * / <nl> test filtering on string value within a json array * /,this pr fixes a bug to allow using json_match predicate in sql queries and adds sql level unit test cases for json_match predicate . <nl> - was modified to fix a bug that was preventing use of json_match predicate in sql queries . <nl> - was modified to allow writing sql test cases using json_match predicate . <nl> - contains sql unit test cases for json_match .,1612326197,"support queries like : . <nl> select avg ( sub ( col1 , col2 ) from foo <nl> select avg ( sub ( div ( col1 , col2 ) , div ( col3 , col4 ) ) ) from foo . <nl> they were failing in avgaggregationfunction as transformblockvalset ( ) did not implement getvaluetype ( ) method . <nl> also added operand checks for transform functions for acceptable data types . <nl> testing : . <nl> added transformqueriestest to test both inner-segment and inter-segment , inter-server queries with custom data",0.9765934348106384
pentaho_pentaho-kettle/7837,- backport of - fields defined in ' key ( s ) to look up the values ' goes missing in the delete step ( version suite ),"it only was backported the changes needed to fix the issue , it was not backported changes related with sonnar .",1611746511,in the pr above there are two issues fixed : and . <nl> this pr is only for .,0.8826673030853271
OpenAPITools_openapi-generator/9490,"rename qt5 to qt <cm-sep> rename , update <para-sep> ( generators/cpp-qt-client.md ) ( generators/cpp-qt-qhttpengine-server.md ) <nl> set modelnameprefix as default for qhttpengine server <nl> cli options <nl> additional properties . these values can be passed to the templates and are available in models , apis , and supporting files <nl> write defaults namespace in properties so that it can be accessible in templates . at this point command line has not been parsed so if value is given in command line it will supersede this content <nl> language specific primitives . these types will not trigger imports by the client generator <nl> mapped as ' file ' type for oas version <nl> uuid support - possible enhancement : use quuid instead of qstring . beware though that serialization/de-serialization of quuid does not come out of the box and will need to be sorted out ( at least imply modifications on multiple templates ) <nl> optional - type declaration . this is a string which is used by the templates to instantiate your types . there is typically special handling for different property types <nl> optional - openapi type conversion . this is used to map openapi types in a into either language specific types via or into complex models if there is not a mapping . <nl> sanitize name <nl> if it 's all uppper case , convert to lower case <nl> camelize ( lower first character ) the variable name petid = > pet_id <nl> for reserved word or word starting with number , append _ <nl> check all return parameter basetype if there is a necessity to include , include it if not already done <nl> check all parameter basetype if there is a necessity to include , include it if not already done <nl> we use qstring to pass path params , add it to include <nl> maps uses qstring as key <nl> source folder where to write the files <nl> set the output folder here <nl> models . you can write model files using the modeltemplatefiles map . if you want to create one template for file , you can do so here . for multiple files for model , just put another entry in the with a different extension <nl> api classes . you can write classes for each api file with the apitemplatefiles map . as with models , add multiple entries with different","rename to in the code , samples , configs and more ( for both client and server generators ) .",1621090584,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) .",0.8536905646324158
Alluxio_alluxio/13332,handle unchecked exceptions similarly to checked exceptions,"previously , unchecked exceptions are swallowed by alluxio workers , leading to client not knowing about the failure .",1620090652,do not create directory breadcrumbs on liststatus or isdirectory .,0.9050518274307251
apache_incubator-pinot/7033,include null check for setting minion tag .,broker and server already carry out similar null check .,1623181964,"when we attempt to fetch configuration value from a certain field , it only returns a partial result . it was because underneath configuration , it use comma to separate values . for configuration value with comma , it automatically separates them as an array list . this pr disable this upon creation .",0.8369136452674866
Alluxio_alluxio/13131,"do not implicitly complete open stream <para-sep> fetch file status when the stream is still open <nl> when the writetype is through , we only see the blocks when the file is committed when the file is not committed , we only see incomplete fileblockinfo","the trade-off is , when we on a file that is currently being written , the number of and we get will mismatch . i do n't think that is a problem .",1616844571,"when s3a.inherit_acl=false , owner and group discovered from the ufs will be empty . in this case , we inherit the ancestor from the parent directory . <nl> $ afs chown usera /usera <nl> changed owner of /usera to usera . <nl> $ afs mount -- option alluxio.underfs.s3a.inherit_acl=false /usera/s3a s3a : //adit-s3a-test/ <nl> mounted s3a : //adit-s3a-test/ at /usera/s3a . <nl> $ afs ls / <nl> drwxr-xr-x usera staff 0 persisted 0-0-0 0:0:0:0 dir /usera .",0.9169533252716064
apache_kafka/10351,used better method to initialize size of collection . <para-sep> check topic names are in the correct place when using topicnames . <nl> topics in topicnames are moved to new topics field <nl> ensure we only use new topics field on versions 0+ . <nl> we should fail if version is less than 0 . <nl> check topic ids are handled correctly . we should only use this field on versions 0+ . <nl> all topic names should be replaced with null <nl> we should fail if version is less than 0 . <nl> createdeletetopicsrequest sets 0 topics <nl> test using ids,for versions 0+ will return an empty list in kafkaapis . this pr uses a new method to efficiently initialize the size of the collection .,1616084929,"current implementation stores reference to wrapped in , which breaks and . <nl> from java docs ) . <nl> > the returned collection does not pass the hashcode and equals operations through to the backing collection , but relies on object 's equals and hashcode methods . <nl> contribution is my own original work and i license the work to the project under the project 's open source license .",0.9160516858100891
elastic_elasticsearch/74399,"add ability for eql to perform ccses . <nl> this introduces the ability for eql to perform searches on a remote <nl> cluster . <para-sep> strip any qualification from the received index string <nl> constructor for ' local ' rest tests <nl> constructor for multi-cluster tests <nl> constructor for ' local ' rest tests <nl> constructor for multi-cluster tests <nl> constructor for ' local ' rest tests <nl> constructor for multi-cluster tests <nl> client used for loading data on a remote cluster only . <nl> returned client is used to load the test data , either in the local cluster ( for rest/javaresttests ) or a remote one ( for multi-cluster ) . note : the client ( ) /adminclient ( ) will always connect to the local cluster . <nl> the transportservice needs to be able to return a valid remoteclusterservices object down the stream , required by the verifier .","this introduces the ability for eql to perform searches on a remote cluster , leveraging es 's ccs capabilities . <nl> the remote cluster needs to be on the same version as the local cluster .",1624349116,adds support for retrieving async eql search result s to eql search api .,0.9820213317871094
jenkinsci_jenkins/5517,"add www to jenkins.io urls <para-sep> jenkins contribution landing page jenkins irc channel <nl> in particular , this happens under . <nl> see .",done using : . <nl> i hope we 're not getting rid of that again in the future 😒 . <nl> ( too minor ),1621695167,* entry 0 : replaced text references to ' slave ' with ' agent ' in various comments and test references .,0.9173539876937866
apache_pulsar/10401,add support for setting time based limit on backlog quota with cli . <para-sep> time based quota is in second,"this change added tests and can be verified as follows : . <nl> added unit test . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : no <nl> - the schema : no <nl> - the default values of configurations : no <nl> - the wire protocol : no <nl> - the rest endpoints : no <nl> - the admin cli options : yes <nl> - anything that affects deployment : no . <nl> - does this pull request",1619524560,"this pr just makes an effort to make it . <nl> the error happens if the client connect to brokers by ipv6 address , like fec0:0:0 : ffff : :0 . <nl> - wrong format : fec0:0:0 : ffff : :0:0 <nl> - correct format : [ fec0:0:0 : ffff : :0 ] :0 . <nl> cause the split regex is ' : ' , brackets are needed and the ip : port ca n't split by ' : ' directly . <nl> validatehostname in serviceuri",0.9180119633674622
keycloak_keycloak/7872,fix oidc conformance for hybrid-flow <para-sep> validate if token_type is null <nl> validate if expires_in is null <nl> validate if token_type is null <nl> validate if expires_in is null <nl> validate if token_type is present <nl> validate if expires_in is present <nl> validate if token_type is present <nl> validate if expires_in is present <nl> validate if token_type is null <nl> validate if expires_in is null <nl> validate if token_type is present <nl> validate if expires_in is present,the response does not meet specs of oidc . further information are provided in jira .,1616174368,"login form from sdk-html uses the same style for both saas and realm , but has slightly different configuration for each : <nl> - different background <nl> - no logo on realm ( until we can support upload of realm logo ) <nl> - powered by keycloak only shown on realm",0.8746629357337952
confluentinc_ksql/7664,add time and date types <cm-sep> add the datetype and timetype files <cm-sep> serde for time type <para-sep> return milliseconds <nl> checkstyle_rules.off : classdataabstractioncoupling checkstyle_rules.on : classdataabstractioncoupling <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"time gets serialized to an integer number of milliseconds , and deserialized to .",1623199008,"for unwrapped single fields it was registering them as a union , i.e . optional . for example , for a unwrapped single field the avro schema was being registered as : . <nl> while this is strictly true , as the value can be null , this would be inconsistent with the schemas ksql would register for a normal row , which would just be an avro record , _not_ a union of and the record type . likewise , the stock confluent avro serializer would also register the same record schema . <nl> so this pr makes a",0.9472501873970032
apache_shardingsphere/10839,add databasetypedsqlparserfacaderegistrytest <cm-sep> modify databasetypedsqlparserfacaderegistrytest method <cm-sep> add sqlparserenginetest,changes proposed in this pull request : <nl> - add more test cases for shardingsphere-sql-parser-engine module .,1623900146,"for postgresqlstatementmemorystrictlyfetchsizesettertest and mysqlstatementmemorystrictlyfetchsizesettertest , assertsetfetchsize and assertgettype added",0.9631937742233276
hazelcast_hazelcast/18561,"add tostring method to indeximpl <nl> this will help to pinpoint issue better in case of test failure <para-sep> lock to serialize updates to the state . number of partitions in the cluster . current state . <nl> monotonically increasing stamp , that is incremented on every partition info update . partitions that are currently indexed . the number of partitions that are being updated at the moment ( indexing or deindexing ) . <nl> double check : if we still see same partition distribution",__modification : __ <nl> add detailed failure message to assertion . this will help to pinpoint issue better . <nl> checklist : .,1618838257,"see commit message for details . <nl> there are also 0 additional changes : <nl> - client lock proxy fails fast on when name is . this makes it consistent with member proxy impl . this behaviour is specified in contract since at least hazelcast version , but it was n't enforced on a client-side .",0.9124560356140137
netty_netty/11171,add websocketclienthandshaker / websocketserverhandshaker close methods that take channelhandlercontext as parameter . <nl> motivation : . <nl> at the moment we only expose close ( ... ) methods that take a channel as paramater . this can be problematic as the write will start at the end of the pipeline which may contain channeloutboundhandler implementations that not expect websocketframe objects . we should better also support to pass in a channelhandlercontext as starting point for the write which ensures that the websocketframe objects will be handled correctly from this position of the pipeline . <nl> modifications : . <nl> - add new close ( ... ) methods that take a channelhandlercontext <nl> - add javadoc sentence to point users to the new methods . <nl> result : . <nl> be able to ' start ' the close at the right position in the pipeline . <para-sep> performs the closing handshake . <nl> performs the closing handshake <nl> performs the closing handshake <nl> performs the closing handshake . closing frame that was received . performs the closing handshake . closing frame that was received . <nl> performs the closing handshake . <nl> performs the closing handshake . <nl> web socket frame that was received .,add websocketclienthandshaker / websocketserverhandshaker close methods that take channelhandlercontext as parameter . <nl> motivation : . <nl> at the moment we only expose close ( ... ) methods that take a channel as paramater . this can be problematic as the write will start at the end of the pipeline which may contain channeloutboundhandler implementations that not expect websocketframe objects . we should better also support to pass in a channelhandlercontext as starting point for the write which ensures that the websocketframe objects will be handled correctly from this position of the pipeline . <nl> modifications : . <nl> -,1618899390,without an option to set the keystore type you must change the configuration of the entire jvm which is impractical . <nl> this pr adds the possibility to set the keystore type !,0.9669276475906372
apache_shardingsphere/10770,add test case for ruleconfigurationchecker <para-sep> algorithm provided encrypt rule configuration checker test . <nl> encrypt rule configuration checker test . <nl> algorithm provided readwrite-splitting ruleconfiguration checker testcase . <nl> readwrite-splitting rule configuration checker test .,changes proposed in this pull request : <nl> - add test case for readwritesplittingruleconfigurationchecker <nl> - add test case for algorithmprovidedreadwritesplittingruleconfigurationchecker <nl> - add test case for encryptruleconfigurationchecker <nl> - add test case for algorithmprovidedencryptruleconfigurationchecker,1623418028,changes proposed in this pull request : .,0.964849054813385
elastic_elasticsearch/73724,"consolidate data stream alias logic . <nl> move data stream alias logic that was scattered in several places to the class . <para-sep> returns the name of this data stream alias . returns the data streams that are referenced returns the write data stream this data stream alias is referring to . write requests targeting this instance will resolve the write index of the write data stream this alias is referring to . if the provided iswritedatastream is set to true then the provided data stream is also set as write data stream . if the provided iswritedatastream is set to false and the provided data stream is also the write data stream of this instance then the returned data stream alias instance 's write data stream is unset . the same instance is returned if the attempted addition of the provided data stream did n't change this instance . <nl> returns null if because of the removal of the provided data stream name a new instance would n't reference to any data stream . the same instance is returned if the attempted removal of the provided data stream did n't change this instance . <nl> the write data stream gets set to null in the returned instance if the write data stream no longer appears in the intersection . <nl> if this instance does n't have a write data stream then the write index of the other data stream becomes the write data stream of the returned instance . <nl> returns a new instance with potentially renamed data stream names and write data stream name . if a data stream name matches with the provided rename pattern then it is renamed according to the provided rename replacement . <nl> add to alias , a different instance is returned with as one of the data streams being referred to <nl> add to alias as write data stream , same as above but the returned instance also refers to as write data stream <nl> add as data stream , which is already referred to by this alias . the same instance is returned to signal a noop . <nl> add as non write data stream , which is already referred to by this alias . the same instance is returned to signal a noop . <nl> add as write data stream , which is already referred to by this alias ,",move data stream alias logic that was scattered in several places to the class .,1622735815,this refactor for the deprecation plugin makes extending and adding more plugin settings deprecation checks simpler .,0.9734896421432495
ballerina-platform_ballerina-lang/28529,read version & lang spec from properties file .,# # purpose <nl> > removed ballerina version and implementation spec constants and changed the code to read those from a properties file .,1612867236,,0.0
apache_beam/14275,fix testgroupbykeywithbadequalshashcode failing on spark structured streaming runner <cm-sep> fix testlargekeys100mb on spark structured streaming runner <cm-sep> change access level groupbykeytest <para-sep> increase memory heap in order to avoid oom errors,test : testlargekeys100mb <nl> problem : out of memory when running test <nl> solution : increase max memory in spark_runner.gradle . <nl> test : testgroupbykeywithbadequalshashcode <nl> problem : illegalaccesserror on inner classes badequalitykey and deterministickeycoder <nl> solution : add access level modifier ' protected ' to classes,1616084351,please add a meaningful description for your change here . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.7470546364784241
apache_incubator-pinot/6887,"remove realtime metrics if it 's destroyed <para-sep> removes a table gauge given the table name and the gauge . the add/remove is expected to work correctly in case of being invoked across multiple threads . <nl> remove gauge from pinot metrics . <nl> remove callback gauge . <nl> cleans up the metrics that reflects the state of the realtime segment . this step is essential as the instance may not be the target location for some of the partitions . e.g . if the number of partitions increases , or a host swap is needed , the target location for some partitions may change , and the current host remains to run . in this case , the current server would still keep the state of the old partitions , which no longer resides in this host any more , thus causes false positive information to the metric system . <nl> this interface should be thread-safe against adds and removes of the same metric .","this step is essential as the instance may not be the target location for some of the partitions . <nl> e.g . if the number of partitions increases , or a host swap is needed , realtime segment assignment needs to be re-calculated . the target location for some partitions may change , and the current host remains to run . in this case , the current server would still keep the states of the old partitions , which no longer resides in this host any more , thus causes false positive information to the metric system .",1620339439,"this pr allows rule-based anomaly detection and algorithm-based detection to run for the same anomaly function at the same time and merge the results . also , enable the potential to add multiple secondary detection functions .",0.9341071248054504
ballerina-platform_ballerina-lang/30270,avoid creating types unnecessarily in type param analyzer <cm-sep> fix langlibarraytest <cm-sep> add tests,"although the type param analyzer does n't add type definitions , when these new types are used in places where type definitions may get added ( like in intersection types ) , they result in in > 0 type definition with the same name , causing code gen to fail .",1619855957,"for the time being , we use -- jvmtarget flag to differentiate these two flows ( like when u build some package with -- jvmtarget flag , then it will look bir files for dependent packages as well .",0.9619911909103394
ballerina-platform_ballerina-lang/27584,move common lexer methods to abstractlexer <cm-sep> refactor documentationlexer <para-sep> check whether a given char is an identifier following char . identifierfollowingchar : = identifierinitialchar | digit <nl> check whether a given char is a digit . digit : = 0 .. 0 <nl> check whether a given char is a hexa digit . hexdigit : = digit | a .. f | a .. f <nl> check whether a given char is an identifier start char . identifierinitialchar : = a .. z | a .. z | _ | unicodeidentifierchar <nl> check whether a given char is a unicode identifier char . unicodeidentifierchar : = ^ ( asciichar | unicodenonidentifierchar ) <nl> check ascii char range <nl> check unicode private use char <nl> todo : if ( unicodepatternsyntaxchar ) return false <nl> check whether a given char is a unicode private use char . unicodeprivateusechar : = 0xe000 .. 0xf8ff | 0xf0000 .. 0xffffd | 0x100000 .. 0x10fffd <nl> check whether a given char is a unicode pattern white space char . unicodepatternwhitespacechar : = 0x200e | 0x200f | 0x2028 | 0x2029 <nl> start the given mode in the token reader . <nl> end the current mode of the token reader . get the current index of the token reader .,"but improved formatting for such scenario ) . <nl> - in documentation lexer , we did a char-sequence-search before tokenizing the content within the backticks . <nl> - now with the new identifier definition searching it at lexer level seemed to be more expensive . <nl> - therefore , we perform a token-sequence-search in the parser level instead .",1608312038,additionally this will add worker formatting and assignment formatting for record literals and add fixes went only with next-release branch,0.9796813726425171
elastic_elasticsearch/74667,"shapebuilders are moved to use geometry classes . <para-sep> make sure that minx ! = maxx after geohash encoding <nl> a geometry collection that is partially within the indexed shape <nl> create mapping <nl> random geometry generator created something other than a point type , verify the correct exception is thrown <nl> no shape","following the effort of removing dependency on legacy geo code , this pr removes this dependency for some of the geo test . shapebuilders are moved to use geometry classes .",1624948198,"the administrative actions for data streams , create , delete , and get , are now index-level actions . in keeping with the decision that privileges should be granted on data streams and indices in the same namespace , the create , delete , and get ( aka view metadata ) actions have been added to the existing , , and privileges , respectively . <nl> because the requests for all index-level actions must implement , that change was included in this pr . it was minor except for the fact that the get data stream request must accept multiple",0.9428815245628357
elastic_elasticsearch/74329,remove buildparams.isinternal . <nl> after breaking up build logic between internal and external we can remove buildparams.isinternal ( ) . <nl> we also resolve bwc versions lazy and not eagerly . this makes configuration of non bwc builds easier and <nl> also makes integration tests easier to setup . <para-sep> required for jarhell to work <nl> enforce the minimum compiler version <nl> core <nl> x-pack,after breaking up build logic between internal and external we are able to remove buildparams.isinternal ( ) . <nl> this also makes resolving bwc versions lazy and not eager . this makes configuration of non bwc builds and <nl> integration tests setup easier .,1624059804,"we recently removed getmapperservice from queryshardcontext in the attempt to avoid consumers depending on the whole mapperservice . searchcontext still has that problem although it is easier to solved as it can delegate to queryshardcontext for the most part , which is what this commit does for most of the existing usages .",0.9520882368087769
apache_druid/10779,"enhance the logic of start up druidschema immediately if there are no segments . <para-sep> lastfailure ! = 0l means exceptions happened before and there 're some refresh work was not completed . so that even serverview is initialized , we ca n't let broker complete initialization .","is used for control whether the broker will wait for its sql metadata view to fully initialize before starting up . <nl> but this pr brings another bug that broker will not wait for its sql metadata view to fully initialize before starting up , even though set druid.sql.planner.awaitinitializationonstart true . <nl> broker will do retry in next loop . <nl> in next loop , is true and exit the loop directly , but there are still several refresh work need to be done . <nl> here is the full logs of this bug : . <nl> as you can",1611051016,"fails creation of taskresource if availabilitygroup is null . <nl> availabilitygroup in taskresource should never be null . if a task has availabilitygroup = null , it does not fails and still runs . however , while this task is running , all other tasks will fails to start ( and will be mark failed ) . once the task with availabilitygroup = null finish running , other tasks will now be able to be created . <nl> the error seen is ( when other good task tries to run and fails ) : . <nl> while availabilitygroup should never",0.9170952439308167
confluentinc_ksql/7157,"clean up descriptions <cm-sep> more cleanup <para-sep> even though all migrations commands implement basecommand , the help command does not so we infer the type as runnable instead <nl> checkstyle_rules.off : npathcomplexity checkstyle_rules.on : npathcomplexity <nl> format initial divider <nl> format header row format trailing divider","various fixes and improvements to the migrations tool : <nl> - basecommand now implements runnable , so works again <nl> - various command description cleanup and improved log messages <nl> - dry-run option moved from basecommand to applymigrationcommand since that 's the only command for which it makes sense <nl> - do n't print migrationsconfig contents on each command since that 's too spammy <nl> - fix execution time to not always print zero due to integer division <nl> - now fails if a config file already exists <nl> - add extra divider on table output for improved readability .",1614846190,note : blocked this needs an enhancement to qtt historic thingy for tests to pass : ' ( . <nl> one of the regex 's in the test framework was stopping tests from testing internal topics . this is now fixed + enhanced one test to include internal topics .,0.927631139755249
Alluxio_alluxio/12899,fix journal error message when rpcs are cancelled <para-sep> note that we can not actually cancel the journal flush because it could be partially written already,"when a rpc is cancelled , we interrupt inodesyncstreams that are doing the sync , which might interrupt journal writes in progress . <nl> before this change , this would produce a rather alarming journal writes failed message , now we show journal writes interrupted instead .",1614016852,some throws ioe exception when unable to read instead of returning 0 . <nl> this test consider the object store eventual consistency and allow retry when fail to read .,0.8600989580154419
neo4j_neo4j/11802,"avid using finalization in graballocator . switch to use cleaner instead . <nl> update grabs to be cleaned using cleaner . <nl> add possibility to close page list . <nl> small renaming in page cache tests . <para-sep> the amount of memory , in bytes , to grab in each grab . <nl> this is a huge allocation . put it in its own grab and keep any existing grab at the head . <nl> this can only happen if our nmare somehow already has a cause initialised , which should not be the case , but it could if the jdk decided to inject a default cause in some future version . to avoid loosing the ability to trace this cause back , we 'll add it as a suppressed exception instead . <nl> okay , we tried . <nl> a memoryallocator is simple : it only allocates memory , until it is closed and frees it all in one go . <nl> close all allocated resources and free all allocated memory . closing can happen by calling close explicitly or by gc as soon as allocator will become phantom reachable . it 's up to implementations to guarantee correctness in scenario when multiple attempts will be made to release allocator resources . as soon as allocated resources will be cleaned any code that will try to access previously available memory will not gon na be able to do so .",update grabs to be cleaned using cleaner . <nl> add possibility to close page list . <nl> small renaming in page cache tests .,1526559416,"the lifecycle of the streamtodisk and the resources it opens , such as pagedfiles and pagedwritablebytechannels , are managed separately from the threads that are writing file contents through it . <nl> previously , the streamtodisk implementation was oblivious to this concurrency , and would freely allow the write threads to race with the closing of the streamtodisk instance . <nl> this could ultimately lead to write page cursors leaking , as in , not being closed when the streamtodisk instance was closed . <nl> when a write page cursor was leaked , it would cause a page in the",0.9662876129150391
runelite_runelite/13489,idle notifier : add support for the imcando hammer,this is the new fancy wieldable hammer from the ruins of camdozaal,1618500823,* new final int for : <nl> * add case for idle notification 's animationchanged method .,0.9294338822364807
elastic_elasticsearch/73840,"runtimefield.builder should not extend fieldmapper.builder <para-sep> parse the field value from an object <nl> the parameter is unknown , but this mapping is from a dynamic template . until 0.x it was possible to use unknown parameters there , so for bwc we need to ignore it","runtimefield.builder currently extends fieldmapper.builder so that it can <nl> share some parsing code and re-use the parameter infrastructure . however , <nl> this also means that we have to have a number of no-op method implementations , <nl> and in addition this will make it complicated to add a parameter within <nl> multi-keyed object field types . this commit removes the class relationship <nl> between these two classes .",1623074118,this converts the three parent-join mapper implementations to parametrized <nl> form ; metajoinfieldmapper and parentidfieldmapper have no builders or <nl> merging logic as they are always created directly by the parentjoinfieldmapper .,0.9675872921943665
neo4j_neo4j/11841,disable tracking of cpu time and memory allocation by default . <nl> tracking of cpu time and memory allocations are expensive operations <nl> and since most users will never need this information before they start <nl> investigations of any sort we will disable keep settings disabled by default,tracking of cpu time and memory allocations are expensive operations <nl> and since most users will never need this information before they start <nl> investigations of any sort we will disable keep settings disabled by default,1527065607,"we now refresh our local view of topology on topology change , <nl> when asked , we now return that view .",0.8553133010864258
apache_druid/11083,fix cast being ignored when aggregating on strings after cast <para-sep> the returned expression can keep an explicit cast from strings to numbers when the column consumed by the expression is the string type .,"currently , is ignored in the query plan when you use certain aggregators on string columns after case . taking a query , , as a example , druid creates a query plan like below . <nl> as a result , this query always returns because strings can not be casted to numbers implicitly . this pr fixes this issue by keeping when it casts from string to a number . <nl> this pr additionally fixes npe in when the input column has nulls . finally , some sqlaggregator tests are refactored to use help functions in",1617917786,"this pr introduces which allows the router to perform query serde but without having to load lookups as happens using the stock with default settings . to achieve this , an interface has been extracted from , the very java named , which is now used everywhere was previously used , _except_ for . i think this is a bit nicer , because now all query processing stuff no longer has obvious access to methods to load and drop lookups , only the method to get the needed to do the transforms . additionally , this has allowed many of",0.9705830812454224
confluentinc_ksql/7569,filter by query status <cm-sep> remove kafka version pin <cm-sep> tom 's fixes for noclassdeffound <cm-sep> update expected test results fortable rowtime fixes <cm-sep> disable stream-stream join improvements <para-sep> disable for now until grace period is made configurable <nl> required filter else querymetadata.getallmetadata ( ) throws <nl> when : <nl> then :,as the title says . <nl> build passes .,1621619008,error message is no longer : . <nl> it is now : . <nl> usual .,0.9655969738960266
apache_druid/11333,"suppress spelling check <cm-sep> mb -- > mib , kb -- > kib <cm-sep> use iec binary prefix <para-sep> updating metadata store can fail if the serialized <nl> so we estimate about 1kib to work around available == 0 bug in gzipinputstream <nl> maximal size of store in gib , if store is larger entries will start expiring <nl> write 4kib of ints and expect the write operation of the file channel will be triggered only once . no need to flush up to 4kib the first byte after 4kib will cause a flush","in that pr , two different standard unit systems are supported : decimal format and binary format . <nl> the former one is a unit system based on powers of 0 ( also known as si format ) , while the latter one is based on powers of 0 ( also knowns as iec format ) . for example , 1kb = 0 bytes while 1kib = 0 bytes . <nl> but in old days , kb/mb/gb are also used to express values based on power of 0 , which causes ambiguities . if there 's an a word ,",1623034492,"while not all indexspec properties are explained , it does explain how roaring bitmaps can be turned on .",0.8575364947319031
elastic_elasticsearch/74169,"more logging on docker build failures . <nl> when compiling , if the configure step fails and a <nl> file exists , then dump it out before exiting to assist diagnosis .","alpine linux version is incompatible with older versions of docker , so pin the <nl> version that we use to version . at some point in the future , it will <nl> be possible to upgrade alpine . <nl> also when compiling , if the configure step fails and a <nl> file exists , then dump it out before exiting to assist diagnosis .",1623835259,unpacking transformation of azul packaged jdks have been broken due to <nl> a different packaging structure not handled correctly by the jdkdownloadplugin . <nl> this fixes this and also fixes the packaging of aarch64 jdks into elasticsearch with <nl> jdk distros,1.0
runelite_runelite/13376,change hs kc patterns to match values greater than 0,"this pr changes the capture groups for the the hallowed sepulchre kc patterns to match values that contain commas , and then strips those commas before invoking setkc .",1616471508,before : . <nl> after : .,0.8470127582550049
apache_kafka/10724,: remove deprecated methods under streamsmetrics . <nl> removal of methods already deprecated since version . <nl> adapt test to use the new alternative method . <para-sep> 0 meters and 0 non-meter metrics plus a common metric that keeps track of total registered metrics in metrics ( ) constructor,removal of methods already deprecated since version . <nl> adapt test to use the new alternative method .,1621415590,".. and remove bulk loading mechanism inside rocksdb . <nl> we need to validate in benchmarks that removing bulk loading would not incur large perf regression ; if yes , we should consider adding other optimizations like separate thread polls and parallel writes before merging this pr .",0.9494599103927612
vespa-engine_vespa/16997,cleanup <cm-sep> retire any kind of host on cloud maintenance event <para-sep> a maintenance event in a cloud service .,"we now support retiring/deprovisioning config hosts , so we no longer need to <nl> file tickets .",1615977642,second commit made it no longer non-functional only : p,0.969673752784729
apache_camel/5703,": adding new iam operations <cm-sep> : add comments to constant and model classes <para-sep> initialize and return a new iam client <nl> perform list users operation <nl> checking for valid exchange body containing user information . body must be an updateuseroption object or a json string <nl> check for user id , which is mandatory to update user <nl> invoke update user method and map return object to exchange body <nl> perform list groups operation <nl> invoke list groups method and map return object to exchange body <nl> perform get group users operation <nl> checking for valid exchange body containing group information . body must be an keystoneupdategroupoption object or a json string <nl> check for group id , which is mandatory to update a group <nl> invoke update group method and map return object to exchange body <nl> update dynamic client configurations . some endpoint parameters ( operation , user id , and group id ) can also be passed via exchange properties , so they can be updated between each transaction . since they can change , we must clear the previous transaction and update these parameters with their new values <nl> constants for properties set on the exchange object class to combine parameters which can be passed through exchange properties and endpoint parameters to avoid checking both each time they are used class containing authentication and secret keys if the user does not want to expose these in the endpoint <nl> the following test cases should be manually enabled to perform test against the actual huaweicloud iam server with real user credentials . <nl> add group options here . example : new keystoneupdategroupoption ( ) .withdescription ( ' description ' ) .withname ( ' name ' ) ; <nl> the following test cases should be manually enabled to perform test against the actual huaweicloud iam server with real user credentials . <nl> the following test cases should be manually enabled to perform test against the actual huaweicloud iam server with real user credentials . <nl> add user options here . example : new updateuseroption ( ) .withdescription ( ' description ' ) .withname ( ' name ' ) ; <nl> the following test cases should be manually enabled to perform test against the actual huaweicloud iam server with real user credentials . <nl> huawei cloud identity and access management ( iam ) ( camel-huaweicloud-iam ) huawei",adding new operations to the huawei cloud iam component : <nl> - update user <nl> - update group .,1623964928,"now i have this structure : <nl> camel-debezium-common <nl> camel-debezium-mysql . <nl> this is a pretty big pr , sorry for that but i think many of these changes are about moving files and renaming them .",0.9783241152763367
apache_druid/11265,do not stop retrying when an exception is encountered . save & propagate last exception if retry count is exceeded . <para-sep> just continue retrying if there is an exception ( it may be transient ! ) but save the last :,"the current class stops retrying if the provided lambda encounters an exception . this behavior causes false positives in some tests ( such as ) . after this pr it will continue retrying until the retry count is hit . in this case , it remembers and propagates the last exception . so if an exception is due to transient conditions then it may succeed and no false positive failure will be reported .",1621291034,"during archiving task runs , it is impossible to tell if the delete part of jets3t 's move workflow succeeded or failed . this adds in more noise in the log about the success/failure of that part of the task .",0.8659123182296753
Graylog2_graylog2-server/10815,"fix race condition in lookup data adapter and cache lifecycle . <nl> previously we have been using separate server.listener instances to <nl> update the live state of adapters and caches as well as counting down a <nl> latch to signal the startup code that all adapters and caches are ready . <nl> since the service listeners are not executed in any specific order , it <nl> could happen that we count down the latches before the services have <nl> actually finished starting . <nl> in that case the lookup table could n't bestarted because the adapters <nl> and caches could n't be found in the live state . <nl> this change fixes the race condition by updating the live state and <nl> counting down the latch in a synchronous way in a single listener <nl> instance . <cm-sep> refactor variable names in cachelistener","previously we have been using separate server.listener instances to <nl> update the live state of adapters and caches as well as counting down a <nl> latch to signal the startup code that all adapters and caches are ready . <nl> since the service listeners are not executed in any specific order , it <nl> could happen that we count down the latches before the services have <nl> actually finished starting . <nl> in that case the lookup table could n't bestarted because the adapters <nl> and caches could n't be found in the live state . <nl> this change fixes",1623263800,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.9600122570991516
elastic_elasticsearch/73570,worksish <para-sep> stops all further fetches of snapshotinfo since context is fail-fast <nl> translating both partial and success to success for now todo : add the differentiation on the metadata level in the next major release <nl> use current time to calculate overall runtime for in-progress snapshots that have endtime == 0 <nl> snapshot ids to fetch info for .,"this pr refactors the api for fetching to enabled implementations to optimize for bulk fetching multiple at once . this is a requirement for making use of a more efficient repository format that does not require loading individual blobs per snapshot to fetch a snapshot listing . also , by enabling consuming as they are fetched on the snapshot meta thread this allows for some more memory efficient usage of snapshot listing . <nl> also , this commit makes use of the new api to make the snapshot status api run a little more parallel if fetching multiple snapshots (",1622478568,this pr deprecates the usage of the id field in the payload for the <nl> invalidateapikey api .,0.9870496392250061
elastic_elasticsearch/74376,[ ml ] adding a boolean ' cleared ' field to notifications index . <nl> the ' cleared ' field will not be set by the backend . the mapping <nl> will exist so that the ui can set ' cleared : true ' for notifications <nl> that a user decides should no longer be displayed in the ui . the <nl> ui will treat ' false ' and ' not present ' identically for this field . <para-sep> creating a document in the .ml- index should cause .ml-annotations creating a document in the .ml- index would normally cause .ml-annotations,the ' cleared ' field will not be set by the backend . the mapping <nl> will exist so that the ui can set ' cleared : true ' for notifications <nl> that a user decides should no longer be displayed in the ui . the <nl> ui will treat ' false ' and ' not present ' identically for this field .,1624294565,renaming api before release . should be for uniformity with the other apis .,0.9114448428153992
apache_pulsar/10745,transaction admin api add synchronize method .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment : ( no ) .",1622426448,motivation <nl> support set maxunackmessagespersubscription on topic level . <nl> modifications <nl> support set/get/remove maxunackmessagespersubscription policy on topic level . <nl> verifying this change <nl> added unit test to verify set/get/remove maxunackmessagespersubscription policy at topic level work as expected when topic level policy is enabled/disabled . <nl> org.apache.pulsar.broker.admin.maxunackedmessagestest # testmaxunackedmessagesonsubscriptionapi <nl> org.apache.pulsar.broker.admin.maxunackedmessagestest # testmaxunackedmessagesonsubscription,0.971104085445404
apache_kafka/10922,: fix ssltransportlayertest.testunsupportedtlsversion with recent jdks . <nl> support for tls version and version was disabled in recent versions of java 0/0 <nl> and all versions of 0. re-enable it in this test so that we can verify <nl> the server behavior when it establishes connections with such tls <nl> versions .,"support for tls version/version was disabled in recent versions of java 0/0 <nl> and all versions of 0 causing this test to fail . <nl> it is possible to make it work by updating the relevant security property , <nl> but it has to be done before the affected classes are loaded and it can <nl> not be disabled after that . given the low value of the test , we remove <nl> it .",1624454571,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.8355243802070618
elastic_elasticsearch/74514,enroll node api does n't return a cluster name . <nl> during implementation we discovered that the clusters should not <nl> necessarily have a unique name and thus we do n't need to convey <nl> this information in the response of the enroll node api .,during implementation we discovered that the clusters should not <nl> necessarily have a unique name and thus we do n't need to convey <nl> this information in the response of the enroll node api .,1624474578,everywhere that pulls the searchanalyzer or searchquoteanalyzer from <nl> mapperservice can either instead pull an analyzer from the mappedfieldtype <nl> they are working with ( which will always have a valid analyzer set ) or can <nl> call mapperservice # getindexanalyzers ( ) # getdefaultsearchanalyzer if they <nl> need a default .,0.9464952945709229
elastic_elasticsearch/73245,use plugin canonical name for the 3rd party security plugin detection instead of rest wrapper canonical name .,use plugin canonical name for the 3rd party security plugin detection instead of rest wrapper canonical name .,1621433340,this pr fixes two bugs that can arise when _source is disabled and we fetch nested documents : <nl> * fix indexoutofboundsexception in nested with disabled _source . <nl> * fix nullpointerexception in nested with disabled _source . <nl> * add more tests for highlighting .,0.8284568786621094
crate_crate/11103,backport nodeversionallocationdecidertests from es . <cm-sep> allow allocation of shards on nodes with lower hotfix version . <nl> fixes the support for a complete ( rolling ) downgrade of a cluster <nl> to a version with same major.minor but different hotfix version . <para-sep> test downgrade to same major.minor but lower hotfix version,fixes the support for a complete ( rolling ) downgrade of a cluster <nl> to a version with same major.minor but different hotfix version .,1614936559,the two first commits are backported dependencies needed for the target commit .,0.8860506415367126
elastic_elasticsearch/73373,"[ ml ] reduce warning logging from get categories grok pattern creation . <nl> the grok pattern creator used within the get categories action <nl> works by looking at the examples for each category . sometimes <nl> these examples are truncated , and can not be used for grok pattern <nl> determination . previously when this happened we would log a warning , <nl> but that caused a feedback loop in the case where the elasticsearch <nl> logs themselves were being categorized : the warning messages would <nl> end up creating new categories in the elasticsearch log categorization , <nl> with very long examples that would be truncated , leading to the same <nl> problem occurring yet again . <nl> this change reduces the warning log to trace for truncated log <nl> messages , and also removes the example from the log message to <nl> shorten it .","the grok pattern creator used within the get categories action <nl> works by looking at the examples for each category . sometimes <nl> these examples are truncated , and can not be used for grok pattern <nl> determination . previously when this happened we would log a warning , <nl> but that caused a feedback loop in the case where the elasticsearch <nl> logs themselves were being categorized : the warning messages would <nl> end up creating new categories in the elasticsearch log categorization , <nl> with very long examples that would be truncated , leading to the same <nl>",1621955873,adding deprecation message if a rest wrapper implementing plugin presents .,0.8759771585464478
apache_kafka/10736,: increase session timeout to 0 seconds,"thanks . <nl> =============== <nl> increase session timeout to 0 secs to make the test reliable . <nl> i had a pr , to duplicate multiple tests and duplicate another tests to increase the session timeout to 0 seconds as comparison . after 0 runs , i found all 0 seconds tests passed , but the original 0 seconds session timeout failed sometimes . that 's why this pr to increase session timeout to 0 seconds is created . <nl> but , there 's also 0 more thing i noticed . not sure if it 's a bug or not",1621496874,"given that the tests do not create clusters larger than 0 , we do not gain much by creating 0 partitions for that topic . reducing it should slightly increase test startup and shutdown speed",0.8477020859718323
apache_beam/14749,"<para-sep> we can encode empty lists , just omit them .","go <nl> java <nl> python <nl> . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1620347488,this upgrades calcite and avatica to the latest release . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.8709283471107483
elastic_elasticsearch/73172,"introduce snapshot_meta threadpool for fetching repository metadata . <nl> adds new snapshot meta pool that is used to speed up the get snapshots api <nl> by making load in parallel . also use this pool to load <nl> . <nl> a follow-up to this would expand the use of this pool to the snapshot status <nl> api and make it run in parallel as well . <para-sep> then , look in the repository if there 's any matching snapshots left <nl> put snapshot info downloads into a task queue instead of pushing them all into the queue to not completely monopolize the snapshot meta pool for a single request <nl> anyway in this case",adds new snapshot meta pool that is used to speed up the get snapshots api <nl> by making load in parallel . also use this pool to load <nl> . <nl> a follow-up to this would expand the use of this pool to the snapshot status <nl> api and make it run in parallel as well .,1621268342,"wrapping a in a for deserialization is inefficient . <nl> this forces jackson to internally buffer ( i.e . copy ) all bytes from the <nl> before deserializing , adding overhead for copying the bytes and managing the buffers . <nl> this commit fixes a number of spots where is the most common type of <nl> to special case this type and parse it more efficiently . <nl> also improves parsing s to use the more efficient direct parsing apis instead of manually wrapping in a reader ( jackson will do this for long strings itself but will use a",0.9722068905830383
jenkinsci_jenkins/5216,restore a deprecated constructor with acegisecurity,"* restore , as deprecated , the old constructor based on acegisecurity authentication parameter in order to keep backward compatibility",1611922089,null pointer exception . instead we create a dummy launcher and return <nl> that if it is unable to get the slave node .,0.9024066925048828
elastic_elasticsearch/72848,"remove bootstrap.system_call_filter setting . <nl> this commit removes the bootstrap.system_call_filter setting , as <nl> starting in elasticsearch version we are going to require that system call <nl> filters be installed and that this is not user configurable . note that <nl> while we force bootstrap to attempt to install system call filters , we <nl> only enforce that they are installed via a bootstrap check in production <nl> environments . we can consider changing this behavior , but leave that for <nl> future consideration and thus a potential follow-up change . <para-sep> initialize native resources . <nl> try to install system call filters ; if they fail to install ; a bootstrap check will fail startup in production mode . todo : should we fail hard here if system call filters fail to install , or remain lenient in non-production environments ? <nl> bootstrap check that system call filters must have installed successfully . <nl> some tests need the ability to disable system call filters ( so they can fork other processes as part of test execution )","this commit removes the bootstrap.system_call_filter setting , as starting in elasticsearch version we are going to require that system call filters be installed and that this is not user configurable . note that while we force bootstrap to attempt to install system call filters , we only enforce that they are installed via a bootstrap check in production environments . we can consider changing this behavior , but leave that for future consideration and thus a potential follow-up change .",1620393868,"removed the autoscaling feature flags , autoscaling is now on by default <nl> ( though it requires an external system to handle the autoscaling <nl> events ) . added experimental notice to all autoscaling related <nl> documentation pages .",0.954346239566803
jenkinsci_jenkins/5357,"use assertthrows where possible <cm-sep> when only using junit assert 's static methods , import statically instead of extending <cm-sep> use junit assertions rather than assert keyword","some test cleanup , mainly eliminating usages of . such usages are prone to false negatives , since the test passes if _any_ statement throws an exception of the expected type ( not just the expected statement ) . junit version offers a safer and more legible alternative in the form of .",1615759070,"as usual , for the pr build…",0.9186453819274902
ballerina-platform_ballerina-lang/27316,add listener declaration completions when typedesc is not available <cm-sep> add completion support within the defaultable parameter context <cm-sep> fix duplicate type descriptor suggestions <cm-sep> fix xml subtype suggestions <cm-sep> sync with master <cm-sep> remove unused import <para-sep> else { cursor within the service servicedeclarationnode servicedeclrnode = ( servicedeclarationnode ) member ; } <nl> check whether the given symbol is a class symbol . <nl> get the type descriptor for the class symbol .,0. listener declaration completions when the type descriptor is not available <nl> 0. completion support within the default parameter context <nl> 0. fix xml subtype suggestions <nl> 0. remove duplicate type descriptor suggestions .,1606974092,"this pr brings slight changes to how trace logs are used following the introduction of the config api . now , to enable http trace logs , users need to set the flag . <nl> this also introduces log level configuring to ballerina user level logging through the config api . there are several aspects to this : log api config vs. package level configs and vs. dynamic parameters . <nl> if we consider dynamic parameters , log level can be set to the entire log api through the flag . to set the log level to a specific package",0.9769349694252014
apache_druid/11185,"fix bug with aggregator expressions on realtime index with string columns always producing 0 values <para-sep> if a type can not sanely convert into a primitive numeric value , then this method should always return true so that these primitive numeric getters are not called , since returning false is assumed to mean these values are valid . get the primtive integer value . <nl> must not be called unless array has a single element <nl> test casting arrays to scalars <nl> strings are still null <nl> arrays can still have nulls <nl> ca n't vectorize if expression","this pr adds a modification that fixes the side-effect of these transformations , to allow array typed to provide scalar values if and only if the array has a single element . otherwise it will retain its current behavior where methods like and return default zero values . this changes makes array expression results mirror the the behavior of scalar expression results , where scalar expressions are currently allowed to present themselves as single element arrays ( which exists to handle cases where array functions are used and the input value is a string column is multi-valued in one segment",1619759504,"double.nan , double.positive_infinity and double.negative_infinity are not real <nl> numbers . because of this , they can not be converted to bigdecimal and instead <nl> throw a numberformatexception . <nl> this change adds support for calculations that produce these numbers either <nl> for use in the function or the havingspecmetriccomparator by not <nl> attempting to convert the number to a bigdecimal . <nl> this pr changes the behavior to treat as , <nl> as and as <nl> . <nl> this behavior deviates from postrges which throws an exception",0.9499570727348328
elastic_elasticsearch/72876,extending parser regex patterns to take into account % appearing in the input .,"problem description <nl> a literal % is not correctly caught by the dissect processor in elasticsearch . see sample below . <nl> expected output would be : . <nl> actual output is : . <nl> implemented solution <nl> changed the regex that captures the tokens denoted by and the surrounding delimiters to lookahead and match on vs simply the first occurrence of . <nl> workarounds ( if any ) : <nl> at the moment , use of additional processors to replace the % in the log message with a supported character .",1620638725,the docs pattern url was using which means zero or many instead <nl> of which means zero or one . the pattern url returned in error <nl> messages was not in sync with the one in the docs .,0.8640614748001099
apache_druid/10880,"add druid jdbc handler config for minimum number of rows per frame <para-sep> a value of 0 supplied as input indicates that the client has no preference for fetch size , and can handle unlimited results ( at our discretion ) . <nl> overriding fetch allows us to track how many frames are processed after the first frame , and also fetch size <nl> use a prepared statement because avatica currently ignores fetchsize on the initial fetch of a statement <nl> set a fetch size below the minimum configured threshold <nl> expect minimum threshold to be used , which should be enough to do this all in first fetch","related , this config also serves as a sort of workaround to a missing feature ( or bug ? ) that pr seems to have lost momentum though , so i 'm going to try to see if i can pick it up and get that issue fixed . <nl> this configuration is still useful even if the avatica issue is resolved , because that fix allows jdbc users to give hints to the size of result sets that they would like , but this pr gives operators control to prevent very small fetch sizes with large result sets from",1613046487,"coordinator loadstatus api full format does not consider broadcast rules . <nl> coordinator loadstatus api full format does not consider broadcast rules . currently , this api only consider the normal load rules and does not return counts of segments that should be loaded under the broadcast rules . this apply to both the coordinator loadstatus ( /druid/coordinator/v1/loadstatus ? full ) and the new datasource loadstatus ( /druid/coordinator/v1/datasources/ { datasource } /loadstatus ? full ) since they share the same code path",0.9613919258117676
elastic_elasticsearch/72928,use hamcrest for matchassertion . <nl> ever since i wrote i 've thought to myself <nl> ' if this were a hamcrest matcher we could use it everywhere and get <nl> nicer error messages . ' a few weeks ago i finally built a work-alike <nl> hamcrest matcher that i think produces better error messages . this plugs <nl> that matcher into the used by our yaml and docs tests .,ever since i wrote i 've thought to myself <nl> ' if this were a hamcrest matcher we could use it everywhere and get <nl> nicer error messages . ' a few weeks ago i finally built a work-alike <nl> hamcrest matcher that i think produces better error messages . this plugs <nl> that matcher into the used by our yaml and docs tests .,1620740557,"this change adds a method that will check any def reference when accessed for null . if the def reference is null it throws a more descriptive error message with the name of the method/field that is accessed . <nl> for the megamorphic cache , we use the as the filter instead of just when looking up if we need to compute a new methodhandle for a changed type .",0.8991581797599792
apache_incubator-pinot/6391,"added h3indexfilteroperator <cm-sep> updates <para-sep> todo : handle composite function that contains st_distance <nl> find the number of rings based on distance for full match use the edge of the hexagon to determine the rings are within the distance . this is calculated by ( 0 ) divide the distance by edge length of the solution to get the number of contained rings ( 0 ) use the ( floor of number - 0 ) for fetching the rings since ring0 is the original hexagon <nl> partial matchedrings use the previous number + 0 to get the partial ring , which is the ceiling of the number <nl> todo : support lower bound <nl> todo : handle nested geography/geometry conversion functions",updated the h3indexfilter operator with the correct algorithm . also fixed the schema and corrupted data in the quickstart example . <nl> example : .,1609225168,"splitting all the tasks of the validationmanager into separate controllerperiodictasks , so that we can better control the frequency of each one : . <nl> offlinesegmentintervalchecker - to check for missing offline segments , can run daily by default <nl> realtimesegmentvalidationmanager - to fix partitions which have stopped consuming , can run hourly by default . can be configured at the controller level to match realtime sla of the cluster <nl> brokerresourcevalidationmanager - to update broker on instance set changes",0.9689328074455261
vespa-engine_vespa/17102,rewrite jax-rs resources in athenz-identity-provider-service as request handlers <cm-sep> move classes to single package root,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616428187,"rewrite and simplify to use slime and a regular handler instead of jersey , <nl> so it 's not necessary to manually update handler when config changes <nl> ( which had not been done in years )",0.9719709157943726
apache_druid/11169,"fix npe involving certain set types . <nl> normally , indimfilters that come from json have hashsets for ' values ' . <nl> some set types , like treesets with natural <nl> ordering , will throw npe on ' contains ( null ) ' , which causes the <nl> indimfilter 's valuematcher to throw npe if it encounters a null value . <nl> this patch adds code to detect if the values set can support <nl> contains ( null ) , and if not , wrap that in a null-checking lambda . <nl> also included : . <nl> - remove unneeded nullhandling.needsemptytonull method . <nl> - update indexedtablejoinable to generate a treeset that does not <nl> require lambda-wrapping . ( this particular treeset is how i noticed <nl> the bug in the first place . ) <para-sep> creates a new filter . <nl> avoid copying ' values ' when it is already in the order we need for cache key computation . <nl> useful for detecting if a sorted set is in natural order or not . may return false negatives ( i.e . there are naturally-ordered comparators that will return false here ) . <nl> check to see if values.contains ( null ) will throw a nullpointerexception . jackson json deserialization wo n't lead to this ( it will create a hashset , which can accept nulls ) . but when indimfilters are created programmatically as a result of optimizations like rewriting inner joins as filters , the passed-in set may not be able to accept nulls . we do n't want to copy the sets ( since they may be large ) so instead we 'll wrap it in a null-checking lambda if needed . <nl> noinspection resultofmethodcallignored <nl> safe to do values.contains ( null ) . <nl> fall through <nl> not safe to do values.contains ( null ) ; must return a wrapper . return false for null , since an exception means the set can not accept null ( and therefore does not include it ) . <nl> note : we are using comparators.naturalnullsfirst ( ) because it prevents the need for lambda-wrapping in indimfilter 's ' createstringpredicate ' method . <nl> regression test for nullpointerexception caused by programmatically-generated indimfilters that use treesets with natural comparators . these sets throw nullpointerexception on contains ( null ) . indimfilter wraps these contains methods in null-checking lambdas .","normally , indimfilters that come from json have hashsets for ' values ' . <nl> some set types , like treesets with natural <nl> ordering , will throw npe on ' contains ( null ) ' , which causes the <nl> indimfilter 's valuematcher to throw npe if it encounters a null value . <nl> this patch adds code to detect if the values set can support <nl> contains ( null ) , and if not , wrap that in a null-checking lambda . <nl> also included : . <nl> - remove unneeded nullhandling.needsemptytonull method . <nl> - update indexedtablejoinable",1619543393,"column of was incorrectly reported for some case . it happened because the in was overwritten in when the segment had more than one replica . this pr fixes : <nl> * segmentmetadatainfo update in <nl> * add to builder 's constructor , so it 's not overwritten <nl> * rename to <nl> * replace with for num_replica",0.9562179446220398
apache_pulsar/10725,transaction admin api get coordinator internal stats . <cm-sep> fix some code style <cm-sep> fix code style <cm-sep> fix some comment <cm-sep> fix some comment <cm-sep> fix some test <cm-sep> fix some test <cm-sep> update pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/transactions.java . <cm-sep> fix some codestyle <cm-sep> fix some comment <cm-sep> transaction admin api get pending ack internal stats <para-sep> get pending ack internal stats . <nl> get pending ack internal stats . <nl> transaction pending ack internal stats . <nl> the transaction pending ack log stats * /,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment : ( no ) .",1622105103,"currently we do n't have a way to unset offload policies for namespaces , we may need one . <nl> add a rest api . <nl> ( please pick either of the following options ) . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> ( or ) . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> ( or ) . <nl> this change added tests and can be verified as follows : . <nl> ( example : ) <nl> - added",0.9821946024894714
ballerina-platform_ballerina-lang/28597,move datamapper function generation to vscode side <cm-sep> fix check style failures <cm-sep> support function generation for multi-module projects <cm-sep> modify unit tests <cm-sep> restrict mapping for non-record types <para-sep> to handle the multi-module projects,data mapper code action is restricted for variables which are not record types .,1613055457,> add package level test cases .,0.9301102161407471
netty_netty/11385,skip the windows tests when there is an entry for localhost in the hosts file . <nl> motivation : . <nl> the tests must be executed only when there is no hosts file or <nl> there is no entry for localhost in the hosts file . the tested functionality <nl> is relevant only in these use cases . <nl> modifications : . <nl> skip the windows tests when there is an entry for localhost in the hosts file . <nl> result : .,motivation : . <nl> the tests must be executed only when there is no hosts file or <nl> there is no entry for localhost in the hosts file . the tested functionality <nl> is relevant only in these use cases . <nl> modifications : . <nl> skip the windows tests when there is an entry for localhost in the hosts file . <nl> result : .,1623408351,correctly propagate failures while update the flow-controller to the multiplexed channel . <nl> motivation : . <nl> we may fail to update the flow-controller and in this case need to notify the stream channel and close it . <nl> modifications : . <nl> attach a future to the write of the update frame and in case of a failure propagate it to the channel and close it . <nl> result : .,0.9171459674835205
elastic_elasticsearch/74132,fix mapping error to indicate values field,the error message erroneously mentions the field being out of order . it should instead mention the field,1623766871,- jcenter has been deprecated in gradle version milestone 0 <nl> - jcenter was announced to be sunset by jfrog <nl> - use gradle plugin portal as maven repository for build dependencies <nl> - use mavencentral as general replacement for jcenter .,1.0
vespa-engine_vespa/18104,only generate ' canonical hostname ' if reverse-lookup yields a mismatch <cm-sep> only require the warning we actually want to check,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622724391,"this fixes . <nl> most of this code is to generate a helpful error message by printing ( the start of ) of the offending document . <nl> also removed a case where could be : i 'm not quite sure how this is possible , as long as we find a document id , should be ?",0.9254672527313232
apache_shardingsphere/10913,move federate test to integration-test <cm-sep> add integration-test to other database <cm-sep> remove federate test <para-sep> get init sql file . <nl> check sql file exist .,changes proposed in this pull request : <nl> - move federate test to integration-test,1624357695,changes proposed in this pull request : <nl> - sharding-jdbc querying support postgresql array type,0.9433261752128601
elastic_elasticsearch/72931,"identify cancelled tasks in list tasks api . <nl> this commit adds a flag to each cancellable task in the <nl> response to the list tasks api , allowing users to see that a task has <nl> been properly cancelled and will complete as soon as possible . <para-sep> returns true if the task supports cancellation and has been cancelled <nl> do n't record this on entries in the tasks index , since we ca n't add this field to the mapping dynamically and it 's not important for completed tasks anyway <nl> if not cancellable then mutate cancellable flag but leave cancelled flag unset if cancelled then mutate cancelled flag but leave cancellable flag set if cancellable but not cancelled then mutate exactly one of the flags cancellable | cancelled | random | cancellable == cancelled | isnowcancellable | isnowcancelled false | false | - | true | true | false true | true | - | true | true | false true | false | false | false | false | false true | false | true | false | true | true","this commit adds a flag to each cancellable task in the <nl> response to the list tasks api , allowing users to see that a task has <nl> been properly cancelled and will complete as soon as possible .",1620742305,changes the backing index naming scheme for data streams from : . <nl> to . <nl> where is the date on which the backing index was created .,0.9686537384986877
apache_camel/5661,": fix rabbitmq connection leak <cm-sep> : add rabbitmq consumer option to disable recovery from exception during declaration of exchanges/queues <para-sep> decides whether an exception during declaration of exchanges or queues is recoverable or not . if the option is false , camel will throw an exception when starting the consumer , which will interrupt application startup ( e.g . in the case when the exchange / queue is already declared in rabbitmq and has incompatible configuration ) . if set to true , the consumer will try to reconnect periodically . <nl> decides whether an exception during declaration of exchanges or queues is recoverable or not . if the option is false , camel will throw an exception when starting the consumer , which will interrupt application startup ( e.g . in the case when the exchange / queue is already declared in rabbitmq and has incompatible configuration ) . if set to true , the consumer will try to reconnect periodically . <nl> decides whether an exception during declaration of exchanges or queues is recoverable or not . if the option is false , camel will throw an exception when starting the consumer , which will interrupt application startup ( e.g . in the case when the exchange / queue is already declared in rabbitmq and has incompatible configuration ) . if set to true , the consumer will try to reconnect periodically . the option is a : & lt ; code & gt ; boolean & lt ; /code & gt ; type . default : false group : consumer <nl> decides whether an exception during declaration of exchanges or queues is recoverable or not . if the option is false , camel will throw an exception when starting the consumer , which will interrupt application startup ( e.g . in the case when the exchange / queue is already declared in rabbitmq and has incompatible configuration ) . if set to true , the consumer will try to reconnect periodically . the option is a : & lt ; code & gt ; boolean & lt ; /code & gt ; type . default : true group : consumer <nl> decides whether an exception during declaration of exchanges or queues is recoverable or not . if the option is false , camel will throw an exception when starting the consumer , which will interrupt application","fixes a connection leak - creating a new connection when another one is already open <nl> added a new option to disable recovery from an error during declaration ( declare=true ) of exchanges/queues - this kind of error ( e.g . trying to re-create an exchange with a different type ) is not recoverable , and it could be beneficial to just fail ( e.g . at an application startup )",1623605717,the key_shared subscription type was added in pulsar version as a beta feature . this pr is to add the capability to camel due to its potential usefulness . it 's already possible to set the pulsar message key through exchange headers .,0.9654340744018555
Alluxio_alluxio/13326,make runufsiotest run in a subdir <para-sep> create a subdir for the io,"the motivations is sometimes when the user runs this command , they expect alluxio to create a child dir in the so they just give a parent dir .",1619775226,- put more details to explain impersonation failure with a link to documentation on impersonation <nl> - fix a wrong url to,0.9227773547172546
grpc_grpc-java/7945,"example-tls : port to tls { channel , server } credentials . <nl> using the new credentials api allows using generic apis instead of <nl> netty-specific ones and allows using grpc-netty-shaded . the new api is <nl> still marked experimental , but it is intended to be stabilized which <nl> is n't the case for the netty-specific api . <nl> the client now looks more similar to helloworldclient . <para-sep> if only defaults are necessary , you can use tlschannelcredentials.create ( ) instead of interacting with the builder . <nl> fallthrough <nl> fallthrough <nl> only for using provided test certs . * / <nl> if only providing a private key , you can use tlsservercredentials.create ( ) instead of interacting with the builder .","using the new credentials api allows using generic apis instead of <nl> netty-specific ones and allows using grpc-netty-shaded . the new api is <nl> still marked experimental , but it is intended to be stabilized which <nl> is n't the case for the netty-specific api . <nl> the client now looks more similar to helloworldclient .",1614994137,refactor to reuse and the implementation in .,0.9488697052001953
confluentinc_ksql/7737,enable schema inference for timestamp/time/date <para-sep> make sure that regular int32/int64 fields do not get converted to date/time/timestamp,adds logic to the schema converter to convert date/time/timestamp to their logical types rather than just int/bigint .,1624911854,"the server response when describing a source schema now includes or to differentiate system columns , i.e . rowtime , and key columns from value column . <nl> old output : . <nl> new output : . <nl> the default is no field type . this design decision was taken as the pojo is used not just to describe the columns in the schema , but also fields in structs and a fieldtype of would n't make much sense for a struct field . where as no field type kind of works . <nl> note , if a column in",0.946514368057251
quarkusio_quarkus/17734,bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump aws-xray-recorder-sdk-aws-sdk-v2 from version to version . <cm-sep> bump flyway-core from version to version . <cm-sep> arc - document io.quarkus.arc.withcaching . <nl> ( cherry picked from commit sha ) <cm-sep> this is needed to remove a warning from sr rm . <nl> ( cherry picked from commit sha ) <cm-sep> capabilities are not persisted . <nl> ( cherry picked from commit sha ) <cm-sep> allow specifying per-port nodeport . <cm-sep> bump awssdk.version from version to version . <nl> bumps from version to version . <nl> updates from version to version . <cm-sep> bump aws-lambda-java-events from version to version . <cm-sep> fix generatedcode output dir . <nl> ( cherry picked from commit sha ) <cm-sep> test output does not always start . <nl> ( cherry picked from commit sha ) <cm-sep> grpc dev ui styling . <nl> ( cherry picked from commit sha ) <cm-sep> add artemis-mqtt-protocol dependency . <nl> ( cherry picked from commit sha ) <cm-sep> use version version in the generated projects . <cm-sep> always setup build time logging . <nl> ( cherry picked from commit sha ) <para-sep> this method should always return true producer # produceint ( ) is only called once <nl> this method should always return false producer # producelong ( ) is called twice per each pinglong ( ) invocation <nl> the nodeport to which this port should be mapped to . this only takes affect when the servicetype is set to node-port .,"please do n't merge , i will merge it myself .",1623081800,"please do n't merge , i will merge it myself .",0.9588276743888855
Alluxio_alluxio/13209,remove creation of breadcrumbs in the next level dir <para-sep> do not recreate the breadcrumb if it already exists,this pr prevents breadcrumbs from being recreated everytime we issue a liststatus request . <nl> the main idea is to check for breadcrumb 's existence before creating it and only create it when a directory is listed not when it is listed as a child of another directory .,1617998057,backup to root ufs by default and modify the docs,0.8847573399543762
vespa-engine_vespa/17193,add feature flag that can be used to disable omitstacktraceinfastthrow jvm option <para-sep> empty option if option not set in property,"add feature flag that can be used to disable omitstacktraceinfastthrow jvm option . <nl> a bit cumbersome code in , would have liked a tobooleanfunction to exist ...",1616745885,"why ? <nl> 0 ) too many redeploys are unecessary and have a cost <nl> 0 ) if restartondeploy is turned on , we may end up not able to <nl> respect it to make sure config is actually deployed if a periodic <nl> redeploy follows right after an application deploy .",0.9750687479972839
apache_incubator-pinot/6359,"add more files/dirs that appeared after top-level build & mvn eclipse <cm-sep> fix dropping of authority & other pre-path elements from input uri <cm-sep> fix up header for new test file <para-sep> confirm output path generation works with uris that have authority/userinfo . <nl> typical file uri <nl> namenode as authority , plus non-standard port <nl> s3 bucket + path <nl> s3 uri with userinfo ( username/password )","support for in job file that uses authority ( hdfs namenode , for example ) . <nl> i had done a complete build ( including top-level ) prior to this patch , and wound up with two artifacts ( and ) that were being treated as new files , so i excluded them via a change to , do n't know if that should have a separate pr . <nl> also the sub-project did n't have any unit tests previously , not sure if i configured things properly ( i use not ) , so looking for input , thanks",1608078809,implement the query method in anomalyfuncitondao for future application summary and evaluation .,0.9221750497817993
confluentinc_ksql/7511,"disallow fk joins in n-way joins <para-sep> checkstyle_rules.off : cyclomaticcomplexity checkstyle_rules.on : cyclomaticcomplexity <nl> after we lift this n-way join restriction , we should be able to support fk-joins at any level in the join tree , even after we add right-deep/bushy join tree support , because a fk-join output table has the same pk as its left input table","three minor changes in this pr : <nl> - disallows foreign key joins in n-way joins , for this first iteration of fk joins . note that it 's fine if a chain of n-way joins starts with an fk join ( as processed from left to right ) , but not if an fk join is encountered later on in the chain . <nl> - adds versions of the existing fk joins tests ( all negative test cases , as the functionality is not yet complete ) with the feature flag enabled <nl> - updates the existing negative test",1620845980,enhance join and group-by tests to cover the values stored in internal topics . thereby hopefully catching any non-backwards compatible changes to the schema/data stored in these intermediate topics . <nl> note : you may notice that the key within the internal topics in the tests are a bit funky . this is because they are the internal of kafka streams .,0.7882565855979919
ballerina-platform_ballerina-lang/28329,add dotted string support <cm-sep> quoted string change <cm-sep> modify table and array impl,"removes deprecated status from class . contains breaking changes to class . afaik only code to cloud uses this class for now , i 'll be updating that code once this is merged . <nl> earlier toml parser api followed query chaining approach instead . the main issue with approach is if you get npe in the middle of the chain it becomes really hard to capture it . the reason for going for this chaining method was quoted string keys in toml spec . <nl> however , with this pr , quoted string keys will be treated differently from",1612162650,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9753457307815552
jenkinsci_jenkins/5522,"fix , , and error prone violations in tests","fixes violations of the , , and error prone checks in tests , mostly by using . <nl> n/a . <nl> n/a . <nl> before the changes are marked as : .",1621826204,i replaced some try finally blocks with try with resources . <nl> * n/a .,0.9282205104827881
grpc_grpc-java/7885,add mtls and trust/keymanager credentials api,it feels great cleaning up the test code .,1612917346,"guava 0 introduced some overloading optimizations for preconditions <nl> that require using guava 0+ at runtime . unfortunately , guava 0 removes <nl> some things that is causing incompatibilities with other libraries , like <nl> cassandra . while the incompatibility did trigger some of those libraries <nl> to improve compatibility for newer guavas , we 'd like to give the <nl> community more time to work through it . <nl> at this commit , we appear to be compatible with guava 0+ . it 's not <nl> clear if we want to actually ' support ' 0 , but it",0.8206217885017395
apache_kafka/10421,remove deprecated apis <cm-sep> remove related unit tests <cm-sep> minor fix,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1616896960,"previously , we depicted creating a jackson serde for every pojo class , which becomes <nl> a burden in practice . there are many ways to avoid this and just have a single serde , <nl> so we 've decided to model this design choice instead .",0.9561742544174194
Graylog2_graylog2-server/10889,parse new error messages for ingestion error during flood stage as retriable . <cm-sep> bumping es version for integration tests . <cm-sep> adjusting to changed error message for missing alias target .,"between es version and version , the error messages returned by the server for these case : . <nl> - a message can not be ingested to an index because the index/cluster is in flood stage <nl> - a message can not be ingested to an alias , because the alias is missing a target . <nl> have changed . therefore our error checking code does not identify these cases as being retriable , resulting in message loss . <nl> this pr addresses these cases and adds the changed error messages in addition to the previous ones in order to",1624009884,"this change introduces the new boolean configuration option , which allows the user to enable/disable the compression of requests going to the indexer ( elasticsearch ) nodes . this helps to significantly reduce the traffic sent over the wire , especially for bulk indexing requests .",0.8901805281639099
grpc_grpc-java/7870,"implement fault injection interceptor in xdsnameresolver <para-sep> a call that queues requests before a real call is ready to be delegated to . <nl> managedchannelimpl.configselectingclientcall always provides calloptions with a callexecutor . <nl> a forwarding client call that counts active fault injections . <nl> * / <nl> * / <nl> special cases for hiding headers : ' grpc-previous-rpc-attempts ' . <nl> special case for exposing headers : ' content-type ' . <nl> header abort , header abort rate = 0 % <nl> no header abort key provided in metadata , rpc should succeed <nl> header abort http status key provided , rpc should fail <nl> header abort grpc status key provided , rpc should fail <nl> header abort , both http and grpc code keys provided , rpc should fail with http code <nl> header abort , no header rate , fix rate = 0 % <nl> header abort , no header rate , fix rate = 0 <nl> fixed abort , fix rate = 0 % <nl> fixed abort , fix rate = 0 % <nl> header delay , header delay rate = 0 % <nl> no header delay key provided in metadata , rpc should succeed immediately <nl> header delay key provided , rpc should be delayed <nl> header delay , no header rate , fix rate = 0 % <nl> header delay , no header rate , fix rate = 0 <nl> fixed delay , fix rate = 0 % <nl> fixed delay , fix rate = 0 % <nl> cluster mismatch with fault config <nl> downstream node match <nl> downstream node mismatch <nl> downstream node absent in headers <nl> headers match <nl> headers mismatch <nl> headers absent <nl> maxactivefaults= * / 0 ) ; <nl> send two calls , then the first call should delayed and the second call should not be delayed because maxactivefaults is exceeded . <nl> once all calls are finished , new call should be delayed . <nl> virtualhost fault config override <nl> route fault config override <nl> weightedcluster fault config override <nl> route fault config override",reusing for injecting delay . made a hack in to propagate callexecutor .,1612543462,the grpclb client will use the backend addresses from resolver if it has not received any server list from any balancer after a certain timeout ( 10s ) .,0.9872344732284546
apache_incubator-pinot/6541,"- adding new validation for json , text indexing <nl> - adding semantic validation for indexing and field config <para-sep> range index semantic validation range index can be defined on numeric columns and any column with a dictionary <nl> var length dictionary semantic validation <nl> additional checks for text and fst index types <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected <nl> expected","- adding semantic validation for indexing and field config . <nl> this pr adds some missing config validation for range , varlength , json , text , fst indexing config . <nl> no <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no <nl> does this pr otherwise need attention when creating release notes ? <nl> no",1612392177,this pull request contains changes to diplay table name aliases . fix for broken heatmap due to setting inclusive end is also included .,0.9483349919319153
elastic_elasticsearch/72742,"fix 0 corner cases in test setup : unsigned_long not support as index sort , <nl> do not overlay a runtime field with index sort . <cm-sep> unmute <cm-sep> add reason <para-sep> random overlay of existing field , only if its not part of sorted fields","fix 0 corner cases in test setup : unsigned_long not support as index sort , do not overlay a runtime field with index sort .",1620205346,this gives the statements a bit more time ( increased to 0 seconds ) to allow <nl> for ilm to execute .,0.8979879021644592
apache_druid/10917,use the latest apache datasketches release version,"this is to bring the extensions-core/datasketches up to date with the latest post-graduation release of apache/datasketches-.version . <nl> there were some api changes in the datasketches library . in particular , tuple sketch classes were reorganized , and the arrayofdoublessketch now has one more level in the class name . the druid code was adjusted accordingly . no user observable behavior should be affected .",1614110691,"using druid with roaring is rather well tested by now , and in most cases i think it is going to provide a better out of the box experience , where the speed is generally worth the potential for larger segment sizes that come with high cardinalities . there will still exist cases of datasets with ultra high cardinality columns where concise might produce smaller segments due to the overhead of the roaring format , but it makes sense to me for the operator to opt into the decision of wanting the smallest possible segments at the potential cost of",0.7627607583999634
pentaho_pentaho-kettle/7924,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) <para-sep> fileobject.isreadable wrongly returns true in windows file system even if not readable <nl> fileobject.isreadable wrongly returns true in windows file system even if not readable,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) .,1617984176,adding new pdi client type ' other ' with a configurable client id,0.818500280380249
apache_pulsar/10061,move duplicate code to abstract parent class <para-sep> determine whether the number of consumers on the subscription reaches the threshold . <nl> use getdataifpresent from zk cache to make the call non-blocking and prevent deadlocks in addconsumer,# # # motivation <nl> move duplicate code to abstract parent class,1616910263,"integration test are basically just not working in apache ci . there are multiple reasons : . <nl> 0. pulsar_mem is set to very high ( ~2g ) . if we start more than 0 containers , it will quickly go up to ~12gb . <nl> 0. we start containers for each tests , which is very inefficient . <nl> 0. set pulsar_mem to use no more than 128m . <nl> 0. switch to use test suite , trying to start containers only once as possible and use them across test suites . <nl> so we only start the cluster",0.9481040239334106
apache_shardingsphere/10532,fix example error <para-sep> private static shardingtype shardingtype = shardingtype.readwrite_splitting ; private static shardingtype shardingtype = shardingtype.sharding_readwrite_splitting ; <nl> private static shardingtype shardingtype = shardingtype.readwrite_splitting ; private static shardingtype shardingtype = shardingtype.sharding_readwrite_splitting ; <nl> private static shardingtype shardingtype = shardingtype.readwrite_splitting ; private static shardingtype shardingtype = shardingtype.sharding_readwrite_splitting ; private static shardingtype shardingtype = shardingtype.readwrite_splitting ; private static shardingtype shardingtype = shardingtype.sharding_readwrite_splitting ;,changes proposed in this pull request : <nl> - fix example error,1622200405,changes proposed in this pull request : <nl> - fix the improper cases for mysql <nl> - fix the improper cases for pg <nl> - add more init sqls for mysql .,0.8159632682800293
hazelcast_hazelcast/18672,"add hazelcastbootstrap instance <para-sep> returns either a local hazelcast instance or a ' bootstrapped ' hazelcast client for a remote hazelcast cluster , depending on the context . the main goal of this factory method is to simplify submitting a jet job to a remote hazelcast cluster while also making it convenient to test on the local machine . when you submit a job to a hazelcast instance that runs locally in your jvm , it will have all the dependency classes available . the instance wo n't join any cluster . with these semantics in place it 's simple to write code that works both in your local development/testing environment ( using a local hazelcast instance ) and in production ( using the remote cluster ) . create a runnable jar ( e.g . the jar should include all dependencies required to run it ( except the hazelcast classes & mdash ; these are already available on the cluster classpath ) . adjust that file as needed . the same code will work if you run it directly from your ide . in this case it will create a local hazelcast instance for itself to run on . for example , you can write a class like this : public class customjetjob { public static void main ( string [ ] args ) { hazelcastinstance hz = hazelcast.bootstrappedinstance ( ) ; hz.getjet ( ) .newjob ( buildpipeline ( ) ) .join ( ) ; } public static pipeline buildpipeline ( ) { // ... } } <nl> a helper class that allows one to create a standalone runnable jar which contains all the code needed to submit a job to a running hazelcast cluster . the main issue with achieving this is that the jar must be attached as a resource to the job being submitted , so the hazelcast cluster will be able to load and use its classes . * / <nl> supplier should be set only once <nl> upcast args to object so it 's passed as a single array-typed argument <nl> the change of job statuses after the check above wo n't be a problem here . because they can not revert back to startup statuses . <nl> turn off all discovery to make sure node does n't join any existing cluster",this pr adds instance and static factory method for getting it . <nl> checklist : .,1620839679,"implementation of send/receive operators . <nl> the pr is pretty straightforward except for the following classes : <nl> 0 . - create executors and their mailboxes from plan nodes <nl> 0 . - submits batches to outboxes , tracking the pending stage <nl> 0 . - sends batches over the wire , performing selective row filtering ( we do not need it now but will use it for partitioned operators ) . <nl> note : current flow control is very simplistic . it is likely to be inefficient . however , we do not have the full infrastructure yet ,",0.9783340096473694
elastic_elasticsearch/73805,make geojson and wellknowntext methods static,"geojson and wellknowntext are utility classes to serialise / deserialise geojson and wkt respectively . in order to use them , we need to instantiate an object with the parameters that are used while reading a geometry . this change makes all methods on the utility class static and adds the need parameters for reading geometries as method parameters . <nl> in addition , geometryvalidators are classes that can work pretty well under singleton pattern . therefore we change as well standardvalidator and geographyvalidator to work under that pattern .",1622959338,this change delays the decoding of the indexed triangles to the tree writer so we do not need to do it up front . in addition it changes the tree writing classes to static methods .,0.9219050407409668
ballerina-platform_ballerina-lang/28650,"implement lsp client-side file-watcher for langserver <cm-sep> add tests for langserver file-watcher <para-sep> the file change notification is sent from the client to the server to signal changes to watched files . <nl> looping through a set to avoid duplicated file events <nl> returns true if file watcher enabled , false otherwise . <nl> mapping of source root to project instance .","this pr implements support for creation and deletion file change events for ballerina source files , toml files and changes to the modules directory .",1613415594,"ballerina supports the concept of fork-join as a built in functionality . users can spawn new workers ( threads ) and join the results of those workers in different manners . in the initial version , we support <nl> - join all of the forked workers or a list of forked workers <nl> - join any one of the forked workers . <nl> given below are samples of how to use fork-join with ballerina . <nl> once the above program is run , you will get the following result <nl> ` <nl> # # fork-join in resource <nl> the following",0.9792089462280273
elastic_elasticsearch/72644,make getsnapshotsaction cancellable . <nl> if this runs needlessly for large repositories ( especially in timeout/retry situations ) <nl> it 's a significant memory+cpu hit = > made it cancellable like we recently did for many <nl> other endpoints .,if this runs needlessly for large repositories ( especially in timeout/retry situations ) <nl> it 's a significant memory+cpu hit = > made it cancellable like we recently did for many <nl> other endpoints .,1620069215,"first step towards async search execution . at the moment we do n't try to cancel <nl> the underlying search requests , and just check if the task is canceled before <nl> performing network operation ( such as field caps and search ) .",0.9672217965126038
elastic_elasticsearch/72834,"deprecate bootstrap.system_call_filter . <nl> we are going to require system call filters . this commit is the first <nl> step in that journey , which is to deprecate the setting that allows <nl> disabling system call filters . <para-sep> details * + <nl> impact * +","we are going to require system call filters . this commit is the first step in that journey , which is to deprecate the setting that allows disabling system call filters .",1620335080,this setting was recently deprecated in favor of node.remote_cluster_client . this commit adds this setting to the deprecation info api .,0.9776262640953064
apache_pulsar/10347,fix concurrentmodificationexception when attempting to update local broker data,it is not enough to ensure the thread safety of every api in localbrokerdata . <nl> it is necessary to ensure the thread safety of multiple apis in localbrokerdata at the same time . <nl> so i added the lock to the two methods above .,1619203849,"- right now , broker does n't validate dynamic-configuration value before updating it to zookeeper . so , user may update configuration with typo . <nl> - also , broker should validate dynamic-config value while starting in order to avoid picking up invalid value . <nl> eg : if someone has dynamic-config present for in old release and .0 has changed the classname then broker startup should notify invalid config value . <nl> - do dynamic-config validation before updating it <nl> - validate dynamic-config value on broker startup <nl> right now , we just have validation on configuration . <nl>",0.9470920562744141
grpc_grpc-java/8154,inject a standalone context that is independent of application rpcs to grpclbloadbalancer for control plane rpcs . the control plane rpc should be independent and not impacted by the lifetime of context used for application rpcs . <cm-sep> add simple test coverage . <para-sep> simulates making rpcs within the context of an inbound rpc . <nl> the inbound rpc finishes and closes its context . the outbound rpc 's control plane rpc should not be impacted ( no retry ) .,"control plane rpcs are independent of application rpcs , they can stand for completely different lifetime . so the context for making application rpcs should not be propagated to control plane rpcs .",1620432172,the spec says users can specify a blacklist a method from binlogs by <nl> saying ' -package.service/method ' .,0.9288573861122131
vespa-engine_vespa/17762,create metric for nr of tenants on each plan <para-sep> calculate initial versions,"not sure if the metric name is great , so please advise",1620305832,setup a container running on the same host as logserver when <nl> using a dedicated host in hosted vespa . this container will be used <nl> for running a handler that can retrieve logs from logserver archive .,0.945635199546814
jenkinsci_jenkins/5190,fix slowness in file fingerprint creation,"when creating the external fingerprint storage , we moved from ' each fingerprint are responsible to create a file on the disk ' to a ' single and exclusive method is responsible to create the fingerprint file on the disk ' . <nl> however , when we are using the maven plugin and have a lot of maven modules on the controller , this creates a performance issue as a single fingerprint file is created at once and it creates a queue of objects , locked behind the method . <nl> due to the action of the method , i",1611137753,* fix nullpointerexception when getting a list of runs with a status threshold ( regression in version ),0.8238799571990967
apache_incubator-pinot/6172,adding a new server api for computing average off heap memory consumed <para-sep> get the last updated index,this number is useful for the caller to get an accurate idea of memory <nl> requirements ( and thus subsequent provisioning ) . <nl> no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no . <nl> does this pr otherwise need attention when creating release notes ? <nl> no,1603319669,"segmentstatuscheckerintegrationtest fails unpredictably , depending on if the table creation and segment pushes take too long , resulting in segmentstatuschecker running before the table is setup . <nl> adding a controllergauge to track number of tables processed in each controllerperiodictask ( reset in preprocess , set to gauge in postprocess ) . checking this metric in the integration test before beginning to test .",0.9557936787605286
apache_shardingsphere/10471,fix the bug 'exceeded the maximum number of open cursors ' <nl> issues :0,"fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - optimized code , extract statement statement = connection.createstatement ( ) ;",1621994022,changes proposed in this pull request : <nl> - close connection after heart beat detection complete .,0.8765630722045898
quarkusio_quarkus/16931,"runs continuations on vertx context . <nl> captures the vertx context from the resteasy endpoint to use it in the dispatcher . <nl> if the endpoint does n't use a vertx context , dispatches through the io dispatcher . <nl> adds specific classes for coroutines for future user customization , once exposed . <para-sep> application wide coroutine scope . should start and die with the rest of the application , along with child coroutines ( structured concurrency ) . this should be the main interception point to place user specific [ coroutinecontext.element ] objects . things like activity ids , logger context propagation , tracing , exception handlers , etc . <nl> dispatches the coroutine in a worker thread from vertx . <nl> context propagation for suspending functions is not enabled yet , will be handled later <nl> base interface implemented by the synthetic beans that represent suspending rest endpoints . <nl> factory for the that is already part of the cdi container <nl> intercepts method invocations to force an endpointinvoker . <nl> not pretty , but this seems to be a limitation of the current method scanning process the handlerchaincustomizer is called in a build step , but also at runtime to actually create the invocation handler classes like securitycontextoverridehandler also use this approach <nl> base interface implemented by the synthetic beans that represent rest endpoints .","when reasteasy reactive endpoints are delegated to the correct bean , it ensures the coroutine is dispatched in the same context that was processing the endpoint . <nl> if the endpoint has not a vertx context , it launches the coroutine in the io dispatcher .",1619858177,"* rework the emitter support <nl> * update the reactive messaging version and axle client version <nl> * update documentation ( , new axle method )",0.9514157772064209
ballerina-platform_ballerina-lang/30698,"update add docs executor to update existing docs <cm-sep> fix newline being added on update documentation <para-sep> an abstract class to perform add/update documentation operations to all the nodes . this will update the documentation if already exists , add otherwise . <nl> already documented nodes <nl> already documented","additionally , merged the functionality of and code actions via an abstract class .",1621514928,code will be generated as below . <nl> this also fixes the printing garbage values when instruction does n't have positions in bir emitter .,0.9640011191368103
confluentinc_ksql/7420,"long-running queries should n't block the main event loop <para-sep> these properties are set together to allow us to verify that we can handle push queries in the worker pool without blocking the event loop . <nl> when <nl> then <nl> this integration test is displaced from the rest-client package to make use of utilities that are not available there . <nl> these properties are set together to allow us to verify that we can handle push queries in the worker pool without blocking the event loop . <nl> we should be able to serve multiple pull queries at once , even though we only have one event-loop thread , because we have enough workers in the worker pool . <nl> close the outputstream on close of the http connection <nl> ignore - it might already be closed","this patch corrects this flaw . <nl> note that the newer http2 api did not have the bug , but the integration test for the older api does hang and time out without the fix in place .",1619118181,add some tests around running of historic tests case . <nl> usual .,0.9093890190124512
apache_pulsar/10162,fix transactionmetadata store recover timeout problem . <para-sep> no operation <nl> thrown when transaction buffer op over max pending numbers .,"it need to use + . <nl> 0. fix lose time out , the original logical will pop the useful transaction from the . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints",1617782616,unify serde and schema . allow serde/schema to be used when creating pulsarsink and pulsarsource .,0.9478878974914551
apache_shardingsphere/10856,support subquery aggregation and partial distinct aggregation <para-sep> judge whether contains join query or not . <nl> judge whether contains partial distinct aggregation .,"changes proposed in this pull request : <nl> - support subquery aggregation by calcite <nl> - support partial distinct aggregation when statement include multi aggregation by calcite <nl> - add test cases for statement , statement and statement",1623997454,changes proposed in this pull request : <nl> - dynamically update configurations of cluster <nl> - add unit tests .,0.9489620923995972
ballerina-platform_ballerina-lang/27362,fix resources <cm-sep> add redirect html,> - adds redirect links to api docs paths . <nl> fixes # .,1607343527,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9218951463699341
Alluxio_alluxio/12670,"disable authority check <para-sep> even if we choose to log the warning , check if the configuration host matches what the user passes . if not , throw an exception letting the user know they do n't match .","this change offers an option to make the alluxio client not throw an exception when the given alluxiouri is incorrect . rather , it finds the correct cluster address from the configuration and connects correctly . <nl> some client has some stale code invoking alluxio like this : . <nl> it 's very hard to dig all the client code and update them one by one . in the upgrade , the design intention is , the admin configures this on all nodes in the cluster , then the client code will not throw an error . <nl> this property",1608644122,"since the control path is tied to the channel , we can not close the channel ( commit blocks ) until the entire file is ready .",0.8750382661819458
apache_pulsar/10650,transaction admin api get transaction coordinator status . <cm-sep> fix some test <cm-sep> fix some comment <cm-sep> transaction admin api component in topic status . <para-sep> get transaction stats in buffer . <nl> get pending ack handle stats . <nl> get transaction metadatastore stats . <nl> get transaction metadatastore stats .,"this is transaction component status . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment",1621493568,"currently the rate limit between replication clusters is not able to control . <nl> in geo-replication , once a cluster is offline , and after a long time , if it comes back , it may get a lot of messages from other clusters , and may use all of the network bandwidth . <nl> this pr tries to provided a way to control the rate limit between cluster replications . add rate limit support for replicator between clusters . <nl> changes : <nl> - change dispatchratelimiter.java to support 0 kind type : topic , subscription , replicator . <nl>",0.9744530320167542
apache_incubator-pinot/6269,"[ te ] fix changing createdtime of anomalies <para-sep> ensure that the createdtime of anomalies is not changed <nl> ensure that the createdtime of anomalies is not changed <nl> first order anomalies from earliest starttime to latest order anomalies from earliest createdtime to latest , if starttime are the same","this pr is to fix a bug that the createdtime of anomalies is updated when new anomalies with earlier starttime is generated , which causes that the same anomalies get send out twice due to updated createdtime of anomalies . the fix is to merge new anomalies into existing anomalies if possible , regardless of its starttime .",1605578240,"- object serialization problem : sparkcontext , pinotfs can not be passing into the lambda function . <nl> - rewrite getfilename method for uri , new file ( uri ) only supports scheme <nl> - do n't always ask for plugins directory for spark function , as they are usually given by the classpath already . <nl> - update example spark ingestion spec to use hdfs",0.9287081360816956
elastic_elasticsearch/74671,"histogram aggregation on histogram field computes wrong doc_count values when _doc_count field is present . <nl> the root cause of the problem is correctly described here . <cm-sep> fix build issue after backport <para-sep> we have added the document already and we have incremented bucket doc_count by _doc_count times . to compensate for this , we should increment doc_count by ( count - _doc_count ) so that we have added it count times . <nl> add the _doc_dcount field",> histogram aggregation on histogram field computes wrong doc_count values when _doc_count field is present . <nl> > <nl> > the root cause of the problem is correctly described here,1624955534,today when upgrading from version.x or version.x version to version.x or later and <nl> if two data ( or more ) data streams exist that have a overlapping prefix and <nl> one data stream name ends with the a date suffix that matches with backing index <nl> date pattern ( uuuu.mm.dd ) then new upgraded nodes may refuse to join . essentially <nl> preventing upgrade of the cluster to continue . <nl> in this case the validation logic in confuses <nl> backing indices of one data stream as regular indices and thinks these indices <nl> collide with another data stream,0.9226683378219604
jenkinsci_jenkins/5465,no reason why or should not work with pipeline <para-sep> searches for builds which include changes by this user or which were triggered by this user .,"* displaying pipeline builds among user build history , and removing incorrect warning about view build history . <nl> before the changes are marked as : .",1620337323,"make sure that the crumb issuer is always set . <nl> > . <nl> > . <nl> > . <nl> configuration ui for some options in jenkins are not shown when there 's only one option . i decided against this approach here for two reasons : . <nl> * even with the default crumb issuer , there 's still the proxy compatibility setting . <nl> * the configuration disappearing altogether might worry experienced and security-conscious jenkins administrators . <nl> i decided to use the same approach to proxy compatibility as is currently used in the setup wizard , i.e",0.8718110918998718
apache_pulsar/10224,"fix transaction log recover sequenceid problem . <para-sep> store max sequenceid in managedledger properties , in order to recover transaction log .","cursor will ack the . <nl> 0. when the ledger have been deleted , store the max sequenceid in properties . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no",1618384680,"currently for all java functions ( and by extension all sources/sinks ) the file from bookkeeper is downloaded and stored as a jar . this means that the logic of figuring out whether a java function is nar or plain jar can not be based on the extension of the file . this pr tries to first interpret the file as nar and if that fails interprets it as jar . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9699147939682007
Alluxio_alluxio/13120,add create/write/mkdir/unlink/rename to stackfs <cm-sep> modify alluxio-fuse with -s option for running stackfs <cm-sep> implement write path in stackfs <para-sep> translate mode to posix file permissions . <nl> add owners permission <nl> add group permissions <nl> add others permissions <nl> todo ( lu ) is it needed to check if offset < byteswritten is the write guarantee to be sequential ? <nl> this should never be reached <nl> this should never be reached,support stackfs operations with alluxio-fuse script . <nl> support write related operations in stackfs .,1616629821,"this is the start of the fuse improvement work on this feature branch . <nl> pr includes these improvements : <nl> - inspect the fuse interactions with the common unix shell commands . improve the error code to indicate that file is written once in alluxio <nl> - upgrade jnr-fuse version <nl> - add mac support . relax checkings of the file open flag to fail late , because mac does not use the strictest mode to open files . <nl> - add user/group integration to support , ,",0.9628071784973145
ballerina-platform_ballerina-lang/27391,"disallow inclusion of readonly classes <cm-sep> fix inclusion with qualifiers <nl> with this change the referencing object should have the same isolated , service , and/or client qualifier ( s ) as the included type ( s ) . <cm-sep> fix object constructor expression with readonly reference <cm-sep> add tests <para-sep> objectone ; objecttwo ; <nl> objectone ; objecttwo ; <nl> foo ; bar ; <nl> foo ; baz ; qux ; <nl> objectone ; objecttwo ; <nl> objectone ; objecttwo ; <nl> foo ; bar ; baz ; qux ; <nl> foo ; bar ; baz ; qux ;","this pr fixes . <nl> - inclusion of object type descriptor with qualifiers . <nl> when object type inclusion is used with an object type descriptor with qualifiers ( , , and/or ) , it is now mandatory for the referencing object to also have these qualifiers . <nl> - fix inclusion with readonly classes . <nl> - object type descriptors can no longer use object type inclusion with classes <nl> - classes can use object type inclusion with classes only if the referencing classes themselves are <nl> - the type reference in an object constructor expression can refer to",1607457590,following scenario will work with this pr .,0.9561785459518433
ballerina-platform_ballerina-lang/31072,skip redeclared symbols from visible symbols <cm-sep> add overloaded version of visiblesymbols ( ) <cm-sep> fix symbol look up test for query exprs <cm-sep> add visible symbols test for the new overloaded visiblesymbols ( ) method <para-sep> lookup the visible symbols at the given location . this additionally takes a list of diagnostic states . these are used to determine whether to include variable symbols with varying diagnostic states .,this basically allows the user to tell the semantic api which var symbols should be dropped when returning the list of visible symbols .,1623254271,"this requirement is a common one in most syntax tree editing scenarios . <nl> while descending , i check for the node to be replaced and replace it with the given replacement . then the new tree nodes are created while ascending . <nl> the original tree will not be modified ; if the node to be replaced can not be found . this implementation does not traverse through the whole tree . that would be a very inefficient approach . it traverses through potential branches in which the node to be replaced can be found .",0.9695463180541992
vespa-engine_vespa/17178,reuse connections for https requests <cm-sep> extend connection log unit test to include multiple requests,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616675233,"up until now every lookup of a flag on zookeeperflagsource would hit zookeeper . <nl> flags are ideal for caching : changes seldom , little data , clients should handle <nl> short-lived inconsistencies at the time it is changed ( flag-flips must be reversible ) . <nl> this pr will make the backing flagsdbimpl cache the /flags/v1 zk directory and <nl> completes the optimization of configserverflagsource .",0.9175426959991455
vespa-engine_vespa/18338,export extra package used by metrics-proxy bundle <cm-sep> add back transitive dependency,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624272087,flag name up for discussion .,0.8000340461730957
ballerina-platform_ballerina-lang/28535,add annotations to bir type-defs <para-sep> skip annotation attachments for now,this change do change the bir . <nl> fixes # .,1612875244,- fixes error messages printing when the constraint is a union type .,0.8716318011283875
OpenAPITools_openapi-generator/9224,"update codegen config <cm-sep> add templates for go echo openapi-codegen <cm-sep> add the yaml config file ! <cm-sep> add goechoservercodegen.java . <nl> this is the first iteration , it works but probably needs a lot of improvements . <cm-sep> update codegen , adds some comments . <cm-sep> update goechoservercodegen.java <cm-sep> update goechoservercodegen.java <cm-sep> update goechoservercodegen.java and related yaml file <cm-sep> add the result of generate-samples.sh for ci purposes . <para-sep> ( generators/go-echo-server.md ) <nl> reserved words . override this with reserved words specific to your language <nl> data type <nl> added ' error ' as it 's used so frequently that it may as well be a keyword <nl> additional properties . these values can be passed to the templates and are available in models , apis , and supporting files <nl> supporting files . you can write single files for the generator with the entire object tree available . if the input file has a suffix of ` .mustache it will be processed by the template engine . otherwise , it will be copied <nl> { { nickname } } - { { { summary } } } <nl> container will hold all dependencies for your application . <nl> newcontainer returns an empty or an initialized container for your handlers . <nl> helloworld is a sample data structure to make sure each endpoint return something . <nl> todo : handle the error ! <nl> middleware <nl> { { nickname } } - { { { summary } } } <nl> start server <nl> list of { { { classname } } } <nl> { { classname } } - { { { description } } } { { /description } } <nl> { { { description } } } { { /description } } <nl> addpet - add a new pet to the store <nl> deletepet - deletes a pet <nl> findpetsbystatus - finds pets by status <nl> findpetsbytags - finds pets by tags <nl> getpetbyid - find pet by id <nl> updatepet - update an existing pet <nl> updatepetwithform - updates a pet in the store with form data <nl> uploadfile - uploads an image <nl> deleteorder - delete purchase order by id <nl> getinventory - returns pet inventories by status <nl> getorderbyid - find purchase order by id <nl> placeorder - place an order for a pet <nl> createuser - create user <nl> createuserswitharrayinput - creates list","this is the first draft for go-echo-server codegen for openapi-codegen . the purpose is that we are internally using go echo , and we needed to create this codegen . still , i thought that it might be worth sharing it with everyone . <nl> i 'm not a java guru , and i mostly used go-gin-codegen codes to build this new codegen , and it 's a bit opinionated . <nl> kindly let me know what needs to be done so we can merge this pr .",1617963234,"here is it now . <nl> is is based on the typescript fetch generator , so differs from the other javascript generators in code and architecture . <nl> simply adding flow annotations did n't work with the current js es6 code . <nl> the code is written in es6 with flow syntax . in order to use it as a library in your react app , it comes with a npm build script to transpile it into node.js and browser compatible es5 syntax with additional .js.flow for flow to use the types properly . <nl> steps to use this client",0.9789839386940002
elastic_elasticsearch/74489,refactor resactiontests to cover all rest methods . <nl> refactoring restgetactiontests and restgestsourceactiontests to remove <nl> duplicated code . previously the tests would fail if rest request was <nl> sent twice to restcontroller .,refactoring restgetactiontests and restgestsourceactiontests to remove <nl> duplicated code . previously the tests would fail if rest request was <nl> sent twice to restcontroller .,1624454559,"with the introduction of per-partition categorization the old <nl> logic for creating a job notification for categorization status <nl> ' warn ' does not work . however , the c++ code is already writing <nl> annotations for categorization status ' warn ' that take into <nl> account whether per-partition categorization is being used and <nl> which partition ( s ) the warnings relate to . therefore , this <nl> change alters the java results processor to create notifications <nl> based on the annotations the c++ writes . ( it is arguable that <nl> we do n't need both annotations and",0.9023827910423279
vespa-engine_vespa/17953,assign slobroks only on cluster controllers <cm-sep> simplify,you 've seen this before . now it can be merged .,1621878075,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9600991010665894
elastic_elasticsearch/74317,"this commit reworks them to instead use search and check what gets returned instead of checking what get mappings returns and doing a string comparison . <para-sep> the root is mapped dynamic : runtime hence there are no type conflicts <nl> obj.runtime is mapped dynamic : runtime hence there are no type conflicts <nl> the parent object has been mapped dynamic : true , hence the field gets indexed <nl> a doc with the same field but a different type causes a conflict",this commit reworks them to instead use search and check what gets returned instead of checking what get mappings returns and doing a string comparison .,1624028013,"there is no point in writing out snapshots that contain no data that can be restored <nl> whatsoever . it may have made sense to do so in the past when there was an snapshot <nl> step that wrote data to the repository that would 've other become unreferenced , but in the <nl> current day state machine without the step there is no point in doing so .",0.9400770664215088
apache_incubator-pinot/6655,kinesis implementation part 0 : rename partitionid to partitiongroupid <para-sep> update the partition group metadata based on the segment metadata,"as part of the kinesis connector work , we will be introducing the concept of partitiongroup , which represents a group of partitions that are part of a consuming segment . <nl> there will be 0 more prs for this : <nl> 0. interface changes for kinesis connector , while making sure kafka impl is unaffected <nl> 0. kinesis module .",1615229355,this pull request contains the changeset for anomaly_tasks and anomaly_jobs table,0.9581092596054077
apache_pulsar/10342,fix avroschematest on jdk11 <cm-sep> fix 0 other similar tests,"- when testing time fields at millisecond precision , use instead of . <nl> - on java 0 , has millisecond precision , but on java 0 , there is microsecond precision by default .",1619177477,move same hash functions for client and broker to common module .,0.8650979399681091
elastic_elasticsearch/74085,"add meta field to deprecation issue definition . <nl> this will allow components to add custom metadata to deprecation issues . <nl> this make extracting additional details about deprecations more robust , <nl> otherwise these details need to be parsed from the deprecation message field . <nl> adjusted the ml model snapshot deprecation to use custom metadata , and <nl> included the job id and snapshot id as custom metadata .","this will allow components to add custom metadata to deprecation issues . <nl> this make extracting additional details about deprecations more robust , <nl> otherwise these details need to be parsed from the deprecation message field . <nl> adjusted the ml model snapshot deprecation to use custom metadata , and <nl> included the job id and snapshot id as custom metadata .",1623686439,"this commit adds a new querystring parameter on the following apis : <nl> - index <nl> - update <nl> - bulk <nl> - create index <nl> - rollover . <nl> these apis now support a flag . this flag changes the preference <nl> creation to use either v2 index templates or v1 templates . this flag defaults to and will be <nl> changed to for version+ in subsequent work . <nl> additionally , setting this flag internally sets the index-level setting . <nl> this setting is used so that actions that automatically create a new index ( things like rollover",0.9711320996284485
confluentinc_ksql/7046,"refactor migrations commands to not call exit from within command <para-sep> all migrations commands must implement basecommand , so we are safe to assume that the type returned is cli","basecommand should handle returning the appropriate exit code after printing the execution time , rather than exiting from within the commands themselves . <nl> minor refactor , more thorough testing ( in general ) coming in a later pr .",1613760115,"we 've already removed and syntax , but the <nl> cli still reports if a topic is registered or not . let 's tidy this up . <nl> this pr removes the column from the command as there is not 'registered topic ' functionality any more .",0.8986558318138123
elastic_elasticsearch/73334,"[ ml ] adding new ks test pipeline aggregation <para-sep> notconsole <nl> test [ setup : correlate_latency ] <nl> neither the name of enthought nor the names of the scipy developers may <nl> mutably divides each element in by the value <nl> this extracts the bucket values as doubles from the passed aggregations . the gap policy is always <nl> utility class for holding an unboxed double value and the document count for a bucket <nl> k-s test alternative hypothesis to calculate <nl> 0 is chosen as that is ~ half of the typical number of cdf points ( 0 ) <nl> yes , this is ' magic ' but in testing it seems that sampling on exceptionally sparse data gives us unreliable statistics . todo bootstrap to support sparse data <nl> fast path , since our sample is the entire cdf space , do n't worry about multiple passes on sampling <nl> these arrays should typically already be sorted but , depending on the sampling methodology , they could be monotonically decreasing instead of increasing calling to capture this situation reliably <nl> the following sided approximation is the same as eq version from : j. l. hodges ' the significance probability of the smirnov two-sample test , ' arkiv för matematik , ark . mat . 0 ( 0 ) , 0-0 , ( 0 jan. 0 ) if calculating , simply use the built in ks-test in apache math . <nl> binarysearch gives no guarantees around duplicates <nl> a sampling methodology that provides cdf points that tend towards the upper values . meaning , more values are sampled from the upper range <nl> a sampling methodology that provides cdf points that tend towards the lower values . meaning , more values are sampled from the lower range <nl> a sampling methodology that provides cdf points that is uniformly sampled . meaning , all values are sampled equally <nl> first try to point to a non-existent agg <nl> now validate with a single bucket agg <nl> since these two distributions are the ' same ' ( both uniform ) assume that the p-value is greater than version <nl> its difficult to make sure things are super close in the sparser case as the sparser data is more ' uniform ' having error of version allows for this . but , the two values should be similar as the distributions","this adds a new pipeline aggregation for calculating kolmogorov–smirnov test for a given sample and buckets path . <nl> for now , the buckets path resolution needs to be . but , this may be relaxed in the future . <nl> it accepts a parameter that indicates the distribution of documents from some other pre-calculated sample . <nl> this particular version of the k-s test is two-sample , meaning , it calculates if the and the distribution of values in the buckets_path are taken from the same distribution . <nl> this in combination with the hypothesis alternatives ( , ,",1621872486,adds a new rate aggregation that can calculate a document rate for buckets <nl> of a date_histogram .,0.9833542108535767
elastic_elasticsearch/74412,"this commit adds two related changes : <nl> * ilm waitfordatatierstep <nl> * autoscaling frozen_existence decider . <nl> the first part ensures that we wait mounting an index until a node that <nl> can hold the index is available , avoiding a failed restore and red <nl> cluster state . this is in particular important for the frozen phase , but <nl> is done generically in the searchable snapshot action . <nl> the second part triggers on indices in the ilm frozen phase to scale the <nl> tier into existence by requiring a minimal amount of memory and storage . <para-sep> create an ignored snapshot to initialize the latest-n file . <nl> verify that searchablesnapshotaction uses waitfordatatierstep and that it waits . <nl> this decider looks at all indices and ensures a minimum capacity is available if any indices are in the frozen ilm phase , since that is designated for partially mounted indices/frozen tier only . effectively , this scales the tier into existence . this works in concert with the in ilm that ensures we wait for autoscaling to spin up the first frozen tier node . <nl> return true if this index is in the frozen phase , false if not controlled by ilm or not in frozen . <nl> deliberately do not parse out the entire to avoid the extra work involved since this method is used heavily by autoscaling .","this commit adds two related changes : <nl> * ilm waitfordatatierstep <nl> * autoscaling frozen_existence decider . <nl> the first part ensures that we wait mounting an index until a node that <nl> can hold the index is available , avoiding a failed restore and red <nl> cluster state . this is in particular important for the frozen phase , but <nl> is done generically in the searchable snapshot action . <nl> the second part triggers on indices in the ilm frozen phase to scale the <nl> tier into existence by requiring a minimal amount of memory and storage .",1624361477,"throttling nightly cleanup as much as we do has been over cautious . <nl> night cleanup should be more lenient in its throttling . we still <nl> keep the same batch size , but now the requests per second scale <nl> with the number of data nodes . if we have more than 0 data nodes , <nl> we do n't throttle at all . <nl> these numbers do seem magical ... maybe it is better to not throttle <nl> at all ...",0.9770764112472534
hazelcast_hazelcast/18703,"restrict renaming __key & this for kv connectors <para-sep> add the default or field as hidden , if not present in the field names",forbade renaming & for kv connectors . <nl> \+ couple of minor cleanups : <nl> - moved & from to . <nl> - moved from to .,1621340566,partition migrating flag should be always set & cleared on partition <nl> operation threads . during promotion commit flag was being set on generic <nl> operation thread . that was causing incorrect set/clear order .,0.955044686794281
elastic_elasticsearch/73013,"move security transport implementation into security module . <nl> the security transport currently still exists in x-pack core , even <nl> though the rest of security was split out when x-pack was split into <nl> modules . it appears this was due to some tests indirectly relying ( and <nl> not needing to ) rely on adding the netty4plugin . this commit moves the <nl> implementation , and the netty module copy that is made in x-pack , into <nl> the security module , which is what actually registers the transport <nl> implementation . <para-sep> needed for usage api cancellation test . todo : do this another way or at least isolate ! <nl> do n't attempt to parse ssl settings from the profile ; profiles need to be killed with fire <nl> just close and ignore - we are already stopped and just need to make sure we release all resources <nl> we create the socket based on the name given . do n't reverse dns <nl> for reading the system-wide configuration for the backlog of established sockets <nl> netty sets custom classloader for some of its internal threads","the security transport currently still exists in x-pack core , even <nl> though the rest of security was split out when x-pack was split into <nl> modules . it appears this was due to some tests indirectly relying ( and <nl> not needing to ) rely on adding the netty4plugin . this commit moves the <nl> implementation , and the netty module copy that is made in x-pack , into <nl> the security module , which is what actually registers the transport <nl> implementation .",1620849220,"instead of doing our own checks against rest status , shard counts , and shard failures , this commit changes all our extractor search requests to set . <nl> - scrolls are automatically cleared when a search failure occurs with set . <nl> - code error handling is simplified .",0.9467920064926147
apache_ignite/8971,"fix ducktape jmx_tools mbean pattern <cm-sep> simple pds compatibility test <cm-sep> linter fix <cm-sep> linter fix <para-sep> simple application that have 0 options . ' load ' - load some predefined data to cache . ' check ' - check if we have that predifined data in that cache . <nl> predefined test data . * / <nl> data model class , which instances used as cache entry values . <nl> * / <nl> * /","a simple test to check pds compatibility of different ignite versions . <nl> ignite versions ' from_version ' and ' to_version ' are set via test parameters . <nl> start ignite cluster version ' from_version ' with pds enabled <nl> start a client application that puts prepared data looks like <nl> user ( 0 , ' john connor ' ) <nl> user ( 0 , ' sarah connor ' ) <nl> user ( 0 , ' kyle reese ' ) <nl> stop cluster and client <nl> start ignite cluster version ' to_version ' without pds clearing <nl> start client that",1617630032,"* call was missing before . to simplify the logic , use with set to , so the stream handles socket disposal for us . <nl> * fix argument validation tests ( message has changed on .net core 0.x ) . <nl> * fix flakiness",0.9604662656784058
apache_druid/10942,"fix runtime error when indexedtablejoinmatcher matches long selector to unique string index . <nl> the issue arises when matching against a long selector on the left-hand side to a string <nl> typed index on the right-hand side , and when that index also returns true from arekeysunique . <nl> in this case , indexedtablejoinmatcher would generate a conditionmatcher that implements <nl> matchsinglerow by calling finduniquelong on the index . this is inappropriate because the index <nl> is actually string typed . the fix is to check the type of the index before deciding how to <nl> implement the conditionmatcher . <nl> the patch adds ' testmatchsinglerowtouniquestringindex ' to indexedtablejoinmatchertest , which <nl> explores this case . <para-sep> makes matchers for long-typed selectors against long-typed indexes . specialized to use finduniquelong when appropriate .","the issue arises when matching against a long selector on the left-hand side to a string <nl> typed index on the right-hand side , and when that index also returns true from arekeysunique . <nl> in this case , indexedtablejoinmatcher would generate a conditionmatcher that implements <nl> matchsinglerow by calling finduniquelong on the index . this is inappropriate because the index <nl> is actually string typed . the fix is to check the type of the index before deciding how to <nl> implement the conditionmatcher . <nl> the patch adds ' testmatchsinglerowtouniquestringindex ' to indexedtablejoinmatchertest , which <nl> explores this",1614798815,"when joining on index tables with string keys , caching the computation of row id to row numbers improves performance on the * benchmarks by about 0 % if the column cache is enabled an by about 0 % if the column cache is disabled",0.9348397254943848
confluentinc_ksql/7103,messing around with almog 's idea <cm-sep> refactor of lambda handling,"this new approach gets around this limitation by assigning types for the sqllambda directly from the lambdatype from the function.parameters ( ) list . we use the existing generic resolving code in order to determine the correct types for the lambda arguments and pass that in through the context as a list ( which we were doing previously . the core change is how this list gets generated ) . <nl> this is done by doing two passes over the functioncall arguments , the first pass , any lambda functions are treated as sqllambda which only has the num input",1614329335,"( previous releases created the command topic with default retention , which is likely to cause loss of command messages over time ) .",0.9874457716941833
elastic_elasticsearch/74343,avoid numerical errors during testing in vector tile factories <para-sep> check if we might have numerical error due to floating point arithmetic <nl> this is the typical case we need to guard from .,"there are currently two types of factories , one that uses map box vector tile library to generate vector tile features and a second one that it generates the features natively . in order to produce the same result in both libraries we need to make sure we do the computation using the same steps so there are no differences due to numerical errors .",1624263528,"this commit unmutes and fixes tests around some geolineaggregator edge <nl> cases . <nl> - mergedgeolines had a silly bug where it was accepting internalgeolines <nl> that were empty <nl> - ' complete ' is measured by the heap-mode of the bucketedsort , which is a problem <nl> since if the length of the data equals the max-size , then it is difficult to know <nl> whether any values were discarded . <nl> - geolinebucketsort had an array-resizing bug s/ > / > = .",0.9440473318099976
elastic_elasticsearch/74117,recycle buffers used for file-based recovery . <nl> adds a missing that prevents buffer recycling during <nl> recovery .,adds a missing that prevents buffer recycling during <nl> recovery .,1623756747,"check that the weight of a line centroid is bigger than 0. in case it is 0 , the centroid is calculated as if the line is a point .",0.912984311580658
Alluxio_alluxio/12777,"add initial replay logics in ufs journal <para-sep> waits for the journal catchup to finish when the process starts . this is intended to be only be called when starting the alluxio master process in secondary mode and before the secondary master becoming the primary master . this is best-effort , because even if it did not finish replaying the journal , the rest of the system will still complete the journal catchup in a different phase . this can be implemented by a journal type to optimize the journal replay , and avoid getting interrupted with primary state changes during journal replay .","currently , all masters register with zk and listen on state change events ( ie . lost , suspended ) immediately after starting . for large namespaces , there is an expensive journal replay step ( > 0 minutes ) . if there is a state change during this period , the progress is reset . this can lead to an infinite loop , especially since gc pressure is higher during journal replay , leading to longer pauses . <nl> this pr tries to let alluxio masters in zookeeper + ufs journal fault-tolerant mode replay its journal first and then",1611896864,for handling foreign uris that are not mounted to alluxio .,0.9677022099494934
apache_kafka/10378,"remove deprecated apis in <para-sep> from window-start through window-end , and for the entire grace period . if not specified , the retention period would be set as the window length ( from window-start through window-end ) plus the grace period . <nl> by default grace period is 0 hours for all windows , in other words we allow out-of-order data for up to a day",0 ) remove all deprecated apis in . <nl> 0 ) remove deprecated apis in windows in .,1616475048,"now that we have augmented windowserde with non-arg parameters , extract it out as part of the public apis so that users who want to i/o windowed streams can use it . <nl> this pr grows out to be a much larger one , as i found a few tech debts and bugs while working on it . here is a summary of the pr : . <nl> 0. public api changes ( i will propose a kip after a first round of reviews ) : . <nl> * add timewindowedserializer , timewindoweddeserializer , sessionwindowedserializer , sessionwindoweddeserializer into o.a.k.streams.kstream .",0.9552925229072571
apache_pulsar/10843,this reverts commit sha . <para-sep> configuration to aggregate various authentication params .,"this reverts commit sha . <nl> reverting since the external cluster configuration was not not needed as there are better ways to interact with external pulsar clusters . a user can simply instantiate a pulsar client , producer , or consumer in a function to interact with another pulsar cluster . this feature is also a security risk as it does not security handle authentication data and it will be written as plain text in the internal function 's metadata topic .",1622999862,to simplify the processing model for functions . <nl> prepare to be able to support running connectors on pulsar functions,0.9687665104866028
elastic_elasticsearch/73232,"[ ml ] switch ml internal index templates to composable templates . <nl> legacy index templates are deprecated but ml was still using <nl> them for its hidden indices . <nl> this pr switches the legacy ml index templates to use the new <nl> composable index template framework . <nl> the composable index templates get installed once the master <nl> node is on a version that understands them . for templates <nl> that need to be up-to-date in mixed version clusters where the <nl> master might still be on a version that does n't understand <nl> composable index templates we still ship the legacy template <nl> too , and install this if required in the mixed version cluster . <nl> ( the notifications index template falls into this category . ) <nl> this makes a couple of places in the code a little messy , as <nl> the new style template definitions do n't contain a dummy _doc <nl> level ( where the type used to be ) , but the legacy template <nl> definitions do - hopefully we can tidy this up in master once <nl> version is released . <nl> there is one more change of note in this pr that is not <nl> strictly related to switching to composable templates , but <nl> which was shown up during the testing . we used to wait for <nl> all templates to be installed by the master node before running <nl> tests in mixed version clusters . i do not believe we should <nl> have been doing this , as other upgrade orchestration systems , <nl> e.g . cloud , will not be doing this . our production code needs <nl> to install templates and/or mappings before any operation that <nl> requires them if there 's a chance that the elected master wo n't <nl> have done this in time .","legacy index templates are deprecated but ml was still using <nl> them for its hidden indices . <nl> this pr switches the legacy ml index templates to use the new <nl> composable index template framework . <nl> the composable index templates get installed once the master <nl> node is on a version that understands them . for templates <nl> that need to be up-to-date in mixed version clusters where the <nl> master might still be on a version that does n't understand <nl> composable index templates we still ship the legacy template <nl> too , and install this if required",1621427547,"this commit allows for composite aggregations in datafeeds . <nl> composite aggs provide a much better solution for having influencers , partitions , etc . on high volume data . instead of worrying about long scrolls in the datafeed , the calculation is distributed across cluster via the aggregations . <nl> the restrictions for this support are as follows : . <nl> - the composite aggregation must have exactly one source <nl> - the sub-aggs of the composite aggregation must have a aggregation on the same timefield as the aforementioned source <nl> - the composite agg must be the only",0.985194981098175
netty_netty/11342,add default block in httpobjectdecoder .,"motivation : . <nl> fix switch case fall through , add default block in httpobjectdecoder . <nl> modification : . <nl> add default block in httpobjectdecoder , thanks .",1622514161,ensure that either sslhandler 's handshake timeout or the handshake <nl> itself ( or its failure ) take place but not both .,0.7761838436126709
confluentinc_ksql/6806,first pass at timestamps <cm-sep> add functional test plans <para-sep> release target : version | status : in development | <nl> given : <nl> when : <nl> then : <nl> timestamp : <nl> timestamp : <nl> parse a sql timestamp from a string . <nl> timestamp : <nl> note : most of the functional test coverage is in defaultsqlvaluecoercertest <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> timestamp : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> keeping this as is to prevent breaking existing streams that convert timestamps to longs <nl> return milliseconds <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"this pr includes casting between strings and timestamps , comparisons and json/avro/delimited serde . <nl> it looks like a lot of files , but most are tests or changes that involve adding timestamp to a list of types . all the other files can be broken down as follows : . <nl> not included in this pr : <nl> * documentation ( this will be in a separate pr ) <nl> * udf/udaf support <nl> * arithmetic functions <nl> * protobuf support - ksql ca n't create a new protobuf topic unless is registered in schema registry . <nl> *",1608341435,"noticed that when a key column is aliased in the projection of a persistent query , the physical plan has the old name for the key column . <nl> this change fixes that by including the names of the key columns in the / physical plan step types . it 's sufficient to track just the column names as they key data can not be changed in a projection , only the column names . <nl> currently , only a single key column is possible . however , the select step pojos take a list of column names in prep",0.9545294046401978
ballerina-platform_ballerina-lang/27073,fix typeconverter . <nl> method didnt have a check for decimal type . <nl> added the check .,an error was generated . <nl> added the check .,1606114922,allow function pointers to be used under type guard .,0.8927755951881409
jenkinsci_jenkins/5424,"improve slow trigger ui , logging , and tests <para-sep> todo : we do not record multiple occurrences of the same trigger ; on which instance would 0 different trigger types take forever ? figure out a better presentation . <nl> used to be milliseconds , now is seconds since jenkins 0.todo .","it also adds a system property to override the default threshold , and to make it user-friendlier , redefines the field as seconds rather than milliseconds . this is , strictly speaking , a breaking change , but i expect nobody uses this static field , which should also have been before – and the only impact is that the monitor stops showing except in ridiculous cases ( a few hours ) . <nl> ui before and after . <nl> > . <nl> > . <nl> * improve ui of slow trigger administrative monitor . <nl> too minor ? unsure",1618529938,"for now it retains the traditional behavior by default , especially as tool metadata like hudson.tasks.maven.maveninstaller.json bears no signature . ( the equivalent does , and the for update centers does too , so this looks like an oversight ; would i think currently break tool download from browsers without support . )",0.9536363482475281
Graylog2_graylog2-server/10065,"use custom timeout when optimizing index for es7 . <cm-sep> actually return value , use correct import . <para-sep> this constraint is related to the duration ( in milliseconds ) being casted to integer at some point .","note : this pr requires a backport to . <nl> prior to this change , the force merge request which is used during the index optimization job did not supply a timeout for es7 . this leads to the default timeout ( 60s ) being used , which is too short in most cases . <nl> this pr is supplying the configured timeout to the request .",1613468948,"right now we can not handle a path prefix for the web interface assets , because of the way they are bundled . the config parameter allows one , so we need to explicitly check for it and raise an error when it is set to prevent undefined/unexpected behavior .",0.9319477677345276
trinodb_trino/8015,remove ambiguous name imports . <nl> name of name constant is not distinct enough to be static-imported .,name of name constant is not distinct enough to be static-imported .,1621590018,this change sets default broadcast join build side limit to 100mb,0.8914268612861633
confluentinc_ksql/7544,reject mismatched decimals from avro topics <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"if you run the following statements . <nl> you would end up with a in the logs , instead of rejecting the value to begin with . <nl> and querying a would return the mismatched decimal . <nl> this pr changes the behaviour so that if there is a mismatching decimal , it first tries to convert the topic decimal to the ksql schema , and if that is impossible , then it skips that value and the logs a in the streams log .",1621297431,( also fixes tabs in expressiontypemanagertest.java to be two spaces instead of four . ) <nl> unit and integration tests are expected for any behavior changes._ . <nl> added unit tests .,0.9196355938911438
apache_shardingsphere/10755,add test case for ruleconfigurationcheckerfactory with ruleconfigurationchecker fixture <cm-sep> add test case for ruleconfigurationcheckerfactory with ruleconfigurationchecker fixture <cm-sep> add test case,changes proposed in this pull request : <nl> - add test case for shardingruleconfigurationchecker <nl> - add test case for algorithmprovidedshardingruleconfigurationchecker,1623338460,changes proposed in this pull request : .,0.9678893089294434
confluentinc_ksql/7627,fixes race condition exposing uninitialized query <para-sep> initialize the query before it 's exposed to other threads via the map/sets . <nl> these fields do n't need synchronization because they are initialized in initialize ( ) before the object is made available to other threads .,"this is done in particular in and . for example , when calling : . <nl> the list of persistent queries is n't guaranteed to be initialized and the calls to the query in such as and will fail with npes .",1622674302,- remove all old expected_topologies as we 're heading for a major version bump and do n't need to maintain backwards compatibility with older versions <nl> - updated all so that the legacy values match the new value - effectively disabling them - they can be removed in follow up prs <nl> - removed some qtt test cases that are no longer valid or test backwards compatibility . <nl> - fixed up some qtt test cases that resulted in test failures due to schema incompatibilities the same test on different formats . <nl> this is only there so we know,0.9048160910606384
grpc_grpc-java/7991,"update cluster_resolver lb policy config definition . <cm-sep> update cds lb policy to support receiving cds update with ring_hash policy as the endpoint level lb policy . <cm-sep> update cluster_resolver lb policy to generate different lb configs for downstream lb policies based on the endpoint-level lb policy . <para-sep> dns-resolved endpoints do not have the definition of the locality it belongs to , just hardcode to an empty locality . <nl> arbitrary priority notation for all dns-resolved endpoints . no weight attribute is attached , all endpoint-level lb policy should be able to handle such it . <nl> generates the config to be used in the priority lb policy for the single priority of logical dns cluster . priority lb - > cluster_impl lb ( single hardcoded priority ) - > pick_first <nl> override endpoint-level lb policy with pick_first for logical dns cluster . <nl> generates configs to be used in the priority lb policy for priorities in an eds cluster . priority lb - > cluster_impl lb ( one per priority ) - > ( weighted_target lb - > round_robin ( one per locality ) ) / ring_hash <nl> depending on the endpoint-level load balancing policy , different lb hierarchy may be created . if the endpoint-level lb policy is round_robin , it creates a two-level lb hierarchy : a locality-level lb policy that balances load according to locality weights followed by an endpoint-level lb policy that simply rounds robin the endpoints within the locality . if the endpoint-level lb policy is ring_hash , it creates a unified lb policy that balances load by weighing the product of each endpoint 's weight and the weight of the locality it belongs to . <nl> endpoint-level load balancing policy with config ( round_robin or ring_hash ) . <nl> private , use one of the static factory methods instead . private , use one of the static factory methods instead . <nl> private , use lbpolicy ( lbpolicy , long , long ) . private , use lbpolicy ( .lbpolicy , long , long ) private , use cdsupdate.foreds ( ) instead . private , use one of the static factory methods instead . private , use one of the static factory methods instead . private , use one of the static factory methods instead . private , use cdsupdate.foraggregate ( ) instead . <nl> one priority with two localities of different","there two main parts of this change : <nl> - changed the cds lb policy to accept ' ring_hash ' as the endpoint lb policy from cds updates . this configuration is directly passed to its child policy ( aka , clusterresolverloadbalancer ) in its config . <nl> - note , for underlying clusters of an aggregate cluster , its endpoint-level lb policy is configured by the top-level cluster configuration . <nl> - changed clusterresolverloadbalancer to generate different lb configs for its downstream lb policies . depending on the endpoint-level lb policies , the downstream lb tree hierarchy will be",1616095767,"this avoids the needs to flatten to eags for cases like pickfirst , <nl> making the attributes in eags able to be used in communication with <nl> core . <nl> this alone will not be enough to rid ourselves of all flattening . we also <nl> need to support list\ with oobchannels . but i 'll do that as a later <nl> pr .",0.9677540063858032
vespa-engine_vespa/18129,add todos about when legacy code can be removed <cm-sep> use generateschemds and remove generatesearchdefinition <cm-sep> add getschemas methods . <nl> deprecate two methods where one should use getschemas instead,"deprecate some methods , add new methods with schemas in name",1622807500,"extracted from upcoming pr , not much interesting to see here ..",0.9485663175582886
Graylog2_graylog2-server/10005,"use classgraph library to improve jerseyservice startup speed . <nl> this reduces the startup time of the jerseyservice by 0 % on my <nl> development machine when running the production artifacts . <nl> ( versions vs versions ) . <nl> since scanning package paths for resources is pretty slow in jersey , <nl> this replaces the usage of resourceconfig # packages with <nl> resourceconfig # registerclasses . <nl> we now scan for resource classes by using the classgraph library . <cm-sep> add comment to findresources <para-sep> adds given api resource as a system resource . this should not be used from plugins ! <nl> install all resource modules <nl> this class provides access to the system and plugin api resources that are available through the guice multi-binder . hk2 does not allow to inject this directly into the resource class . <nl> returns all system resources . <nl> wait for es before starting the graylog node to avoid any race conditions <nl> to be able to search for data we need the index ranges to be computed . since this is an async background job , we need to wait until they have been created . <nl> with the default configuration , there should be a least one ' graylog_ ' prefixed index","this reduces the startup time of the by 0 % on my development machine when running the production artifacts . <nl> ( versions vs versions ) . <nl> since scanning package paths for resources is pretty slow in jersey , we now register all rest resources explicitly via in the guice bindings . this will also allow us to disable resources via feature flags and runtime profiles in the future . <nl> i compared the output of the with both implementations and we get the same resources registered with the new one . ( tested in a production artifact deployment",1612275133,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.8564616441726685
apache_shardingsphere/10438,explain case <cm-sep> explain case <cm-sep> explain <cm-sep> add assertion implementation for explainstatement,changes proposed in this pull request : <nl> - add assertion implementation for explainstatement,1621828158,changes proposed in this pull request : <nl> - fix for set transaction of mysql,0.9369291067123413
apache_kafka/10790,fix for documentation for describeacls <cm-sep> revert ' fix for documentation for describeacls ' . <nl> this reverts commit sha <cm-sep> : fix for documentation for describeacls,it 's a small fix for documentation bug . i do n't think any test case is required for that . <nl> closes .,1622273666,this pr fixes two typos in the javadoc for class .,1.0
Alluxio_alluxio/13336,support overwrite in migrateconfig . <nl> migrateconfig has an overwrite flag that did n't do anything . <nl> this has the side effect where distributedcp and distributedmv are now <nl> going to overwrite and the retries are going to work in more cases ( when <nl> destination file is partially written ) .,migrateconfig has an overwrite flag that did n't do anything . <nl> this has the side effect where distributedcp and distributedmv are now going to overwrite and the retries are going to work in more cases ( when destination file is partially written ) .,1620155143,conflicts resolved in last two commits,0.9672189950942993
confluentinc_ksql/7222,"feat ( java client ) : add createconnector , dropconnector , listconnectors and describeconnector to java client <para-sep> creates a connector . <nl> drops a connector . <nl> returns a list of connectors . <nl> returns metadata about a connector .","# # # description <nl> adds , , and to the java client . i can split this into separate prs if that makes it easier to review .",1615589841,docs will come in a follow-up pr . javadocs on the new methods/interfaces/user-facing classes are included in this one . <nl> added unit and integration tests .,0.9827393889427185
apache_incubator-pinot/6323,"decimal percentile support . <para-sep> double arguments percentile ( e.g . percentile ( foo , 0 ) , percentiletdigest ( bar , 0 ) , etc . ) where the second argument is a decimal number from version to version . <nl> version 0 functions specified in the of form percentile ( column ) version 0 functions of form percentile ( column , . ) <nl> version 0 functions specified in the of form percentileest ( column ) version 0 functions of form percentileest ( column , . ) <nl> version 0 functions specified in the of form percentiletdigest ( column ) version 0 functions of form percentiletdigest ( column , . ) <nl> schema for first query is different from schema of the rest of the queries because the second query is using percentileemv function that works off decimal values . <nl> schema for first query is different from schema of the rest of the queries because the second query is using percentileemv function that works off decimal values . <nl> schema for first query is different from schema of the rest of the queries because the second query is using percentileemv function that works off decimal values .","this pr adds support for specifying decimal percentile ( version , version , etc ) through the following functions : . <nl> however , the internal implementation of these functions were changed to support decimal percentile values as well . <nl> files modified to allow for successfully parsing and validating decimal values in new percentile functions : . <nl> > aggregationfunctionfactory.java . <nl> existing implementation of percentile functions were modified to allow for supporting both the existing and the new percentile functions with decimal values : . <nl> > percentileaggregationfunction.java <nl> > percentileestaggregationfunction.java <nl> > percentileestmvaggregationfunction.java <nl> > percentilemvaggregationfunction.java <nl>",1607147339,"this pr adds support for other month-over-month , day-over-day , and hour-over-hour baselines in the rca gui . the ui changes are unobtrusive to enable us to pilot these changes with select users .",0.9653927683830261
apache_pulsar/10987,feat # add some test for namespacebundlesplitalgorithmtest,# # # modifications . <nl> supplementary test for this project .,1624169605,# # # motivation . <nl> make sure we record charset in the properties . so that we know which charset to be used for encoding and decoding strings . <nl> add charset to the properties,0.9531199336051941
apache_incubator-pinot/6885,updating queryrunner static methods to return object of report summary/stats,"for clients that call the queryrunner methods directly ( not through command line ) , i added return objects for the methods so that that the client does not have to collect the results from the log output .",1620331504,0. add bulk deletion by predicate to genericpojodao . <nl> 0. add adhocdb functions to clean up dataset and anomaly functions .,0.9469276666641235
apache_camel/5550,": route template / kamelets . allow to use # type and # class for local beans <cm-sep> : route template / kamelets . allow to use # type and # class for local beans <cm-sep> : route template / kamelets . allow to use # type and # class for local beans <cm-sep> : route template / kamelets . allow to use # type and # class for local beans <cm-sep> : route template / kamelets . allow to use # type and # class for local beans <para-sep> * * * test set-up * * * <nl> must use { { mybar } } to refer to the local bean <nl> * * * test set-up * * * <nl> must use { { mybar } } to refer to the local bean <nl> * * * test set-up * * * <nl> must use { { mybar } } to refer to the local bean <nl> * * * test set-up * * * <nl> must use { { mybar } } to refer to the local bean <nl> * * * test set-up * * * <nl> must use { { mybar } } to refer to the local bean <nl> bean class is optional for supplier <nl> do not set properties when using # type as it uses an existing shared bean <nl> the component needs to be initialized to have the configurer ready <nl> see if there is a configurer for it <nl> enrich the error with more precise details with option prefix and key <nl> special for java-dsl to allow using lambda style <nl> what type to use for creating the bean . can be one of : # class , # type , bean , groovy , joor , language , mvel , ognl . <nl> optional properties to set on the created local bean <nl> the script to execute that creates the bean when using scripting languages . if the script use the prefix resource : such as resource : classpath : com/foo/myscript.groovy , resource : file : /var/myscript.groovy , then its loaded from the external resource . <nl> the script to execute that creates the bean when using scripting languages . if the script use the prefix resource : such as resource : classpath : com/foo/myscript.groovy , resource : file : /var/myscript.groovy , then its loaded from the external resource",todo : i need to update the documentation but here is something to take a first look at .,1620892761,converted the restconsumerbindingprocessor into restbindingadvice to control the order between rest binding and contract processing . now you can use rest binding and contract based transformer together in a same route .,0.986282229423523
ballerina-platform_ballerina-lang/30281,"fix annotation tests <cm-sep> remove tests that use versioned imports <cm-sep> remove obsolete object bala tests <cm-sep> fix dataflow analysis tests <cm-sep> fix service test <cm-sep> fix expression tests <para-sep> this class is used for external functions in annotation tests . <nl> this class tests the freeze ( ) and isfrozen ( ) builtin functions . <nl> { ' testletexprinrecord ' } , { ' testletexprinobj ' } , <nl> bassertutil.validateerror ( resultnegative , ++i , incompatibletypes + ' expected 'string ' , found 'boolean ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , ++i , incompatibletypes + ' expected 'bar ' , ' + ' found 'map ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , ++i , incompatibletypes + ' expected 'string ' , found 'boolean ' ' , 0 , 0 ) ; <nl> bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'message ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'abc ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'r2 ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'message2 ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'rest ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'message3 ' ' , 0 , 0 ) ; bassertutil.validateerror ( resultnegative , i++ , ' can not assign a value to final 'abc3 ' ' , 0 , 0 ) ; <nl> function testletexprintransaction ( ) { int a = 0 ; if ( a == 0 ) { int c = 0 ; transaction { int b = let int y = 0 + c , int z = 0 + a in z + y + a + c + globalvar ; a = b ; checkpanic commit ; } asserttrue ( a == 0 , ' a == 0 ' ) ; } <nl> function testletexprinarrowfunction ( ) { int a = 0 ; if ( a == 0 ) { int b =",this pr removes some obsolete tests that were disabled .,1619926679,"this will fix several npes at the code analyzer level . with this fix , it will first check for type checking or semantic analysis issues , and only if there are no such issues , then it 'll proceed to code analyzer .",0.9884728193283081
OpenAPITools_openapi-generator/8845,fix cyclic types <cm-sep> fixed up bad enum names <cm-sep> fixed double crate : : issue <cm-sep> add required tostring for enum classes <cm-sep> adds debug/clone derive macro for generated configuration type <cm-sep> updates versions of dependencies recorded in generated cargo.toml <cm-sep> fix merge <cm-sep> bin/generate-samples.sh <para-sep> todo : deleting the variable from the array was problematic ; i do n't know what this is supposed to do so i 'm just cloning it for the moment,this fixes a few rust code generation issues . i 've included links to small test cases . <nl> - compile errors incorrectly referencing types e.g . <nl> - compile errors on types named <nl> - compile errors on cyclic types <nl> - compile warnings on incorrectly named enum values .,1614298393,- mark feign 0.x ( instead of 0.x ) as the default <nl> - mark 0.x as deprecated .,0.8683631420135498
neo4j_neo4j/11713,"adds primitive implementations of distinct . <nl> the general purpose distinct implementation uses a <nl> lot of objects to make the output distinct . <nl> this implementation avoids objects and uses primitive <nl> sets to do work , which should be create less memory <nl> pressure and is easier for the cpu to do efficiently . <para-sep> when you need to have a set of arrays of longs representing entities - look no further this set will keep all it 's state in a single long [ ] array , marking unused slots using 0 , a value that should never be used for node or relationship id 's . the set will be resized when either probing has to go on for too long when doing inserts , or the load factor reaches 0 % . the word ' offset ' here means the index into an array , and slot is a number that multiplied by the width of the values will return the offset . <nl> adds a value to the set . <nl> we know we need to add the value to the set , but there is no space left <nl> need to restart linear probe after resizing <nl> found a different value in this slot <nl> * returns true if the value is in the set . <nl> return h ; // uncomment this to go back to normal hashing <nl> this is tabulation hashing ! <nl> linear probe until we find an unused slot . no need to check for size here - we are already inside of resize ( ) <nl> semi random numbers to use for tabulation hashing <nl> we use these objects to figure out : a ) can we use the primitive distinct pipe ? b ) if we can , what offsets are interesting <nl> =========================================================================== compile-time initializations =========================================================================== <nl> =========================================================================== runtime code =========================================================================== <nl> create key array <nl> found something ! set it as the next element to yield , and exit <nl> =========================================================================== compile-time initializations =========================================================================== <nl> =========================================================================== runtime code =========================================================================== <nl> found something ! set it as the next element to yield , and exit","the general purpose distinct implementation uses a <nl> lot of objects to make the output distinct . <nl> this implementation avoids objects and uses primitive <nl> sets to do work , which should be create less memory <nl> pressure and is easier for the cpu to do efficiently .",1525416079,so that it will apply to all testing . tests that want bigger page cache <nl> will have to explicitly specify that .,0.9563894867897034
elastic_elasticsearch/73066,[ ml ] adds latest record timestamp to model snapshot deprecation warning,this adds the latest record timestamp of the deprecated model snapshot in the warning . <nl> this hopefully gives the user a better view into whether they would want to delete the snapshot or to upgrade it .,1620933535,"if an email action is used in a foreach loop , message ids could have <nl> been duplicated , which then get rejected by the mail server . <nl> this commit introduces an additional static counter in the email action <nl> in order to ensure that every message id is unique .",0.8863283395767212
apache_flink/15236,"refactor slicingwindowaggoperatorbuilder to accept serializer instead of logicaltype <para-sep> serializer to copy key if required . * / <nl> actually , the return value is just for saving checkskipreadforfixlengthpart in the mapfrompages , the cost is very small . todo so , we can remove this return value for simplifying interface . <nl> we can not return the num of bytes skipped by keyserializer . the return value is to help better relocate the start offset where the data is located , and the offset we need here is the offset that we started to write . at this time , its offset should also be 0 . <nl> in the mini-batch window operators and window is identified by window end timestamp .","# # what is the purpose of the change . <nl> refactor slicingwindowaggoperatorbuilder to accept serializer instead of logicaltype <nl> now slicingwindowaggoperatorbuilder accept logicaltypes , it is better to avoid logicaltypes in runtime operators and functions . <nl> refactor slicingwindowaggoperatorbuilder . <nl> this change is a trivial reworkwithout any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) :",1615889840,"for multi-gate inputs , there existed inconsistent offset handling of barrierhandlers and checkpointedinputgates for unaligned checkpoints . this pr unifies the creation of barrierhandlers and checkpointedinputgate . <nl> - use the non-unioned ( indexed ) inputgates as the main information source that is needed to create handlers . <nl> - unioned input gates are only used to create the checkpointedinputgate . <nl> covered by existing ( modified ) tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class",0.9567969441413879
ballerina-platform_ballerina-lang/30227,fix issue with order of param list <cm-sep> add unit tests for included record parameter <cm-sep> fix failing tests,according to the spec param list should be in the following order .,1619591077,could use jballerina-unit-test : org.ballerinalang.test.expressions.lambda.functionpointerstest . * to verify .,0.9233934283256531
confluentinc_ksql/7086,"table scan : filters out streamsmetadata for wrong subtopology <cm-sep> remove comments <cm-sep> fix test <para-sep> given : the ' a- ' prefix creates a repartition and and therefore 0 subtopologies . this is important to exercise the logic that filters source topics by subtopology for table scans . <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> it 's important that we consider only the source topics for the subtopology that contains the state store . otherwise , we 'll be given the wrong partition - > host mappings . the underlying state store has a number of partitions that is the max of the number of partitions of all source topics of the subtopology . since partition x of all source topics of the particular subtopology will map to the same host , we can collect partition - > host for these topics to find the locations of each partition of the state store . <nl> ideally , we 'd also throw an exception if we found a mis-mapping for the standbys , but with multiple per partition , we ca n't easy sanity check . <nl> for the particular state store , this finds the subtopology which contains that store , and then finds the input topics for the subtopology by finding the source nodes . these topics are then used for checking against all the metadata for the state store and used to find the active and standby hosts for the topics . without doing this check , incorrect assignments could be chosen since different subtopologies can be run by different hosts .","the calling code assumed that it was for just one subtopology , so this resulted in a bug where topicpartitions from the wrong subtopology could overwrite the intended one .",1614131948,currently datagen only sets the system time as the message timestamp . this patch enable the datagen to set the message timestamp to a given column in the value the same way the message key can be configured . <nl> the column that is used for timestamp should have long type .,0.9570648074150085
apache_pulsar/10667,"fix issues in advancenondurablecursors <para-sep> this method also addresses a corner case for durable cursors in which the cursor is caught up , i.e . the mark delete position happens to be the last entry in a ledger . if the ledger is deleted , then subsequent calculations for backlog size may not be accurate since the method getnumberofentries we use in backlog calculation will not be able to fetch the ledger info of a deleted ledger . thus , we need to update the mark delete position to the ' 0 ' entry of the first ledger that is not marked for deletion . <nl> need to move mark delete for non-durable cursors to the first ledger not marked for deletion calling getnumberofentries latter for a ledger that is already deleted will be problematic and return incorrect results <nl> move the mark delete position to the highestpositiontodelete only if it is smaller than the add confirmed to prevent the edge case where the cursor is caught up to the latest and highestpositiontodelete may be larger than the last add confirmed",there are a couple of issues in advancenondurablecursors . <nl> 0. durable cursors unnecessarily run through this logic <nl> 0. for non-durable and durable cursors that are caught up reading the topic . the following warning message can be printed . <nl> this happens because highestpositiontodelete calculated when the reader/consumer is caught up is going to be higher than the last confirmed for the of the managed ledger . there is also no point in trying to advance the mark delete position if the reader/consumer is caught up .,1621579647,"in version version , support deadlettertopic feature . this feature based on message redelivery . so ack timeout is necessary . <nl> set acktimeout ( 30s ) when enable the dead letter policy but not set the acktimeout ;",0.8569144010543823
elastic_elasticsearch/73432,"users can access the centroid , bounding box and dimensional type of the shape . <para-sep> returns the dimensional type of this geometry * / <nl> returns the bounding box of this geometry * / <nl> returns the centroid of this geometry * / <nl> reset the geometry .","users can access the centroid , bounding box and dimensional type of the shape .",1622048366,"this adds support for the xdbc and cli clients . <nl> based on these , the csvjdbc-based qa tests are also added .",0.9826114177703857
grpc_grpc-java/8176,"the cluster_resolver lb poolicy shouold wait until endpoints of all clusters being resolved before propgate them to its child lb policy . <cm-sep> fix tests . <para-sep> propagate endpoints to the child lb policy only after all clusters have been resolved . <nl> nameresolver.listener api can not distinguish between address-not-found and transient errors . if the error occurs in the first resolution , treat it as address not found . otherwise , either there is previously resolved addresses previously encountered error , propagate the error to downstream/upstream and let downstream/upstream handle it . <nl> cluster2 : locality1 with priority 0 and locality3 with priority 0 . <nl> cluster1 : locality2 with priority 0 . <nl> endpoints of all clusters have been resolved . <nl> dns resolution failed , but there are eds endpoints can be used .","the cluster_resolver lb policy resolves endpoints for _an ordered list of clusters_ . the addresses its child lb policy ( aka , priorityloadbalancer ) receives is ordered first by clusters , then by priorities within each cluster . for example , if the cluster_resolver lb policy receives [ clustera , clusterb , clusterc ] , the priority lb policy should be expected to receive addresses ordered as [ addrs_clustera_priority0 , addrs_clustera_priority1 , ... , addrs_clusterb_priority0 , addrs_clusterb_priority1 , ... , addrs_clusterc_priority0 , ... ] . <nl> this requires the cluster_resolver lb policy to _synchronize_ all of its resolutions . that",1620930145,"is appropriate for plumbing optional objects , especially useful for a long plumbing path where components in the middle may not care or see all objects in the container . it 's not the case for the on . both the default port and the proxy detector are guaranteed to be there and the plumbing path is very short . in this case , a first-class object is more appropriate and easier to use . <nl> we we also considering merging into the , to make match the api .",0.9478421807289124
apache_druid/11352,"ignore bysegment query context for sql queries <para-sep> ' bysegment ' results are never valid to use with sql because the result format is incompatible so , overwrite any user specified context to avoid exceptions down the line <nl> should contain only query id , not bysegment since it is not valid for sql <nl> test initialize <nl> setting parameters should not change the state <nl> test authorization <nl> test prepare <nl> prepare doens't change lifecycle state <nl> test plan <nl> test execute <nl> test emit <nl> this test is a duplicate of teststatetransition except with a slight variation of how validate and authorize is run <nl> test initialize <nl> setting parameters should not change the state <nl> test authorization <nl> test prepare <nl> prepare doens't change lifecycle state <nl> test plan <nl> test execute <nl> test emit","also added a test for state transitions while i was here , to cover the happy path and make sure state transitions happen as expected . this stuff was all pretty well indirectly tested , but did n't have an actual test of its own",1623237348,"this pr introduces an additional lifecycle stage , which runs first on startup and last on shutdown . <nl> additionally , ties 'task-master ' lifecycle to lifecycle in order to gracefully stop being leader when task master is stopping . <nl> also adds a field to which helps with additional logging around lifecycle stage startup and stops and which lifecycle they belong to . <nl> on startup : . <nl> and stopping : .",0.9393889307975769
grpc_grpc-java/8245,"add comment to note the parsed weight value of 0 for lbendpoint and localitylbendpoints indicates unspecified weight . <cm-sep> only set endpoint 's weight attribute if its weight had been specified/defined in xds resource , avoid setting 0 for unspecified weight values . <cm-sep> the parsed localitylbendpoint 's weight is guaranteed to be greater than 0 . <cm-sep> revert redundant test case . <para-sep> locality 's weight for inter-locality load balancing . guaranteed to be greater than 0 . <nl> endpoint 's weight for load balancing . if unspecified , value of 0 is returned . <nl> endpoints in locality1 have no endpoint-level weight specified , so all endpoints within locality1 are equally weighted .","when parsing the lbendpoint , the presence information is discarded . that is , if not specified in eds , the parsed lbendpoint will have a weight of 0. then when computing the overall weights for endpoint-level load balancing ( e.g. , ring_hash ) , those endpoint will have an explicit attribute of 0 weight . this may cause trouble for the load balancing algorithm ( e.g. , in ring_hash if some endpoints have 0 weight , those endpoints will never have rpcs routed to ; if all endpoints have 0 weight , the algorithm is broken ) . <nl>",1623189361,"changes in processing eds responses : <nl> - localities without weight or with weight of 0 are ignored ( as grpc always enables locality weighted load balancing ) . <nl> - validate priority continuity for localities in each cluster , should nack the response if priority values are skipping .",0.8946341872215271
apache_pulsar/11059,"[ issue 0 ] fixed flaky test adminapitest.testupdatedynamiclocalconfiguration . <nl> at certain moments , due to zookeeper delayed notification , <nl> the number of retry waiting times exceeded . <nl> - change busy waiting to awaitility.await method .","at certain moments , due to zookeeper delayed notification , <nl> the number of retry waiting times exceeded . <nl> - change busy waiting to awaitility . await method .",1624503291,motivation . <nl> connection can be null when closing consumer . <nl> changes . <nl> check if the connection is null or not during closing .,0.8350457549095154
apache_beam/13835,"load user-provided jars in calcfn . <nl> note that it is possible for one calcfn to require multiple jars , so for <nl> now it is the user 's responsibility to ensure there are no conflicts . <nl> this is no different from user-provided jars in the java sdk . <nl> this adds an optional jar path field to scalarfunctionimpl . this field <nl> will be populated in a later pr . <para-sep> maps potentially remote jar paths to their local file copies . * / <nl> this code creates a classloader , which needs permission if a security manager is installed . if this code might be invoked by code that does not have security permissions , then the classloader creation needs to occur inside a doprivileged block . <nl> optional beam filesystem path to the jar containing the bytecode for this function . empty if the function is assumed to already be on the classpath .","note that it is possible for one calcfn to require multiple jars , so for <nl> now it is the user 's responsibility to ensure there are no conflicts . <nl> this is no different from user-provided jars in the java sdk . <nl> this adds an optional jar path field to scalarfunctionimpl . this field <nl> will be populated in a later pr",1611870428,this pr adds the support of,0.9669302105903625
confluentinc_ksql/6727,catch stack overflow error when parsing/preparing statements <para-sep> when : <nl> then :,"there were two possible places throwing the stack overflow error , while parsing/preparing . <nl> one suggestion was to limit the where clause size , but i do n't think that 's an optimal since it 's possible to have a large where clause and not hit this issue . the error is being thrown when recursively trying to evaluate the boolean expression that 's part of the where clause , and the number of nested parentheses expressions is causing the deep recursion tree , but if the boolean expression was something like ` where itm.item_id = ' 0 ......",1607128313,"the bug is that the close callback passed to the querystreamwriter/topicstreamwriter sets a flag ( ) that causes the loop to end and close the underlying kafka streams app/kafka consumer , but when http/0 is used , is never called so this does n't happen even though the flag is set . this pr fixes the bug by introducing a new method , , that directly closes the underlying kafka streams app/kafka consumer and is called when the 0 response is returned ( upon discovering an http/0 request to the /query endpoint for a request type that requires an http",0.8845173716545105
Alluxio_alluxio/12963,change the default fuse type to jni-fuse <cm-sep> modify related docs <para-sep> alluxio jni-fuse,use jni-fuse as default alluxio posix api implementation,1614638486,add ' please make sure that alluxio master is running ' to error message,0.8319271802902222
jenkinsci_jenkins/5288,"merge back security tests <para-sep> otherwise it 's not passing on machine not running english as os language <nl> network or file access is bad <nl> network or file access is bad <nl> ensure not side effects <nl> currently , but doing so will be a bit more future-proof <nl> ensure the other data were not saved <nl> this really should n't return 0 , but that 's what it does now . <nl> could also be reached using static// <nl> required as cf1.xml is outside the temporary folders created for the test and if the test is failing , it will not be deleted <nl> that file exists , so we need to ensure if it 's returned , the content is not the expected one from the test data . <nl> expected refusal after the correction <nl> content retrieval occurred before the correction , we have to check the content to ensure non-regression <nl> this really should n't return 0 , but that 's what it does now . <nl> this really should n't return 0 , but that 's what it does now . <nl> this is a simplified version of the original report in . <nl> the view to create has to be nonexistent , otherwise a different code path is followed <nl> this really should n't return 0 , but that 's what it does now . <nl> this should have a different message , but this is the current behavior demonstrating the problem . <nl> the view should still be nonexistent , as we gave it a user and not a view . <nl> this is the same thing as the original report , except it uses valid xml . <nl> the view to create has to be nonexistent , otherwise a different code path is followed <nl> this really should n't return 0 , but that 's what it does now . <nl> this should have a different message , but this is the current behavior demonstrating the problem . <nl> the view should still be nonexistent , as we gave it a user and not a view . <nl> this really should n't return 0 , but that 's what it does now . <nl> correspond to the hardening of escapeentrytitleanddescription <nl> check the displayname <nl> check the description <nl> the existing add button can already trigger an xss <nl> only possible",no related tickets . <nl> merge back the non-regression tests added for last security release . we are doing that during security release to prevent unexpected merge conflict to ease the process . <nl> ℹ️ only changes applied to the tests are about : <nl> - assertthat from junit moved to the one from hamcrest due to the deprecation <nl> - a change related to locale for digester2test <nl> - some cleanup of before methods that has to be integrated . <nl> * ( skip ) . <nl> n/a . <nl> - [ n/a ] ( if applicable ) jira,1613396512,"i 'm assuming enough time has elapsed that the todos can be addressed . <nl> - internal : merge back different security tests that were splitted for the security release . <nl> - [ n/a ] jira issue is well described . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . ) <nl> - [ n/a ] appropriate autotests or explanation to why this change has no tests <nl> - [ n/a ] for dependency updates : links to external changelogs and , if possible , full diffs .",0.9707785248756409
apache_incubator-pinot/6690,combine operators : remove redundant variables and override logger in subclass <para-sep> groupbycombineoperator use numoperators as numthreads groupbyorderbycombineoperator use numoperators as numthreads,"this pr just does some code cleanup : <nl> * remove redundant variables in subclass <nl> * override logger in subclass for easy debugging <nl> * remove unnecessary constructor in baasecombineoperator since subclass has access to protected variables in supper class . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1615963499,"* currently , we use uri . this does n't make sense because it will always be copied to the local filesystem , so we should use a file object .",0.9296270608901978
hazelcast_hazelcast/18542,"re-enable jet class/jar deployment tests . <nl> this test was ignored during the merge . <nl> it was failing during the phase , where we had jet split across 0 <nl> modules . <nl> the tests work fine now after moving the required resources . <nl> this reverts commit sha .","this reverts commit sha . <nl> this test was ignored during the merge . <nl> it was failing during the phase , where we had jet split across 0 <nl> modules . <nl> the tests work fine now after moving the required resources .",1618492191,_see commit messages for additional details._ .,0.8997973203659058
elastic_elasticsearch/73243,more precise total data set size verification in frozensearchablesnapshotsintegtests . <para-sep> the original shard size from the snapshot <nl> an extra segments_n file is created for bootstrapping new history and associating translog . we can extract the size of this extra file but we have to unwrap the in-memory directory first .,"because restoring a searchable snapshot shard creates a new in-memory segment size , the verification of the data set size was implemented in an approximative fashion : between the expected size and twice the expected size . <nl> this pull request changes the test so that it now verifies the exact data set size returned by the indices stats api , which should be the sum of the original expected size of the snapshotted size + the length of the extra segment file in memory .",1621432658,this change revises an approach that generates an id using the ids of the <nl> segments of an index commit .,0.9090273380279541
ballerina-platform_ballerina-lang/27544,fix using readonly with classes . <nl> allow using readonly intersections with classes and allow using a readonly class as the type of a readonly record field . <cm-sep> fix all field compatibility check and fix tests <cm-sep> add tests for classes as readonly record fields <cm-sep> add tests for readonly intersections with classes <cm-sep> add readonly record field test for implicitly readonly class,since intersections with classes result in types ( as opposed to classes ) it is not possible to use with such an intersection . <nl> - allows classes as field types of records . <nl> - sets the read-only bit for closed anonymous record types with all fields . <nl> the following is now allowed .,1608188886,code : . <nl> output : .,0.9794870018959045
jenkinsci_jenkins/5435,"support zip64 in ziparchiver <para-sep> we probably do n't have enough free disk space . that 's ok , we 'll skip this test ... <nl> probably running on openjdk 0 and hitting","this pr fixes both bugs : the test now correctly creates a 0 gib file ( the change from to in the test ) , and the production code now correctly sets the length in the resulting archive ( the change to ) . <nl> i also simplified and rewrote the test significantly to make it easier to read and improve error handling ( while also eliminating 0 lines of code ) . <nl> the result passes on openjdk version but not on openjdk version_282 ( ubuntu ) , where it fails trying to open the large archive with .",1618787062,"moving functionality to a new plugin for anyone who needs it . <nl> * : jenkins no longer creates symbolic links inside project or build directories . the build symlink plugin may be installed to restore this functionality if desired . urls such as are not affected , only tools which directly access the filesystem . existing symlinks are not automatically removed by the update ; administrators wishing to clean up may run something like the following : .",0.9521641135215759
vespa-engine_vespa/17172,remove unnecessary test constructor <cm-sep> simplify constructor <para-sep> for testing only,"minor cleanup , no functional changes",1616666415,"added a object structure for groupingrequest objects , accessable from query.getselect ( ) .getgrouping ( ) . i believe i have done what you described .",0.9299796223640442
apache_incubator-pinot/6945,"update decoder to support complex-type <para-sep> extracts the root-level names from the fields , to support the complex-type handling . for example , a field a.b.c will return the top-level name a . <nl> do nothing","so the fields to read will parse path with complex-type and read the fields accordingly . <nl> also , update the quickstart examples to include all fields under the complex-type structure after flattening/unnesting .",1621455486,"this pr allows rule-based anomaly detection and algorithm-based detection to run for the same anomaly function at the same time and merge the results . also , enable the potential to add multiple secondary detection functions .",0.8935464024543762
elastic_elasticsearch/72844,".snapshot-blob-cache index is created today with a data tier <nl> preference set to data_cold , data_warm , data_hot . this does <nl> not works well with autoscaling and clusters that only have <nl> a hot and a frozen tier : in such cases autoscaling adds a <nl> cold tier just to host this system index . <nl> this commit changes the tier preference to data_content , data_hot . <cm-sep> adjust version <para-sep> prefer to allocate to the data content tier and then the hot tier .",".snapshot-blob-cache index is created today with a data tier <nl> preference set to data_cold , data_warm , data_hot . this does <nl> not works well with autoscaling and clusters that only have <nl> a hot and a frozen tier : in such cases autoscaling adds a <nl> cold tier just to host this system index . <nl> this commit changes the tier preference to data_content , data_hot .",1620375843,"0. we passed for the map which is n't nullable any longer <nl> when creating , fixed by just passing an empty map <nl> like the handling did in the past . <nl> 0. the removal of a failed state snapshot from the cluster state tried <nl> removing it from the finalization loop ( the set of repository names that are <nl> currently finalizing ) . this will trip an assertion since the snapshot failed <nl> before its repository was put into the set . i made the logic ignore the set <nl> in case we remove a failed state",0.8881648778915405
apache_incubator-pinot/6601,"[ te ] conform to standard sql requirement for quotes <para-sep> if have single quotes inside a string , it should be specified as 0 consecutive single quotes",conform to standard sql requirement for quotes as pinot moves to standard sql .,1614038769,this pr is to fix misuse of mainly and also include miscellaneous changes .,0.8794838786125183
Alluxio_alluxio/13235,"fix metadata load performance <para-sep> skip the load metadata step in the sync if it has been just loaded <nl> sync plan does not know about the root of the sync if descendanttype.one we only sync children if we are syncing root of this stream <nl> if loadmetadata is only for one level , and the path is not the root of the loadmetadata , do not load the subdirectory <nl> cancelled call should not return any results verify that the previous sync did not complete","previously , loadmetadata on a single level of directory would load that directory and its children , causing unnecessary delay . <nl> this prevents that from happening by changing the descendant type when we are loading a non-base path .",1618458910,"previously we had flakiness due to the following flow : <nl> 0. unit test 0 creates a master , e.g . filesystemmaster , which uses a heartbeat thread . the heartbeat thread x is initialized to use the scheduled timer . <nl> 0. the scheduled timer becomes ready to schedule and adds itself to the map in . this creates a mapping from the string ' x ' to the timer object . <nl> 0. the test calls schedule , removing the timer from and executing a heartbeat . after the heartbeat has executed , the timer adds itself back",0.9256699085235596
ballerina-platform_ballerina-lang/27468,"remove internal runtime api usages <cm-sep> sync with master <cm-sep> fix ballerina test sources debugging <cm-sep> remove obsolete utils <para-sep> identifier specific expression modifier implementation . <nl> removes quoted identifier prefix , if presents . <nl> processes escaped unicode codepoints . <nl> encodes the user provided identifier in order to be aligned with jvm runtime identifiers . <nl> identifier types based on different runtime identifier encoding mechanisms . <nl> returns full-qualified class name for a given jdi class reference instance . <nl> removes ' .bal ' extension if exists .",- refactor identifier encoding implementation to remove internal runtime api usages .,1607710583,- fix calling init multiple times when services are used <nl> - refactor suite initializing logic and update bal files <nl> - update tests and fix broken tests .,0.9477279186248779
apache_pulsar/10648,transaction admin api get transaction coordinator status . <cm-sep> fix some test <cm-sep> transaction admin api get transaction in pending ack stats . <para-sep> get transaction in pending ack stats . <nl> get transaction in pending ack stats . <nl> the position of this transaction cumulative ack . * /,"this is transaction buffer metrics . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment",1621477075,"this means that creation/update of connectors with improper config can be rejected outright at request time rather than at runtime which is the current case . this will lead to faster troubleshooting when developing and running connectors . we make this check gated by a worker config parameter - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a",0.9784852266311646
apache_incubator-pinot/6372,"fixing the init fields in record extractor , as the fields might be modified after the init call <para-sep> extract from json with path to string <nl> extract from json with path to long <nl> extract from json with path to double","the issue found was that this field set used to init recordextractor might be modified after , so we should n't reply on it . <nl> discovered this when debugging a realtime table with all columns extracting from a json payload object . in the init call , this payload field is there , but when doing the real msg decoder , the same class only contains fields in schema and the payload field is gone . <nl> 0. adding jsonpath functions with a default value , to avoid ingestion stop or msg loss .",1608331527,adding alert self service with minimal configurations .,0.9683669209480286
apache_druid/10976,fix kinesis increament throwaway on eos record <cm-sep> fix checkstyle <para-sep> we do not count end of shard record as thrown away event since this is a record created by druid note that this only applies to kinesis <nl> verify that event thrown away count was not incremented by the reshard <nl> failed task may not have a task stats report . we can ignore it as the task did not consume any data,fix kinesis should not increment throwaway count on eos record . <nl> druid writes a record with the sequence number ' eos ' to kinesis stream when kinesis stream is re-shard ( i.e . number of shard increased ) . druid then consume this record ( with the sequence number ' eos ' ) and see that it is empty and increment the ' throwaway ' count . we should not increment the ' throwaway ' count as the record was generated by druid and incrementing the ' throwaway ' count makes it very difficult to determine if any data,1615414735,drop segment will now use the balancer to get an iterator of objects which can be consumed to get the best candidate servers to drop segments from .,0.9625024795532227
vespa-engine_vespa/17972,do n't create test driver twice <cm-sep> upgrade httpclient5 to version,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621958424,"no longer return empty response with content-type , instead use ( only used by 0 endspoints ) . <nl> return better json responses for restart and deactivate application . <nl> in access logs i only found a few s , few requests from browsers and 0 % from , all of which should handle this change . ( current will return a for restart/deactivate , so that will be a json string , we can change that to just extract the message field later .",0.9013497233390808
runelite_runelite/13011,modified widgetid class shop items_container from 0 to 0 to bring in line with in-game shop item container widget .,modified widgetid class shop items_container from 0 to 0 to bring in line with in-game shop item container widget .,1609890708,default idle notifications will execute when animation 0 ( pisc crane repair ) has ended .,0.854902982711792
runelite_runelite/13485,update falador hard task text to match update,all diary steps involving runecraft now specify that the runes must be crafted from essence rather than the cores dropped by the new golems . <nl> tested in game .,1618427958,ingame text has been changed to stop referring to the five cities of great kourend as zeah houses,0.9056915044784546
apache_druid/11091,"unit tests for timeout exception in init <cm-sep> integration tests <cm-sep> run integraion test on travis <para-sep> this server manager is designed to test various query failures . - missing segments . a segment can be missing during a query if a historical drops the segment after the broker issues the query to the historical . to mimic this situation , the historical with this server manager announces all segments assigned , but reports missing segments for the first 0 segments specified in the query . see itqueryretrytestonmissingsegments . - other query errors . this server manager returns a sequence that always throws an exception based on a given query context value . see itqueryerrortest . <nl> query context key that indicates this query is for query retry testing . <nl> this class tests various query failures . - sql planning failures . - various query errors from historicals . <nl> a simple query used for error tests from historicals . what query is does not matter because the query is always expected to fail . <nl> a simple sql query template used for plan failure tests . <nl> ensure that wikipedia segments are loaded completely <nl> test a sql without select <nl> test a sql that selects unknown column <nl> disable cache so that each run hits historical . <nl> segments . <nl> this method is visible for testing query retry on missing segments .","to easily test query errors from historicals , is refactored to mimic other query failures",1618035126,"adds a druid expression to allow use in and , as well as sql virtual column expression support .",0.9761682748794556
apache_kafka/10786,: integrate controller snapshoting with raft client,"directly use , and in the quorum controller . <nl> 0. allow users to create snapshots by specifying the last committed offset and last committed epoch . these values are validated against the log and leader epoch cache . <nl> 0. remove duplicate classes in the metadata module for writing and reading snapshots . <nl> 0. changed the logic for comparing snapshots . the old logic was assuming a certain batch grouping . this did n't match the implementation of the snapshot writer . the snapshot writer is free to merge batches before writing them . <nl> 0. improve to",1622230246,"in kafka streams the source-of-truth of a state store is in its changelog , therefore when committing a state store we only need to make sure its changelog records are all flushed and committed , but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary . <nl> on the other hand , flushing a state store too frequently may have side effects , e.g . rocksdb flushing would gets the memtable into an l0 sstable , leaving many small l0 files",0.9701818227767944
elastic_elasticsearch/72871,"for geotileaggregation , the relationship between the grid and the bounded box <nl> can be disjoint . <para-sep> todo : optimize for when a shape fits in a single tile an <nl> this makes validtile ( ) always return false <nl> compute minx , miny <nl> touching tiles are excluded , they need to share at least one interior point <nl> compute maxx , maxy <nl> touching tiles are excluded , they need to share at least one interior point","for geotileaggregation , the relationship between the grid and the bounded box <nl> currently for precision 0 we always assume that document match the bucket that gets generated . this might not be true for bounded geo tile aggregations where the bounding box is out of range for the area covered by this aggregation . therefore this pr removes the allcellvalues implementation . <nl> in addition , this pr refactor all geogridtest in order to share as many test as possible .",1620631077,"this merges the global-ordinals-based implementation for <nl> into the global-ordinals-based implementation of <nl> , removing a bunch of copy and pasted code that is subtly <nl> different across the two implementations and replacing it with an <nl> explicit with nice stuff like javadoc . <nl> the actual behavior is mostly unchanged , though i was able to remove a <nl> redundant copy of bytes representing the string from the result <nl> construction phase of .",0.9725988507270813
elastic_elasticsearch/73761,"reroute when new repository is registered . <nl> today we fail to allocate searchable snapshot shards if the repository <nl> containing their underlying data is not registered with the cluster . <nl> this failure is somewhat messy , we allocate them and let the recovery <nl> fail , and furthermore we do n't automatically retry the allocation if the <nl> repository is subsequently registered . <nl> this commit introduces an allocation decider to prevent the allocation <nl> of such shards , and explain more clearly why , and also a cluster state <nl> listener that performs a reroute when a new repository is registered . <para-sep> take snapshot containing the actual data to one repository <nl> back up the cluster to a different repo <nl> clear out data & the repo that contains it <nl> restore the backup snapshot <nl> re-register the repository containing the actual data & verify that the shards are now allocated <nl> we always force snapshot recovery source to use the snapshot-based recovery process on the node","today we fail to allocate searchable snapshot shards if the repository <nl> containing their underlying data is not registered with the cluster . <nl> this failure is somewhat messy , we allocate them and let the recovery <nl> fail , and furthermore we do n't automatically retry the allocation if the <nl> repository is subsequently registered . <nl> this commit introduces an allocation decider to prevent the allocation <nl> of such shards , and explain more clearly why , and also a cluster state <nl> listener that performs a reroute when a new repository is registered .",1622807714,today a coordinating node does not have ( easy ) access to the mappings <nl> for the indices for the searches it wishes to coordinate . this means it <nl> ca n't properly interpret a timestamp range filter in a query and must <nl> involve a copy of every shard in at least the phase . it <nl> therefore can not cope with cases when shards are temporarily not started <nl> even if those shards are irrelevant to the search . <nl> this commit captures the mapping of the field for indices <nl> which expose a timestamp range in their,0.9785236716270447
apache_ignite/9161,fix tests ignitecachelocalquerydefaulttimeoutselftest for lazy=true mode <para-sep> * / <nl> lazy mode . * / <nl> execute update queries . * / <nl> execute local queries . * / <nl> * /,fix tests ignitecachelocalquerydefaulttimeoutselftest for lazy=true mode .,1623231743,the following test are combined into one parametrized jdbcthinbulkloadselftest : . <nl> jdbcthinbulkloadatomicpartitionednearselftest <nl> jdbcthinbulkloadatomicpartitionedselftest <nl> jdbcthinbulkloadatomicreplicatedselftest <nl> jdbcthinbulkloadtransactionalpartitionednearselftest <nl> jdbcthinbulkloadtransactionalpartitionedselftest <nl> jdbcthinbulkloadtransactionalreplicatedselftest,0.9501855373382568
vespa-engine_vespa/17376,"control cased/uncased in dictionary setting <cm-sep> add cased/uncased to match settings too . <nl> only allow btree uncase/uncased , and hash : cased/cased for now . <para-sep> set the matching type for this field and all subfields . todo : when this is not the same as getmatching ( ) .setthis we have a potential for inconsistency . find the right matching object for struct fields as lookup time instead .",lowercasing control is up next .,1618235680,support global routing control of deployments using rotations as well . the <nl> existing implementation of this is in internal repo and will be <nl> removed/simplified .,0.9694141745567322
jenkinsci_jenkins/5451,enable avoidnoargumentsuperconstructorcall checkstyle check <cm-sep> enable annotationusestyle checkstyle check <cm-sep> enable noenumtrailingcomma checkstyle check,"enables the , , and checkstyle checks and fixes all violations . the motivation is to make the code easier to read by using a consistent style throughout .",1619624505,"fixed following spotbugs issues in core : . <nl> * wmi_wrong_map_iterator <nl> * os_open_stream <nl> * va_format_string_uses_newline <nl> * minor code improvements ( diamond operator , removed unused import ) . <nl> * internal : fixed spotbugs issues . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8828667998313904
ballerina-platform_ballerina-lang/27422,use the correct loadproject method <cm-sep> use build distribution cache as the test file system cache . <nl> this commit also removes an unused method getproject as it is <nl> replaced by the loadproject method . <cm-sep> enable symbolbirtest,this pr also removes an unused method getproject as it is replaced by the loadproject method .,1607543282,in here readbytelength is redundant . so the new read api is read ( int length ) returns byte [ ] |io : error . <nl> fixes # .,0.8764426708221436
elastic_elasticsearch/74402,"move and rename parsercontext . <nl> parsercontext is an inner class of mapper.typeparser but is used outside of the context of parsing mappers , for instance also to parse runtime fields . its purpose is to be used to parse mappings in general , and its name is confusing as it differs ever so slightly from parsecontext which is used for parsing incoming documents . <nl> this commit moves parsercontext to be a top-level class , and renames it to mappingsparsercontext . <para-sep> holds everything that is needed to parse mappings . this is carried around while parsing mappings whether that be from a dynamic template or from index mappings themselves . <nl> true if this pars context is coming from parsing dynamic template mappings","parsercontext is an inner class of mapper.typeparser but is used outside of the context of parsing mappers , for instance also to parse runtime fields . its purpose is to be used to parse mappings in general , and its name is confusing as it differs ever so slightly from parsecontext which is used for parsing incoming documents . <nl> this commit moves parsercontext to be a top-level class , and renames it to mappingsparsercontext .",1624350743,this pr renames : <nl> - to <nl> - to <nl> - to <nl> - classes to .,0.935401201248169
apache_pulsar/10647,": initialize managedledgerfactory with metadatastore <para-sep> delete all managed ledger resources and metadata . <nl> factory to create bookkeeper-client for a given ensembleplacementpolicy . <nl> only one copy of the offload metadata information is stored in metadata store ,",pass the metadatastore instance from pulsarservice directly to . there are not anymore interactions of managedledger with zookeeper .,1621476759,"currently , in functions internal code , temporary files are created for purposes of downloading function packages locally . these files care never cleaned up and may linger around for a long time . in the best case , this will only cause storage to be unnecessarily wasted but in the worst case this can cause memory issues ( which usually is going to be a lot smaller than storage ) especially for brokers/workers running in containers since the whole filesystem is just in memory . <nl> clean up the temporary files that are created . to do this i",0.9704285264015198
apache_pulsar/10957,"fix nonrecoverableledgerexception when get last message id by reader . <nl> if a topic only have non-durable subscriptions or mark delete position of all the durable subscriptions <nl> are reached the lac , all the ledgers except the current ledger will be deleted . <nl> since the current ledger may not have any data , occurs nonrecoverableledgerexception in the broker side . <nl> in this case , the we should return the message id ( 0 , 0 ) . <para-sep> in this case , the ledgers been removed except the current ledger and current ledger without any data <nl> if a topic only have non-durable subscriptions or mark delete position of all the durable subscriptions are reached the lac , all the ledgers except the current ledger will be deleted . since the current ledger may not have any data , so the test is to ensure the get last message id api can work in this case . in this case , the we should return the message id ( 0 , 0 ) . <nl> to trigger the ledger rollover <nl> this will call the get last message id api .","if a topic only have non-durable subscriptions or mark delete position of all the durable subscriptions <nl> are reached the lac , all the ledgers except the current ledger will be deleted . <nl> since the current ledger may not have any data , occurs nonrecoverableledgerexception in the broker side . <nl> in this case , we should return the message id ( 0 , 0 ) if ca n't read the entry of the lac . <nl> here is the exception stack : . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does",1623934254,"# # # motivation <nl> upgrade to latest stable zk version version . the new minor versions brings several advantages : . <nl> performance improvements ( eg : tuning group commit on txn log ) <nl> prometheus based metrics ( so that we can get rid of aspectj hacky way to instrument zk ) <nl> new features like persistent recursive watches which would greatly simplify the logic to handle metadata cache invalidations . <nl> the possibility of rollback to previous version has also been validated . <nl> - this change is already covered by existing tests , such as (",0.9368693828582764
OpenAPITools_openapi-generator/8963,fix deprecation warning : bodyinserters.fromobject .,to validate this run the java generator with the webclient library no deprecation warning should be displayed anymore .,1615576966,no impact to samples after generation .,1.0
apache_beam/14342,support multilayer unnest <cm-sep> fix bug in beamunnestrule as well,"support multilayer zetasql unnest . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1616717725,"adds for overriding the query planner specified in pipelineoptions . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.8893756866455078
vespa-engine_vespa/17310,move nodes to 'failed ' during activate <para-sep> returns a copy of this where wanttofail is set to true and history is updated to reflect this . <nl> returns the subset of nodes with want to fail set to true * / <nl> reset want to fail : we 'll retry failing unless it heals in the meantime <nl> this node was scheduled for failing <nl> fails these nodes in a transaction and returns the nodes in the new state which will hold if the transaction commits . <nl> returns whether this node should be de-provisioned when possible . <nl> returns a copy of this with want to fail set to the given value * / <nl> returns whether this node should be failed * /,node failing was based on a quick hack where we made a change to active nodes outside deployment . <nl> this fixes that by introducing a wanttofail setting .,1617886789,"extends to collect rotation status metrics and <nl> write them to zk . currently it will store the result of the default <nl> implementation of ( empty map ) . <nl> once the real implementation of learns how to fetch these <nl> metrics and has run at least once in production , <nl> we can change the application api to use the cached values . <nl> this can safely be merged as it does not depend on changes to internal code .",0.9632824063301086
apache_pulsar/11009,fix flaky test testenableanddisabletopicdelayeddelivery <cm-sep> fix flaky test testenableanddisabletopicdelayeddelivery,"# # # motivation <nl> when is executed , topicpolicies may not be initialized yet . <nl> this problem occurs when only a single unit test is executed . <nl> when the entire unit test is executed , it rarely appears , because other unit tests initialize the topicpolicies under this namespace",1624329205,we have observed a deadlock that happens when consumers are added because isconsumersexceededontopic and isconsumersexceededonsubscription are blocking calls even though addconsumer is called in async fashion . <nl> make the calls isconsumersexceededontopic and isconsumersexceededonsubscription nonblocking by only getting the data from cache and not going to zk . there can be instances when the data is stale but it should be rare since the data is like already in cache . the more permanent solution would be to make those calls async and addconsumer async but that requires a big change . we are currently in the process of refactoring,0.877930223941803
keycloak_keycloak/8053,"simple validation api . <nl> return validationcontext with the outcome of the validation in validate methods . <nl> move validator lookup from keycloaksession into dedicated validatorlookup class for now . <nl> validator spi polishing . <nl> move validator spi to server-spi-private for now . <nl> add test to demonstrate validator config validation . <nl> add support for context-less validations . <nl> introduce validatorconfig and add some default validator implementations . <nl> add license headers . <nl> revise builtinvalidators . <nl> validator polishing . <nl> allow lookups for validatorfactories for dynamic config validation . <nl> revise validatortests . <nl> validator polishing . <nl> add example for nested validation . <nl> refactor validator api . <nl> refactor validator api . <nl> - merged builtinvalidators and validatorlookup into validators facade class . <nl> ease validation of validatorconfigs . <nl> assume validatorconfig 's are valid for validator 's that do n't support config . <nl> make built-in validator method names more for static imports . <nl> revise validation api according to discussions from code review . <nl> pass keycloaksession to validatorconfig validation methods . <nl> this allows validatorconfig validations to access services as well as <nl> the current keycloakcontext . <nl> revise validation api according to discussions from code review . <nl> - derive valid state from errors in validationcontext <nl> - simplify validationresult by not inheriting from consumer > <nl> - add addtional test cases . <nl> revise validation api according to discussions from code review . <nl> - revise numbervalidator to only check for double conversion <nl> - removed support for string based regex pattern . <nl> ease validation of validatorconfig <para-sep> base class for arbitrary value type validators . functionality covered in this base class : accepts supported type , collection of supported type . null values are always treated as valid to support optional fields ! <nl> validate type , format , range of the value etc . can be called multiple time for one validation if input is collection . <nl> base class for string value format validators . <nl> noop <nl> noop <nl> noop <nl> holds information about the validation state . <nl> we deliberately use a linkedhashset here to retain the order of errors . <nl> denotes an error found during validation . <nl> a generic invalid value message . <nl> empty message parameters fly-weight . <nl> holds an inputhint . this could be a attribute name","it is refined to work for userprofile spi . main changes against the original pr : <nl> * default ' format ' validators like email , length , pattern etc improved to work on list of strings ( as userprofile attributes are list of strings ) . added reusable abstract base classes to make implementation for this kind of validators easier . <nl> * improved handling of null values in default validators ( treated as valid values now ) to allow format validations for optional attributes in userprofile .",1621353463,works for as7/eap 0 and wildfly/eap7,0.9797196388244629
apache_beam/14332,"validate casts from double literals to numeric during expression conversion . <nl> numeric values in zetasql are subject to constraints : they must fall within certain hardcoded limits , and the scale also can not exceed 0. currently we have stricter constraints than these when preparing the expression in beamzetasqlcalcrel due to . however , to force beamcalcrel to have correct behavior , we should check the constraints earlier , during expression conversion . <para-sep> maximum and minimum allowed values for the numeric/decimal data type . <nl> number of digits after the decimal point supported by the numeric data type . <nl> tests for zetasql number type handling ( on int64 , double , numeric types ) . * /","validate casts from double literals to numeric during expression conversion . <nl> numeric values in zetasql are subject to constraints : they must fall within certain hardcoded limits , and the scale also can not exceed 0. currently we have stricter constraints than these when preparing the expression in beamzetasqlcalcrel due to . however , to force beamcalcrel to have correct behavior , we should check the constraints earlier , during expression conversion",1616628463,"an it for mongodbio . <nl> i suggested different kubernetes scripts naming for mongo than for postgres scripts . the postgres ' naming is quite confusing to me - the ' local ' scripts are used everywhere right now , not only while running tests locally , so why call them ' local ' ? <nl> there is another thing that bothers me : the node port service kubernetes setup can be used only if the whole test ( including and methods ) is run in the same network , as the k8 cluster is ( to have direct access",0.957682728767395
apache_ignite/8980,"evt_client_node_disconnected is not triggered in k8s . <nl> * fixed tcpdiscoveryspi might be stuck infinitely resolving ip addresses , now the process is configurable either using nettimeout or jointimeout depending on a process . <nl> ( cherry picked from commit sha ) <para-sep> time when resolution process started . <nl> * / <nl> listening test logger . * / <nl> * / <nl> * / <nl> * / <nl> tests server node disconnection with dynamic ip finder . server node should catch node_left event , no calls to ip resolver . <nl> tests server node disconnection with static ip finder . server node should catch node_left event , no calls to ip resolver . <nl> * / <nl> tests that dynamic ip finder does n't allow server node to join topology if ipresolver is unavailable and jointimeout is not specified . server node should be constantly trying to obtain ip addresses . <nl> tests that static ip finder does n't allow server node to join topology if ipresolver is unavailable and jointimeout is set to 0 server node should be constantly trying to obtain ip addresses . <nl> tests that broken static ip finder allows server node to join topology when jointimeout expires . <nl> tests shared ip finder with empty list allows server to start . <nl> tests non shared ip finder with empty list is not allowed . <nl> gets node configuration with dynamic ip finder . <nl> gets node configuration with dynamic ip finder . <nl> gets node configuration with dynamic ip finder . <nl> shared ipfinder implementation for testing purposes . <nl> * / <nl> ctor . <nl> simulates service fail . <nl> super class for kubernetes discovery tests . * / <nl> mock of kubernetes api . * / <nl> * / <nl> * / <nl> * / <nl> * / <nl> * / <nl> * / <nl> mocks http server response . <nl> mocks http server response . <nl> * / <nl> * / <nl> * / <nl> test that client node is disconnected from a cluster if kubernetesipfinder fails . <nl> * / <nl> * / <nl> tests that client is disconnected with default settings . * / <nl> runs disconnection test and check that a client is disconnected from the grid . <nl> runs disconnection test and check that a client is connected to the grid .","* fixed tcpdiscoveryspi might be stuck infinitely resolving ip addresses , now the process is configurable either using nettimeout or jointimeout depending on a process . <nl> ( cherry picked from commit sha ) .",1617795062,fix memory leak on unstable topology caused by partition reservation,0.959313154220581
apache_flink/15707,"remove unnecessary field <para-sep> this test is known to be unstable , but the exact cause is unknown","beefs up the to allow configuring retries per class , and subsequently sets up retries for the entire . <nl> to avoid inconsistent/unexpeced behaviors when combinding class-wide retries with expected exceptions , the latter are now properly handled by the retry rule ( i.e. , if they occur then we do n't retry and just rethrow the exception ) . <nl> the existing pattern of annotating single methods was not really viable for this case because various tests are inherited from a parent class , which we could only annotated by overriding each of them . <nl> this seemed like",1619012996,"fixes an instability in the where the shutdown of the dispatcher caused a slot allocation to fail , resulting in the job failing , reaching a terminal state and afterwards being removed from zookeeper . <nl> we now prevent the job from reaching a terminal state by enabling a fixed-delay restart strategy . should the allocation fail the jm will retry until the jm itself is being shut down . on shutdown the jm will suspend the job , allowing it to be recovered by other dispatchers . <nl> i verified the fix by re-running the test until i ran",0.847529947757721
apache_beam/13638,"only drop event_timestamp when it exists <para-sep> if a timestamp attribute is used , make sure the timestamp_field is propagated to the element 's event time . pubsubio will populate the attribute from there . <nl> warn the user if they 're writing data to timestamp_field , but event timestamp is mapped to publish time . the data will be dropped .","see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1609376866,"this pr fix it by following the same way that bigquery handles unspecified or duplicate field name . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",0.9037896990776062
netty_netty/11237,disable tlsv1 and tlsv1.0 by default . <nl> motivation : . <nl> tlsv1 and tlsv1.0 is considered insecure . let 's follow the jdk and disable these by default . <nl> modifications : . <nl> disable tlsv1 and tlsv1.0 by default when using openssl . <nl> result : . <nl> use only strong tls versions by default when using openssl <para-sep> expected,motivation : . <nl> tlsv1 and tlsv1.0 is considered insecure . let 's follow the jdk and disable these by default . <nl> modifications : . <nl> disable tlsv1 and tlsv1.0 by default when using openssl . <nl> result : . <nl> use only strong tls versions by default when using openssl,1620635333,opensslsession.getlocalcertificates ( ) and getlocalprincipal ( ) must return null on client side if mtls is not used . <nl> motivation : . <nl> opensslsession.getlocalcertificates ( ) and getlocalprincipal ( ) must return null on client side if mtls is not used as stated in the api documentation . at the moment this is not always the case . <nl> modifications : . <nl> - ensure we only return non-null if mtls is used <nl> - add unit tests . <nl> result : . <nl> follow sslsession api contract,0.9504488110542297
runelite_runelite/13763,"create startenddata value to track start and end of conversations <cm-sep> fix childid so we stop getting bad data and add start/end data values to track conversations better <cm-sep> fix comments <para-sep> if we were not in a conversation , but now one of these widgets is not null , we have started a conversation . else if we were in a conversation , but now there is no widget , we have left the conversation .","- change childid for from 0 to 0 <nl> - without this change , we are getting junk data instead of player dialogue <nl> - add a new data type to mark the beginning and end of conversations for better parsing in post",1624210988,"examining an item when the looting bag was open was n't implemented , so went ahead and added a case within the examine plugin to handle that . also went ahead and added the groupid and childid for the looting bag for future usage within widgetid and widgetinfo along with fixing a typo in a comment .",0.9021174311637878
elastic_elasticsearch/73650,[ 0.x ] delete mounted indices after in searchable snapshots yaml tests <cm-sep> revert ' [ 0.x ] delete mounted indices after in searchable snapshots yaml tests ' . <nl> this reverts commit sha . <cm-sep> add wipesearchablesnapshotsindices <cm-sep> adjust version <cm-sep> of course <cm-sep> found the culprit <cm-sep> ifs <para-sep> returns whether to preserve searchable snapshots indices . defaults to not preserving them . only runs at all if xpack is installed on the cluster being tested . <nl> clean up searchable snapshots indices before deleting snapshots and repositories <nl> retrieves all indices with a type of store equals to ' snapshot ',"this commit adds some clean up logic to esresttestcase so that searchable snapshots indices are deleted after test case executions , before the snapshot and repositories are wipe out .",1622622065,"as requestoptions add requestconfig , users can set some request config per request , e.g sockettimeout . <nl> without requestconfig , sockettimeout can only set in restclient init . <nl> as different kind of request maybe have different request options , users can set requestconfig optional .",0.9284741878509521
apache_pulsar/10249,add tests for test retries <cm-sep> add test for excludedgroups <cm-sep> test retries with fail-fast mode <cm-sep> decouple pulsartestlistener and failfastnotifier <cm-sep> speed up execution of flaky test group,"since the improvements in tests have been made to reduce resource leaks , it is now possible to remove parameter used in the execution of the broker_flaky test group ( part of workflow ) . <nl> this will make the execution of a lot faster . the execution time drops from 1h 20h 40mins to about 0 minutes . <nl> this pr also includes some minor improvements to test listeners and adds better test coverage to verify the behavior . <nl> - remove and change to for / test group . <nl> - add better test coverage for testng listeners",1618597506,"avoid using same opaddentry between different ledger handles . <nl> add state for opaddentry , if op handled by new ledger handle , the op will set to closed state , after the legacy callback happens will check the op state , only initiated can be processed . <nl> when ledger rollover happens , pendingaddentries will be processed . when process pendingaddentries , will create a new opaddentry by the old opaddentry to avoid different ledger handles use same opaddentry . <nl> added new unit test . <nl> if was chosen , please highlight the changes . <nl> - dependencies",0.9366251230239868
Alluxio_alluxio/12795,add option for concurrent job count,"commands like distributedload and distributedcp submits jobs to the cluster job service . the command creates 0 job for each file . by default the command allows up to 0 jobs to be submitted and waiting for completion . when there are many distributedload/cp commands running by many users , there may be too many jobs in the queue for the job service . <nl> this change intends to add a way to throttle the job submission speed at the command side . especially when the distributedload/cp jobs are submitted with automated scripts , we may want less than 0",1612244396,"the setattribute rpc in the client works via omission of <nl> properties . if a property is included within the rpc options <nl> object , then it is assumed the user set this property and <nl> should then be set on the inode . this works for all fields <nl> within the setattribute call except for the sync interval . <nl> the metadata sync interval must be included on client rpcs . <nl> otherwise , if it is not included , then the <nl> defaultfilesystemmaster will assume that the user has <nl> implicitly set a sync interval of 0 -",0.9231238961219788
OpenAPITools_openapi-generator/8908,adds getter and setter for additionalpropertiesisanytype in ijsonschemavalidationproperties <cm-sep> removes venv <cm-sep> implements getter and setter in codegenmodel <cm-sep> implements getter and setter in codegenproperty <cm-sep> implements getter and setter in codegenparameter <cm-sep> adds getter and setter in codegenresponse <cm-sep> creates setaddprops <para-sep> recursively look in schema sc for the discriminator discpropname and return a codegenproperty with the datatype and required params set the returned codegenproperty may not be required and it may not be of type string,"adds getadditionalpropertiesisanytype/setadditionalpropertiesisanytype to java schema classes <nl> this is needed if one is generating classes for object schemas . <nl> by default object schema includes additionalproperties = anytype , so if this boolean is false , then one needs to generate a custom class for the object schema . <nl> tests added of x.getadditionalpropertiesisanytype for : <nl> - codegenmodel <nl> - codegenproperty <nl> - codegenparameter <nl> - codegenresponse .",1615020660,i want to embed annotation when in kotlin-spring .,0.9522484540939331
apache_pulsar/11022,fix transaction ca n't init pending ack and tc persistent topic . <para-sep> pulsar client transaction test .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1624367333,"0. expose consumer names after the mark delete position for the key_shared subscription . <nl> 0. remove the consumer from the recenlyjoinedconsumer depends on the valid next position of the next position . previously , we use the position.nextposition to decide to remove the consumer from the recenlyjoinedconsumer but this will lead to consumers ca n't be deleted property . for example , if ledger rollover and the mark delete position is the last position of the old ledger and the max read position is the first position of the new ledger , in this situation , we should remove",0.9699552655220032
jenkinsci_jenkins/5282,reload update center data on upgrade/downgrade <para-sep> schedule an update of the update center after a jenkins upgrade <nl> schedule an update of the update center after a jenkins downgrade,"i 've done quite a bit of interactive testing with this and it works from what i can tell both for upgrade and downgrade . <nl> upgrade testing was done from version to a local built snapshot . downgrade testing was just changing the version in and making sure the code was executed . <nl> , reload update center data on upgrade/downgrade",1613084734,"actually this patch adds some diagnostics instead of the unchecked class cast we had here before . <nl> * , bug , - prevent unhandled classcastexception when loading fingerprints from corrupted files <nl> * .. . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9252325296401978
prestodb_presto/16036,"track column statistics only in recoverable mode . <nl> data in statistics pages is final for any completed <nl> task in non-recoverable mode . <cm-sep> allow statisitcs page reset in lifespanandstagestate . <nl> the total memory for all statistics page could be <nl> large and cause full gc issue . removing page that <nl> will not be accessed . <cm-sep> track system memory in tablefinishoperator . <nl> column statistics and partitionupdate could be <nl> memory expensive , for example , in grouped execution .","- commit will improve presto on spark driver memory as pos uses strategy . <nl> test plan . <nl> - built a custom package and deployed to a real cluster with shadowed queries . <nl> - enable large batch mode , set , to increase memory used for stats collection . running shadow query for 0 hr , no full gc found in coordinator . <nl> ` <nl> == release notes == . <nl> general changes <nl> * track system memory used by column statistics in tablefinishoperator .",1620063353,add a version of testhiveclientinmemorymetastore with filter pushdown enabled . this test enabled testing of coercions and bucket adaptation for the aria scan . the support for coercions and bucket adaptation will come in future prs .,0.9171314835548401
ballerina-platform_ballerina-lang/28874,"fix stackoverflow error in record field completions . <nl> when a record contains a required field of same type as the record , <nl> commonutil throws a stackoverflow error . fixed that by checking <nl> if a field is of same type as the record .",fixed that by checking <nl> if a field is of same type as the record .,1614183375,fix object create value method to populate field values .,0.8818985819816589
apache_incubator-pinot/6651,"when default value is available , do n't throw exception in json_extract_scalar function . <para-sep> evaluate json_extract_scalar over string column that does not contain valid json data . * / <nl> json_extract_scalar throws exception since we are trying to parse a non-json string . <nl> json parsing exception expected . <nl> json data is stored in columns of type string , so there is nothing preventing the column from storing bad json string . bad json string in columns will cause json_extract_scalar to throw an exception which would terminate query processing . however , when json_extract_scalar is used within the where clause , we should return the default value instead of throwing exception . this will allow the predicate to be evaluated to either true or false and hence allow the query to complete successfully . returning default value from json_extract_scalar is an undocumented feature . ideally , json_extract_scalar should return null when it encounters bad json . however , null support is currently pending , so this is the best we can do . <nl> none of the values in stringcolumn are valid json . hence , json_extract_scalar should default to ' 0 ' for all rows and count returned by the query should be 0 ( same as number of rows in the table ) .","bad json string in columns will cause json_extract_scalar to throw an exception which would terminate query processing . however , when json_extract_scalar is used within the where clause , we should return the default value instead of throwing exception . this will allow the predicate to be evaluated to either true or false and hence allow the query to complete successfully . returning default value from json_extract_scalar is an undocumented feature . ideally , json_extract_scalar should return null in when it encounters bad json . however , null support is currently pending , so this is the best we can",1614979572,adding ability to override controllerrestapi in custom implementations of segmentpreprocessingjob,0.911485493183136
confluentinc_ksql/7399,"set confluent to version , kafka to version . <para-sep> release version version-0 <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- > <nl> -- >",unit and integration tests are expected for any behavior changes._ .,1618924520,"why ? mainly because the code does not care about these two types having a common base class . is just a helper . so composition is preferable to inheritance . <nl> also , it reduces the temptation to place inappropriate code in which is intended as a generic helper , and should not know about specific properties . <nl> non-functional change .",0.9378325343132019
elastic_elasticsearch/72599,remove multiple paths from nodeenvironment . <nl> this commit converts the multiple paths and locks internal to <nl> nodeenvironment into a singular data path .,this commit converts the multiple paths and locks internal to <nl> nodeenvironment into a singular data path .,1619987696,this change delays the decoding of the indexed triangles to the tree writer so we do not need to do it up front . in addition it changes the tree writing classes to static methods .,0.9416101574897766
gocd_gocd/8572,"provide auto complete information on secret configs spa <cm-sep> update package repository name from the config . <nl> - earlier package repository name held no significance while execution . now with support for secrets , the package repo name should we updated along with the configuration values <cm-sep> update the pluggable scm name from config <nl> - since the rules validation is on pluggable scm name , the material should have the name updated from the config",description : <nl> - provide auto_complete support on secrets spa <nl> - update package repository name in the package material while building work to be executed <nl> - same with plugin materials - update pluggable scm name .,1600683682,note i have signed the cla . <nl> description : <nl> we think that adding a go_agent_resources environment variable with a comma-separated or json/yaml list of assigned agent resources would help in continuous delivery situations where the devops people want to get smart/fancy about how pipelines execute . in our case it unblocks using more agents for cm with ansible .,0.872970461845398
ballerina-platform_ballerina-lang/29690,"make whitespace positions within service decl return empty symbols <cm-sep> add rename tests for renaming from within service decl <para-sep> a service decl is a special case . since there is n't a name associated with it , we take the starting position of the node to lookup the service symbol .","instead of checking whether the cursor was within the the service node , checked whether the cursor is at the start of the service declaration node .",1617032962,this pr add quoted identifier support to const declarations . <nl> fixes # .,0.8885858654975891
elastic_elasticsearch/74105,"api key authcache is set to expire after write ( by default 0 hours ) . <nl> expireafterwrite is generally preferred over expireafteraccess because it <nl> guarantees stale entries get evicted eventually in edge cases , e.g . when the <nl> cache misses a notification from the cluster . <nl> however , things are a bit different for the authcache . there is an additional <nl> roundtrip to the security index for fetching the api key document . if the <nl> document does not exists ( removed due to expiration ) or is invalidated , the <nl> authentication fails earlier on without even consulting the authcache . this <nl> means the stale entries wo n't cause any security issues when they exist . <nl> therefore , this pr changes the authcache to be expire after access , which helps <nl> preventing potential cyclic surge of expensive hash computations especially <nl> when a large number of api keys are in use . <nl> to further help the cache efficiency , this pr also actively invalidates the <nl> authcache if the document is either not found or invalidated so it does not <nl> have to wait for 0 hour to happen . note that these are all edge cases and we <nl> do n't expect them to happen often ( if at all ) . <cm-sep> fix for 0.x quirks <para-sep> pkg private for testing","api key authcache is set to expire after write ( by default 0 hours ) . <nl> expireafterwrite is generally preferred over expireafteraccess because it <nl> guarantees stale entries get evicted eventually in edge cases , e.g . when the <nl> cache misses a notification from the cluster . <nl> however , things are a bit different for the authcache . there is an additional <nl> roundtrip to the security index for fetching the api key document . if the <nl> document does not exists ( removed due to expiration ) or is invalidated , the <nl> authentication fails earlier",1623715300,"this commit adjusts the behavior when calculating the diff between two <nl> objects , so that the default values of settings <nl> whose default values depend on the values of other settings are <nl> correctly calculated . previously , when calculating the diff , the default <nl> value of a depended setting would be calculated based on the default <nl> value of the setting ( s ) it depends on , rather than the current value of <nl> those settings .",0.9493877291679382
elastic_elasticsearch/73955,"test for timezones . fails on purpose <cm-sep> yaml test for composite epoch seconds <cm-sep> force epoch into utc for format only <para-sep> test that if we format a datetime using the format , we can then parse the result back into the same value we started with , for all timezones ' why would you put a timezone on epoch_seconds ? it does n't make sense ' you might be asking . i was . the key to remember here is that we use the same time zone parameter for date histogram bucket generation and formatting . so , while asking for ( e.g . ) epoch_seconds in new york time is nonsensical , asking for day-buckets in new york time with the keys formatted in epoch_seconds is pretty standard . this test validates that if someone does this in composite , we can then parse the after key we generated into the correct value . parsing also happens on missing values . <nl> convert to seconds","date based aggregations accept a timezone , which gets applied to both the bucketing logic and the formatter . this is usually what you want , but in the case of date formats where a timezone does n't make any sense , it can create problems . in particular , our formatting logic and our parsing logic were doing different things for and formats with time zones . this led to a problem on composite where we 'd return an after key for the last bucket that would parse to a time before the last bucket , so instead of",1623247781,in addition it prevents a possible circuitbreaker leak during initialisation .,0.9301680326461792
hazelcast_hazelcast/18637,make the naming for timestamps consistent <cm-sep> cleanup <para-sep> hazelcast specific date-time types parsing . <nl> datetime <nl> todo : reduce to else branch once engines are merged and custom date-time parsing is used,"removed _pseudo type_ . <nl> extended with the possibility to use which is equivalent simply to . <nl> customized parser so it accepts instead of . <nl> as imdg engine still uses built-in parser , tests still reference instead of - ~left todos to change that once engines are merged~ .",1620197494,"this cleanup mostly removed warnings , moved tests to the correct package and aligns the naming schema of implementations ( cache did n't follow the map implementations here ) .",0.9511804580688477
vespa-engine_vespa/18309,"revert ' revert ' cleanup , no functional changes , take 0 ' ' <cm-sep> do n't print a line for every request",now it manages to run more than a few thousand requests as well ...,1623965766,last commit is the interesting one .,0.9395442605018616
apache_kafka/10492,added sentinel topic id to metadata topic <para-sep> a uuid for the metadata topic in kraft mode . will never be returned by the randomuuid method . <nl> return the topic id associated with the log . <nl> of the raft implementation . it uses a hard-coded topic . <nl> the topic id must be constant . <nl> return the topic id associated with the log .,"introduces topic ids to topics , but there is a small issue with how the metadata topic will interact with topic ids . <nl> in order to get these ids , brokers must fetch from the metadata topic . this leads to a sort of ' chicken and the egg ' problem concerning how we find out the metadata topic 's topic id . <nl> one solution proposed in was to introduce a ' sentinel id ' for the metadata topic . this is a reserved id for the metadata topic only . this pr adds the sentinel id when",1617739581,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.9101445078849792
elastic_elasticsearch/74099,geoip rework <cm-sep> fix <cm-sep> imports <cm-sep> remove unneeded method <cm-sep> imports <cm-sep> termination <para-sep> verify before updating dbs <nl> enable downloader : <nl> disable downloader :,this pr changes the way and handle situation when we are unable to update databases for 0 days . in that case : . <nl> - will delete all chunks from index <nl> - will delete all files on ingest nodes <nl> - will tag document with field ( same way as in logstash ) . <nl> this change also fixes bug with that breaks and when it tires to download databases after updating timestamp only ( checks if there are new databases and updates timestamp because local databases are up to date ),1623695689,"could actually call the internal method more than once on contention . <nl> if i read the javadocs , it says : . <nl> so , it could be getting multiple updates on contention , thus having a race condition where stats are double counted . <nl> to fix , i am going to use a . the objects allows fast thread safe writes in high contention environments . these can be protected by the . <nl> when stats are persisted , i need to call reset on all these adders . this is not thread safe if additions are",0.9714705944061279
neo4j_neo4j/11710,gbptreeplayground . <nl> tool for interactively make updates to a gbptree and see how it changes . <nl> useful during development and debugging . <para-sep> utility method,tool for interactively make updates to a gbptree and see how it changes . <nl> useful during development and debugging .,1525357073,changelog : added set-password command to neo4j-admin,0.983378529548645
ballerina-platform_ballerina-lang/28876,add jar conflict warning when generating executable <cm-sep> add listconflictedclasses to work with ballerina.toml <para-sep> print warnings for conflicted jars,the goal is to direct if the same class gets overwritten at executable jar creation . <nl> if the user wants to see conflicting classes he can use build option .,1614191703,now there are child buckets with values in both internal and external syntax tree nodes . but the public api does not expose those null values due to the usage of optional .,0.9722326993942261
elastic_elasticsearch/73778,<para-sep> a base parser implementation for point formats * / <nl> geopoint parser implementation * / <nl> note that this parser is only used for formatting values . <nl> cartesianpoint parser implementation * / <nl> note that this parser is only used for formatting values .,this interface has been added to be able to share the same parser implementation between different field mappers . this makes the generic from the parser be different to the generic of the class which breaks the symmetry with the geo_shape implementation and makes it harder to work with . <nl> this change moves the abstraction to the parser in order to simplify the classes and makes it more in-line with shape implementations .,1622820499,"this pr refactors all spatial field mappers to a common that implements shared parameter functionality ( e.g. , , ) and provides a common framework for overriding type parsing , and building in xpack . common shape functionality is implemented in a new that is reused and overridden in , , , and , respectively . this abstraction provides a reusable foundation for adding new xpack features ; such as coordinate reference system support .",0.9667670130729675
ballerina-platform_ballerina-lang/28464,"add custom diagnostic message for toml validator <cm-sep> add holder <cm-sep> refactor schema class <cm-sep> refactor toml schema visitor <cm-sep> address review suggestions <cm-sep> fix error messages <cm-sep> use toml parser schema validator for toml validations <cm-sep> fix package manifest tests & add all package entries to manifest <para-sep> validate ballerinatoml using ballerina toml schema <nl> check org is valid identifier <nl> check that the package name is valid <nl> check version is compatible with semver <nl> validate dependencies toml using dependencies toml schema <nl> negative tests <nl> package name is the root directory name <nl> org is user name <nl> version is version <nl> todo : need to remove manifest , it 's utils and tests .","also added licence , authors , keywords and repository to the class .",1612704181,> add annotation in the resource signature instead of having req.getqueryparamvalue ( string key ) function . <nl> > add annotation for path params .,0.9775798916816711
grpc_grpc-java/8205,"replace downstreamtlscontext by sslcontextprovidersupplier in the listener <para-sep> go thru the old listener and release all the old sslcontextprovidersupplier <nl> returns the sslcontextprovidersupplier from that filterchain , else null . <nl> locate a matching filter and return the corresponding sslcontextprovidersupplier or else return one from default filter chain . <nl> we want to increment the ref-count so call findorcreate again ...",use sslcontextprovidersupplier instead of downstreamtlscontext to ensure reference counting and lazy loading of sslcontextprovider 's in the current listener object .,1621963829,"the large changes are mostly in tests . please focus on non-test files first . <nl> in hierarchical s ( e.g. , ) or wrapped s ( e.g. , , the top-level receives state updates from the channel impl , and they almost always pass it down to its children s . <nl> sometimes the children s are not directly created by the parent , thus requires whatever api in the middle to also pass subchannel state updates , complicating that api . for example , the proposed includes solely to plumb state updates to where they are used .",0.9782992005348206
eclipse-openj9_openj9/11264,"remove java16 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java15 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java14 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java13 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java12 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java11 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove java10 preprocessor flag . <nl> * replace with 'java_spec_version > = 0 ' . <cm-sep> remove unused flag , 'open-module-support ' . <para-sep> [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / java_spec_version > = 0 / [ if java_spec_version = 0 ] / java_spec_version > = 0 / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / <nl> [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0/ [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0/ [ if java_spec_version > = 0 ] / java_spec_version > = 0 / [ if java_spec_version > = 0 ] / java_spec_version > = 0 / <nl> [ if java_spec_version > = 0 ] / java_spec_version > = 0/ <nl> [",* remove and replace with <nl> * remove and replace with <nl> * remove and replace with <nl> * remove and replace with <nl> * remove and replace with <nl> * remove and replace with <nl> * remove and replace with <nl> * remove unused flag,1606244472,"this pr should be purely comment changes for words ( or families of words ) that start w/ . <nl> to make my life easier , these initial comment focused prs will have 0 commits : <nl> * one which is the fixes <nl> * and one which is the copyright bumping . <nl> that branch will grow as i make progress ( i 've finished ) .",0.9056733250617981
elastic_elasticsearch/74143,make ilm steps use infinite master timeout . <nl> having a timeout on these internal ' requests ' <nl> only adds more noise if master is slow already when timed out steps trigger <nl> moves to the error step . <nl> it seems like it is safe to remove the setting for the timeout outright as well <nl> as it was not used anywhere and never documented as far as i can tell .,having a timeout on these internal ' requests ' <nl> only adds more noise if master is slow already when timed out steps trigger <nl> moves to the error step . <nl> it seems like it is safe to remove the setting for the timeout outright as well <nl> as it was not used anywhere and never documented as far as i can tell .,1623777985,"we recently removed getmapperservice from queryshardcontext in the attempt to avoid consumers depending on the whole mapperservice . searchcontext still has that problem although it is easier to solved as it can delegate to queryshardcontext for the most part , which is what this commit does for most of the existing usages .",0.9108448624610901
apache_druid/11200,add auto clean up <para-sep> remove terminated supervisors created before the given timestamp . <nl> terminated supervisor will have it 's latest supervisorspec as noopsupervisorspec ( noopsupervisorspec is used as a tombstone marker ) <nl> coordinatorduty for automatic deletion of terminated supervisors from the supervisor table in metadata storage . <nl> test that supervisor was inserted <nl> try delete . supervisor should not be deleted as it is still active <nl> test that supervisor was not deleted <nl> test that supervisor was inserted <nl> do delete . supervisor should be deleted as it is terminated <nl> verify that supervisor was actually deleted <nl> test that supervisor was inserted <nl> do delete . supervisor should not be deleted . supervisor is terminated but it was created just now so it 's created timestamp will be later than the timestamp 0-0-01t00:0:00z <nl> verify that supervisor was not deleted,add feature to automatically remove supervisors based on retention period . <nl> this pr adds a similar auto cleanup based on duration ( time to retained ) but for the supervisor table to auto clean up terminated supervisors . <nl> this is useful when druid user has a high churn of task / datasource in a short amount of time causing the metadata store size to grow uncontrollably,1620178811,"this pr adds a new method to the interface , . which produces _parseable_ expression strings so that any tree can be converted back into a which can later be parsed into an equivalent expression . <nl> prior to this pr , not all which could exist at evaluation time were actually parseable , specifically empty numeric arrays and arrays with null elements . to make all able to satisfy the contract , the grammar has been updated to support these constructs . empty arrays may now be defined like so : , , , and arrays like are now",0.9610466361045837
elastic_elasticsearch/72557,"consolidate and clarify mappinglookup semantics . <nl> mappinglookup has been introduced to expose a snapshot of the mappings to the search layer . we have been using it more and more over time as it is convenient and always non null . <nl> this commit documents some of its semantics and makes it easier to trace when it is created with limited functionalities ( without a document parser , index settings and index analyzers ) . <para-sep> an index does not have mappings only if it was created without providing mappings explicitly , and no documents have yet been indexed in it . <nl> a lookup representing an empty mapping . <nl> note that the provided mappings are not re-parsed but only exposed as-is . no consistency is enforced between the provided mappings and set of mappers . this is a commodity method to be used in tests , or whenever no mappings are defined for an index . <nl> parses the provided document .","mappinglookup has been introduced to expose a snapshot of the mappings to the search layer . we have been using it more and more over time as it is convenient and always non null . <nl> this commit documents some of its semantics and makes it easier to trace when it is created with limited functionalities ( without a document parser , index settings and index analyzers ) .",1619789829,limit the creation of data streams only for namespaces that have a composable template with a data stream definition . <nl> this way we ensure that mappings/settings have been specified and will be used at data stream creation and data stream rollover .,0.9682912230491638
vespa-engine_vespa/17003,"use zk node version as cache , instead of reading all bytes and computing hash <para-sep> for each application id ( path ) , store the zk node version and its deserialised data - update when version changes . this will grow to keep all applications in memory , but this should be ok","use zk node version as cache , instead of reading all bytes and computing hash . <nl> this is already done for deployment job data : )",1615984046,will be replaced pretty soon .,0.9336404204368591
grpc_grpc-java/7783,"define internal constants for xds cluster name attribute . <cm-sep> make googledefault protocol negotiator use alts for xds endpoints blongs to non-cfe clusters . otherwise , use tls . <cm-sep> exclude internal contants definition in javadoc . <cm-sep> attach xds cluster name to endpoint address attributes . <para-sep> same as io.grpc.xds.internalxdsattributes.attr_cluster_name <nl> name of the cluster that provides this equivalentaddressgroup . <nl> one locality with two endpoints . <nl> simulates leaf load balancer creating subchannels .","attach an attribute to endpoint addresses when using xds and let googledefault protocol negotiator select alts if the endpoint is google cfe ( otherwise , select tls ) .",1609974214,"cleaning up channels is something users should do . to promote this <nl> behavior , add a log message to indicate that the channel has not <nl> been properly cleaned . <nl> this change users phantomreferences to avoid keeping the channel <nl> alive and retaining too much memory . only the id and the target <nl> are kept . additionally , the lost references are only checked at <nl> jvm shutdown and on new channel creation . this is done to avoid <nl> object finalizers . <nl> the test added checks to see that the message is logged . since",0.9637694358825684
elastic_elasticsearch/74460,this change ensures that we validate point in times provided by individual search <nl> requests in _msearch . <cm-sep> fix imports,this change ensures that we validate point in times provided by individual search <nl> requests in _msearch .,1624414488,this change ensures that we validate point in times provided by individual search requests in _msearch .,0.9999999403953552
apache_beam/14616,"remove log messages about files to stage . <nl> these log messages are duplicated from pipelineresources.java , and they could cause an npe .","these log messages are duplicated from pipelineresources.java , and they could cause an npe",1619050053,"debugcapture is using an old version of the jacksonfactory from google api client that will not be present when running jobs on dataflow , but is currently on the test classpath . update it to use the latest to match the rest of the dataflow runner and the java sdk , and remove the jar providing the old version of the jacksonfactory from the dataflow runner test configuration",0.8815338015556335
apache_kafka/10835,replace easymock and powermock with mockito for namedcachemetricstest,"development of easymock and powermock has stagnated while mockito continues to be actively developed . with the new java cadence , it 's a problem to depend on libraries that do bytecode generation and are not actively maintained . in addition , mockito is also easier to use. % 20and % 20assignee % 20in % 0 ( empty ) % 20and % 20text % 0~ % 0 % 22mockito % 0 ) .",1623082248,this results in validation error during connector startup . <nl> unit tests were added for both and to avoid such issues in the future .,0.8716506361961365
grpc_grpc-java/7854,enhance managedchannelbuilder.overrideauthority ( ) <para-sep> * /,"enhance to make it impossible to use a different authority to a backend by wrapping clienttransportfactory.newclienttransport ( ) and setting clienttransportoptions ’ authority . to avoid confusing the lb policy , it would need to keep the original addresses to return during",1611870304,"having two s ( the other being ) is proven to <nl> be confusing , and the one in is fundamentally different <nl> from the one from , as the latter mutates the states while <nl> the former does n't . renaming it to make it less awkward to <nl> expose it to , which is needed for creating s <nl> for per-locality routing in the .",0.9508897662162781
elastic_elasticsearch/74086,avoid scaling empty tier unnecessarily . <nl> autoscaling supports data tiers using attributes . this commit refines <nl> the check to avoid bootstrapping a tier when a non-filter decider says <nl> no .,autoscaling supports data tiers using attributes . this commit refines <nl> the check to avoid bootstrapping a tier when a non-filter decider says <nl> no .,1623687371,this commits allows data streams to be a valid source for analytics and transforms . <nl> data streams are fairly transparent and our and actions work without error . <nl> for the check-pointing works as desired as well . data streams are effectively treated as an and the backing index values are stored within checkpointing information .,0.9660560488700867
apache_flink/15520,cliresultview should wait refreshthread exits before exits <para-sep> ignore,"cliresultview should wait refreshthread exits before exits . <nl> the failed test is mainly to test the view thread has the ability to exit gracefully when users ( main thread ) interrupt the view thread . <nl> we have 0 threads in the test : main thread , view thread and refresh thread . <nl> the main thread has the resource terminal and uses the the resource to create the view thread . when the view thread starts , it set the interrupt flag on the view thread and close the terminal until view thread exits . <nl> - when",1617850990,"support add_sink ( ) for python datastream api . <nl> - add a new module named connectors which includes all source/sink related classes . <nl> - add add_sink ( ) interface for datastream api . <nl> this change currently have no test case coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : (",0.8306834697723389
apache_druid/10947,"add flag to disable left base filter <para-sep> this flag control whether a sql join query with left scan should be attempted to be run as direct table access instead of being wrapped inside a query . with direct table access enabled , druid can push down the join operation to data servers . <nl> duplicate prefixes or prefixes that shadow each other across the clauses duplicate prefixes or prefixes that shadow each other across the clauses <nl> since context is usually immutable in tests , make a copy","however , the change could actually underperform depending on the kind of query . this pr introduces a flag to switch between two behaviors . default value of this flag is false .",1614929525,"these functions were both added in the service of adding sql functions that allow filtering multi-value dimensions as expressively as native druid queries , and , where the stands for 'multi-value ' . <nl> i 've actually defined these as aliases for and , since both sets of these functions are driven internally by and respectively , so they can share operator conversion implementations . so this is equivalent : . <nl> the reasoning for the dupe naming is : most of the druid expression array functions pose no problem with accepting either or typed input , but the functions",0.9563592672348022
apache_shardingsphere/10719,optimize calcite select logic <para-sep> get schema metadata by schema name . <nl> trim the semicolon of sql .,changes proposed in this pull request : <nl> - fix calcite parse error when sql include semicolon <nl> - fix check error when result include decimal type <nl> - fix select with prepared statement class case exception,1623149566,changes proposed in this pull request : <nl> - add sqlserver with clause for delete statement . <nl> - add sqlserver test case for delete with clause .,0.9481269717216492
apache_incubator-pinot/6400,add real-time h3 index reader <para-sep> a h3 index reader for the real-time h3 index values on the fly . this class is thread-safe for single writer multiple readers . <nl> todo support multiple resolutions <nl> reader of the h3 index . <nl> gets the matching doc ids of the given h3 index id as bitmaps .,add the h3 index support to real-time segments . <nl> updated the realtimequickstart example to utilize the h3 index . for example .,1609634901,"- update the anomaly detector interface to return a detection result which includes anomalies and time series ( containing time stamps , predicted baseline , current value , upper/lower bounds ) <nl> - implement the new detector interface in threshold , percentage change , absolute change , and holt-winters detector . <nl> - implement the baseline provider interfaces in threshold , percentage change , absolute change classes .",0.9582651257514954
elastic_elasticsearch/72886,add painless script support for geoshape field <para-sep> returns the dimensional type of this geometry * / <nl> returns the bounding box of this geometry * / <nl> returns the centroid of this geometry * / <nl> reset the geometry .,"this pr proposes the extension of painless api to support accessing selected information stored in geo fields . the new methods are based in two immediate needs : . <nl> 0 ) we have request to be able to query geo shapes by some geometric characteristics . e.g . this information is not available in the lucene index but it is available in the geoshape doc values . therefore adding the possibility to get that information with painless , it we ca support such queries using runtime fields . for example , we can sort our geoshapes by height using",1620653023,"this adds support for the xdbc and cli clients . <nl> based on these , the csvjdbc-based qa tests are also added .",0.9826101660728455
ballerina-platform_ballerina-lang/27772,"clear cache for intersection types . <nl> intersection types were cached in the symbolenter . when the symbol enter phases were reused in the testpackage symbol enter , this made the previous intersection types to be redefined . hence cleared the cache just after defining the intersection types .","when the symbol enter phases were reused in the testpackage symbol enter , this made the previous intersection types to be redefined . hence cleared the cache just after defining the intersection types .",1610344287,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.8802395462989807
apache_druid/10895,add property for binding view manager type,"this pr adds a new string property that allows for custom viewmanager implementions to be bound . <nl> as there are no viewmanager implementations available presently , the docs are omitted for now",1613531338,"this pr introduces an sql aggregator for the bloom filter extension , as well as complex value serialization for sql results , which is controllable via a new config option , which defaults to . previous behavior for complex types in sql results was to print the class name , now if the setting is enabled , it will serialize values using the object mapper . <nl> because these values are serialized , so things like strings will be represented as json strings in csv output results , e.g . if is the string serialized output of some complex type",0.9602260589599609
apache_pulsar/10315,optimize code path for functions that only read from one topic <para-sep> set source topic to null because we are setting the topic information separately <nl> create a producer that creates a topic at broker <nl> multiply by 0 since function is reading from two topics <nl> delete functions <nl> we can use a single consumer to read <nl> use singleconsumerpulsarsource if possible because it will have higher performance since it is not a push source that require messages to be put into an immediate queue <nl> check new config with schema types or classnames <nl> add provider only if it 's not in the jvm <nl> open connector with configuration . <nl> attach a consumer function to this source . this is invoked by the implementation to pass messages whenever there is data to be pushed to pulsar . <nl> get length of the queue that records are push onto users can override this method to customize the queue length,"currently , the internal pulsarsource used in the pulsar function framework used to read from topics extend the pushsource . this is done to support the use case in which multiple consumers have to be created to read from multiple topics with different consumer settings . while this approach is necessary for reading from multiple topics with consumers with different settings , it is inefficient for reading a single topic or list of topics with the same consumer settings ( not address in this pr ) . the inefficiency is due to the fact that for pushsource all messages are",1619055673,"add multiversionavroreader . <nl> add multiversiongenericavroreader . <nl> add multiversiongenericjsonreader . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( yes ) <nl> the schema : ( yes ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no )",0.9843278527259827
apache_shardingsphere/10800,<para-sep> shardingsphere federate refresher for drop table statement .,changes proposed in this pull request : <nl> - create droptablestatementfederaterefresher <nl> - add droptablestatementfederaterefreshertest <nl> -,1623568730,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9670272469520569
elastic_elasticsearch/73030,the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,1620886697,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.9336522817611694
apache_beam/14620,use formatting string for checkargument to avoid excess string appends,"use formatting string for checkargument to avoid excess string appends . <nl> - x ] [ choose reviewer ( s ) and mention them in a comment ( ) . <nl> - [ x ] format the pull request title like , where you replace with the appropriate jira issue , if applicable . this will automatically link the pull request to the issue . <nl> - [ x ] update with noteworthy changes . <nl> - x ] if this contribution is large , please file an apache [ individual contributor license agreement",1619113217,"be sure to do all of the following to help us incorporate your contribution <nl> quickly and easily : . <nl> travis-ci on your fork and ensure the whole test matrix passes ) . <nl> number , if there is one . <nl> individual contributor license agreement . <nl> this ensures that while processing a bundle all elements see the same <nl> contents for any sideinput window .",0.8460531234741211
Alluxio_alluxio/12479,simplify migratedefinition <para-sep> a job that migrates a single file from source path to a destination path .,distributedcp and distributedmv now no longer needs the complicated folder to folder operation and now only handles file to file . removing a bunch of code that does folder to folder work .,1604959848,"previously we extended to provide slightly different implementations for a single protected method . now we pass a factory into which expresses the difference . this decouples from its previous children , making it much easier to test ( we no longer need to use whitebox ) .",0.9522736072540283
Graylog2_graylog2-server/9986,"since we can not change the order of the tabs <nl> this is quite inconvinient for the user . <nl> - instead of using the serach queryids we use the views queryids which <nl> we previously fixed in the order . <nl> - when loading a view and selecting the activequery we also use the <nl> view.state queryids instead of the search ones . <cm-sep> * display the timezone settings to the user . <nl> * fix settings section test <cm-sep> fix pattern used to identify parameters in search/dashboard query strings . <nl> * consolidating backend-agnostic query parsing/metadata creation . <nl> * fixing test . <nl> * adding test cases for bug . <nl> * adjusting regex for query string parser . <nl> * removing unused parameter . <cm-sep> the new paginated endpoint in streamresource is using mongojack to <nl> deserialize the database objects . in some setups the alertreceivers <nl> object in the database might not be complete . <nl> change alertreceivers to use defaults for missing values . <nl> ( cherry picked from commit sha ) <cm-sep> the component passes an event as argument to its <nl> function but but we were expecting a string containing <nl> a number . this change fixes that by extracting the value from the <nl> received event . <cm-sep> * avoid using a stage number that is already used . <nl> check if selected stage number already exists in pipeline , displaying <nl> an error in that case and not allowing to submit the form . this will <nl> prevent users of accidentally overriding one of their existing stages . <nl> additionally improve the initial suggestion for new stages . before we <nl> always displayed when creating a stage , now we base that value in <nl> the existing stages for the pipeline . <nl> * do not submit form when using an existing stage <cm-sep> * retry read timeouts for elasticsearch . <nl> before this change , the retry strategy used for es requests did not <nl> retry for instances of , raised in case of read <nl> timeouts . this resulted in exceptions being raised when individual nodes <nl> were not responding and node discovery was not used . this was e.g . being <nl> noticable when performing searches and 0 of 0 nodes was failing , so <nl> every 3rd search request was timing out and returning an error",update .0 branch with latest changes from version .,1611840250,users might ( rightfully ) want to run the graylog rest api and the web interface on the same network listener with the web interface being served on the root context path ( ) and the graylog rest api being served from a path below that ( ) . <nl> this pr merges and into a single service which handles setting up the required handlers accordingly . <nl> painfully . <nl> things that might still be broken and might only be working on my machine™ : <nl> - swagger ui in general <nl> - the generic 0-handler so that the,0.9786613583564758
apache_pulsar/10910,"when the replicator is enabled , updating the number of partitions will not create managedledger <para-sep> create partitioned-topic from r1 <nl> list partitioned topics from r2 <nl> list partitioned topics from r3 <nl> update partitioned topic from r2 <nl> update partitioned topic from r3 <nl> update partitioned topic from r1","now we only update the number of partitions in , so if we do not create a producer or consumer , the data obtained in another cluster will be incorrect .",1623472434,fix the issue with classloaders and add tests,0.8909282684326172
ballerina-platform_ballerina-lang/28703,"fix dependently-typed functions with defaultable params <cm-sep> fix and enable variablereturntypesbalatest <cm-sep> add tests <para-sep> { ' testxml ' } ,",this pr also enables most of the tests in variablereturntypesbalatest . <nl> will fix it separately .,1613548863,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.952218234539032
quarkusio_quarkus/17350,"upgrade to smallrye graphql version <para-sep> register the api class and all classes that it references for reflection <nl> an equivalent of io.smallrye.graphql.client.typesafe.impl.cdi.graphqlclientbean that produces typesafe client instances <nl> needed to be able to convert config values to uri ( performed by the graphql client code ) <nl> in this test , we only check that the injected client instance has the correct url value i do n't know if it 's possible to know the actual url ( where the server side will be available ) beforehand , so that we could put it into application.properties and then actually use the injected client to call something on the server <nl> set the lucky number to 0 <nl> get the lucky number and assert that it 's 0",subscription support and a user guide coming up next,1621422411,"this pr has two commits : . <nl> * the first drops and introduces a few classes that allows the creation of the proxy classes using only gizmo . proxy creation supports jdk 0-0 but the classes are n't particularly optimized ( but since they are meant to only be used during augmentation maybe it does n't really matter ? ) <nl> * the second commit attempts to lay the groundwork for allowing the creation of proxies for jdk 0+ . as can be seen in the comments , this currently only works for a small set of proxies -",0.9635406732559204
apache_pulsar/11042,"made the pulsarclustermetadatateardown deletes idempotent <para-sep> try delete again , should not fail","if some of the z-nodes are not there anymore , the cluster teardown operation should not fail . <nl> also changed the delete recursive operation to delete in parallel for children of same node , to speed up the overall execution time .",1624440536,"when produce/consume permissions for a role on a namespace are revoked , producers and consumers connected to the topic under the namespace using that role should be disconnected from the broker . however , i noticed that producers/consumers can stay connected in some topics even if the permissions are revoked . <nl> in subscriptions that consumer has never connected to since the broker started , the dispatcher has not been initialized , so returns null . <nl> as a result , the process of is aborted . <nl> before calling a dispatcher method , make sure that the dispatcher is",0.9074321389198303
elastic_elasticsearch/73214,"javadoc for how aggs work <para-sep> aggregations builds analytic information over all hits in a search request . aggregations are essentially a tool for sumarizing data , and that summary is often used to generate a visualization . types of aggregations there are three main types of aggregations , each in their own sub package : bucket aggregations - which group documents ( e.g . a histogram ) metric aggregations - which compute a summary value from several documents ( e.g . a sum ) pipeline aggregations - which run as a seperate step and compute values across buckets additionally there is a support sub package , which contains the type checking and resolution logic , primarily . how aggregations work todo : info about search phases goes here aggregations operate in general as map reduce jobs . the coordinating node for the query dispatches the aggregation to each data node . these values are shipped back to the coordinating node , which performs the reduction on them ( partial reductions in place on the data nodes are also possible ) . three modes of operation when it comes to actually collecting values , there are three ways aggregations operate , in general . which one we choose depends on limitations in the query and how the data was ingested ( e.g . if it is searchable ) . the easiest to understand is the compatible ( i.e . usable in all situations ) mode , which can be thought of as iterating each query hit and collecting a value from it . this is the least performant way to evaluate aggregations , requiring looking at every hit . the fastest way to run an aggregation is by looking at the index structures directly . for example , lucene just stores the minimum and maximum values of fields per segment , so a min aggregation matching all documents in a segment can just look up its result . finally , we can rewrite an aggregation into faster aggregations , or ideally into just a query . generally , the goal here is to get to filter by filters ( which is an optimization on the filters aggregation which runs it as a set of filter queries ) . often this process will look like rewriting a datehistogram into a daterange , and then rewriting the daterange into filters . in","i typed up some notes from nik 's great talk on different modes of how we aggregate . this is just javadoc , because that 's what we 've decided to standardize on for developer docs . i 'm happy to move this elsewhere if we think that 'll be better .",1621354844,adds package level javadoc for snapshot clones .,0.8475956320762634
elastic_elasticsearch/73258,"refactor restoreservice restore path . <nl> make the restore path a little easier to follow by splitting it up into <nl> the cluster state update and the steps that happen before the cs update . <nl> also , document more pieces of it and remove some confusing redundant code . <para-sep> fork handling to the generic pool since it loads various pieces of metadata from the repository over a longer period of time <nl> start the snapshot restore process . first validate that the snapshot can be restored based on the contents of the repository and the restore request . if it can be restored , compute the metadata to be restored for the current restore request and submit the cluster state update request to start the restore . <nl> make sure that we can restore from this snapshot <nl> get the global state if necessary <nl> get data stream metadata for requested data streams <nl> remove the data streams from the list of requested indices <nl> and add the backing indices <nl> determine system indices to restore from requested feature states <nl> resolve the indices that were directly requested <nl> combine into the final list of indices to be restored <nl> log a deprecation warning if the any of the indexes to delete were included in the request and the snapshot is from a version that should have feature states <nl> now we can start the actual restore process by adding shards to be recovered in the cluster state and updating cluster metadata ( global and index ) as needed <nl> apply renaming on index names , returning a map of names where the key is the renamed index and the value is the original name <nl> optionally updates index settings in indexmetadata by removing settings listed in ignoresettings and merging them with settings in changesettings . <nl> cluster state update task that is executed to start a restore operation . <nl> the restore request that triggered this restore task . <nl> feature states to restore . <nl> map of index names to restore to the repository index id to restore them from . <nl> snapshot info of the snapshot to restore <nl> metadata loaded from the snapshot <nl> check if the snapshot to restore is currently being deleted <nl> clear out all existing indices which fall within a system index pattern being restored <nl> updating cluster state <nl>","make the restore path a little easier to follow by splitting it up into <nl> the cluster state update and the steps that happen before the cs update . <nl> also , document more pieces of it and remove some confusing redundant code . <nl> outside of spots that have inline comments to the contrary , this is a purely mechanical <nl> refactoring , no logical changes . <nl> partly also motivated by upcoming changes to how is loaded ( with the current structure it 's essentially impossible to make loading async ) . <nl> note to reviewers : this",1621485703,"per rest endpoint media types declaration allows to make parsing/validation more strict . <nl> if a media type was declared only in one endpoint ( for instance csv in sql endpoint ) it should not be allowed to parse that media type when using other endpoints . <nl> however , the need to be able to understand all media types supported by elasticsearch in order to parse a compatible-with=version parameter . <nl> this implies that endpoints need to declare which media type they support and how to parse them ( if introducing new media types - like sql ) .",0.9681059718132019
apache_kafka/10311,"fix in streamsrebalancelistener , exit early in streamthread main loop after poll phase <para-sep> we need to still invoke handlerevocation if the thread has been told to shut down , but we should n't ever transition away from pending_shutdown once it 's been initiated ( to anything other than dead )",should be cherrypicked back to version & version,1615593641,brokers are supposed to force sasl clients to re-authenticate ( and kill <nl> such connections in the absence of a timely and successful <nl> re-authentication ) when sasl re-authentication is enabled via <nl> a positive connections.max.reauth.ms configuration value . there was a <nl> flaw in the logic that caused connections to not be killed in the <nl> absence of a timely and successful re-authentication if the client did <nl> not leverage the saslauthenticaterequest api ( which was defined in <nl> ) .,0.79634028673172
elastic_elasticsearch/73942,"tighten up write permissions in docker image . <nl> recursively remove write access from the , , and <nl> directories , since this access is not required , and removing <nl> it makes it harder to exploit other issues in an es distribution .","recursively remove write access from the , , and <nl> directories , since this access is not required , and removing <nl> it makes it harder to exploit other issues in an es distribution .",1623228827,this commit migrates the esintegtestcase tests in x-pack to the <nl> internalclustertest source set .,0.9224389791488647
ballerina-platform_ballerina-lang/29792,"add type hash based runtime type resolver <para-sep> filter anon types and sorts them before generating switch case . <nl> create labels for the cases <nl> if name contains $ anon and does n't belong to the same package , load type using getanontype ( ) method . <nl> btype hash comparator to sort birtypedefinitions according its type hash code . <nl> btype hash visitor to visit and generate a hash code for a given btype .","generated method : . <nl> generated usage : . <nl> in case , if the type could n't be resolved , a runtime error similar to the following will be thrown .",1617348510,this pr refactors the aggregator functions visit implementation . the visiting implementation is moved to a new class called streamingaggregatorarraybuilder,0.9798837304115295
apache_pulsar/10723,add explicit test case for nondurable subscriptions and broker restart <para-sep> 0 setup producer、consumer <nl> 0 send messages <nl> 0 receive the first 0 messages <nl> 0 trigger reconnect <nl> 0 for non-durable we are going to restart from the next entry <nl> 0 restart broker <nl> 0 for non-durable we are going to restart from the next entry,add new tests cases that cover broker restart and non durable subscriptions : <nl> - test all subscription types with nondurable subscription mode <nl> - test the case of broker restart,1622101388,"when using a multi-broker service url to create a producer , if the connection to the first broker failed , the creation will fail . <nl> add backoff retries when getting partitioned metadata from brokers .",0.9399835467338562
Graylog2_graylog2-server/10767,"add prometheus-client_java dependency <cm-sep> add prometheus exporter . <nl> this implements a prometheus exporter that maps the internal dropwizard <nl> metrics to prometheus compatible metric names and labels . <nl> the metric mapping is configurable via config files . <cm-sep> fix built-in mapping resource name <cm-sep> add license headers <para-sep> check if we really want this or if we consider this a private reporter and should choose a default port outside of the ' official ' prometheus exporter range . <nl> this allows atomic collector registry replacements at runtime . <nl> add nodeid to every metric . <nl> the file did n't exist before so we want to trigger a change <nl> use latest file info to make update check correct on next call <nl> synchronize to ensure atomic update of the file info fields <nl> if an external core mapping file exists it takes precedence over the included mapping resource <nl> load custom mappings if they exist . custom mappings can not override core mappings ! <nl> just check a sample from our built-in metrics to verify that the resource loading works <nl> write an initial config <nl> initially it should n't have been marked as changed <nl> after writing to it , it should have changed <nl> add another metric <nl> write an initial config <nl> initially it should n't have been marked as changed <nl> after writing to it , it should have changed <nl> add another metric",this implements a prometheus exporter that maps the internal dropwizard <nl> metrics to prometheus compatible metric names and labels . <nl> the metric mapping is configurable via config files .,1622579636,it will search for events in the event streams and <nl> will return timestamp and message from the event . the searchtype.result will only contain <nl> events created from streams visible for the user . <nl> in this step we fetch the widgets <nl> and provide a backend implementation . <nl> add the ' events ' search type to a existing search manually and execute it via api endpoint .,0.9780216813087463
apache_flink/15944,use sql file in tpch end to end tests,use sql files to init environment in tpch tests .,1621331705,"use to replace in , <nl> in order to fix latency metrics drift apart . <nl> latencymarker only affect one latency metric . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that",0.8497128486633301
Graylog2_graylog2-server/9948,"fix date format specifiers in index mapping templates for es7 . <nl> before this change , the pre-es7 date format specifiers were reused for <nl> es7 to define the format of date fields in index mapping templates . <nl> this change is now splitting up the date format specifiers and uses joda <nl> syntax for es6 and syntax for es7 . in addition , the overly <nl> lax exposition of the date format specifiers from the class was <nl> locked down to prevent them leaking into new places . <cm-sep> adjusting tests/expected results . <cm-sep> adjusting single date format in gim mapping for v7 too . <cm-sep> prefixing date format for es6 to disable deprecation notice . <nl> as we are using a deprecated formatter according to the es breaking changes , <nl> this commit is adding the prefix to prevent a warning . <cm-sep> prefixing legacy date formats in gim mapping . <cm-sep> adjusting tests to use .","before this change , the pre-es7 date format specifiers were reused for es7 to define the format of date fields in index mapping templates . <nl> unfortunately , this results in warnings being returned in responses to searches operating on date fields , due to a breaking change introduced in es7 . <nl> this change is now splitting up the date format specifiers and uses joda syntax for es6 and syntax for es7 . in addition , the overly lax exposition of the date format specifiers from the class was locked down to prevent them leaking into new places .",1611244821,"the only populated the field of the generated elasticsearch document if the field was filled , but not if the field in the map was being used . <nl> this lead to inconsistent ' exports ' of the internal representation .",0.919520914554596
apache_druid/11026,gcs lookup support <para-sep> remove path prefix from file name <nl> recognize ' standard ' directory place-holder indications <nl> recognize place-holder objects created by the google storage console or s3 organizer firefox extension . <nl> object for directory prefix/dir/0/ <nl> object for directory prefix/dir/0/,support loading lookups from gcs similar to s3,1616578344,syntax is the same as hive/presto 's .,0.9775257706642151
confluentinc_ksql/7320,"reorganize query management and clean up listeners . <nl> this patch cleans up our code for managing the life-cycle of continuous queries . in particular : <nl> - break out query management from enginecontext into its own module ( called queryregistry ) <nl> with more explicit interfaces . enginecontext should really just be a place for pointers to <nl> context - it should n't actually be executing query management logic . this is moved into <nl> queryregistry and queryregistryimpl . this patch also adds detailed doc-comments about the <nl> queryregistry interface . <nl> - clean up query event listeners . we had various bits of code that listened on different events <nl> from a query . for example , we had a listener that tracked query status metrics , another that <nl> listened for close queries to clean up state , and another to manage the set of live queries . <nl> in a future pr i intend to add another listener for doing validation against the runtime ( e.g . <nl> streams ) . there were also multiple ways of listening on an event in some places . ie this patch , <nl> i 've created an explicit interface for listeners of query events that contains all the possible <nl> events to listen on . listeners should register with queryregistryimpl when creating it . <nl> - we were not explicitly sandboxing listeners , which is dangerous because we may accidentally <nl> take some action in response to an event on a sandbox . this patch adds an interface for <nl> listeners to handle the case where the engine is being sandboxed for validation . <nl> there 's also a couple of more minor changes : <nl> - move to persistentquerymetadata . transient queries ca n't be stopped - they can only <nl> be closed . we were previously jsut calling close from stop , but i think this is cleaner and <nl> more explicit . <nl> - call initialize from one place for all queries ( from registerquery ) <nl> - drop uptime from querymetadata - we do n't use this anymroe <para-sep> called when a new query is created . <nl> called when the state of the underlying kafka streams application of a given query changes <nl> called when a query hits a query execution error <nl> called when a query is removed from the registry . <nl>",this patch cleans up our code for managing the life-cycle of continuous queries . in particular : <nl> - break out query management from enginecontext into its own module ( called queryregistry ) <nl> with more explicit interfaces . enginecontext should really just be a place for pointers to <nl> context - it should n't actually be executing query management logic . this is moved into <nl> queryregistry and queryregistryimpl . this patch also adds detailed doc-comments about the <nl> queryregistry interface . <nl> - clean up query event listeners . we had various bits of code that listened on,1617094349,"this change moves the validation done to ensure columns referenced in the projection for a query out of the / and into the logical model . <nl> at this point , only the validation of select expressions has moved . the rest will move in follow up prs . <nl> to achieve this , the needs to not take a logical schema as a parameter , but instead build it once the select items have been validated . this means logical plan nodes are no longer immutable . <nl> this is necessary work to enable the removal of joinkey udf",0.9834945201873779
hazelcast_hazelcast/18583,bump testcontainers.version from version to version . <nl> bumps from version to version .,bumps from version to version . <nl> updates from version to version . <nl> release notes <nl> sourced from rabbitmq 's releases . <nl> version <nl> what 's changed <nl> 🚀 features & amp ; enhancements . <nl> 🐛 bug fixes . <nl> 📖 documentation . <nl> 🧹 housekeeping . <nl> 📦 dependency updates . <nl> version <nl> what 's changed . <nl> ... ( truncated ) . <nl> commits . <nl> updates from version to version . <nl> release notes <nl> sourced from postgresql 's releases . <nl> version <nl> what 's changed <nl> 🚀 features & amp ;,1619056955,the client should not use localhost if it is not explicitly configured and the discovery is configured .,0.8973800539970398
elastic_elasticsearch/73478,"add cross cluster support to _terms_enum . <nl> this commit adds the support to search cross cluster indices ( with the cross cluster syntax ) <nl> in the _terms_enum api . <para-sep> _terms_enum on a remote cluster <nl> _terms_enum on mixed clusters ( local + remote ) <nl> internal terms enum request executed directly against a specific node , querying potentially many <nl> adjust the amount of permitted time the shard has remaining to gather terms . <nl> todo - if already timed out can we shortcut the trip somehow ? throw exception if remaining time < 0 ? <nl> simply ignore non active operations <nl> only one node response has to be incomplete for the entire result to be labelled incomplete . <nl> handle remote clusters <nl> todo : handle exceptions in the atomic response array <nl> todo : handle exceptions in the atomic response array",this commit adds the support to search cross cluster indices ( with the cross cluster syntax ) <nl> in the _terms_enum api . <nl> this pr is marked as a non-issue since the api is new in version .,1622123551,"this introduces support for accessing multivalue fields , whose value can be retrieved with a newly added array function . only value extraction is of concern for this pr . <nl> is only allowed in projections , will only accept a field name as parameter and ca n't be provided as another function 's parameter .",0.9847081899642944
elastic_elasticsearch/72615,"remove documentmapperfortype . <nl> documentmapperfortype is used to create a document mapper when no mappings exists for an index and we are indexing the first document in it . this is only to cover for the edge case of empty docs , without any fields to dynamically map , being indexed , as we need to ensure that any index with at least one document in it has some mappings . <nl> we can replace using documentmapperfortype with the same logic that mapperservice # documentmapperwithautocreate includes . this also helps clean up the only case where we create a documentmapper from its public constructor , which can be removed and replaced by a more targeted static method . <para-sep> if we are indexing but there is no mapping we create one . this is to ensure that whenever at least a document is indexed some mappings do exist . it covers for the case of indexing an empty doc ( ) . <nl> todo this throws npe if there are no mappings yet , we have the same problem in painlessexecutionaction","documentmapperfortype is used to create a document mapper when no mappings exists for an index and we are indexing the first document in it . this is only to cover for the edge case of empty docs , without any fields to dynamically map , being indexed , as we need to ensure that any index with at least one document in it has some mappings . <nl> we can replace using documentmapperfortype with the same logic that mapperservice # documentmapperwithautocreate includes . this also helps clean up the only case where we create a documentmapper from its public constructor",1620036803,"indextemplatemetadata x-content serialization is a bit confused and trappy at the <nl> moment , with multiple static methods on the builder object which may or may not <nl> emit the template name and/or mapping types . this commit consolidates everything <nl> into a single method on the base class , with different options passed <nl> through as . deserialization is converted to use an , <nl> taking the template name as a context .",0.9668017625808716
apache_incubator-pinot/6272,set acl based on config <para-sep> implementation of pinotfs for aws s3 file system <nl> determines if the file exists at the given path,"these will be useful when the pinot-cluster and s3 bucket are in different aws accounts . <nl> here is the issue related to this . <nl> note : i 've tested this in our setup and it was working as expected ( controller was able to create data dir , launched an ingestion job to test pushing and loading of segments ) .",1605620829,* add enum values for supported tdigest pinot function syntax <nl> * add logic to reduce tdigests in thirdeye dashboard app by using a count-weighted average ( since pinot returns doubles for tdigest function aggregations ),0.9319517016410828
vespa-engine_vespa/18111,report idle timeout as 0 instead of 0 . <nl> http/0 stream idle timeouts are more common and clients should get a <nl> better indication that the stream has timed out . <cm-sep> add connector config for http/0 streams <para-sep> e.g stream idle timeout for http/0,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622732511,"today , you get 0 bad request when activation fails due to a conflict . using 0 seems correct and will also gives us the possibility to retry deployment if we want to avoid deployment failures in this scenario . <nl> doc will be updated in another pr .",0.9418487548828125
apache_pulsar/10529,fix partitioned system topic check bug,the check logic is . <nl> the partitioned topic name is like . <nl> 0. add a test to cover this case .,1620649185,"in the method of , eligible subscriptions will be cleaned up .",0.9295529127120972
ballerina-platform_ballerina-lang/27048,"add support for defaultable params , named args and rest args <cm-sep> enhance object method invocation evaluation support <cm-sep> sync with master <cm-sep> add minor fixes <cm-sep> add integrations tests for function invocation evaluation <cm-sep> fix spotbugs warnings <para-sep> returns module compilation for a given expression by injecting it into the given debugger source . <nl> as expressions can not be compiled standalone , coverts into a compilable statement . <nl> injects the expression into the source file content , at the end of the current debug point line . <nl> visits object expression . <nl> do an early exit if the result is already found . <nl> here we use the existing strand instance to execute the function invocation expression . <nl> here we use the existing strand instance to execute the function invocation expression . <nl> validates and processes invocation arguments of ballerina functions and object methods . <nl> returns all the module class names which belong to the current module that is being debugged . <nl> todo - use balo reader to derive module class names by accessing module balo files . <nl> arguments for required parameters can be passed as positional arguments . positional arguments need to be passed in the expected order . <nl> arguments for required parameters can also be passed as named arguments . named arguments do not have to be specified in the order in which the parameters are defined . <nl> call the function by passing a value only for the parameter . the and parameters default to 0 and version respectively . <nl> call the function by passing values only for the and parameters . the value for the parameter is passed as a named argument . the parameter defaults to version . <nl> call the function again by passing values only for the and parameters , now passing the value for the parameter as a positional argument . the parameter defaults to version . <nl> call the function by passing values only for the and parameters . the parameter defaults to 0 . <nl> in order to pass the value for as a positional argument , a value would have to be specified for the parameter too . all arguments are positional arguments here . <nl> call the function by passing values for all three parameters , the first argument as a positional argument and the rest as named",this pr also adds integration tests for newly supported scenarios .,1605883302,"also , as an improvement going with this particular change , a user can query the content of a package without explicitly adding the import statement and this is at the moment limited to the standard library functions . as the next step , we 'll be adding the capability for the packages which can be found in the ballerina local repository and the project repository .",0.9752362966537476
apache_druid/11186,"adjust topn heap algorithm to only use known cardinality path when dictionary is unique <para-sep> only report the underlying selector cardinality if the column the selector is for is dictionary encoded , and the dictionary values are unique , that is they have a 0:0 mapping between dictionaryid and column value <nl> we must know cardinality to use array based aggregation we check for uniquely dictionary encoded values because non-unique ( meaning dictionary ids do not have a 0:0 relation with values ) negates many of the benefits of array aggregation : - if different dictionary ids map to the same value but dictionary ids are unique to that value ( :0 ) , then array aggregation will be correct but will still have to potentially perform many map lookups and lose the performance benefit array aggregation is trying to provide - in cases where the same dictionary ids map to different values ( 0 : or : ) , results can be entirely incorrect since an aggregator for a different value might be chosen from the array based on the re-used dictionary id","the known cardinality path to aggregate values uses an array based approach , where an array of aggregator arrays the size of the value cardinality is created , and the dictionaryid is expected to index to an array position with the aggregators for that value , as an optimization to avoid a map lookup . <nl> however , when a selector is aggregated which does not have unique dictionaryids , but does know its cardinality , such as a selector from an from a join result which uses the row number as the dictionaryid instead , it means that each",1619787313,raw hyperloglogcollectors and such are n't very useful . when writing <nl> expressions like users will expect and to be finalized .,0.899669885635376
vespa-engine_vespa/16991,"simplify <cm-sep> update javadoc <cm-sep> improve names <cm-sep> trigger os upgrade for all hosts <para-sep> automatically set the os version target on a schedule . trigger os upgrade of zones in the system , according to the current os version target . target os version is set per cloud , and an instance of this exists per cloud in the system . <nl> an upgrader that delegates the upgrade to the node itself , triggered by changing its wanted os version . this implementation limits the number of parallel upgrades to avoid overloading the orchestrator with suspension requests . used in clouds where nodes can upgrade themselves in-place , without data loss . <nl> the maximum number of nodes , within a single node type , that can upgrade in parallel . * / <nl> interface for an os upgrader . <nl> trigger upgrade to given target * / <nl> disable os upgrade for all nodes of given type * / <nl> thread-safe class that manages an os version change for nodes in this repository . <nl> an upgrader that retires and deprovisions nodes on stale os versions . retirement of each node is spread out in time , according to a time budget , to avoid potential service impact of retiring too many nodes close together . used in clouds where nodes must be re-provisioned to upgrade their os . <nl> no action needed in this implementation . <nl> upgrade given host by retiring and deprovisioning it * /","review , but hold merge .",1615923478,"please review only , will merge later",0.9452287554740906
apache_incubator-pinot/6383,"add 'lookup ' transform function <cm-sep> add sample lookup query to join quickstart <para-sep> lookup function takes 0 or more arguments : tablename : name of the dimension table which will be used columnname : column name from the dimension table to look up joinkey : primary key column name for the dimension table . lookup function returns the value of the column 'teamname ' . <nl> lookup parameters <nl> check that there are correct number of arguments <nl> validate lookup table and relevant columns <nl> prepare pk <nl> lookup <nl> confirm we can read primary column list <nl> creating a mock table which looks like : teamid ( pk , str ) | teamname ( str ) | teamname_mv ( str [ ] ) | teaminteger ( int ) | teaminteger_mv ( int [ ] ) | teamfloat ( float ) | ... all values are dynamically created to be variations of the primary key . e.g lookuprowbyprimarykey ( [ 'foo ' ] ) - > ( teamid : 'foo ' , teamname : 'teamname_for_foo ' , teaminteger : hashcode ( [ 'foo ' ] ) , ... <nl> success case <nl> wrong number of arguments <nl> wrong number of join keys <nl> non literal tablename argument <nl> non literal lookup columnname argument <nl> non literal lookup columnname argument <nl> lookup col : stringsv pk : <nl> lookup col : intsv pk : <nl> lookup col : doublesv pk : <nl> lookup col : bytessv pk : <nl> lookup col : stringmv pk : <nl> lookup col : integermv pk : <nl> lookup col : floatmv pk : <nl> lookup col : longmv pk : <nl> lookup col : doublemv pk : <nl> preparing simple tables for testing different primary key types ( int , string , long ) <nl> pk : <nl> pk : <nl> pk : <nl> pk : <nl> pk : <nl> pk : [ byte [ ] ]",introducing a new transform function ; as a part of join project as described in lookup udf join in pinot . <nl> lookup is a regular transform function which uses the previously added dimensiontabledatamanager to execute a lookup from a dimension table . call signature is as follows : . <nl> tablename : name of the dimension table which will be used <nl> columnname : column name from the dimension table to look up <nl> joinkey : primary key column name for the dimension table . note : only primary key is supported for joinkey <nl> joinvalue : primary key,1608854873,- implementation of pinotfs for amazon s3 to support pluggable storage <nl> - aws sdk 0.x is used to support future java versions as well as async requests if needed <nl> - needed to exclude the dependencies from sdk and include them explicitly in pom to suppress maven enforcer plugin warnings .,0.9835848808288574
elastic_elasticsearch/74418,"add keyword fields above to . <nl> currently the field indexes and stores the names of every field in a document that has been ignored <nl> because eg . it was malformed . the option for keyword-type fields <nl> serves a somewhat similar purpose , so this change add logix that adds these <nl> fields to the ' _ignored ' field as well for , and <nl> fields . <para-sep> would work but either leaves us positioned on the seek term ( if it exists ) or the term after ( if the seek term does n't exist ) . that complicates any subsequent iteration logic so this class simplifies the pagination use case .","currently the field indexes and stores the names of every field in a document that has been ignored <nl> because eg . it was malformed . the option for keyword-type fields <nl> serves a somewhat similar purpose , so this change add logix that adds these <nl> fields to the ' _ignored ' field as well for , and <nl> fields .",1624363912,"currently , when a document source mixed json object and dotted syntax like e.g . <nl> { ' foo ' : { ' bar ' : 0 } , ' foo.bar ' : 0 } , extracting the values from the source <nl> map via xcontentmapvalues # extractvalue returns after the first value for a path <nl> has been found . instead we should exhaust all possibilities and return a list of <nl> objects of we find more than one value when extending the lookup path .",0.9263424277305603
vespa-engine_vespa/17927,add configuration of headers through cli <cm-sep> add http/0 stream id to request log,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621523897,"with this change , a new application will have initial value for common reindexing set to the first time the maintainer runs . the config generator can use the default to avoid starting reindexing twice when a new application is deployed ( one for immediate value , and one for the maintainer 's value )",0.9414520263671875
OpenAPITools_openapi-generator/8988,"fixes generator devaultvalues for int64/float/double <para-sep> we use a custom version of this function to remove the l , d , and f suffixes from long/double/float defaultvalues remove the l because our users will use long.parselong ( string defaultvalue ) remove the d because our users will use double.parsedouble ( string defaultvalue ) remove the f because our users will use float.parsefloat ( string defaultvalue ) note : for codegenparameters we do need these suffixes because those defaultvalues are used as java value literals assigned to long/double/float <nl> we had an issue where int64 , float , and double values were having single character string suffixes included in their defaultvalues this test verifies that those characters are no longer present <nl> make sure that the operation parameters omit character suffixes .","instead , the spring generator uses string type default values for codegenparameter only . typically those values are handled with parselong/parsefloat/parsedouble etc which fail if the value includes a character suffix . <nl> we now use values which lack the suffix so parselong/parsedouble/parsefloat will work <nl> codegenparameter defaultvalues : . <nl> ' 0 ' ( int64 ) <nl> ' version ' ( float ) <nl> ' version ' ( double ) .",1615966095,- updated go samples <nl> - tested pass locally <nl> - added a test case,0.9322853088378906
elastic_elasticsearch/72754,this adds io_time_in_millis to nodes stats api . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan,this adds io_time_in_millis to nodes stats api . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan .,1620225912,"there are circumstances in which we ca n't retrieve correct value for total memory or total swap space , which can lead to subtraction errors and invalid arguments to . related test failures have recently appeared in mixed cluster tests with 0.x and version nodes . <nl> although this issue shows up in tests , it could also appear as warnings from node stats endpoints .",0.9386359453201294
vespa-engine_vespa/18471,remove really old unused code <cm-sep> remove really old unused code <cm-sep> add new rpc api for fetching local view,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624988526,"remove unneeded , suspendable tasks will just be called with .",0.8538106083869934
elastic_elasticsearch/72800,"handle properly precision 0 for geotilegrid <para-sep> todo : optimize for when a shape fits in a single tile an <nl> this makes validtile ( ) always return false <nl> compute minx , miny <nl> touching tiles are excluded , they need to share at least one interior point <nl> compute maxx , maxy <nl> touching tiles are excluded , they need to share at least one interior point","currently for precision 0 we always assume that document match the bucket that gets generated . this might not be true for bounded geo tile aggregations where the bounding box is out of range for the area covered by this aggregation . therefore this pr removes the implementation . <nl> in addition , this pr refactor all geogridtest in order to share as many test as possible .",1620291652,"the autoscaling decision api now returns an absolute capacity , <nl> and leaves the actual decision of whether a scale up or down <nl> is needed to the orchestration system . <nl> the decision api now returns both a tier and node level required <nl> and current capacity as wells as a decider level breakdown of the <nl> same .",0.9706566333770752
apache_shardingsphere/10377,"support mysql create udf statement execute <cm-sep> modify createudf to createloadablefunction <cm-sep> rename mysql describe to explain <cm-sep> extract explain statement & support postgresql explain statement <cm-sep> resolve conflict <cm-sep> fix checkstyle <para-sep> explain statement context . <nl> todo extract table from declare , execute , creatematerializedview , refreshmaterializedview <nl> todo visit declare statement <nl> todo visit create materialized view statement <nl> todo visit refresh materialized view statement <nl> extract table that should be rewrite from sql statement . <nl> explain statement . <nl> get sql statement . <nl> explain statement handler for different dialect sql statements . <nl> get simple table segment . <nl> mysql explain statement . <nl> get simple table segment . <nl> postgresql explain statement . <nl> explain statement assert . <nl> assert explain statement is correct with expected parser result . <nl> describe statement test case .",changes proposed in this pull request : <nl> - rename mysql describe to explain <nl> - extract abstract explain statement <nl> - support postgresql explain statement <nl> - correct mysql explain statement,1621331784,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - add proxy meta data <nl> - fix some problems <nl> -,0.9678178429603577
OpenAPITools_openapi-generator/8484,"implement unit tests for feign client . <nl> implement tests <nl> migrate to junit 0 <cm-sep> default feign client does not support patch verb . <nl> default feign client does not support patch verb <cm-sep> remove test for get endpoint with request body <cm-sep> configure junit in gradle build <cm-sep> configure logback for unit tests <cm-sep> add missing dependencies to sbt <cm-sep> fix gradle dependency <cm-sep> add logback to gradle unit test <cm-sep> regenerate samples <para-sep> model tests for { { classname } } <nl> model tests for { { classname } } <nl> todo : test { { classname } } <nl> test the property ' { { name } } ' <nl> todo : test { { name } } <nl> todo <nl> todo can not serialize bytearray to x-www-form-urlencoded , must use multipart <nl> todo get method does not allow request body <nl> to test class name in snake case to test class name in snake case <nl> api tests for petap <nl> delete purchase order by id for valid response try integer ids with value & lt ; 0. anything above 0 or nonintegers will generate api errors <nl> returns pet inventories by status returns a map of status codes to quantities <nl> find purchase order by id for valid response try integer ids with value & lt ; & # x3d ; 0 or & gt ; 0. other values will generated exceptions <nl> place an order for a pet","hello . <nl> this pr includes the following changes . <nl> - unit tests for java feign client <nl> - implement the unit tests with junit5 <nl> - set default feign http client to okhttp , the default feign client does not support patch verb . <nl> cc : .",1611142892,"as a first step to refactor inlinemodelresolver , this pr applies minor fixes which is recommened by intellij idea . 🏭 .",0.907650351524353
apache_kafka/10891,add reset to snapshotregitry and revertable <para-sep> reverts to the initial value . <nl> collection of all revertable registered with this registry <nl> associate with this registry . <nl> delete all snapshots and resets all of the revertable object registered . <nl> check that the table is empty,allow revertable types to reset to their initial values by calling snapshotregistry : :reset . this is needed to be able to support re-loading snapshots in the inactive/follower controllers .,1623873345,"* the deadletterqueuereporter has a kafkaproducer that it must close to clean up resources <nl> * currently , the producer and its threads are leaked every time a task is stopped <nl> * responsibility for cleaning up errorreporters is transitively assigned to the <nl> processingcontext , retrywithtoleranceoperator , and workersinktask/workersinktask classes <nl> * one new unit test in errorreportertest asserts that the producer is closed by the dlq reporter . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate",0.9376556277275085
apache_pulsar/10337,fix cpu 0 % in some cases <para-sep> init namespace <nl> init topic and policies,"this will trigger topic 's <nl> however , in onpoliciesupdate , the data of the policies node on zk will be read , such as : <nl> due to the deletion of the namespace , the zk node may no longer exist at this time . <nl> failure to read data will trigger infinite retries . <nl> if there are many topics , there will be a short-term cpu spike .",1619162719,"when the subscriptions reach the max subscriptions of the topic , the broker should reject the new subscription request and reject the consumer to subscribe to this topic . <nl> 0. add limit max subscriptions per topic .",0.933692216873169
grpc_grpc-java/8039,fix validation of hcm filter and router httpfilter <para-sep> - application_protocols is non-empty,- do n't enforce a specific name-match for hcm and router httpfilter <nl> - do n't allow ' managed-mtls ' in the application-protocols .,1617301341,"the original intention was only generating status proto from trailers . in actual use cases requires to handle null and derive the status proto from status . the main reason is there are few cases when the server does n't send trailers such as server unreachable , unavailable or deadline_exceeded .",0.8797534108161926
jenkinsci_jenkins/5054,"draft change to integrate a draft remoting pr . <nl> adds retries to some additional remoteclassloader operations . <nl> restructures the retries for improved consistency . <para-sep> if we receive an interruptedexception here , we probably ca n't do much anyway . perhaps we should just return at this point since we probably ca n't do anything else . it might make sense to introduce retries , but it 's probably not going to get better .","there is n't much that can be done with the exception further up the stack . acknowledge it here and log it , in case in can later be used for some troubleshooting . <nl> this case may get triggered in some situations in which the revised rcl logic in remoting version handles some issues . since the interrupts are now handled differently , it may propagate to this level , but there still is n't anything useful to be done here .",1605030801,"[ fix ] : use english as default-locale , so the resourcebundleutiltest runs also on systems with other default os locales .",0.8197099566459656
OpenAPITools_openapi-generator/9033,"turns on setting model.additionalproperties for composed schemas when supportsadditionalpropertieswithcomposedschema is true , tests updated for v2 and v3 specs <para-sep> if we are trying to set additionalproperties on an empty schema stop recursing <nl> this is the legacy config that most of our tooling uses <nl> map_string <nl> map_with_additional_properties <nl> map_without_additional_properties <nl> check of composed schema model <nl> the petstore-with-fake-endpoints-models-for-testing.yaml does not set the 'additionalproperties ' keyword for this model , hence assert the value to be null . <nl> when the 'additionalproperties ' keyword is not present , the model should allow undeclared properties . <nl> map_string this property has the following inline schema . additionalproperties : type : string <nl> map_with_additional_properties this property has the following inline schema . additionalproperties : true <nl> it is unfortunate that child.getadditionalproperties ( ) returns null for a v2 schema . we can not differentiate between 'additionalproperties ' not present and additionalproperties : true . <nl> map_without_additional_properties this property has the following inline schema . additionalproperties : false <nl> it is unfortunate that child.getadditionalproperties ( ) returns null for a v2 schema . we can not differentiate between 'additionalproperties ' not present and additionalproperties : false . <nl> check of composed schema model <nl> map_with_undeclared_properties_string <nl> map_with_undeclared_properties_anytype_1 <nl> map_with_undeclared_properties_anytype_2 <nl> map_with_undeclared_properties_anytype_3 <nl> empty_map <nl> check of composed schema model <nl> as per oas spec , when the 'additionalproperties ' keyword is not present , the schema may be extended with any undeclared properties . however , in legacy 'additionalproperties ' mode , this is interpreted as 'no additional properties are allowed ' .","sets model.additionalproperties for composed schemas <nl> this allows v2 spec additionalproperties values to default to { } ( anytype schema ) when omitted <nl> no generator uses this data yet . <nl> tests updated for v2 and v3 additionalproperties checking <nl> v2 specs , legacy behavior ( disallowadditionalpropertiesifnotpresent = true , supportsadditionalpropertieswithcomposedschema = false ) <nl> - additionalproperties unset/false/true - > model.additionalproperties = null <nl> - additionalproperties schema - > model.additionalproperties = schema . <nl> v2 specs , new behavior ( disallowadditionalpropertiesifnotpresent = false , supportsadditionalpropertieswithcomposedschema=true ) <nl> - additionalproperties unset/false/true - > model.additionalproperties = { } anytype schema <nl>",1616343096,"cli now supports , which will output a file change status similar to git status -- porcelain . this option will be necessary in order to present users with vendor extensions which heavily rely on the generator inputs and often on logic defined by some generator implementations which is only evaluated during generation . <nl> the user may also specify for a one-liner below each file explaining why the change operation might take place . <nl> this pr also cleans up some lint warnings and improves general code cleanliness <nl> of defaultgenerator . <nl> specifically : . <nl> * logger",0.9518601298332214
apache_druid/10904,"introduce primitive-typed bucketstart , increment methods . <nl> saves creation of unnecessary datetime objects in timestamp_floor and <nl> timestamp_ceil expressions . <para-sep> same as above , but using the millis form of the method .","saves creation of unnecessary datetime objects in timestamp_floor and <nl> timestamp_ceil expressions . <nl> i was running a query that had a in it and was greeted by the following flame graph : . <nl> 0 % of the time is spent on . it 's not necessary , because the periodgranularity code is doing the hard work on the primitive milliseconds .",1613722874,"it does n't appear to be necessary , so i have removed it to reduce confusion and lower maintenance overhead to not require any consumer of an implementation to add it 's url prefix to the filter in order for it to behave as intended were this code path actually in place .",0.9365352988243103
Graylog2_graylog2-server/10699,"fix apache httpclient to version version . <nl> managing and fixing the http client to a specific version works <nl> around resolving the dependency to different versions in plugins . <cm-sep> expose docker network of graylog backend test container . <nl> expose the docker network , so that other containers that need to be <nl> launched during a test can use the same network .",exposes the docker network that is used for the backend test containers . <nl> this is useful if a test needs to spin up an additional container which has to be reachable by the graylog server .,1621931149,"this pr handles the situation when es is not available and displays a warning dialogue with some information . <nl> i also saw that the es cluster health was not being refreshed in the system overview page , and now we update the information when the component is mounted .",0.8754241466522217
Alluxio_alluxio/13119,"add unique blocking queue implementation <cm-sep> convert to using uniqueblockingqueue <para-sep> a blocking queue containing only unique elements , based on linkedblockingqueue implementation . we serialize the insertion into the queue , otherwise , we may end up with duplicate elements in the queue . <nl> constructor for a uniqueblockingqueue . <nl> the interface description suggests that offer can only fail for capacity reason , but we are failing for uniqueness reasons . <nl> the interface description suggests that offer can only fail for capacity reason , but we are failing for uniqueness reasons . <nl> do nothing <nl> asynccachetask is a runnable task that can be considered equal if the blockid of the request is the same . <nl> constructor for an asynccachetask . <nl> only care about the block id being the same . do not care if the source host or port is different . <nl> only care about the block id being the same . do not care if the source host or port is different . <nl> check if the block has already been cached on this worker <nl> depends on the request , cache the target block from different sources","this is done so that duplicated tasks are not added to the queue , causing the queue to fill up and eventually start rejecting legitimate async caching requests .",1616618081,added apis for intercepting grpc client and server with custom data serialization/deserialization . <nl> also made the worker send read response asynchronously to improve throughput for single read request .,0.9880537390708923
hazelcast_hazelcast/18852,"fix multiple jet enabled logs issue . <nl> i added a new flag to disable the first jetextension # onclusterversionchange <nl> call so that it does not take effect when called after the first initial <nl> version setting . because its intended use is only on cluster version <nl> upgrades , not the initial version setting . after this change only after <nl> afterstart is called , these jetextension # onclusterversionchange calls <nl> will be effective . <para-sep> activate jet after rolling upgrade in which the cluster version is upgraded from 0.x to version","this pr aims to disable <nl> callbacks made before is being performed . <nl> since 's intended use ( while it <nl> is introduced by me ) , is to be called after the cluster version upgrade <nl> scenarios , not at the initial version setting . although running this after <nl> the initial version setting did not cause execution errors , it was producing <nl> meaningless logs . <nl> due to this issue , the log that should normally be printed in rolling upgrade <nl> scenarios , was being printed at startup time : . <nl> also , this",1623077203,"the test occasionally fails but the attempt limit is set to the default <nl> number of 0. since a lot of tests increase this limit , we are increasing <nl> it here as well .",0.868269145488739
apache_pulsar/10628,pulsar admin : return a better error message,"sometimes , in case of internal server error pulsar admin users see this kind of errors : . <nl> handle inputstream and try to extract properly the string . <nl> this change is a trivial rework / code cleanup without any test coverage .",1621353847,"adding a subdirectory associated with current time willmake it easier to process hdfs files in batch . <nl> for example , user can create multiple running sink instances with pattern . then stop all instances at next hour . eventually , files of the subdirectory will contain all messages consumed during this hour . <nl> - add a field to <nl> - update some simple tests for <nl> - update the doc of hdfs2 sink . <nl> - does this pull request introduce a new feature ? ( yes ) <nl> - if yes , how is the feature documented",0.9362578988075256
elastic_elasticsearch/74678,"fix combinedfieldquery ( lucene 0 ) . <nl> this commit moves a fix for a bug in multinormsleafsimscorer in lucene that <nl> fixes an error in the new combinedfieldquery for missing values . this is a <nl> temporary copy of the affected query and its updated dependencies that should be <nl> removed again once we are able to use the original fix from lucene . <para-sep> these should be temporary , query needs package private access to termscorer though",this commit moves a fix for a bug in multinormsleafsimscorer in lucene that <nl> fixes an error in the new combinedfieldquery for missing values . this is a <nl> temporary copy of the affected query and its updated dependencies that should be <nl> removed again once we are able to use the original fix from lucene .,1624964068,"this commit adds aggregation support for the geo_shape field <nl> type on geo * _grid aggregations . <nl> it introduces a tiler for both tiles and hashes that enables a new type of <nl> valuessource to replace the geopoint 's cellidsource . this makes it possible <nl> for the existing aggregator to be re-used , so no new implementations of <nl> the grid aggregators are added .",0.9868937730789185
OpenAPITools_openapi-generator/9196,add multiple frameworks support <cm-sep> test in appveyor <para-sep> multiple target framework <nl> just a single value <nl> throws exception if the input targetframework is invalid <nl> not intended to be user-settable <nl> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .plg <nl> .opt <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> configure oauth2 access token for authorization : petstore_auth <nl> add a new pet to the store <nl> petapi | addpet | post /pet | add a new pet to the store petapi | deletepet | delete /pet/ { petid } | deletes a pet petapi | findpetsbystatus | get /pet/findbystatus | finds pets by status petapi | findpetsbytags | get /pet/findbytags | finds pets by tags petapi | getpetbyid | get /pet/ { petid } | find pet by id petapi | updatepet | put /pet | update an existing pet petapi | updatepetwithform | post /pet/ { petid } | updates a pet in the store with form data petapi | uploadfile | post /pet/ { petid } /uploadimage | uploads an image storeapi | deleteorder | delete /store/order/ { orderid } | delete purchase order by id storeapi | getinventory | get /store/inventory | returns pet inventories by status storeapi | getorderbyid | get /store/order/ { orderid } | find purchase order by id storeapi | placeorder | post /store/order | place an order for a pet userapi | createuser | post /user | create user userapi,- add multiple frameworks support <nl> - tested with .,1617775561,"this adds support for callbacks to rust server . this is a reasonable substantial change to the templates - mainly to prevent duplication between the server and client cases . <nl> the key change that callbacks make is that the server now needs to act as a client ( in order to send callbacks ) , and the client needs to act as a server ( in order to receive callbacks ) . <nl> as such , we modify the generator to produce a and a module . these are only generated if the api uses callbacks ( to avoid",0.9366875886917114
neo4j_neo4j/11813,make tx-state aware <cm-sep> make tx-state aware <para-sep> given <nl> then <nl> given <nl> then <nl> given <nl> then <nl> given <nl> then <nl> given <nl> then <nl> given <nl> then,the method of and and of were n't considering transaction state .,1526642395,"if creation of a gbptree index file is interrupted mid-way , e.g . by process <nl> crashing or something similar then the index file will exist , but its <nl> meta pages empty or half-initialized . previously only a missing index file <nl> was interpreted correctly by throwing ioexception , such that the layer <nl> immediately above gbptree would recognized that and rebuild that index or similar , <nl> whereas the other cases of half-initialized meta pages would throw other <nl> types of internal exceptions and not be properly handled by above layer . <nl> this commit improves on this",0.9487967491149902
apache_shardingsphere/10558,"add definition for with clause <cm-sep> add start , stop indices for subquery segment <para-sep> get with segment . <nl> get with segment .","please check it . i 'll change them based on your feedback . <nl> changes proposed in this pull request : <nl> - added sql definition for statement 's with clause . <nl> - added test cases for with clause . <nl> - i asserted subquery in the . <nl> - in the , i changed the 's start and stop indices by getting from 's .",1622391487,changes proposed in this pull request : <nl> - support mysql insert select statement parse <nl> - add some test cases,0.9593339562416077
OpenAPITools_openapi-generator/9063,"use interruptedexception , ioexception instead of just exception <cm-sep> undo changes to the license","- use interruptedexception , ioexception instead of just the generic to improve the code quality .",1616596520,"otherwise the client has to check for the type ( interruptedexception ) of the cause of the thrown exception . <nl> note that i did n't commit the output of running the ./bin/ scripts ... it seemed to create a much larger diff than i expected , that i 'm not sure it 's doing the right thing .",0.7678627371788025
ballerina-platform_ballerina-lang/30704,"fix incorrect parsing of field access expression <nl> fix incorrect parsing of field access expression , add support for function type desc with complex binding patterns <cm-sep> add test cases",0 . $ title <nl> 0. add support for function type desc with complex binding patterns <nl> 0. add keyword to method .,1621571039,"for now this supports following constructs of the ballerina language . <nl> - functions <nl> - connectors initial support <nl> - actions initial support <nl> - structs initial support <nl> - enum initial support <nl> - global and local variable initial support . <nl> there are few scenarios which are still not supporting , like search inside if condition , while condition , endpoint creation . support for these will be added soon with future releases . <nl> note : there is an issue with position calculation of nodes as some nodes ( i.e . enum ) contains 0 as",0.8686932921409607
apache_shardingsphere/10562,support pg tablespace statement <cm-sep> support mysql tablespace statement <para-sep> alter tablespace statement . <nl> create tablespace statement . <nl> drop tablespace statement . <nl> mysql alter tablespace statement . <nl> mysql create tablespace statement . <nl> mysql drop tablespace statement . <nl> postgresql alter tablespace statement . <nl> postgresql create tablespace statement . <nl> postgresql drop tablespace statement .,changes proposed in this pull request : <nl> - support mysql & pg tablespace statement,1622429523,"changes proposed in this pull request : <nl> - support mysql store procedure create , alter , drop , call statement parse",0.9781737923622131
vespa-engine_vespa/17441,"funnel type resolving through outputtype ( ) <cm-sep> remove duplicated code <cm-sep> just log warning when reducing unknown dimension <cm-sep> wire in typeresolver.reduce <para-sep> throw new illegalargumentexception ( ' reducing non-existing dimension ' +name+ ' in type ' +inputtype ) ; <nl> for now , these will just log a warning checkreducefails ( ' tensor ( ) ' , ' x ' ) ; checkreducefails ( ' tensor ( y { } ) ' , ' x ' ) ; checkreducefails ( ' tensor ( y [ 0 ] ) ' , ' x ' ) ; checkreducefails ( ' tensor ( y [ 0 ] ) ' , ' x ' ) ;",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618483811,"i attempted to make the change to directly , but it broke a lot of tests which assume that they can ready provisioned nodes . the method seems to only be used by tests .",0.9302430748939514
vespa-engine_vespa/18375,"schedule upgrade to stable os version <para-sep> returns the current stable os version for the given major version * / <nl> a stable os version . <nl> the version number * / <nl> returns the time this was promoted to stable * / <nl> clouds present in this system * / <nl> automatically schedule upgrades to the next os version . <nl> upgrade to given release in cloud * / <nl> the version number of this * / <nl> the budget to use when upgrading to this * / <nl> os release based on a stable tag * / <nl> the cool-down period that must pass before a stable version can be used * / <nl> os release based on calendar-versioning * / <nl> the time to wait before scheduling upgrade to next version * / <nl> the interval at which new versions become available . we use this to avoid scheduling upgrades to a version that has not been released yet . example : version n is the latest one and target is set to n+0 . if n+0 does not exist the zone will not converge until n+0 has been released and we may end up triggering multiple rounds of upgrades . <nl> todo ( mpolden ) : remove this block after 0-0-0. if we have n't written scheduledat at least once , we need to deduce the scheduled instant from the version . <nl> todo ( mpolden ) : require after 0-0-0 <nl> returns when this target was scheduled * / <nl> initial run does nothing as the cloud does not have a target <nl> target is set <nl> simulate setting target without scheduledat , to force parsing scheduled time from version number <nl> just over 0 days pass , and a new target replaces the expired one <nl> set initial target <nl> new version is promoted to stable <nl> enough time passes since promotion of stable release <nl> another version is promoted , but target remains unchanged as the release has n't aged enough",merge together with internal pr .,1624432062,"- introduce a new type of suspension status : permanently_down , which <nl> is set when a node is scheduled to be removed from the application . <nl> a normal resume call will not clear permanently_down . <nl> - store a json for each suspended host : contains status , and a since timestamp <nl> for the time when the node was suspended . the suspension timestamp <nl> is preserved when switching statuses between suspension statuses . <nl> - the json is stored in a new path , void of any zone . this means that <nl> we eventually can",0.9838731288909912
vespa-engine_vespa/18317,"do not create application package notification for reindexing <cm-sep> add notification level info <cm-sep> add notification type reindex <cm-sep> add reindexing progress to deployment metrics <cm-sep> create reindex notifications from deployment metrics <para-sep> application cluster is reindexing document ( s ) * / <nl> updates notifications based on deployment metrics ( e.g . feed blocked and reindexing progress ) for the given deployment based on current cluster metrics . will clear notifications of any cluster not reporting the metrics or whose metrics indicate feed is not blocked or reindexing no longer in progress . will set notification for clusters : - that are ( level.error ) or are nearly ( level.warning ) feed blocked , - that are ( level.info ) currently reindexing at least 0 document type . <nl> filter out old feed block notifications and reindex for this deployment <nl> find the max among levels <nl> cluster1 and cluster2 are having feed block issues , cluster 0 is reindexing <nl> cluster1 improves , while cluster3 starts having feed block issues and finishes reindexing 'build ' documents",must be merged with internal pr,1624016055,ignore response filter chain bindings when constructing access control filter chains . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9530054926872253
elastic_elasticsearch/73121,"get rid of anonymous inners <cm-sep> format errors should hint mappings may be the cause <para-sep> use an explicit * <nl> singleton , stateless formatter for ' raw ' values , generally taken to mean keywords and other strings . <nl> singleton , stateless formatter , for representing bytes as base64 strings <nl> singleton , stateless formatter for geo hash values <nl> stateless , singleton formatter for boolean values . parses the strings ' true ' and ' false ' as inputs . <nl> stateless , singleton formatter for ip address data","when an aggregation gets run across multiple indices with conflicting mappings ( e.g . one maps the field being aggregated as an ip address and another maps it as a keyword ) , the situation can go undetected until the formatting stage . formatting can then fail with an unhelpful error ( e.g . ) . this pr catches many such errors and wraps them with a clearer error message , which will hopefully steer users towards a resolution .",1621020254,"this commit removes the configuration time vs execution time distinction <nl> with regards to certain buildparms properties . because of the cost of <nl> determining java versions for configuration jdk locations we deferred <nl> this until execution time . this had two main downsides . first , we had <nl> to implement all this build logic in tasks , which required a bunch of <nl> additional plumbing and complexity . second , because some information <nl> was n't known during configuration time , we had to nest any build logic <nl> that depended on this in awkward callbacks . <nl>",0.9481574296951294
confluentinc_ksql/7416,allow collect_ * to be configured with string values,"the properties file by default sets the properties as strings , not integers , so the old mechanism of casting to a number does n't work . <nl> unit test + local testing .",1619049922,"the api is a new method added in kafka version . if ksql runs on kafka version or lower , this api will return null causing a npe in ksql and denying any operation executed on a kafka version environment . <nl> to avoid the npe issue , ksql avoids enabling the topic validator instead . look at the which checks if the from the cluster is null . <nl> run local tests with kafka version . warning message is printed : . <nl> [ 0-0-0 0:0:0,0 ] warn the kafka broker has an authorization service enabled , but the",0.9233301281929016
apache_shardingsphere/10430,add update from event test cases for datasourcestatusregistryservice,changes proposed in this pull request : <nl> - add update from event test cases for datasourcestatusregistryservice,1621634795,"changes proposed in this pull request : <nl> - assertisnotserialexecutewhennotintransaction , assertisnotserialexecutewhenintransactionandbasetransactiontype , assertisserialexecutewhenintransactionandlocaltransactiontype and assertisserialexecutewhenintransactionandxatransactiontype added",0.9374566674232483
Alluxio_alluxio/13114,"wait file closed before umount fuse <cm-sep> make sure ce willbe removed <para-sep> release operation is async , we need to make sure all out stream is closed before umount the fuse","since release function is async , we need to wait for all out stream closed before umount the fuse",1616471294,"after mkdirs , the directories owner should be set to the client end-user . <nl> also added a new configuration to allow ufs setowner failure , if users would like to proceed in case the alluxio service is not a ufs super user .",0.9248979687690735
apache_incubator-pinot/6627,allow escaping comma characters in csv files . <para-sep> check if we can parse a csv file that has escaped comma characters within fields . <nl> create csv config with backslash as escape character . <nl> create a csv file where records have two values and the second value contains an escaped comma . <nl> try to parse csv file with escaped comma . <nl> check if parsing succeeded .,"such a file would be difficult to import as a table since comma is being used as a field delimiter . note that is not specific to comma character , but can happen with any other delimiter character as well . this pr adds support for escaping delimiters that appear within csv fields so that they do n't get confused with actual delimiters . <nl> example csv file with fields containing escaped comma delimiter : . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that",1614654031,"this pull request removes dependency on collectionconfig , collectionschema and dashboardconfig . it uses the metricconfig , datasetconfig and dahsboardconfig tables generated by the script which migrated datasets into database . <nl> tested that the dashboard works with these changes . the detectionscheduler and workers have also been tested <nl> todo : test alert , monitor and merge",0.9137269258499146
grpc_grpc-java/8194,"core , netty : support socketaddress with channelcredentials . <nl> this adds support for creating a netty channel with socketaddress and channelcredentials . <nl> this aligns with nettyserverbuilder.foraddress ( socketaddress address , servercredentials creds ) . <para-sep> creates a new managed channel builder with the given server address , authority string of the channel . transport implementors must provide client transport factory builder , and may set custom channel default port provider . <nl> creates a new builder with the given server address . this factory method is primarily intended for using netty channel types other than socketchannel . if an unresolved inetsocketaddress is passed in , then it will remain unresolved .","this adds support for creating a netty channel with socketaddress and channelcredentials . <nl> this aligns with nettyserverbuilder.foraddress ( socketaddress address , servercredentials creds ) . <nl> ( sorry for all the commits , i do n't have a local build environment , please squash )",1621682822,"this is mainly aimed at allowing android users to force the okhttp channel to use a particular network , via providing a socket factory obtained from ) . the corresponding feature request from an internal user is at b/0 .",0.9507474303245544
apache_beam/14604,"allow unboundedly large side inputs in portable java . <nl> we now cache just the ( decoded ) first page of elements read over <nl> the state api , rather than the whole thing . <nl> there is a slight change of semantics here : the pages must be delimited <nl> at element boundaries . this is already the case for elements sent over <nl> the data channel , other langauges , and all runners , but required some <nl> changes to tests . <para-sep> this adapter handles using the continuation token to provide iteration over all the elements returned by the beam fn state api using the supplied state client , state request for the first chunk of the state stream , and a value decoder . the first page , and only the first page , of the state request results is cached for efficient re-iteration for small state requests while still allowing unboundedly large state requests without unboundedly large memory consumption . <nl> a iterable that contains a single element , provided by a supplier which is invoked lazily . * / <nl> an helper class that ( lazily ) gives the first page of a paginated state request separately from all the remaining pages . <nl> chunk gets into 0 byte return blocks <nl> compute the new continuation token <nl> ensure it 's fully lazy . <nl> no more is read than necissary . <nl> the first page is cached . <nl> the contents agree .","we now cache just the ( decoded ) first page of elements read over <nl> the state api , rather than the whole thing . <nl> there is a slight change of semantics here : the pages must be delimited <nl> at element boundaries . this is already the case for elements sent over <nl> the data channel , other langauges , and all runners , but required some <nl> changes to tests",1619023946,"wire up the docker environmentfactory , and make the environment choice configurable . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .",0.9756048917770386
OpenAPITools_openapi-generator/9631,bump swagger-parser-version to v2.version <para-sep> use # tostring because the equals methods is a little stricter than necessary for this test,this pr updates the upstream version and adds a test for this issue .,1622475899,"0. add a new ' useabstractionforfiles ' config option that uses abstract objects instead of files where files are needed . with this option , the user will be able to use byte array or input stream instead of java.io.file . the new config option is currently supported only by the resttemplate library . <nl> 0. fix the dir path mentioned in the pull request template .",0.9274920225143433
apache_kafka/10309,"; loosen end offset validation of remote replicas <para-sep> follower crashes and disk is lost . it fetches an earlier offset to rebuild state . the leader will report an error in the logs , but will not let the high watermark rewind <nl> we run this test without the and invariants since the loss of committed data on one node can violate them . <nl> kill a random node and drop all of its persistent state . the raft protocol guarantees should still ensure we lose no committed data as long as a new leader is elected before the failed node is restarted . <nl> now restart the failed node and ensure that it recovers .","currently the raft leader raises an exception if there is a non-monotonic update to the fetch offset of a replica . in a situation where the replica had lost it disk state , this would prevent the replica from being able to recover . in this patch , we relax the validation to address this problem . it is worth pointing out that this validation could not be relied on to protect from data loss after a voter has lost committed state .",1615587241,remember the of the last update to metadata so we can avoid unnecessarily checking each partition for leader epoch changes on every call to,0.96604984998703
apache_druid/11004,"vectorize longdeserializers . <nl> also , add many more tests . <cm-sep> more faster <cm-sep> more more faster <cm-sep> more cleanup <para-sep> name of the long encoding strategy . for longs , this is a composite of both byte level block compression and encoding of values within the block . <nl> todo : filter set distributions to simulate different select patterns ? ( because benchmarks do n't take long enough already .. ) <nl> setup bitset filter <nl> skip already selected rows if any <nl> for testing encodings : validate that all encoders read the same values noinspection unused <nl> controls the probability that any generated value will be a zero , to simulate sparely populated columns <nl> number of rows generated for the value distribution <nl> value distributions to simulate various patterns of long column <nl> number of rows in the segment . if it is smaller than only this many rows will be read , if larger then the benchmark will explode trying to read more data than exists rows . this is a hassle , but ensures that the row count ends up in the output measurements . <nl> path to a segment file to read long columns from . this should n't really be used as a parameter , but is nice to be included in the output measurements . this is byo segment , as this file does n't probably exist for you , replace it and other parameters with the segment to test . <nl> friendly name of the segment . <nl> writes column values to an intermediary text file , 0 per line , encoders read from this file as input to write encoded column files . <nl> uncomment this block to run sanity check to ensure all specified encodings produce the same set of results checkstyle.off : regexp immutablelist all = immutablelist.of ( ' lz4-longs ' , ' lz4-auto ' ) ; for ( string _enc : all ) { if ( ! _enc.equalsignorecase ( encoding ) ) { setupfromfile ( _enc ) ; } } checksanity ( decoders , all , rows ) ; checkstyle.on : regexp <nl> uncomment this block to run sanity check to ensure all specified encodings produce the same set of results checkstyle.off : regexp list all = immutablelist.of ( ' lz4-longs ' , ' lz4-auto ' ) ; for ( string _enc : all ) {","it works by unrolling value reads to line up with get methods to eliminate overlapping reads where possible , reading blocks of 0 values at a time for un-aligned values ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) . aligned bit-packing widths ( 0 , 0 , 0 , 0 ) actually performed worse when this same unrolling was performed , so instead they utilize a traditional for loop with the aligned get methods . <nl> most of the improvement is on the small end since it has the",1615951623,"the copied is from as of verison version instead of master , since this commit seems to have broken backwards compatibility by using 0 bytes instead of 0 to store and test ints/floats . <nl> the copied implementation should be removed once the linked hive ticket is resolved and the fix is released so we can update .",0.9240070581436157
vespa-engine_vespa/18032,"use inheritance information from the uncompiled rankprofile to sort out when <nl> to use extrenal files , and when they are overridden . <para-sep> todo this merges all functions from inherited profiles too and erases inheritance information . not good . <nl> due to compiled rankprofiles flattening inheritance we need to use the uncompiled to sort out what comes from external files and not .","use inheritance information from the uncompiled rankprofile to sort out when . <nl> to use extrenal files , and when they are overridden .",1622418147,"take a look , but do not merge . i have yet to get proof of concept in a proper test .",0.9717251062393188
grpc_grpc-java/8000,"ads parsing change : collect all errors before nack <para-sep> unpack the listener . <nl> process listener into ldsupdate . <nl> ldsupdate parsed successfully . <nl> unpack httpconnectionmanager from the listener . <nl> obtain max_stream_duration from http protocol options . <nl> parse filters . <nl> parse rds info . <nl> found inlined route_config . parse it to find the cluster_name . <nl> found rds . <nl> unpack the routeconfiguration . <nl> process routeconfiguration into rdsupdate . <nl> unpack the cluster . <nl> process cluster into cdsupdate . <nl> cds responses represents the state of the world , eds resources not referenced in cds resources should be deleted . <nl> unpack the clusterloadassignment . <nl> process clusterloadassignment into edsupdate . <nl> note endpoints with health status other than healthy and unknown are still handed over to watching parties . it is watching parties ' responsibility to filter out unhealthy endpoints . see envoyprotodata.lbendpoint # ishealthy ( ) . <nl> notify the watchers . <nl> for state of the world services , notify watchers when their watched resource is missing from the ads update . <nl> attach error details to the subscribed resources that included in the ads update . <nl> initialize metadata in unknown state to cover the case when resource subscriber , is created but not yet requested because the client is in backoff . <nl> initial fetch scheduled or rescheduled , transition metadata state to requested . <nl> the metadata of the xds resource ; used by the xds config dump . <nl> the last successfully updated version of the resource . * / <nl> the client status of this resource . * / <nl> the timestamp when the resource was last successfully updated . * / <nl> the last successfully updated xds resource as it was returned by the server . * / <nl> the metadata capturing the error details of the last rejected update of the resource . * / <nl> resource status from the view of a xds client , which tells the synchronization status between the xds client and the xds server . this is a native representation of xds configdump clientresourcestatus , see config_dump.proto <nl> captures error metadata of failed resource updates . this is a native representation of xds configdump updatefailurestate , see config_dump.proto <nl> the rejected version string of the last failed update attempt . * / <nl> details about the last","as specified in grfc a40 — ads parsing logic update : continue after first error , this pr changes ads parsing logic to not stop on the first error , but process all resources , and capture errors in resource metadata .",1616200875,loadbalancers that call the old will get implicitly called with a listener that passes updates to the deprecated . those who call the new will have to call explicitly . <nl> this pr has 0 commits : <nl> 0. roll forward the original change . <nl> 0. revert grpclb back to the old api . see commit message for the reason . <nl> 0. the revision . <nl> nothing new is introduced in commits 0 and 0. reviewers should only need to review commit 0 .,0.9726710915565491
apache_camel/5612,- base commit for huawei cloud function graph component . <nl> this commit contains the camel component for integrating with huawei cloud 's function graph ( serverless funtions ) . <para-sep> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> since camel { since } * <nl> { component-header } * <nl> component options : start <nl> component options : end <nl> endpoint options : start <nl> endpoint options : end <nl> huawei cloud component to integrate with functiongraph services <nl> initialize the client <nl> convert exchange body to map object <nl> checking for function name and function package <nl> invoke the function <nl> update dynamic client configurations <nl> checking for required operation <nl> checking for required function name ( exchange overrides endpoint function name ) <nl> checking for optional function package ( exchange overrides endpoint function package ) <nl> checking for optional xcfflogtype <nl> set all dynamic configurations to null <nl> gets the fieldname from the jsonstring and returns it as a string <nl> returns the urn based on urnformat and clientconfigurations <nl> checking for required region <nl> checking for optional proxy authentication <nl> checking for required project id <nl> checking for ignore ssl verification <nl> checking for required cloud ak ( authentication key ) <nl> checking for required cloud sk ( secret key ) <nl> the following test cases should be manually enabled to perform test against the actual huaweicloud functiongraph server with real user credentials .,"functiongraph is huawei cloud 's offering for serverless computation service that lets you run code without provisioning or managing servers , creating workload-aware cluster scaling logic , maintaining event integrations , or managing runtimes . this service allows you to run your code ensuring high availability and scalability . all you need to do is upload your code and set execution conditions and functiongraph will take care of the rest . <nl> this pr contains camel component for integrating with already existing functions ( created by the cloud user via huaweicloud webconsole ) .",1622487794,this adds azure eventhubs component .,0.9868640899658203
gocd_gocd/8486,update modifications api <nl> - send user display name - which sends 'anonymous ' when username is not set <cm-sep> updated the modification modal <nl> - styled it like a table <nl> - revision and username are truncated as needed <cm-sep> render comment as is . <nl> - render comment with a fixed height with a scroll bar for longer messages,description : <nl> updated modifications modal on materials spa <nl> - render modifications in a tabular format <nl> - render comment as is . in case of longer messages - make it scrollable,1598431873,description : <nl> - fix password shown as plain text <nl> - the scm api would not encrypt as secure variable if the value is passed instead of encrypted_value . they would get encrypted when a full config save happens . fixed that for all versions <nl> - fixed broken hover message and no usage found message,0.791906476020813
neo4j_neo4j/11492,dump internal and user logs on test failure to diagnose the problem <para-sep> prints logs to the specified print stream if log is available * /,we have come across a couple of tests that need access to server logs in order to get an insight about what was happening . this pr adds a capability of dumping user and internal logs to standard output on test failures to .,1523270983,"we 're not in a good spot if we fail to apply a transaction . such failures would <nl> happen after a transaction has already been committed , or during recovery . both <nl> are awful places for exceptions to pop out . <nl> this commit captures exceptions that occur during apply , and wraps them in <nl> another exception that adds information about the transaction , e.g . log <nl> position , which might be helpful for debugging the cause of the failure .",0.9584826827049255
apache_incubator-pinot/6658,add context on data type transform failure . <para-sep> note : the standardized value could be null for empty collection/map/object [ ] . <nl> convert data type if necessary <nl> multi-value column <nl> single-value column,bubbles up the column name on failure when generating segments with invalid schema .,1615243978,this pr fixes shutdown method in helixinstancedatamanager . <nl> currently the shutdown method does n't call the shutdown methods for all the tables .,0.7642354369163513
apache_incubator-pinot/6583,"implement queryop class . <nl> implement queryop class , which take a file that has queries , and <nl> a file that has results , run the queries through the broker/server <nl> and compare the results with the result file . <para-sep> queries the broker 's sql query endpoint ( /sql ) <nl> queries the broker 's sql query endpoint ( /sql ) <nl> todo : verify by getting the number of rows before adding the segment , and the number of rows after adding the segment , then make sure that it has increased by the number of rows in the segment . <nl> if the test compares the returned results to be a subset of total qualified results , ignore the comparison of result length and metadata ( numdocsscanned , numentriesscannedinfilter , numentriesscannedpostfilter , etc ) . <nl> sort elements","if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1613504597,initial code drop for output format design review .,0.9804072380065918
apache_pulsar/10257,transaction buffer client add look up . <cm-sep> fix end topic and add test,"it ca n't init in broker , so the command will always fail . <nl> 0. add a cache for the transaction buffer client . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest",1618759086,"this is very bad because we 're calling that from io threads which are used for critical publish tasks . <nl> several internal methods introduced in that commit are async on the surface , though are blocking in practice . <nl> additionally , the logic for checking that a topic exists is unnecessarily expensive : fetching the list of topics in a namespace and then iterating through the list to compare with the current topic . <nl> refactored the handling of partitionmetadatarequest to ensure everything is end-to-end async .",0.9681593179702759
grpc_grpc-java/7859,support xdsclient parsing endpoint load balancing policy other than round_robin . <cm-sep> add per-route hashing policy configuration . <para-sep> ignore <nl> list of hash policies to use for ring hash load balancing . <nl> configuration for the route 's hashing policy if the upstream cluster uses a hashing load balancer . <nl> the specifier that indicates the component of the request to be hashed on . <nl> the flag that short-circuits the hash computing . <nl> the name of the request header that will be used to obtain the hash key . only valid if type is header . <nl> the regular expression used to find portions to be replaced in the header value . only valid if type is header . <nl> the string that should be substituted into matching portions of the header value . only valid if type is header . <nl> xds resource update for cluster-level configuration . * / <nl> endpoint-level load balancing policy . <nl> only valid if lbpolicy is ' ring_hash ' . <nl> only valid if lbpolicy is ' ring_hash ' . <nl> only valid if lbpolicy is ' ring_hash ' . <nl> alternative resource name to be used in eds requests . / only valid for eds cluster . <nl> load report server name for reporting loads via lrs . only valid for eds or logical_dns cluster . <nl> max number of concurrent requests can be sent to this cluster . only valid for eds or logical_dns cluster . <nl> tls context used to connect to connect to this cluster . only valid for eds or logical_dns cluster . <nl> list of underlying clusters making of this aggregate cluster . only valid for aggregate cluster . <nl> fixme ( chengyuanzhang ) : delete this after upstreamtlscontext 's tostring ( ) is fixed . <nl> exclude upstreamtlscontext as its string representation is cumbersome . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> private do not use . <nl> client sent an ack cds request .,"this change adds two parts to xdsclient for receiving configurations that support hashing based load balancing policies : <nl> - each contains a list of s , which specifies the hash value generation for requests routed to that route . <nl> - each resource can specify lb policy other than ' round_robin ' ( which is the only one we support nowadays ) . if it is ' ring_hash ' , it contains the configuration for mapping each rpc 's hash value to one of the endpoints .",1612221389,"introduce , which is a utility provided to loadbalancer implementations ( potentially nameresolvers too ) for recording events to channel trace . it is also useful for any loadbalancer implementations to record important information . <nl> channellogger implementation is backed by the internal channeltracer/channelz . because channelz limits the number of retained events , and events are lost once the process ends , i have expanded it to also log java logger . this would provide a ' last resort ' in cases where there are too many events or off-line investigation is needed . all logs are prefixed with",0.9813134670257568
quarkusio_quarkus/18138,"add scramsaslclientfactory to the reflective classes . <nl> enable all security services when kafka security protocol is set . <para-sep> enable ssl support if kafka.security.protocol is set to something other than plaintext , which is the default",enable all security services when kafka security protocol is set .,1624554712,mongodb with panache enlist for reflection entities ( and repository parameterized types ) automatically . <nl> this pr adds the same facility for the reactive implementation .,0.9245050549507141
apache_incubator-pinot/6607,deprecate pql endpoint on broker <para-sep> legacy api to query pinot using pql ( pinot query language ) syntax and semantics . this api is deprecated and pql is no longer supported by pinot . the api will be removed in the next release . please use the standard sql syntax ( api /query/sql ) to query pinot . <nl> legacy api to query pinot using pql ( pinot query language ) syntax and semantics . this api is deprecated and pql is no longer supported by pinot . the api will be removed in the next release . please use the standard sql syntax ( api /query/sql ) to query pinot .,this pr deprecates the endpoint on broker . the controller endpoint is already deprecated . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no . <nl> does this pr otherwise need attention when creating release notes ? things to consider : <nl> yes pql endpoint on broker is deprecated . labelled the pr with release-notes . <nl> info for release notes - apache pinot has adopted sql syntax and semantics . legacy pql ( pinot query language ) is deprecated and no longer supported . please use sql syntax to query pinot on broker endpoint and,1614187036,remove group by dimensions which also have top k dimensions heatmap breakdown .,0.8549810647964478
keycloak_keycloak/7853,: allow installed adapter to be reused . <nl> also add a close method to stop callback if response has not been received yet .,also add a close method to stop callback if response has not been received yet .,1615633056,- added the remove button functionality for totp authenticator <nl> - added one new and extended existing totp test <nl> - fixed one typo and one issue with button color,0.8920614719390869
ballerina-platform_ballerina-lang/31097,"refactor evaluation engine to support action invocations <cm-sep> fix object method calls invocation for object references defined in imported modules <cm-sep> add more improvements to method signature resolving <cm-sep> sync with upstream <cm-sep> add integration tests <cm-sep> resolve false positive spotbugs warnings <para-sep> visits object expression . <nl> adds expression syntax . <nl> adds action syntax . <nl> class resolver implementation for resolving visible ballerina class definitions ( object types ) for a given source location , using the semantic apis . <nl> evaluator implementation for remote method call invocation actions . <nl> calls a remote method of a client object . this works the same as a method call expression , except that it is used for a client object method with the remote qualifier . <nl> if the expression result is an object , try invoking as an object method invocation . <nl> resolves the jni signature to see if the the object/class is defined with a dependency module . <nl> since ballerina codegen phase introduces an additional boolean helper parameter for every method parameter except for the parameter , total number of parameters defined in the runtime method will be 2n + 0 . <nl> evaluator implementation for basic literals . <nl> a numeric-literal represents a value belonging to one of the basic types int , float or decimal . the basic type to which the value belongs is determined as follows : 0. if the numeric-literal includes a floattypesuffix , then the basic type is float ; 0. if the numeric-literal includes a decimaltypesuffix , then the basic type is decimal ; 0. if the numeric-literal is a hexfloatingpointliteral , then the basic type is float ; 0. otherwise , the basic type depends on the applicable expected numeric type ( where the possible basic types are int , float and decimal ) : - if the applicable contextually expected type is a subtype of decimal , then the basic type is decimal ; - if the applicable contextually expected type is a subtype of float , then the basic type is float ; - otherwise , if the numeric literal is an int-literal , then the basic type is int ; - otherwise , the basic type is float . <nl> removes hex indicator . <nl> removes decimal type suffix . <nl> removes float type suffix . <nl> todo - add support for hex floats",- adds integration tests to cover the related scenarios .,1623323456,"with this commit , you can use the ballerina import keyword to import your dependent packages .",0.962337076663971
gocd_gocd/8512,added endpoint to trigger mdu for a material given its fingerprint <nl> - the user needs to have the permission to view the material else 0 will be thrown <cm-sep> add mdu start time info in the materials index call <cm-sep> add trigger update button for materials . <nl> - the button will be disabled if mdu is in progress <nl> - the disabled button will have the timestamp when the running mdu started <cm-sep> - add the value of for a material to the index call - this will be used to disable the trigger button <nl> - update the triggerupdate call to throw 0 in case user does not have operate permissions for this pipeline . added a method in the service to get the material config from fingerprint . this method will throw related exceptions rather than using operationresult object <cm-sep> update material spa to disable trigger button when can_trigger_update is set to false,description : <nl> add a trigger material update button for the materials <nl> - will be disabled if the user does not have operate permissions for any group <nl> - will be disabled if a material update is currently in progress . on hover- the update start time will be shown . <nl> preview : . <nl> - message shown on successful trigger,1598951130,- this is to update last-used time for the token in db . every minute it will dump the local cache to db when security is enabled . in case of security is not configured for the gocd server timer will do nothing .,0.963668167591095
Alluxio_alluxio/13483,"add alluxio stacksservlet to display stacks on web ui page . <para-sep> prints the information and stack traces of all threads . <nl> the value of the previous log time , unit is ms . <nl> log the current thread stacks at info level . <nl> swallow the nit exception to keep silent . <nl> stacks servlet to display the stacks of this process .","you can use to show the stack info in the web ui page for alluxio master , worker , jobmaster , jobworker , proxy .",1621913659,"alluxio shell command ' bin/alluxio fs ' should provide a sub-command called ' help ' , which works like the following : <nl> for “ bin/alluxio fs help ” , this will print help message for the given command . <nl> for “ bin/alluxio fs help ” , this will print help messages for all supported commands . <nl> to implement this feature , this ' help ' command should be a class ' alluxio.shell.command.helpcommand.java ' , inheriting ' alluxio.shell.command.abstractshellcommand ' .",0.9658591151237488
elastic_elasticsearch/73196,fix edge-case threading bug in transportmountsearchablesnapshotaction . <nl> the callback to loading the repository-data may not run on generic in the uncached case <nl> because of the repo data deduplication logic . <para-sep> use snapshot_meta pool since we are slow due to loading repository metadata in this action,the callback to loading the repository-data may not run on generic in the uncached case <nl> because of the repo data deduplication logic .,1621339119,we need to make sure that the hasher selected for hashing in the <nl> beginning of the tests is not the same that is set in <nl> passwordhashingsettings for the test to make sense .,0.8454064130783081
elastic_elasticsearch/73193,"adjust get alias api with aliases pointing to data streams . <nl> change the get alias api to not return a 0 when filtering <nl> by alias name that refers to data streams . <para-sep> no need to do filtering like is done for aliases pointing to indices ( ^ ) , because this already happens in transportgetaliasesaction .",change the get alias api to not return a 0 when filtering <nl> by alias name that refers to data streams .,1621333422,this commit restores the filtering of empty fields during the <nl> xcontent serialization of searchhit .,0.9497331380844116
apache_druid/11068,"enable rewriting certain inner joins as filters . <nl> the main logic for doing the rewrite is in joinablefactorywrapper 's <nl> segmentmapfn method . the requirements are : . <nl> - it must be an inner equi-join . <nl> - the right-hand columns referenced by the condition must not contain any <nl> duplicate values . ( if they did , the inner join would not be guaranteed <nl> to return at most one row for each left-hand-side row . ) <nl> - no columns from the right-hand side can be used by anything other than <nl> the join condition itself . <nl> hashjoinsegmentstorageadapter is also modified to pass through to <nl> the base adapter ( even allowing vectorization ! ) in the case where 0 % <nl> of join clauses could be rewritten as filters . <nl> in support of this goal : . <nl> - add query getrequiredcolumns ( ) method to help us figure out whether <nl> the right-hand side of a join datasource is being used or not . <nl> - add joinconditionanalysis getrequiredcolumns ( ) method to help us <nl> figure out if the right-hand side of a join is being used by later <nl> join clauses acting on the same base . <nl> - add joinable getnonnullcolumnvaluesifallunique method to enable <nl> retrieving the set of values that will form the ' in ' filter . <nl> - add lookupextractor cangetkeyset ( ) and keyset ( ) methods to support <nl> lookupjoinable in its efforts to implement the new joinable method . <nl> - add ' enablerewritejointofilter ' feature flag to <nl> joinfilterrewriteconfig . the default is disabled . <para-sep> returns the list of columns that will be read out of a datasource by a query that uses the provided objects in the usual way . if the virtual columns , filter , dimensions , aggregators , or additional columns refer to a virtual column , then the inputs of the virtual column will be returned instead of the name of the virtual column itself . therefore , the returned list will never contain the names of any virtual columns . <nl> everyone needs __time ( it 's used by intervals filters ) . <nl> returns the set of columns that this query will need to access out of its datasource . this method does not ' look into ' what the datasource itself is doing","the main logic for doing the rewrite is in joinablefactorywrapper 's <nl> segmentmapfn method . the requirements are : . <nl> - it must be an inner equi-join . <nl> - the right-hand columns referenced by the condition must not contain any <nl> duplicate values . ( if they did , the inner join would not be guaranteed <nl> to return at most one row for each left-hand-side row . ) <nl> - no columns from the right-hand side can be used by anything other than <nl> the join condition itself . <nl> hashjoinsegmentstorageadapter is also modified to pass through",1617650119,"several bugs are found in the overshadowablemanager . it could happen in various cases , but it was essentially the contract of the of the atomicupdategroup was not respected properly . i updated its javadoc as below to make it more clear : . <nl> the main bug fixes have been fixed in and . <nl> in , it should consider the following cases : . <nl> 0 ) the latest standby group should be visible if there is no full group . <nl> 0 ) if an overshadowed group becomes full , it could be promoted to visible if",0.9811277985572815
elastic_elasticsearch/73851,"the org.elasticsearch.bootstrap package exists in server with classes <nl> for starting up elasticsearch . the elasticsearch-core jar has a handful <nl> of classes that were split out from there , namely java version parsing <nl> and jarhell . this commit moves those classes to a new <nl> org.elasticsearch.jdk package so as to not split the server owned <nl> bootstrap package . <para-sep> simple check for duplicate class files across the classpath . this class checks for incompatibilities in the following ways : checks that class files are not duplicated across jars . <nl> no instantiation * / <nl> simple driver class , can be used eg . from builds . returns non-zero on jar-hell * / <nl> checks the current classpath for duplicate classes <nl> parses the classpath into an array of urls <nl> parses the classpath into a set of urls . for testing . <nl> technically empty classpath element behaves like cwd . so below is the ' correct ' code , however in practice with es , this is usually just a misconfiguration , from old shell scripts left behind or something : if ( element.isempty ( ) ) { element = system.getproperty ( ' user.dir ' ) ; } instead we just throw an exception , and keep it clean . <nl> we should be able to just paths.get ( ) each element , but unfortunately this is not the whole story on how classpath parsing works : if you want to know , start at sun.misc.launcher , be sure to stop before you tear out your eyes . we just handle the ' alternative ' filename specification which java seems to allow , explicitly , right here ... <nl> ' correct ' the entry to become a normal entry change to correct file separators <nl> if there is a drive letter , nuke the leading separator <nl> now just parse as ordinary file <nl> eclipse adds this to the classpath when running unit tests ... <nl> junit4.childvm.count <nl> should not happen , as we use the filesystem api <nl> checks the set of urls for duplicate classes <nl> we do n't try to be sneaky and use deprecated/internal/not portable stuff like sun.boot.class.path , and with jigsaw we do n't yet have a way to get a ' list ' at all . so just exclude any elements underneath the java home <nl> exclude system resources","the org.elasticsearch.bootstrap package exists in server with classes <nl> for starting up elasticsearch . the elasticsearch-core jar has a handful <nl> of classes that were split out from there , namely java version parsing <nl> and jarhell . this commit moves those classes to a new <nl> org.elasticsearch.jdk package so as to not split the server owned <nl> bootstrap package .",1623079334,there are a few tiny packages that seem like they might be out of place . this pr moves their contents around so that they vanish .,0.875552237033844
elastic_elasticsearch/74676,backport start <para-sep> testresponse [ s/ ' end_time ' : ' 0-0-06t21:0 : versionz ' / ' end_time ' : $ body.snapshots.0.end_time/ ] <nl> testresponse [ s/ ' uuid ' : ' dkb54xw67gvdrctlcxsket ' / ' uuid ' : $ body.snapshots.0.uuid/ ] testresponse [ s/ ' uuid ' : ' vdrctlcxsketdkb54xw67g ' / ' uuid ' : $ body.snapshots.0.uuid/ ] testresponse [ s/ ' version_id ' : / ' version_id ' : $ body.snapshots.0.version_id/ ] testresponse [ s/ ' version ' : / ' version ' : $ body.snapshots.0.version/ ] testresponse [ s/ ' start_time ' : ' 0-0-06t21:0 : versionz ' / ' start_time ' : $ body.snapshots.0.start_time/ ] testresponse [ s/ ' start_time ' : ' 0-0-06t21:0 : versionz ' / ' start_time ' : $ body.snapshots.0.start_time/ ] testresponse [ s/ ' start_time_in_millis ' : 0/ ' start_time_in_millis ' : $ body.snapshots.0.start_time_in_millis/ ] testresponse [ s/ ' start_time_in_millis ' : 0/ ' start_time_in_millis ' : $ body.snapshots.0.start_time_in_millis/ ] testresponse [ s/ ' end_time ' : ' 0-0-06t21:0 : versionz ' / ' end_time ' : $ body.snapshots.0.end_time/ ] testresponse [ s/ ' end_time ' : ' 0-0-06t21:0 : versionz ' / ' end_time ' : $ body.snapshots.0.end_time/ ] testresponse [ s/ ' end_time_in_millis ' : 0/ ' end_time_in_millis ' : $ body.snapshots.0.end_time_in_millis/ ] testresponse [ s/ ' end_time_in_millis ' : 0/ ' end_time_in_millis ' : $ body.snapshots.0.end_time_in_millis/ ] testresponse [ s/ ' duration_in_millis ' : 0/ ' duration_in_millis ' : $ body.snapshots.0.duration_in_millis/ ] testresponse [ s/ ' duration_in_millis ' : 0/ ' duration_in_millis ' : $ body.snapshots.0.duration_in_millis/ ] <nl> todo : dry up duplication across this suite and org.elasticsearch.snapshots.getsnapshotsit more <nl> exclude old version snapshot from test assertions every time and do a prefixed query in either case half the time <nl> wait for at least 1ms to ensure that snapshots can be ordered by timestamp deterministically <nl> get repository metadata for given repository names from given cluster state . <nl> provide a map of user metadata that should be included in the snapshot metadata . <nl> constructs a new get snapshots request with given repository names and list of snapshots <nl> constructs a new get snapshots request with given repository names <nl> sets repository names <nl> returns repository names <nl> constructs the new get snapshot request with specified repositories <nl> sets the repository names <nl> returns true if there is a least one failed response . <nl>,"backport of the recently introduced snapshot pagination and scalability improvements listed below . <nl> merged as a single backport because the and master snapshot status api logic had massively diverged between master and 0.x . with the work in the below prs , the logic in master and 0.x once again has been aligned very closely again .",1624963042,,0.0
apache_kafka/10356,cache size set by the thread,make is so threads do not directly resize other threads caches .,1616102174,- added a new unit test where the hostname changes . <nl> - also tested in production .,0.9019391536712646
ballerina-platform_ballerina-lang/27459,enable metrics test cases for main function <cm-sep> enable tracing test cases for main function <cm-sep> rename tags to fit the latest ballerina spec <para-sep> source related boolean flag tags,the following changes had been done to the tags . <nl> > tag changes <nl> * connector_name = > src.object.name <nl> * object_name = > src.object.name <nl> * action = > src.function.name <nl> * function = > src.function.name <nl> * src.entry_point.main = > src.main <nl> * src.remote = > src.client.remote <nl> * src.entry_point.resource = > src.service.resource <nl> > new tags <nl> * src.service.remote <nl> * entrypoint.function.module <nl> * entrypoint.function.position <nl> * listener.name <nl> > removed tags <nl> * service <nl> * resource .,1607681975,0 ) . org.wso2.carbon.core <nl> 0 ) . org.wso2.carbon.messaging <nl> 0 ) . org.wso2.carbon.config <nl> 0 ) . org.wso2.carbon.deployment.engine,0.9199570417404175
apache_incubator-pinot/6495,allow derived columns in ingestion config . sort the transform functions <cm-sep> remove annotation <para-sep> sort the transform functions based on dependencies <nl> derived columns - should pass,"for example , millissinceepoch = f ( isodatetime ) and hourssinceepoch = f ( millissinceepoch ) i.e . user created millissinceepoch column while ingesting , using a transform function on a isodatetime column , and did not keep the isodatetime column . if we do n't allow chained transform functions , user wo n't be able to use millissinceepoch column in derived function for hourssinceepoch .",1611710282,"0. store the message and stack trace of the exceptions that are induced during task execution . <nl> 0. if more than 0 % of dimension exploration or 0 % of merged anomaly updates fail , the task becomes failed instead of complete . the error message will be logged in te 's db . <nl> tested on local anomaly detection .",0.949836015701294
grpc_grpc-java/8253,"skip fallback if the lb is already in fallback mode . this can be triggered by receiving updated addresses containing backend addresses only . <para-sep> no balancer address : close existing balancer connection and prepare to enter fallback mode . if there is no successful backend connection , it enters fallback mode immediately . otherwise , fallback does not happen until backend connections are lost . this behavior might be different from other languages ( e.g. , existing balancer connection is not closed in c-core ) , but we are n't changing it at this time . <nl> create 0 distinct backends <nl> name resolver gives the first two backend addresses <nl> /////////////////////////////////////////////////////////////////////////////////////// name resolver sends new resolution results with new backend addr but no balancer addr /////////////////////////////////////////////////////////////////////////////////////// name resolver then gives the last three backends <nl> shift to use updated backends","when receiving updated addresses from the resolver with backend addresses only , grpclb will executes the fallback task . <nl> this change eliminates the reuse of fallbackmodetask for handling address update without lb address . that is , every time receiving address update , we manually check if it is already in fallback instead of reusing to fallbackmodetask perform the check .",1623369109,interop-testing : apply -- server_host_override regardless of flag order in the stress test client . <nl> the previous pr incorrectly failed to apply -- server_host_override unless it was set before the -- server_address flag .,0.915042519569397
hazelcast_hazelcast/18696,"fix map reader/writer processor issues . <nl> issues with imap writer : <nl> - we used map with putall , that 's not supported <nl> - when we did that , the error was n't reported , but instead the operation got stuck <nl> - we cleared the buffer right after putallasync returned , but it was used <nl> concurrently , which hid the error . <nl> issue with imap reader : <nl> - bad assert , checked the before it was assigned . failed only with larger data set . <para-sep> to invalidate nearcache , the method would need a deserialized key . it ca n't deserialize because it does n't know the job-specific serializers .","issues with imap writer : <nl> - we used map with putall , that 's not supported <nl> - when we did that , the error was n't reported , but instead the operation got stuck <nl> - we cleared the buffer right after putallasync returned , but it was used <nl> concurrently , which hid the error . <nl> issue with imap reader : <nl> - bad assert , checked the before it was assigned . failed only with larger data set .",1621275066,( cherry-picked from sha ) .,0.9668115377426147
neo4j_neo4j/11680,"explicitly flush after write in test connections <cm-sep> unflake boltschedulershouldreportfailurewhenbusyit . <nl> it used to fail sometimes because bolt server rejected incoming <nl> messages . they were rejected because server did not have free <nl> threads to process them . it might take some time for a thread to get <nl> returned to the thread pool after the previous task is executed . <nl> this commit makes the test retry finite amount of time on message <nl> rejection . it also adds increasing sleeps between messages with every <nl> retry . <para-sep> retry couple times because worker threads might seem busy <nl> failed to enter the streaming state , record the error and retry",it used to fail sometimes because bolt server rejected incoming messages . they were rejected because server did not have free threads to process them . it might take some time for a thread to get returned to the thread pool after the previous task is executed . <nl> this pr makes the test retry finite amount of time on message rejection . it also adds increasing sleeps between messages with every retry .,1525102452,"the store files are very likely in an invalid state , but could be able to start <nl> if opening a db on them , which would see very strange and inconsistent data . <nl> therefore logs failure/success and also tells user about this fact .",0.916559100151062
apache_druid/11036,"request logs through kafka emitter <para-sep> there is 0 seconds wait in kafka emitter before it starts sending events to broker , so set a timeout for 0 seconds <nl> although the latch may have count down , producer.send may not have been called yet in kafkaemitter so wait for sometime before verifying the mock <nl> just continue","send request logs through kafka emitter , if request topic is set then the event will be emitted otherwise skipped and added to count . when is set , lost request logs are logged under metric",1616771980,syntax is the same as hive/presto 's .,0.982280969619751
runelite_runelite/13440,added chat color option for user 's own rsn,options added in 'chat color ' config for both transparent and opaque .,1617583959,do not draw text on top of mark of grace <nl> - this is grounditemsplugin 's job . <nl> agility plugin small code cleanup <nl> - do not use 0 line ifs <nl> - mark fields final properly <nl> - remove confusing comments,0.8776083588600159
elastic_elasticsearch/74772,"<para-sep> first ensure that the pattern bank contains no simple circular references ( i.e. , any pattern containing an immediate reference to itself ) as those can cause the remainder of this algorithm to recurse infinitely <nl> next recursively check any other pattern names referenced in the pattern <nl> next check any other pattern names found in the pattern",certain combinations of patterns could result in circular references that were not properly detected . this pr resolves that .,1625071231,"this commit includes a number of changes to reduce overall build <nl> configuration time . these optimizations include : . <nl> - removing the usage of the 'nebula.info-scm ' plugin . this plugin <nl> leverages jgit to load read various pieces of vcs information . this <nl> is mostly overkill and we have our own minimal implementation for <nl> determining the current commit id . <nl> - removing unnecessary build dependencies such as perforce and jgit <nl> now that we do n't need them . this reduces our classpath considerably . <nl> - expanding the usage lazy task creation ,",0.9444101452827454
ballerina-platform_ballerina-lang/28405,"fix current project modules not being suggesting <para-sep> note : here we skip the langlib packages <nl> here the distrepopackages does not contain the langlib packages <nl> if the object type desc is a client , then we avoid all the remote methods",0. add the completion support for the modules in the same project <nl> 0. remove langlib suggestions since the predeclaration of the lang libs have been added . <nl> 0. remove error keyword suggestion duplication . <nl> 0. avoid suggesting remote methods on method access .,1612329109,load stdlib from balo at compile time,0.9650102257728577
elastic_elasticsearch/74639,"add support to the migrate to data tiers api . <nl> this adds support for a parameter for the <nl> api . this defaults to , but when <nl> configured to it will simulate the migration of elasticsearch <nl> entities to data tiers based routing , returning the entites that need to <nl> be updated ( indices , ilm policies and the legacy index template that 'd <nl> be deleted , if any was configured in the request ) . <para-sep> let 's wait for this index to have received the configuration from the warm phase/allocate action <nl> wait for the index to advance to the warm phase <nl> let 's wait for this index to have received the configuration from the warm phase/allocate action <nl> let 's stop ilm so we can simulate the migration <nl> response should contain the correct ' to migrate ' entities <nl> however the entities should not have been changed the index template should still exist <nl> the index settings should not contain the _tier_preference <nl> let 's check the ilm policy was not migrated - ie . the warm phase still contains the allocate action","this adds support for a parameter for the <nl> api . this defaults to , but when <nl> configured to it will simulate the migration of elasticsearch <nl> entities to data tiers based routing , returning the entities that need to <nl> be updated ( indices , ilm policies and the legacy index template that 'd <nl> be deleted , if any was configured in the request ) .",1624893608,adds script cache stats to . <nl> if using the general cache : . <nl> if using context caches : .,0.98077392578125
vespa-engine_vespa/17133,"allow instanceconfirmation as response <cm-sep> retrieve path suffix with ' * ' <cm-sep> add getter for restapi instance <cm-sep> create copy of default objectmapper instance . <nl> objectmapper is mutable/configurable , and is exposed through various getters in restapi .",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616520174,"calling implies reading complete version status from <nl> zookeeper , and doing this for every single app is naturally expensive .",0.883278489112854
elastic_elasticsearch/72569,"clarify remote_cluster_client is required to run ml . <nl> i can not find a proper way to say it in the documentation , so feel free to rephrase/reword it . <nl> in short , should be enabled on every master eligible node and every node that can run machine learning jobs if you 're willing to run a job on a remote index .","i can not find a proper way to say it in the documentation , so feel free to rephrase/reword it . <nl> in short , should be enabled on every master eligible node and every node that can run machine learning jobs if you 're willing to run a job on a remote index . <nl> this should be backported to applicable versions ( ideally all ) .",1619795571,unpacking transformation of azul packaged jdks have been broken due to <nl> a different packaging structure not handled correctly by the jdkdownloadplugin . <nl> this fixes this and also fixes the packaging of aarch64 jdks into elasticsearch with <nl> jdk distros,1.0
Graylog2_graylog2-server/9973,"adding tests for relative range . <cm-sep> adding test case for specifying only parameter . <cm-sep> supporting specifying implicitly , defaulting to ' now ' .","recently , support for specifying relative / values for the relative range was implemented . this pr allows to omit the parameter , defaulting to an implicit value of or . this makes the relative range -notation semantically identical to specifying .",1611678486,"this makes the class easier to use . if a file is n't present or inaccessible , return a null object that allows rechecking for modifications . <nl> if the size of the file is the same after modification , this class can only detect changes if the modification time has changes . the resolution of that is typically only a second",0.9278257489204407
apache_druid/11075,"do stuff <para-sep> if the descriptor path already exists , do n't overwrite , and risk clobbering it . if it already exists , it means that the segment data is already written to the tmp path , and the existing descriptor written should give us the information we need to rename the segment index to final path and publish it in the top level task . <nl> renames the index files for the segments . this works around some limitations of both filecontext ( no s3n support ) and natives3filesystem.rename which will not overwrite . note : segments should be renamed in the index task , not in a hadoop job , as race conditions between job retries can cause the final segment index file path to get clobbered . <nl> rename the file . this works around some limitations of both filecontext ( no s3n support ) and natives3filesystem.rename <nl> we should have a lock from before we started running only if interval was specified <nl> note : if locktimeoutms is larger than serverconfig.maxidletime , the below line can incur http timeout error . <nl> try to wait for segments to be loaded by the cluster if the tuning config specifies a non-zero value for awaitsegmentavailabilitytimeoutmillis","segment index file zips are now renamed from the index task , rather than in the hadoop reduce job . when index file renaming <nl> occurs in the hadoop reduce job , it was found that at times , the final index file would get deleted because of a race condition <nl> between between job retries",1617755368,"since the cardinality aggregator has a ' round ' option to round off estimated <nl> values generated from the hyperloglog algorithm , add the same ' round ' option to <nl> the datasketches hll sketch module aggregators to be consistent . <nl> for reviewers : the key changed/added classes in this pr are , , , and",0.9855051040649414
OpenAPITools_openapi-generator/9049,"fix model , property name check in c # generator <para-sep> _client | string | | _specialmodelname | string | | <nl> / gets or sets _client <nl> / specialmodelname . <nl> / gets or sets _specialmodelname / <nl> / <nl> _client | string | | _specialmodelname | string | | <nl> / gets or sets _client <nl> / specialmodelname . <nl> / gets or sets _specialmodelname / <nl> / <nl> _client | string | | _specialmodelname | string | | <nl> / gets or sets _client <nl> / specialmodelname . <nl> / gets or sets _specialmodelname / <nl> / <nl> _client | string | | _specialmodelname | string | | <nl> / gets or sets _client <nl> / specialmodelname . <nl> / gets or sets _specialmodelname / <nl> / <nl> _client | string | | _specialmodelname | string | | <nl> / gets or sets _client <nl> / specialmodelname . <nl> / gets or sets _specialmodelname / <nl> / <nl> _client | string * | | <nl> / gets or sets _client <nl> specialmodelname | string * | | <nl> get specialmodelname <nl> specialmodelname | string * | | <nl> get specialmodelname",model and property name ca n't be the same in the c # class . this pr fixes a bug in the comparison using the model name instead of the original name obtained from the spec . <nl> update test spec to include a test case .,1616471448,allow users to specify a stability type to include when listing generator . excludes deprecated generators by default . <nl> example output when using this new option : . <nl> this also adds the experimental enum to a couple of generators which were missing it .,0.9278603196144104
apache_pulsar/10706,async the method onmanagedledgerlastledgerinitialize for managedledgerinterceptor,"async the method onmanagedledgerlastledgerinitialize for managedledgerinterceptor . the interceptor shouldn ’ t be making any blocking calls . <nl> here is the detailed stacktrace : . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> -",1621991825,health check from spawner to instance . the health is also used in reverse for instance to determine if spawner is still alive,0.9197037220001221
apache_pulsar/11005,do not expose meaningless stats for consumer . <nl> currently we have exposed some meaningless consumer stats to users such as . <nl> all of these stats are not used by users but used internally . <nl> so remove these stats from the exposed consumer stats .,"currently , we have exposed some meaningless consumer stats to users such as . <nl> all of these stats are not used by users but used internally . <nl> so remove these stats from the exposed consumer stats .",1624284646,"this pr adds the ability to specify pulsar functions using fully qualified function names ( fqfns ) as an alternative to tenant , namespace , and name .",0.9310789108276367
apache_druid/11366,fix bug in needscompaction <cm-sep> fix bug in needscompaction <para-sep> different indexspec as what is set in the auto compaction config <nl> create segments that were compacted ( compactionstate ! = null ) and have segmentgranularity=day <nl> duration of new segmentgranularity is the same as before ( p1d ) <nl> we should get all segments in timeline back since indexspec changed <nl> no more,"fix bug in auto compaction needscompaction method that can skip segments incorrectly . <nl> however , if the segments was also previously compacted without segmentgranularity and the configured segmentgranularity ( in auto compaction ) is the same as the segments current segmentgranularity , then we would incorrectly set needscompaction back to be false",1623872730,- also better lookup docs .,0.9138144850730896
OpenAPITools_openapi-generator/9088,"<para-sep> this is here to potentially warn the user when an option is not supported by the target framework . <nl> kotlin version gradle version <nl> sets a validation function that will check given instance and return , or null if credential does not correspond to an authenticated principal <nl> todo : define a callback url here . <nl> kotlin version gradle version <nl> initialization order with shadow version and gradle version is weird . <nl> kotlin version gradle version <nl> initialization order with shadow version and gradle version is weird . <nl> todo : define a callback url here . <nl> add a new pet to the store <nl> update an existing pet <nl> updates a pet in the store with form data <nl> uploads an image <nl> place an order for a pet <nl> create user this can only be done by the logged in user . <nl> creates list of users with given input array <nl> creates list of users with given input array <nl> updated user this can only be done by the logged in user . <nl> sets a validation function that will check given instance and return , or null if credential does not correspond to an authenticated principal","hi , <nl> i am part of the ktor team . <nl> this pr updates ktor server generator to the newest version of kotlin and ktor . changes : <nl> * add flag to choose between using feature or default routing <nl> * generate locations for requests too <nl> * update to the latest version and fix warnings and errors <nl> * minor codestyle fixes . <nl> .. .",1616705216,- add ' usesinglerequestparameter ' option to rust client generator so that the method parameters will be grouped in a single struct <nl> - tested locally and the result is good .,0.9375202655792236
hazelcast_hazelcast/18881,add support of time without leading zeroes and timestamp with space instead of 't ' symbol <para-sep> region date-time formatters <nl> endregion,"add support of time without leading zeroes and timestamp with space instead of 't ' symbol . <nl> supported formats examples : <nl> - time : , , , , , , , , <nl> - timestamp : both and formats . <nl> checklist : .",1623341218,"makes the number of ports to use by the cluster configurable ( it was hardcoded as 0 ) . <nl> in most cases this is not an issue , since there will not be more than 0 hazelcast <nl> instances running on a single machine . but in those rare cases where this is needed <nl> ( e.g . for testing ) this property can be set . if not set , it will default to 0 , so <nl> there will not be any change if not configured explicitly .",0.9034284353256226
elastic_elasticsearch/73855,resurrect the removed hot threads endpoints <cm-sep> add a simple yamlrestcompattest test,adds back the various removed routes when using rest compatibility for a request .,1623080354,this addresses two bugs in snapshot upgrader that were found in backport and adds a new mixed cluster test .,0.8607905507087708
confluentinc_ksql/7148,add lambda feature flag <cm-sep> fixing testing <para-sep> given : <nl> when : <nl> then :,"a bit of refactoring to pass in ksql config information all the way to ast sanitizer , could be used in the future if we want access to feature flag info in these classes <nl> # # # testing done <nl> unit test to make sure we throw the proper error .",1614800891,this pr adds a flag that allows you to point to an extensions directory where you can provide your own jar of udfs . <nl> ran existing tests .,0.9595485329627991
vespa-engine_vespa/17288,add unit test for lambda optimization bug <cm-sep> only allow getdirectevaluator when arguments are accessed normally,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1617723456,"i discovered two errors with current implementation . <nl> 0. we have a special hardcoded applicationinstancereference for the config server that did not fit the assumption made in the id conversion to applicationid <nl> 0. the cluster controller path to set all nodes in a cluster in maintenance was wrong . <nl> both have been tested in the dev environment . the clustercontroller path was tested with : . <nl> { <nl> ' wasmodified ' : true , <nl> ' reason ' : ' ok ' <nl> } .",0.9113419055938721
apache_pulsar/10383,"fix schema ledger deletion when delete topic with delete schema . <para-sep> it 's not a serious error , we did n't need call future.completeexceptionally ( )","fix schema ledger deletion when deleting topic with delete schema . <nl> delete ledgers according to the schema index . <nl> new unit tests added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> -",1619437107,"so , fixing func-url validation method .",0.9478310942649841
ballerina-platform_ballerina-lang/27089,consider the flags for function shapes,"for functions , the shape only used to consider parameter/return types and not the flags , which led to issues when the bir was used , because all the subsequent function ( s ) may not have the correct flags . <nl> fixes # .",1606137414,* add the bindgen command to ballerina help page . <nl> * fix a bug in the java class to ballerina object mapping template .,0.840071439743042
Alluxio_alluxio/12842,"add gcs version 0 <para-sep> a stream for reading a file from gcs using google cloud api ( gcs input stream version 0 ) . the main purpose is to provide a faster skip method , as the underlying implementation will read and discard bytes until the number to skip has been reached . this input stream returns 0 when calling read with an empty buffer . <nl> bucket name of the alluxio gcs bucket . * / <nl> key of the file in gcs to read . * / <nl> the google cloud storage client . * / <nl> the pre-allocated buffer for single byte read operation . * / <nl> the underlying input stream . * / <nl> position of the stream . * / <nl> this method leverages the ability to open a stream from gcs from a given offset . when the underlying stream has fewer bytes buffered than the skip request , the stream is closed , and a new stream is opened starting at the requested offset . <nl> opens a new stream at mpos . <nl> a stream for writing a file into gcs using google cloud api ( gcs output stream version 0 ) . the data is streaming writing to gcs without waiting for the complete file to arrive in alluxio worker . <nl> bucket name of the alluxio gcs bucket . * / <nl> key of the file when it is uploaded to gcs . * / <nl> the google cloud storage client . * / <nl> the pre-allocated buffer for single byte write operation . * / <nl> the blob information of the key . * / <nl> the write channel of google storage object . * / <nl> flag to indicate this stream has been closed , to ensure close is only done once . * / <nl> constructs a new stream for writing a file . <nl> google storage write channel does not support flush operation <nl> todo ( lu ) storageexception has isretryable ( ) method , can help handle retry <nl> static hash for a directory 's empty contents . * / <nl> google cloud storage client . * / <nl> bucket name of user 's configured alluxio bucket . * / <nl> the environment variable google_application_credentials is set or the application is running in google app engine or compute engine <nl> setting gcs owner",add gcs version 0 integration using google cloud api,1613078745,added apis for intercepting grpc client and server with custom data serialization/deserialization . <nl> also made the worker send read response asynchronously to improve throughput for single read request .,0.9862385392189026
vespa-engine_vespa/18072,add 'onerror ' to contentchannel <cm-sep> pass error from servlet read listener to content channel <para-sep> invoked when an error occurs during processing of request content . signals that the caller was unable to write all data to this contentchannel . <nl> jdisc will automatically generate an error response in this scenario,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622549924,"only sha added after last review round . <nl> in particular for the code which takes over for the messagebus functionality . <nl> note that this is _not yet_ considered production ready , so still quite a few todos/fixmes in code paths that are n't enabled by default . but it 's sufficiently functional that we can very soon begin internal system/performance testing ( we need a configurable rpc thread pool size before that , though ) .",0.8996616005897522
elastic_elasticsearch/74509,"fix error in fieldcapabilitiesresponse serialization . <nl> in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version . <para-sep> check that failure serialization between different minor versions after version works <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> check that failure serialization to minor versions before version works without serializing the failures part <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> minimum version set to version because the nested fieldcapabilities had another serialization change there","in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version .",1624468661,this commit restores the filtering of empty fields during the <nl> xcontent serialization of searchhit .,0.939982533454895
apache_kafka/10398,fix newly added flaky test <para-sep> we use a countdown latch to ensure that we get to the first call to before we increment the time below to trigger the disconnect . <nl> the longer timeout is needed to avoid transient failures due to slow or overloaded machines .,"i noticed this test hanging frequently locally . there is a race condition between the background thread calling and the call to in the test . if the call to happens first , then the test hangs . i fixed it by giving a way to listen to calls . this combined with a latch fixes the race .",1616641798,"when attempting to get topic list via kafkaadminclient against a server that is n't resolvable , the worker thread can get killed as follows , leading to a zombie kafkaadminclient : . <nl> it looks like cause is a bug in state handling between and : <nl> - invokes as seen in the above stacktrace <nl> - invokes , which internally invokes to resolve the host when creating an entry for the connection . <nl> - if this host lookup fails , a can be thrown back to and the connection entry is not created in . this exception does",0.9390574097633362
confluentinc_ksql/7087,implement 'validate ' command <cm-sep> post-merge fixes <cm-sep> unit test shell <cm-sep> validate migration state <cm-sep> more tests <cm-sep> expose getlatestmigratedversion as util,"the command of the migrations tool : <nl> 0. finds the latest migrated version by querying the metadata table for the current version and following ' previous ' pointers until one with status migrated is found . this should never involve more than one hop following pointers since the command should always use the latest migrated version as ' previous ' . currently an error is thrown if this is not the case , but we can revisit when we introduce the command to get out of bad states due to race conditions . <nl> 0. continuing to follow '",1614143892,"adds basic auth support to the new api server . enable the feature with the following server properties : . <nl> one difference between the new and existing basic auth implementations is a reinterpretation of the meaning of as a jaas role for the config : the existing implementation is jetty-based and therefore means to use the config in the associated web.xml file , and this was the default if the config was unspecified . as far as i can tell , ksql has never had a file so this default amounted to not allowing access for any roles .",0.977637767791748
OpenAPITools_openapi-generator/8350,"rename titlecase , minor code format",- rename ( as flagged as a bug in sonar report ) to <nl> - minor code format .,1609933968,- add copyright note <nl> - add dockerfile <nl> - update documentation,0.8734153509140015
elastic_elasticsearch/73994,"this failure can happen if the after test logic in <nl> esresttestcase.wipesearchablesnapshotsindices ( ) <nl> correctly found a searchable snapshot index to <nl> delete but that index was already deleted and <nl> converted to an alias in the meanwhile , by the <nl> last step of the ilm searchable snapshot action <nl> for frozen phase . <nl> this in-flight alias swap while the partially index <nl> has a completed ilm state is possible because <nl> of the copyexecutionstatestep which updates <nl> the cluster state with completed in frozen phase <nl> and the alias swap request is executed after the <nl> updated cluster state is published .","this failure can happen if the after test logic in <nl> esresttestcase.wipesearchablesnapshotsindices ( ) <nl> correctly found a searchable snapshot index to <nl> delete but that index was already deleted and <nl> converted to an alias in the meanwhile , by the <nl> last step of the ilm searchable snapshot action <nl> for frozen phase . <nl> this in-flight alias swap while the partially index <nl> has a completed ilm state is possible because <nl> of the copyexecutionstatestep which updates <nl> the cluster state with completed in frozen phase <nl> and the alias swap request is executed after the <nl>",1623317039,this change adds deprecation warning when multiple v1 templates match with a new index . <nl> this is deprecated because with v2 templates only one template can match and multiple ' levels ' of settings should be done using component templates .,0.8483069539070129
Graylog2_graylog2-server/10507,url-encode template name so special characters are quoted . <cm-sep> quote special characters in index prefixes before creating regex . <cm-sep> adding test case .,"this pr is making a couple of changes to support the + character in index set prefixes . the required changes were : . <nl> - properly url encode in names when creating the index template <nl> - quote when creating the regular expression used to match indices against the prefix . <nl> when an index set is configured with a in the index set prefix , all kinds of issues show up , making it effectively unusable . indices are not identified to belong to this index set , creation of new indices for this index set do not",1619436919,this pr adds some improvements to the events definition page : . <nl> - displays loading state when loading list of events definitions <nl> - uses pagination from the resource to display a paginated list <nl> - adds a filter component and implements filtering capabilities in the backend resource <nl> - displays information about scheduling and notifications in the list of event definitions .,0.9317896962165833
apache_druid/11182,"vectorize the cardinality aggregator . <nl> does not include a byrow implementation , so if byrow is true then <nl> the aggregator still goes through the non-vectorized path . <nl> testing strategy : . <nl> - new tests that exercise both styles of ' aggregate ' for supported types . <nl> - some existing tests have also become active ( note the deleted <nl> ' cannotvectorize ' lines ) . <para-sep> ! byrow because there is not yet a vector implementation . <nl> nothing to close . <nl> sql standard spec does not count null values , skip counting null values when we are not replacing null with default value . a special value for null in case null handling is configured to use empty string for null . <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> do nothing . <nl> do nothing . <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> save position , limit and restore later instead of allocating a new bytebuffer object <nl> can not vectorize due to first , last aggregators . can not vectorize due to extraction dimension spec . can not vectorize outer query due to inlined inner query . can not vectorize due to extraction dimension spec . can not vectorize due to extraction dimension spec . can not vectorize next test due to extraction dimension spec .","does not include a byrow implementation , so if byrow is true then <nl> the aggregator still goes through the non-vectorized path . <nl> testing strategy : . <nl> - new tests that exercise both styles of ' aggregate ' for supported types . <nl> - some existing tests have also become active ( note the deleted <nl> ' cannotvectorize ' lines ) .",1619684998,added post-aggs : <nl> quantilesdoublessketchtorank <nl> quantilesdoublessketchtocdf,0.9854711294174194
elastic_elasticsearch/74234,"dynamic runtime to not dynamically create objects . <nl> that proved to be a poor choice , because the runtime section is flat , supports dots in field names , and does not really need objects . also , these end up causing unnecessary mapping conflicts . <nl> with this commit we adapt dynamic : runtime to not dynamically create objects . <para-sep> depending on the order of the documents field types may differ , but there are no mapping conflicts <nl> with dynamic : runtime all leaf fields will be runtime fields unless explicitly mapped , hence we do n't dynamically create empty objects under properties , but rather carry around an artificial object mapper <nl> fields can be mapped under properties , as concrete fields that get indexed , objects get dynamically mapped only under dynamic : true . used for sub-fields of objects that are mapped as dynamic : runtime .","that proved to be a poor choice , because the runtime section is flat , supports dots in field names , and does not really need objects . also , these end up causing unnecessary mapping conflicts . <nl> with this commit we adapt dynamic : runtime to not dynamically create objects .",1623932270,this change adds full restart test and rolling restart test that include data streams .,0.9649142026901245
eclipse-openj9_openj9/11521,remove varhandle equals and hashcode . <nl> these methods were originally intended to be part of java 0 and then removed .,- these methods were originally intended to be part of java 0 and then removed .,1608328612,"the existing logic ( removed code in this pr ) was effectively sunk down into omr and z/os support was subsequently added . there should be no change in behavior for existing platforms , and the test coverage proves this is the case .",0.899885356426239
OpenAPITools_openapi-generator/8995,update aspnetcore nuspec and csproj with authors and description,update aspnetcore nuspec and csproj with authors and description .,1616001379,use customized source folder in build config when provided .,0.9386575818061829
grpc_grpc-java/7951,"allow multiple authorities in lb backends instead of flattening to a single one , using overrideauthority attributes . change oob channel interface to accept an equivalentaddressgroup list instead of a single object . <para-sep> updates the addresses with a new eag list . connection is continued when old and new addresses overlap . * /","grpclb : allow multiple authorities in lb backends instead of flattening to a single one , using overrideauthority attributes . change oob channel interface to accept an equivalentaddressgroup list instead of a single object .",1615319128,"major changes in this pr : . <nl> 0. added field for cluster name in eds lb config ( i.e. , ) . cds policy will set it to the cluster name it receives from cds responses . <nl> - currently , is optional since the resolver in prod tests does not have it . so for eds-only , it will be set to the hostname ( including port ) for creating the grpc channel . <nl> 0. xdsclient will give exactly as it receives in cds responses to cds policy . that is , in can be . lrs",0.9677180051803589
apache_druid/10891,"fix maxbytesinmemory <cm-sep> fix maxbytesinmemory check <cm-sep> fix maxbytesinmemory check <para-sep> after swapping the sink , we use memory mapped segment instead . however , the memory mapped segment still consumes memory . these memory mapped segments are held in memory throughout the ingestion phase and permanently add to the bytescurrentlyinmemory <nl> we are still over maxbytestuningconfig even after persisting . this means that we ran out of all available memory to ingest ( due to overheads created as part of ingestion )","fix maxbytesinmemory for heap overhead of sinks and hydrants check . <nl> there is currently two bugs with maxbytesinmemory for heap overhead of sinks and hydrants check . <nl> the first bug is that the check for maxbytesinmemory for heap overhead of sinks and hydrants check is currently done instead the method . the method is done in the background and while the method is running , there could already be another concurrent in-memory ingestion . the new in-memory ingestion would use the old value of without accounting for the heap overhead of sinks and hydrants from the latest persist",1613465012,"if cardinality was high , the computation could overflow an int . there <nl> were tests for this , but the tests were wrong .",0.9108598232269287
jenkinsci_jenkins/5412,revert isempty ( ) changes <cm-sep> use hashset to avoid node iteration,"reimplementing trimlabels this way improves this code even more as tested by a user . synthetic tests also show even more improvement . <nl> , reduce queue-lock contention when creating or deleting nodes .",1618269584,"currently the interface requires the api user to implement already deprecated methods . <nl> it does not make much sense , and the api could be simplified . <nl> * n/a or ' developer : introduce default implementations of deprecated methods of builableitem and item ' .",0.9268736243247986
apache_druid/10823,"add sql operators for bitwise expressions <cm-sep> more test <para-sep> happy path maths <nl> funny types two strings is sad but one is ok , druid forgives you <nl> unary does n't accept any slop <nl> conversion returns null if nonsense inputs","for example , doing nonsense with wikipedia data :",1612158747,"one downside of sql 's flexibility is that users tend to forget adding time filter when writing queries , which is usually very bad for timeseries data analysis and causes stability issue . <nl> since native query requires users to specify ' intervals ' , i think it 's reasonable to force sql users to specify __time filter in many cases adds a new option to support such needs . it defaults to false though so that the default behaviour is the same as before",0.9426410794258118
Alluxio_alluxio/13456,improve error message for taking snapshot on single master,display a more actionable message instead of complaining no follower available when running in single master mode .,1621537870,"this pr fixes a problem when a user is using alluxio with without setting . in this case , user may see login error like ' failed to login : no alluxio user is found ` . the root cause is two classloaders are introduced by hadoop jar . <nl> when hadoop creates alluxio fs , the first one is used to load alluxio fs and related classes ; while when entering alluxio world , the second is used as context one . having two classes causes confusion as a class is actually identified by the pair ( classname ,",0.8969773054122925
ballerina-platform_ballerina-lang/28318,remove unknown service and resource values from observability data <cm-sep> move operations on spans out of trace manager <cm-sep> remove tracemanager and refactor bspan class <cm-sep> move bspan to a class field in observer context <para-sep> start a new span without a parent . the started span will be a root span . <nl> start a new span with a parent using parent span . <nl> start a new span with a parent using parent trace context . the started span is part of a trace which had spanned across multiple services and the parent is in the service which called the current service . <nl> util class to hold tracing specific util methods . <nl> adding error message to trace span <nl> adding specific error code to trace span,the span starting had been moved to a single method as the current method of keeping a separate map is redundant and a spanbuilder is not required for the current use cases of ballerina tracing .,1612098951,i 've redesigned the types implementation avoid may if-else to figure out the value for a given type . i had to do this to support the array type .,0.973822832107544
elastic_elasticsearch/73828,"[ ml ] fix end offset for first_non_blank_line char_filter . <nl> when the input gets chopped by a char_filter immediately after <nl> a token , that token must be reported as ending at the very end <nl> of the original input , otherwise analysis will have incorrect <nl> offsets when multiple field values are analyzed in the same <nl> _analyze request . <nl> the pattern_replace filter works like this . this pr changes <nl> the new first_non_blank_line filter to work in the same way . <para-sep> when the input gets chopped by a char filter immediately after a token , that token must be reported as ending at the very end of the original input , otherwise multi-message analysis will have incorrect offsets","when the input gets chopped by a char_filter immediately after <nl> a token , that token must be reported as ending at the very end <nl> of the original input , otherwise analysis will have incorrect <nl> offsets when multiple field values are analyzed in the same <nl> _analyze request . <nl> the pattern_replace filter works like this . this pr changes <nl> the new first_non_blank_line filter to work in the same way .",1623066537,"to easy correlation between anomaly results and category definitions , this commit adds a new keyword mapped field . <nl> this field is always the same as the field ( which is mapped as a long ) . but since anomaly results store <nl> the as a keyword , it simplifies queries if category_definitions also had this field as a keyword . <nl> the stored json is a . <nl> additionally , this commit adds a entry to category definition documents . <nl> this will help simplify and unify result queries in the future .",0.8789083957672119
Alluxio_alluxio/13689,"updating apache ratis api to version to use new transferleadership functionality <para-sep> clientid , serverid , and groupid must not be null",updating the apache ratis api from v1.version to v2.version . <nl> this upgrade will allow alluxio to use the new transferleadership functionality in ratis version . this will allow alluxio masters to gracefully give up their leadership manually . <nl> no .,1624466582,move ttl modification to a and remove some unnecessary code,0.9374949932098389
ballerina-platform_ballerina-lang/29783,add support to log the ballerina-internal.log printed by observability test cases <cm-sep> update observability test utils tests to avoid port conflicts in parallel test runs <cm-sep> update observability integration tests to avoid port conflicts in parallel test runs <cm-sep> add missing wait calls for ports <cm-sep> add missing port into the required ports list <cm-sep> re-enable observability test utils listener endpoint test cases <cm-sep> add support to log ballerina internal log in observability utils tests <cm-sep> fix concurrency issue in ballerina test utils,"to fix this concurrency issue in the agent port manager , the method had been synchronized .",1617335926,we should be able to add a default value to a function pointer when it works as a function parameter .,0.924582302570343
apache_beam/13726,"change fhir search dofn 's output type from string to jsonarray <cm-sep> apply spotless <cm-sep> change the input type of fhir search to kv > from kv > . <nl> since the fhir search api takes in object as a parameter , we <nl> should also keep the fhir search connector as generic as possible <nl> so parameters other than strings ( e.g . list ) can be passed <nl> in . <cm-sep> change the input type of fhir search to kv > from kv > . <nl> since the fhir search api takes in object as a parameter , we <nl> should also keep the fhir search connector as generic as possible <nl> so parameters other than strings ( e.g . list ) can be passed <nl> in . <para-sep> search resources from a fhir store with string parameter values . <nl> search resources from a fhir store with any type of parameter values . <nl> search using the resource type of each written resource and empty search parameters . <nl> verify that there are no failures . <nl> verify that none of the result resource sets are empty sets .","change the input type of fhir search in the fhirio library to kv > from kv > . <nl> since the fhir search api takes in object as a parameter , we should also keep the fhir search connector as generic as possible so parameters other than strings ( e.g . list ) can be passed in",1610403591,"wire up the docker environmentfactory , and make the environment choice configurable . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .",0.957735002040863
OpenAPITools_openapi-generator/9807,conditional serialization add only those property which user wants to configure . <para-sep> / / returns false as { { name } } should not be serialized given that it 's read-only . / / false ( boolean ) <nl> / / returns false as { { name } } should not be serialized given that it 's read-only . / / false ( boolean ) <nl> to ensure ' { { # lambda.camelcase_param } } { { name } } { { /lambda.camelcase_param } } ' is required ( not null ) <nl> / / returns false as { { name } } should not be serialized given that it 's read-only . / / false ( boolean ) <nl> / / returns false as { { name } } should not be serialized given that it 's read-only . / / false ( boolean ) <nl> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .plg <nl> .opt <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> to test special tags <nl> anotherfakeapi | call123testspecialtags | patch /another-fake/dummy | to test special tags defaultapi | fooget | get /foo | fakeapi | fakehealthget | get /fake/health | health check endpoint fakeapi | fakeouterbooleanserialize | post /fake/outer/boolean | fakeapi | fakeoutercompositeserialize | post /fake/outer/composite | fakeapi | fakeouternumberserialize | post /fake/outer/number | fakeapi | fakeouterstringserialize | post /fake/outer/string | fakeapi | getarrayofenums | get /fake/array-of-enums | array of enums fakeapi | testbodywithfileschema,"conditionalserialization is exposed as flag when it sets to true it generates the shouldserialize ( ) method for each property along with flag which detect that property has been changes or set , if the property has been changed then the flag is set to true and shouldserialize return true , which allows the serialization that configured property in request body . <nl> -this gives a control to the user to decide what are the properties can be set in request body irrespective of sending all the other property which user does not configured . <nl> we face the issue",1624018656,- use comparenetobject for deep/recursive object comparison <nl> - add tests for pet <nl> - add tests for array of array of decimal .,0.9649114608764648
elastic_elasticsearch/72908,"add basic alias support for data streams . <nl> aliases to data streams can be defined via the existing update aliases api . <nl> aliases can either only refer to data streams or to indices ( not both ) . <nl> also the existing get aliases api has been modified to support returning <nl> aliases that refer to data streams . <nl> aliases for data streams are stored separately from data streams and <nl> and refer to data streams by name and not to the backing indices of <nl> a data stream . this means that when backing indices are added or removed <nl> from a data stream that then the data stream alias does n't need to be <nl> updated . <nl> the authorization model for aliases that refer to data streams is the <nl> same as for aliases the refer to indices . in security privileges can <nl> be defined on aliases , indices and data streams . when a privilege is <nl> granted on an alias then access is also granted on the indices that <nl> an alias refers to ( irregardless whether privileges are granted or denied <nl> on the actual indices ) . the same will apply for aliases that refer <nl> to data streams . <cm-sep> made code compatible with java 0 <para-sep> // <nl> // <nl> test <nl> test <nl> test <nl> do n't include backing indices of data streams , because it is just noise . aliases ca n't refer to backing indices directly . <nl> todo : take into account aliases ... ( this is only used from snapshot / restore ) <nl> it is important that we look up the index using the metadata builder we are modifying so we can remove an index and replace it with an alias . * / <nl> handle the actions that do data streams aliases separately : <nl> create a template <nl> add logs-myapp1 - > logs & logs-myapp2 - > logs <nl> remove logs-myapp1 - > logs & logs-myapp2 - > logs <nl> add logs- * - > logs <nl> remove logs- * - > logs <nl> create a template",aliases to data streams can be defined via the existing update aliases api . <nl> aliases can either only refer to data streams or to indices ( not both ) . <nl> also the existing get aliases api has been modified to support returning <nl> aliases that refer to data streams . <nl> aliases for data streams are stored separately from data streams and <nl> and refer to data streams by name and not to the backing indices of <nl> a data stream . this means that when backing indices are added or removed <nl> from a data stream that,1620722193,"this change allows to use an in the field capabilities api . indices are filtered from <nl> the response if the provided query rewrites to on every shard : . <nl> ` . <nl> the filtering is done on a best-effort basis , it uses the can match phase to rewrite queries to instead of fully executing the request . the first shard that can match the filter is used to create the field capabilities response for the entire index .",0.9847798943519592
elastic_elasticsearch/73366,deprecate realm names with a leading underscore . <nl> deprecation warning is now issued if any realm is configured with a name <nl> prefixed with an underscore . this applies to all realms regardless <nl> whether they are enabled or not . <para-sep> ensure at least one realm has invalid name,deprecation warning is now issued if any realm is configured with a name <nl> prefixed with an underscore . this applies to all realms regardless <nl> whether they are enabled or not .,1621950578,"with this change , the recommend way of disabling file/native realm is to explicitly set to , e.g . : <nl> this pr ensures that a warning is generated whenever file and/or native realm is implicitly disabled . <nl> this change also brings a question about the parameter . currently , the parameter is mandatory in version and gets a warning message if it is missing in 0.x . however , it makes sense to not specify the parameter if the realm is disabled . so i also updated the parameter related code to do just that .",0.973864734172821
Graylog2_graylog2-server/10146,"use shaded kafka version version for disk journal <cm-sep> update scala to version . <nl> workaround a bug in the jackson bom . <nl> it does n't contain a managed dependency for <nl> jackson-module-scala_2.0 . <nl> this makes it being resolved through kafka to a newer <nl> version , which prevents jersey to start . <cm-sep> switch to current kafka client <cm-sep> update log4j2 filter for shaded kafka <cm-sep> bump kafka to version 0 which should now be on mavencentral <cm-sep> keep kafka legacy mode using the shaded client version <cm-sep> use a better readable client.id . <nl> - fix use of wrong props variable <nl> - use a shortened node-id because the full node-id plus input-id is <nl> just too long to be readable <cm-sep> remove workarounds for bugs in the old kafka client . <nl> those are not necessary anymore . <cm-sep> mention workaround for incomplete jackson bom .","using a shaded dependency of the old kafka version client , allows us to update to a current kafka version , <nl> without breaking backwards compatibility on our on-disk kafka journal . <nl> the disk-journal and the kafka legacy input keeps on using the old library . <nl> it is known to hang on high loads and shows problems when partitions are re-balanced . <nl> tested against multiple kafka versions : , , ( the latter also with legacy mode ) . <nl> i 've extended partitions for a topic : . <nl> they get rebalanced just fine : .",1614163266,"created , edited and deleted a content pack with collectors .",0.8470768332481384
apache_shardingsphere/10305,"support postgresql prepare statement <cm-sep> add prepare statement validate test case <cm-sep> modify test case <para-sep> sharding prepare statement validator . <nl> prepare statement context . <nl> todo : fixme , since there is no segment for insertvaluesclause , insertstatement is created by sub rule . todo : deal with insert select <nl> todo : unsupported for withclause . <nl> todo deal with functiontable and xmltable <nl> postgresql deallocate statement . <nl> postgresql execute statement . <nl> postgresql prepare statement . <nl> get select statement . <nl> get insert statement . <nl> get update statement . <nl> get delete statement .","changes proposed in this pull request : <nl> - support postgresql , and statement ( and statement still need extra query to decide route result , and it will be optimized in next pr . ) <nl> - move postgresql , , and statement to postgresqlstatementsqlvisitor",1620720092,changes proposed in this pull request : <nl> - add unit test for historydatasynctaskgroup <nl> - move spilt logic to historydatasynctaskgroup <nl> - refactor historydatasynctaskgroup,0.9719492793083191
elastic_elasticsearch/73157,"be cleverer about extracting nested sources <para-sep> for the provided nested path , return its source maps from the parent xcontent map . <nl> in some circumstances , we can end up with arrays of arrays of nested objects . a nested source should always be a map , so we iterate down through the arrays to pull out the leaf maps","we store the source of nested documents on their parent doc , and then <nl> reconstruct inner hits sources by loading the parent source and extracting <nl> the relevant nested paths . the code paths that do this currently assume <nl> that all nested docs sit in a single array , but there are circumstances where <nl> nested docs within an object mapper can break this assumption . for example , <nl> the following document splits its nested docs across multiple arrays : . <nl> we accept this and index the three docs as nested docs of their parent with",1621259264,"when using custom processors , the field names extracted from the documents are not the <nl> same as the feature names used for training . <nl> consequently , it is possible for the stratified sampler to have an incorrect view of the feature rows . <nl> this can lead to the wrong column being read for the class label , and thus throw errors on training <nl> row extraction . <nl> this commit changes the training row feature names used by the stratified sampler so that it matches <nl> the names ( and their order ) that are sent to",0.9447967410087585
confluentinc_ksql/6785,"split groupbyparamsfactory <cm-sep> split execution steps <cm-sep> split group by builders <cm-sep> finish wiring up new steps <para-sep> we compare sets of column objects in case the column objects themselves are reordered ( which is fine ) , but the actual columns themselves may not be reordered -- the set comparison fails in that case as column objects store the index of the column in the schema <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then :","this pr fixes the issue by introducing new versions of the and execution steps instead . <nl> note that nothing is currently broken for users since the new multi-column group by logic is currently behind a feature flag . the presence of this feature flag is also the reason no historic qtts failed on the previous pr . <nl> for reviewers : the raw number of lines changed in this pr is high but each of the changes are straightforward . four commits for ease of reviewing : <nl> - split into ( old behavior , i.e. , single ,",1608104061,"( note : the feature is currently disabled behind the 'allow any key column name ' feature flag ) . <nl> this change fixes an issue with our repartition semantics . <nl> old style query semantics for partition by are broken : . <nl> s1 : rowkey = > b , c ( meaning s1 has a schema with rowkey as the key column , and b and c as value columns - types are n't important ) . <nl> s2 : rowkey = > b , c . <nl> as you can see the schema of s2 is still",0.989240288734436
elastic_elasticsearch/73631,"write next cluster state fully on all failures . <nl> today we do not set the flag <nl> on all failures , notably on an . since we do n't exit <nl> immediately on an oome we may have failed part-way through writing a <nl> full state but still proceed with another apparently-incremental write . <nl> with this commit we ensure is <nl> only set if the previous write was successful . <para-sep> noinspection emptytryblock <nl> ok <nl> ok","today we do not set the flag <nl> on all failures , notably on an . since we do n't exit <nl> immediately on an oome we may have failed part-way through writing a <nl> full state but still proceed with another apparently-incremental write . <nl> with this commit we ensure is <nl> only set if the previous write was successful .",1622573638,this pr ensures that api key role descriptors are always rewritten to a target node <nl> compatible format before a request is sent .,0.9557587504386902
apache_pulsar/10407,fix transaction buffer client channel not active problem .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1619536976,"we recently moved all config validation from client side to server side . <nl> however in order for the cli to submit its function to the server , users should supply some basic information ( like tenant/namespace/name ) because the submission path involves them . <nl> this pr adds back some basic checks back in the client so that we do basic checks for these fields . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9334821105003357
apache_druid/10812,"before i leaped i should 've seen , the view from halfway down <para-sep> for callers who have already authorized their query , and where simplicity is desired over flexibility . this method does it all in one call . logs and metrics are emitted when the sequence is either fully iterated or throws an exception . <nl> got ta transition those states , even if we are already authorized <nl> initialize the query lifecycle , setting the raw string sql , initial query context , and assign a sql query id . <nl> assign dynamic parameters to be used to substitute values during query exection . this can be performed at any part of the lifecycle . <nl> validate sql query and authorize against any datasources or views which will take part in the query . <nl> validate sql query and authorize against any datasources or views which the query . <nl> set planner context for logs/metrics in case something explodes early <nl> set parameters on planner context , if parameters have already been set <nl> we ca n't collapse catch clauses since sqlplanningexception has type-sensitive constructors . <nl> not authorized ; go straight to jail , do not pass go . <nl> prepare the query lifecycle for execution , without completely planning into something that is executable , but including some initial parsing and validation and any dyanmic parameter type resolution , to support prepared statements via jdbc . <nl> we ca n't collapse catch clauses since sqlplanningexception has type-sensitive constructors . <nl> plan the query to enable execution . <nl> execute the fully planned query . <nl> prepare an sql query for execution , including some initial parsing and validation and any dyanmic parameter type resolution , to support prepared statements via jdbc . <nl> sanity check <nl> this is sort of lame , planner wo n't cough up its validator , which is nice and seeded after validating a query , but it is private and has no accessors , so make another one so we can get the parameter types ... but i suppose beats creating our own prepare and planner implementations <nl> bindings for dynamic parameters to bind during planning <nl> result of authentication , providing identity to authorize set of resources produced by validation <nl> set of datasources and views which must be authorized <nl> result of authorizing set of resources against authentication","this pr primarily does two things : <nl> * refactors the ( afaict ) currently unused druid view system in the hopes that someday it can be built into something useful , by splitting into a separate calcite schema and introducing a new authorization construct to allow defining access to views separately from datasources . <nl> * refactors to authorize datasources ( and now views ) up front , before preparing or planning a query , by analyzing the sql expression directly rather than waiting until after the transformation from sql to native druid query is done . <nl> _note",1611831707,"in this pr , i newly added two methods to for lazy evaluation of initial value of accumulation . <nl> after this patch , the buffer acquisition order for nested group-by query execution is changed from outer - > inner to inner - > outer . in addition , once the intermediate result of inner queries are n't needed anymore , the buffer holding it is released immediately . as a result , nested group-by queries always need at most 0 buffers . <nl> so , please review it first .",0.9801061153411865
elastic_elasticsearch/73992,simplify blobstore consistency check in tests . <nl> this adds that async <nl> check and removes the need to manually pass executors around as well .,this adds that async <nl> check and removes the need to manually pass executors around as well .,1623316513,"implemented method that would automatically register a default aggregator implementation for any . although , this was a very powerful feature , it was not very flexible , as there was no way to override the default aggregator for one or more s. . <nl> the aggregations that used the method so far were : , and . <nl> in this pr we remove the method and replace it with explicitly registering all with their aggregator . this means that all classes are registered explicitly with their aggregators ( for , and ) . <nl> for the sub-classes of that",0.9295759201049805
elastic_elasticsearch/73244,"add a test that exhibits the bug <cm-sep> handle the existence of system data streams in get aliases api . <nl> this commit adjusts the behavior of the get aliases api to more <nl> thoroughly prevent errors and warnings from being emitted unnecessarily <nl> from the get aliases api when system data streams exist . <nl> this is a hack which should be removed as soon as possible . <cm-sep> spotless <cm-sep> check both base route and nonexistent alias in test <para-sep> resolve all concrete indices upfront and warn/error later <nl> system index that backs system data stream <nl> note that we are superuser here but do not provide a product origin <nl> note that we are both superuser here and provide a product origin <nl> create a system data stream <nl> create a system index - this one has an alias <nl> create a regular index <nl> create a system index - this one has an alias <nl> create a regular index <nl> get a non-system alias , should not warn or error <nl> fully specify a regular index and alias , should not warn or error <nl> the rest of these produce a warning <nl> the base _alias route warns because there is a system index in the response <nl> specify a system alias , should warn <nl> fully specify a system index and alias , should warn <nl> check an alias that does n't exist <nl> specify a system data stream as an alias - should 0 <nl> create a system data stream <nl> create a system index - this one has an alias <nl> create a regular index","this commit adjusts the behavior of the get aliases api to more <nl> thoroughly prevent errors and warnings from being emitted unnecessarily <nl> from the get aliases api by retrieving all indices including system ones <nl> and only warning in the post processing of the action . <nl> additionally , the indexabstractionresolver has been updated to properly <nl> handle system data streams when evaluating visibility .",1621432702,this creates an auto update service . the first automatic update is rewriting datafeed aggregations if they exist .,0.9653140306472778
jenkinsci_jenkins/5438,fix newlineatendoffile checkstyle violations in tests <cm-sep> fix onetoplevelclass checkstyle violation in tests <cm-sep> fix onestatementperline checkstyle violations in tests <cm-sep> fix illegalimport checkstyle violation in tests <cm-sep> fix unusedimports checkstyle violations in tests <cm-sep> fix modifierorder checkstyle violation in tests <cm-sep> fix redundantmodifier checkstyle violations in tests <cm-sep> enable checkstyle for test sources,"i kept seeing new unused imports crop up , which i thought i had fixed already by enabling the checkstyle check . then i realized that checkstyle was not being run against test sources . this pr enables checkstyle for test sources and cleans up any existing violations . the motivation is to keep code cleanups from regressing in the future .",1618868308,* no tests <nl> * changelogs are not required .,0.8818394541740417
apache_flink/16257,fix upsert-kafka produce duplicates when enable object reuse <cm-sep> address the comments,"fix upsert-kafka produce duplicates when enable object reuse . <nl> - add tests in to verify the results if enable object reuse . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that",1624450931,"currently , format only support deserialization , but not support serialization , which is not convenient for users to writing changelogs to an message queue . the serialization for could follow the json strcuture of debezium , but should consider currently flink ca n't combine and into a single message . this could encode and as and debezium messages . therefore , this could support serialization for format . <nl> - add which serialization schema from flink table/sql internal data structure to debezium json . <nl> - supports with creating encodingformat for . <nl> - add test cases for to",0.9358683824539185
pentaho_pentaho-kettle/7926,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) <para-sep> fileobject.isreadable wrongly returns true in windows file system even if not readable <nl> fileobject.isreadable wrongly returns true in windows file system even if not readable,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) .,1617984633,adding new pdi client type ' other ' with a configurable client id,0.8271981477737427
apache_flink/15285,introduce desc grammar in sql parser <para-sep> describe | desc [ extended ] [ [ catalogname . ] databasesname ] .tablename sql call .,"introduce desc grammar in sql parser , combine desc and describe commands in sql client module . <nl> this change added tests and can be verified as follows : <nl> - added tests in flinksqlparserimpltest and flinkhivesqlparserimpltest to verify syntax support . <nl> - change tests in sqlcommandparsertest to verify parser desc syntax with sql parser . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl>",1616150815,"* support optional retention policy for influxdb metric reporter ( currently only default is allowed ) . <nl> * added support for retention policy specification for influxdb metrics reporter along with supporting tests and documentation . <nl> this change added tests and can be verified as follows : . <nl> * running the unit test suite . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths",0.8012978434562683
elastic_elasticsearch/73449,"trigger a reroute after registering a node for removal . <nl> the cluster will not automatically react to the node shutdown being <nl> registered unless we notify it that something has changed that may <nl> require a change in shard allocation . this commit modifies the put <nl> shutdown action to invoke a reroute after the cluster state has been <nl> updated , as well as an integration test to verify that shards quickly <nl> move away from nodes which are shutting down for removal . <para-sep> create an index with enough replicas to ensure one would normally be allocated to each node <nl> now that we know all shards of the test index are assigned except one , make sure it 's unassigned because of the allocation decider . <nl> checks that a reroute is started immediately after registering a node shutdown , so that shards will actually start moving off of the node immediately , rather than waiting for something to trigger it . <nl> check to ensure there 's a shard on the node we want to shut down <nl> double check that there 's actually a shard on the node we want to shut down <nl> register the shutdown <nl> assertbusy waiting for the shard to no longer be on that node <nl> create an index with enough replicas to ensure one would normally be allocated to each node <nl> watch to ensure no shards gets allocated to the node that 's shutting down <nl> delete the shutdown <nl> check that the shard is assigned now <nl> put a shutdown request <nl> verify that there 's not already a shutdown metadata for this node","the cluster will not automatically react to the node shutdown being <nl> registered unless we notify it that something has changed that may <nl> require a change in shard allocation . this commit modifies the put <nl> shutdown action to invoke a reroute after the cluster state has been <nl> updated , as well as an integration test to verify that shards quickly <nl> move away from nodes which are shutting down for removal .",1622072792,this commit removes all but one reference to . <nl> this is to support more than one result index for a single job .,0.9642473459243774
Alluxio_alluxio/12482,explicitly respond empty message to journal writer <para-sep> explicitly return empty future since no response message is expected by the journal writer avoid using super.applytransaction ( ) since it will echo the message and add overhead <nl> create a counting master implementation that counts how many journal entries it processed . <nl> create entries on the leader journal context . these will be replicated to follower journal context . <nl> wait for sequences to be caught up .,ratis by default echo the journal message back after it is applied . this wastes a lot of memory and cpu time . this change makes the state machine explicitly return empty message since the journal write does n't really care about the response content .,1605032692,add human readable format option for count .,0.9185042381286621
Alluxio_alluxio/12512,check whether updatechecker is running in tests,processes launched with multiprocesscluster did n't have updatechecker enabled and thus sending unnecessary data to diagnostics.alluxio.io .,1605550756,error ( inconsistent files ) .,0.9029442071914673
apache_druid/11017,"fix subquery with order by <para-sep> first frame , ask for all rows .","problem : <nl> in the jdbc connection , it is invalid to use subquery with clause . it will throw excepiton with msg : . <nl> reason : <nl> the exception was thrown in , let 's see the orginal code : . <nl> the problem should focus on , we try to validate sqlnode to get parametertypes , however , when we use order by clause , the item will be pushed down into node through the method invoke chain <nl> - > - > - > - > , therefore , the variable was change in the first",1616223739,"all dimension positions other than the first index ( which has the value of the last column ) , will have null values instead . <nl> prior to this fix the added test would fail with",0.9268174171447754
hazelcast_hazelcast/18599,share cluster in expressiontestsupport . <nl> reduces the affected tests form 0 seconds to about 0 seconds locally . <nl> also makes the laptop more quiet during that . <para-sep> after each test ditch all jobs and objects,reduces the affected tests form 0 seconds to about 0 seconds on my machine . <nl> also makes the laptop more quiet during that .,1619449874,"hazelcastinstancefactory is an internal api , but we discovered external projects do use it directly anyway . <nl> we recently did two changes : . <nl> renamed hazelcastinstancefactory into hazelcastinstancemanager ( sha ) <nl> introduced a new abstraction for hazelcastinstancefactory ( sha ) and dynamic registration via meta-inf <nl> both changes might break external projects . <nl> the 1st change is easy to revert as it 's just naming . manager actually describes the responsibility better , <nl> but api compatibility has priority . we could introduce a compatibility layer , but it 's not worth the extra complexity .",0.9136064052581787
apache_shardingsphere/10758,fix calcite select result merge error when call execute method <para-sep> todo process getstatement,changes proposed in this pull request : <nl> - support calcite query for execute method in and <nl> - fix arrayindexoutofbounds exception when get shorthand projection with duplicate table <nl> - refactor duplicate code in <nl> - add test cases for execute method in and,1623383889,changes proposed in this pull request : <nl> - support geturl <nl> - support getbigdecimal .,0.9560704827308655
Alluxio_alluxio/13083,"prevent unnecessary inode syncing . <nl> before this pr , running . <nl> will trigger syncing inodes : <nl> ( 0 ) <nl> ( 0 ) <nl> ( 0 ) ( added to pending inode queue when <nl> traversing ( 0 ) ) . <nl> reading ( 0 ) is unnecessary w.r.t . the command we are interested . this pr <nl> check and prevent setting flag unnecessarily . <nl> in addition , this patch also saves one unnecessary rpc on ls command . <cm-sep> resolve conflict <para-sep> only sync children when ( 0 ) descendanttype.all or ( 0 ) syncing root of this stream & & descendanttype.one",note that this port no longer saves the one rpc request that was saved in the original commit .,1615853475,fix infinite retries when a directory can not be created in ufs due to permission issue .,0.9154240489006042
ballerina-platform_ballerina-lang/28008,fix several issues <nl> this commit fixes <nl> - considering included fields when setting the flag for record types with all fields <nl> - flag not being set for some unions with implicitly members <nl> - certain cyclic unions not having all members at runtime <nl> - check for cyclic unions with the fix for the previous issue <cm-sep> add tests for implicit readonly-ness with inclusions <cm-sep> add test for cyclic union comparison against subset <para-sep> commonresponse ; <nl> commonresponse ; <nl> openrecordwithallreadonlyfields ; closedrecordwithallreadonlyfields ; <nl> closedrecordwithallreadonlyfields ; <nl> commonresponse ; <nl> commonresponse ;,will create an issue to revisit this .,1611137065,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.953488826751709
hazelcast_hazelcast/18554,"fix kafka added partitions test . <nl> what likely happened is that the 1000ms sleep probably was n't enough . it <nl> takes a while after adding a partition until the producer finds out <nl> about it . i moved the sleep into the loop so that we reset it after each <nl> attempt . <para-sep> add a partition and produce an event to it <nl> we produce to a partition that did n't exist during the previous job execution . the job must start reading the new partition from the beginning , otherwise it would miss this item . <nl> reset the producer for each attempt as it might not see the new partition yet",what likely happened is that the 1000ms sleep probably was n't enough . it <nl> takes a while after adding a partition until the producer finds out <nl> about it . i moved the sleep into the loop so that we reset it after each <nl> attempt .,1618592509,"- detailed states ( mc_license_not_required , mc_conn_err_ etc ) <nl> - fixed null check at jsonutil",0.9263113141059875
apache_shardingsphere/10524,support pg drop multi index statement & add validator test <cm-sep> fix checkstyle <cm-sep> fix checkstyle,"changes proposed in this pull request : <nl> - support pg drop multi index statement <nl> - add add index , alter index , drop index validator and test",1622188633,add data consistency check function .,0.9600828886032104
elastic_elasticsearch/73538,fix method ref bug <cm-sep> fix bug for primitive capture in method ref <cm-sep> fix antlr <cm-sep> fix antlr <para-sep> interfaces that override a method from object receive the method handle for object rather than for the interface ; we change the first parameter to match the interface type so the constant interface method reference is correctly written to the constant pool <nl> describes if the first capture of a method reference requires boxing * /,this changes fixes three bugs all related to function references in painless . <nl> first : <nl> fixes a bug where if a primitive type is used as a capture a verifyerror is returned from the compiler . the primitive is now boxed automatically on behalf of the user . <nl> example : . <nl> second : <nl> fix a bug where we output an internal error as opposed to a user error in the case of a static method used with a non-static capture . we now give the user feedback that they can not do this instead of,1622232613,this commit populates the _stats api response with sensible ' empty ' <nl> and objects when the job itself <nl> has not started reporting them .,0.9096531271934509
apache_pulsar/10639,transaction admin api get transaction coordinator status .,"this is transaction buffer metrics . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment",1621414736,3rd part of changes for . includes the creation of the snapshots when the replicated subscriptions feature is enabled .,0.9860115647315979
OpenAPITools_openapi-generator/9039,change break to consumes so that all operations will be processed,an error in the handling of the for loops caused it to early exit in case the spec contained entries without consuming properties .,1616415826,- add copyright <nl> - format code <nl> - change logger.info to logger.debug <nl> - change permission on shell script .,0.7963157296180725
prestodb_presto/16250,"fix naming for spilled aggregation tests . <nl> methods should be lower camel case , and tests should begin with the <nl> word ' test ' <cm-sep> add flags to disable spill for distinct/order by aggregations . <nl> queries can sometimes use more memory in distinct and order by <nl> aggregations when spill is enabled compared to when it is n't . until <nl> this is fixed we want to be able to disable those features and still <nl> have other operator spilling happen . <para-sep> set this low so that if we ran with spill the query would fail <nl> set this low so that if we ran with spill the query would fail <nl> the sum ( ) is necessary so that the aggregation is n't optimized into multiple aggregation nodes","added flags to disable spilling for distinct and order by aggregations since with spill enabled , they can cause queries to use more memory than without spilling . left the features enabled by default to maintain previous behavior . <nl> test plan - unit test .",1623425182,topnrownumberoperator can cause increased memory footprint <nl> ( e.g : 2x ) vs plain windowoperator if partitions are small <nl> ( e.g : few rows ) . this can cause queries to fail because of <nl> out of memory .,0.873345136642456
apache_pulsar/10074,use unique function names <cm-sep> use awaitility for all function status checks . <nl> - wait up to 0 seconds <para-sep> get function status,pulsarfunctionsprocesstest tests are currently the most flaky tests . this pr contains a few changes as an attempt to reduce flakiness . <nl> * use unique function names for all tests <nl> * use awaitility in all getfunctionstatus calls <nl> * extend maximum polling time to 0 seconds,1617026150,"this pr moves the rest of the functions worker related code to use v2 style <nl> # # # modifications . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.8681468963623047
apache_kafka/10502,cleanup <cm-sep> first fix <cm-sep> revert ' cleanup ' . <nl> this reverts commit sha .,# # # committer checklist ( excluded from commit message ) .,1617843021,"this api was removed previously in an unrelated change , but seems worth keeping",0.895340621471405
Alluxio_alluxio/13314,add label for alluxio worker to support distributed load to specific worker by given label .,"with this pr , we can use distributedload shell like this . <nl> so , job master can dispatch the task to the job worker which belong to the racka .",1619681793,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9665070176124573
grpc_grpc-java/7941,make altsserverbuilder extend forwardingserverbuilder . <cm-sep> make addservices ( ) a final method on serverbuilder and delete from its forwarders .,make altsserverbuilder extend forwardingserverbuilder so we do not need to worry about method forwarding test . <nl> internal changes : cl/0,1614911410,improves debugging experience with clientcall instances .,0.88660728931427
hazelcast_hazelcast/18811,"read , filter & project kafka records in a single processor <para-sep> an immutable and thread-safe context of a running query .",to support watermarks from sql we need the row ( ) to be accessible while applying event time policy .,1622458041,this reverts commit sha . <nl> an alternate or augmented solution must be considered .,0.9585358500480652
OpenAPITools_openapi-generator/9672,"fix python fastapi tests , update readme , add ci test",- better tests to avoid status code comparison <nl> - better readme <nl> - add ci tests <nl> - fix paypal link .,1622776749,this pr fixes the errors in models .,1.0
neo4j_neo4j/11525,made backup names in onlinebackuphait unique . <nl> backup names may have been coliding between tests . <nl> makes backup names unique,backup names may have been coliding between tests . <nl> makes backup names unique,1523461271,"there is a bug in the schema index partitioning that could lead to problems adding/updating lucene documents . the problem is the following : . <nl> lucene 's docids are 0 bits ( so we need partitioning ) and those are assigned using the indexreader 's maxdoc ( ) property . maxdoc ( ) is generally larger than numdocs ( ) which takes deleted documents into account . as deleted documents are not removed asap ( it may take very long time until they are deleted , sometimes they are never deleted , especially because you are using the '",0.909220814704895
confluentinc_ksql/6884,enable decimal for protobuf <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> then ( did not throw ),this pr enables decimal for protobuf in ksqldb .,1611268928,adds support for listing queries to the java client . <nl> docs will come in a follow-up pr . javadocs on the new method and interface are included in this one . <nl> added unit and integration tests .,0.9747917056083679
elastic_elasticsearch/73198,"this commit adds deprecation warnings for use of the path.shared_data <nl> setting as well as the index setting index.data_path . <para-sep> note : this must be done with an explicit check here because the deprecation property on a path setting will cause es to fail to start since logging is not yet initialized on first read of the setting <nl> 0 % of the time , for non-external clusters",this commit adds deprecation warnings for use of the path.shared_data <nl> setting as well as the index setting index.data_path .,1621342313,ccs with remote indices only does not require any privileges on the local cluster . <nl> this pr ensures that search with scroll follow the permission model .,0.9450350999832153
elastic_elasticsearch/72967,"add verification for having on tophits with subquery . <nl> previously , when a tophits aggregation function was used ( first/last , <nl> or min/max on keyword field ) in a subquery and on an outer query this <nl> aggregation was filtered ( with where/having ) the verification was passed <nl> successfully and the query was planned and translated resulting into an <nl> unsupported query dsl - since bucket selector on a tophits agg is not <nl> currently supported , and the user received a weird error msg . <nl> verify this case of subselects with tophits aggs and throw an <nl> appropriate error message to the user .","previously , when a tophits aggregation function was used ( first/last , <nl> or min/max on keyword field ) in a subquery and on an outer query this <nl> aggregation was filtered ( with where/having ) the verification was passed <nl> successfully and the query was planned and translated resulting into an <nl> unsupported query dsl - since bucket selector on a tophits agg is not <nl> currently supported , and the user received a weird error msg . <nl> verify this case of subselects with tophits aggs and throw an <nl> appropriate error message to the user .",1620817573,"this commit unmutes and fixes tests around some geolineaggregator edge <nl> cases . <nl> - mergedgeolines had a silly bug where it was accepting internalgeolines <nl> that were empty <nl> - ' complete ' is measured by the heap-mode of the bucketedsort , which is a problem <nl> since if the length of the data equals the max-size , then it is difficult to know <nl> whether any values were discarded . <nl> - geolinebucketsort had an array-resizing bug s/ > / > = .",0.9185329675674438
apache_beam/14883,"support side input in samza portable runner <para-sep> map from side input id to global pcollection id . <nl> creates a new state handler for the given stage . note that this requires a traversal of the stage itself , so this should only be called once per stage rather than once per bundle . <nl> find values for the given key <nl> find all keys <nl> mapping from view id to a view mapping from side input id to a view <nl> todo : support state handlers <nl> the method is used to translate both portable gbk transform as well as grouping side inputs into samza . <nl> analyze side inputs <nl> create a runner-side view <nl> use gbk to aggregate the side inputs and then broadcast it out <nl> this method follows the same way in flink to create a runner-side java pcollectionview to represent a portable side input . <nl> todo : support custom mapping fn <nl> group the side input globally with a null key and then broadcast it to all tasks . <nl> this method is used to translate both native java publishview transform as well as portable side input broadcasting into samza .","add support of side input inside samza portable runner . similar to flink , we are creating a corresponding view on the java side , and then use gbk and broadcast it to all the worker tasks",1621975075,"wire up the docker environmentfactory , and make the environment choice configurable . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .",0.9669855237007141
Graylog2_graylog2-server/10708,"okta on-prem : support external users <cm-sep> add auth service types <cm-sep> typings for okta auth service <cm-sep> updated vendor modules <cm-sep> okta on-prem : new api active-backend-type <cm-sep> load active backend and show login form if matched <cm-sep> okta on-prem : renamed api active-backend/type <cm-sep> * add okta backend config shape . <nl> * user correct active backend endpoint <cm-sep> * centralize timeout multiplier handling in tests . <nl> * centralize timeout multiplier handling . <nl> in a couple of places we need to set custom timeouts for jest tests . in <nl> these cases we should take the env variable into <nl> account . in order to avoid having to handle that over and over again <nl> ( parsing , validating , applying it ) , this change is adding two functions <nl> to the module : . <nl> - : returning the raw multiplier , if not <nl> set or not parseable <nl> - : applies the configured timeout <nl> multiplier to any given timeout . <nl> the latter function should be used in tests to apply the multiplier to <nl> any custom timeout override . <nl> * adding license header . <nl> * use default values for scaling & interpolation if absent . <nl> * return default value for scaling factor if absent . <nl> * use if interpolation mode is absent . <nl> * allow emptying relative range value inputs in date time picker when entering new value . <nl> * allow to temporary empty relative range value inputs in date time picker . <nl> before this change it was not possible to temporary empty the relative <nl> range value inputs . when a user tried to remove all numbers , we <nl> automatically inserted a 0. we mainly did this because we are always <nl> updating the form state . if we would define for example <nl> for the relative range value , we would loose the <nl> information which range type is selected . the range type is <nl> being inferred based on the time range form value . <nl> for example if the form state value for the relative range is 0 , the <nl> displays : 0 ( value ) minutes ( type ) . <nl> with this pr we are implementing a separate state for the which controls the <nl> relative range inputs . we are still updating the form","in this first step we are migrating the authentication feature to on-prem enterprise users , to improve consistency between the versions . <nl> - unit tests <nl> - manual api testing <nl> - local ui testing <nl> it is important to test this change in various plugin configurations <nl> 0. core : behavior should be unchanged , i.e . only ldap/ad/db are supported <nl> 0. enterprise : oidc/okta is available as an additional authentication service <nl> 0. enterprise + cloud : behaviour is unchanged from cloud , i.e . oidc/okta is the only available authentication service .",1621956444,- disable the stacked field form in quickvalues configuration when elasticsearch version is < 0 <nl> - reset loading state in case of an error so the user can change settings and try again <nl> - reset quickvalues visualization config to defaults when analyzing a new field . <nl> note : this needs to go into the version branch as well,0.9037922620773315
elastic_elasticsearch/73558,"add support for is_write_index flag to data stream aliases . <nl> this allows indexing documents into a data stream alias . <nl> the ingestion is that forwarded to the write index of the data stream <nl> that is marked as write data stream . <nl> the parameter can be used to indicate what the write data stream is , <nl> when updating / adding a data steam alias . <para-sep> unset write flag <nl> change write flag : <nl> setting up data stream and alias with write flag in leader cluster : <nl> setting up data stream and alias with write flag in follower cluster : <nl> todo : do n't update logs-http alias in follower cluster when data streams are automatically replicated from leader to follower cluster : ( only set the write flag to logs-http-na ) create alias in follower cluster that point to leader and follower data streams : <nl> create a template","this allows indexing documents into a data stream alias . <nl> the ingestion is that forwarded to the write index of the data stream <nl> that is marked as write data stream . <nl> the parameter can be used to indicate what the write data stream is , <nl> when updating / adding a data steam alias .",1622467583,adds a hard_bounds parameter to explicitly limit the buckets that a histogram <nl> can generate . this is especially useful in case of open ended ranges that can <nl> produce a very large number of buckets .,0.9627954363822937
elastic_elasticsearch/73991,"this adds an async query mode to sql . <nl> it ( re ) uses the same request and response async-specific eql object <nl> parameters . <nl> also similar to eql , the running search task can have its state <nl> monitored and canceled and its results stored and deleted , with <nl> intermediary responses not supported ( the entire result is available <nl> once search finished ) . <nl> the initial query and subsequent pagination/scrolling requests will both <nl> be started in the async mode . <cm-sep> this extends the async implementation to support working with the text <nl> formats ( txt , csv , tsv ) . <nl> a test validating the administrator operation of a user with the <nl> ' manage ' permission has also been added . <para-sep> internal class for temporary storage of eql search results <nl> update the expiration time of the ( partial ) response . <nl> this method is called when the task is finished successfully before unregistering the task and storing the results <nl> this method is called when the task failed before unregistering the task and storing the results <nl> return currently available partial or the final results <nl> exposes sql async action names for the rbac engine <nl> service for managing eql requests <nl> wrapper for eqlsearchrequest that creates an async version of eqlsearchtask <nl> if we did n't start operation for any reason , we need to clean up the task that we have created <nl> this is will performed in case of timeout <nl> this will be performed at the end of normal execution <nl> we finished before timeout <nl> we finished after timeout - saving results <nl> we finished before timeout <nl> we finished after timeout - saving exception <nl> we should only unregister after the result is saved <nl> adds a self-unregistering listener to a task . it works as a normal listener except it retrieves a partial response and unregister itself from the task if timeout occurs . <nl> timeout was triggered <nl> a response for * ql search status request <nl> get status from the stored ql search response <nl> returns the id of the eql search status request . <nl> this could be either because eql search has n't finished yet , or if it finished and some shards have failed or timed out . <nl> returns a timestamp when the eql","this adds an async query mode to sql . <nl> it ( re ) uses the same request and response async-specific eql object <nl> parameters . <nl> also similar to eql , the running search task can have its state <nl> monitored and canceled and its results stored and deleted , with <nl> intermediary responses not supported ( the entire result is available <nl> once search finished ) . <nl> the async implementation is extended to work with the sql-specific <nl> text formats ( txt , csv , tsv ) as well , besides xcontent . <nl> ( feature-branch merging",1623315980,,0.0
ballerina-platform_ballerina-lang/28102,fix ballerina.toml compilation issues <para-sep> check org is valid identifier <nl> check that the package name is valid <nl> check version is compatible with semver <nl> this was put in as a temporary fix to prevent update breaking from possible errors <nl> 0 ) initialize the project instance <nl> 0 ) check editing files,this pr contains the fix . <nl> fixes # .,1611296838,pr adds <nl> - removeheaders native function to remove all headers from the message <nl> - test cases <nl> - refactor doc comments .,0.9375116229057312
hazelcast_hazelcast/18586,"add reproducer for rebalance in stage which is later fused and a naive fix <para-sep> if the first stage of the chain is rebalanced , then we set the rebalance flag of the created fused stage . only consider the case when first element of the chain is rebalanced because there is n't any other case . if any stage in the middle includes rebalance , then those stages are not fused by findfusablechain ( ) .",this pr fixes the problem by transferring the rebalance flag of the first stage of the fused transform chain to the newly created combined stage .,1619162017,this was actually addressed in following pr . <nl> members and clients disconnect the connection as soon as <nl> heartbeat timeout is detected . <nl> this pr fixes member side heartbeat monitor . it was not closing <nl> the connections if the connection is not an owner connection .,0.9096975326538086
Graylog2_graylog2-server/10483,"happy path working <cm-sep> update and refactor unit test <cm-sep> unit tests <para-sep> return the es query string for the group by fields specified in event ; or empty if none specified . search value is escaped and enclosed in quotes . <nl> group by fields need to be saved on the event so they are available to the subsequent notification events <nl> determine event source streams based on given search and aggregation <nl> this can happen if the user did n't select any stream in the event definition and an event should be created based on the absence of a search result . ( e.g . count ( ) < 0 ) when the source streams field of an event is empty , every user can see it . that 's why we need to add streams to the field . we decided to use all currently existing streams ( minus the default event streams ) to make sure only users that have access to all message streams can see the event . <nl> if the search streams is empty , we search in all streams and so we include all source streams from the result . <nl> with an empty result we just include all streams from the event definition . <nl> we do n't want source streams in the event which are unrelated to the event definition . <nl> helper to perform basic lucene escaping of query string values <nl> these characters are part of the query syntax and must be escaped <nl> helper to call sourcemessagesforevent when testing query string values - we do n't care about anything else <nl> helper method to build test aggregationresult , since we only care about a few of the values <nl> helper method to build test eventdefinitiondto , since we only care about a few of the values",the map is populated when processing an alert with an aggregation . we later refer to the map in order to select the correct set of messages for the notification backlog . i.e . the backlog contains only messages that match the key value ( s ) in the notification . <nl> any group-by selection is ignored . <nl> tested locally via the ui and unit testing .,1619009001,"so far it has not been possible to execute only parts of a search , e. , g. , to retrieve a single page of a paginated message list widget . <nl> this pr allows to define a whitelist of s under the part of the execution state which can be passed to the endpoint . <nl> the way to load a single page for a a message list widget would be to define and in the part of and specifiy only this in the whitelist : .",0.9184973835945129
Alluxio_alluxio/13001,add listingcache metrics <para-sep> record a cache hit . <nl> record a cache miss . <nl> record a loading of data asa result of cache miss . <nl> record evictions in the cache .,there are 0 changes here : . <nl> 0. make it more specific that load times are loads that happened as a result of a cache miss . <nl> 0. add listing cache statistics .,1614883961,"the previous user group mapping does not work , so i also think it 's a bug . in addition , the user group translation is mistakenly included in the version doc ( and a user asked about it in mailing list before ) so we should cherry pick it to version .",0.9518435597419739
apache_kafka/10715,": increase heartbeat and session timeout <para-sep> increase the session timeout value , to avoid unnecessary rebalance",increase heartbeat and session timeout to make the test reliable . <nl> session timeout - > 0 sec <nl> heartbeat timeout - > 0/0 = 0 sec .,1621306003,"given that the tests do not create clusters larger than 0 , we do not gain much by creating 0 partitions for that topic . reducing it should slightly increase test startup and shutdown speed",0.9021885991096497
Alluxio_alluxio/12475,log some information when trylock fail,the metrics from is . <nl> worker_block_remover_blockstoremoved_success_count_xx version . <nl> worker_block_remover_blockstoremoved_take_count_xx version . <nl> worker_block_remover_blockstoremoved_size version . <nl> worker_block_remover_removingblocks_size version,1604934884,"this pr introduces a retry for the open call instantiated as part of . due to eventual consistency in object stores , an open ( get ) after a create might fail on first attempt . <nl> note : ufs : open is only called for files alluxio already has the meta-data for and expects to exist in the ufs .",0.9547023773193359
vespa-engine_vespa/18418,"no functional changes <cm-sep> split into tables <cm-sep> serialize writes to each table <cm-sep> continue on old data <cm-sep> remove redundant check <para-sep> ( 0 is timestamp ) <nl> ( 0 is timestamp ) <nl> example : nodetable.ensurecolumnexists ( ' write_rate ' , ' float ' ) ; <nl> example : clustertable.ensurecolumnexists ( ' write_rate ' , ' float ' ) ; <nl> a questdb table * / <nl> we remove full days at once and we want to see at least three days to not every only see weekend data <nl> remove unless all partitions are old : removing all partitions ' will be supported in the future ' <nl> repairs this db on corruption . <nl> we can not add old data to questdb , but we want to use all recent information <nl> too old ; discard",nothing here you have n't seen,1624634758,"while trying to add another field to node i came upon the multitude of places <nl> the constructor is called . this is simplified by using a builder . <nl> the builder is internal to node for now . if wanted/needed , it can be made <nl> public ( especially tests may be interested - i have touched as few as <nl> possible ) .",0.9651044011116028
OpenAPITools_openapi-generator/8788,use files.createtempfile to address security concerns,"in the online generator , use files.createtempfile to address security concerns .",1613982853,- update readme <nl> - add copyright note <nl> - minor code format <nl> - move the petstore sample under sub-folder .,0.8620409369468689
apache_pulsar/10618,"process async results in the same java runnable thread . <nl> motivation . <nl> after introducing the support for async functions , the java function processing semantic is not enforced . <nl> for example , if it fails to write a sink , it does n't fail the java instance or fail the message . hence it keeps <nl> receiving messages but never ack or nack . <nl> modification . <nl> change the way how aysnc function requests are processed to fix the issues we have seen in kinesis connector . <para-sep> the thread used for processing async results failed <nl> peek the next result <nl> process the synchronous results <nl> the function does n't produce any result or the user does n't want the result . <nl> increment total successfully processed <nl> fail the source record","motivation . <nl> after introducing the support for async functions , the java function processing semantic is not enforced . <nl> for example , if it fails to write a sink , it does n't fail the java instance or fail the message . hence it keeps <nl> receiving messages but never ack or nack . <nl> modification . <nl> change the way how aysnc function requests are processed to fix the issues we have seen in kinesis connector .",1621291861,"according to , we need to support builder for topicsconsumer . <nl> - add in consumerbuilder <nl> - add test for the builder .",0.9646723866462708
elastic_elasticsearch/74252,"fail composite aggregation if after key is unparsable <para-sep> this method will then attempt to parse the formatted value using the specified format , and throw an illegalargumentexception if parsing fails . this in turn prevents us from returning an after_key which we ca n't subsequently parse into the original value . <nl> yyyy is week-based year . the parser will ignore mm ( month-of-year ) and dd ( day-of-month ) <nl> yyyy is week-based year . the parser will ignore mm ( month-of-year ) and dd ( day-of-month ) <nl> yyyy is week-based year . the parser will ignore mm ( month-of-year ) and dd ( day-of-month )","it is possible that the format for the composite after key will generate a string that can not be parsed back into the original value . this typically occurs either because of a format error ( e.g . mixing month and week based date formats ) or because the format resolution is coarser than the bucket resolution ( e.g . you asked for hourly buckets but formatted the keys as days ) . when the user then sends back this after key for the next page , they will get an earlier page of data instead . this can result",1623944313,"generating a ca on the fly is an attempt at workflow optimisation that was inherited from certgen . there are potential pitfalls with this approach . overall it is recommended to separate the step of ca creation and mandate a ca to be specified when generating certificate . <nl> this pr add a deprecation message if the cert command is used without specifying a ca . a follow up pr will throw error for this usage in version . <nl> for use case where we explicitly trust a certificate without needing a ca , e.g . saml message signing ,",0.9371306300163269
vespa-engine_vespa/18175,"this reverts commit sha , reversing <nl> changes made to sha . <cm-sep> update cliclient to use new jsonfeeder inteface",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623240350,this is not much in the way of functionality yet .,0.9795838594436646
apache_pulsar/10888,"make keyvalueschema an interface visible in the public schema api <nl> - allow users of pulsar-client-api to use keyvalueschema <nl> - move keyvalueschema implementation to keyvalueschemaimpl <nl> - introduce a new interface keyvalueschema <para-sep> this interface models a schema that is composed of two parts . a key and a value . <nl> get the schema of the key . <nl> get the schema of the value . <nl> get the keyvalueencodingtype . <nl> [ key , value ] pair schema definition <nl> schemainfo combined by keyschemainfo and valueschemainfo : [ keyinfo.length ] [ valueinfo.length ] <nl> key value schema using passed in schema type , support json and avro currently . <nl> avro <nl> if either key schema or value schema requires fetching schema info , we do n't need to configure the key/value schema info right now . defer configuring the key/value schema info until is called . <nl> encode as bytes : [ key.length ] [ key.bytes ] [ value.length ] [ value.bytes ] or [ value.bytes ] <nl> get the schema of the key . <nl> get the schema of the value . <nl> get the keyvalueencodingtype .",- allow users of pulsar-client-api to use keyvalueschema <nl> - move keyvalueschema implementation to keyvalueschemaimpl <nl> - introduce a new interface org.apache.pulsar.client.api.schema.keyvalueschema . <nl> the integration test file testgenericobjectsink has been changed to use the new api class .,1623309615,# # # motivation . <nl> there are so many classes in functions code that are called utils.java . <nl> this makes find methods different and development unwieldy . <nl> consolidate some utils classes and rename some classes as well .,0.9561161398887634
elastic_elasticsearch/73788,"rename bootstrap package in core jar . <nl> the org.elasticsearch.bootstrap package exists in server with classes <nl> for starting up elasticsearch . the elasticsearch-core jar has a handful <nl> of classes that were split out from there , namely java version parsing <nl> and jarhell . this commit moves those classes to a new <nl> org.elasticsearch.jdk package so as to not split the server owned <nl> bootstrap package . <para-sep> simple check for duplicate class files across the classpath . this class checks for incompatibilities in the following ways : checks that class files are not duplicated across jars . <nl> no instantiation * / <nl> simple driver class , can be used eg . from builds . returns non-zero on jar-hell * / <nl> checks the current classpath for duplicate classes <nl> parses the classpath into an array of urls <nl> parses the classpath into a set of urls . for testing . <nl> technically empty classpath element behaves like cwd . so below is the ' correct ' code , however in practice with es , this is usually just a misconfiguration , from old shell scripts left behind or something : if ( element.isempty ( ) ) { element = system.getproperty ( ' user.dir ' ) ; } instead we just throw an exception , and keep it clean . <nl> we should be able to just paths.get ( ) each element , but unfortunately this is not the whole story on how classpath parsing works : if you want to know , start at sun.misc.launcher , be sure to stop before you tear out your eyes . we just handle the ' alternative ' filename specification which java seems to allow , explicitly , right here ... <nl> ' correct ' the entry to become a normal entry change to correct file separators <nl> if there is a drive letter , nuke the leading separator <nl> now just parse as ordinary file <nl> eclipse adds this to the classpath when running unit tests ... <nl> junit4.childvm.count <nl> should not happen , as we use the filesystem api <nl> checks the set of urls for duplicate classes <nl> we do n't try to be sneaky and use deprecated/internal/not portable stuff like sun.boot.class.path , and with jigsaw we do n't yet have a way to get a ' list ' at all . so just exclude any elements","the org.elasticsearch.bootstrap package exists in server with classes <nl> for starting up elasticsearch . the elasticsearch-core jar has a handful <nl> of classes that were split out from there , namely java version parsing <nl> and jarhell . this commit moves those classes to a new <nl> org.elasticsearch.jdk package so as to not split the server owned <nl> bootstrap package .",1622835222,there are a few tiny packages that seem like they might be out of place . this pr moves their contents around so that they vanish .,0.8647573590278625
apache_kafka/10880,"; flush in progress not cleared after transaction completion <para-sep> initially , the transaction is still in progress , so we should respect the linger . <nl> once the transaction begins completion , then the batch should be drained immediately . <nl> begin a transaction and successfully add one partition to it . <nl> send a couple records and assert that they are not sent immediately ( due to linger ) . <nl> now begin the commit and assert that the produce request is sent immediately without waiting for the linger . <nl> respond to the produce request and wait for the endtxn request to be sent . <nl> respond to the expected endtxn request . <nl> finally , we want to assert that the linger time is still effective when the new transaction begins . <nl> begin a transaction and successfully add one partition to it . <nl> send one produce request . <nl> enqueue another record and then commit the transaction . we expect the unsent record to get sent before the transaction can be completed . <nl> now respond to the pending produce requests . <nl> finally , respond to the expected endtxn request .","we had been using in order to force the to flush pending batches when a transaction was being completed . internally , has a simple counter for the number of flushes in progress . the count gets incremented in and it is expected to be decremented by . the second call to decrement the counter never happened in the transactional path , so the counter could get stuck at a positive value , which means that the linger time would effectively be ignored . <nl> the patch here fixes the problem by removing the use of in . instead ,",1623690309,"this change adds a check to the kafkaconfigbackingstore , kafkaoffsetbackingstore , and kafkastatusbackingstore to use the admin client to verify that the internal topics are compacted and do not use the cleanup policy . <nl> connect already will create the internal topics with if the topics do not yet exist when the connect workers are started ; the new topics are created always as compacted , overwriting any user-specified . however , if the topics already exist the worker did not previously verify the internal topics were compacted , such as when a user manually creates the internal topics before",0.9690475463867188
ballerina-platform_ballerina-lang/30850,fix build from outside of project with mvn dependency,this pr fixes this issue . <nl> ballerina.toml . <nl> error . <nl> fixes # .,1622208609,- handle http connector not available case <nl> - use the correct send method from httpclientconnector,0.8557879328727722
apache_shardingsphere/10363,fix projection owner check when exist subquery temporary table,changes proposed in this pull request : <nl> - remove exception check in tablescontext # findtablenamefromsql method <nl> - support subquery temporary table when init projectionscontext,1621241872,changes proposed in this pull request : <nl> - fix shadow value in literal expression,0.9326117634773254
apache_beam/14923,"add timeout and waitforready support in java grpc calls . <nl> 0. add jobservertimeout option that defaults to 60s to all job server requests ( with exception to the ones that are expected to last long or hang ) to be on par with python <nl> 0. add waitforready for externalenvironment <para-sep> run the job and wait for a result , we do n't set a timeout here because it may take a long time for a job to complete and streaming jobs never return a response .",0. add jobservertimeout option that defaults to 60s to all job server requests ( with exception to the ones that are expected to last long or hang ) to be on par with python <nl> 0. add waitforready for externalenvironment .,1622591253,with version we are able to write genericrecords to bigquery,0.9255383014678955
runelite_runelite/13692,double stamina potion energy restore when equipping charged ring of endurance,basically duplicating the logic for prayer potions which checks for ring of gods and swapping the ring .,1622816170,before : . <nl> after : .,0.9139562845230103
vespa-engine_vespa/17614,"never throttle failing of children on failed hosts <cm-sep> less docker <para-sep> allow failing any node within policy <nl> always allow failing a minimum number of hosts always allow failing children of a failed host <nl> add ready node two ready hosts and a ready node die , but only 0 of those are failed out","i think this can only happen when manually failing host , but it 's right action <nl> in any case .",1619513585,"no longer return empty response with content-type , instead use ( only used by 0 endspoints ) . <nl> return better json responses for restart and deactivate application . <nl> in access logs i only found a few s , few requests from browsers and 0 % from , all of which should handle this change . ( current will return a for restart/deactivate , so that will be a json string , we can change that to just extract the message field later .",0.9024673104286194
OpenAPITools_openapi-generator/8538,use version spec for testing <cm-sep> add new files <para-sep> 0 | successful operation | - | 0 | successful operation | - | 0 | successful operation | - | 0 | successful operation | - |,- migrate samples to use oas v3 .,1611628780,- fix npe for null string <nl> - improve travis config file,0.7447711229324341
apache_pulsar/10541,add jetty-alpn-conscrypt-server jar <cm-sep> enable conscrypt / openssl provider if it is available <cm-sep> use conscrypt version <cm-sep> set default hostname verifier for conscrypt <cm-sep> move tlshostnameverifier for pulsar-client to pulsar-common <cm-sep> use pulsar 's tlshostnameverifier with conscrypt <cm-sep> add conscrypt.version property for managing conscrypt version in pom.xml <cm-sep> update license file <cm-sep> add comments about hostnameverifier in conscrypt <para-sep> conscrypt -- org.conscrypt-conscrypt-openjdk-.version.jar <nl> domain types differentiated by mozilla public suffix list . <nl> from apache http client <nl> a collection of utilities relating to inetaddresses . <nl> the above pattern is not totally rigorous as it allows for more than 0 hex fields in total <nl> must not have more than 0 colons ( i.e . 0 fields ) <nl> checks whether the parameter is a valid ipv4 address <nl> checks whether the parameter is a valid standard ( non-compressed ) ipv6 address <nl> checks whether the parameter is a valid compressed ipv6 address <nl> checks whether the parameter is a valid ipv6 address ( including compressed ) . <nl> from apache http client <nl> from apache http client <nl> public suffix is a set of dns names or wildcards concatenated with dots . it represents the part of a domain name which is not under the control of the individual registrant an up-to-date list of suffixes can be obtained from publicsuffix.org,* load conscrypt if it 's available on the classpath <nl> * use the conscrypt security provider when it 's available . use it for non-netty tls configurations created with securityutils or keystoresslcontext class . <nl> * move the pulsar specific hostnameverifier part of pulsar client from pulsar-client module to pulsar-common module so that it can be used with conscrypt . <nl> * configure conscrypt to use tlshostnameverifier . <nl> * configure conscrypt 's default hostname verifier to use pulsar 's tlshostnameverifier which is more relaxed than the conscrypt hostnameverifier checking for rfc 0 conformity . <nl> * certificates used,1620757788,"recently , multiple times we have seen that for a specific topic , all repl clusters reached to backlog quota in below scenario . <nl> 0. initially client had non-partitioned topic in one of the colo ( eg : topic1 ) and then client had made it partitioned-topic with partition 0 . <nl> 0. now when broker tires to load bundle it tries to load non-partition topic ( topic1 ) which starts replication-producer which internally creates producer on partitioned-topic ( topic1- and topic1- ) because topic has been converted to partitioned-topic in global-zk . <nl> 0. now , when broker",0.9402368068695068
elastic_elasticsearch/74181,[ rest api compatibility ] typed indexing stats . <nl> the per type indexing stats is simplified and when _types is requested <nl> it will return total stats for the index repeated under types/_doc/ . <para-sep> translog settings removal is not supported under compatible api <nl> overrides for indices.stats todo fix to remove the below match,the per type indexing stats is simplified and when _types is requested <nl> it will return total stats for the index repeated under types/_doc/ .,1623848089,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.939678966999054
apache_shardingsphere/10747,fix index validate and show logic <cm-sep> fix checkstyle <para-sep> index meta data utility class . <nl> get logic index name . <nl> get actual index name .,changes proposed in this pull request : <nl> - fix npe in when logic index not exist <nl> - fix wrong result of show create table index info <nl> - optimize drop index post validate logic when statement include table,1623304706,changes proposed in this pull request : <nl> - persist schemanames for getchildren . <nl> - upgrade spring-boot version . <nl> - fix server.yaml orchestration content .,0.9653872847557068
apache_pulsar/10441,using objectmapper to parse sink config <nl> fixed minor issue in closing some of the pulsarclientimpl resources <cm-sep> using objectmapper to parse source config,data types should be preserved after deserializing the sink/source config . <nl> using objectmapper instead of gson to parse the config . <nl> this change added tests and can be verified as follows : . <nl> ( example : ) <nl> - added unit tests . <nl> - the schema : do n't know,1619704982,if client acks with invalid message-id ( message-id > ledger.lastconfirmedentry ) then broker does n't do validation and it tries to process it which can corrupt the state of cursor . <nl> eg : if is invalid then ledger.getnextvalidposition ( ) returns null and broker stores . <nl> and it creates below exception : . <nl> validate mark-delete position before processing it . <nl> prevents any state corruption at cursor .,0.9018191695213318
vespa-engine_vespa/17448,update modelinfo from opsdbinfoupdater <cm-sep> newline <para-sep> ensures that the host information for all hosts is up to date . <nl> note : only supports switchhostname and modelname,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618488816,we need to be able to override the applications override of the system level override of the system majorversion on the application level .,0.9651697874069214
apache_pulsar/10883,use objectmapper for sink config <cm-sep> use objectmapper to parse sink & source config,"cmdsink and cmdsource uses to parse the json configs from pulsar-admin . but most of connectors are using objectmapper to serde the config into actual class . will also convert int/long value into float by default , which will lead objectmapper can not parse float string into int/long correctlly . <nl> use objectmapper to parse sink/source config .",1623299886,"peekmessage admin command gets ' n'th entry from the mark delete position . <nl> if the message is a batch message it does n't unbatch which results in garbage data being seen on the screen . <nl> also fixed another bug in display , properties were shown as . <nl> instead of . <nl> due to this line . <nl> on the broker side , we send a new header which will indicate whether the message is batched or not . <nl> on the admin client side , we unbatch the message and display individual messages separately along with it",0.9299171566963196
apache_incubator-pinot/6847,"convert concatcollector implmentation from memory-based to off-heap <para-sep> a collector implementation for collecting and concatenating all incoming rows . <nl> todo : avoid using bufferedoutputstream , and use bytebuffer directly . however , bytebuffer has a limitation that the size can not exceed 2g . hence , would need to implement a hybrid approach or a trigger a flush when size exceeds on collector . <nl> serialize the given genericrow . the data is stored in native byte order . <nl> deserializes bytes from the native order data buffer to genericrow",pending : this pr only changes concatcollector . will update rollupcollector in a following pr .,1619488615,support predicate for equal/not equ/in/not in/ range,0.9814729690551758
apache_incubator-pinot/6176,"merge common apis for dictionary <para-sep> note : for new added columns during the ingestion , this will be constant value dictionary instead of mutable dictionary . <nl> base implementation of immutable dictionary . <nl> this method should not be called for sorted dictionary . <nl> this method is for the stats collection phase when sealing the consuming segment , so it is not required for regular immutable dictionary within the immutable segment . <nl> returns the number of values in the dictionary . the value does not exist . this method is for the cross-type predicate evaluation . returns the insertion index of the string representation of the value in the dictionary . all sorted dictionaries should support this method . this method is for the range predicate evaluation . <nl> returns a set of dictids in the given value range , where lower/upper bound can be ' * ' which indicates unbounded range . all unsorted dictionaries should support this method . this method is for the range predicate evaluation . <nl> returns the comparison result of the values ( actual value instead of string representation of the value ) for the given dictionary ids , i.e . <nl> returns the minimum value in the dictionary . undefined if the dictionary is empty . <nl> returns the maximum value in the dictionary . undefined if the dictionary is empty . <nl> returns an sorted array of all values in the dictionary . this method is for the stats collection phase when sealing the consuming segment . <nl> note : should be overridden for string and bytes dictionary . <nl> interface for mutable dictionary ( for consuming segment ) . <nl> indexes a single-value entry ( a value of the dictionary type ) into the dictionary , and returns the dictid of the value . <nl> indexes a multi-value entry ( an array of values of the dictionary type ) into the dictionary , and returns an array of dictids for each value . <nl> this method should not be called for unsorted dictionary .","in order to use them , we need to cast the dictionary first , which is hard to manage and can potentially cause casting error . <nl> e.g . <nl> we should move the common read apis to the root interface to avoid the casting , and let all types of dictionary support these apis . <nl> merge the following common apis from and to : <nl> - <nl> - <nl> - <nl> - <nl> - <nl> -",1603393818,"this pull request introduces clients.yml file , to define configs for all clients we will use in thirdeye . the client to use will be defined in the individual thirdeye requests . <nl> currently , all requests are going to the default pinot client .",0.9782193303108215
Alluxio_alluxio/12891,add the metrics for embedded journal snapshot <para-sep> the last index of the latest journal snapshot created by this master or downloaded from other masters,add metrics for better understanding the embedded journal snapshot behaviors,1613774735,adding metrics for backup and restore from backup to track number of entries and time taken for backup .,0.9362214803695679
apache_flink/16011,remove unused field from operatorchain <cm-sep> remove volatile from the idle flag in streamsourcecontexts,"this pr removes unnecessary volatile modifier from the idle flag . the flag is always accessed under the checkpoint lock . this fixes the performance regression . <nl> all the tests still pass . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes",1622115741,"- dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos , zookeeper : ( yes / no / do",0.8805830478668213
elastic_elasticsearch/74459,this change ensures that we validate point in times provided by individual search <nl> requests in _msearch .,this change ensures that we validate point in times provided by individual search <nl> requests in _msearch .,1624413768,this change ensures that we validate point in times provided by individual search requests in _msearch .,1.0000001192092896
ballerina-platform_ballerina-lang/29681,fix issue with field visibility in object inclusion <cm-sep> add tests <para-sep> foo : employee3 ; <nl> foo : employee3 ; <nl> foo : employee4 ; <nl> foo : employee5 ; <nl> type ; <nl> obj0 ; <nl> class ; <nl> class2 ; <nl> class4 ;,"public type type object { <nl> public int [ ] vals ; <nl> } ; . <nl> public class class { <nl> * type ; <nl> int [ ] vals = [ ] ; // no qualifier , compilation error <nl> } .",1617011102,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9434338212013245
confluentinc_ksql/7580,backport various cve bumps to version,unit and integration tests are expected for any behavior changes._ .,1621898887,added test to ensure the latest version of ksqldb gives a meaningful error message if an unknown function is called with a non-aggregate select expression . previous versions failed with somewhat confusing error e.g . <nl> now fails with : . <nl> also added test covering non-table udafs being used on a table source . <nl> test only change .,0.8699610829353333
runelite_runelite/13625,add option to screenshot plugin for new collection log entries,takes a screenshot when the new collection log entry appears . <nl> ( e.g . ),1621732883,uses ingame drop notifier to set the loot value and whether to include untradeables . <nl> triggers on chat message . <nl> tested on the following strings . will not work if there 's an item that contains ' in their name . <nl> ` public static void main ( string [ ] args ) { <nl> testpattern ( ' valuable drop : 0 x bronze arrow ( 0 coins ) ' ) ; <nl> testpattern ( ' valuable drop : 0 x ranging potion ( 0 ) ( 0 coins ) ' ) ; <nl> testpattern ( ' untradeable,0.9211280345916748
apache_kafka/10504,"add new allocateproducerids rpc and support for zk-mode <cm-sep> fix apikeystest throttling test <cm-sep> actually use throttling in kafkaapis for allocateproducerids rpc <para-sep> introduce allocateproducerids ( ) <nl> handle a few short-circuits <nl> producerids are managed by the controller . when requesting a new range of ids , we are guaranteed to receive a unique block . <nl> once we reach this percentage of pids consumed from the current block , trigger a fetch of the next block <nl> creates a produceridgenerate that directly interfaces with zookeeper , ibp < version-iv0 <nl> creates a produceridgenerate that uses allocateproducerids rpc , ibp > = version-iv0 <nl> get or create the existing pid block from zk and attempt to update it . we retry in a loop here since other brokers may be generating pid blocks during a rolling upgrade <nl> grab the first block of producerids <nl> send an initial request to get the first block <nl> check if we need to fetch the next block <nl> if we 've exhausted the current block , grab the next block ( waiting if necessary ) <nl> do some sanity checks on the response <nl> create producer ids manager * / <nl> this should never happen : the written data has exceeded long type limit <nl> request enough pids from each broker to ensure each broker generates two pid blocks <nl> mutable test implementation that lets us easily set the idstart and error <nl> holds a range of producer ids used for transactional and eos producers . the start and end of the id block are inclusive .","this change adds a new allocateproducerids rpc which is used by the broker to ask for a block of producer ids from the controller . in particular , this pr only includes changes for the broker and zookeeper-based controller . <nl> in produceridmanager.scala , i 've added a prefetch to avoid the case of an initproducerid request being blocked waiting on an allocateproducerids request . once the generated producer id has reached 0 % of the current block , the next block is fetched and stored locally until it is needed . this could lead to blocks being needlessly consumed",1617904950,"summary of changes : . <nl> currently , in sslfactory.java , when the keystore is created null ( caused by passing an empty config value to ssl.keystore.location ) , the default sun keymanager is used ignoring the 'ssl.keymanager.algorithm ' provided . <nl> i included changes to fetch keymanager from the keymanagerfactory based on the provided keymanager algorithm , populated by 'ssl.keymanager.algorithm ' if the keystore is found empty",0.9730507731437683
apache_incubator-pinot/6402,add support for stream partition offsets <para-sep> todo : iterate upon all the shardids in the map,"currently , kinesis integration is not working as expected due to streampartition offsets being long . the pr aims to fix this issue by implementing checkpoints in kinesis as offsets .",1609772633,implement the query method in anomalyfuncitondao for future application summary and evaluation .,0.9534091949462891
apache_druid/11188,"sql timeseries no longer skip empty buckets with all granularity <para-sep> ca n't vectorize due to substring expression . <nl> timeseries with all granularity have a single group , so should return default results for given aggregators <nl> uppercase <nl> lowercase ; also , filtered <nl> on extractionfn <nl> on expression <nl> on native theta sketch column <nl> on native theta sketch column <nl> makes empty bloom filters <nl> makes empty bloom filters <nl> an aggregation query should return one row per group , with no grouping ( e.g . all granularity ) , the entire table is the group , so we should not skip empty buckets . when there are no results , this means we return the initialized state for given aggregators instead of nothing . <nl> timeseries with all granularity have a single group , so should return default results for given aggregators which for count is 0 and sum is null in sql compatible mode or version in default mode . <nl> this behavior was not always correct , so make sure legacy behavior can be retained by skipping empty buckets explicitly in the context which causes these timeseries queries to return no results <nl> timeseries with a granularity is grouping by the time expression , so matching nothing returns no results <nl> timeseries with all granularity have a single group , so should return default results for given aggregators <nl> timeseries with all granularity have a single group , so should return default results for given aggregators","in sql when running a query with only aggregators , such as , then the aggregation is done as if there is a single universal grouping key , and so this example query should return something even if there are no values which match , and should produce in this case . <nl> we plan queries like this example into a druid native timeseries query , and prior to this patch would always set query context parameter to 'true ' , because a timeseries query with a granularity other than 'all ' is equivalent to grouping by a time floor",1619999638,"fixes # tbd . ( need to open an issue about an issue that occur in kinesis ingestion in streams with a large number of shards ) . <nl> prior to this patch , the main run thread , http threads , and background threads of the would all fight over the with conflicting assignments , despite the fact that all usages are for the same set of partitions it has assigned to the tasks it is monitoring . this was extra unchill to the kinesis supervisor , which these assignments and subsequent seeks would result in creating and destroying",0.9663328528404236
apache_shardingsphere/10540,optimize drop table & drop index post validate logic <para-sep> judge whether route unit and data node are different size or not . <nl> judge whether contains not exist clause or not . <nl> judge whether contains exist clause or not . <nl> judge whether contains exist clause or not .,changes proposed in this pull request : <nl> - optimize drop table & drop index post validate logic <nl> - refactor pg antlr rule,1622265404,changes proposed in this pull request : <nl> - add config/datasource package <nl> - optimize datasourceconfiguration <nl> - optimize datasourcefactory <nl> - rename variable configuration to config,0.961763322353363
apache_kafka/10620,": kafkaproducer.flush holds onto completed producerbatch ( s ) until flush completes . <nl> when flush is called a copy of incomplete batches is made . this <nl> means that the full producerbatch ( s ) are held in memory until the flush <nl> has completed . for batches where the existing memory pool is used this <nl> is not as wasteful as the memory will be returned to the pool , <nl> but for non pool memory it can only be gc 'd after the flush has <nl> completed . rather than use copyall we can make a new array with only the <nl> producefuture ( s ) and await on those . <para-sep> obtain a copy of all of the incomplete producerequestresult ( s ) at the time of the flush . we must be careful not to hold a reference to the producebatch ( s ) so that garbage collection can occur on the contents . the sender will remove producerbatch ( s ) from the original incomplete collection .","when flush is called a copy of incomplete batches is made . this <nl> means that the full producerbatch ( s ) are held in memory until the flush <nl> has completed . for batches where the existing memory pool is used this <nl> is not as wasteful as the memory will be returned to the pool , <nl> but for non pool memory it can only be gc 'd after the flush has <nl> completed . rather than use copyall we can make a new array with only the <nl> producefuture ( s ) and await on those .",1619792617,"many patch and minor updates . <nl> scalatest and jetty deprecated classes that we <nl> use . i removed usages for the former and filed for the latter ( i <nl> suppressed the relevant deprecation warnings until the jira is fixed ) . as <nl> part of the scalatest fixes , i also removed since it duplicates <nl> . <nl> i also fixed a few compiler warnings that have crept in since my last sweep .",0.8637760281562805
OpenAPITools_openapi-generator/9169,this reverts commit sha <cm-sep> this reverts commit sha <cm-sep> add response body to exception message,concatenate the response body to the exception message in case of unsuccessful response .,1617546587,' /group1/subgroup1/op1 ' - > ' /group1/subgroup1 ' is moved to class level annotation .,0.9378900527954102
apache_pulsar/10057,"implement schema # object prototype <cm-sep> reduce code duplication <cm-sep> cleanup <cm-sep> fix imports <cm-sep> add primitiverecord in order to support primitive types in schema.auto_consume <cm-sep> implement pulsarobject <cm-sep> implement pulsarobject <para-sep> use genericrecord even for primitive types it will be a primitiverecord <nl> use genericrecord even for primitive types it will be a primitiverecord <nl> this is an abstraction over the logical value that is store into a message . pulsar decodes the payload of the message using the schema that is configured for the topic . <nl> return the schema tyoe . <nl> return the internal native representation of the object , like a avro genericrecord , a string or a byte [ ] . <nl> auto detect schema , returns only genericrecord instances . <nl> schemaless topic <nl> schemainfo null means that there is no schema attached to the topic . <nl> implementation of genericrecord that wraps objects of non struct types .","contents : <nl> - introduce new high level interface genericobject , that represents every logical value on the pulsar topic <nl> - allow autoconsumeschema to deal with every schema type <nl> - handle schema less topics with autoconsumeschema ( return bytes schema and byte [ ] payload ) <nl> - rename to . <nl> how it works : <nl> - in case of non struct schema , like for primitives and for keyvalue , wrap the result into a primitiverecord class , that is an implementation of genericrecord that wraps a object and a schematype , it returns an empty",1616851338,org.apache.pulsar.admin.cli.pulsaradmintooltest # topics <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivetopicapi <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testtopiclevelinactivepolicyupdateandclean <nl> org.apache.pulsar.broker.service.inactivetopicdeletetest # testdeletewhennosubscriptionswithtopiclevelpolicies,0.9792032241821289
quarkusio_quarkus/18090,"reactive sql guide : document placeholders . <nl> reactive sql clients use different placeholders for prepared queries . <nl> now the database clients details section shows the differences . <nl> ( cherry picked from commit sha ) <cm-sep> flyway devmode : confirm before cleaning the schema . <nl> ( cherry picked from commit sha ) <cm-sep> liquibase devmode : prompt before cleaning the schema . <nl> ( cherry picked from commit sha ) <cm-sep> extension registry transfer listener . <nl> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> upgrade to hibernate orm version.final . <nl> ( cherry picked from commit sha ) <cm-sep> disable availablesettings.hbm2ddl_scripts_create_append . <nl> ( cherry picked from commit sha ) <cm-sep> validate option for hibernate database generation . <nl> in the hibernate-orm guide , is not shown as a valid value for the property . <nl> ( cherry picked from commit sha ) <cm-sep> h2 devservices should not attempt to stop a stopped server . <nl> ( cherry picked from commit sha ) <para-sep> test first , to not make too much noise if the server is dead already ( perhaps we failed to start ? ) <nl> make sure the db is removed on close <nl> never append on existing scripts : <nl> accepted values : , , , , , . accepted values : , , , , , .","please do n't merge , i will merge it myself .",1624397258,provide a welcome page ( static asset ) to avoid the ' forbidden ' message .,0.9258988499641418
neo4j_neo4j/11598,fix error message with wrong type in point function . <nl> refactor code shared between batchimported and cypher for point <nl> function to have less code duplication .,includes 0 fixes : <nl> * correct error message when a value in the map passed to the point function has the wrong type . <nl> * allow,1524064286,"refactor so that an expression knows about its type . this makes it possible to remove explicitly typed methods for addition , subtraction , multiplication and comparison operators which makes for a nicer api .",0.9466065168380737
apache_beam/13751,"support date , time , datetime in pubsub <para-sep> extracts localdate from the jsonnode ( iso 0 format string ) if it is valid . <nl> extracts localtime from the jsonnode ( iso 0 format string ) if it is valid . <nl> extracts localdatetime from the jsonnode ( iso 0 format string ) if it is valid .","see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1610606155,"adds a to so that actually runs . since this test has n't been running it has a few issues , which i 've also attempted to resolve here . a summary of the changes to that end : <nl> - when testing a sub-class use the components list as the expected components , rather than the usual arguments list . <nl> - add to list of dataflow known coders . <nl> - now only validates that dataflow known coders do n't have a rather than _all_ model coders . <nl> - add equals and hashcode for schemacoder and rowcoder",0.9359268546104431
hazelcast_hazelcast/18972,"remove jetbuildinfo . <nl> after the merge , it seems that the jetbuildinfo does not carry useful <nl> information and can be removed . <nl> there are two problematic places , where we were using the jetbuildinfo : . <nl> - in , we were sending the jet version to mc , <nl> if it exists <nl> - in , we were sending the jet version to the phone home server , <nl> if it exists . <nl> now , in both of these cases , we were behaving as if there were no jetbuildinfo <nl> in the first place . if it is okay to break things , we might do further cleanups .","after the merge , it seems that the jetbuildinfo does not carry useful <nl> information and can be removed . <nl> there are two problematic places , where we were using the jetbuildinfo : . <nl> - in , we were sending the jet version to mc , <nl> if it exists <nl> - in , we were sending the jet version to the phone home server , <nl> if it exists . <nl> now , in both of these cases , we were behaving as if there were no jetbuildinfo <nl> in the first place . if it is",1624518762,this reverts commit sha . <nl> an alternate or augmented solution must be considered .,0.9691798686981201
confluentinc_ksql/7410,fix topologytestdrivercontainer to use new ttd methods,unit and integration tests are expected for any behavior changes._ .,1618951651,finally bit the bullet to fix the internals of this class . <nl> type is heavily tested through current qtt tests .,0.9513986110687256
Graylog2_graylog2-server/10094,"creating integration test for . <cm-sep> correcting json path , adding safeguard if not present .","prior to this change , the implementation for es7 was using the same json path as in es6 , although the structure of the response has changed . this , in combination with an overly relaxed parsing of the response lead to the method always returning 0 . <nl> the consequence of this is that any configured count-based rotation policy was never triggered , due to the threshold never being crossed . <nl> this pr is adding a test for the method , fixes the json path and makes sure that if the node is not found , it will",1613662784,this pr makes some improvements around how we handle the field type refresh interval for index sets : .,0.8983769416809082
elastic_elasticsearch/74222,[ rest api compatibility ] type metadata for docs used in simulate request . <nl> this commit allows to provide _type field on document ingested in <nl> simulate pipeline requests .,this commit allows to provide _type field on document ingested in <nl> simulate pipeline requests .,1623919487,"when a data stream is deleted , also deletes all its backing indices .",0.9534804821014404
elastic_elasticsearch/74083,fix literal projections of es index with filter <cm-sep> sql spec <cm-sep> merge master into fix/literalprojectionwithcondition <cm-sep> fix imports <cm-sep> fix all imports <cm-sep> replace asserts <cm-sep> fmt <para-sep> exclude localrelations that have been introduced by earlier optimizations ( skipped esrelations ) <nl> skipqueryiffoldingprojection <nl> select true as a <nl> select true as a from table where col is null,"queries with a literal selection and a filter like are currently erroneously optimised to use a local relation . this causes es to always return a single record , no matter how many records match the filter condition . <nl> this pr makes sure that only skips the query if it 's an aggregate with only constants ( e.g . ) . <nl> besides this the ' skip query ' optimization , the class also folds constants from s and pushes the evaluated values into a new ( e.g . for queries like ) .",1623685343,"this rewrites two tests for aggregations to use 's <nl> simpler way of making s , allowing us to remove a ctor on <nl> that we were n't happy about . now there is <nl> only a single test call to and we can <nl> remove that soon .",0.9363569021224976
jenkinsci_jenkins/5461,"redirect to previous page after login <para-sep> try to obtain a return point from the query parameter <nl> abstractauthenticationtargeturlrequesthandler expects no context part as path of the redirect url , so remove it . <nl> ensure we only redirect to local urls <nl> could be simplified to if we 're willing to edit loginlink.jelly <nl> could be simplified to if we 're willing to edit loginlink.jelly <nl> we do n't really care where this ends up as long as it does n't leave the host todo do we need to ensure we remain in the context path ?",* jenkins redirects users to the previous page after login even if they were able to view it while not logged in . ( regression in version ),1620205507,"* added a warning when cron trigger spent more than a threshold ( 30s ) in its execution . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9587785005569458
apache_druid/11338,bump commons-io from version to version . <nl> bumps commons-io from version to version .,"bumps commons-io from version to version . <nl> dependabot will resolve any conflicts with this pr as long as you do n't alter it yourself . you can also trigger a rebase manually by commenting . <nl> [ // ] : # ( dependabot-automerge-start ) <nl> [ // ] : # ( dependabot-automerge-end ) . <nl> dependabot commands and options . <nl> you can trigger dependabot actions by commenting on this pr : <nl> - will rebase this pr <nl> - will recreate this pr , overwriting any edits that have been made to it <nl> - will merge this",1623099458,"however , relevant documentation has not been updated ( as a matter of fact it also has not been updated when upgrading from to ) . this patch fixes it . <nl> also , in sha i am suggesting to remove from example config files . please read my commit message for more detailed argumentation .",1.0
hazelcast_hazelcast/18757,restore ee behaviour modified by networking changes,the recent fixes done to solve reconnection floods ( pr 0 ) broke behavior related to ssl functionality in ee . this pr attempt to restore that functionality .,1621860667,"seems failure reason is jitter ( for instance even logging took around 0 seconds ) , due to that , loading was not finished in expected time interval . with this pr , i increase the timeouts .",0.842334508895874
apache_incubator-pinot/6322,"api to get status of consuming segments of a table across all servers <cm-sep> treemap for getting order <para-sep> information regarding the consumer of a segment <nl> returns a set of consuming segments for the given realtime table . <nl> this is a helper class that calls the server api endpoints to fetch consuming segments info only the servers returning success are returned by the method . for servers returning errors ( http error or otherwise ) , no entry is created in the return list <nl> this method retrieves the consuming segments info for a given realtime table . <nl> gets info for segments with llrealtimesegmentdatamanager found in the table data manager <nl> segments which are in consuming state but found no consumer on the server <nl> this method makes a multiget call to all servers to get the consuming segments info . <nl> map containing all consuming segments and their status information <nl> contains all the information about a consuming segment <nl> server0 - 0 consumer each for p0 and p1 . consuming . <nl> server1 - 0 consumer each for p0 and p1 . consuming . <nl> server2 - p1 consumer consuming . p0 consumer not_consuming <nl> server3 - 0 consumer for p1 . no consumer for p0 <nl> server4 - unreachable/error/timeout <nl> server to return fake consuming segment info <nl> 0 servers , 0 partitions , 0 replicas , all consuming <nl> 0 servers , 0 partitions , 0 replicas . p0 consumer in not_consuming <nl> 0 servers , 0 partitions , 0 replicas . no consumer for p0 . consuming state in idealstate . <nl> 0 servers , 0 partitions , 0 replicas . no consumer for p0 . offline state in idealstate . <nl> 0 servers , 0 partitions , 0 replicas . server4 times out . <nl> the state of the consumer of this segment <nl> get the current offsets for all partitions of this consumer <nl> get the state of the consumer","this includes 0. consumer status 0. partition to offsets map 0. server name , for consuming segments across all servers . <nl> api on the controller calls the servers to get consumer info . it returns a map of segment name to consumption information for all servers . <nl> api on the server returns status for all consumers found in the tabledatamanager . <nl> some manual testing : <nl> 0. segment build failed . consumer went into error state . but is , ev and segment metadata looks all good . <nl> 0. exception in offline to consuming state transition",1607124782,"if we want to reduce the number of replicas for an offline table , then <nl> running helix autorebalancestragy to recompute partitions does not work . <nl> it does work if we want to increase number of replicas . <nl> added a separate utility command to reduce the number of replicas . <nl> also fixed the rebalancer to account for idealstate changes during the time <nl> th command is run .",0.981020450592041
apache_ignite/9131,fix ducktape jmx_tools mbean pattern <cm-sep> rewrite test to use sql,internal api used in test are different now . <nl> it 's better to replace internal api usage to thin client ( official documentation way ) .,1622046244,added ability to create dynamic caches for thin clients with expiry policies . <nl> - added expiry policy property to thin client cache configuration <nl> - added withexpirypolicy method to the client cache interface . <nl> ( cherry picked from commit sha ),0.7793688774108887
elastic_elasticsearch/74563,"this disables the filter-by-filter aggregation optimization used by <nl> , , , and aggregations unless <nl> we 're sure that its faster than the ' native ' implementation . mostly this <nl> is when the top level query is empty or we can merge it into the filter <nl> generated by the agg rewrite process . <nl> now that we have hard and fast rules we can drop the cost estimation <nl> framework without too much fear . so we remove it in this change . it <nl> stomps a bunch of complexity . sadly , without the cost estimation stuff <nl> we have to add a separate mechanism for blocking the optimization <nl> against runtime fields for which it 'd be kind of garbage . for that i <nl> added another rule preventing the filter-by-filter aggregation from <nl> running against the queries made by runtime fields . its not fool-proof , <nl> but we have control over what queries we pass as a filter so its not <nl> wide open . <nl> i spent a lot of time working on an alternative to this that preserved <nl> that fancy filter-by-filter collection mechanism and was much more kind <nl> to the query cache . it detected cases where going full filter-by-filter <nl> was bad and grouped those filters together to collect in one pass with a <nl> funny oring collector . it worked . and , if we were super concerned with <nl> the performance of the aggregation it 'd be the way to go . but <nl> it was very complex and it was actually slower than using the native <nl> aggregation for things like and . it was <nl> glorious . but it was wrong for us . too complex and optimized the wrong <nl> things . <nl> so here we are . hopefully this is a fairly simple solution to a sneaky <nl> problem . <para-sep> we know that runtime fields are n't fast to query at all but we expect all other sorts of queries are at least as fast as the native aggregator . <nl> for now any complex union kicks us out of filter by filter mode . its possible that this de-optimizes many ' filters ' aggregations but likely correct when ' range ' , ' date_histogram ' , or ' terms ' are converted to this agg . we investigated a sort","this disables the filter-by-filter aggregation optimization used by <nl> , , , and aggregations unless <nl> we 're sure that its faster than the ' native ' implementation . mostly this <nl> is when the top level query is empty or we can merge it into the filter <nl> generated by the agg rewrite process . <nl> now that we have hard and fast rules we can drop the cost estimation <nl> framework without too much fear . so we remove it in this change . it <nl> stomps a bunch of complexity . sadly , without the cost estimation",1624543215,the backport required modifications to handle the possibility of multiple mapping types .,0.9706408977508545
runelite_runelite/13746,"remove dead overlay menuops . <nl> menu options are never added on dynamic widgets since they do n't have <nl> bounding boxes <cm-sep> runelite-client : use menu entries for focusing world map points . <nl> the previous way had usability issues since it would cover up the close <nl> button , consumed clicks for no reason on any icon , making it difficult <nl> to pan around the map when zoomed out , and had no tooltips . <nl> it previously also accessed widgets on the edt , which is a threading <nl> issue .","the previous way had usability issues since it would cover up the close <nl> button , consumed clicks for no reason on any icon , making it difficult <nl> to pan around the map when zoomed out , and had no tooltips . <nl> it previously also accessed widgets on the edt , which is a threading <nl> issue .",1623865374,this allows players to select from a number of positions where they <nl> would like highlighted player 's names to be drawn relative to the <nl> player 's model .,0.9464634656906128
apache_druid/11010,"vector group by support for string expressions <para-sep> 0 : group by string expr with non-expr agg <nl> 0 : group by string expr with expr agg <nl> there must be at least one expression with a computable scalar output type for this method to return true . <nl> there must be at least one expression with a computable scalar output type for this method to return true . <nl> many strings enter , one string leaves ... <nl> in sql compatible mode , nulls are handled by super class and never make it here ... <nl> result of concatenation is null if any of the values is null . e.g . 'select concat ( null , ' abc ' ) as c ; ' will return null as per standard sql spec . <nl> expression virtual columns . <nl> group_by_missing_value is used to indicate empty rows , which are omitted from the result map . <nl> must be single valued","the key addition that makes this possible is , which is the vectorized group by engine version of , and allows the vector group by engine to group on strings which are not dictionary encoded . <nl> to help showcase this , i added vectorization support to the concat operator , and the concat function . <nl> it provides a pretty decent performance increase . from the added benchmark queries : . <nl> vectorizing additional string expressions i will save for a future pr",1616070282,this strategy can be enabled by setting to,0.9847385883331299
elastic_elasticsearch/74348,be stricter about which source paths we load values from,"contains a hack whereby we <nl> ignore extra 'dummy ' dotted path values appended to a source path - ie , <nl> loading data from will also load from . this was <nl> used to implement source loading for multifields , which do not have a name <nl> that corresponds to an existing path in source data . this was safe in general <nl> because you ca n't have a field that is a dot prefix of another field in index <nl> mappings . <nl> with runtime fields , however , this changes . you can define scriptless runtime <nl>",1624265507,"this adds a new flag for get transform api . <nl> this flag is useful for when a transform needs to be cloned within a cluster or exported/imported between clusters . <nl> it removes certain fields that are not able to be set via the put api ( e.g . version , create_time ) .",0.9445465207099915
confluentinc_ksql/7570,"add fk-join logical to physical plan translation <cm-sep> rebased and cleanup <cm-sep> github comment + checkstyle <cm-sep> updated specs for tableselectbuilder change <para-sep> primary key join detected <nl> after we lift this n-way join restriction , we should be able to support fk-joins at any level in the join tree , even after we add right-deep/bushy join tree support , because a fk-join output table has the same pk as its left input table <nl> we need to extend this to support expressions later on <nl> column names may be represented as","this rewrite is safe because the only functional change is that we are tracking a new serde ( or two ) in certain situations . all the other spec changes are byproducts of running the test rewriter , such as recording avro schemas in some tests where we previously were n't ( probably because the tests were from before we started doing this ) and the occasional reordering of topics which is inconsequential for test validity . <nl> note that the fk join functionality is still not complete with this pr . remaining tasks include : <nl> - updating qtt",1621626765,"breaking change : any column identified in the clause must be of the same sql type as . <nl> users can provide the name of a value column that matches the key column , e.g . <nl> before primitive keys was introduced all keys were treated as . with primitive keys can be types other than , e.g . <nl> it therefore follows that any column identified in the clause must have the same sql type as the _actual_ key , i.e . <nl> with this change the above example statement will fail with the error : . <nl> as",0.9765231609344482
apache_druid/10758,"retain order of and , or filter children . <nl> if we retain the order , it enables short-circuiting . people can put a <nl> more selective filter earlier in the list and lower the chance that <nl> later filters will need to be evaluated . <nl> this patch tries to solve that <nl> problem a different way . <nl> this patch moves filter simplification logic from ' optimize ' to <nl> ' tofilter ' , because that allows the code to be shared with filters.and <nl> and filters.or . the simplification has become more complicated and so <nl> it 's useful to share it . <nl> this patch also removes code from calcitecnfhelper that is no longer <nl> necessary because filters.and and filters.or are now doing the work . <para-sep> this method optimizes children , but does n't do any special and-related stuff like flattening or duplicate removal . that will happen in ' tofilter ' , which allows us to share code with filters.and ( ... ) . <nl> returns the child filters for this filter . this is a linkedhashset because we do n't want duplicates , but the order is also important in some cases ( such as when filters are provided in an order that encourages short-circuiting . ) <nl> this method optimizes children , but does n't do any special and-related stuff like flattening or duplicate removal . that will happen in ' tofilter ' , which allows us to share code with filters.or ( ... ) . <nl> create a filter representing an and relationship across a list of filters . deduplicates filters , flattens stacks , and removes literal ' false ' filters . <nl> original ' filters ' list must have been 0 % literally-true filters . <nl> and of false with anything is false . <nl> create a filter representing an or relationship across a list of filters . deduplicates filters , flattens stacks , and removes literal ' false ' filters . <nl> original ' filters ' list must have been 0 % literally-false filters . <nl> or of true with anything is true . <nl> flattens children of an and , removes duplicates , and removes literally-true filters . <nl> flattens children of an or , removes duplicates , and removes literally-false filters . <nl> result must receive an actual orfilter , so wrap if filters.or managed to","if we retain the order , it enables short-circuiting . people can put a <nl> more selective filter earlier in the list and lower the chance that <nl> later filters will need to be evaluated . <nl> this patch tries to solve that <nl> problem a different way . <nl> this patch moves filter simplification logic from ' optimize ' to <nl> ' tofilter ' , because that allows the code to be shared with filters.and <nl> and filters.or . the simplification has become more complicated and so <nl> it 's useful to share it . <nl> this patch also",1610587981,"this pr refactors sql planning to re-use expression virtual columns when possible when constructing a . additionally , filter expressions are now allowed to define and re-use virtual columns transitioning use of to a fallback or post-filter ( having ) use cases , and allowing virtual columns to be defined in filter expressions . <nl> before : . <nl> after : . <nl> check out the changes to 'expected ' native queries in changed tests in to see more of the effect that this patch has on the native druid queries that are generated by the planner . <nl> also",0.9780914187431335
elastic_elasticsearch/73880,this makes the forcemerge step inspect the response of the forcemerge <nl> operation and retry if there are any failed shards . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan <para-sep> let 's report it as a failure and retry,this makes the forcemerge step inspect the response of the forcemerge <nl> operation and retry if there are any failed shards . <nl> ( cherry picked from commit sha ) <nl> signed-off-by : andrei dan .,1623138346,"when merging component template , index template , and request mappings , we now treat any declaration <nl> of a top-level field the same as replacing all sub-objects . for example , assuming two component <nl> templates with mappings and template b taking precedence : .",0.9459490776062012
ballerina-platform_ballerina-lang/29002,"treat after operator mode as same as normal . <nl> after operator mode was treated differently causing brackets to not registering in the after operator mode . fix the logic to handle these cases . <para-sep> this will also handle normal state just after an operator . <nl> the whitespace characters are ignored . they simply act as no-op characters . <nl> change the transitioning state according to the current character . if current character is an operator , the next state would be after_operator . <nl> 0 0 0","in ballerina shell parser state machine , after_operator state was treated differently causing brackets to not registering in the after operator mode . <nl> here is not registered so cli does not wait for the rest of the input .",1614850514,with this pr following cases are invalid .,0.9340042471885681
Alluxio_alluxio/13154,"improve tiered storage related logging <para-sep> for <nl> convenient way to break on failure cases , no intention to loop <nl> free space is the entry for immediate block deletion in order to open up space for new or ongoing blocks . - new blocks creations will not try to free space until all tiers are out of space . - ongoing blocks could end up freeing space oftenly , when the file 's origin location is low on space . this method is synchronized in order to prevent race in its only client , allocations . if not synchronized , new allocations could steal space reserved by ongoing ones . removing synchronized requires implementing retries to this call along with an optimal locking strategy for fairness . todo ( ggezer ) : remove synchronized .","- add info logging for each storage dir on init , which will be very useful for debugging worker tiered storage <nl> - prevent duplicated error info in worker.log as seen in the following . the same error caused two logging messages , one in tiered block store and on in blockwritehandler . this is because previous code catches an exception from allocator , log it and returns null , then in its caller , based on null , another exception is created and thrown . this pr simply keep the original exception from allocator . <nl> - remove from",1617227319,clean up the previous rocksdb metastore instead of creating a new one at a different path each time . <nl> also fix a couple flaky tests,0.9521634578704834
grpc_grpc-java/7994,allow using testserviceclient for making traffic director rpcs,"internal issue b/0 for context . <nl> the need to configure channels without an explicit port has more context in b/0 ( and is the method currently used for c++ ) . <nl> the env var is needed to reach alternative instances of td for testing , and is supported by go and c++ .",1616171477,"changes in processing eds responses : <nl> - localities without weight or with weight of 0 are ignored ( as grpc always enables locality weighted load balancing ) . <nl> - validate priority continuity for localities in each cluster , should nack the response if priority values are skipping .",0.893161952495575
elastic_elasticsearch/73524,"change rest status code for taskcancelledexception to 0 <para-sep> tasks are typically cancelled at the request of the client , so a 4xx status code is more accurate than the default of 0 ( and means we do n't log every cancellation at warn level ) . there 's no perfect match for cancellation in the available status codes , but ( quoting rfc 0 ) 0 bad request ' indicates that the server can not or will not process the request due to something that is perceived to be a client error ' which is broad enough to be acceptable here .","currently when a rest action receives a , the response is translated to a http 0 error ( internal_server_error ) . this in turn gets logged as a warning in the elasticsearch logs . <nl> arguably , a task cancelation should not be consider a internal error as it is more normally related to something done by the client . there is no a good mapping between http errors and task cancellation but after discussing with david and armin , we think a 0 ( bad_request ) is a better code for such an error . <nl> this in turn",1622202486,right now you ca n't tell from the task description whether or not the <nl> search is a scroll . this adds that information to the description which <nl> is super useful if you are trying to debug a cluster that is running out <nl> of scroll contexts .,0.8664162158966064
apache_kafka/10220,"copy over files <cm-sep> get things compiling <para-sep> each instance of this class is provided with a configuration for the cluster . this context also provides parameter resolvers for : clusterconfig ( the same instance passed to the constructor ) clusterinstance ( includes methods to expose underlying socketserver-s ) integrationtesthelper ( helper methods ) <nl> copy properties into the testkit builder <nl> need to pass security protocol and listener name here <nl> this class manages a future which is completed with the proper value for controller.quorum.voters once the randomly assigned ports for all the controllers are known . <nl> note : we ca n't accurately set controller.quorum.voters yet , since we do n't yet know what ports each controller will pick . set it to a dummy string \ for now as a placeholder . <nl> just like above , we set a placeholder voter list here until we find out what ports the controllers picked . <nl> wait for a controller to mark all the brokers as ready ( registered and unfenced ) . <nl> we can choose any controller , not just the active controller . if we choose a standby controller , we will wait slightly longer . <nl> create a test topic <nl> list created topic <nl> delete topic <nl> list again <nl> create many topics <nl> list created topic <nl> create many topics <nl> list created topic","adds kafkaclustertestkit , an integration test framework for starting up kafka brokers and controllers in raft mode . <nl> also included here is the support for raft mode in the junit integration test extensions .",1614355914,* added pluginstest file which did not exist before <nl> * removed converter : :configure test case <nl> * removed headerconverter test plugin and test cases <nl> * removed converter types test cases <nl> * removed classloader control test cases .,0.9689019918441772
vespa-engine_vespa/17469,"cache nodes based on zknode version . <nl> reduces reads , avoids potential hash collisions and reduces evictions . <cm-sep> remove unused zone field <para-sep> returns the children of this path , which may be empty / returns the a copy of the content of this child - which may be empty / returns the stat data of given path * / <nl> deserializing a node from slime is expensive , and happens frequently . node instances that have already been deserialized are returned from this cache instead of being deserialized again . <nl> returns cache statistics for curator cache / returns cache statistics for the node cache /","reduces reads , avoids potential hash collisions and reduces evictions .",1618577822,this passes argument type information in rank properties when set . it does not use them for anything yet .,0.9674128890037537
ballerina-platform_ballerina-lang/29011,add array and map initialization data to bir . <nl> backport of sha,"eg int [ ] i = [ 0,0,0 ] ; <nl> now 0,0,0 will appear in the new array initialization .",1614860305,indirect error constructor is only allowed when error reason can be identified by error name alone . <nl> that is it 's only allowed for error types that have a single error reason type . <nl> this is because spec does not allow error reason to be specified in indirect error constructor expressions .,0.893663227558136
netty_netty/11367,"use kmp algorithm to optimize bytebufutil.indexof ( ) method and add test case . <para-sep> this method uses the two-way string matching algorithm , which yields o ( 0 ) space complexity and excellent performance . <nl> when the needle has only one byte that can be read , the firstindexof method needs to be called","motivation : . <nl> bytebufutil.indexof can be inefficient for substring search on <nl> bytebuf , in terms of algorithm complexity ( o ( needle.readablebytes * haystack.readablebytes ) ) , consider using the two way algorithm to optimize the bytebufutil.indexof ( ) method . <nl> modification : . <nl> use the two way algorithm to optimize bytebufutil.indexof ( ) method . <nl> result : . <nl> the performance of the bytebufutil.indexof ( ) method is higher than the original implementation",1623032871,"hi , . <nl> here are the very same fixed issue while it is now using the ' git ' format ( and better since i found out some mis configuration on my diff ) . <nl> i checked those fix by applying them to my own local code . <nl> also add some close ( ) that were missing . <nl> frederic",0.9465815424919128
elastic_elasticsearch/73670,"sometimes our fancy ' run this agg as a query ' optimizations end up <nl> slower than running the aggregation in the old way . we know that and use <nl> heuristics to dissable the optimization in that case . but it turns out <nl> that the process of running the heuristics itself can be slow , depending <nl> on the query . worse , changing the heuristics requires an upgrade , which <nl> means waiting . if the heurisics make a terrible choice folks need a <nl> quick way out . this adds such a way : a cluster level setting that <nl> contains a list of queries that are considered ' too expensive ' to try <nl> and optimize . if the top level query contains any of those queries we 'll <nl> disable the ' run as query ' optimization . <nl> the default for this settings is wildcard and term-in-set queries , which <nl> is fairly conservative . there are certainly wildcard and term-in-set <nl> queries that the optimization works well with , but there are other queries <nl> of that type that it works very badly with . so we 're being careful . <nl> better , you can modify this setting in a running cluster to disable the <nl> optimization if we find a new type of query that does n't work well . <para-sep> for now this just hooks into a cluster level setting so users can disable the behavior when the existing heuristics do n't detect cases where its slower .","sometimes our fancy ' run this agg as a query ' optimizations end up <nl> slower than running the aggregation in the old way . we know that and use <nl> heuristics to dissable the optimization in that case . but it turns out <nl> that the process of running the heuristics itself can be slow , depending <nl> on the query . worse , changing the heuristics requires an upgrade , which <nl> means waiting . if the heurisics make a terrible choice folks need a <nl> quick way out . this adds such a way : a cluster",1622642403,~~if a data stream is used in the list of index expressions then each <nl> data stream is resolved to the latest backing index ( write index ) of data stream.~~ . <nl> update index settings and put mapping apis calls that target a data stream are <nl> executed on all backing indices . <nl> in a followup an additional parameter will be added to the put mapping api that controls <nl> whether a put mapping api call that targets a data stream is executed on all backing indices ( default ) or <nl> only the write index of a,0.9537925124168396
jenkinsci_jenkins/5072,"inline icon-set lib <para-sep> simple icon metadata class . <nl> icon instance . <nl> get the class specification for this icon . <nl> get the icon 's normalized css selector . <nl> get the icon url . <nl> get the qualified icon url . qualifying the url involves prefixing it depending on whether the icon is a core or plugin icon . <nl> get the icon style . <nl> normalize the supplied string to an icon name class e.g . ' blue_anime ' to ' icon-blue-anime ' . <nl> normalize the supplied string to an icon name e.g . ' blue_anime ' to ' blue-anime ' . <nl> normalize the supplied string to an icon size class e.g . ' 16x16 ' to ' icon-sm ' . <nl> generate a normalized css selector from the space separated list of icon class names . the normalized css selector is the list of class names , alphabetically sorted and dot separated . this means that ' icon-help icon-xlg ' and ' icon-xlg icon-help ' have the same normalized selector ' .icon-help.icon-xlg ' . spaces are not relevant etc . <nl> trim all tokens first <nl> refill classnametoka <nl> sort classnametoka <nl> build the compound name <nl> normalize the supplied url . <nl> an icon set . <nl> get an icon instance from a class specification . <nl> get an icon instance from a class specification . <nl> get an icon instance from it 's url . <nl> get an icon instance from it 's url . <nl> normalize the supplied string to an icon name class e.g . ' blue_anime ' to ' icon-blue-anime ' . <nl> normalize the supplied string to an icon name class e.g . ' blue_anime ' to ' icon-blue-anime ' . <nl> normalize the supplied string to an icon size class e.g . ' 16x16 ' to ' icon-sm ' . <nl> normalize the supplied string to an icon size class e.g . ' 16x16 ' to ' icon-sm ' . <nl> normalize the supplied url . <nl> normalize the supplied url . <nl> initialize the core jenkins icons . we need all this stuff so as to maintain backward compatibility . <nl> small icons . .png versions will override .gif versions = > only time a gif should be returned by name is when it 's an animated status icon ( ' -anime- ' ) <nl>","it would be a lot easier if iconset lib is in core for this .. . <nl> any objections ? <nl> iconset library inlined into jenkins core , developers using this should remove the dependency",1606118514,"allows simple retention policies to be set via system property ( for example ) . <nl> more exotic policies could be added from plugins , for example to use a bounded lru list , or to drop or downgrade references after a delay . if this seems to be going too far , the extension classes could be made private . <nl> this is incompatible for anyone assuming a is a . i grepped all java code in github.com/jenkinsci and found nothing outside of core referring to this class , so i think it is safe to make that change",0.9554098844528198
apache_pulsar/10902,"correct topicname # getpartitionindex implementation . <para-sep> for the ' topic-partition-0 ' <nl> for the ' topic- ' <nl> ignore exception <nl> following behavior is not right actually , none partitioned topic , partition index is 0","current partitioned topic check logic is not rigorous enough , such as the this should not partitioned topic .",1623405609,"when produce/consume permissions for a role on a namespace are revoked , producers and consumers connected to the topic under the namespace using that role should be disconnected from the broker . however , i noticed that producers/consumers can stay connected in some topics even if the permissions are revoked . <nl> in subscriptions that consumer has never connected to since the broker started , the dispatcher has not been initialized , so returns null . <nl> as a result , the process of is aborted . <nl> before calling a dispatcher method , make sure that the dispatcher is",0.9034843444824219
apache_kafka/10640,: set streamsconfig on internaltopologydriver before writing topology <para-sep> only 0 window stores should be available <nl> only 0 window stores should be available <nl> 0 window stores + 0 shared window store should be available <nl> only 0 window stores should be available <nl> 0 window stores + 0 shared window store should be available,"while running some tests , i noticed the kstreams-outershared store , used in left/outer joins , was still added in the list of state stores when the flag was false . when this flag is false , the shared store should not be added to the join nodes . <nl> testing <nl> - added unit tests .",1620305562,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.8769977688789368
apache_shardingsphere/10462,support postgresql alter table rename statement <para-sep> get rename table .,changes proposed in this pull request : <nl> - support postgresql alter table rename statement <nl> - refresh metadata for alter table rename statement,1621940245,changes proposed in this pull request : <nl> - support insert without columns . <nl> - support insert without columns and generating generated-key . <nl> - add some tests and expected files for this usage . <nl> - modify some tests .,0.9647164940834045
confluentinc_ksql/6901,timestamp math functions <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"example usages are : . <nl> ~~in order to do this , a new ' type ' was introduced , , that represents an interval of time . users define them using an intervalexpression , which consists of numeric expression and a windowunit . can only be used within a function and can not be used as an actual data type ( similar to intervals in mysql ) .~~ .",1611692586,"part of the work to introduce primitive , then structured , keys . <nl> keys are currently assumed to be kafka serialized strings . when we introduce a way to specify a there must be a way to declare the key is a kafka serialized string if we 're to maintain backwards compatibility . also , many companies using kafka serialized ints or longs as keys . <nl> this pr brings a new format , which will use the appropriate standards kafka serde classes to deserialize a primitive key or value , e.g . <nl> will handle the case where",0.979375422000885
apache_druid/10896,"suppress unknown resourcetype and action for basic-security authorizer stuff <para-sep> sanity check <nl> ignore unparseable , it might be resource types we do n't know about <nl> bad resourcetype <nl> bad action <nl> this one has an unknown resourcetype , expect only 0 permission to deserialize correctly and failure ignored <nl> this one has an unknown action , expect only 0 permission to deserialize correctly and failure ignored","rather than rework these types to deserialize into strings and then filtering out permissions with unknown resource types or action values from the list ( or , i guess null checking everywhere ) , this pr instead introduces a custom deserializer for the list of permissions stored in a , chomping json processing exceptions so it can ignore any permissions which fail to deserialize . i 'm open to other approaches to this too if anyone has opinions here",1613568471,"adds a druid expression to allow use in and , as well as sql virtual column expression support .",0.9533334970474243
ballerina-platform_ballerina-lang/30310,"add debug server support for individual test debugging <cm-sep> add debugger test framework support to configure launch args <cm-sep> add integration tests <para-sep> adds test arguments , which is required to run individual tests . <nl> initialize test debug session . <nl> initialize test debug session . <nl> adds an inclusive test filter as a launch argument . <nl> test for break point hit at testmain ( ) <nl> since the test filter will exclude the ' testfunction ( ) ' method , continuing the debugger should hit the after-suite function instead of the breakpoint inside the ' testfunction ( ) ' method .",- adds integration tests for the above scenario .,1620043925,update annotations support with package name qualified notation and restructure the current http dispatcher,0.9619617462158203
vespa-engine_vespa/17216,- add option to provide token map while construction wand/wset/dotproduct . <nl> - parse to number directly if possible . <para-sep> creates an empty wanditem .,- add option to provide token map while construction wand/wset/dotproduct . <nl> - parse to number directly if possible .,1616861720,"adds two metrics for and : <nl> * vespa.container.feed.operations <nl> * vespa.container.feed.latency . <nl> with dimensions : <nl> api ( , ) <nl> operation ( , , ) <nl> status ( , , )",0.9615748524665833
quarkusio_quarkus/17606,upgrade to jandex version <cm-sep> upgrade to jandex-maven-plugin version <cm-sep> upgrade to org.kordamp.gradle.jandex version <para-sep> container element constraints,draft because we 're waiting for : .,1622560578,some very minor improvements i 've come across .,0.7472016215324402
OpenAPITools_openapi-generator/8999,generic docs update and fixes . <nl> * none of the dart generators supports xml <nl> * jaguar is no longer maintained <nl> * dart and dart-dio support bearer token <nl> * none of the dart generators supports composition atm . <para-sep> / get auth information on given route for the given type . / can return an empty list if type is not present on auth data or / if route does n't need authentication . / get auth information on given route for the given type . / can return an empty list if type is not present on auth data or / if route does n't need authentication . / get auth information on given route for the given type . / can return an empty list if type is not present on auth data or / if route does n't need authentication . / get auth information on given route for the given type . / can return an empty list if type is not present on auth data or / if route does n't need authentication .,* none of the dart generators supports xml <nl> * jaguar is no longer maintained <nl> * dart and dart-dio support bearer token <nl> * none of the dart generators supports composition atm .,1616073356,add the option to determine the name of the enum class .,0.8312519192695618
ballerina-platform_ballerina-lang/29231,fix issue in parsing array type <cm-sep> update test cases <cm-sep> add unit test <cm-sep> fix failing tests <cm-sep> resolve conflicts <cm-sep> fix matchexpr not cloned issue,- $ subject <nl> - improve bracketed list recovery <nl> - improve typed binding pattern recovery <nl> - improve match statement recovery .,1615880472,additionally this will add worker formatting and assignment formatting for record literals and add fixes went only with next-release branch,0.9516481161117554
vespa-engine_vespa/17498,do not require any specific value subclass <cm-sep> use newest install vespajlib,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618919018,this should fix the perf . test without any change on the other side ( although that change still make sense ) .,0.822819709777832
elastic_elasticsearch/74443,"this commit adds two related changes : <nl> * ilm waitfordatatierstep <nl> * autoscaling frozen_existence decider . <nl> the first part ensures that we wait mounting an index until a node that <nl> can hold the index is available , avoiding a failed restore and red <nl> cluster state . this is in particular important for the frozen phase , but <nl> is done generically in the searchable snapshot action . <nl> the second part triggers on indices in the ilm frozen phase to scale the <nl> tier into existence by requiring a minimal amount of memory and storage . <para-sep> create an ignored snapshot to initialize the latest-n file . <nl> verify that searchablesnapshotaction uses waitfordatatierstep and that it waits . <nl> this decider looks at all indices and ensures a minimum capacity is available if any indices are in the frozen ilm phase , since that is designated for partially mounted indices/frozen tier only . effectively , this scales the tier into existence . this works in concert with the in ilm that ensures we wait for autoscaling to spin up the first frozen tier node . <nl> return true if this index is in the frozen phase , false if not controlled by ilm or not in frozen . <nl> deliberately do not parse out the entire to avoid the extra work involved since this method is used heavily by autoscaling .","this commit adds two related changes : <nl> * ilm waitfordatatierstep <nl> * autoscaling frozen_existence decider . <nl> the first part ensures that we wait mounting an index until a node that <nl> can hold the index is available , avoiding a failed restore and red <nl> cluster state . this is in particular important for the frozen phase , but <nl> is done generically in the searchable snapshot action . <nl> the second part triggers on indices in the ilm frozen phase to scale the <nl> tier into existence by requiring a minimal amount of memory and storage .",1624384310,this new api provides a way for users to upgrade their own anomaly job <nl> model snapshots . <nl> to upgrade a snapshot the following is done : <nl> - open a native process given the job id and the desired snapshot id <nl> - load the snapshot to the process <nl> - write the snapshot again from the native task ( now updated via the <nl> native process ) .,0.9789776802062988
ballerina-platform_ballerina-lang/26871,"remove stored resources support and fix resource func qualifiers <cm-sep> add parser unit tests for qualifiers <cm-sep> fix ballerinaparsererrorhandler <para-sep> we only reach here for invalid qualifiers <nl> we only reach here for invalid qualifiers <nl> we only reach here for invalid qualifiers <nl> - isolated , transactional and resource are allowed . - remote is not allowed . <nl> we only reach here for invalid qualifiers",- remove stored resources support <nl> - support isolated and transactional qualifiers with resource functions .,1605101842,"there was feature to sanitize outbound request uri . however , doing so is wrong . we only should sanitize inbound request request uri . this pr fixes this issue . <nl> moreover , in addition to that , i have refactored the code a bit to make it more readable .",0.9725985527038574
OpenAPITools_openapi-generator/9728,"update httpclient version , fix compilation issue in the sample <para-sep> body | pet * | pet object that needs to be added to the store | <nl> body | pet * | pet object that needs to be added to the store | <nl> body | order * | order placed for purchasing the pet | <nl> body | user * | created user object | <nl> body | list & lt ; user & gt ; * | list of user object | <nl> body | list & lt ; user & gt ; * | list of user object | <nl> body | user * | updated user object | <nl> the version of the openapi document : version the version of the openapi document : version the version of the openapi document : version <nl> the version of the openapi document : version the version of the openapi document : version <nl> verify the required parameter 'body ' is set",- update httpclient version to address security issues . <nl> - fix compilation issues in the sample .,1623205340,"- fixed some issues with the 0.x templates which meant the resulting code did not compile . <nl> - improve reporting , i.e . code shows correct .net core version <nl> - introduced new templates for 0.x using idiomatic asp.net core 0 . <nl> - change default startup to show the swagger definition rather than a non-existent page . <nl> - improved the docker file so that we can integrate into visual studio docker generation ; not running under docker at the moment .",0.8228275179862976
crate_crate/10783,try to fix flaky resizeshardsitest . <nl> fixes the number of replicas to 0 .,fixates the number of replicas to 0 .,1605711953,this reverts the initial fix which also changed the behavior to fully <nl> unnest multi dimensional arrays . <nl> that can break use cases and should n't be <nl> done as part of a hotfix . <nl> it instead fixes the return type to avoid a later <nl> on .,0.8087467551231384
ballerina-platform_ballerina-lang/29940,"add an enum to identify the dependency version kind . <nl> there are two kinds : user_specified and latest <cm-sep> add methods to check for pre-release and initial versions <cm-sep> update version selection logic to consider pre-release versions <cm-sep> consider version kind when creating the dependency graph . <cm-sep> add test cases to validate package resolution with pre-release versions <para-sep> this class is used to identify a dependency package version as a version specified in dependencies.toml or as a version resolved by the package resolver . a version resolved by the package resolver is typically the latest version . <nl> indicates that the dependency version is specified by the user in dependencies.toml or a transitive dependency version of package specified in the dependencies.toml . <nl> indicates that the dependency version is resolved by the package resolver . <nl> create a resolution request <nl> pick the new version and update the graph node with scope default here we pick the new version because it is a user specified version and the resolution algorithm give priority to user specified versions in the graph <nl> pick the latest version and update the graph node with scope default <nl> here we ignore following cases : 0 ) both versions having the latest version kind , because both versions should be the same 0 ) new version is latest and old version is user_specified <nl> we do n't persist test_only scope dependencies <nl> only one version is a pre-release version return the version which is not a pre-release version <nl> both versions are pre-release versions or both are not pre-release versions find the the latest version <nl> contains cases to test pre-release version resolution logic . <nl> package_unstable_k_alpha has no dependencies and its version is version-alpha <nl> check whether there are any diagnostics <nl> check direct package dependencies <nl> package_m_with_unstable_dep -- > package_l ( version ) -- > package_k ( version-beta ) package_l ( version ) -- > package_k ( version-alpha ) this test case should fail . there are two incompatible versions of package-k in the dependency graph of package_m_with_unstable_dep . <nl> package_m_with_unstable_transitive_dep -- > package_l ( version ) -- > package_k ( version-alpha ) package_m_with_unstable_transitive_dep -- > package_k ( version is not specified ) this test case should not fail . the package_k version in the graph should be version-alpha <nl> package_l_with_stable_dep -- > package_k ( version is not specified ) there are","this pr fixes those spec deviations . <nl> this captures whether a particular version is a user-specified version or the latest compatible version available in a package repository . whenever a package version is added to the dependency graph , the algorithm gives priority to the user-specified .",1617929073,times for 2b operations : . <nl> value | operation | before ( ms ) | after ( ms ) <nl> -- | -- | -- | -- <nl> record | create | 0 | 0 <nl> | | get | 0 | 0 <nl> | | set | 0 | 0 <nl> | map | create | 0 | 0 <nl> | | get | 0 | 0 <nl> | | set | 0 | 0 . <nl> sample code used : .,0.966209888458252
ballerina-platform_ballerina-lang/31316,improve global variable dependency graph . <nl> by incorparating record field default values into the calculation <nl> and incorparate typ of global variable into consideration <cm-sep> improve type-dependency tracking <para-sep> global variable reference from a field assignment of an record type declaration . <nl> global variable referenced inside of nested record decl causing a dependency cycle .,something like below : . <nl> should be re-roder into : .,1624261984,this includes the constraint scope and the connector init scope .,0.9660765528678894
elastic_elasticsearch/74298,move dynamic templates tests to dynamictemplatestests . <nl> some tests around dynamic templates used to be in rootobjectmappertests while others are in dynamictemplatestests . this commits moves all tests to be under dynamictemplatestests . <para-sep> no update if templates are not set explicitly <nl> there should be no update if templates are not set . <nl> dynamic templates should be appended and deduplicated .,some tests around dynamic templates used to be in rootobjectmappertests while others are in dynamictemplatestests . this commits moves all tests to be under dynamictemplatestests .,1624018027,"these tests were left disabled since the introduction of the runtime section , as dynamic templates could not yet create a runtime field . now that dynamic templates can do that , we re-enable them , though we lose a bit of coverage as we have no ability to mimic the multi-field that 's created when string fields are dynamically mapped .",0.843612015247345
neo4j_neo4j/11690,"make not throw eviction exception . <nl> the only _really_ needs to assert that the page <nl> cache has not been closed . it is not strictly necessary for this method <nl> to assert that the page cache is healthy . furthermore , now that it is <nl> used for implementing , checking for the eviction <nl> exception is outright harmful . the method is one of <nl> a few ways to clear the eviction exception . <nl> the background eviction thread now also no longer spins forever , if it <nl> can not evict any pages because they throw exceptions . this makes testing <nl> it easier . <para-sep> though the eviction thread is unable to flush any dirty pages because the file system throws exceptions on all writes . <nl> this will run into that exception , in background eviction : <nl> we now have a background eviction exception . a successful flushandforce should clear it , though . <nl> and with a cleared exception , we should be able to work with the page cache without worry .","the only _really_ needs to assert that the page <nl> cache has not been closed . it is not strictly necessary for this method <nl> to assert that the page cache is healthy . furthermore , now that it is <nl> used for implementing , checking for the eviction <nl> exception is outright harmful . the method is one of <nl> a few ways to clear the eviction exception . <nl> the background eviction thread now also no longer spins forever , if it <nl> can not evict any pages because they throw exceptions . this makes testing <nl> it",1525256446,"if the page cache eviction thread encounters an exception during eviction , such <nl> as running out of storage space , then that exception will be stored in a field <nl> an delivered to the next unfortunate passersby accessing the page cache . <nl> if this is the gbptree in the process of shutting down , then the exception <nl> would bubble out without any attempt at recovering the situation . <nl> this behaviour was different from how the record stores shut down , and it would <nl> prevent shut down even after the fault had been corrected , such",0.8571470379829407
runelite_runelite/13050,add crabclaw caves obstacles <cm-sep> fix crabclaw caves tunnel ( quest ) worldpoint,"the agility obstacles in this cave have an 0 agility requirement . as they have icons on the worldmap , they should be labeled properly in runelite as well . the dungeon icon for the depths of dispair section of the dungeon was previously labeling the main dungeon entrance , which already had a label . this has been fixed to correctly label the entrance to the quest dungeon within crabclaw caves .",1610566094,"i altered the saradominbrew and superrestore classes to better support the ( - ) , normal , and ( + ) variants of xeric 's aid / revitalization potions , as well as adding the ( + ) variants to the itemstats plugin . i can not find the information for ( - ) or normal modifiers so i did not add them , but i took the ( + ) information from the wiki and tested in game . the wiki improperly suggests that the standard potions are equivalent to sara brews/super restores but a friend who tested said",0.8162171840667725
elastic_elasticsearch/73733,deprecations for single data node setting . <nl> this commit adds deprecation warnings to 0.x <nl> to ensure we can make only true valid in version . <para-sep> details * + <nl> impact * + <nl> empty,this commit adds deprecation warnings to 0.x <nl> to ensure we can make only true valid in version .,1622743014,"this fixes a gap in testing and a bug that can occur in various forms : <nl> when we would start a snapshot or clone related to a shard that was done <nl> snapshotting/cloning but its overall operation was not yet finalized <nl> at the time of starting the operation , we would base the operation off of <nl> the wrong generation . this would not cause a corrupted repo , but would <nl> cause the operation to be . <nl> this commit fixes the state machine to take into account the correct generation <nl> in this case .",0.9466086626052856
vespa-engine_vespa/18308,set the correct path for gdb on rhel8 . <para-sep> todo : remove when we do not have any installs left,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623961325,take config server out of rotation ( status.html ) until it is bootstrapped . <nl> also make sure that health api status code is 'initializing ' until rpc <nl> server is actually running .,0.8771221041679382
OpenAPITools_openapi-generator/9118,removes colliding __init__model.mustache in pythonclientcodegen.java <cm-sep> removes unused files,fix python custom model template feature <nl> i verified locally that using only a custom model template works with this update .,1616946693,visionmedia/superagent version is vulnerable to zip bomb attacks . <nl> refs : nvd - 0 . <nl> it has been fixed in v3.version . <nl> > - limit maximum response size . prevents zip bombs ( kornel ),0.8720306754112244
elastic_elasticsearch/74523,"do n't throw an npe when getting the status for a node that 's not in the cluster <cm-sep> clarify explanation <cm-sep> ensure delete'ing a node that 's not shutting down returns 0 , not 0 <para-sep> ensures that attempting to delete the status of a node that is not registered for shutdown gives a 0 response code . <nl> we do n't know about that node","this pr cleans up a few issues with the node shutdown api , specifically : <nl> - get'ing the status of a node that 's registered for shutdown , but not in the cluster , now produces a useful response instead of an npe . <nl> - the explanation of the status now calls out that the allocation explain api should be used on the given shard in particular . we may handle this differently soon , but this improves things for now . <nl> - delete'ing a non-existent shutdown request now returns http code 0 instead of 0 .",1624487732,this allows the step to move past the allocation check <nl> if the tier routing settings are manually unset . <nl> this helps a user unblock ilm in case a tier is removed ( ie . if the warm tier <nl> is decommissioned this will allow users to resume the ilm policies stuck in <nl> waiting for the warm nodes to become available and the managed <nl> index to allocate . this allows the index to allocate on the other available tiers ) .,0.9466233849525452
hazelcast_hazelcast/18669,"<para-sep> bind to receive interface <nl> setting loopbackmode is just a hint - and the argument means ' disable ' ! to check the real value value we call getloopbackmode ( ) ( and again - return value means ' disabled ' ) <nl> if loopback mode is not enabled ( i.e . getloopbackmode return true ) and bind address is a loopback one , then print a warning <nl> this configuration may affect the multicast behavior on some platforms .","restores old code of adding setinterfaces , without modification of other branches . <nl> checklist : .",1620815656,"there 's a small chance that mc version will not contain communication model related changes . for this reason , mc uses the new client operations only in a feature branch . until we merge the feature branch back to mc master branch , we need to support the old way of executing operations on the cluster . this pr reverts back changes made in a previous pr removing support for mapconfigrequest and also fixes it so that it works with the current mc .",0.9760808944702148
hazelcast_hazelcast/18923,"fix failures related to not cleaning hazelcastbootstrap <para-sep> set the static instance supplier field of hazelcastbootstrap to null . because of the lifetime of this field spans many test classes run on the same jvm , hazelcastbootstraptest and hazelcastcommandlinetest were interfering with each other before this cleanup step added .","this pr fixes the hazelcastcommandline test failures caused by not clearing <nl> the static field , , used by two separate tests . <nl> because static field cleanup is not performed after , <nl> tests were failing with <nl> . <nl> this was happening when these two tests run on the same jvm ( share same static field ) <nl> and runs before . now , <nl> we cleanup this static field after running this . <nl> checklist : .",1623858081,* fixes the issue when mc client could not change cluster state if the cluster is in state,0.8741964101791382
vespa-engine_vespa/17335,throw exception for unexpected enum value in more places <cm-sep> restrict values to fit into target cell type <cm-sep> cosmetic tweaks,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1617965804,"before this pr , the plugin outputs 0 sets of packages when run with maven 's -x debug option : . <nl> r = referenced packages <nl> d = defined packages <nl> e = exported packages by dependencies . <nl> for the following we need to split d into : . <nl> d_p = defined packages in the project 's class files <nl> d_c = defined packages in the project 's compile scoped deps . <nl> this pr is a best effort to output sets of packages that can cause problems when the bundle is deployed in a jdisc container",0.9486536979675293
OpenAPITools_openapi-generator/9578,fix android crash on api level,this means that on api level 0 and bellow it will crash the app . <nl> so in this pr we revert to use a deprecated api that does n't crash the app .,1621951312,"this is a follow-up story that completes this pr proposed before . this pr adds a new parameter that has default value to false to maintain retro-compatibility . <nl> this is especially problematic when adding more fields to existing endpoints , since the order of the parameters might change . this leads to a breaking changes in the generated client , even if the api introduced a non-breaking change ( a new optional parameter ) . <nl> this is not a new solution , it has been implemented in other generators and there is already a proposed solution using this",0.9235736727714539
apache_kafka/10550,add support for zk authorizer with kraft <para-sep> createchrootifnecessary=true is necessary in case we are running in a kraft cluster because such a cluster will not create any chroot path in zookeeper ( it does n't connect to zookeeper ) <nl> logic to handle acl requests . <nl> to kafka.zk.embeddedzookeeper <nl> to kafka.zk.embeddedzookeeper,"this patch adds support for running the zookeeper-based with kraft clusters . set the config as well as the config while also setting the typical kraft configs ( , , etc . ) , and the cluster will use kraft for metadata and zookeeper for acl storage . a system test that exercises the authorizer is included . <nl> this patch also changes ' raft ' to ' kraft ' in several system test files . it also fixes a bug where system test admin clients were unable to connect to a cluster with broker credentials via the ssl security",1618619291,"comparing all other test cases , the starts an async producer sending records throughout the test other than just synchronously sent and acked a few records before we start the streams application . right after the streams app is started , we check that at least one record is sent to the output topic ( i.e . completed processing ) . however since only this test starts the producer async and did not wait for it to complete , it is possible that the async producer gets too longer to produce some records and causing it to fail . <nl>",0.8131906390190125
elastic_elasticsearch/74292,"[ ml ] refresh results indices before running delete by query . <nl> the reason is that the results <nl> index has not been refreshed thus those docs are not visible to <nl> the search the delete by query action is doing . <nl> this commit adds a call to the refresh api before running delete <nl> by query to the results indices . <para-sep> first , we refresh the indices to ensure any in-flight docs become visible",the reason is that the results <nl> index has not been refreshed thus those docs are not visible to <nl> the search the delete by query action is doing . <nl> this commit adds a call to the refresh api before running delete <nl> by query to the results indices .,1624011668,"in some cases , if shard level results are incomplete in the data streams stats call , it is possible to get inaccurate counts of the number of backing indices , despite this data being accurate and available in the cluster state . if an index has no shards allocated due to a failure , or because it is closed ( as i 've seen on 0.x line ) , or if all shards of an index fail to return a result , then the shard level responses would contain none from the unallocated index , and thus the index",0.9306999444961548
ballerina-platform_ballerina-lang/27723,"fix completion issue for object members <cm-sep> fix hover issues and diagnostic publishing issue <para-sep> get remote method declaration snippet block . <nl> added +0 since the completion is valid after listener <nl> clear old entries with an empty list <nl> get the description only hover object . <nl> fix test cases replacing expected using responses jsonobject obj = new jsonobject ( ) ; obj.add ( ' position ' , configjson.get ( ' position ' ) ) ; obj.add ( ' expected ' , parser.parse ( response ) ) ; java.nio.file.files.write ( fileutils.res_dir.resolve ( ' hover ' ) .resolve ( ' configs ' ) .resolve ( config ) , obj.tostring ( ) .getbytes ( java.nio.charset.standardcharsets.utf_8 ) ) ; <nl> get the expected value from the config json . <nl> testtype ; <nl> testtype ;",0. fix diagnostics map caching issue in language server <nl> 0. fix completions for object members .,1610015783,> add annotation in the resource signature instead of having req.getqueryparamvalue ( string key ) function . <nl> > add annotation for path params .,0.9612393379211426
hazelcast_hazelcast/18879,"fix getjob ( long ) after new master takes over . <nl> the with parameter , on a master , looked <nl> only at and at map , <nl> but not at . after a new master takes over , it takes a short <nl> time until the new master loads . during this time , <nl> returned null for an existing job . <nl> the fix is to look at all too .","the with parameter , on a master , looked <nl> only at and at map , <nl> but not at . after a new master takes over , it takes a short <nl> time until the new master loads . during this time , <nl> returned null for an existing job . <nl> the fix is to look at all too .",1623333290,if we push a block of calls the reconnection calls are checked for a <nl> response but the never were written to cluster . also on single write the <nl> reconnection calls is checked twice with the same call . this will check <nl> all reconnection calls for a response ( also not submitted ones ) . <nl> if their are more reconnection calls pending the duplicates check after <nl> every write causes that it takes too long to complete : 100ms * <nl> numberofreconnectioncalls \ * numberofreconnectioncalls . <nl> on reconnection we also have to reorder the blocked calls,0.8548668026924133
apache_pulsar/10966,fix get wrong backlog number .,"now when create a new complete . if is the lac it will delete the previousledger from . when get backlog we will use range.close to get 0 , if previousledger not exist will get the wrong number . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations :",1623987707,if client acks with invalid message-id ( message-id > ledger.lastconfirmedentry ) then broker does n't do validation and it tries to process it which can corrupt the state of cursor . <nl> eg : if is invalid then ledger.getnextvalidposition ( ) returns null and broker stores . <nl> and it creates below exception : . <nl> validate mark-delete position before processing it . <nl> prevents any state corruption at cursor .,0.9191731214523315
apache_incubator-pinot/6590,introduce a metric for query/response size on broker . <nl> this change introduce a metric in the broker that indicates the <nl> size of the query and response .,"this change introduce a table level metric in the broker that indicates the size of the query and response . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1613618299,"this pr adds metrics to track the number of partitions for which controller becomes leader , so that <nl> when the total number of this metric is aggregated from multiple controllers , we know every partitions have their own leader .",0.8904430866241455
elastic_elasticsearch/73055,"previously , when a tophits aggregation function was used ( first/last , <nl> or min/max on keyword field ) in a subquery and on an outer query this <nl> aggregation was filtered ( with where/having ) the verification was passed <nl> successfully and the query was planned and translated resulting into an <nl> unsupported query dsl - since bucket selector on a tophits agg is not <nl> currently supported , and the user received a weird error msg . <nl> verify this case of subselects with tophits aggs and throw an <nl> appropriate error message to the user . <nl> ( cherry picked from commit sha )","previously , when a tophits aggregation function was used ( first/last , <nl> or min/max on keyword field ) in a subquery and on an outer query this <nl> aggregation was filtered ( with where/having ) the verification was passed <nl> successfully and the query was planned and translated resulting into an <nl> unsupported query dsl - since bucket selector on a tophits agg is not <nl> currently supported , and the user received a weird error msg . <nl> verify this case of subselects with tophits aggs and throw an <nl> appropriate error message to the user . <nl>",1620917251,"this adds support for v2 index templates to the cat templates api . it uses the field as <nl> priority in order not to break compatibility , while adding the field to show component <nl> templates that are used from an index template .",0.9165888428688049
apache_kafka/10885,"we prevent handling metadatarequests where the topic name is null ( to prevent npe ) as <nl> well as prevent requests that set topic ids since this functionality has not yet been <nl> implemented . <nl> added tests to ensure the error is thrown . <nl> reviewers : dengziming , ismael juma <cm-sep> fix kafkaapistest <para-sep> the response does not allow null , so convert to empty string if necessary <nl> version 0 adds topicid and allows name field to be null . however , this functionality was not implemented on the server . versions 0 and 0 should not use the topicid field or set topic name to null . <nl> construct invalid metadatarequesttopics . we will build each one separately and ensure the error is thrown . <nl> if version is 0 or 0 , the invalid topic metadata should return an error <nl> topic ids are not supported for versions 0 and 0. topic names can not be null in these versions . <nl> construct invalid metadatarequesttopics . we will try each one separately and ensure the error is thrown . <nl> if version is 0 or 0 , the invalid topic metadata should return an error",cherry-pick of sha <nl> updated kafkaapistest to use version code .,1623776152,"when the connect worker forwards a rest api request to the leader , it might get back a that suggests the worker should forward the request to a different worker . this can happen when the leader changes , and the worker that receives the original request forwards the request to the worker that it thinks is the current leader , but that worker is not the current leader . in this case . in most cases , the worker that received the forwarded request includes the url of the current leader , but it is possible ( albeit rare",0.904837429523468
apache_pulsar/10533,removed aspectj based metrics for zookeeper,"so far , we have been relying on a wacky approach to gather metrics for zookeeper usage . that was done because zk used not to have a decent set of exported metrics in server or client side . <nl> we were relying on aspectj to intercept specific points in zookeeper client/server execution and collect the data points and expose them through prometheus . <nl> there are few problem with this approach : <nl> 0. it 's hacky because we 're jumping inside zk undocumented code internals , which break between releases and there 's overhead in the aspectj interception",1620687560,"integration test are basically just not working in apache ci . there are multiple reasons : . <nl> 0. pulsar_mem is set to very high ( ~2g ) . if we start more than 0 containers , it will quickly go up to ~12gb . <nl> 0. we start containers for each tests , which is very inefficient . <nl> 0. set pulsar_mem to use no more than 128m . <nl> 0. switch to use test suite , trying to start containers only once as possible and use them across test suites . <nl> so we only start the cluster",0.9552425742149353
elastic_elasticsearch/72920,"consolidate parsing runtime fields from source . <nl> every runtime field type allows users to omit its script , in which case the field values will be loaded at runtime from _source . <nl> this is implemented by having each field type expose a parse from source script factory that extracts the values and converts them to the appropriate type that can then be emitted . <nl> the extraction logic from source is though always the same , what changes between the different types is the factory type that is needed and how the object values are converted to their appropriate type . this commit moves the common bits to abstractfieldscript . especially the conversion from object to the appropriate type is handy in a specific method as it will be reused to emit multiple fields from a single <nl> script . <para-sep> ignore <nl> ignore <nl> ignore <nl> [ 0 , 0 ] : two values but one single point , return it as a list or each value will be seen as a different geopoint . <nl> e.g . [ [ 0,0 ] , { lat:0 , lon:0 } ] <nl> e.g . { lat : 0 , lon : 0 } <nl> ignore <nl> ignore parsing exceptions <nl> ignore ;","every runtime field type allows users to omit its script , in which case the field values will be loaded at runtime from _source . <nl> this is implemented by having each field type expose a parse from source script factory that extracts the values and converts them to the appropriate type that can then be emitted . <nl> the extraction logic from source is though always the same , what changes between the different types is the factory type that is needed and how the object values are converted to their appropriate type . this commit moves the common",1620733905,this simplifies the code to to avoid future <nl> issues and save over 0 loc . <nl> also this fixes a bug in where trying to instantiate a time value with a negative time could throw and unexpected exception and as a result leak a listener .,0.9322158694267273
quarkusio_quarkus/17875,update description . <nl> then it has the same structure as for the remove command .,then it has the same structure as for the remove command .,1623486771,jdk11 has been around over a year . time to upgrade,1.0
trinodb_trino/7947,"clear pagesindex in windowoperator # close ( ) . <nl> in windowoperator , spillablepagestopagesindexes is not cleared after query failed due to exceptions ( eg . exceededmemorylimitexception ) , resulting in holding unnecessary data in memory . <nl> this commit adds clear ( ) function to spillablepagestopagesindexes to clear underlying pagesindex , and calls it in windowoperator # close ( ) .","in windowoperator , spillablepagestopagesindexes is not cleared entirely after query failed due to exceptions ( eg . exceededmemorylimitexception ) , resulting in holding unnecessary data in memory . <nl> from my local profiling result , if query is interrupted or failed due to exception during ' unspill ' stage , <nl> mergedpagesindexwithhashstrategies will not be cleared and still holding considerable memory . <nl> this commit adds clearindexes ( ) function to spillablepagestopagesindexes to clear underlying pagesindex , and calls it in windowoperator # close ( ) .",1621273316,"the old name ( ) was a left-over since the times when the <nl> method was returning . it was kept unchanged to ease migration . <nl> now that we change the method name anyway , we can fix it too .",0.7452307343482971
apache_kafka/10301,": increase max.poll.interval.ms for withstate test to avoid unexpected rebalance <para-sep> the app first commits after each 0 records per partition ( total 0 records ) , and thus will have 0 * 0 uncommitted writes <nl> the app first commits after each 0 records per partition ( total 0 records ) , and thus will have 0 * 0 uncommitted writes and store updates ( ie , another 0 uncommitted writes to a changelog topic per partition ) in the uncommitted batch , sending some data for the new key to validate that upon resuming they will not be shown up in the store the failure gets inject after 0 committed and 0 uncommitted records got received we need more processing time under ' with state ' situation , so increasing the max.poll.interval.ms to avoid unexpected rebalance during test , which will cause unexpected fail over triggered <nl> the app first commits after each 0 records per partition , and thus will have 0 * 0 uncommitted writes then , a stall gets injected after 0 committed and 0 uncommitted records got received","found the root cause about why the the test failed sometimes with unexpected committed/uncommitted result . the reason is the unexpected rebalance during committing messages , and it causes the fail over mechanism . and the reason why the rebalance is triggered is because we reduce the value to 0 seconds ( default is 0 mins ) for the test , which is trying to stall a thread , and wait for exceeding the , and trigger the rebalance . as we know , under situation , we have more things to handle with the state and additional topics ...",1615438005,"0. inside statedirectory # cleanremovedtasks , skip deleting the lock file ( and hence the parent directory ) until releasing the lock . and after the lock is released only go ahead and delete the parent directory if . that is , this is triggered from and users are responsible to make sure that streams instance is not started and hence there are no other threads trying to grab that lock . <nl> 0. as a result , during scheduled cleanup the corresponding task.dir would not be empty but be left with only the lock file , so effectively we",0.9345852732658386
vespa-engine_vespa/17907,"improve readability <cm-sep> prepare for raw fields to be presented as base64 encoded in summary . <para-sep> returns true if 'raw ' fields shall be presented as base64 in summary note that tis is temporary and will disappear on vespa 0 as it will become default , and only option . <nl> represents a binary field that is presented as base64",note as suggested under as trigger .,1621454223,"should status.html also be protected from stealing ? <nl> i did n't add an check before throwing when a reserved binding is used . if you try to steal a binding today , the built-in handler wins , but deployment does not fail .",0.9635511636734009
apache_camel/5582,": add salesforce 'raw ' operation . <para-sep> raw - send requests to salesforce and have full , raw control over endpoint , parameters , body , etc . <nl> deserialize json results or handle in some other way <nl> raw - send requests to salesforce and have full , raw control over endpoint , parameters , body , etc . <nl> deserialize json results or handle in some other way <nl> parameters for the raw operation <nl> raw operation properties <nl> the portion of the endpoint url after the domain name . e.g. , ' + ' '/services/data/v52.0/sobjects/account/ ' <nl> http method to use for the raw operation <nl> comma separated list of message headers to include as query parameters for raw operation . do not url-encode values as this will be done automatically . <nl> comma separated list of message headers to include as http parameters for raw operation . <nl> raw operation <nl> replace old token <nl> make a raw http request to salesforce <nl> make a raw http request to salesforce <nl> urlencoder likes to use '+ ' for spaces <nl> comma separated list of message headers to include as http parameters for raw operation . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : producer <nl> http method to use for the raw operation . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : producer <nl> the portion of the endpoint url after the domain name . e.g. , '/services/data/v52.0/sobjects/account/ ' . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : producer <nl> comma separated list of message headers to include as query parameters for raw operation . do not url-encode values as this will be done automatically . the option is a : & lt ; code & gt ; java.lang.string & lt ; /code & gt ; type . group : producer <nl> there are 0 enums and the value can be one of : getversions , bulk2deletequeryjob , raw there are 0 enums and the value can be one of : getversions , bulk2deletequeryjob , raw comma separated list of message headers to include as http parameters","for users who have been using the rawpayload option of the composite operation in unintended ways , this will give them a better option . then we can deprecate and remove most of the xml serialization that is just extra work to maintain and does not add value . <nl> i 've currently only got tests for queries and basic rest api operations , as the latter is what people have been using the rawpayload option for . <nl> would like feedback on the approach here . also , since i did n't make it in time for version ,",1621289306,: camel-main - add logic for automatic routebuilder class detection ala camel-spring-boot has,0.9777275919914246
apache_flink/15328,"[ .0 ] backport flink-metrics-datadog changes from master . <nl> commit 313e20e8e03953a5e1cec9daa467f561ccfbd599author : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> add histogram support <nl> commit 38e424fd5fa7c4a6e6165921689a232a10e85bddauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> encapsulate metric meta data this allows us to use the 'metricmetadata ' container for histograms later on , which will not directly extend 'dmetric ' . <nl> commit ea317c20ac4ab76c9e71fb0c1aa8a104e7173057author : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> remove outdated comments <nl> commit f01e1916edf015d3f1b800065eeea4c2ae4af7baauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> rework tests - re-parse json to ignore order of serialization - restrict 'datadoghttpclient.serialize ( ) ' to 'dseries' - test series serialization - refer to constants where possible <nl> commit 7fcb628c0cd6a3daf3f19917ef2414d8743bcc7aauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> explicitly mark fields relevant for serialization it was difficult to tell which fields are relevant for serialization . adding annotations makes this more obvious , and allows us more freedom in regards to naming . <nl> commit 4d5053067199d46134366abc5c8954c57757a82eauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> merge dseries # add * ( ) the distinction between metric types adds unnecessary complexity . <nl> commit bf058d68acdcdcb4ea28e6fe3a22904a5f385b8aauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> cleanup code <para-sep> returns the count of events since the last report . <nl> maps histograms to datadog gauges . note : we can not map them to datadog histograms because the http api does not support them . <nl> all metadata associated with a given metric . * / <nl> * /","i created this pr by copying the files from master because due to the code reformat it would have been cumbersome to cherry pick individual commits . changes included : . <nl> commit 313e20e8e03953a5e1cec9daa467f561ccfbd599author : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> add histogram support <nl> commit 38e424fd5fa7c4a6e6165921689a232a10e85bddauthor : chesnay schepler date : tue dec 0 0:0:0 0 +0 <nl> encapsulate metric meta data this allows us to use the 'metricmetadata ' container for histograms later on , which will not directly extend 'dmetric ' . <nl> commit ea317c20ac4ab76c9e71fb0c1aa8a104e7173057author : chesnay schepler date : tue dec",1616433710,"# # what is the purpose of the change . <nl> integrate hive to streaming file sink . <nl> - integrate parquet and orc streaming writer to hive . <nl> - integrate to streamingfilewriter and streamingfilecommitter . <nl> - hivetablesinktest.testpartstreamingwrite <nl> - hivetablesinktest.testnonpartstreamingwrite . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or",0.9741398692131042
Graylog2_graylog2-server/10561,"cleaning up tests , adding test case for issue . <cm-sep> do not quote index match pattern . <para-sep> use a special match pattern and wildcard to match restored indices like","this works fine unless is defined . the index match pattern can contain special characters and regex terms deliberately , which must not be quoted . the index match pattern is currently used by archiving , which lead to it not being able to identify indices belonging to the restored archives index set . <nl> this pr is removing quoting for the index match pattern . any usage of the index match pattern must ensure that all special characters are quoted properly .",1620121133,"up until now , trying to generate a field chart on a non-numeric value failed , as the server did only try to calculate statistical aggregations for the field and that is not possible . anyway , we could still calculate the total and cardinality functions for those fields , as we do in the statistics analyzer . <nl> this pr changes how we treat non-numeric field charts , enabling users to generate graphs for cardinality and total . it is as well possible to stack them to other field charts , and add them to dashboards , just as",0.84294593334198
OpenAPITools_openapi-generator/8848,"deepobject also for required parameters <cm-sep> fix nullpointerexception on inline deepobject such as a dictionary <cm-sep> add deepobject in parametertomultimap for deepobjects without explicit parameters <cm-sep> add some context to todos <cm-sep> parametertomultimap fixed in csharp template for oas 0 dicts , taking deepobject into account <cm-sep> remove added whitespace <cm-sep> update samples",looking into the issue i found that indeed swaggerui and the csharp-netcore client libraries were generating different queries . <nl> this pull request does two things : .,1614343822,"currently a field which matches a rust keyword e.g . is rendered as the rust variable in order to produce valid rust . this is confusing , because a leading underscore indicated an unused variable in rust code . <nl> instead we match convention in the rust community and suffix variables with an instead . for fields which begin with a number ( e.g . ) , we prefix them with to avoid this problem , and avoid being unable to to start with a number .",0.8630084991455078
ballerina-platform_ballerina-lang/30511,"remove unwanted mapping intersection constraint <para-sep> when there are errors in this type , we ca n't just use the tname . fall back to pkgalias : typename pattern",and improve the error message for intersection between types that we do n't handle at the moment .,1620805015,a valid main function signature requires : <nl> - the public modifier <nl> - the return type to be an int if returns exist ( alternatively the main function may not return a value ),0.9524104595184326
hazelcast_hazelcast/18903,fix problematic reflection usage <para-sep> get field to manipulate and save it 's old value to replicatedmapdataserializablefactory,we want to do this in order to change access modifiers of . this pr modifies the code so that is used in order to change modifiers of . <nl> this could be backported . <nl> checklist : .,1623684823,"it 's not safe to convert a composite value in-place for hd , since <nl> it may undergo some other transformation , e.g . canonicalization , <nl> at the same time on a different thread . <nl> also , unneeded warning suppressions are cleaned up in queryrunner .",0.8606116771697998
jenkinsci_jenkins/5525,"stop bundling unnecessary copy of asm 0 <cm-sep> be more gentle to users of scm api ( i.e. , most jenkins users )","like that pr , we still pull in the version of stapler that drops the dependency on the repackaged asm 0 and also stop consuming the repackaged asm 0 from jenkins core . this allows for a smoother ( albeit more prolonged ) transition period . <nl> n/a . <nl> n/a . <nl> before the changes are marked as : .",1621886991,"* use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8234111070632935
ballerina-platform_ballerina-lang/28025,fix verifyerror when using union of streams as a function param . <cm-sep> add error|never support for streams and queries . <cm-sep> remove print function from query helpers <cm-sep> test using union of streams as args for functions <cm-sep> test assignability of streams after error|never change <para-sep> never . <nl> test the negative assignability of stream and stream <nl> test the assignability of stream and stream,note : this will also fix the verifyerror which occurs when using a union of streams as arguments to a function .,1611156488,"this pr also introduces , which extends the to separate the kinds of literals based on whether they are numeric literals or non-numeric literals . this refactor effort is carried out to fix a couple of issues related to the finite types those made up of decimal constants .",0.9771102070808411
apache_pulsar/10741,fix transaction ack delete marker position when do n't have transaction ack . <para-sep> is transaction ack present .,"when do n't have transaction ack , we don ' need to check the next position is transaction marker position . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no",1622267494,"0）testtopiclevelinactivetopicapi：the error is caused by , due to the slow startup of the broker , the cache has not been initialized yet . <nl> 0 ) testtopiclevelinactivepolicyupdateandclean：we previously updated the event trigger timing of topic-policies . the update is triggered after the event is consumed . therefore , it is not enough to judge that the policy in the cache is null . we need to sleep and wait for the event to be consumed .",0.8989510536193848
ballerina-platform_ballerina-lang/29922,implement isolation inference for functions <cm-sep> fix bir emitter for flags <cm-sep> add tests <cm-sep> fix symbolflagtoqualifiermappingtest <cm-sep> fix tests,this pr introduces isolated inference based on function/method calls . both the following are inferred to be isolated . <nl> to do : isolated inference for objects and variables .,1617865730,> this do not support sender panic related scenarios .,0.9840542674064636
apache_incubator-pinot/6559,optimize group-key generator <para-sep> note : map size = map capacity ( power of 0 ) * load factor <nl> todo : clear the holder after processing the query instead of before arraymapbasedholder <nl> longmapbasedholder <nl> intmapbasedholder <nl> initialize the map with capacity 0 so that the _keyvalueholder can fit into a single memory page <nl> returns the group id for the given raw key . create a new group id if the raw key does not exist and the group id upper bound is not reached . <nl> note : key 0 is reserved as the null key . use ( rawkey + 0 ) as the internal key because rawkey can never be 0 . <nl> handle hash hit separately for better performance <nl> hash collision <nl> clear the map <nl> init the map ( clear and trim ),the improvement ( up to ~0 % ) is mainly from replacing the with the new implemented . the stores both keys and values within a single array so that it is more friendly to cpu cache . <nl> the benchmark result for these 0 map implementations are as followings ( with 0 threads ) : . <nl> also move the thread-local data structures into the and fixes the issue of not dropping the large map that should not be cached .,1612829810,"adding a segment size based flush threshold updater which updates the flush threshold rows of the new segment metadata , based on the segment size and number of rows of previous segment <nl> the formula used to compute new number of rows is : <nl> where a = version , b = version <nl> this ensures that we take into account the history of the segment size and number rows",0.9788268804550171
Alluxio_alluxio/12602,"give more clear description to bytes and throughput metrics <para-sep> gets total bytes written remote . <nl> gets total bytes written remote throughput . <nl> sets total bytes written remote . <nl> sets total bytes written remote throughput . <nl> for example , counter of cluster.bytesreadremote is aggregated from the worker reported worker.bytesreadremote . <nl> bytesreadremote : 通过该worker从alluxio存储读取的数据量，单位为byte。 byteswrittenremote : 通过该worker写到alluxio存储的数据量，单位为byte。 <nl> bytesreadremote and bytesreadremotethroughput represent data transmission via the network stack ; bytesreaddomain and bytesreaddomainthroughput * represent data transmission via domain socket .","bytesreadalluxio metrics only represent the remote alluxio read metrics , modify the description to be clearer .",1607022187,"all they need to know is to specify the s3 bucket using url like <nl> - some s3 related properties are and some others are , very confusing to hard to remember . <nl> we should support the canonical s3 bucket url by ' s3 : // ' . <nl> - update corresponding docs",0.9541486501693726
apache_camel/5461,camel-test-infra-chatscript : added new test infra for chatscript <cm-sep> camel-chatscript : automated the previously manual it test <para-sep> no-op <nl> no-op <nl> test infra service for chatscript,- added a test infra for chatscript <nl> - automated the it test for chatscript .,1619181077,"comments <nl> this is a work in progress , but opening a draft pr to welcome comments . this pass has somewhat basic support , sufficient for my current needs . i propose we land this functionality ( when no longer wip ) and queue up individual features for future goals ( for which i will gladly itemize as issues in jira ) . <nl> currently , the behavior is as follows ( this is also included in the doc ) : <nl> when configured as a message queue consumer endpoint , the endpoint will poll <nl> a message queue",0.9619835615158081
pentaho_pentaho-kettle/7687,fix fo sub-job to be executed if execute every input row checked <para-sep> : ' < ' was changed to ' < = ' to make sure we iterate once in case execute every input row checkbox is checked : get the result row from rows based on iteration index if rows is not empty otherwise result row is null <nl> this check is for avoiding outofboundexception in next statement as iteration < = rows.size ( ) condition is not leaving while loop after processing the last row . otherwise if iteration == rows.size ( ) indicates that we processed already the last row and just need to break from the loop,fix fo sub-job to be executed if execute every input row checked,1600710519,- the 'minimal width ' button ported to actual text file input step <nl> - textfileinputdialogtest switched from deprecated to actual text file input step,0.9155954122543335
elastic_elasticsearch/73434,add product response header to all responses,"this pr adds a header to all elasticsearch responses that confirms the type of service operating on the other end of the connection . this will aid in validating client-server connections to ensure protocol compatibility between requestors and the server . <nl> the header returns from all requests ( except unauthenticated ones ) and its format is as follows : . <nl> edit : updated the default casing of the header , updated that it is not returned on unauthenticated requests .",1622054206,add debug logging of the autoscaling capacity api reponse .,0.9126521944999695
apache_pulsar/11110,fix getlistinbundle return all topics in bundle <cm-sep> fix unit test,"0 . <nl> in nonpersistenttopics should only return the list of non-persistent topics under a namespace bundle . <nl> but now it returns all the topics . <nl> 0 . <nl> now it will traverse all topics on broker . when there are a lot of topics , timeouts often occur . <nl> i will support getting all topics or only persistent topics in another pr .",1624692670,"- right now , broker does n't validate dynamic-configuration value before updating it to zookeeper . so , user may update configuration with typo . <nl> - also , broker should validate dynamic-config value while starting in order to avoid picking up invalid value . <nl> eg : if someone has dynamic-config present for in old release and .0 has changed the classname then broker startup should notify invalid config value . <nl> - do dynamic-config validation before updating it <nl> - validate dynamic-config value on broker startup <nl> right now , we just have validation on configuration . <nl>",0.947655439376831
ballerina-platform_ballerina-lang/27436,fix compiler plugin for service-decl . <nl> and re-enable compiler plugin tests <para-sep> skip service classes generated for service-decl as they are processed via service annot . <nl> this class tests the compiler plugin implementation . <nl> test service events <nl> test struct events <nl> test function events,fix compiler plugin for service-decl and re-enable compiler plugin tests . <nl> fixes # .,1607604862,add test cases for uniquelengthwindow .,0.9471396207809448
elastic_elasticsearch/72788,make large bulk snapshot deletes more memory efficient . <nl> use an iterator instead of a list when passing around what to delete . <nl> in the case of very large deletes the iterator is a much smaller than <nl> the actual list of files to delete ( since we save all the prefixes <nl> which adds up if the individual shard folders contain lots of deletes ) . <nl> also this commit as a side-effect adjusts a few spots in logging where the <nl> log messages could be catastrophic in size when trace logging is activated . <para-sep> track up to 0 failed blob deletions for the exception message below <nl> we are sending quiet mode requests so we ca n't use the deleted keys entry on the exception and instead first remove all keys that were sent in the request and then add back those that ran into an exception . <nl> the aws client threw any unexpected exception and did not execute the request at all so we do not remove any keys from the outstanding deletes set .,use an iterator instead of a list when passing around what to delete . <nl> in the case of very large deletes the iterator is a much smaller than <nl> the actual list of files to delete ( since we save all the prefix repetition in strongly <nl> referenced blob names which adds up if the individual shard folders contain lots of deletes ) . <nl> also this commit as a side-effect adjusts a few spots in logging where the <nl> log messages could be catastrophic in size when trace logging is activated .,1620281424,"this change was mainly triggered by the need for to pass during its constructor when creating . also , is carried around in some places where only a subset of it is needed . <nl> with this change we rather carry around the components that are strictly needed , in a couple of cases functions that provides , which helps clarifying the dependency between , and , as well as removing the need for mapperservice to pass to . <nl> some more details about the choices made : . <nl> - avoid carrying documentmapperparser around ( and expose it through",0.9649878740310669
apache_shardingsphere/10351,add task finish method <cm-sep> invoke executeprocessengine.finish ( executionid ) <cm-sep> impl executeprocessreporter.finish ( executionid ) <cm-sep> enable ddl execute process <cm-sep> cleanup execute_id thread local variable <para-sep> report execute process . <nl> execute process report event . <nl> todo load query header for first query <nl> clean . <nl> finish . <nl> report this task on completion .,changes proposed in this pull request : <nl> - add task finish method <nl> - invoke executeprocessengine.finish ( executionid ) <nl> - implement executeprocessreporter.finish ( executionid ) <nl> - cleanup execute_id thread local variable <nl> - enable ddl execute process,1621059556,- shutdown proxy thread pool when channel was closed . <nl> - add atomikos usertransaction for sharding-proxy .,0.9569799304008484
apache_flink/15406,"move copied hive classes to a separate package <cm-sep> add more hive code <para-sep> counterpart of hive 's org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.hivebetween . * / <nl> operand type-inference strategy where an unknown operand type is derived from the first operand with a known type , but the first operand is a boolean . <nl> find whether we should execute the current query due to explain . <nl> counterpart of hive 's org.apache.hadoop.hive.ql.lib.defaultgraphwalker . * / <nl> opstack keeps the nodes that have been visited , but have not been dispatched yet <nl> opqueue keeps the nodes in the order that the were dispatched . then it is used to go through the processed nodes and store the results that the dispatcher has produced ( if any ) <nl> towalk stores the starting nodes for the graph that needs to be traversed <nl> dispatch the current operator . <nl> returns dispatch result <nl> starting point for walking . <nl> some walkers extending defaultgraphwalker e.g . forwardwalker do not use opqueue and rely uniquely in the towalk structure , thus we store the results produced by the dispatcher here todo : rewriting the logic of those walkers to use opqueue <nl> store the results produced by the dispatcher <nl> walk the current operator and its descendants . <nl> push the node in the stack <nl> while there are still nodes to dispatch ... <nl> dispatch current node <nl> add a single child and restart the loop <nl> counterpart of hive 's org.apache.hadoop.hive.ql.plan.exprnodecolumnlistdesc . * / <nl> column or constant <nl> counterpart of hive 's org.apache.hadoop.hive.ql.plan.exprnodesubquerydesc . * / <nl> subquerytype . * / <nl> rexnode corresponding to subquery . * / <nl> counterpart of hive 's org.apache.hadoop.hive.ql.lib.expressionwalker . * / <nl> we should bypass subquery since we have already processed and created logical plan ( in genlogicalplan ) for subquery at this point . subqueryexprprocessor will use generated plan and creates appropriate exprnodesubquerydesc . <nl> subquery either in where in form or where exists form in first case lhs should not be bypassed <nl> walk the current operator and its descendants . * / <nl> push the node in the stack <nl> while there are still nodes to dispatch ... <nl> dispatch current node <nl> add a single child and restart the loop <nl> counterpart of hive 's org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.hiveextractdate . <nl> counterpart of hive 's org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.hivefloordate . * / <nl> monotonic iff its first argument",copy more code from hive and move them to a dedicated package . <nl> - move the copied hive classes to package <nl> - copy more hive code . <nl> existing tests . <nl> na . <nl> na,1616998967,"add support csvrowdatadeserializationschema and csvrowdataserializationschema for the new data structure rowdata . this will be used by new tablesource and tablesink connectors . <nl> the implemented csv schema feature aligns with the exsiting ones . <nl> - for deserialize csv into . <nl> - for serialize into csv . <nl> - ported tests from to . <nl> - dependencies ( does it add or upgrade a dependency ) : yes <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths (",0.9882937669754028
Alluxio_alluxio/12501,add ufs version validation task <para-sep> get a list of supported versions for a particular ufs path . <nl> copy properties to not modify the original conf . <nl> unset the configuration to make sure any supported factories for the path are returned . <nl> check if any versioned factory supports the default configuration <nl> this validates the ufs configuration for a users configured ufs path . it ensures that the version of the ufs library is available ( if configured ) .,"this new task helps expose some more information about available ufs versions to users . the cases for configuration and corresponding outputs are defined below . <nl> - ufs version not configured : skip validation <nl> - ufs version configured , but does n't exist in list of valid versions : error with info and list of available versions <nl> - ufs version configured , but list of versions empty : this indicates the ufs does n't support versioning ( i.e . non-hdfs ) , and directs the user to change configuration <nl> - ufs version configured and exists in",1605247690,"skipping data from an inputstream used to fetch data from remote storage . now instead , a new stream is opened starting at the desired position .",0.9586177468299866
eclipse-openj9_openj9/13040,java preprocessor : recognize '-nowarnincludeif ' option . <cm-sep> add jpp configuration 'ddr_vm ' . <para-sep> [ if platform-mz31 | platform-mz64 ] * / <nl> platform-mz31 | platform-mz64 * / <nl> note : ibm java 0 builds do not use the preprocessor so the [ if ] condition is ignored : this must have the proper control flow ignoring those comments . [ if platform-mz31 | platform-mz64 ] * / <nl> platform-mz31 | platform-mz64 * /,* update preprocessor to recognize '-nowarnincludeif ' option <nl> * add ddr_vm preprocessor configuration <nl> * update ddr_vm code with necessary preprocessor conditions <nl> * remove stub implementation of zfile .,1624454955,com.ibm.oti.reflect . * is mostly unused except for the <nl> annotation parsers . delete the unused method/field/ <nl> constructor implementations and leave the annotation <nl> forwarders . <nl> further cleanup here may be possible .,0.9081375002861023
netty_netty/11195,"improve usability . <nl> __motivation__ . <nl> constructor calls internally which disallows using certain methods on the builder later . additionally , the constructor is package private which limits extension of the as well as usage outside the available and static methods . <nl> __modification__ . <nl> - introduce a no-arg constructor to . <nl> - increase visibility of constructor to to allow extensions of to instantiate the codec . <nl> __result__ . <nl> can now be used to create the codec with or and which was earlier not possible due to implicit call to by the constructor .","__motivation__ . <nl> constructor calls internally which disallows using certain methods on the builder later . additionally , the constructor is package private which limits extension of the as well as usage outside the available and static methods . <nl> __modification__ . <nl> - introduce a no-arg constructor to . <nl> - increase visibility of constructor to to allow extensions of to instantiate the codec . <nl> __result__ . <nl> can now be used to create the codec with or and which was earlier not possible due to implicit call to by the constructor .",1619469321,motivation : . <nl> grpc ( and potentially other libraries ) has an optimized header processor that requires direct access to the hpackdecoder . <nl> modifications : . <nl> make the hpackdecoder and its constructors public . <nl> result : .,0.8526597619056702
apache_shardingsphere/10287,move the user configuration to authority rule,changes proposed in this pull request : <nl> - move the user configuration to authority rule and fix unit test .,1620554211,changes proposed in this pull request : <nl> - move out taskid from configuration <nl> - use jobid replace taskid in shardingscalingjob <nl> - use synctaskid replace taskid in datasynctask,0.9679224491119385
apache_beam/14372,"add support for bigquery 's bignumeric ( for paths where the schema is specified ) <cm-sep> lint fixes <para-sep> decimalconversion.tobytes returns a bytebuffer , which can be mutated by callees if passed to other methods . we wrap the byte array as a bytebuffer before adding it to the genericrecords . <nl> bigquery encodes numeric and bignumeric values to avro using the bytes type with the decimal logical type . avrocoder ca n't apply logical types to schemas directly , so we need to get the <nl> in order to update the schema for numeric and bignumeric values , we need to recreate all of the fields . birthdaymoney is nullable field with type bytes/decimal . <nl> lotterywinnings is nullable field with type bytes/decimal .",this change adds bignumeric support in the java beam connector specifically for the path where the table 's schema is specified by the user ( and does not need to inferred ) . <nl> the inference path and support for the python connector shall be added in follow-up prs,1617117040,"i wish to be able to write bytes type fields to bigquery . <nl> in bigqueryutils ( sdks/io/google-cloud-platform ) when serialising a bytes type beam field for bq there is a faulty cast to java.nio.bytebuffer while the value will always be a primitive byte array ( see org.apache.beam.sdk.values.row.builder # verifyprimitivetype ) . <nl> trying to use bigqueryutils when writing a bytes field to biqquery will cause <nl> ` <nl> java.lang.classcastexception : [ b can not be cast to java.nio.bytebuffer at org.apache.beam.sdk.io.gcp.bigquery.bigqueryutils.frombeamfield ( bigqueryutils.java:0 ) <nl> ` <nl> and the added tests in bigqueryutilstest will trigger this , and the changes",0.925487756729126
apache_incubator-pinot/7053,fix bug for aggregatemetrics rule in recommendation engine <para-sep> keep in mind that the group-by columns that appear in selection are ok and do n't need to be inside sum functions . <nl> acceptable case ; skip,"it misses the fact that for group-by queries , groupby columns appear in selection with no function and that 's a valid case for which aggergatemetrics can be turned on . this pr checks that scenario and acts accordingly .",1623447860,"during the onboard process , one missing component is the ability to check the replay execution status . after function set-up , the replay is triggered . a detection job is triggered , and tasks are generated to perform analyses . the front-end then can check the status through this end-point to get the status of the job . once the job is completed , the alerts or the auto-tune can be triggered afterward . <nl> - enable detection jobs to return job ids . <nl> - implement an endpoint to check the job status",0.9608232378959656
apache_shardingsphere/10255,fix oracle like query parse exception <para-sep> create literal expression .,changes proposed in this pull request : <nl> - fix oracle & sql92 like query parse exception,1620281310,changes proposed in this pull request : <nl> - fix format for variable . <nl> - adjust set grammar .,0.9300684332847595
elastic_elasticsearch/73940,set parsesarrayvalue to true for shape field mappers <para-sep> gets the formatter by name .,"currently parsesarrayvalue is set to true for point field mappers and false for shape mappers . we oversee that in some cases , it might be better if the current mappers can work with the whole array so let set the value to true for shape field mappers . this simplifies the implementation as well .",1623223868,"implemented method that would automatically register a default aggregator implementation for any . although , this was a very powerful feature , it was not very flexible , as there was no way to override the default aggregator for one or more s. . <nl> the aggregations that used the method so far were : , and . <nl> in this pr we remove the method and replace it with explicitly registering all with their aggregator . this means that all classes are registered explicitly with their aggregators ( for , and ) . <nl> for the sub-classes of that",0.8688141703605652
quarkusio_quarkus/16695,"upload surefire reports when build is failing or cancelled <cm-sep> more consistency for the step names , job name is already descriptive <cm-sep> attempt to fix the kafka ci issues . <nl> today , we are starting three brokers side-by-side , which include three kafka instances and three zookeeper instances . that may be too much and may lead to unexpected issues . <nl> this commit split the tests into three different modules : . <nl> - kafka verifies the typical kafka behavior ( producer , consumer , codecs ... ) <nl> - kafka-ssl verifies the connection with ssl <nl> - kafka-sasl verifies the connection with sasl . <nl> each of them starts a single broker with a specific configuration . <nl> ( cherry picked from commit sha ) <cm-sep> rewrote kafka ssl tests . <nl> * the previous code was actually not configured ssl consistently <nl> * switch to test container ( strimzi containers ) <nl> * configure the native test to actually use ssl . <nl> ( cherry picked from commit sha ) <cm-sep> rewrote kafka sasl tests . <nl> - switch to test containers ( using strimzi containers ) <nl> - make sure sasl is configured consistently . <nl> ( cherry picked from commit sha ) <cm-sep> switch from debezium to test containers to start the kafka brokers . <nl> debezium requires kafka and scala which lead to issues when updating these libraries ( alignment ) . <nl> ( cherry picked from commit sha ) <para-sep> endpoint to check the ssl/sasl connection . <nl> used by the test <nl> used by the application <nl> use a fixed port container to ease sasl configuration . <nl> sort kafka version from low to high <nl> exposing kafka port from the container <nl> we need it for the startzookeeper ( ) ; and startkafka ( ) ; to run container before ... <nl> endpoint to check the ssl connection . <nl> used by the test <nl> used by the application <nl> sort kafka version from low to high <nl> exposing kafka port from the container <nl> we need it for the startzookeeper ( ) ; and startkafka ( ) ; to run container before ... <nl> used by the application <nl> sort kafka version from low to high <nl> exposing kafka port from the container <nl> we need it for the startzookeeper ( ) ; and startkafka ( ) ;","this is a test to backport some infrastructure related changes to version as kafka tests do n't work there anymore either . <nl> please do n't merge , i will merge it myself .",1619021887,- the logic was moved from resteasy standalone <nl> - thanks to that static resources are served even for vertx-web,0.9743215441703796
elastic_elasticsearch/74323,this reverts commit sha . <cm-sep> documentation <para-sep> if > is <nl> > > > <nl> use a proxy endpoint * <nl> use a custom endpoint * <nl> manually update your geoip2 databases *,this change will enable geoip downloader by default again . it also brings back relevant documentation .,1624033263,"constructing the timout checker first and then registering the watcher allows the test to have a race condition . <nl> the timeout value could be reached before the matcher is added . to prevent the matcher never being interrupted , a new value is added to the watcher thread entry . then when a new matcher is registered , if the thread was previously timedout , we interrupt the matcher immediately .",0.8760398030281067
apache_druid/10732,"add a config for monitorscheduler type <cm-sep> check interrupted <para-sep> run one more time even if the monitor was removed , in case there 's some extra data to flush <nl> do nothing if the monitor is still running . <nl> monitorfuture must be done at this moment if it 's not null <nl> monitor.monitor ( ) is called 0 times since a new task is scheduled first and then the current one is executed . see scheduledexecutors.scheduleatfixedrate ( ) for details . <nl> monitor.monitor ( ) is called 0 times since a new task is scheduled first and then the current one is executed . see scheduledexecutors.scheduleatfixedrate ( ) for details . <nl> a real executor service to execute crontask asynchronously . many tests in this class use mocks to easily control the behavior of cronscheduler and the executorservice used by monitorscheduler . however , as monitorscheduler uses two differnt threads in production , one for scheduling a task to schedule a monitor ( cronscheduler ) , and another for running a scheduled monitor asynchronously , these tests also require to run some tasks in an asynchronous manner . as mocks are convenient enough to control the behavior of things , we use another executorservice only to run some tasks asynchronously to mimic the nature of asynchronous execution in monitorscheduler .","this change looks good to me except that i 'm not sure how well-tested is . this pr adds the previous -based back , and a new config , , to determine what type of to use . this pr also changes the default back to . some brave users may want to explore the new . the new config is intentionally not documented as we will get rid of it once the new scheduler is proven to be safe . however , it should be called out in the release notes . <nl> this pr additionally fixes 0 bugs",1609986506,"adds additional tests to bring all implementations in extension to near 0 % coverage ( i got lazy and did n't add tests for some of the boring comparators ) . i replaced some and implementations which allowed subclasses of different types to test as equal since i do n't think that is what we really want , with intellij generated versions . <nl> more prs to follow to do the same for other implementations .",0.9754462242126465
elastic_elasticsearch/74472,"make document a top-level class . <nl> there is no reason for document to be an inner class of parsecontext , especially as it is public and accessed directly from many different places . <nl> this commit takes it out to its own top-level class file , which has the advantage o simplifying parsecontext that can use some love too . <para-sep> return the path associated with this document . <nl> return a prefix that all fields in this document should have . <nl> return the parent document , or null if this is the root document . <nl> either a meta fields or starts with the prefix","there is no reason for document to be an inner class of parsecontext , especially as it is public and accessed directly from many different places . <nl> this commit takes it out to its own top-level class file , which has the advantage o simplifying parsecontext that can use some love too .",1624440179,"now that all our fieldmapper implementations extend parametrizedfieldmapper , <nl> we can collapse the two classes together , and remove a load of cruft from <nl> fieldmapper that is unused . in particular : . <nl> * we no longer need the lucene fieldtype field on fieldmapper <nl> * we no longer use for merging , so we can remove it from all impls <nl> * the serialization code in fieldmapper that assumes we 're looking at text fields can go",0.928269624710083
ballerina-platform_ballerina-lang/29884,"refactor runtime to use tool api diagnostics <cm-sep> refactor runtime diagnostics impl <cm-sep> codegen location to configurable variable <cm-sep> merge master branch and fix conflicts <cm-sep> add location to error messages of config tests <para-sep> a diagnostic represents a error , a warning or a message related to runtime . <nl> represent the location of a diagnostic at runtime . <nl> a diagnostic log manages the runtime diagnostics . <nl> test cases for runtime diagnosis . <nl> config array value which is not supported as cli arg <nl> config record value which is not supported as cli arg <nl> config table value which is not supported as cli arg","please refer to the following sample . <nl> ballerina project . <nl> main.bal . <nl> mod1 : mod1/bal . <nl> with the above improvement , the error message will be output as below . <nl> bal run -- -ca=sometext <nl> output .",1617778816,this pr is to support passing custom headers with grpc message and handle in both client and server side . following changes are done to support custom headers . following will be supported from this fix . <nl> server side header support <nl> ` . <nl> client side header support <nl> `,0.9836869239807129
prestodb_presto/16146,add iceberg connector to devel configs <cm-sep> fix partitionmutator not bound error during server start,add iceberg to the devel config in presto-main <nl> fix load iceberg module failure when connecting hive-metastore .,1621805694,we have seen those 0 types of transient failures in nightly verifier runs .,0.8346816301345825
quarkusio_quarkus/18106,enable the generation of documentation for extensions whose package name contains 0 specific components . <nl> because i 'm going to introduce an extension named <nl> ... <cm-sep> remove some dead code in docgeneratorutil,"because i 'm going to introduce an extension named . yes that 's a mouthful , but considering it 's an integration into the existing , there is n't much choice in how to name it .. . <nl> the change is quite similar to sha , so i expect it should be safe ? <nl> note i also tried the pattern as an alternative , but it does n't work : it seems capturing groups in non-capturing groups are ignored for some reason .",1624452507,"maven version and earlier does not seem to correctly resolve exclusions <nl> and dependency management in dependencies . <nl> the element in particular is heavily used in in <nl> gradle-generated poms , and is apparently ignored by maven when <nl> computing transitive dependencies . <nl> this can lead maven-enforcer-plugin to witness multiple dependencies <nl> to the same artifact with different versions , which breaks the <nl> dependency convergence rule and fails the build . <nl> in our case , the only affected transitive dependencies are declared by <nl> the elasticsearch rest client , which we depend on in the elasticsearch",0.7697791457176208
confluentinc_ksql/7526,add qtt cases for fk-join with flipped join condition,"add new tests for fk-joins with ' flipped ' join condition . luckily take care of the order by calling if necessary , and thus we do n't need to write additional code for fk-joins for this case . however , we should have the corresponding tests . <nl> not sure if we should add tests for n-way joins at this point , as do n't plan to support n-way joins yet .",1620975734,temporarily changed the kafkfatopicclientimpl to address the issue from reusing the adminclient . will change back after the adminclient issue is fixed .,0.8567003011703491
Alluxio_alluxio/12714,"fix tmp file issue <cm-sep> move tmp file to subdir of mount point <para-sep> use concatpath to join path if base is not starting with // <nl> get temp path for async persistence job . <nl> join base without trailing ' / ' <nl> join base with trailing ' / ' <nl> redundant separator must be trimmed . <nl> get temporary path <nl> get temporary path with root path <nl> make temp path for temp file to avoid the error reading ( failure of temp file clean up ) <nl> check if the destination direction is valid , if there is n't exist directory , create it and it 's parents <nl> create parent path if there is n't exiting ancestors path for final persistence file . <nl> get file path <nl> get the parent path of current file <nl> stop when the directory already exists in ufs . <nl> ufs mkdirs might fail if the directory is already created . if so , skip the mkdirs and assume the directory is already prepared , regardless of permission matching .","currently , alluxio writes the temporary file of async persistence to the path , which is the same as the destination file path . the computing framework , like presto , will pick up the tmp files , which is leftover there for some reason , fail to clean up , etc . <nl> this change writes the tmp file of async persistent to the sub dir of the mount point .",1610563354,"- web ui should be able to show all alluxio-related configurations and fsadmin report configuration should be able to show all configurations . <nl> - we have a merge function to merge to our map . <nl> - however , map actually do not need to store default property key value pairs , so someone delete the codes to merge to map . the can use to get default value of this key . can use to know that this key exists . <nl> - map now only store systemproperties , siteproperties and some of the properties that we set",0.9548199772834778
confluentinc_ksql/7499,update joins to allow lack of pre-join repartition,"this pr only affects foreign key joins ( still under development , hidden behind a feature flag ) . this pr updates prejoinproject to accommodate this rather than the current behavior which is to throw an error . <nl> local qtt with feature flag enabled . ( qtt for foreign key join still does not pass since the feature is n't complete yet , but the previous error that was thrown in prejoinproject is no longer thrown . )",1620770305,moved out of the same try catch block as the rest of the transaction operations . <nl> added more specific error message . ( added as a pluggable one for scenarios where it does n't make sense to advise the user to set their kafka configs ) .,0.9125580191612244
vespa-engine_vespa/18105,"support mulitple endpoints , circuit breaker , and improve concurrency <cm-sep> parse responses <para-sep> send a document put with the given parameters , returning a future with the result of the operation . * / <nl> send a document update with the given parameters , returning a future with the result of the operation . * / <nl> send a document remove with the given parameters , returning a future with the result of the operation . / shut down , and reject new operations . operations in flight are allowed to complete normally if graceful . / <nl> initiates graceful shutdown . * / <nl> controls what to retry , and how many times . / allows slowing down or halting completely operations against the configured endpoint on high failure rates . / <nl> called by the client whenever a successful response is obtained . * / <nl> called by the client whenever a transient or fatal error occurs . * / <nl> the current state of the circuit breaker . * / <nl> circuit is closed : business as usual . * / <nl> circuit is half-open : something is wrong , perhaps it recovers ? * / <nl> circuit is open : we have given up . * / <nl> a document put operation . this is idempotent . * / <nl> a document update operation . this is idempotent if all its contained updates are . * / <nl> a document remove operation . this is idempotent . * / <nl> sets the number of connections this client will use per endpoint . <nl> breaks the circuit when no successes have been recorded for a specified time . <nl> todo : what to do with exceptions here ? ex on 0 , 0 , 0 , etc , and wrap and throw ? <nl> todo : update doc <nl> sleep when circuit is half-open , nap when queue is empty , or we are throttled . <nl> forcibly terminates this , causing all inflight operations to complete immediately . * / <nl> wait for all inflight requests to complete . * /","this got a bit jumbled up . the changes are : . <nl> 0. avoid locking . <nl> 0. dispatch from a dedicated thread ( or user thread ) . <nl> 0. queue up excess inflight requests if throttled . <nl> 0. add configurable circuit breaker , which allows client to go to ping mode , causes it to shut down if fully opened . <nl> 0. add to wait until nothing is in flight . ( may want to change semantics here , await/close meh ) <nl> 0. support multiple endpoints . <nl> 0. parse json response from /document/v1",1622725503,"i do n't recommend reading the individual commits , only the end result .",0.9907730221748352
vespa-engine_vespa/17780,check for query timeout before dispatching streaming search query,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620401222,proxy nodes need to talk to each other as they 're part of the same application/cluster .,0.8726959824562073
apache_flink/15308,"update type of hivetablepartition # partitionspec from map to map <para-sep> parse partition string specs into object values . * / <nl> this keeps align with hive , maybe it should be null for string columns as well <nl> * / <nl> * / <nl> convert flink logicaltype to hive typeinfo . for types with a precision parameter , e.g . timestamp , the supported precisions in hive and flink can be different . therefore the conversion will fail for those types if the precision is not supported by hive and checkprecision is true . <nl> * /","in order to support watermark for hive connector ( ) , we need to extract time from the partition string values . however , currently uses type to store the partition spec which is hard convert back to string values . therefore , i propose to use the raw type instead which is easier to convert into when needed . <nl> - update type of from to . <nl> this change is a trivial rework which can be covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no",1616341551,"splits into and . the latter should use indices of input and field within input as a reference rather than simply always looking up field by name . <nl> proper use of the fieldreferenceexpression is not part of this pr . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : (",0.955112099647522
apache_flink/15597,use the latest checkpoint in unalignedcheckpointtests,"iterates over the checkpoints to return a completed one . <nl> currently , during the iteration the cluster is n't shut down so it can concurrently remove any files read . <nl> with this change , cluster is shut down first and then checkpoint is collected . <nl> this change is a trivial rework without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record",1618321517,"modifies the to not blanket-wrap all exceptions in a , syncing the behavior with the . this prevented stacktraces from being forwarded to users . <nl> additionally contains a small hotfix to improve logging message when dealing with unhandled exceptions .",0.8420032858848572
quarkusio_quarkus/17784,"attempt to fix ct intermittent failures . <nl> continuous testing tests can fail sometimes as an <nl> additional unexpected run is triggered . this is because <nl> a write is actually two seperate operations , a truncate <nl> followed by a write , so the update processor can see this <nl> as two seperate changes and trigger two seperate test <nl> runs ( depending on the timing ) . this fixes it by re-checking <nl> the timestamps after compilation , and also attempting to <nl> re-compile if they do n't match . <para-sep> so this is pretty yuck , but on a lot of systems a write is actually a truncate + write its possible we see the truncated file timestamp , then the write updates the timestamp which will then re-trigger continuous testing/live reload the empty fine does not normally cause issues as by the time we actually compile it the write has completed ( but the old timestamp is used ) <nl> give time for the write to complete note that this is just 'best effort ' the file time may have already been updated by the time we get here <nl> ignore <nl> now we record the timestamps as they are before the compile phase <nl> check to make sure no changes have occurred while the compilation was taking place . if they have changed we update the timestamp in the compile time set , and re-run the compilation , as we have no idea if the compiler saw the old or new version <nl> now we re-update the underlying timestamps , to the values we just compiled if the file has changed in the meantime it will be picked up in the next scan <nl> a write can be a 'truncate ' + 'write ' if the file is empty we may be seeing the middle of a write <nl> ignore <nl> re-read , as we may have read the original ts if the middle of a truncate+write , even if the write had completed by the time we read the size <nl> should never happen","improve continuous test/dev mode output <nl> - fix output if no tests run <nl> - display time test were run <nl> - remove compiling log message , replace with message for test/dev mode <nl> restart with changed classes . <nl> - do n't count skipped tests towards the number run .",1623214903,this pull request addresses the following issues : . <nl> and adds two improvements : . <nl> - remove unused imagestream when using non default builder image ( s2i ) <nl> - improves the s2i build log display .,0.9547468423843384
apache_druid/10980,fix smile encoding bug . <cm-sep> add unit tests <para-sep> a 'null ' means the content-type in response defaults to content-type of request <nl> a encoder/decoder that encodes/decodes requests/responses based on content-type .,"/druid/v2 endpoint supports jackson smile encoding both for request and response . but there 's a bug there when processing a request with 'accept : application/x-jackson-smile ' header . <nl> current implementation takes 'accept ' parameter , which indicates server that smile encoding is accepted by client to decode the http response , to decode a json request . according to http protocol on 'content-type ' and 'accept ' , server should alway decode the body according to 'content-type ' header , while encode response by 'accept ' header ( if not provided , 'accept ' defaults to 'content-type '",1615456684,"this pull request introduces support for random sharding by estimating cardinality of input data set using hyperloglog and distributing the rows in shards on the basis on hashcode , random sharding has two major improvements over singledimension sharding - <nl> 0 ) better distribution of data resulting in almost equal sized partitions , thus achieving better query parallelism . <nl> 0 ) the mapper job for cardinality estimation does very less hadoop io and thus is much more efficient than single dimension sharding . <nl> changes - <nl> 0 ) support for random sharding <nl> 0 ) new partitionspec type",0.981208860874176
vespa-engine_vespa/17572,remove unused dependencies <cm-sep> remove old jaxrs resource definitions from orchestrator-restapi <cm-sep> remove old jaxrs resource definitions from vespa-athenz,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1619186137,"removes jax-rs interfaces from zone apis and , only used by internal cli tool . <nl> adds method from to that are used by controller components .",0.9682093858718872
hazelcast_hazelcast/18797,replace usages of teststream with generate_stream,"replaced usages of with - i will be changing to be able to support custom data , similarly to .",1622183109,"- fix metadataraftgrouptest snapshotting test : instead of blocking network communication completely , just drop append requests to force installing snapshot on follower . otherwise , we should handle various network split scenarios in the test . <nl> - reset known cp group leader when is received : is thrown when an invocation packet can not be sent to target . in that case , we should reset the known leader , because it might not be the leader anymore .",0.8183861374855042
Alluxio_alluxio/12593,increase default job capacity + increase default active jobs size,increase default active jobs size because this increases performance for smaller file size distributedcp/load cases without hurting the large files . ( the only increased cost is increased memory usage but the memory usage here is n't large . ),1606757649,replaced an integer literal with constants.gb when creating the localalluxioclusterresource object in filesystemaclintegrationtest .,0.6477245688438416
ballerina-platform_ballerina-lang/31293,bump to beta3 development version <cm-sep> avoid overriding terminator at trap expr <cm-sep> revert restriction for break/continue usage <cm-sep> set terminator unless its set within onfail <cm-sep> refactor onfail clause node <cm-sep> add onfail tests with brakes <cm-sep> desugar fail to a onfail statement expression <cm-sep> refactor desugar steps <cm-sep> add symbols within onfail to fail env <cm-sep> remove unused imports and revert version bump <para-sep> $ shouldpanic $ = true ; error $ trxerror $ = $ trapresult $ ;,"this is because each function is visited separately at the bir . <nl> this lead us to restrict the usage of statements that changed the flow of control across blocks such as break and continue within onfail/transaction . <nl> the scope entires are populated to the fail statement 's enclosing scope . <nl> > as we can have break/continue statements within onfail/transaction bodies , at bir generation the terminator for specific statements such as traps should only be set only if the terminator is not already set .",1624048420,also contains fixes for definition test failures .,0.9533600807189941
jenkinsci_jenkins/5337,"add a couple of admin monitors . <nl> warn against leaving executors configured on the controller , under two different scenarios . <cm-sep> add line endings .","running jobs on executors on the controller can have some negative consequences . they can compete for resources . as noted in the old documentation there can be security implications . ( this documentations needs to be migrated and updated but that 's separate from this current pr . ) unfortunately , administrators often do n't know about these concerns and leave executors configured on the controller . <nl> this pr adds two new admin monitors to warn admins . one is activated when there are no agents or clouds defined , recommending they be set up . the other",1614973862,"the variable is first defined in rss:0 but then overriden in functions.initpagevariables that 's call by the new tag introduced . <nl> to solve the problem , i am just using the existing which corresponds to . <nl> for sample files , please refer to the jira ticket . <nl> edit : the test covers especially the regression part and only this one in order to be ' quickly backported ' . a followup ticket was created to improve the test coverage in general in the rss area . this is not the focus of this ticket . <nl> *",0.9656680822372437
apache_beam/14840,allow config map to be passed to confluent schema registry client,this change allows a config map to be passed through to . it is now possible to pass authentication related properties for connecting to secured confluent schema registry instances,1621438111,fixes : insert values not working . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9078906774520874
elastic_elasticsearch/74177,dynamic templates do not correctly validate runtime field mappings <cm-sep> error out on bad runtime dynamic mappings in 7x <para-sep> in 0.x versions this will issue a deprecation warning <nl> in 0.x it will error out,"when a dynamic template is applied to a 0.x index , we do some validation checks <nl> against the generated mappings and issue a deprecation warning if the validation <nl> fails . we had some tests that were checking this at a low level , but nothing that <nl> exercised the full logic . <nl> when dynamic runtimes were added , we expected this behaviour to carry over ; <nl> however , a bug in building the parsercontext to pass to the runtime builder meant <nl> that we would instead always throw an error . in fact , erroring here",1623847344,"these additional tests verify that runtime fields do n't get lost when a dynamic mapping update comes in . also , wen rootobjectmapper gets cloned , its runtime fields map should be reset , or it will look as is the dynamic mapping update is adding the existing runtime fields while they were already defined .",0.930720865726471
elastic_elasticsearch/74230,"deprecate xpack and typed endpoints for graph explore api <para-sep> we 're not actually testing anything to do with the client , but need to set this so it does n't fail the test for being unset .",previously the api was indicating to use which is also deprecated . <nl> this commit deprecates all typed endpoints,1623928602,"if more than 0 shard-follow tasks are trying to connect to the remote <nl> cluster , then some of them will abort with ' connect listener queue is <nl> full ' . this is because we retry on esrejectedexecutionexception , but not <nl> on rejectedexecutionexception .",0.9102293848991394
vespa-engine_vespa/17069,assessor includes host assessments <para-sep> group impacted application nodes by parent host <nl> todo : some better heuristic for what 's considered problematic <nl> add tenant hosts <nl> add tenant hosts,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616152718,"before this pr , the plugin outputs 0 sets of packages when run with maven 's -x debug option : . <nl> r = referenced packages <nl> d = defined packages <nl> e = exported packages by dependencies . <nl> for the following we need to split d into : . <nl> d_p = defined packages in the project 's class files <nl> d_c = defined packages in the project 's compile scoped deps . <nl> this pr is a best effort to output sets of packages that can cause problems when the bundle is deployed in a jdisc container",0.9648095965385437
apache_shardingsphere/10742,add test case for ruleconfigurationcheckerfactory with ruleconfigurationchecker fixture <cm-sep> add test case for ruleconfigurationcheckerfactory with ruleconfigurationchecker fixture,changes proposed in this pull request : <nl> - add test case for ruleconfigurationcheckerfactory with ruleconfigurationchecker fixture,1623237956,"for postgresqlstatementmemorystrictlyfetchsizesettertest and mysqlstatementmemorystrictlyfetchsizesettertest , assertsetfetchsize and assertgettype added",0.9548482894897461
confluentinc_ksql/7331,scatter gather task metadata for query descriptions <para-sep> and the streams metadata task set,"if we ran a query where the source topic has two partitions and then got a querydescription of it , the description would only have 0 task metadata before this patch . now it has both . <nl> sample response with two ksqldb servers running .",1617233114,prep work for some other minor clean up prs that want to use the walker to build up state along the way .,0.9380001425743103
apache_kafka/10300,: remove deprecated overloads of processorcontext # forward . <nl> processorcontext # forward was changed via in version release . this pr removes the old and deprecated overloads .,processorcontext # forward was changed via in version release . this pr removes the old and deprecated overloads .,1615431964,"0. let to call on underlying bytes store directly , using the more restricted range . <nl> 0. fix the conservative upper range for multi-key range in session schema . <nl> 0. minor : removed unnecessary private wrappedsessionstorebytesiterator class as it is only used in unit test . <nl> 0. minor : removed unnecessary schema # init function by using the direct bytes-to-binary function .",0.9185991287231445
elastic_elasticsearch/73036,"mappinglookup has a method simplematchtofieldname that attempts <nl> to return all field names that match a given pattern ; if no patterns match , <nl> then it returns a single-valued collection containing just the pattern that <nl> was originally passed in . this is a fairly confusing semantic . <nl> this pr replaces simplematchtofullname with two new methods : . <nl> * getmatchingfieldnames ( ) , which returns a set of all mapped field names <nl> that match a pattern . calling getfieldtype ( ) with a name returned by <nl> this method is guaranteed to return a non-null mappedfieldtype <nl> * getmatchingfieldtypes , that returns a collection of all mappedfieldtypes <nl> in a mapping that match the passed-in pattern . <nl> this allows us to clean up several call-sites because we know that <nl> mappedfieldtypes returned from these calls will never be null . it also <nl> simplifies object field exists query construction . <para-sep> check the ancestor of the field to find nested and object fields . runtime fields are excluded since they can override any path . todo find a way to do this that does not require an instanceof check <nl> we added this path on another field already <nl> checks if the parent field contains sub-fields <nl> no field type , it must be an object field <nl> returns all the mapped field types that match a pattern note that if a field is aliased and both its actual name and its alias match the pattern , the returned collection will contain the field type twice . <nl> no wildcards <nl> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field <nl> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field <nl> returns all the mapped field types that match a pattern note that if a field is aliased and both its actual name and its alias match the pattern , the returned collection will contain the field type twice .","mappinglookup has a method simplematchtofieldname that attempts <nl> to return all field names that match a given pattern ; if no patterns match , <nl> then it returns a single-valued collection containing just the pattern that <nl> was originally passed in . this is a fairly confusing semantic . <nl> this pr replaces simplematchtofullname with two new methods : . <nl> * getmatchingfieldnames ( ) , which returns a set of all mapped field names <nl> that match a pattern . calling getfieldtype ( ) with a name returned by <nl> this method is guaranteed to return a non-null mappedfieldtype",1620903598,adds deleting multiple snapshots in one go without significantly changing the mechanics of snapshot deletes otherwise . <nl> this change does not yet allow mixing snapshot delete and abort . abort is still only allowed for a single snapshot delete by exact name .,0.9758730530738831
vespa-engine_vespa/17480,"add more logging . <nl> * make it possible to track which location broker <nl> various components are registered with or <nl> mirroring information from . <nl> * most of these log messages should now look the same <nl> in the java and c++ implementations <para-sep> check if a certain delay should result in an information message logged . <nl> note : since this happens quite often during normal operation , the level is lower than the more-natural level.warning :",* make it possible to track which location broker <nl> various components are registered with or <nl> mirroring information from . <nl> * most of these log messages should now look the same <nl> in the java and c++ implementations . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618819661,"add support for serializing and compressing once , instead of once per backend node .",0.9449626207351685
apache_beam/14354,"add test for complex flat schema <para-sep> example : row [ ] transactions { string [ ] banks , double purchaseamount } - > string [ ] [ ] transactions_banks , double [ ] transactions_purchaseamount <nl> example : row [ ] transactions { row [ ] banks { string name string address } , double purchaseamount } - > string [ ] [ ] transactions_banks_name , string [ ] [ ] transactions_banks_address , double [ ] transactions_purchaseamount",fixed for nested array fields . <nl> test case :,1617031543,this pr also adds some zetasql unit tests that expose the previous bug .,0.9145253896713257
jenkinsci_jenkins/5402,do minimal checking for isempty ( ),"instead of checking every node , when possible simply return fast instead of calculating the cached value . <nl> this does alter its behaviour somewhat but not to the point its contracts are changed . <nl> tested with a simple test . <nl> , reduce queue-lock contention when creating or deleting nodes",1617890398,note : jenkins currently ignores form validation errors for all fields when changing job configuration . so job configuration can be saved in an erroneous state . the errors are retained when the configure page is revisited .,0.9399760365486145
vespa-engine_vespa/17880,do n't setup metrics proxy container for tester instances,"i guess we do n't need metrics proxy for tester instances ? they are shortlived and i 'm not sure if anyone ever look at metrics for them ? removing it will save some time starting vespa on the node , since this is run on a node with few resources and starting a container requires some cpu seconds",1621344335,seems we end up doing the same thing as for hwfailure most of the time,0.8466679453849792
apache_incubator-pinot/6354,"ingestion resource with apis for ingestion via file/uri <cm-sep> remove extra spaces <para-sep> apis related to ingestion ingest data into the tablenamewithtype using the form multipart file /ingestfromfile ? tablenamewithtype=foo_offline & batchconfigmapstr= { ' inputformat ' : ' csv ' , ' recordreader.prop.delimiter ' : ' | ' } ingest data into the tablenamewithtype using the source file uri /ingestfromuri ? tablenamewithtype=foo_offline & batchconfigmapstr= { ' inputformat ' : ' json ' , ' input.fs.classname ' : ' org.apache.pinot.plugin.filesystem.s3pinotfs ' , ' input.fs.prop.region ' : ' us-central ' , ' input.fs.prop.accesskey ' : ' foo ' , ' input.fs.prop.secretkey ' : ' bar ' } & sourceuristr=s3 : //test.bucket/path/to/json/data/data.json <nl> directory to use under the controller datadir . controller config can be added for this later if needed . <nl> api to upload a file and ingest it into a pinot table . this call will copy the file locally , create a segment and push the segment to pinot . a response will be returned after the completion of all of the above steps . all steps happen on the controller . this api is not meant for production environments/large input files . for production setup , use the minion batch ingestion mechanism <nl> api to ingest a file into pinot from a uri . this call will copy the file locally , create a segment and push the segment to pinot . a response will be returned after the completion of all of the above steps . <nl> a driver for the ingestion process of the provided file . responsible for copying the file locally , building a segment and uploading it to the controller . <nl> creates a segment using the provided data file/uri and uploads to pinot <nl> setup working dir <nl> copy file to local working dir <nl> build segment <nl> tar and push segment <nl> enum to identify the source of ingestion file <nl> wrapper around file payload <nl> helper methods for ingestion from file <nl> copy the file from given uri to local file <nl> copy the file from the uploaded multipart to a local file <nl> using current time as postfix to prevent overwriting segments with same time ranges <nl> uploads the segment tar files to the provided controller <nl> tests for the ingestion restlet <nl> add schema & table <nl> create a file with few records <nl> ingest from file <nl>","these are meant for quick testing/trials , and not intended for production usage . we will be using these in the cluster manager to introduce a ' test a file ' flow . <nl> file ingest . <nl> uri ingest <nl> note : <nl> 0. the fs details only need to be provided if scheme is not already registered . <nl> 0. credentials will by default be taken from local aws credentials .",1608003592,this pr is involved with the redesign of alert . the email formatter allow users to customized their own email template or to organize their alert . this emialcontentformatter gives more flexibility on the template design .,0.9879835844039917
ballerina-platform_ballerina-lang/29836,fix issue in type resolving <cm-sep> add more tests <cm-sep> extend getintersectiontype method <cm-sep> fix several issues with match patterns <cm-sep> add tests <cm-sep> fix anydata checks at runtime <cm-sep> improve array/tuple intersection check and add tests <cm-sep> add tests for fixed issues,this pr also fixes the following .,1617616640,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.975078821182251
vespa-engine_vespa/17257,"minor group logic improvements . <nl> - non-functional cleanup <nl> - add cluster id to log messages <nl> - do n't warn that we only have n/n and require n nodes ( all for the same n ) <cm-sep> simplify <cm-sep> allow retired nodes to be unreachable . <nl> if we have sufficient document coverage , and the expected number <nl> of nodes in a group is up , then do n't fail it just because <nl> there are additional nodes that are down . that will be because <nl> they are about to be retired and in any case it is harmless . <para-sep> returns the wanted number of nodes per group - size ( ) /groups.size ( ) . the actual node count for a given group may differ due to node retirements .",the last commit is the interesting one .,1617274961,"the last commit is the one to pay attention to , the earlier ones are just cleanup . <nl> we 're observing uneven load on containers during feeding on some applications , and this is the only reason for it that i can see . once we let connections pass through the routing layer i guess this becomes more likely .",0.9137054681777954
Graylog2_graylog2-server/9978,"adding test to check if indexing retries for invalid alias targets . <cm-sep> adding indexing listener to bulk indexing to improve tests . <cm-sep> suppressing specific warnings . <cm-sep> introducing . <cm-sep> retrying bulk indexing upon . <cm-sep> relaxing es exception regex . <cm-sep> throw specific exception if parsed exception indices invalid write target . <cm-sep> fixing error parsing for ess6 , extracting target for exception . <cm-sep> reverting changes to . <cm-sep> adding related test case for es exception parser . <cm-sep> fix implicit mutation of retryer builder when listener is present . <para-sep> checking is always if at least one item fails . instead , we are checking the response code to to determine if the result failed in general .","prior to this pr , if one of the write targets in a bulk indexing request is an alias with zero or multiple targets , indexing failed and messages were silently dropped . this results in an error type being returned from es different to the ones we handled before . before this we had : . <nl> - requests failing completely : due to general errors ( e.g . networking errors ) , indicated by an being thrown and no response being returned <nl> - requests failing partially ( one or all individual bulk items failing ) : due",1611764639,"if we try to bulk index a batch of messages that exceeds the <nl> elastic search setting . ( default 100mb ) <nl> elastic will respond with an http 0 entity too large error . <nl> in this case we retry the request by splitting the message batch <nl> in half . <nl> when responding with an http 0 error , the server is allowed to close the connection <nl> immediately . this means that our http client ( jest ) will simply report <nl> an ioexception ( broken pipe ) instead of the actual error . <nl> this can",0.9748353958129883
apache_incubator-pinot/6546,improve realtime provisioning helper tool <para-sep> a class to generating data for a column with type bytes <nl> a helper class for generating multi value entries <nl> generate mv entries <nl> last item <nl> a class to generate data for a time column <nl> constructor used for processing the given completed segment constructor used for processing the given data characteristics ( instead of completed segment ) <nl> this class is used in memory estimator to generate segment based on the the given characteristics of data <nl> deserialize schema <nl> create maps of ' column name ' to ... <nl> generate data <nl> deserialize schema <nl> create segment <nl> verify segment <nl> seconds <nl> minutes <nl> check hours <nl> arrange inputs <nl> act <nl> assert <nl> cleanup,"with the changes in this pr , a user can provide data characteristics instead of an actual segment . with this option , the tool does a preprocessing step and generates a segment based on the provided characteristics . after the segment is generated , it just uses that segment to provide insight on the memory footprint as usual . <nl> that main changes in the code : <nl> - refactored a few existing s in package and also added a couple of new ones <nl> - added to <nl> - modified <nl> # # testing done <nl> - unit",1612481325,this pull request contains the data completeness checker code . the data completeness checker will check periodically for completeness of time buckets of datasets .,0.9911577701568604
quarkusio_quarkus/16951,"sync fastbootmetadatabuilder # applymetadatabuildercontributor with entitymanagerfactorybuilderimpl # applymetadatabuildercontributor from orm version . <nl> this code was updated since it was copied years ago . <cm-sep> add property quarkus.hibernate-orm.metadata-builder-contributor <cm-sep> fix prevalidatedquarkusmetadata ignoring custom sql functions <cm-sep> test custom metadata builder contributors <para-sep> stay clear of options related to classpath scanning in particular . this setting is exposed mainly to allow registration of types , converters and sql functions . ==== <nl> metadata builder contributor <nl> this would normally be done by the constructor of sessionfactorybuilderimpl , but we do n't use a builder to create the session factory , for some reason .","to be honest i 'm not a fan of the api , because it exposes many different things . <nl> some of these things can be of great value for quarkus users : . <nl> * defining user types <nl> * defining custom sql functions <nl> * defining attribute converters ( without annotations ) <nl> * etc . <nl> others are duplicate of configuration properties : . <nl> * defining naming strategies <nl> * defining the default schema name <nl> * configuring cache regions <nl> * . <nl> and finally , some really are implementation details for quarkus users and",1620053199,"this pr : <nl> - supports a forced jwk refresh based on a vertx auth version feature with a controlled refresh interval period ( 0 mins by default ) . right now , if the rotation happens and the current token has no local jwk with a matching to verify it then 0 requests will go to oidc server , 0 jwk refresh from our handler and one fallback introspection request - this is not really a problem for now as it will happen only once in some long enough irregular rotation interval in a long running application <nl> -",0.9797865748405457
apache_pulsar/10348,"reader support seek from separate messageid/time <para-sep> seek by time <nl> seek by msg id <nl> reset the subscription associated with this consumer to a specific message id or message publish time . the function input is topic+partition . it returns only timestamp or messageid . exception is thrown if other object types are returned . exception in a partition may affect other partitions . reset the subscription associated with this consumer to a specific message id or message publish time asynchronously . the function input is topic+partition . it returns only timestamp or messageid . exception is thrown if other object types are returned . exception in a partition may affect other partitions . <nl> reset the subscription associated with this consumer to a specific message id or message publish time . the function input is topic+partition . it returns only timestamp or messageid . the return value is the seek position/timestamp of the current partition . exception is thrown if other object types are returned . if returns null , the current partition will not do any processing . exception in a partition may affect other partitions . <nl> reset the subscription associated with this consumer to a specific message id or message publish time asynchronously . the function input is topic+partition . it returns only timestamp or messageid . the return value is the seek position/timestamp of the current partition . exception is thrown if other object types are returned . if returns null , the current partition will not do any processing . exception in a partition may affect other partitions .",is it possible to add start message per partition / topic .,1619259413,"currently , the transaction abort on partitions operation is not getting through . <nl> make the transaction abort on partitions operation get through . <nl> this change added tests and can be verified as follows : . <nl> - org.apache.pulsar.broker.transaction.transactionproducetest # produceandaborttest <nl> - org.apache.pulsar.client.transaction.endtoendtest # partitionaborttest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( yes ) <nl> - the schema : ( no ) <nl> - the default values of configurations : (",0.9675685167312622
apache_camel/5712,"preserve captured headers <para-sep> csv constants <nl> csv message header record <nl> utility class <nl> indicates whether or not the unmarshalling should capture the header record . <nl> indicates whether or not the unmarshalling should capture the header record . <nl> if we want to capture the header record , thus the header must be either fixed or automatic <nl> autoload headers","during the parsing of the csv and is set to , the headers are collected and beautifully validated . these headers are then used in map output but discarded on list output . it would be nice to preserve that knowledge downstream in the message header .",1624060927,add allowemptystream option to the camel-bindy dataformat .,0.9573992490768433
vespa-engine_vespa/17371,"add typeresolver . <nl> * with unit tests mostly cribbed from c++ version <para-sep> common type resolving for basic tensor operations . <nl> both types decide the new cell type <nl> only the tensor decide the new cell type <nl> only the tensor decide the new cell type <nl> result of computation must be at least float <nl> when changing cell type , make it at least float",* with unit tests mostly cribbed from c++ version . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618226887,also a common bundle containing just the interface . <nl> use version bundle by default,0.9573858976364136
elastic_elasticsearch/74291,fix snapshots recording incorrect max . segment counts . <nl> if sequence numbers are equal across snapshots ( and thus no files get written to the repository ) <nl> the segment count in the index commit is not reliable as it may have changed due to background merges . <nl> = > fixed by always using the segment count determined from the file names in the snapshot instead . <para-sep> disable merges <nl> create an empty snapshot so that later snapshots run as quickly as possible <nl> create a situation where we temporarily have a bunch of segments until the merges can catch up <nl> snapshot with a bunch of unmerged segments <nl> reactivate merges <nl> wait for merges to reduce segment count,"if sequence numbers are equal across snapshots ( and thus no files get written to the repository ) <nl> the segment count in the index commit is not reliable as it may have changed due to background merges . <nl> = > fixed by always using the segment count determined from the file names in the snapshot instead . <nl> i 'm not the biggest fan of my test here to be honest , but i could n't find a way to have more fine grained control over background merges so i went with this rather brute force approach (",1624011165,"today a mounted searchable snapshot defaults to having the same replica <nl> configuration as the index that was snapshotted . this commit changes this <nl> behaviour so that we default to zero replicas on these indices , but allow the <nl> user to override this in the mount request .",0.9610589742660522
jenkinsci_jenkins/5269,replaced deprecated jenkins.getinstance ( ) calls with .get ( ),replaced deprecated calls with . <nl> * n/a,1612695329,"previously logged as severe was i think incorrect , as it was simply reacting on ' standard ' user interaction . <nl> ought to be enough because anyway , that 's the default logged level , hence will still be seen by admins if needed . <nl> we saw this reported over sentry from evergreen instances running the alpha phase . <nl> _side note : there 's clearly duplications of code here . <nl> i might address it later , but do not want to right now transform a 0 min task into a much riskier one._ . <nl> *",0.8833329081535339
quarkusio_quarkus/17283,"initialize classes using j.u.random at runtime in kafka-client . <nl> ( cherry picked from commit sha ) <cm-sep> runtime initialize grpc class using j.u.random . <nl> ( cherry picked from commit sha ) <para-sep> io.grpc.internal.retriablestream uses j.u.ramdom , so needs to be runtime-initialized <nl> classes using java.util.random , which need to be runtime initialized","please do n't merge , i will merge it myself .",1621253126,should be easy enough to review .,0.9416664838790894
elastic_elasticsearch/74504,"fix error in fieldcapabilitiesresponse serialization . <nl> in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version . <para-sep> check that failure serialization between different minor versions after version works <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> check that failure serialization to minor versions before version works without serializing the failures part <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> minimum version set to version because the nested fieldcapabilities had another serialization change there","in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version .",1624464639,this commit restores the filtering of empty fields during the <nl> xcontent serialization of searchhit .,0.9451593160629272
Alluxio_alluxio/12801,fix ' allocation after freeing space ' log message,dirview has no tostring implementation . so it is certainly not what you want .,1612380400,there are sporadic occurrences of ' illegalstateexception : call already closed ' in server logs .,0.8701183795928955
runelite_runelite/13733,loot tracker : add supply crate ( wintertodt ),adds loot tracking for supply crate from wintertodt .,1623629647,this will prevent the scout overlay from rendering while at olm as the information there is obsolete .,0.8586092591285706
ballerina-platform_ballerina-lang/27735,"re-enable bir-spec tests <cm-sep> add type inclusions to ksy file <para-sep> ballerina compiler backend that does not emit backend code , used for testing bir . <nl> class to hold both expected and actual compile result of bir .",note : jballerina back-end is modifying the object while generating jvm code . so the bir module that is used in serialization of bir differs from the one used in tests .,1610097146,"with this phase of the auto-imports feature , we allow auto importing of packages available in the ballerina sdk .",0.9841667413711548
apache_beam/14024,add null checks to fhirio.search for when the search results are empty . <para-sep> search using a search that will return no results . <nl> verify that there are no failures . <nl> verify that the result is empty .,"when the search result returned from fhirio.search is empty , the following exception occurs : . <nl> changed the first ' addall ' to be within the ' while hasnext ' loop , and fixed ' hasnext ' to also check for null , as this causes :",1613763714,"fixes an thrown by the method when the user does not provide a . it is optional in the method and the behaviour should be the same for the method . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9155844449996948
ballerina-platform_ballerina-lang/26984,"remove unused test projects <cm-sep> add test projects for package resolution tests <cm-sep> add the initial set of package resolution tests <cm-sep> update test cachebalo logic to use a cache in build directory <cm-sep> update packageorg with the support for checking ballerina and ballerinax orgs <cm-sep> improve package cache to store the project . <nl> whenever a package is requested we should get the lastest version from the project <cm-sep> delete unused packageresolver implementation <cm-sep> introduce an interface for packagecache utility <cm-sep> introduce writable package cache interface <cm-sep> introduce a project-level pkg cache . <nl> this cache implementation delegate most of the requests to the environmentpackagecache <cm-sep> replace packageresolver usages with packagecache in jballerinabackend <cm-sep> replace packageresolver with packagecache <cm-sep> update bootstrap to use the new packagecache <cm-sep> decouple package caching from packageresolver utility <cm-sep> update the class comment to reflect new changes <para-sep> returns the package with the given organization , name and version . <nl> returns all the package versions with the given org and name . <nl> environment-level package cache . <nl> do we have a need to improve this logic ? <nl> do we have a need to improve this logic ? <nl> per project package cache that delegates most requests to the global cache . <nl> caches the given package instance . <nl> contains cases to test package resolution logic . <nl> here package_a depends on package_b and package_b depends on package_c therefore package_c is transitive dependency of package_a <nl> package_c -- > { } <nl> check whether there are any diagnostics <nl> check direct package dependencies <nl> package_b -- > package_c <nl> check whether there are any diagnostics <nl> check direct package dependencies <nl> package_a -- > package_b -- > package_c <nl> check whether there are any diagnostics <nl> check direct package dependencies <nl> package_d -- > package_b -- > package_c package_d -- > package_e <nl> check whether there are any diagnostics <nl> check direct package dependencies <nl> compilation cache that dumps bir and jars inside the build directory .","in addition to the above , i 've added a few test cases to validate package resolution logic .",1605672419,i 've redesigned the types implementation avoid may if-else to figure out the value for a given type . i had to do this to support the array type .,0.9758829474449158
apache_camel/5643,": set topic value after setproperties method <para-sep> if a topic is not defined in the kafkaconfiguration ( set as option parameter ) but only in the uri , it can happen that it is not set correctly in the configuration of the endpoint . therefore , the topic is added after setproperties method and an null check to avoid overwriting a value from the configuration .","if a kafkaconfiguration is used ( see code in jira ticket ) and no topic is defined in the configuration , the parameter from the uri is not taken over , but a null value is set . <nl> this leads to a consumer not having a valid topic name , but null being provided as a value . <nl> therefore , the topic is only set after this method if the topic is still null . <nl> it looks like setproperties ( endpoint , parameters ) ; overrites the topic with null .",1623276141,"on partition-revoke , do the clearing of the offset inside a finally . <nl> that way , it will happen even if the commit failed .",0.8176501393318176
ballerina-platform_ballerina-lang/28852,"get native jar file <cm-sep> remove dependency jars and pick only needed jars for coverage report <cm-sep> filter module-info class file <cm-sep> resolve path to store java class files <para-sep> typical class path is .jar///class for .bal files this function extracts the to create a unique directory for .bal files for .java files , the parent directory of the class file is returned",this fix adds data from java source files to the report .,1614090686,- receiveactionnode <nl> - asyncsendactionnode <nl> - syncsendactionnode <nl> - forkstatementnode .,0.9523013830184937
apache_druid/11327,"fix a bunch of type inference nullability bugs <para-sep> sets the return type of the operator to ' typename ' , marked as non-nullable . if this method is used it implies the operator should never , ever , return null . these methods can not be mixed ; you must call exactly one . these methods can not be mixed ; you must call exactly one . <nl> sets the return type of the operator to ' typename ' , marked as nullable if any of its operands are nullable . these methods can not be mixed ; you must call exactly one . <nl> these methods can not be mixed ; you must call exactly one . these methods can not be mixed ; you must call exactly one . <nl> in default mode strpos is 0 because the '+ 0 ' of the expression ( no null numbers in default mode so is 0 + 0 for null rows )","a new method , , has been added to builder type , which allows defining operators with a return type that is only nullable if any of the operands are nullable , which is many of them . i only evaluated all callers of , and did n't look closely if some of the should be switched to this new method . <nl> list of impacted functions : <nl> * / <nl> * / <nl> * / <nl> * / <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> * <nl> *",1622719127,"0 ) druid master restricts maximum number of segments to merge <nl> 0 ) indexing service verifies znode sizes before creation -- this is done via ' if ' checks everywhere , it may be better to wrap curatorframework",0.9394502639770508
elastic_elasticsearch/73711,"fieldtypelookup and mappinglookup expose the getmatchingfieldtypes method to look up matching field type by a string pattern . we have migrated existsquerybuilder to instead rely on getmatchingfieldnames , hence we can go ahead and remove the remaining usages and the method itself . <nl> the remaining usages are to find specific field types from the mappings , specifically to eagerly load global ordinals and for the join field type . these are operations that are performed only once when loading the mappings , and may be refactored to work differently in the future . for now , we remove getmatchingfieldtypes and rather call for the two mentioned scenarios getmatchingfieldnames ( * ) and then getfieldtype for each of the returned field name . this is a bit wasteful but performance can be sacrificed for these scenarios in favour of less code to maintain . <para-sep> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field","fieldtypelookup and mappinglookup expose the getmatchingfieldtypes method to look up matching field type by a string pattern . we have migrated existsquerybuilder to instead rely on getmatchingfieldnames , hence we can go ahead and remove the remaining usages and the method itself . <nl> the remaining usages are to find specific field types from the mappings , specifically to eagerly load global ordinals and for the join field type . these are operations that are performed only once when loading the mappings , and may be refactored to work differently in the future . for now , we remove getmatchingfieldtypes",1622708875,"this commit refactors some of the rest test transformations unit tests . <nl> specifically , this refactor introduces a common parent that the ' match ' <nl> tests ( and other future tests ) can consume . also , the example tests <nl> have been simplified to better illustrate the change . <nl> there should no functional changes , just refactoring . this will help with <nl> future commits to allow focus only for the relevant changes .",0.9650582075119019
apache_druid/11071,start schema-resgity and replace json template,the it for kinesis-data-format ca n't work because : <nl> 0. did n't launch schema registry service . <nl> 0. did n't parse supervisor.json correctly . <nl> this pr solved this bug and tested on local env,1617701654,this pr allows users to specify additional command line options to the <nl> pull deps command while creating druid distribution . <nl> e.g . to also package graphite-emitter in druid tarball one can run - . <nl> this also trims any additional whitespace in the coordinate string if any .,0.806976854801178
ballerina-platform_ballerina-lang/29637,fix the issue with current directory output,sad . error produced when a user-specified output path in the bindgen command contains a current directory notation such as or .,1616754282,* handle union message type passing as message type and throw error message . <nl> * fix build failure when service is created inside package and has nested message type . <nl> * fix the issue when place send ( ) expression inside match statement .,0.8589518070220947
apache_incubator-pinot/7099,add minion metrics of task queueing time and task numbers <para-sep> jobcontext.getstarttime ( ) return the time in milliseconds of job being put into helix queue .,"this pr add minion metric/gauge of : <nl> * task queuing time : task_dequeue_time - task_inqueue_time ( assume the time drift between helix controller and pinot minion is not large , otherwise the value may be negative ) <nl> * number of tasks in progress . whenever minion start a task , increase the gauge by 0 , whenever minion completed ( either succeeded or failed ) a task , decrease it by 0 .",1624917738,"segment commit takes place in 0 steps : <nl> 0. mark committing segment metadata to done <nl> 0. create new segment metadata to in_progress <nl> 0. update ideal state with segment state to online and new segment state to consuming . <nl> the retentionmanager checks for segments which have metadata present but no entry in ideal state . if the retentionmanager happens to check between steps 0 and 0 above , it will mark the newly created segment for deletion . <nl> in this pr , a check is put in place to look for all segments online in ideal",0.8887331485748291
hazelcast_hazelcast/18606,"fix jet related ru compatibility issue <para-sep> add configurations for the internal jet distributed objects , compatible with v4.0 it can block ru4_2 only if there are existing configurations with the same name as the jet 's internal objects . for this case , recommend disabling jet .",we re-enable these accesses after cluster version is upgraded to version version or higher . <nl> note : i did n't consider the accesses to jet service with using sql api . <nl> checklist : .,1619610513,support spring xml configuration for mutual auth in management center config .,0.9033918380737305
grpc_grpc-java/7777,multiple changes needed for ga : <nl> - check to allow xdsserverbuilder.build ( ) only once <nl> - add transportbuilder ( ) to xdsserverbuilder <nl> - remove ' grpc/server ' hardcoding <nl> - reorder the shutdown of delegate and xdsclient as per new design,- check to allow xdsserverbuilder.build ( ) only once <nl> - add transportbuilder ( ) to xdsserverbuilder <nl> - remove ' grpc/server ' hardcoding <nl> - reorder the shutdown of delegate and xdsclient as per new design .,1609809050,protectedpromise will be used in frameprotector in psp . <nl> psp also needs to call writebufferedandremove .,0.9148291349411011
elastic_elasticsearch/74511,calculate sha256 fingerprint for enrollment token .,calculate sha256 fingerprint for enrollment token .,1624473088,"in order to prepare for ml to take advantage of kibana privileges , we are taking an intermediate step to distinguish between ml users and ml admins by giving each their own ' reserved ' kibana privilege .",0.8740347623825073
ballerina-platform_ballerina-lang/30709,fix readonly-ness of slice of readonly arrays,this pr will fix the readonly-ness of the sliced arrays which are obtained from readonly arrays .,1621579002,"previously , it was simply modeled as a nil-able user defined type .",0.9073082208633423
runelite_runelite/12957,add ' scorched ' lletya regionid recognition to timetracking 's farmingworld,"from the issue : <nl> > i am far enough along in song of the elves that lletya has been attacked , and is ' scorched ' . without completing the quest , i have planted a palm tree in the fruit tree patch there , but it is not timed in the time tracking plugin . <nl> > [ ... ] when passing through the tree entrance to lletya , your character is warped from region 0 on the left side , to region 0 on the right side . <nl> this patch adds recognition for region 0 ,",1608526475,the port sarim stash was reported as incorrect by an individual in discord . <nl> upon further testing of other stashes with non zero planes the wizards tower stash was discovered as being incorrect also .,0.8148182034492493
vespa-engine_vespa/17167,"convert stateresource as request handler <cm-sep> configserverlocation component is removed <cm-sep> add binding without trailing '/ ' <cm-sep> do n't close client <para-sep> a web service to discover and proxy vespa service state info . <nl> if it points to a port and host not part of the application , rewriting will not occur , so this is kind of safe <nl> nop",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616603040,"refreshing routing policies and performing the necessary dns updates are <nl> somewhat time sensitive , especially in manually deployed environments , hence it <nl> makes sense that this should be done as early as possible . <nl> because name service requests are now executed asynchronously by <nl> default , we can refresh policies during deployment ( de ) activation without <nl> worrying about dns service failures or rate limits . <nl> benefits of this change : . <nl> - reduces worst-case dns propagation time by 0 minutes . <nl> - we no longer need to update all routing policies in",0.978423535823822
vespa-engine_vespa/17115,update api to show secret store information . <nl> - add information about the iam role <nl> - put everything inside its own object <nl> - todo to remove the old structure after console update <para-sep> retrieve the names of the tenant roles ( host and container ) . does not guarantee these roles exist * / <nl> todo : remove this once console is updated,- add information about the iam role <nl> - put everything inside its own object <nl> - todo to remove the old structure after console update . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616491826,"first commit is refactoring ( no functional changes ) , second commit add prod.us- to the set of zones that should load minimal set of model versions",0.905016303062439
apache_kafka/10752,"quorumcontroller support for allocateproducerids <cm-sep> used timelinelong <cm-sep> better name in callback <para-sep> this is a no-op since brokers get their producer id blocks directly from the controller via allocateproducerids rpc response <nl> allocate a block of producer ids for transactional and idempotent producers <nl> an object which stores the controller 's view of the latest producer id that has been generated . this must be accessed only by the event queue thread . <nl> ca n't go backwards in producer ids <nl> gaps in the id range are okay . <nl> verify that after reloading state from this ' snapshot ' , we do n't produce any overlapping ids",this pr adds support on the kraft controller for handling allocateproducerids requests and managing the state of the latest producer id block in the controller and committing this state to the metadata log .,1621880747,"added a class that generates producer payload ( key and value ) . makes sure that the values are populated to target a realistic compression rate ( version - version ) if compression is used . the generated payload is deterministic and can be replayed from a given position . for now , all generated values are constant size , and key types can be configured to be either null or 0 bytes . <nl> added messagesize parameter to producer spec , that specifies produced key + message size .",0.9521764516830444
Graylog2_graylog2-server/10757,"fix resolving targets for alias with wildcard ( s ) . <cm-sep> removing todo . <cm-sep> adding method to return multiple alias targets , using it for reopened indices . <para-sep> the es return value of this has an awkward format : the first key of the hash is the target index . thanks .","prior to this change , retrieving the index sets ( and their wildcards ) containing reopened indices was broken , due to a number of issues . <nl> this pr is fixing : . <nl> - retrieving the list of targets for an index wildcard <nl> - checking if an index set wildcard contains reopened indices . <nl> this unbreaks the indices overview page after multiple indices were restored .",1622474196,we can not use ' future # sync ( ) ' to wait for the result of the dns <nl> resolver . this can block forever ( until the server gets restarted ) <nl> when the dnsnameresolver and the netty event loop gets shut down while a <nl> dns request is running . <nl> this happened on busy systems that do a lot of dns lookups and the dns <nl> lookup data adapter gets restarted while dns requests are running . ( e.g . <nl> by updating the data adapter 's configuration ) . <nl> it can get even worse,0.9483412504196167
apache_druid/11047,"allow list for jdbc connection properties to address 0 <para-sep> we should consider either expanding recognized mysql protocols or restricting allowed protocols to just a basic one . <nl> see org.apache.druid.server.initialization.jdbcaccesssecurityconfig for more details . <nl> check the properties in the connection url . note that jdbcextractionnamespace does n't use metadatastorageconnectorconfig.getdbcpproperties ( ) . if we want to use them , those dbcp properties should be validated using the same logic . <nl> check the given url whether it contains non-allowed properties . <nl> you do n't want to do anything with properties . <nl> unknown format but it is not allowed <nl> there is something wrong with the url format . <nl> check the properties in the connection url . note that jdbcdatafetcher does n't use metadatastorageconnectorconfig.getdbcpproperties ( ) . if we want to use them , those dbcp properties should be validated using the same logic . <nl> check the given url whether it contains non-allowed properties . <nl> you do n't want to do anything with properties . <nl> unknown format but it is not allowed <nl> there is something wrong with the url format . <nl> this method should be in sync with - org.apache.druid.server.lookup.jdbc.jdbcdatafetcher.checkconnectionurl ( ) - org.apache.druid.query.lookup.namespace.jdbcextractionnamespace.checkconnectionurl ( ) <nl> this method should be in sync with - org.apache.druid.server.lookup.jdbc.jdbcdatafetcher.checkconnectionurl ( ) - org.apache.druid.query.lookup.namespace.jdbcextractionnamespace.checkconnectionurl ( ) <nl> postgresql jdbc driver is embedded and thus must be loaded . <nl> the properties that will be used for the jdbc connection . note that these properties are not currently checked against any security configuration such as an allow list for jdbc properties . instead , they are supposed to be checked before adding to this class . <nl> we validate only the connection url here as all properties will be read from only the url except users and password . if we want to allow another way to specify user properties such as using metadatastorageconnectorconfig.getdbcpproperties ( ) , those properties should be validated as well . <nl> you do n't want to do anything with properties . <nl> extract property keys from the given jdbc url . <nl> a config class that applies to all jdbc connections to other databases . <nl> mysql <nl> postgresql <nl> any properties resulted by connection url parsing are regarded as system properties if they start with the prefixes in this set . <nl> mysql there can be multiple host and port","this pr adds an allow list for jdbc connection properties that is enforced against every jdbc connections for ingestion and lookups but not metadata stores . the allow list is enforced to connections to postgresql as well as mysql . this is because , even though the known security vulnerability can be exploitable with only mysql , we want to be conservative and avoid the same issue even with postgresql that can be potentially exploitable in the future . the jdbc connection will fail if it uses a property that is not in the allow list . <nl> implementation-wise ,",1617057940,"in version , brokers gained the ability to serve segments . to support this change , <nl> a servertype was added to . <nl> druid nodes prior to this change do not know of this new server type and so <nl> they would fail to deserialize this node 's announcement . <nl> this change makes it so that the broker only announces itself if the segment <nl> cache is configured on the broker . it is expected that a druid admin will only <nl> configure the segment cache on the broker once the cluster has been upgraded <nl> to a",0.9761219620704651
apache_incubator-pinot/6869,"add segment size rule to rule engine <cm-sep> fix a small issue <para-sep> silent rules will run , but their output will only be used in other rules and it will not be present to user <nl> cardinalities provided by users are relative to number of records per push , but we might end up creating multiple segments for each push . using this methods , cardinalities will be capped by the provided number of rows in segment . <nl> some rules have to be run even if user has disabled them . the reason is the output of these rules are used in other rules . this method is used to hide the output from the final result that 's going to be presented to the user . <nl> this rule generates a segment based on the provided schema characteristics and then recommends the followings using the size and number of records in the generated segments : - number of segments - number of records in each segment - size of each segment the purpose of generating a segment is to estimate the size and number of rows of one sample segment . in case user already have a production segment in hand , they can provide actualsegmentsize and numrowsinactualsegment parameters in the input and then this rule uses those parameters instead of generating a segment to derived those values . it 's worth noting that since this rule gets executed before other rules , we run into chicken-egg problem . - index recommendation , dictionary , bloom filter rules will be run next . - only after the subsequent rules run and the index recommendation is available , will we know what segment might look like . so here we just assume dictionary on all dimensions and raw for metric columns and try to generate a segment quickly . this also means that the calculated size of the optimal segment should ideally be bumped up by a factor , say 0 % , to account for what the size might look like when all the index/dictionary/bloom recommendations are applied . <nl> no need to estimate segment size & optimal number of segments for realtime only tables ; rt provisioning rule will have a comprehensive analysis on that <nl> generate a segment <nl> recommenderconstants.segmentsizerule.index_overhead_ratio_for_segment_size ) ; <nl> cleanup <nl> estimate optimal segment count & size parameters <nl> wire the",this rule recommend some parameters related to segment size for offline tables . the rule generates a segment based on the provided schema characteristics and then recommends the followings using the size and number of records in the generated segments : <nl> - number of segments <nl> - number of records in each segment <nl> - size of each segment .,1619797106,* objectseries for arbitrary objects in dataframe . <nl> * expressions for fast introspection of objects in objectseries . <nl> * type inference from objectseries to specialized series type ( e.g . longseries ) . <nl> * type conversion from objectseries via default methods . <nl> * opportunistic approach to comparison and ordering within objectseries . <nl> * grouping min/max specialization . <nl> * expanded unit tests and benchmarks . <nl> * code cleanup,0.9815942645072937
apache_pulsar/10931,"fixes # throwable exception not thrown . <nl> motivation <nl> i found some throwable exception that not thrown , maybe it 's a bug .","fixes # throwable exception not thrown . <nl> motivation <nl> i found some throwable exception that not thrown , maybe it 's a bug .",1623792138,"motivation . <nl> there are bunch of fixes in version regarding dns cache , ledger storage flushes . <nl> version is a minor release of version , so it is safe to upgrade and included in version release .",0.8276941776275635
apache_shardingsphere/11006,prepare logicsql for executeprocessreporter <cm-sep> persist logic sql and show in info column <para-sep> get sql statement context .,"changes proposed in this pull request : <nl> - add in , replace <nl> - add in , replace <nl> - persist to zk <nl> - show sql in column when executing ' show processlist '",1624582340,changes proposed in this pull request : <nl> - extract datasource check to shardingscalingjobpreparer,0.9378247261047363
apache_pulsar/11052,fix async response filter <para-sep> nothing to do <nl> async response test .,"currently , the response filter could n't process async responses correctlly , the response interceptor may be called before the async response returning . <nl> add listener when using async request . <nl> add a new test to verify the response interceptor is called after async response returning . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations :",1624473768,"# # # motivation . <nl> for connectors like jdbc connector , we will be using for mapping individual fields to the sink destination . if a function or connector is programming using the , pulsar should use schema.auto to detect schema automatically . <nl> enable in functions and connectors . <nl> we are able to use in functions and connectors .",0.9702094197273254
apache_flink/15438,set a default character set in inputstreamreader to solve potential garbled problems,"set a default character set in inputstreamreader to solve potential garbled problems . <nl> when a inputstreamreader is used , the parameter setting of a default character set is recommended to solve potential garbled problem .",1617125434,"# # what is the purpose of the change . <nl> this pull request adds comapfunction for python datastream api . <nl> - add connect ( ) on datastream . <nl> - add comapfunction on datastream . <nl> - refactor the previous to and add a for connect . <nl> this change added tests and can be verified as follows : . <nl> - added and integration tests in test_data_stream . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated",0.8228766322135925
apache_pulsar/10594,"fixed missed zk caching when fetching list of namespaces for a tenant <para-sep> if the length is 0 then this is probably a leftover cluster from namespace created with the v1 admin format ( prop/cluster/ns ) and then deleted , so no need to add it to the list",the zk reads triggered by the ' get namespaces of a tenant ' admin operation are being issued directly on the zk client and therefore are not getting cached by brokers . <nl> this change is only for version branch . the issue is not present in current master since the code was already ported to use metadatastore api .,1621036847,pip22 dead letter topic is available in java client but not in websocket proxy . <nl> added two query params and to the websocket handler to be able to set the 's . <nl> dead letter topic can be used with websockets . <nl> example request : .,0.8910531401634216
ballerina-platform_ballerina-lang/27609,"allow field access on structural constructors <para-sep> first analyze the accessible expression . <nl> container expression must be a accessible expression . <nl> container expression must be a accessible expression . <nl> eg : list-construct , record literal , grouped expression , etc ...",note : this pr will change the inheritance hierarchy of blangaccessexpression and blangvariablereference .,1608550807,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9596962332725525
OpenAPITools_openapi-generator/8900,"[ go ] fix example value for non string enums <para-sep> fakeapi * | fakepropertyenumintegerserialize | post /fake/property/enum-int | <nl> outerobjectwithenumproperty | outerobjectwithenumproperty * | input enum ( int ) as post body | <nl> value | outerenuminteger * | | <nl> openapi petstore this spec is mainly for testing petstore server and contains fake endpoints , models . please do not use this for any other purpose . <nl> / please update the test case below to test the model . / <nl> todo uncomment below to declare an instance variable for outerobjectwithenumproperty private outerobjectwithenumproperty instance ; <nl> / / setup before each test / <nl> todo uncomment below to create an instance of outerobjectwithenumproperty instance = new outerobjectwithenumproperty ( ) ; <nl> / / clean up after each test / <nl> / / test an instance of outerobjectwithenumproperty / <nl> todo uncomment below to test ' isinstanceof ' outerobjectwithenumproperty assert.isinstanceof ( typeof ( outerobjectwithenumproperty ) , instance ) ; <nl> / / test the property 'value ' / <nl> todo unit test for the property 'value ' <nl> / test serialization of enum ( int ) properties with examples / / thrown when fails to make api call / input enum ( int ) as post body / outerobjectwithenumproperty <nl> / / / / / test serialization of enum ( int ) properties with examples / / thrown when fails to make api call / input enum ( int ) as post body / apiresponse of outerobjectwithenumproperty <nl> / / / / / test serialization of enum ( int ) properties with examples / / thrown when fails to make api call / input enum ( int ) as post body / cancellation token to cancel request ( optional ) / task of outerobjectwithenumproperty <nl> / / / / / test serialization of enum ( int ) properties with examples / / thrown when fails to make api call / input enum ( int ) as post body / cancellation token to cancel request ( optional ) / task of apiresponse ( outerobjectwithenumproperty ) <nl> / / / / / test serialization of enum ( int ) properties with examples / / thrown when fails to make api call / input enum ( int ) as post body / outerobjectwithenumproperty <nl> / / test serialization of enum ( int ) properties with examples / / thrown when fails",fix example value for enum of integers to make sure that examples can be compiled .,1614950651,issue 0 modified mustache files for go to support nullable in the spec v3.0+ ; updated model files running .sh scripts for go . <nl> should we try to make new classes for that ? do you have any guide for that ?,0.9901218414306641
apache_druid/11280,"bitwise aggregators , better nulls for expression agg <para-sep> deserialize an expression stored in a bytebuffer , e.g . for an agg . this should be refactored to be consolidated with some of the standard type handling of aggregators probably <nl> | expression bytes | <nl> set a bit to indicate we have n't aggregated on top of expression type ( not going to lie this could be nicer ) <nl> scrub not aggregated bit <nl> newer versions of calcite have this built-in so someday we can drop this ...","in the process of adding this , i 've also modified to have an additional json property , <nl> , which determines if the aggregator will produce a value or / . for example , an sql compatible count aggregator would have set to and have set to , so that it would always return 0 even if no rows were aggregated , while a sum would have it set to so that it would return in the same case . for the buffer aggregator , this is tracked by setting a bit in the expression type byte which prefixes",1621571654,"the correct code is actually in place already in , but this was getting pre-empted by which had it 's own predicate defined specifically handling long columns , along with a code comment : . <nl> unfortunately , it just had n't been done yet . <nl> prior to this pr , the added in would fail with an error of the form : . <nl> while adding tests for this fix , i also encountered an issue with the , which did not implement for it 's predicate , causing it to be unable to feed null values into",0.9490493535995483
OpenAPITools_openapi-generator/8886,fix not processing enums in cpp-pistache-server . <nl> defining a reusable enum as a component schema results in an empty <nl> class . following changes are made : . <nl> - activate 'postprocessmodelsenum ' in 'abstractcppcodegen ' <nl> - modify model templates for the 'cpp-pistache-server ' project . <nl> as 'postprocessmodelsenum ' is now available in the 'abstactcppcodegen ' <nl> the 'enumvars ' variables are now available in mustache templates for all <nl> cpp based code generators . <nl> as the 'abstractcppcodegen ' was touched all cpp based <nl> samples were updated . <para-sep> to have a valid default value . avoiding nameclashes with user defined enum values,defining a reusable enum as a component schema results in a class that does not include enum values . following changes are made : . <nl> - override 'toenumvalue ' in 'abstractcppcodegen ' <nl> - modify model templates for the 'cpp-pistache-server ' project <nl> .,1614832908,"add validations ( e.g . pattern , maxitems , etc ) to model .",0.9787070751190186
runelite_runelite/13419,menu entry swapper : add tempoross leave swap,"after subduing tempoross , to save some time , most players choose to ' leave ' instantly by interacting with one of four npcs in the cove . i believe swapping the default ' talk-to ' with ' leave ' would be a minor qol improvement for the boss . <nl> some self-asked qa questions : . <nl> is there a risk that players will leave by accident before the fight is over ? <nl> nope , because the option to leave early is called ' forfeit ' , which is not being swapped . so throughout the fight ,",1617177014,"this is intended to make the tags feature more discoverable , as people keep requesting ' plugin categories ' . putting plugins into a singular category that will make sense for most users is impossible , as many plugins will can logically be placed into multiple categories . <nl> the category tag list is intended to be a short , curated , list of tags that are helpful to a user trying to find plugins . <nl> the icon for this list only shows up when the input is empty , otherwise it shows the existing clear button .",0.8829137682914734
apache_ignite/9017,exception handling implemented for errors in static initializer during remote filter deployment in cq,exception handling implemented for errors in static initializer during remote filter deployment in cq .,1618777178,provide the ability to manage the process from cli : . <nl> starts master key rotation . <nl> displays cluster 's current master key name .,0.983416736125946
runelite_runelite/13277,"require java 0 or higher for building . <nl> we still support java 0 at runtime since older launchers shipped with <nl> it , and there are still many installs that use those older launchers . <cm-sep> factor frame handling out <para-sep> try not to start autocomplete when it has no useful context <nl> ctor inserts into the map <nl> rsyntaxtextarea : :setantialiasingenabled actually forces it to match the platform 's default , which is pointless <nl> make sure jshell is on the classpath <nl> workaround a jdk bug <nl> it might be nice to highlight stuff here <nl> welcome to the runelite development shell everything executed here runs on the client thread by default . by default client , clientthread , configmanager and log are in scope you can subscribe to the event bus by using subscribe ( event.class , ev - > handler ) ; and you can access things in the global injector module with var thing = inject ( thing.class ) ; press ctrl+r or f10 to execute the contents of this editor","adds a shell to devtools that lets you execute test programs . <nl> this makes the client require java 0 or higher to build . it still runs on any java 0+ , however the shell will be inaccessible for these older vms .",1614361287,"replaces the vartracker with a gui that works with varp/bit/cint/cstrs . <nl> i would like to add some more stuff to this in the future , perhaps inventory deltas , and a way to get/set all var types , similar to the widget inspector .",0.9564326405525208
apache_flink/16088,fix rankend validation of windowrank to support top1,"the pull request aims to a minor fix on rankend validation of windowrank to support top1 . <nl> - a minor update in to support top1 . <nl> - add itcase in windowrankitcase . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery :",1623050787,"# # what is the purpose of the change . <nl> add a page to document hive streaming writing reading and join . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos , zookeeper : no <nl> - the s3 file",0.8012547492980957
apache_beam/14844,"use non-sdf based translation for read by default on all runners except dataflow . <nl> ( cherry picked from commit sha ) <para-sep> todo ( ) : use sdf read as default when we address performance issue . <nl> portable flink only support sdf as read . todo ( ) : use sdf read as default when we address performance issue . <nl> todo ( ) : use sdf read as default for non-portable execution when we address performance issue . <nl> default to using the primitive versions of read.bounded and read.unbounded for non-portable execution . todo ( ) : use sdf read as default when we address performance issue . <nl> default to using the primitive versions of read.bounded and read.unbounded . todo ( ) : use sdf read as default when we address performance issue . <nl> default to using the primitive versions of read.bounded and read.unbounded . todo ( ) : use sdf read as default when we address performance issue . <nl> todo ( ) : use sdf read as default when we address performance issue . <nl> todo ( ) : use sdf read as default when we address performance issue . <nl> populate experiments directly to have kafka use legacy read . <nl> todo ( ) : remove additional experiments when sdf read is default . <nl> only dataflow runner requires sdf read at this moment . for other non-portable runners , if it does n't specify use_sdf_read , it will use legacy read regarding to performance concern . todo ( ) : remove this special check when we address performance issue .",( cherry picked from commit sha ) .,1621462114,"there 's a risk that other runners mutate pipelineoptions and depend on this though . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.8917104601860046
neo4j_neo4j/11804,"backport or implement page cache features that are needed for experimental parallel flushing , and a rudimentary page cache warmer backport . <cm-sep> backport a simplified page cache warmer feature from version . <cm-sep> backport contrived version of the parallel check point flushing . disabled by default . <para-sep> the mappings can change as soon as this method returns . note : the calling code should not close the returned paged files , unless it does so in collaboration with the code that originally mapped the file . report any thread-local events to the global page cache tracer , as if acquiring a thread-specific page cursor tracer , and reporting the events collected within it . <nl> note that we are not incrementing the reference count here . calling code is expected to be able to deal with asynchronously closed pagedfiles . <nl> the file is not supposed to be closed , since we have a positive ref-count , yet we got a closedchannelexception anyway ? it 's an odd situation , so let 's tell the outside world about this failure . <nl> otherwise : the file was closed while we were trying to flush it . since unmapping implies a flush anyway , we can safely assume that this is not a problem . the file was flushed , and it does n't really matter how that happened . we 'll ignore this exception . <nl> the page cache warmer , in this rudimentary implementation , just blindly loads in all pages of all mapped files at startup . <nl> stopping warmer process . <nl> reheat the page cache by accessing all pages of all mapped files . <nl> the database is allowed to map and unmap files while we are trying to heat it up . <nl> we use the monitor lock to guard the job handle . however , it could happen that a job has already started , ends up waiting for the lock while it 's being held by another thread calling . in that case , we need to make sure that the signal to stop is not lost . cancelling a job handle only works on jobs that have n't started yet , since we do n't propagate an interrupt . this is why we check the field in the method . <nl> no additional faults must have been reported .","both are disabled by default . <nl> this needs to be forward merged into version , and then null-merged into version and version .",1526567016,variable length encoding of references decoding and encoding or records in enterprise format takes some additional time . <nl> to minimise damage for common case ( small records ) possibility of fixed records introduced . <nl> from now on in case if record can be encoded in a fixed reference format ( criteria based on references that are used in record ) it will be used instead of variable-length format . <nl> in case if record ca n't be encoded in fixed references format - default variable-length format will be selected and used . <nl> changelog : <nl> speeding up,0.9885206818580627
grpc_grpc-java/7926,add serverbuilder.addservices ( ) api . <para-sep> adds a list of service implementations to the handler registry together .,an api for adding a list of services can be useful for tooling implementations such as the admin interface .,1614380886,"testing for grpc components that instantiate a is hard since channel creation is inside 's primary constructor . <nl> introducing , a factory for creating xds channels .",0.9214274287223816
apache_incubator-pinot/6967,"prefetch call to prefetch buffers of columns seen in the query <para-sep> this is a hint to the the implementation , to prefetch buffers for specified columns <nl> for segments that can only provide the inputstream to the metadata <nl> fetch the buffer for this column <nl> this is a hint to the the implementation , to prefetch buffers for specified columns","introducing a prefetch call to fetch buffers for columns , based on columns seen in the queries . <nl> default implementations are no-op",1621909012,"- change to pql query : for nonadditive ( pre-aggregated ) dataset , we assume that there exists one dimension value ' all ' , which is user configurable , that aggregates all dimension values on the corresponding dimension name . therefore , if a user does not specify which value s/he is looking at at that dimension , then thirdeye automatically append filters such as ' thatdimensionname=all ; ' after the query . consequently , thirdeye would get the pre-aggregated value instead of sum up the non-additive dimension . <nl> - change to ui : for nonadditive ( pre-aggregated",0.9645234942436218
pentaho_pentaho-kettle/7943,"json input step behavior changes when the order of the fields is changed <para-sep> gets the max size of the result rows . <nl> see . when parsing , if the first field returned null , the second field would also return null , when in reality the path existed . this test makes sure that regardless of the order of the fields being searched the result is the same ( the field with a path that exists returns the correct value ) . <nl> create two meta inputs with two different orders a , b and b , a <nl> regardless of the order the result should contain the findings ' one ' and ' three ' .",json input step behavior changes when the order of the fields is changed .,1618942876,- backport of - udjc can not read fields from table input info step ( version suite ) .,0.9377804398536682
jenkinsci_jenkins/5390,use system properties and declared some suggested static properties final,use system properties and declared some suggested static properties final . <nl> * internal : declared some internal fields to final . should not impact any existing script console commands,1617562781,"as usual , for the pr build…",0.8946958184242249
ballerina-platform_ballerina-lang/28321,"move highlightdiagnostics function to stringutils <cm-sep> write some tests for stringutils class <cm-sep> fix highlight diagnostics to have dashes in between <cm-sep> add tests to highlight diagnostic method <para-sep> error message thrown should be in ' syntax error : error ' format . <nl> highlight and show the error position . <nl> error spans for several lines , will not highlight error <nl> get the source code <nl> count leading spaces <nl> result should be padded with a tab","the errors will now follow format , , , format .",1612108238,this pr will change default verb behavior from ' get ' to any verb . even passthru scenario is possible after this change .,0.9614701271057129
neo4j_neo4j/11459,skip index verification for not completed constraints during the consistency check . <nl> constraints create using separate transactions and separate commands . <nl> it can be the case that index command was already executed and the index is there <nl> while actual constraint transaction is not yet/longer there . <nl> this pr updates only consistency checker to ignore such indexes and <nl> only warn about those instead of claim about store inconsistency .,constraints create using separate transactions and separate commands . <nl> it can be the case that index command was already executed and the index is there <nl> while actual constraint transaction is not yet/longer there . <nl> this pr updates only consistency checker to ignore such indexes and <nl> only warn about those instead of claim about store inconsistency .,1522860832,"as statements are reference counted , it is not idea to let the abstracttraverseriterator close it 's resource ( statement ) more than once . this was exposed with the increased strictness of asserting that statements are open before operations . <nl> changelog : fix a bug that would cause exceptions with the message when using the traversal api from inside procedures .",0.9729729890823364
hazelcast_hazelcast/18594,"rename params to arguments or ' param values ' . <nl> this is to unify terminology : query has parameters , and for each <nl> parameter we provide an argument or a value <para-sep> convenient method to execute a distributed query with the given parameter values . <nl> gets the statement parameter values . <nl> sets the values for statement parameters . character . for every placeholder , a when the method is called , the contents of the list are copied . subsequent changes to the original list do n't <nl> adds a single parameter value to the end of the parameter values list . <nl> clears statement parameter values .","this is to unify terminology : query has parameters , and for each <nl> parameter we provide an argument or a value . <nl> nothing in the public api is changed , except for the method parameter names .",1619433178,see commit messages for details .,0.9028282761573792
Graylog2_graylog2-server/10118,"adding test case to check if index optimization throws npe . <cm-sep> if request config is , create new one instead of copying .","this made things much worse , by trying to copy a instance that is in this situation . this results in an npe and is aborting the index optimization job before it can perform any action . <nl> this change is now checking if the instance is and instantiates a new one in this case instead of trying to copy it .",1614014762,"before this change , any alert conditions associated with a stream were <nl> cloned identically ( including using the same id ) when cloning a stream . <nl> this was leading to a bug , where the alert condition was shown as being <nl> associated with the source of the clone process instead of the target . <nl> with this change , the alert condition is recreated during cloning , <nl> including generating a new id for it . <nl> ( cherry picked from commit sha )",0.8780240416526794
apache_incubator-pinot/6200,add controls for verbosity and query dialect,all changes backwards-compatible . <nl> no <nl> no . <nl> no,1603828511,"recipient provider factory now could instantiate both external and internal recipient providers . it first check the property file ( if it exists ) and try to instantiate the provider using the given class . if it fails , then it try to instantiate the provider using internal classes . if both fails , then a dummy provider is used . <nl> tested on local controller .",0.9526357054710388
ballerina-platform_ballerina-lang/29298,consider function typed vars of t ? kind as regular var symbols <cm-sep> fix broken unit tests <cm-sep> add test case for symbol ( ),this pr removes this behaviour and models such vars as regular var symbols .,1615997679,pr introduces <nl> - server connector connection as a param in resource signature . <nl> - respond native function to send back the response to the caller .,0.9383686184883118
apache_kafka/10730,: remove deprecated schedule method in processorcontext . <nl> removes the schedule method in processorcontext and all its <nl> implementations . <nl> method was deprecated back in version,"removes the schedule method in processorcontext and all its <nl> implementations . <nl> method was deprecated back in version . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1621429811,".. and remove bulk loading mechanism inside rocksdb . <nl> we need to validate in benchmarks that removing bulk loading would not incur large perf regression ; if yes , we should consider adding other optimizations like separate thread polls and parallel writes before merging this pr .",0.9494336247444153
elastic_elasticsearch/74186,"protect newly introduced system indices fully . <nl> this change updates the way we handle net new system indices , which are <nl> those that have been newly introduced and do not require any bwc <nl> guarantees around non-system access . these indices will not be included <nl> in wildcard expansions for user searches and operations . direct access <nl> to these indices will also not be allowed for user searches . <nl> the first index of this type is the geoip index , which this change sets <nl> the new flag on . <para-sep> search before indexing doc <nl> create a doc <nl> search again <nl> index wildcard search <nl> direct index search <nl> check if it is net new <nl> does the system index back a system data stream ?","this change updates the way we handle net new system indices , which are <nl> those that have been newly introduced and do not require any bwc <nl> guarantees around non-system access . these indices will not be included <nl> in wildcard expansions for user searches and operations . direct access <nl> to these indices will also not be allowed for user searches . <nl> the first index of this type is the geoip index , which this change sets <nl> the new flag on .",1623855143,add support for ' missing_bucket ' in group_by .,0.9759747982025146
apache_beam/14404,"nexmark query 0 . <para-sep> smear the shard into something more random-looking , to avoid issues with runners that do n't properly hash the key being shuffled , but rely on it being random-looking . e.g . <nl> used by query 0. this specifies number of random keys to generate . generated events will be assigned to these keys randomly and then goes through a gbk . <nl> used by query 0. this specifies cpu usage factor that the pardo in query 0 should use . version means pardo should be the cpu expensive operation on every element and version means pardo should pass through all elements directly . <nl> query ' 0 ' portability_batch ( not in original suite ) . this benchmark is created to stress the boundary of runner and sdk in portability world . the basic shape of this benchmark is source + gbk + pardo , in which the gbk read + pardo will require that runner reads from shuffle and connects with sdk to do cpu intensive computation . <nl> force round trip through coder .","in portability world , we expect on workers there are runners and sdks . current nexmark queries , e.g . nexmark query 0 , does not stress the boundary between runner and sdk . <nl> so i propose to have nexmark query 0 , which contains a source + gbk + pardo , to stress the boundary between runner and sdk",1617313915,"to extract the jobgraph , flink calls the main method of a jar and suppresses the <nl> stdout/stderr . it only prints the output on errors , or when no jobgraph was <nl> found . this is often not desired for debugging purposes and logging purposes . <nl> this change restores the original stdout/stderr when we detect that we are <nl> running inside the . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9477958679199219
grpc_grpc-java/7913,update readme etc to reference version <cm-sep> bump version to version <cm-sep> bump version to version-snapshot,there are three commits . they will be merged as separate commits . the second one will be the released commit .,1614041581,do not push merge button .,1.0
OpenAPITools_openapi-generator/8727,disable nullable fields by default . <nl> this is not in line with the oas and will prevent future dart nullabilty features ( nnbd ) from being useful as all types would be optional . <nl> users can still opt-in for this . <cm-sep> properties are nullable when not required and not nullable <cm-sep> support nullable/required fields . <nl> * properties in built_value need to be nullable when they are nullable in oas or when they are not required in oas <nl> * built_value does not support serializing values by default as it is based on a serialization format based on iterables/lists and not maps <nl> * dart-dio uses the built_value json plugin to convert the built_value format to regular json <nl> * by generating a custom serializer for each class we can add support for serializing values if the property is required and nullable in oas <nl> * this is a breaking change as not all properties in the models are nullable by default anymore <cm-sep> implement required/nullable for dart <cm-sep> changes for set types and enum names after rebase <cm-sep> add some comments and fix built_value fields with default being nullable <para-sep> a map always has string keys <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and call build ( ) <nl> todo add properties to the builder and,+ disable all fields nullable by default : <nl> this is not in line with oas and will prevent future dart nullabilty features ( nnbd ) from being useful as all types would be optional . this is a breaking change with fallback ( set ) . <nl> + properties are when nullable or ( not required and no defaultvalue ) . <nl> + support nullable/required fields in json <nl> * properties in built_value need to be when they are nullable in oas or when they are not required in oas <nl> * built_value does not support serializing values by,1613507368,"problem : the current client is based on a set of libraries ( package set ) from one year ago , based on the release of ghc . it is typical for library writers in the haskell community to maintain compatibility with the latest 0 major versions of the compiler . by this standard ( since , and are out ) we are generating an outdated client . moreover , the library itself went through several breaking versions in the meanwhile , so the code generated by this generator is not really compatible with a project started today . <nl>",0.9073390960693359
grpc_grpc-java/8237,"add some validation for ring_hash_lb_config . <para-sep> same as clientxdsclient.default_ring_hash_lb_policy_min_ring_size <nl> same as clientxdsclient.default_ring_hash_lb_policy_max_ring_size <nl> maximum number of ring entries allowed . setting this too large can result in slow ring construction and oom error . same as clientxdsclient.max_ring_hash_lb_policy_ring_size <nl> private , use roundrobinlbpolicy ( ) or ringhashlbpolicy ( long , long ) . <nl> private , use ringhashlbpolicy ( long , long ) . private , use ringhashlbpolicy ( long , long ) .","envoy uses default parameters for ring hash lb config ( min_ring_size = 0 , max_ring_size = 8m ) . <nl> the change follows the way that c-core does this : <nl> - grpc 's ring_hash lb config parser sets default values if the raw config does not specify min_ring_size or max_ring_size . <nl> - note , for us we need to do this in both ring_hash lb config parser and the cds lb policy that instantiates the directly .",1622834130,"in the future , the xds bootstrap may provides multiple xds server , with each has its own server uri and channel credential configurations . grpc client will try to connect to them one by one until found the first reachable one . for now , we only support using the first one . <nl> in this pr : <nl> - changed the logic of parsing bootstrap file , including the format of data returned to grpc client . <nl> - reformated json strings in bootstrap related tests . <nl> - added a couple of test cases for parsing bootstrap",0.9606032371520996
apache_druid/10874,"filter unauthorized views in informationschema <para-sep> function for the common pattern of generating a resource-action for reading from a view , using the view name . <nl> the ' view ' subschema functions represent views on druid datasources","this pr adjusts the informationschema class such that it properly filters out views based on authorization checks . previously it checked the view subschema against the ' druid ' schema name , and thus fell back on the unfiltered path",1612990641,"this pr adds a new /health endpoint on all services , intended for external health checks issued to druid services . <nl> this endpoint is unsecured , as external health checks do not necessarily support attaching authentication credentials ( e.g. , those issued by amazon elb ) . <nl> this pr also removes auth checks from the ' /isleader ' endpoints on coordinators and overlords , for similar external compatibility reasons .",0.872707188129425
keycloak_keycloak/7792,oidcidentityprovider incorrectly sets firstname and lastname in brokeredidentitycontext,"this is my first pr to keycloak ... please review carefully and let me know if i have to improve something . <nl> cheers , <nl> torsten",1613646482,the referenced commit should do the same and be a lot faster with big databases . i suspect db2 and other databases will have the same issues .,0.7637598514556885
ballerina-platform_ballerina-lang/28802,fix locations in keys <para-sep> transforms st stringliteralnode into ast string node . <nl> gives location of list of tomlnodes should only call this method when the execution order is ensured .,"this includes dotted keys , table array nodes generated tables and key lists . <nl> this pr also few npes on tostring as well caused by null keys in anonymous tables .",1613974806,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9283527135848999
vespa-engine_vespa/18169,preserve wanttorebuild until host is readied . <nl> this prevents starting too many rebuilds if hosts never transition out of <nl> provisioned after rebuild . <nl> this also ensures that we retry rebuilds until they succeed ( host becomes <nl> ready ) . <para-sep> preserve wanttorebuild/wanttoretire when rebuilding as the fields should n't be cleared until the host is readied ( i.e . we know it is up and rebuild completed ) <nl> set host 0 properties and deprovision it,this prevents starting too many rebuilds if hosts never transition out of <nl> provisioned after rebuild . <nl> this also ensures that we retry rebuilds until they succeed ( host becomes <nl> ready ) .,1623161100,"return status code 0 and print stack trace if nullpointerexception is thrown . <nl> when building a model , return 0 ( as opposed to 0 now ) and print stack trace <nl> when a nullpointerexception is thrown",0.8498858213424683
elastic_elasticsearch/73653,also rename write data stream alias during a restore . <nl> rename during a restore should also rename write data stream in data stream alias . <cm-sep> take include_aliases flag into account when restoring data stream aliases . <nl> take restoresnapshotrequest # includealiases ( ) into account when restoring <nl> data stream aliases from a snapshot into a cluster .,* take restoresnapshotrequest # includealiases ( ) into account when restoring <nl> data stream aliases from a snapshot into a cluster .,1622625426,this allows the step to move past the allocation check <nl> if the tier routing settings are manually unset . <nl> this helps a user unblock ilm in case a tier is removed ( ie . if the warm tier <nl> is decommissioned this will allow users to resume the ilm policies stuck in <nl> waiting for the warm nodes to become available and the managed <nl> index to allocate . this allows the index to allocate on the other available tiers ) .,0.929718554019928
grpc_grpc-java/7793,delete loadbalancer.helper apis that had been deprecated for a long time .,delete a bunch of old loadbalancer.helper apis that had been deprecated for a long time . <nl> - . <nl> - . <nl> these deprecated apis has stronger implementation requirement for synchronization as they originally did not require invocations to be from the synchronizationcontext ( although a logged warning was added later if detected the call is not from the synchronizationcontext ) . their replacements relaxed the burden for implementations to be thread-safe and would throw if calls are not from the synchronizationcontext .,1610149799,this has been deprecated since version,0.9528336524963379
hazelcast_hazelcast/18562,"remove client endpoint on connection remove . <nl> client endpoints were not destroyed on connection remove but <nl> instead a periodic task was cleaning them up ( every 0 seconds ) <nl> this was causing some tests to take long . <nl> added client connections to server connection manager so that <nl> can be called and related endpoint is <nl> removed as soon as the connection is removed . <para-sep> socket address can be null if connection closed before bind <nl> remote address can be null if connection closed before bind . on such a case , will not be called for this connection since we did not register the connection . endpoint removal logic ( inside ) will not be able to run , instead endpoint will be cleaned up by clienthearbeatmonitor # cleanupendpointswithdeadconnections later .",client endpoints were not destroyed on connection remove but <nl> instead a periodic task was cleaning them up ( every 0 seconds ) <nl> this was causing some tests to take long . <nl> added client connections to server connection manager so that <nl> can be called and related endpoint is <nl> removed as soon as the connection is removed .,1618844751,"makes the number of ports to use by the cluster configurable ( it was hardcoded as 0 ) . <nl> in most cases this is not an issue , since there will not be more than 0 hazelcast <nl> instances running on a single machine . but in those rare cases where this is needed <nl> ( e.g . for testing ) this property can be set . if not set , it will default to 0 , so <nl> there will not be any change if not configured explicitly .",0.9480669498443604
OpenAPITools_openapi-generator/9120,"added int arrays parsing in parameters . respect the 'required ' property . <cm-sep> replaced spaces with tabs <cm-sep> generate samples with new spacing <para-sep> only process the following type ( or we can simply rely on the file extension to check if it 's a go file ) import ' time ' if the operation has a required time parameter <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> parseint64parameter parses a string parameter to an int64 . <nl> parseint32parameter parses a string parameter to an int32 . <nl> parseint64arrayparameter parses a string parameter containing array of values to [ ] int64 . <nl> parseint32arrayparameter parses a string parameter containing array of values to [ ] int32 . <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl> if an error occurred , encode the error with the status code if no error , encode the body and the result code <nl>","_ * affects the go-server only._ . <nl> before : . <nl> after : . <nl> _before/after below assume , that mentioned optional and required fields are missing in the payload._ <nl> before : . <nl> after : . <nl> itself does n't initialize the parameters . <nl> before : . <nl> after : .",1617001907,e.g contains which has a special meaning in c++ .,0.8633375763893127
apache_kafka/10512,": remove deprecated partitionassignor interface <para-sep> first try to get the class if passed in as a string <nl> latter 's cached metadata while sending subscriptions , and the latter needs former 's returned assignment when","more detailed description of your change <nl> 0. remove partitionassignor and related classes , update docs <nl> 0. move unit test <nl> 0. fix some related typo . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1617975931,"this does not make a lot of sense as these classes are meant to represent cluster resources , which would not have a concept of 'name type ' . this work has not been released yet , so we have time to change it . <nl> this pr looks to refactor the code to remove the name type field from the java class . ( the scala one will age out once is done , and removing it would involve changes to the interface , so this class was not touched ) . <nl> this is achieved by replacing the",0.9393734335899353
runelite_runelite/13099,add redwood objects and log message,"add more data to track for crowdsourcing woodcutting and cooking . new log object ids , log messages , and a spit-roast cooking message .",1611398835,remove full clue description ( clue text ) from cryptic clues and hot/cold clue as the solutions are written right below and with the full text this sometimes makes clue helper unusable in fixed mode .,0.7492707371711731
apache_beam/14988,refactor external worker service to be part of sdks-java-harness . <nl> move external worker service from runners/portability/java to sdks/java/harness <nl> move external worker service depdended classes from runners/java-fn-execution to sdks/java/fn-execution . <nl> in order that external worker service can be launched in worker container 's boot script where only beam-sdks-java-harness is intially included in the image . <para-sep> an interface sharing common behavior with services used during execution of user fns . * / <nl> a headeraccessorprovider which intercept the header in a grpc request and expose the relevant fields . <nl> this method should be called from the request method . * / <nl> remove the null check below once this is fixed .,move external worker service from runners/portability/java to sdks/java/harness <nl> move external worker service depdended classes from runners/java-fn-execution to sdks/java/fn-execution . <nl> in order that external worker service can be launched in worker container 's boot script where only beam-sdks-java-harness is initially included in the image .,1623354757,it also extends the runners web page with information about the version version,0.8697091937065125
Alluxio_alluxio/13126,"track cache put failure on no space on disk <para-sep> failed put attempt due to ' no space left on device ' error . this can happen on misconfiguration ( e.g. , cache capacity is larger than what 's available ) , disk issues , or under-estimation of file system overhead ( e.g. , writing a file of 10b may result in 0 b on disk ) . in this case , we need to force data to be evicted in retries , otherwise hitratio may drop due to inability to write new data to cache . <nl> check if we are able to insert page after evicting victim page <nl> errors when adding pages due to failed writes but before reaching cache capacity . * /","this happens when ( 0 ) cache is configured with wrong and smaller capacity , ( 0 ) for some reason disk capacity allocated to alluxio was ' stolen ' by other applications , or ( 0 ) alluxio cache is under-counting the real space used on disk ( e.g. , due to bugs , inode overhead and etc ) . <nl> this pr aim to <nl> 0. add a metrics to monitor and report when happens <nl> 0. force evicting items in a retry in this case <nl> 0. add a new flag to allow users to set the",1616696651,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9685928821563721
apache_incubator-pinot/6549,adding metrics for minion tasks status <para-sep> number of tasks status <nl> reset all the status to 0,"sample metrics reported by jmx : . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1612518972,* add enum values for supported tdigest pinot function syntax <nl> * add logic to reduce tdigests in thirdeye dashboard app by using a count-weighted average ( since pinot returns doubles for tdigest function aggregations ),0.9242100715637207
ballerina-platform_ballerina-lang/26872,"remove stdlib from the build <para-sep> implementation project ( ' : language-server : language-server-stdlib ' ) baloimplementation project ( path : ' : ballerina-lang : annotations ' , configuration : 'baloimplementation ' ) baloimplementation project ( path : ' : language-server : language-server-stdlib ' , configuration : 'baloimplementation ' ) <nl> implementation project ( ' : ballerina-runtime-api ' ) <nl> include ( ' : ballerina-auth ' ) include ( ' : ballerina-cache ' ) include ( ' : ballerina-config-api ' ) include ( ' : ballerina-crypto ' ) include ( ' : ballerina-file ' ) include ( ' : ballerina-log-api ' ) include ( ' : ballerina-mime ' ) include ( ' : ballerina-reflect ' ) include ( ' : ballerina-system ' ) include ( ' : ballerina-task ' ) include ( ' : ballerina-time ' ) include ( ' : ballerina-cli-utils ' ) include ( ' : language-server : language-server-stdlib ' ) include ( ' : ballerina-libs ' ) include ( ' : bir-spec ' ) project ( ' : ballerina-runtime-api ' ) .projectdir = file ( 'stdlib/runtime-api ' ) project ( ' : ballerina-auth ' ) .projectdir = file ( 'stdlib/auth ' ) project ( ' : ballerina-cache ' ) .projectdir = file ( 'stdlib/cache ' ) project ( ' : ballerina-config-api ' ) .projectdir = file ( 'stdlib/config-api ' ) project ( ' : ballerina-crypto ' ) .projectdir = file ( 'stdlib/crypto ' ) project ( ' : ballerina-file ' ) .projectdir = file ( 'stdlib/file ' ) project ( ' : ballerina-log-api ' ) .projectdir = file ( 'stdlib/log-api ' ) project ( ' : ballerina-mime ' ) .projectdir = file ( 'stdlib/mime ' ) project ( ' : ballerina-reflect ' ) .projectdir = file ( 'stdlib/reflect ' ) project ( ' : ballerina-system ' ) .projectdir = file ( 'stdlib/system ' ) project ( ' : ballerina-task ' ) .projectdir = file ( 'stdlib/task ' ) project ( ' : ballerina-time ' ) .projectdir = file ( 'stdlib/time ' ) project ( ' : ballerina-cli-utils ' ) .projectdir = file ( 'cli/ballerina-cli-utils ' ) project ( ' : language-server : language-server-stdlib ' ) .projectdir = file ( 'language-server/modules/langserver-stdlib ' ) project ( ' : ballerina-stringutils ' ) .projectdir = file ( 'stdlib/stringutils ' ) project ( ' : ballerina-libs ' ) .projectdir = file ( 'distribution/libs ' ) project ( ' : bir-spec ' )",fix the build without test . should pass .,1605102207,this will also temporarily disable some negative test cases as well .,0.8826414346694946
apache_beam/13891,"enable user-defined java scalar functions in zetasql . <nl> this completes the proof of concept . note however that when udfs and <nl> built-in zetasql operators are mixed , the program will crash without <nl> warning . <para-sep> pass jars used by java udf tests via system properties . <nl> tests for zetasql udfs written in java . system properties beam.sql.udf.test.jarpath and beam.sql.udf.test.empty_jar_path must be set . <nl> this is a loophole in type checking . the sql function signature does not need to match the java function signature ; only the generated code is typechecked . todo ( ) : fix this and adjust test accordingly . <nl> the java definition for isnull takes a string , but here we pass it a long . <nl> todo ( ) this should fail earlier , before compiling the calcfn . <nl> todo ( ) add tests that mix udfs and builtin functions that rely on the zetasql c++ implementation .","this completes the proof of concept . note however that when udfs and <nl> built-in zetasql operators are mixed , the program will crash without <nl> warning",1612392356,"adds a policy for custom timestamps & timestamps . this is useful most common situations for users to use directly . changes in this pr : . <nl> - is changed to a so that it is lambda friendly . ( e.g . <nl> - added : built in custom timestamp policy where the timestamps are expected to be roughly monotonic , with a bound on maximum delay/skew . this handles advancing watermark when a partition is idle . <nl> - the policy itself is fairly simple : keep advancing the watermark to . the two special cases are future",0.9763904809951782
confluentinc_ksql/7238,"bubble up errors from harouting unless explicit use of standbyfallbackexception <para-sep> if we threw some explicit exception , then let it bubble up . all of the row handling is wrapped in a ksqlexception , so any intentional exception or bug will be surfaced . <nl> if we get some kind of unknown error , we assume it 's network or other error from the ksqlclient and try standbys <nl> if this is the first row overall , skip the header <nl> if we receive an error that 's not a network error , we let that bubble up . <nl> this exception is thrown to indicate that pull queries should fallback on the next standby in line . <nl> when : <nl> then : <nl> given : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","the issue is that certain errors are deterministic and often caused by some form of user error or code bug . not only is there no use in retrying something that will have the same effect on a standby , but if we treat it similar to a transient error and print the error message , it 's rather confusing since trying again wo n't fix the issue . <nl> the goal of this pr is to surface any bug by requiring any standby retries to explicitly use and by bubbling up other exceptions by default . in particular ,",1615913956,"this pr has two parts . <nl> the first commit makes it possible to have where clause bounding windowstart using the following comparison types : <nl> - <nl> - <nl> - <nl> - <nl> - . <nl> some of which were already supported in certain situations , but are now all full supported . <nl> the second commit removes the requirement to have a bound on windowstart at all for windowed tables . with no bounds , all windows are returned . <nl> e.g . <nl> usual .",0.9456827044487
apache_incubator-pinot/6284,"wip - support for text index withour raw <para-sep> text-index enabled sv column <nl> for text index on raw columns , check the config to determine if actual raw value should be stored or not <nl> by default always store the raw value if the config is set to true , do n't store the actual raw value there will be a dummy value <nl> test for the text index configured to not store the default value full index is stored <nl> configurable default value is used","adding support for text index without raw data . <nl> our use cases are indexing huge blobs of text ( string ) data . we have seen the raw forward index size upto 2gb per segment for text data . as an example for few of our tables , supporting this mode of text index will lead upto 2tb storage space saving per colo per table . these tables use text index only in the filter clause . the raw values are neither projected nor used in the query in filter other than text_match clause . <nl> - like other",1605946499,"when using segment size based auto tuning , the initial rows threshold is 100k currently . adding a config to override the initial num rows , so that it can be changed if a table needs more/less as the initial .",0.9570661783218384
apache_druid/10912,"allow overlapping intervals for the compaction task <para-sep> this test iterates huge intervals ( version years ) with the second granularity . the motivation behind this test is ensuring that intervalsbygranularity can handle these huge intervals with a tiny granularity . however , this test takes a long time to populate all intervals based on the second granularity ( more than 0 min ) , so is ignored by default . we should make this test not a unit test , but a load test . <nl> all segments in the previous expectedsegments should still appear as they have larger segment granularity .",this is a valid use case where you run a compaction task that overwrites a segment of a huge interval and other segments of smaller intervals that overlap the huge one,1613854306,"each time a segment is ' add ' ed to a timeline , ' iscomplete ' is called on the holder that it is added to . ' iscomplete ' is an o ( segments per chunk ) operation , meaning that adding n segments to a chunk is an o ( n^0 ) operation . this blows up badly if we have thousands of segments per chunk . <nl> the patch defers the ' iscomplete ' check until after all segments have been inserted . <nl> the problem was especially noticeable in , since segment allocation operations need to",0.9586431980133057
ballerina-platform_ballerina-lang/28441,stop considering isolated var access as transferring in <cm-sep> add tests,the following is now allowed .,1612448831,"fix array type , invalid syntax parser test cases",0.8066527843475342
elastic_elasticsearch/74264,"add migrate to data tiers api . <nl> this adds the api to expose the service for migrating the elasticsearch <nl> abstractions ( indices , ilm policies and an optional legacy template to <nl> delete ) to data tiers routing allocation ( away from custom node attributes ) <para-sep> > <nl> { ilm-init } must be stopped before performing the migration . use the > <nl> // <nl> testsetup <nl> teardown // <nl> represents the name of node attribute used for index shard allocation filtering ( usually ) <nl> represents the name of the legacy ( v1 ) index template to delete . <nl> some tests might stop ilm in order to perform the migration to data tiers , let 's restart it <nl> creating a legacy template to use in the migrate api <nl> let 's create a policy that 'll need migrating , with a long for the cold phase such that managed indices stop in warm/complete/complete - this will ensure the migration will have to update the cached phase for these indices <nl> wait for the index to advance to the warm phase <nl> let 's also have a policy that does n't need migrating <nl> assign the rollover-only policy to a few other indices - these indices and the rollover-only policy should not be migrated in any way <nl> let 's stop ilm so we can perform the migration <nl> let 's verify the legacy template does n't exist anymore <nl> let 's assert the require.data : warm configuration the ' indexwithdatawarmrouting ' had was migrated to _tier_preference : data_warm , data_hot <nl> let 's retrieve the migrated policy and check it was migrated correctly - namely the warm phase should not contain any allocate action anymore and the cold phase should contain an allocate action that only configures the number of replicas <nl> let 's also verify the cached phase definition was updated - as the managed index was in the warm phase , which after migration does not contain the allocate action anymore , the cached warm phase should not contain the allocate action either","this adds the api to expose the service for migrating the elasticsearch <nl> abstractions ( indices , ilm policies and an optional legacy template to <nl> delete ) to data tiers routing allocation ( away from custom node attributes ) . <nl> the api is . <nl> the response will contain the name of the deleted legacy index template <nl> ( if any was deleted ) , a list of ilm policies and a list of indices names containing <nl> the policies and indices that were migrated .",1623959714,adds t_test metric aggregation that can perform paired and unpaired two-sample <nl> t-tests . in this pr support for filters in unpaired is still missing . it will <nl> be added in a follow-up pr .,0.9890169501304626
apache_druid/11070,"make dropexisting flag for compaction configurable <cm-sep> fix checkstyle <cm-sep> fix checkstyle <cm-sep> fix test <cm-sep> add tests <cm-sep> fix spelling <para-sep> set the dropexisting flag to true in the ioconfig of the compaction task <nl> all the hour segments got dropped even if we do not have all minutes segments fully covering the 0 hours interval . in fact , we only have 0 minutes of data out of the 0 hours interval . <nl> all the hour segments did not get dropped since minutes segments did not fully covering the 0 hours interval . <nl> set dropexisting to true <nl> set dropexisting to true <nl> set dropexisting to false <nl> all segments in the previous expectedsegments should still appear as they have larger segment granularity . <nl> set dropexisting to false <nl> set dropexisting to true <nl> set dropexisting to true <nl> since dropexisting is set to true ... <nl> 0 segments across 0 days ( 0 total ) ... <nl> set dropexisting to false <nl> set dropexisting to false <nl> since dropexisting is set to false ... the earlier segment with year granularity is still 'used ' as it ’ s not fully overshaowed . this is because we only have newer version on 0-0-0 to 0-0-0 and 0-0-0 to 0-0-0. the version for the year segment is still the latest for 0-0-0 to 0-0-0 and 0-0-0 to 0-0-0. hence , all three segments are available and the expected intervals are combined from the day and year segment granularities ( which are 0-0-0 to 0-0-0 , 0-0-0 to 0-0-0 and 0-0-0 to 0-0-0 ) <nl> set dropexisting to true <nl> set dropexisting to true <nl> since dropexisting is set to true ... <nl> 0 segments across 0 days ( 0 total ) ... <nl> set dropexisting to false <nl> we wil have one segment with interval of 0-0-0/0-0-0 ( compacted with year ) <nl> 0 segments . 0 compacted year segment and 0 newly ingested day segments across 0 days we wil have one segment with interval of 0-0-0/0-0-0 ( compacted with year ) from the compaction earlier two segments with interval of 0-0-0/0-0-0 ( newly ingested with day ) and two segments with interval of 0-0-0/0-0-0 ( newly ingested with day ) <nl> set dropexisting to false <nl> since dropexisting is set to true ... this will submit a single compaction task for interval of 0-0-0/0-0-0","make dropexisting flag for compaction configurable and add warning documentations . <nl> however , it was pointed out after the pr was merged that this new option can cause temporary data unavailability for data within the specified interval of the ingestion task . this pr also adds documentation with warning to temporary data unavailability if dropexisting flag is used . <nl> this pr does not contain the fix for this problem yet . the fix will come later",1617685733,"with this pr , users can simply skip head rows rather than guessing the schema from the head rows . the is effective for only non-hadoop index tasks .",0.977371335029602
apache_shardingsphere/10698,fix create sharding table rule error,changes proposed in this pull request : <nl> - fix create sharding table rule error,1623051308,changes proposed in this pull request : <nl> - fix shadow value in literal expression,0.9379577040672302
ballerina-platform_ballerina-lang/27410,"remove type checking of service remote and resource methods <para-sep> as of service typing changes , resource functions are not considered for object subtyping . <nl> service classes are not required to implement reference resource functions . <nl> service typing does not consider resource methods when type checking . <nl> service resource methods are not considered as part of service objects type . <nl> stype ;","this is a breaking change , this disallow resource method decl in object type decl .",1607504232,a valid main function signature requires : <nl> - the public modifier <nl> - the return type to be an int if returns exist ( alternatively the main function may not return a value ),0.9314184784889221
apache_pulsar/10450,improve error handling during localrun start <cm-sep> cleaning up <para-sep> todo : correctly implement function version and id,"if there is an error during localrun start , it might leave localrun in a unhealthy state . <nl> make sure we safely exit if a error occurs during startup",1619758242,"fix break changes in namespace offload policy and rabbitmq sink . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no ) <nl> - anything that affects deployment :",0.9100661873817444
apache_beam/14309,"resubmit storage api sink with noop failing test removed . <cm-sep> remove bogus test <para-sep> use the new , experimental storage write api . * / <nl> control how many parallel streams are used when using storage api writes . <nl> this ensures that the beam rows are directly translated into protos for sorage api writes , with no need to round trip through json tablerow objects . <nl> fallback behavior : convert to json tablerows and convert those into beam tablerows . <nl> create a write stream for use with the the storage write api . * / <nl> create an append client for a given storage api write stream . the stream must be created first . <nl> flush a given stream up to the given offset . the stream must have type buffered . * / <nl> finalize a write stream . after finalization , no more records can be appended to the stream . <nl> commit write streams of type pending . the streams must be finalized before committing . * / <nl> an interface for appending records to a storage api write stream . * / <nl> append rows to a storage api write stream at the given offset . * / <nl> pin this object . if close ( ) is called before all pins are removed , the underlying resources will not be freed until all pins are removed . <nl> unpin this object . if the object has been closed , this will release any underlying resources . <nl> / * * controls whether to use the map or row fieldtype for a tableschema field that appears to <nl> retry manager used by storage api operations . this class manages a sequence of operations ( e.g . sequential appends to a stream ) and retries of those operations . if any one operation fails , then all subsequent operations are expected to fail true and will alll be retried . <nl> enum returned by onerror indicating whether errors should be retried . <nl> the in-flight operations will not be retried . <nl> all operations will be retried . <nl> run all the operations again . <nl> base dynamicdestinations class used by the storage api sink . * / <nl> storage api dynamicdestinations used when the input is a beam row . * / <nl> todo : make static ! or at least","the test was broken and did n't test anything . a better test would be to modify bigquerytornadoes to test this path , but we will do this in a different pr ( first we need to ensure that the testing project is whitelisted by bigquery ) .",1616516740,"for example , users can use this annotation to write a method that extracts a value saved in a state before garbage collection",0.9884223341941833
apache_flink/15982,log the remote address when channel is closed in nettypartitionrequestclient,"for , when a channel is closed , the channel will throw a localtransportexception with the error message ' sending the partition request to 'null ' failed. ' . the message is confusing since we would n't know where the remote client connected to this channel locates , and we could n't track down to that taskexecutor and find out what happened . <nl> in this situation , we need to log the address stored in instead of the null value in . users can located the destination taskmanager based on this remote address . <nl> - log the remote",1621579465,"programtargetdescriptor # jobid possibly can be of type jobid instead of string . <nl> replacing programtargetdescriptor # jobid type string with type jobid . <nl> changing related tests code . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( do n't know ) <nl> - the runtime per-record code paths ( performance sensitive )",0.8583484292030334
elastic_elasticsearch/74388,increase default api key auth cache size to 25k . <nl> also add trace logging on eviction for the api key auth cache to help <nl> identify any cache thrashing issue . <para-sep> package private for test <nl> fill the cache <nl> wait for the entry to expire <nl> cache a new entry <nl> fill the cache <nl> prepare the warning logging to trigger <nl> will not log warning again for the next eviction because of throttling,this pr increases default size of the api key auth cache from 10k to 25k <nl> to cover the majority of expected deployment sizes . also add trace logging <nl> on eviction for the api key auth cache to help identify any cache thrashing <nl> issue .,1624328919,"today a transport response uses the same wire format version as the <nl> corresponding request . this mostly works since we mostly know we are <nl> communicating with a node with a compatible version . tcp handshakes do n't have <nl> this guarantee since they use <nl> to let us handshake with older nodes . this results in the strange situation of <nl> a node of major version responding to a node of major version using a <nl> wire format of version . <nl> we put extra effort into the longer bwc requirements for successful responses , <nl> but we",0.9614526629447937
elastic_elasticsearch/72991,"disallow non-collapsable subselects with order by . <nl> ordering an already pre-ordered and limited subselect is not allowed , <nl> as such queries can not be collapsed and translated into query dsl , but <nl> the require an extra ordering step on top of the results returned <nl> internally by the search/agg query . <para-sep> select with collapsable subqueries","ordering an already pre-ordered and limited subselect is not allowed , <nl> as such queries can not be collapsed and translated into query dsl , but <nl> the require an extra ordering step on top of the results returned <nl> internally by the search/agg query .",1620831001,"the pom files for our published artifacts are sent to maven central <nl> during elastic 's release process , but we may not found out until then <nl> that we have inadvertently broken the pom structure , as has happened <nl> several times before . this commit adds validation of the pom file <nl> specifically for the rules required by maven central .",0.9362277984619141
OpenAPITools_openapi-generator/8940,better error handling for toexamplevalue <para-sep> put toexamplevalue in a try-catch block to log the error as example values are not critical,better error handling for toexamplevalue with a try-catch block so that a single issue in generating the example wo n't stop the code generation process from completion .,1615364013,description of the original pr <nl> > we want to able to unit test our code that uses the generated api code . <nl> in order to do that we need a virtual interface to mock away the <nl> generated api code . <nl> > <nl> > this pr introduces two new config options for the cpprest generator : <nl> > <nl> > ' generateinterfacesforapis ' will generate an abstract base class <nl> ( interface ) for all apis . <nl> > ' generategmocksforapis ' will additionally generate google mock classes <nl> for the apis . this config option of,0.8285666704177856
elastic_elasticsearch/74468,"adjust ccr data stream test that tests following a backing index after the <nl> data stream has been auto followed . <nl> avoid that a data stream matches with a builtin template that uses ilm . <nl> the manual rollover that happens in this test , may cause ilm to add <nl> setting , which causes explicit <nl> follow index api call to fail in this test . <para-sep> the data stream name should n't match with builtin ilm policies to avoid test instabilities . ( the manual rollover that happens in this test , may cause ilm to add setting , which causes explicit follow index api call to fail in this test ) <nl> because the builtin logs template is n't used , a template should be defined here .","adjust ccr data stream test that tests following a backing index <nl> after the data stream has been auto followed . <nl> avoid that a data stream matches with a builtin template that uses ilm . <nl> the manual rollover that happens in this test , may cause ilm to add <nl> setting , which causes explicit <nl> follow index api call to fail in this test .",1624439237,this pr introduces using adoptopenjdk 's official api to download jdks .,0.9060516357421875
apache_druid/11078,"add config to skip storing audit payload if exceed limit <cm-sep> fix checkstyle <para-sep> this string is the default message stored instead of the actual audit payload if the audit payload size exceeded the maximum size limit configuration <nl> inserts an audit entry in the audit table <nl> serialize object to string <nl> the objectmapper of this annotation will skip serialization of any field with null value . <nl> provides objectmapper that suppress serializing properties with null values <nl> in our test , payload object is already a string so to serialize to string , we just return a string <nl> entry 0 payload has a null field for one of the property","introduce a new configuration that skip storing audit payload if payload size exceed limit and skip storing null fields for audit payload . <nl> audit log such as coordinator.compaction.config can get very large as datasources and their configurations churn . this can cause problems such as <nl> - metadata database taking up too much space / running out of storage space <nl> - configuration change ( such as compaction configuration ) failing as we are not able to insert new row into audit table due to exceeding the database size limit ( max_allowed_packet , etc ) . <nl> this pr",1617775889,and classes are introduced that can wrap existing long/float aggregators to handle string columns . both of the classes are used by to be used when input column is known to be of string type,0.9823904633522034
vespa-engine_vespa/17209,reorder generic types for request and response in handler <cm-sep> be explicit if generic type is for request or response entity <cm-sep> rename 'tohttpresponse ' to 'executehandler ' <cm-sep> rename class 'uri ' to 'uribuilder ' <cm-sep> add 'requestcontext.uribuilder ( ) ' <cm-sep> use uri builder in staterequesthandler <para-sep> a uri which provides convenience methods for creating various manipulated copies . this is immutable . <nl> the uri instance wrapped by this * / <nl> returns a uri with the given path appended and all parameters removed * /,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616767367,"please review only , will merge later",0.9368317127227783
elastic_elasticsearch/74717,this reverts commit sha . <cm-sep> fix <para-sep> we have to close here before accessing the bytes when using compression to ensure that some marker bytes ( eos marker ) are written . <nl> compressed stream wrapped bytes must be no-close wrapped since we need to close the compressed wrapper below to release resources and write eos marker bytes but must not yet release the bytes themselves,two things that can be simplified here : . <nl> 0. instantiating a when not doing any compression <nl> just needlessly wastes a few objects and adds indirection . when doing compression <nl> it does not really simplify the code by much if at all . <nl> = > removing it to save some cycles on the io threads . <nl> 0. the fact that the compressible stream closes the stream that it wraps is never used productively <nl> and we had to hack around it by wrapping the stream to disable close <nl> = > changed behavior here to,1624994575,merges the remaining implementation of into <nl> so that we can more easilly make them work properly without <nl> which should save memory and speed them up .,0.9402883052825928
grpc_grpc-java/8134,"ignore balancing state update from priority 's child lb policy after the entire priority load balancer is shut down . <para-sep> reactivate policy_a , balancing state update reflects the latest connectivity state and picker . <nl> lb shutdown and subchannel state change can happen simultaneously . if shutdown runs first , any further balancing state update should be ignored . <nl> lb shutdown and subchannel state change can happen simultaneously . if shutdown runs first , any further balancing state update should be ignored . <nl> lb shutdown and subchannel state change can happen simultaneously . if shutdown runs first , any further balancing state update should be ignored .","loadbalancers should not propagate balancing state updates after itself being shutdown . <nl> for lb policies that maintain a group of child lb policies with each having its independent lifetime , balancing state update propagations from each child lb policy can go out of the lifetime of its parent easily , especially for cases that balancing state update is put to the back of the queue and not propagated up inline . <nl> for lbs that are simple pass-through in the middle of the lb tree structure , it is n't a big issue as its lifecycle would be the",1620066681,"i tried to keep the changes minimal , to allow for easily backporting this to earlier releases if necessary . <nl> currently , if a server half-closes a stream with a netty client , both server and client will hold onto the stream resources until ( if ever ) the client calls halfclose ( ) . the same problem does not occur with an okhttp client , as triggers deletion of the stream reference on the client and sends a rst_stream to the server , which lets the netty server drop the stream resources as well . <nl> this pr",0.9378643035888672
OpenAPITools_openapi-generator/9167,"improve types & imports . <nl> * do n't use importmapping as it is intended for something different that is not possible in dart <nl> * introduce imports map for dart specific features <nl> * always import <nl> * get rid of additionalreservedwords <nl> * fix not working <nl> * use required type mappings in samples <nl> * no longer define additional reserved words as it is impossible to list all anyways , they can now be configured via type-mapping parameter <nl> * simplify dio imports <para-sep> these types return isprimitive=true in templates <nl> data types of the above values which are automatically imported <nl> import everything , unless it is from dart : core . <nl> check if there is a mapping that can be used <nl> anything with an import mapping is likely generator specific and can not be used as model name . <nl> name of the pet <nl> fake endpoint for testing various parameters 假端點 偽のエンドポイント 가짜 엔드 포인트 fake endpoint for testing various parameters 假端點 偽のエンドポイント 가짜 엔드 포인트","* do n't use importmapping as it is intended for something different that is not possible in dart <nl> * introduce imports map for dart specific features <nl> * always import <nl> * get rid of additionalreservedwords <nl> * fix not working <nl> * use required type mappings in samples <nl> * no longer define additional reserved words as it is impossible to list all anyways , they can now be configured via type-mapping parameter <nl> * improve dart-dio imports . <nl> i think this is a much better solution and allows customization via cli or config parameters . <nl>",1617543551,"summary <nl> - generators without runtime models conversion use ' original ' property naming by default . it 's still possible to change it via cli options - might be helpful when used together with customized templates . the cli option description has been modified to provide some more context . <nl> - generators with runtime conversion ( typescript-fetch , typescript-node , typescript-reduxquery ) keep using ' camelcase ' . <nl> implementation notes <nl> - i decoupled from . former respects the , while latter keeps always using camelcase . <nl> - refactoring : use an enum instead of string",0.9528994560241699
gocd_gocd/9126,removed scms version v3 <cm-sep> removed secret-configs version v2,remove deprecated scms and secrets config api .,1615799695,for a quick version release we had reverted all changes mad post version . this pr is to bring back all the reverted changes .,0.9769818782806396
apache_camel/5685,yaml-dsl : support inline rest verbs <cm-sep> yaml-dsl : support restconfiguration <cm-sep> yaml-dsl : sort yaml properties to avoid code changes in the geenrated code <cm-sep> yaml-dsl : simplify deserializers generator <cm-sep> yaml-dsl : support descriptiondefinition <para-sep> xmlelementref <nl> special handling for rest + verb definition,- yaml-dsl : support inline rest verbs <nl> - yaml-dsl : support restconfiguration <nl> - yaml-dsl : sort yaml properties to avoid code changes in the geenrated code <nl> - yaml-dsl : simplify deserializers generator <nl> - yaml-dsl : support descriptiondefinition .,1623916007,- fix ( ) : propagate inline count in camel-olingo2 component . <nl> add result count ( coming from system query option $ inlinecount ) to odata entries when using splitresults . <nl> - fix ( ) : configure entity provider properties on camel-olingo2 . <nl> add uri param configuration settings for read/write entity provider properties . the entity provider properties are used for each read/write operation and specify the way to serialize odata entries as json/xml/atom data . <nl> - fix ( ) : fix merge operation in camel-olingo2 . <nl> merge operation must enable isdatabasedpropertyserialization setting in the,0.9451823830604553
apache_beam/14610,"optimize byte size calculation of lazy iterables <para-sep> advance lazy elementbytesizeobservers , if any . <nl> mock doing work on the iterable items <nl> check that the underlying consumers are each invoked per element . <nl> clear the timestamp before comparison .",update the byte size calculation for lazy iterables after processing instead of counting output stream,1619035088,"added test cases for implementation for in . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9485810399055481
apache_kafka/10902,: process entire batch reader in the commit handler <para-sep> for testing purposes if ' records ' is empty just assume that there is one control record in the batch,process entire batch and make sure that is called before calling on the iterator .,1623983715,"in the original test , we will sleep for static 0 seconds to ensure the automated group offset sync is complete . it sometimes synced fast ( less than 0 sec ) , and sometimes slow ( ~ 0 seconds ) . i rewrite the sleep to wait for specific condition : <nl> 0. to make sure the topic partition metadata is synced <nl> 0. to make sure the consumergroupoffset is also synced . <nl> i 've tested in my local environment a lot of times . it can make the test more stable . <nl> thanks .",0.8907350301742554
elastic_elasticsearch/72682,add test for persistent cache clean up after relocation,this pull request adds a test to verify that the persistent cache is correctly cleaned up after a shard is relocated . i 've been surprised to see we do n't have integ tests for this .,1620131164,the assertions in the existing logic tripped for non-primary shards . <nl> this commit adds a path to the size data without those assertions and a test that the <nl> allocator works correctly for replica shards . <nl> - non issue because this bug has n't been released yet,0.9476511478424072
OpenAPITools_openapi-generator/9661,moved switch to abstract <cm-sep> build samples,moving the nullable reference types switch from aspnet generator to abstract so all csharp can use it .,1622678174,update the generated code comment to the following official go pattern : . <nl> this allows the auto-generated code to be differentially processed by go lint as discussed here : . <nl> this is also used by go report card .,0.8949412703514099
prestodb_presto/15673,allow node to be identified as resource manager <cm-sep> add resourcemanager <cm-sep> allow multiple coordinators in distributedqueryrunner <cm-sep> allow multiple coordinators to update memory assignments <cm-sep> add drift annotations for basicqueryinfo and nodestatus serialization <para-sep> / ;,test plan - verifier run .,1612392755,"- trigger bucket rebalancer after cluster restart . we still wait for a grace period to make sure all workers are back online . <nl> - add minimum alive worker check when reassigning buckets . the limit is configurable and the default is 0 . <nl> the purpose of the minimum worker count check is to prevent unnecessary recovery when too many nodes go down and the rest of the cluster is not able to hold the data . under such situation , we may rather fail the cluster than wasting resources recovering . <nl> note that this check should",0.8949493169784546
elastic_elasticsearch/74520,clean up build tools dependencies and fix maven coordinates <para-sep> },"this pull request fixes some fallout form the refactoring . a few things : . <nl> 0. fix the maven coordinates for the project so it 's published under the group as intended . <nl> 0. remove the runtime dependency so it 's not included in the published pom . we embed this dependency in the build tools jar so there 's no need to bring it in transitively . also , we do n't publish it , so that would fail . <nl> 0. remove the compile time dependency on the shadow plugin . we only reference it for",1624485660,"ldapsessionfactorytests # testssltrustisreloaded relies on the resource watcher <nl> to detect the cert file overwriting . resource watcher detects changes by only <nl> inspecting the file size on disk and the last access timestamp . <nl> for the last access timestamp , the resolution can be as low as one second depending <nl> on the jdk and the fs type . it is thus preferable to rely on file size differences in tests .",0.8349658846855164
elastic_elasticsearch/73190,"cache repositorydata outright instead of serialized . <nl> serializing and compressing seems to have been the wrong trade-off in hindsight . <nl> while saving some heap on a quiet master it makes every repository operation cost heap for <nl> the a newly instantiated . concurrent repository operations and snapshot api <nl> requests can thus easily lead to many duplicate instances on heap causing memory pressure . <nl> limiting caching to smaller instances also appears to have been the wrong choice in hindsight . <nl> while duplication of a few 100kb instances of is mostly not a big deal , duplicating <nl> a instance a couple of times ( e.g . seen during heavily concurrent get snapshots requests ) <nl> eventually becomes a problem . <para-sep> creates a copy of this instance that does not track any shard generations . <nl> best effort cache of the latest known repository data <nl> we can cache in the most recent version here without regard to the actual repository metadata version since we 're only caching the information that we just wrote and thus wo n't accidentally cache any information that is n't safe <nl> cache repository data if repository data caching is enabled . <nl> do n't cache shard generations here as they may be unreliable","serializing and compressing seems to have been the wrong trade-off in hindsight . <nl> while saving some heap on a quiet master it makes every repository operation cost heap for <nl> the a newly instantiated . concurrent repository operations and snapshot api <nl> requests can thus easily lead to many duplicate instances on heap causing memory pressure . <nl> limiting caching to smaller instances also appears to have been the wrong choice in hindsight . <nl> while duplication of a few 100kb instances of is mostly not a big deal , duplicating <nl> a instance a couple of times (",1621328963,"elasticsearch has a number of different bytesreference implementations . <nl> these implementations can all implement the interface in different ways <nl> with subtly different behavior and performance characteristics . on the <nl> other-hand , the jvm only represents bytes as an array or a direct byte <nl> buffer . this commit deletes the specialized netty implementations and <nl> moves to using a generic bytebuffer reference type . this will allow us <nl> to focus on standardizing performance and behave around a smaller number <nl> of implementations that can be used by all components in elasticsearch .",0.9567585587501526
apache_pulsar/10935,fixed # fixed incorrect use list.remove method .,# # # modifications . <nl> i fixed an incorrect use list.remove method and add a test .,1623826802,"motivation . <nl> currently , broker has a timeout mechanism on loading topics . however , the underlying managed ledger library <nl> does n't provide a timeout mechanism . this will get into a situation that a topicload operation times out <nl> after 0 seconds . but the completablefuture of opening a managed ledger is still kept in the cache of managed ledger <nl> factory . the completable future will never return . so any sub-sequent topic lookups will fail because any <nl> attempts to load a topic will never attempt to re-open a managed ledger . <nl> modification .",0.9254434704780579
jenkinsci_jenkins/5463,migrate remaining tests from to <para-sep> schedule a scan on boot <nl> and stage some data <nl> todo there is a long-undiagnosed issue with the test harness not being compatible with message.groovy 's f.submit . work around this by matching the behavior of a real browser ( adding the desired button to the request as a parameter ) .,this pr migrates the remaining tests to . <nl> - commit sha ( from december 0 ) added a todo in . i completed this todo by renaming the property to . <nl> - was added in commit sha ( from november 0 ) and was described at that time as ' unfortunately yet disfunctional ' . rather than trying to get it to work i just deleted it . <nl> - had been flaky since it was first introduced in commit sha ( from january 0 ) . it was later ignored in commit sha ( from may 0,1620267048,( correspondingly for vs . . ),0.9752535223960876
jenkinsci_jenkins/5464,reduce usages of in favor of native java functionality <para-sep> todo or just pass all request headers ?,"the underlying motivation is to make the code easier to read by using a consistent paradigm as much as possible ( namely , jdk classes rather than a mixture of jdk classes and guava classes ) .",1620326459,"see . <nl> details : removes references to trilead classes in jenkins core to allow the trilead jar to be split out of core at some future point . <nl> this change does not modify cli - which bundles trilead independently of the version in core - nor does it modify the sftpclient class in core as this depends on trilead 's implementation and will therefore need migrated out of core alongside the jar . <nl> change is covered under existing unit tests , no new tests added . <nl> * use the prefix if the change has no user-visible",0.9557299613952637
elastic_elasticsearch/73900,"runtimefield to expose more than one mappedfieldtype . <nl> up until now , there was a 0:0 relationship between a runtimefield and a mappedfieldtype . actually , the two were only recently split to support emitting multiple fields from a single runtime script . the next step is to change the signature of asmappedfieldtype to make it return multiple sub-fields . the leaf fields that are supported to-date will return a collection with a single item , but the upcoming runtime ' object ' field will return as many subfields as are listed in its definition . <nl> together with this , we are introducing two consistency checks : <nl> - sub-fields exposed by a runtimefield either have its same name , or belong to its namespace ( e.g . object.subfield ) <nl> - there ca n't be two mapped field types with the same name as part of the same runtime section , overrides happen defining the same field in two different sections ( index mappings and search request ) <para-sep> we have n't found a mapper with this name above , which means if a field type is found it is for sure a runtime field . <nl> this is because runtime fields with the same name are not accepted as part of the same section .","up until now , there was a 0:0 relationship between a runtimefield and a mappedfieldtype . actually , the two were only recently split to support emitting multiple fields from a single runtime script . the next step is to change the signature of asmappedfieldtype to make it return multiple sub-fields . the leaf fields that are supported to-date will return a collection with a single item , but the upcoming runtime ' object ' field will return as many subfields as are listed in its definition . <nl> together with this , we are introducing two consistency checks :",1623158952,"* use mapping source directly instead of using mapper service to extract the relevant mapping details <nl> * moved assertion to timestampfield class and added helper method for tests <nl> * improved logic that inserts timestamp field mapping into an mapping . <nl> if the timestamp field path consisted out of object fields and <nl> if the final mapping did not contain the parent field then an error <nl> occurred , because the prior logic assumed that the object field existed .",0.9669430255889893
apache_incubator-pinot/6930,"add command to infer pinot schema from json data <para-sep> reads the first json object from the file that can contain multiple objects <nl> do nothing <nl> do nothing <nl> returns the data type stored in pinot that is associated with the given avro type . <nl> unnest collection entries <nl> change delimiter <nl> class for command to infer pinot schema from json data . given that it is not always possible to automatically do this , the intention is to get most of the work done by this class , and require any manual editing on top . <nl> build a map with column name as key and fieldtype ( dimension/metric/time ) as value , from the options list .","add a command to infer the pinot schema from the json data , with the complex type handling . <nl> for example , a run of . <nl> on the github event data . <nl> will output .",1621290072,"following improvements are made based on the the latest usage to enhance an internal test framework . <nl> - the global dictionary code was taking too long since the initial implementation was array based and used linear search while building the global dictionary . we had earlier avoided use of map/set to minimize the heap overhead as opposed to optimizing for performance . but it turns out that for higher cardinalities , linear search is significantly slowing down this tool . this pr implements a map based global dictionary to keep the bound to o ( logn ) . <nl>",0.983720600605011
vespa-engine_vespa/18208,"change names of sentinel connectivity limits <para-sep> not ok , but not a serious issue either",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623401075,some zones spend more than 0 hour upgrading .,0.8597651124000549
elastic_elasticsearch/72683,"fix early termination of search request with sort optimization . <nl> the query phase applies an optimization when sorting by a numeric field . <nl> this optimization does n't handle early termination correctly when <nl> and/or are used . an iae exception is thrown at the shard <nl> level when the timeout is reached . <nl> this commit fixes the bug , early terminated exceptions are correctly caught <nl> and the result is computed from the documents that the shard was able to collect <nl> before the termination . <para-sep> lucene sets shards indexes during merging of topdocs from different collectors we need to reset shard index ; es will set shard index later during reduce stage <nl> 0. test a sort with terminate after <nl> 0. test a sort with timeout","the query phase applies an optimization when sorting by a numeric field . <nl> this optimization does n't handle early termination correctly when <nl> and/or are used . an iae exception is thrown at the shard <nl> level when the timeout is reached . <nl> this commit fixes the bug , early terminated exceptions are correctly caught <nl> and the result is computed from the documents that the shard was able to collect <nl> before the termination .",1620131923,add a new ids field to the api of invalidating api keys so that it supports bulk <nl> invalidation with a list of ids . <nl> note the existing id field is kept as is and it is an error if both id and ids are specified .,0.9654601812362671
grpc_grpc-java/7837,"update proto definition for changes made for xds timeout interop testing . <cm-sep> support test rpc dynamic timeout configuration . <cm-sep> implement new format of stats report . <para-sep> configuration applies to the specific type of rpcs . * / <nl> stats recorder for test rpcs . * / <nl> todo ( chengyuanzhang ) : delete the following two after corresponding fields deleted in proto . <nl> e.g. , rpctype.unary_call - > ' unary_call ' <nl> e.g. , rpctype.unary_call - > ' unarycall ' <nl> the number of completed rpcs for each peer . the number of completed rpcs for each peer . <nl> the number of rpcs that failed to record a remote peer . <nl> deprecated : use stats_per_method.rpcs_started instead . <nl> deprecated : use stats_per_method.result instead . <nl> deprecated : use stats_per_method.result instead . <nl> the number of rpcs that were started for this method . <nl> the number of rpcs that completed with each status for this method . the key is the integral value of a google.rpc.code ; the value is the count . <nl> per-method rpc statistics . the key is the rpctype in string form ; e.g . 'empty_call ' or 'unary_call ' <nl> the deadline to use , in seconds , for all rpcs . if unset or zero , the client will use the default from the command-line .",implements test client 's support for xds timeout test . <nl> - changed to be the configuration for per test method type . added for its deadline configuration . <nl> - changed accumulated stats to include rpc status instead of just succeeded/failed .,1611370988,"this is part one of handling service config , and also enabled grpclb to work . i manually tested this with some complex dns data , but i dont have many unit tests because we dont have a dummy dns server . <nl> handling or the srv records logs failures and tries to keep going . <nl> this can be enabled by setting to true .",0.9669848084449768
Alluxio_alluxio/13088,add absent cache metrics <para-sep> absent cache stats <nl> edge cache stats <nl> number of absent cache hits . * / <nl> number of absent cache misses . * / <nl> number of absent cache invalidations . * /,add some metrics for the absent cache,1615928617,adding metrics for backup and restore from backup to track number of entries and time taken for backup .,0.9505310654640198
elastic_elasticsearch/74578,"[ ml ] delete left behind docs on data frame analytics creation . <nl> in the case a data frame analytics job gets deleted partially <nl> ( e.g . the config gets removed but not the state ) , creating <nl> a job with the same id might result into problems . <nl> this commit adds logic to delete any prior documents when <nl> a dfa job gets created . this way any issues because of partial <nl> deletes gets fixed automatically . <para-sep> this is expected <nl> step 0. delete the config <nl> step 0. delete job docs from stats index <nl> step 0. delete state","in the case a data frame analytics job gets deleted partially <nl> ( e.g . the config gets removed but not the state ) , creating <nl> a job with the same id might result into problems . <nl> this commit adds logic to delete any prior documents when <nl> a dfa job gets created . this way any issues because of partial <nl> deletes gets fixed automatically .",1624558458,this moves model storage from handling the fully parsed json string to handling two separate types of documents . <nl> 0. modelsizeinfo which contains model size information <nl> 0. trainedmodeldefinitionchunk which contains a particular chunk of the compressed model definition string . <nl> is assumed to be handled first . this will generate the model_id and store the initial trained model config object . then each chunk is assumed to be in correct order for concatenating the chunks to get a compressed definition .,0.9607940912246704
elastic_elasticsearch/72817,change data tier preference of snapshot blob cache index <para-sep> prefer to allocate to the data content tier and then the hot tier .,index is created today with a data tier preference set to . this does not works well with autoscaling and clusters that only have a hot and a frozen tier : in such cases autoscaling adds a tier just to host this system index . <nl> this pull request changes the current tier preference to .,1620311457,returning tokengroups attribute as sid string instead of byte array ( ad metadata ) .,0.8944903016090393
apache_kafka/10360,": emit records with same value and same timestamp . <nl> emit on change introduced in streams with might lead to <nl> data loss if a record is put into a source ktable and emitted <nl> downstream and then a failure happens before the offset could be <nl> committed . after streams rereads the record , it would find a record <nl> with the same key , value and timestamp in the ktable ( i.e . the same <nl> record that was put into the ktable before the failure ) and not <nl> forward it downstreams . hence , the record would never be processed <nl> downstream of the ktable which breaks at-least-once and exactly-once <nl> processing guarantees .","emit on change introduced in streams with might lead to <nl> data loss if a record is put into a source ktable and emitted <nl> downstream and then a failure happens before the offset could be <nl> committed . after streams rereads the record , it would find a record <nl> with the same key , value and timestamp in the ktable ( i.e . the same <nl> record that was put into the ktable before the failure ) and not <nl> forward it downstreams . hence , the record would never be processed <nl> downstream of the ktable which",1616161659,"the bug was introduced by having a logical path leading to be 0 , which is assigned to and later being checked by . in the subsequent check we will throw illegal argument if the is 0 . <nl> this bug is both impacting new version application and upgrades to version in certain types of topology . the example in original jira was imported as a new integration test to guard against such regression . we also verify that without the bug fix application will still fail by running this integration test .",0.9562770128250122
Alluxio_alluxio/13406,"support read ( bytebuffer buf ) method in localcachefileinstream <cm-sep> fix the localcachefileinstreamtest <para-sep> reads up to buf.remaining ( ) bytes into buf . callers should use buf.limit ( .. ) to control the size of the desired read . after a successful call , buf.position ( ) will be advanced by the number of bytes read and buf.limit ( ) should be unchanged . in the case of an exception , the values of buf.position ( ) and buf.limit ( ) are undefined , and callers should be prepared to recover from this eventually . implementations should treat 0-length requests as legitimate , and must not signal an error upon their receipt . <nl> todo ( binfan ) : take bytebuffer once cachemanager takes bytebuffer to avoid extra mem copy <nl> read some number of bytes from the input stream and stores them into the buffer array . <nl> read some number of bytes from the input stream and stores them into the bytebuffer . <nl> cache miss <nl> cache hit <nl> populate cache <nl> sequential read <nl> cache miss <nl> cache hit <nl> cache miss <nl> cache hit","0. hdfs supports the nio read ( bytebyffer buffer ) function , and we 'd better be compatible with hdfs api . <nl> 0. the client uses the read ( bytebyffer buffer ) method to access the hdfs data [ 0 ] , ' by using java directbytebuffers we can avoid copying the bytes onto the java heap . instead the data will be directly copied from kernel space to the c heap ' .",1620888090,wrap the correct portion of the byte array and consume the data on the client side properly . also a cosmetic fix in the server exception logging .,0.9676824808120728
grpc_grpc-java/7772,"cluster_manager lb policy : do not delay propagation of address update to child lb policies , but instead delay balancing state update upcalls . <cm-sep> propagate address update to child lb policies directly , delay balancing state update upcall instead . <cm-sep> weighted_target lb policy : propagate address update to child lb policies directly , delay balancing state update upcall instead . always return a picker and the latest balancing state when receiving new address updates . <cm-sep> fix test breakage in cluster_impl lb policy , which instantiates real weighted_target lb instances . <para-sep> must update channel picker before return so that new rpcs will not be routed to deleted clusters and resolver can remove them in service config . <nl> subchannel picker and state are saved , but will only be propagated to the channel when the child instance exits deactivated state .","delaying for propagating configs to the child lb policy can be problematic . for example , if channel shutdown has been enqueued when calling child policy 's is being enqueued ( e.g. , receiving updates from xdsclient ) , it should not be executed . otherwise , subchannels may be created by lbs that have already been shut down . <nl> we should follow the convention that never delay update/error propagation to downstream lb policies . to avoid reentrancy of downstream lb policies calling in-place , lb policy implementations can wrap the helper to delay such upcalls . <nl> in",1609368332,"when deadline expires , both the client and the server try to cancel the stream . there is a race between server receiving the cancellation from the client and the server cancelling the stream , which changes the final status of the stream from the server 's perspective . if the former wins , server sees cancelled . if the latter wins , server sees deadline_exceeded . <nl> because does n't pass the final status to the server-side application , this ambiguity is n't a problem in most cases . however , the status is passed to , and thus",0.9449752569198608
hazelcast_hazelcast/18946,"support mapproxyimpl.putifabsentasync <para-sep> if the operation is retried , the return value can be wrong . consider : key k is n't present . we do putifabsent ( k , v ) . the operation puts the value , updates the backup , but before the response is sent , the member crashes . the caller does n't receive the response , so retries with the new key owner . this time , the operation does nothing because the key is n't absent , and returns the old value . the unnecessary invalidation does n't hurt as much as non-invalidated near cache would . <nl> this brings the cached_as_null into the near cache <nl> here we _might_ still see the cached_as_null","added server side , async version of in form of . <nl> this is prerequisite for sql inserts .",1624278801,operations count and latencies will be counted separately for imap.set <nl> and imap.put operations . new stats will be available via localmapstats .,0.958504855632782
apache_druid/11039,"improve bitmap vector offset to report contiguous groups <para-sep> skip already selected rows if any <nl> skip already selected rows if any <nl> break if we run into an existing contiguous section <nl> for example : [ 0 , 0 , 0 , 0 ] : 0 - 0 == 0 == 0 - 0 [ 0 , 0 , 0 , 0 ] : 0 - 0 == 0 ! = 0 - 0 <nl> every bit is set , start from every offset and ensure all batches are contiguous <nl> this test is sort of vague set a lot of the rows so that there will be some contiguous and always at least 0 non-contiguous group ( i imagine this is somewhat dependent on underlying bitmap iterator implementation ) <nl> depending on the distribution of set bits and starting offset , there are some which are never contiguous","looking closer , it was due to how the benchmark uses a to simulate filtering rows , which prior to this pr would _never_ report the current set of offsets as contiguous , even if it was . <nl> these include : <nl> - random : , bitmap is set randomly for desired number of rows <nl> - contiguous-start : from starting offset 0 to desired number of rows <nl> - contiguous-end : opposite end of column as 'contiguous-start ' <nl> - contiguous-bitmap-start : , bitmap set from 0 to desired number of rows <nl> - contiguous-bitmap-end : opposite end",1616834597,"modify any aggregator to not skip null values . <nl> modify any aggregator to not skip null values and hence return null values if that is the first value the aggregator encountered . <nl> - doubleanyaggregatorfactory , floatanyaggregatorfactory , longanyaggregatorfactory instead of extending from simpledoubleaggregatorfactory ( which skip null values ) will instead extend aggregatorfactory and will handles null values by in it 's anyaggregator . <nl> - anyaggregator will have additional flag to mark if null value is found . if null value is found , all subsequent values will be skipped . <nl> - anyaggregator can return null",0.9431988000869751
apache_shardingsphere/10299,correct transaction state when postgresql ready for query <cm-sep> correct postgresql command completion tag about transaction,"if the tcl of postgresql is executed in the preparedstatement , the transaction state of will be incorrect , resulting in the proxy thinking that there is no transaction , but the actual database has opened the transaction .",1620660801,changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9502857327461243
apache_flink/16089,"disable unaligned checkpoints for broadcast partitioning . <nl> broadcast partitioning can not work with unaligned checkpointing . there <nl> is no guarantees that records are consumed at the same rate in all <nl> channels . this can result in some tasks applying state changes <nl> corresponding to a certain broadcasted event while others do n't . in turn <nl> upon restore it may lead to an unconsistent state . <cm-sep> add the possibility to force certain exchanges to be aligned . <nl> introduces the alignmenttype to checkpointoptions that includes a forced_aligned . this barrier acts as an aligned barrier for certain exchanges . the flag is then later used to restore the unaligned characteristic in subtaskcheckpointcoordinatorimpl for downstream exchanges . <cm-sep> remove subtaskstatemapper.discard_extra_state which does <nl> not work . <nl> the mapping implemented via discard_extra_state is not supported on the <nl> network level . at the same time there is no use for that mapping . it 's <nl> better to remove the mapper for now , so that it is not used by mistake .","broadcast partitioning can not work with unaligned checkpointing . there are no guarantees that records are consumed at the same rate in all channels . this can result in some tasks applying state changes corresponding to a certain broadcasted event while others do n't . <nl> in turn upon restore , it may lead to an inconsistent state . this is especially harmful to the most common pattern for using a broadcast pattern where only a single operator checkpoints its state and that state is copied over to all other operators on restore .",1623051185,"# # what is the purpose of the change . <nl> we should support ' insert overwrite ' ' insert ... partition ( ) ' without dialect limitation . <nl> we should : <nl> - remove hive dialect limitation for supported ' insert overwrite ' and ' insert ... partition ( ... ) ' . <nl> - limit ' create table ... partitioned by ' to hive dialect . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e.",0.8457164764404297
jenkinsci_jenkins/5450,"add lock free new computer update <para-sep> we always need computer for the master as a fallback in case there 's no other computer . <nl> if there is a retention strategy , it is responsible for deciding to start the computer <nl> we should never get here , but just in case , we 'll fall back to the legacy behaviour <nl> todo : maybe it should be allowed , but we would just get npe in the original logic before <nl> clean up the cancelled launch activity , then count the # of executors that we are about to bring up . <nl> we are not supposed to try and recover from errors <nl> just log it <nl> the contract for list.remove ( o ) is that the first element i where ( o==null ? get ( i ) ==null : o.equals ( get ( i ) ) ) is true will be removed from the list since plannednode.equals ( o ) is not final and we can not assume that subclasses do not override with an equals which does not assure object identity comparison , we need to manually do the removal based on instance identity not equality","while investigating i saw that technically addnode can be made lock-free so this is a stab at it . this would greatly help cloud implementations when provisioning a large number of nodes but of course this will not help removal as that will still require locking . <nl> it can be made non locking because a node with no computers will not have any executors , this will ensure that it does not confuse queue # maintain ( ) . but because updatecomputerlist deals with other computers as well this method needs to lock . adding a separate method for",1619621611,"this is for discussion . <nl> * internal java code cleanup . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9467552304267883
apache_druid/11032,make laning test less sensitive to timing <para-sep> pretend to be a query that is waiting on results,"this test sometimes fails because it is sensitive to timing ( locally more than travis i think ) . maven retries usually let it get by , hopefully this will make it fail a bit less . i tried to get it working with latches , but it is sort of hard to get them in all the right places to use that approach here so i gave up and did this way for now .",1616659530,"currently , the method of will incorrectly mark all lazy workers as lazy when the parameter is 0. this is the case where current workers are lazy , yet required to satisfy the autoscaler setting , which results in all lazy workers being killed every idle timeout , and replaced immediately , indefinitely or until at least are no longer considered lazy .",0.8488147854804993
jenkinsci_jenkins/5170,fixed some deprecated warnings of mockito methods and minor cleanup,"fixed some deprecated warnings of mockito methods and minor cleanup . <nl> and some minor stuff , added missing and removed superflous . <nl> * internal : n/a",1610489059,"* jenkins will now prevent core or plugin code from mistakenly attempting to serialize jobs , builds , or users except in their intended top-level xml file positions , preventing a class of serious errors .",0.9301674962043762
ballerina-platform_ballerina-lang/30517,fix indexoutofboundsexception in ls . <nl> indexoutofboundsexception is thrown in ls when a .bal file of <nl> a sub module is opened . <para-sep> test documentid of a document which it 's module name contains package name . package name : winery module name : winery1 <nl> 0 ) initialize the project instance <nl> 0 ) load current package <nl> 0 ) compile the package <nl> inputs from langserver <nl> load the project from document filepath,"the issue was at where is split using the regex . here , the result of split is an empty array . since is a special character and it should be escaped . hence , escaping the in this pr .",1620816458,"this pr will allow user to set a negative value to setmaxinactiveinterval ( ) method to avoid session being timeout . <nl> eg . http : setmaxinactiveinterval ( ses , 0 ) ;",0.9164683222770691
apache_druid/10767,"vectorized theta sketch aggregator . <nl> also a refactoring of bufferaggregator and vectoraggregator such that <nl> they share a common interface , basebufferaggregator . this allows <nl> implementing both in the same file with an abstract + dual subclass <nl> structure . <para-sep> getting the object from value selectors is outside this class . <nl> in the code below , i am returning setop.getresult ( true , null ) ' true ' returns an ordered sketch but slower to compute than unordered sketch . however , advantage of ordered sketch is that they are faster to ' union ' later given that results from the aggregator will be combined further , it is better to return the ordered sketch here <nl> builds vector processors that return object arrays . not a terribly efficient way to write aggregators , since this is fighting against the strongly-typed design of the vector processing system . however , it simplifies the aggregator code quite a bit , and most of the sketches that use this do n't have special handling for primitive types anyway , so we hopefully should n't lose much performance . <nl> noinspection unchecked <nl> treats all rows as null .","update 0 : the patch has been expanded to pay down some debt related to how vector processors handle complex columns , in order to ensure that the theta agg behaves properly in all situations . ( see comment below . ) <nl> ~~also a refactoring of bufferaggregator and vectoraggregator such that <nl> they share a common interface , basebufferaggregator . this allows <nl> implementing both in the same file with an abstract + dual subclass <nl> structure.~~",1610693862,"* add and to allow better inspection of features s supports , it enables safer/more correct code working with s in , , . <nl> * add , to make to be able to decorate s with unknown cardinality . <nl> * optimize in 's ( which is refactored as ) , 's and . <nl> * use two singletons , and , instead of . <nl> * add singleton and use it in",0.9915375709533691
elastic_elasticsearch/73620,"add setting to disable aggs optimization . <nl> sometimes our fancy ' run this agg as a query ' optimizations end up <nl> slower than running the aggregation in the old way . we know that and use <nl> heuristics to dissable the optimization in that case . but it turns out <nl> that the process of running the heuristics itself can be slow , depending <nl> on the query . worse , changing the heuristics requires an upgrade , which <nl> means waiting . if the heurisics make a terrible choice folks need a <nl> quick way out . this adds such a way : a cluster level setting that <nl> contains a list of queries that are considered ' too expensive ' to try <nl> and optimize . if the top level query contains any of those queries we 'll <nl> disable the ' run as query ' optimization . <nl> the default for this settings is wildcard and term-in-set queries , which <nl> is fairly conservative . there are certainly wildcard and term-in-set <nl> queries that the optimization works well with , but there are other queries <nl> of that type that it works very badly with . so we 're being careful . <nl> better , you can modify this setting in a running cluster to disable the <nl> optimization if we find a new type of query that does n't work well . <cm-sep> explain <para-sep> for now this just hooks into a cluster level setting so users can disable the behavior when the existing heuristics do n't detect cases where its slower .","sometimes our fancy ' run this agg as a query ' optimizations end up <nl> slower than running the aggregation in the old way . we know that and use <nl> heuristics to dissable the optimization in that case . but it turns out <nl> that the process of running the heuristics itself can be slow , depending <nl> on the query . worse , changing the heuristics requires an upgrade , which <nl> means waiting . if the heurisics make a terrible choice folks need a <nl> quick way out . this adds such a way : a cluster",1622561549,~~if a data stream is used in the list of index expressions then each <nl> data stream is resolved to the latest backing index ( write index ) of data stream.~~ . <nl> update index settings and put mapping apis calls that target a data stream are <nl> executed on all backing indices . <nl> in a followup an additional parameter will be added to the put mapping api that controls <nl> whether a put mapping api call that targets a data stream is executed on all backing indices ( default ) or <nl> only the write index of a,0.9537503123283386
ballerina-platform_ballerina-lang/29099,temporary handle async send as expression,when the parser parses async send as an expression it causes cce in nodetransformer . this pr handles it by giving a error message .,1615359478,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.90337735414505
vespa-engine_vespa/17606,"use a single-threaded executor that delegates to another for zk session work . <nl> use a single-threaded executopr to make sure that events are handled in order , <nl> but delegate to a multi-threaded executor for the real work <para-sep> single-threaded executor ( to make sure that getting data for a zookeeper watcher event is done serially ) that delegates to another executor ( that uses a cached thread pool )","use a single-threaded executor that delegates to another for zk session work . <nl> use a single-threaded executor to make sure that events are handled in order , <nl> but delegate to a multi-threaded executor for the real work .",1619455631,i plan to use a feature flag so we can switch between these versions with shorter turnaround and without breaking builds for such a long time,0.9555327296257019
jenkinsci_jenkins/5563,"fixes to processtree implementation on darwin <cm-sep> freebsd support in <para-sep> implementation for freebsd based on sysctl ( 0 ) . <nl> taken from sys/errno.h <nl> taken from sys/sysctl.h <nl> local constants <nl> find out how much memory we need for kern.proc.all . <nl> add some padding to account for new processes . <nl> now get kern.proc.all . <nl> allocate first so that parse errors will result in empty data and avoid retry . <nl> this happens with insufficient permissions , so just ignore the problem . <nl> allocate first so that parse errors will result in empty data and avoid retry . <nl> this happens with insufficient permissions , so just ignore the problem .","the freebsd version is similar , but not identical to , the darwin version . the main difference is that and are two separate s rather than darwin 's single . on the bright side , the result is easier to parse ( just a flattened list of strings ) . reviewers might find helpful . <nl> i tested this interactively on a 0-bit freebsd system inspecting both 0-bit and 0-bit processes . <nl> the jenkins process management functionality now supports freebsd",1623013483,"[ fixed ] fixed the 0 when clicking the testresult on the project page when there is only an aggregated test result for a freestyle job . the name of the link is still wrong . <nl> moreover , no test trend is shown for the aggregated test result and the method ' getaggregatedtestresult ' never returns the aggregated test result of the publisher .",0.9504292607307434
ballerina-platform_ballerina-lang/28054,restrict loop alter from different functions,"hence , even though a lambda function is nested within a loop , using a break/continue to alter the loop flow will be restricted from this .",1611217596,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.8829572796821594
elastic_elasticsearch/73965,"fix split package with voting-only nodes . <nl> moves the implementation of voting-only nodes to the <nl> package . <para-sep> start a fresh full master node , which will be brought into the cluster as master by the voting-only nodes <nl> dedicated voting-only master node <nl> voting-only master node that also has data <nl> only the da <nl> if local node is voting only , have additional checks on election quorum definition <nl> if all votes are from voting only nodes , do not elect as master ( no need to transfer state ) <nl> if there 's a vote from a full master node with same state ( i.e . last accepted term and version match ) , then that node should become master instead , so we should stand down . there are two exceptional cases , however : 0 ) if we are in term 0. in that case , we allow electing the voting-only node to avoid poisonous situations where only voting-only nodes are bootstrapped . 0 ) if there is another full master node with an older state . in that case , we ensure that satisfiesadditionalquorumconstraints can not go from true to false when adding new joinvotes in the same election . as voting-only nodes only broadcast the state to the full master nodes , eventually all of them will have caught up and there should not be any remaining full master nodes with older state , effectively disabling election of voting-only nodes .",moves the implementation of voting-only nodes to the <nl> package .,1623261645,"this commit removes task from all es-plugins . <nl> most relevant projects have been converted to use yamlresttest , javaresttest , <nl> or internalclustertest in prior prs . <nl> a few projects needed to be adjusted to allow complete removal of this task <nl> * x-pack/plugin - converted to use yamlresttest and javaresttest <nl> * plugins/repository-hdfs - kept the integtest task , but use plugin to define the task <nl> * qa/die-with-dignity - convert to javaresttest <nl> * x-pack/qa/security-example-spi-extension - convert to javaresttest <nl> * multiple projects - remove the integtest.enabled = false ( yay ! )",0.8695172071456909
OpenAPITools_openapi-generator/9285,"resolve merge conflicts <cm-sep> use + in type mapping , add tests <para-sep> allows custom type_format mapping . use { type } + { format } <nl> we want to make sure that the type mapping works as expect",========================= . <nl> makes it possible to map format . <nl> for example these args can be used to properly map the following : . <nl> by default it would map to .,1618632234,this change uses the existing addproperties ( ) method to combine properties of composed schemas .,0.9275156259536743
Alluxio_alluxio/13151,hardcode buffer size when writing blocks,therefore we do n't need to take the risk of misconfiguration by users . <nl> this pr removed this property and hardcoded the value as 1mb .,1617217165,"large directory list and delete test pagination in the ufs . to speed up testing the parameter ' alluxio.underfs.listing.length ' can be set to a small number , allowing testing pagination for smaller directories . <nl> s3 returns a maximum of 0 list items . did n't find similar documentation for other ufss .",0.918738067150116
ballerina-platform_ballerina-lang/27954,change the ballerina command name <para-sep> ex : bal format [ ballerinafile | modulename ] [ -d | -- dry-run ],* update the ballerina command name in all the help text files .,1611043689,added more documentation with a refreshed formatting inspired by go and git help pages .,0.901704728603363
grpc_grpc-java/7818,"tls should be selected for addresses without cluster name attributes , even if grpc-xds is in classpath . <para-sep> add the negotiator handler last , but to the front . putting this in ctor above would make it throw early . <nl> check that the message complained about the alts code , rather than ssl . alts throws on being added , so it 's hard to catch it at the right time to make this assertion . <nl> same as io.grpc.xds.internalxdsattributes.attr_cluster_name","more specifically , is the buggy line that oversees the case for td 's address .",1610926806,"this changes our detection of the google play security provider from using the class name to the provider name , . this would seem to be equally as stable , and recent versions of okhttp do the check similarly , although i realized in testing this that okhttp uses , which did not work in my tests ( checking elsewhere , it should indeed be , and the lookup is case-sensitive ) .",0.9519542455673218
elastic_elasticsearch/74047,"flatting the logic for parsing to go field by field like we do for <nl> which is both easier to read and also faster ( mostly when moving to batch multiple of these blobs into one <nl> and doing on-the-fly filtering in an upcoming pr where the approach allows for more tricks ) . <nl> also , simplified/deduplicated parsing out ( mostly/often ) empty lists in the deserialization code <nl> and used the new utility in a few more spots as well to save empty lists . <para-sep> the returned list may or may not be mutable . <nl> some older versions a redundant null value for this field <nl> it was probably created by newer version - ignoring","flatting the logic for parsing to go field by field like we do for <nl> which is both easier to read and also faster ( mostly when moving to batch multiple of these blobs into one <nl> and doing on-the-fly filtering in an upcoming pr where the approach allows for more tricks ) . <nl> also , simplified/deduplicated parsing out ( mostly/often ) empty lists in the deserialization code <nl> and used the new utility in a few more spots as well to save empty lists .",1623611652,"fetchsubphase has two 'execute ' methods , one which takes all hits to be examined , <nl> and one which takes a single hitcontext . it 's not obvious which one should be implemented <nl> by a given sub-phase , or if implementing both is a possibility ; nor is it obvious that we first <nl> run the hitexecute methods of all subphases , and then subsequently call all the <nl> hitsexecute methods . <nl> this commit reworks fetchsubphase to replace these two variants with a processor class , <nl> , that is returned from a single method . this",0.9699268341064453
netty_netty/11167,ensure dnsnameresolver resolves the host ( computer ) name on windows . <nl> motivation : . <nl> on windows dnsnameresolver is not able to resolve the host ( computer ) name as it is not in the hosts file and the dns server is also not able to resolve it . <nl> the exception below is the result of the resolution : <nl> caused by : java.net.unknownhostexception : failed to resolve 'host ( computer ) -name ' after 0 queries <nl> at io.netty.resolver.dns.dnsresolvecontext.finishresolve ( dnsresolvecontext.java:0 ) <nl> at io.netty.resolver.dns.dnsresolvecontext.trytofinishresolve ( dnsresolvecontext.java:0 ) <nl> at io.netty.resolver.dns.dnsresolvecontext.query ( dnsresolvecontext.java:0 ) <nl> at io.netty.resolver.dns.dnsresolvecontext.trytofinishresolve ( dnsresolvecontext.java:0 ) <nl> at io.netty.resolver.dns.dnsresolvecontext.access $ 0 ( dnsresolvecontext.java:0 ) <nl> at io.netty.resolver.dns.dnsresolvecontext $ 0.operationcomplete ( dnsresolvecontext.java:0 ) . <nl> modifications : . <nl> on windows dnsnameresolver maps host ( computer ) name to localhost . <nl> result : . <nl> dnsnameresolver is able to resolve the host ( computer ) name on windows .,motivation : . <nl> on windows is not able to resolve the host ( computer ) name as it is not in the hosts file and the dns server is also not able to resolve it . <nl> the exception below is the result of the resolution : . <nl> modifications : . <nl> on windows maps host ( computer ) name to . <nl> result : . <nl> is able to resolve the host ( computer ) name on windows .,1618858192,"this tests the following classes more : . <nl> 0 : internalloggerfactorytest <nl> tests internalloggerfactory.getinstance ( class ) . <nl> 0 : defaultattributemap / defaultattribute ( 0 % ) <nl> 0 : networkconstants ( version % , functionally 0 % ) <nl> 0 : stringutil ( 0 % , functionally 0 % )",0.9030123353004456
Alluxio_alluxio/12897,"cherry-pick with conflict <cm-sep> resolve conflicts <para-sep> context for merging journal entries together for a wrapped journal context . this is used so that we can combine several journal entries into one using a merge function . this prevents partial writes of these journal entries causing system to be left in an inconsistent state . for example , createfile without completing the file . note that these journal entries are not persisted and they will only be persisted when close is called on them . closing the mergejournalcontext will also not close the enclosed journal context . <nl> it will log a warning if the number of buffered journal entries exceed 0 <nl> note that we do not close the enclosing journal context here <nl> merge inode entry with subsequent update inode and update inode file entries . <nl> file id : index in the newentries , inodefileentry <nl> use the old entry as a placeholder , to be replaced later <nl> replace the old entry place holder with the new entry , to create the file in the same place in the journal <nl> we do not want to close this wraprpccontext because it uses elements from another context","before this change , syncmetadata writes an inode journal entry and then <nl> two additional updateinode entries to complete the file . this combines <nl> three entries into one so that we do not have a failure mode where the <nl> first inode entry is inserted and incomplete files are left behind .",1613840378,sometimes user wants to preserve the original attributes of files and directories when using command . this change add a new option to the command to enable such functionality . note that user will need to have the required permissions to perform the operation .,0.9585757851600647
netty_netty/11362,"the mqttdecoder incorrectly skip bytes before throwing toolongframeexception . <nl> motivation : . <nl> commit sha incorrectly skip the bytes of the replay decoder buffer . the number of bytes to skip is determined by bytebuf # readablebytes ( ) instead of using bytetomessagedecoder # actualreadablebytes ( ) . as result it throws an exception because the bytebuf provided will return a too large value ( integer.max_value - reader index ) causing a bound check error in the skipbytes method . this is not detected by the tests because most tests are calling the decode ( ... ) method with a regular bytebuf . in practice when this method is called with a specialized bytebuf when channelread ( ... ) is called . such tests should actually use channelread with proper mocking of the channelhandlercontext . <nl> modification : . <nl> - rewrite the mqttcodectest to use channelread ( ... ) instead of decode ( ... ) and use proper mocking of channelhandlercontext to get the message emitted by the decoder . <nl> - use actualreadablebytes ( ) instead of buff.readablebytes ( ) to compute the number of bytes to skip . <nl> result : . <nl> skip correctly the number of bytes when a too large message is found and improve testing . <para-sep> set the reserved flag in the connect packet to 0 <nl> setting an invalid message type ( 0 , reserved and forbidden by mqtt version spec )",motivation : <nl> commit sha incorrectly skip the bytes of the replay decoder buffer . the number of bytes to skip is determined by bytebuf # readablebytes ( ) instead of using bytetomessagedecoder # actualreadablebytes ( ) . as result it throws an exception because the bytebuf provided will return a too large value ( integer.max_value - reader index ) causing a bound check error in the skipbytes method . this is not detected by the tests because most tests are calling the decode ( ... ) method with a regular bytebuf . in practice when this method is called,1622728119,motivation : . <nl> as we have java8 as a minimum target we can use methodhandles . we should do so when we expect to have a method called multiple times . <nl> modifications : . <nl> - replace usage of reflection with methodhandles where it makes sense <nl> - remove some code which was there to support java < 0 . <nl> result : . <nl> faster code,0.8830039501190186
grpc_grpc-java/8266,"two context <para-sep> allows for defining a way to provide a custom executor to handle the server call . it 's an optional parameter . <nl> defines what executor handles the server call , based on each rpc call information at runtime . * / <nl> returns an executor to handle the server call . it should never throw . it should return null to fallback to the default executor . * / <nl> only call this from this serializingexecutor runnable , so that the executor is immediately visible to this serializingexecutor executor . * / <nl> run in serializing executor so jumplistener.setlistener ( ) is called before any callbacks are delivered , including any errors . methodlookup ( ) and handleservercall ( ) are proactively queued before any callbacks are queued at serializing executor . methodlookup ( ) runs on the default executor . when executorsupplier is enabled , methodlookup ( ) may set/change the executor in the serializingexecutor before it finishes running . then handleservercall ( ) and callbacks would switch to the executorsupplier executor . otherwise , they all run on the default executor .","methodlookup ( ) runs on default executor , handleservercall ( ) may run on the executorsupplier executor . <nl> * callbacks are queued after methodlookup ( ) and handleservercall ( ) <nl> * make executor settable in serializing executor to switch executor for the server call handling runnable as a result of the outcome of the method lookup runnable .",1623882097,the grpclb client will use the backend addresses from resolver if it has not received any server list from any balancer after a certain timeout ( 10s ) .,0.973289430141449
vespa-engine_vespa/18058,"do n't fail nodes/v2 requests if questdb fails . <nl> deployment jobs pools the application path , but does <nl> not need information from questdb , so just return <nl> without it if questdb fails . <para-sep> create a cluster model if possible and logs a warning and returns empty otherwise . this is useful in cases where it 's possible to continue without the cluser model , as questdb is known to temporarily fail during reading of data .","deployment jobs pools the application path , but does <nl> not need information from questdb , so just return <nl> without it if questdb fails .",1622538986,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8965568542480469
grpc_grpc-java/7853,user is responsible to override authority for resolvingoobchannelbuilder <para-sep> the returned oob-channel builder defaults to use the same authority and channelcredentials ( without bearer tokens ) as the parent channel 's for authentication . <nl> override authority to keep the old behavior . createresolvingoobchannelbuilder ( string target ) will be deleted soon .,"should not override authority for , because does not know what and are .",1611861452,use a separate stopwatch for load balancer to manage backoff time .,0.883408784866333
apache_incubator-pinot/6678,"extends groupbycombineoperator and groupbyorderbycombineoperator from basecombineoperator <para-sep> use a phaser to ensure all the futures are done ( not scheduled , finished or interrupted ) before the main thread returns . we need to ensure this because the main thread holds the reference to the segments . if a segment is deleted/refreshed , the segment will be released after the main thread returns , which would lead to undefined behavior ( even jvm crash ) when processing queries against it . <nl> use a _blockingqueue to store the per-segment result <nl> processsegments will execute query on one or more segments in a single thread . <nl> register the thread to the phaser note : if the phaser is terminated ( returning negative value ) when trying to register the thread , that means the query execution has finished , and the main thread has deregistered itself and returned the result . directly return as no execution result will be taken . <nl> query is satisfied , skip processing the remaining segments <nl> early-terminated by interruption ( canceled by the main thread ) <nl> caught exception , skip processing the remaining operators <nl> mergeresultsfromsegments will merge multiple intermediate result blocks into a result block . <nl> todo : use combineoperatorutils.getnumthreadsforquery ( ) to get the parallelism of the query instead of using all threads <nl> we use a countdownlatch to track if all futures are finished by the query timeout , and cancel the unfinished _futures ( try to interrupt the execution if it already started ) . besides the countdownlatch , we also use a phaser to ensure all the futures are done ( not scheduled , finished or interrupted ) before the main thread returns . we need to ensure no execution left before the main thread returning because the main thread holds the reference to the segments , and if the segments are deleted/refreshed , the segments can be released after the main thread returns , which would lead to undefined behavior ( even jvm crash ) when executing queries against them . <nl> register the thread to the _phaser . if the _phaser is terminated ( returning negative value ) when trying to register the thread , that means the query execution has timed out , and the main thread has deregistered itself and returned the result . directly return as no execution result will be taken","sorry for the inconvenience . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1615574853,* remove dao di from taskcontext . <nl> * refactor daoregistry for unit testing . <nl> * refactor detectiontaskrunner for unit testing . <nl> * add daoregistry tests . <nl> * add detectiontaskrunner test,0.9635633230209351
apache_pulsar/11136,fix replay topic policy messge not work <cm-sep> format code <cm-sep> format code <para-sep> replay policy message <nl> set namespace level inactive topic policies set namespace retention policies <nl> set topic level inactive topic policies <nl> set topic level retention policies <nl> check inactive topic policies and retention policies .,"the reason is when replay the __change_events topic message on stage , it create a reader and read message from earliest and notify the message to update policy for each topic . on update topic policy , it will call gettopicpolicies method . <nl> this method will check whether init or not for specific namespace . <nl> however , before replay all message completely , the keep in not init stage . <nl> thus the will throw and the topic policy message will replay failed . <nl> 0. add retention policy check test for broker restart check .",1624895415,allow enums in pojos to be visible in sql for querying . <nl> enums in pojos will be presented as varchar in presto,0.9170815944671631
apache_kafka/10253,: apply atomic append to the log,"append to the log in one batch when handling : . <nl> 0. client quota changes <nl> 0. configuration changes <nl> 0. feature changes <nl> 0. topic creation . <nl> * more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests",1614793090,"* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",0.9603121876716614
vespa-engine_vespa/17971,split cli and programmatic api artifacts to separate maven modules <cm-sep> allow configuration of crypto material through pem files <para-sep> parses command line arguments <nl> main method for cli interface,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621956946,"- added enough bits to dispatchconfig so that it can be disabled when multi-level dispatching is configured <nl> - fixed coverage reporting again , since it predictably broke with the changes to behaviour during node failures",0.9489098191261292
OpenAPITools_openapi-generator/9252,"do n't include read-only properties in python examples . <nl> when using a schema with read-only fields as api inputs , python <nl> generates examples for those : this excludes them . <para-sep> my_readonly | readonly * | | <nl> name | str * | |","when using a schema with read-only fields as api inputs , python <nl> generates examples for those : this excludes them .",1618315475,add support for models as query params for oas3 .,0.9496166706085205
confluentinc_ksql/6811,add mention of in clause to pull query error msg ( minor ),previously : . <nl> now : . <nl> the only change in this pr is an update to an error message .,1608584988,commiting the 'ratings ' example dataset used for workshop content so we do n't lose it,0.8229742646217346
elastic_elasticsearch/73074,"remove deprecated ._tier allocation filtering settings . <nl> this commit also ensures that the settings are removed from index metadata when the metadata is <nl> loaded . the reason for this is that if we allow the settings to remain ( because they are not <nl> technically ' invalid ' ) , then the index will not be able to be allocated , because the <nl> will be looking for nodes with the attribute . <para-sep> details * + <nl> impact * + <nl> remove _tier routing settings if available , because though these are technically not invalid settings , since they are now removed the filterallocationdecider treats them as regular attribute filters , and shards can not be allocated . <nl> removes index level ._tier allocation filters , if they exist <nl> clear any allocation rules other than preference for tier <nl> remove all entries that use ' _tier_preference ' , as these will be handled elsewhere","this commit also ensures that the settings are removed from index metadata when the metadata is <nl> loaded . the reason for this is that if we allow the settings to remain ( because they are not <nl> technically ' invalid ' ) , then the index will not be able to be allocated , because the <nl> will be looking for nodes with the attribute .",1620939067,"deprecate and remove as fallback settings : <nl> * in favor of <nl> * in favor of <nl> * in favor of . <nl> default to context cache . <nl> add , default to totally disable compilation rates . this setting is intended for integration tests .",0.8783456087112427
apache_pulsar/10680,in lockmanager use sync block to handle locks notifiications,"in , the notification will use the locks set to re-check the status of the lock against the metadata store . the access needs to be synchronized because new locks could be added again to the list from other threads . <nl> that leads to these exceptions : . <nl> additionally , we should use a instead of a to avoid going through the list when one single node is deleted .",1621691572,move same hash functions for client and broker to common module .,0.8995769023895264
elastic_elasticsearch/74575,add ilm policy configuration telemetry <cm-sep> add injected migrate actions to the usage reports .,"this pr adds some ilm action configurations to each set of phase stats within the ilm usage response . additionally , the change detects if the migrate action should be added for a phase and lists the action in the list of phases . the new usage stats look like the following : .",1624554335,this commit adds statistics about the index creation versions to the endpoint . the <nl> stats look like : . <nl> ( is only shown with the flag ) . <nl> this is useful for telemetry as it allows us to see if/when a cluster has indices created on a <nl> previous version that would need to be either upgraded or supported during an upgrade .,0.9837238192558289
vespa-engine_vespa/17542,reapply ' arnej/evaluate bindings in parent context ' . <nl> this reverts commit sha . <cm-sep> add unit test for argument binding resolution <cm-sep> resolve bindings via parent context <para-sep> bound to a function argument ?,"i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> it looks like we have to handle resolving of arguments to rank features , like in from the ' outside ' . i 'm not 0 % sure if the fix here is complete .",1619082425,"we want metadata to be able to find unused tenants , there is no way of <nl> tracking this today without tracking all sessions for a tenant and we allow <nl> sessions some lifetime , so this makes it impossible to find out in systems <nl> where there are a lot of short-lived deployments ( test systems ) . <nl> writing metadata is guarded by a feture flag .",0.9519993662834167
apache_kafka/10713,undo renaming <cm-sep> qualify public interface,"by mistake , we also renamed the interface itself , which is a public api . this was n't really the intended point of that pr , so rather than do a retroactive kip , let 's just reverse the renaming .",1621269620,this is a straight-forward change that make the name of the partition assignor to be aligned with streams .,0.9045179486274719
apache_camel/5623,add missing cell separator after red hat link . <cm-sep> remove adoc files with duplicates in camel-website/community <cm-sep> remove .adoc with duplicates in camel-website/community content . fix links in navigation and pages to reference the community files . <cm-sep> fix links in readme.md . change site.yml to antora-playbook.yml in how-do-i-edit-the-website.adoc <cm-sep> : remove contributing section from user manual . <nl> the contributing.md page in the repostiory is shortened and links to the <nl> contributing page in the community section ( now in camel-website ) . <nl> links in user manual and faq content and navigation are adjusted . <cm-sep> : minor fixes to new contributing.md <cm-sep> : support parsing routes with no namespace with jaxb <para-sep> add the namespace uri to all elements,"modify the jaxbhelper class to add the camel namespace to the dom if it is not present , when loading routes , route templates or rests from xml .",1622839320,the new renameusingcopy option controls whether rename operations are <nl> performed using a copy and delete strategy . this is primarily used in <nl> environments where the regular rename operation is unreliable ( e.g . <nl> across different file systems and networks ) .,0.9366623759269714
apache_pulsar/10968,"fix parsemessagemetadata error cause by not skip broker entry metadata <para-sep> first , build a message with broker entry metadata <nl> build message metadata <nl> build broker entry metadata <nl> build final data which contains broker entry metadata <nl> second , parse message metadata without skip broker entry metadata <nl> expected <nl> third , parse message metadata with skip broker entry metadata first <nl> initially reader-index may point to start of broker entry metadata : increment reader-index to start_of_headandpayload to parse metadata",skip broker entry metadata if exist before parsing message metadata .,1623994603,"it is useful to be able to control message flow from the client but still use messagelistener to be notified when new messages arrive . currently you have to use consumer.receive ( ) and receiverqueuesize which requires polling , which is inefficient for thousands of consumers . the c++ client has consumer.pausemessagelistener ( ) and resumemessagelistener ( ) . <nl> added consumer.pause ( ) and consumer.resume ( ) . when paused the consumer does not send requests for more messages to the broker . this works when using messagelistener and consumer.receive ( ) which is why i did n't use",0.9545710682868958
grpc_grpc-java/8021,"add leaksafeonewaybinder and tests . <nl> another util class , this one with tests which need to run on <nl> android . <para-sep> the transaction should n't have been processed . <nl> since binder objects can be anchored forever by a misbehaved remote process , any references they hold can lead to significant memory leaks . once detached , this binder returns false from any future transactions ( and pings ) . since two-way transactions block the calling thread on a remote process , this class only supports one-way calls .","another util class , this one with tests which need to run on android .",1616762378,"everything is currently permitted , but i 've tested with other <nl> configurations and all tests pass . i 'll set the restrictive default at <nl> the same time as adding a configuration api .",0.9806457757949829
apache_druid/11135,lay the groundwork for throttling replicant loads per runrules execution <cm-sep> add dynamic coordinator config to control new replicant threshold . <cm-sep> remove redundant line <cm-sep> add some unit tests <para-sep> this is the maximum number of non-primary segment replicants to load per coordination run . this number can be set to put a hard upper limit on the number of replicants loaded . it is a tool that can help prevent long delays in new data loads after events such as a historical server leaving the cluster . <nl> numassigned - 0 because we do n't want to count the primary assignment <nl> normal - 0 replicants maxnonprimaryreplicantstoload - 0 expect only 0 segments to be loaded despite there being 0 primary + non-primary replicants to load ! <nl> nodes : normal - 0 replicants hot - 0 replicants maxnonprimaryreplicantstoload - 0 expect only 0 segments to be loaded despite there being 0 primary + non-primary replicants to load ! <nl> nodes :,"start release notes . <nl> adds new dynamic coordinator config with default value of . this configuration can be used to set a hard upper limit on the number of non-primary replicants that will be loaded in a single druid coordinator execution cycle . the default value will mimic the behavior that exists today . <nl> example usage : if you set this configuration to 0 , the coordinator duty will load a maximum of 0 non-primary replicants in each execution . meaning if you ingested 0 segments with a replication factor of 0 , the coordinator would load 0",1618873843,"opentsdb emitter sends metric names to opentsdb verbatim as what druid <nl> names them , for example ' query.count ' , this does n't fit well with a <nl> central opentsdb server which might have namespaced metrics , for example <nl> ' druid.query.count ' . this adds support for adding an optional prefix . <nl> the prefix also gets a trailing dot ( . ) , after it , so the metric name <nl> becomes . <nl> configureable as ' druid.emitter.opentsdb.namespaceprefix ' , as <nl> documented",0.9743883609771729
OpenAPITools_openapi-generator/8929,remove trailing spaces <cm-sep> add support of discriminator mapping for typecript-angular generator,( link on the issue ) . <nl> it could probably be improved ( maybe using a dictionnay instead of looping through the mapping array ) . <nl> i did n't commit the result of the following commands because there is no files related to modified . <nl> i hope it will help : ) .,1615225659,"problem : the current client is based on a set of libraries ( package set ) from one year ago , based on the release of ghc . it is typical for library writers in the haskell community to maintain compatibility with the latest 0 major versions of the compiler . by this standard ( since , and are out ) we are generating an outdated client . moreover , the library itself went through several breaking versions in the meanwhile , so the code generated by this generator is not really compatible with a project started today . <nl>",0.9170365929603577
Alluxio_alluxio/13334,revert ' revert ' cancel sync job in middle of ufs calls if client cancelled ' ' . <nl> this reverts commit sha . <cm-sep> increase prefetch pool size,the previous version slowed down the sync because the number of prefetch threads were much smaller than the number of rpc threads that were performing a sync in many cases .,1620148128,"this commit also fixes an issue which could occur when the lock pool is empty . if two threads tried to acquire the last lock in the rwlock pool for the same block id , the second acquire would hang until a rwlock was returned to the pool . it should instead share the block lock acquired by the first thread . as a result , you could have n blocks and n locks , but not be able to lock all the blocks at once .",0.9675493240356445
apache_pulsar/10885,only expose managed ledger metrics if topic level metrics is enabled <para-sep> generate managedledger metrics,motivation . <nl> provide a flag to disable managed ledger metrics,1623303333,"explain here the context , and why you 're making that change . <nl> what is the problem you 're trying to solve . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.8772538900375366
apache_kafka/10836,added recorddeserializationexception containing partition and offset for deserialization exception,this allows the consumer to decide to take an action such as to shut down or skip past the record . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .,1623082595,"0. add new fields of subscription / assignment and bump up consumer protocol to v2 . <nl> 0. update tests to make sure old versioned protocol can be successfully deserialized , and new versioned protocol can be deserialized by old byte code .",0.9733660221099854
apache_pulsar/10704,fix npe when filtering read entries,"# # # motivation <nl> when concurrentopenlongpairrangeset does not contain any data , calling span ( ) will throw npe .",1621962138,motivation . <nl> nullpointerexception was thrown when function worker is running as part of broker and metrics collection kicks in <nl> before worker service completes initialization . <nl> changes . <nl> only generate functions when worker service is ready .,0.8964158296585083
apache_druid/10961,"k8s discovery module : fix issue for druid.host being more than 63chars not permitted as k8s resource label value <cm-sep> update doc <cm-sep> fix test <para-sep> druiddiscoveryannouncement-id-hash = hashencodestringforlabelvalue ( host : port ) <nl> a valid label must be an empty string or consist of alphanumeric characters , '- ' , ' _ ' or ' . ' , and must start and end with an alphanumeric character","fixes a bug which shows up in specific deployments , that use k8s based discovery module , where gets set to something more than 0 characters which is the max length limit on kubernetes label values . <nl> currently we put full as a k8s label inside pod spec , which can be of arbitrary length . this patch changes node discovery mechanism to work with a hash of in the label value instead . <nl> since this issue will be encountered by users quickly so hoping to have this included in version release . <nl> ps : existing [",1615248867,this patch adds an ' identity ' field to queryplus and sets it in <nl> querylifecycle when the query starts executing . this is important <nl> because it allows it to be used for future querymetrics created <nl> by that queryplus object . <nl> we also add ' identity ' to the request-level querymetrics object <nl> created in emitlogsandmetrics .,0.8833568692207336
confluentinc_ksql/7212,ensures basesubscriber.makerequest is called on context,"fixes a small bug where can be called from outside the vertx context , which should be disallowed . <nl> is called from and there are currently a few paths into : <nl> - one is which is called from the context <nl> - the other is which is inherently blocking and should n't be called from the context . <nl> for this reason , this pr exposes and invokes using that .",1615507487,error message is no longer : . <nl> it is now : . <nl> usual .,0.9599583745002747
Graylog2_graylog2-server/10512,allow configuration of which plugins are loaded for full backend tests <cm-sep> provide ability to specify different maven project dir <para-sep> do n't delete the image after running the tests so we do n't have to rebuild it every time ...,"this change adds some degree of flexibility to the full backend tests to allow creating tests for plugins outside of the repository . <nl> tests can now specify <nl> * which plugin jars they want to include when running the server <nl> * which maven project needs to be built when executing the tests <nl> * mongodb fixtures they require to be imported into mongodb before the server is started . <nl> * support some kind of meta-annotation , so that plugin tests do n't need to specify the now numerous parameters of for each and every test class .",1619510039,"the frontend needs to know which entities a user <nl> currently owns . this is expressed with a new permissions <nl> type , that is incompatible with the existing wildcardpermission . <nl> introduce a new field into the usersummary object . <nl> the serialized format of a grnpermission is . <nl> e.g . : .",0.9722610712051392
elastic_elasticsearch/74353,"fix double counting geotilegrid aggregation <cm-sep> remove leftovers <para-sep> when the left and right box land in the same tile , we need to make sure we do n't count then twice <nl> tests that bounding boxes that crosses the dateline and cover all longitude values are correctly wrapped","in the extreme case that a geotile grid aggregation with a bounded box that crosses the dateline , and that bounding box edges are landing in the same tile , then it might happen that we are counting twice the same tile . <nl> this pr makes sure this does not happen by adjusting which tiles we iterate for each side of the bounding box that crosses the dateline .",1624269458,"when performing a multi_match in cross_fields mode , we group fields based on <nl> their analyzer and create a blended query per group . our docs claimed that the <nl> group scores were combined through a boolean query , but they are actually <nl> combined through a dismax that incorporates the tiebreaker parameter . the <nl> default tiebreaker is version , meaning it just selects the maximum score . <nl> this commit updates the docs and adds a test verifying the behavior .",0.9001547694206238
Alluxio_alluxio/13619,verify embedded journal metrics and update desc,update some vague metric descriptions . <nl> descriptions should be clearer to users to enhance understanding,1623305268,we recently added colon marks in yml file which broke the syntax . put them in quotes fixed it .,0.8634365797042847
jenkinsci_jenkins/5573,"( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> ( cherry picked from commit sha ) <cm-sep> this reverts commit sha . <cm-sep> ( cherry picked from commit sha ) <para-sep> try to obtain a return point from the query parameter <nl> the following three functions are darwin-specific . the native ' long ' and ' size_t ' types always have the same size on darwin , we use nativelong and nativelongbyreference where the native functions use ' size_t ' and ' size_t * ' respectively . by updating jna to version and adding a dependency on ' jna-platform ' , the ' com.sun.jna.platform.unix.libcapi.size_t ' and ' com.sun.jna.platform.unix.libcapi.size_t.byreference ' types could be used instead . <nl> abstractauthenticationtargeturlrequesthandler expects no context part as path of the redirect url , so remove it . <nl> ensure we only redirect to local urls <nl> could be simplified to if we 're willing to edit loginlink.jelly <nl> could be simplified to if we 're willing to edit loginlink.jelly <nl> we do n't really care where this ends up as long as it does n't leave the host todo do we need to ensure we remain in the context path ? <nl> schedule a scan on boot <nl> and stage some data <nl> avoid double form submission in htmlunit <nl> trying very hard to find the right button ...","_note : there was minor conflicts on : , , so appreciate some sanity checking_",1623657838,"eliminate the logging line that says . <nl> possibly trimming /var/jenkins_home/fingerprints/ [ ... ] . <nl> this line fills up the fingerprints log file with repetitive , useless information . <nl> the operation it calls provides its own logging that can be turned on if detailed <nl> logging is actually needed instead of running this one repeatedly . <nl> also , while in the area , convert a couple of filefilter inner classes to lambdas <nl> and inline them . this reduces unnecessary boilerplate and improves clarity . <nl> in order to make this change testable , i elected to",0.9791807532310486
jenkinsci_jenkins/5128,bump tyrus-standalone-client-jdk from version to version . <nl> bumps tyrus-standalone-client-jdk from version to version .,"bumps tyrus-standalone-client-jdk from version to version . <nl> dependabot will resolve any conflicts with this pr as long as you do n't alter it yourself . you can also trigger a rebase manually by commenting . <nl> [ // ] : # ( dependabot-automerge-start ) <nl> [ // ] : # ( dependabot-automerge-end ) . <nl> dependabot commands and options . <nl> you can trigger dependabot actions by commenting on this pr : <nl> - will rebase this pr <nl> - will recreate this pr , overwriting any edits that have been made to it <nl> - will merge this",1608152720,"use this permission to a couple more places , including maven probe and groovyshcommand",0.9450318813323975
apache_kafka/10252,; ensure local state deleted on received <para-sep> visible for testing . it 's useful to execute events synchronously,this patch implements additional handling logic for records : . <nl> - update to ensure addition of deleted partitions to set <nl> - ensure topic configs are removed from <nl> - propagate deleted partitions to so that corresponding offset commits can be removed . <nl> this patch also changes the controller topic id generation logic to use rather than .,1614747346,the kafkaproducer code would set infinite retries ( max_int ) if the producer was configured with idempotence and no retries were configured by the user . this is superfluous because changed the retry functionality to both be time-based and the default retries config to be max_int .,0.8227351307868958
elastic_elasticsearch/73868,ensure minimum compiler version is picked when running bwc builds,fixes the picking of minimum compiler versions for bwc builds after we renamed <nl> buildsrc to build-tools-internal .,1623101000,we ca n't use the high level create snapshot request any longer <nl> since we changed some of its default parameters in and those <nl> are not understood by older versions like .,0.9087374210357666
apache_incubator-pinot/6468,"adding cluster config to config minion task : segmentgenerationandpushtaskgenerator number of concurrent tasks per instance <para-sep> get the cluster config for a given config name , return null if not found . <nl> default is 0 <nl> set config to 0 <nl> set config to invalid and should still get 0",- adding cluster config : to config number of concurrent tasks per instance for minion task : segmentgenerationandpushtaskgenerator <nl> - adding new api in clusterinfoaccessor to fetch cluster config,1611173308,update selection query limit if max_query_selection_limit is set . <nl> this is to avoid bad/malformed usage and protect pinot servers .,0.9650623202323914
grpc_grpc-java/8258,fixes netty resources to references shaded class names <para-sep> a transformer which updates the netty jar meta-inf/ resources to accurately reference shaded class names . <nl> a map of resource file paths to be modified <nl> verify that resources under meta-inf/native-image reference shaded class names . * /,this modifies the shading operation to transform native-image resources so they correctly reference shaded class names .,1623712204,"with these change , it passes the reproducer in that issue .",0.8547068238258362
Alluxio_alluxio/12695,flush when written journal reach to the given batch size <para-sep> journal entry size max is the hard limit set by underlying ratis use a smaller value to guarantee we do n't pass the hard limit,there are always chances that some new big journal entries are added unexpectedly which violates the underlying assumption of the raft implementation . <nl> this pr reduces the possibilities of flushing a single big journal entry by introducing journal size check and flush when reach journal batch size .,1609783886,"one todo still left in when delegation is turned on , because worker ca n't easily get the status of a alluxio directory .",0.9527754783630371
apache_pulsar/10831,fix possible race in getfirstavailableconsumerpermits . <nl> - there 's a chance for a race so that the consumer 's available permits goes <nl> below zero after it has been checked in ' isconsumeravailable ',- there 's a chance for a data race so that the consumer 's available permits goes <nl> below zero after it has been checked in . <nl> - check that before returning,1622842361,"when i use oracle jdk version，the broker metrics will export as follow : . <nl> and then prometheus will failed when parsing . <nl> the reason is when using to collect jvm info , it returns jvm vendor with , and in the pulsar source code , it adds in both sides , so it comming with , and prometheus parse failed .",0.8828905820846558
elastic_elasticsearch/72588,"explicitly set illegal-access to deny for tests . <nl> since java 0 , the default value for illegal-access is deny . this means <nl> the latest release of elasticsearch , and all current integration tests , <nl> run with deny ( since we do n't explicitly set it in jvm options ) . yet <nl> tests run with illegal-access=warn , for legacy reasons . <nl> this commit explicitly sets tests to deny . this has the added benefit <nl> that any failures will be caught even when running tests with older <nl> jvms . <para-sep> todo : only open these for mockito when it is modularized","since java 0 , the default value for illegal-access is deny . this means <nl> the latest release of elasticsearch , and all current integration tests , <nl> run with deny ( since we do n't explicitly set it in jvm options ) . yet <nl> tests run with illegal-access=warn , for legacy reasons . <nl> this commit explicitly sets tests to deny . this has the added benefit <nl> that any failures will be caught even when running tests with older <nl> jvms .",1619822772,"the api name could cause issues in the client <nl> libs because is a reserved word in many languages . rename the <nl> api to avoid this , and rename the other apis for consistency .",0.7901343703269958
apache_pulsar/10845,fix retry topic does not exist,"if we set allowautotopiccreation=false , the client will receive , which means that the retry topic does not exists . <nl> this makes users very confused . my topic clearly exists , why is it still prompted like this ? <nl> therefore , the prompt information is improved to facilitate users to troubleshoot problems .",1623043689,"motivation . <nl> when using the rest api to request to list all the non-persistent <nl> topics , it will show the persistent topics . <nl> modifications . <nl> - add a filter when before sending the response",0.9172418117523193
apache_pulsar/10334,fix mltransactionlog open manageledger name problem .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1619151074,"collect and expose metrics related to the caffeine and guava caches in brokers . <nl> this will report the sizes , hit/misses rates and load latency .",0.9319441318511963
apache_incubator-pinot/6741,"aggregate threadcputimens at broker side and emit a gauge <para-sep> set the total thread cpu time used against realtime table in request handling , into the broker response . <nl> set the total thread cpu time used against offline table in request handling , into the broker response . <nl> get the total thread cpu time used against realtime table in request handling , into the broker response . <nl> get the total thread cpu time used against offline table in request handling , into the broker response . <nl> brw - > shorthand for broker reduce worker threads . <nl> for query like , we skip alias update .","note : ' pinot.server.instance.enablethreadcputimemeasurement ' is disabled by default , so value of ' threadcputimens ' for a query will be 0 by default . <nl> here is a -end manual test for a query after setting ' enablethreadcputimemeasurement ' as true : . <nl> note : the aggregated ' threadcputimens ' value now is included into the query response json , but not included into ' query response stats ' so end user will only see it after toggling the ' show json format ' button . <nl> if you have a series of commits adding or enabling a",1617398357,"this pr allows us to know how effective is our pruning strategy . the flow is as follows <nl> 0. total number of segments ( numsegments ) <nl> 0. broker side pruning ( numsegmentsprunedbybroker ) <nl> 0. broker queries all servers after pruning ( numsegmentsqueried ) <nl> 0. each server applies further pruning ( numsegmentsprunedbyserver ) <nl> 0. each server processes all segments after pruning ( numsegmentsprocessed ) <nl> 0. of these , only some segments have at least one matching row ( numsegmentsmatched ) . <nl> this pr adds _numsegmentsqueried , numsegmentsprocessed , numsegmentsmatched_ <nl> if the pruning (",0.9611820578575134
grpc_grpc-java/7841,parse httpfault filter from lds/rds response <cm-sep> add tests <para-sep> listener contains the httpfault filter . <nl> client sends an ack lds request .,- httpfilters in httpconnectionmanager in lds response <nl> - will be a field of <nl> - typedperfilterconfigmap in virtualhost <nl> - will be a field of <nl> - typedperfilterconfigmap in route <nl> - will be a field of <nl> - typedperfilterconfigmap in clusterweight <nl> - will be a field of .,1611596235,"this pr contains all the changes in interface that i think are necessary for issues i encountered in its implementation . <nl> - method is no longer needed . constructor will take build the channel . the first rpc is sent only after a first watcher is registered . <nl> - methods need to take in the that was used for registering the watcher , so that we do not need to maintain another mapping from watcher to cluster name . <nl> with these data api defined , the xds resolver and lb policies should be able to proceed with",0.9831549525260925
runelite_runelite/13295,add more plugin search tags <cm-sep> add ' pin ' as plugin search tag,"add some more related keywords to the item identifications plugin . open to suggestions for others to add , was considering if it 's worth adding all the other kinds of items that the plugin can label for example . <nl> also add the keyword ' pin ' to the bank plugin to help find the keyboard bankpin feature .",1614623144,gave the gesearchmode option in the grandexchange plugin a more meaningful descriptions so users can differentiate between what each search mode does .,0.8360549211502075
grpc_grpc-java/8048,"do not implicitly refresh name resolution when subchannel connection is broken , let lb policies handle it . <cm-sep> add subchannel refreshing name resolution when connection broken logic in pick_first . <cm-sep> add subchannel refreshing name resolution when connection broken logic in round_robin . <cm-sep> add subchannel refreshing name resolution when connection broken logic in grpclb . <cm-sep> fix mock in rls test . <para-sep> historically the channel automatically refreshes name resolution if any subchannel connection is broken . it 's transitioning to let load balancers make the decision . if not , it will do it and log a warning . this will be removed in the future and load balancers are completely responsible for triggering the refresh . this should rarely be used , but sometimes the address for the subchannel was n't provided by the name resolver and a refresh needs to be directed somewhere else instead . then you can call this method to disable the short-tem check for detecting loadbalancers that need to be updated for the new expected behavior . <nl> no-op <nl> todo ( chengyuanzhang ) : change to let lb policies explicitly manage oob channel 's state and refresh name resolution if necessary . <nl> break subchannel connection <nl> normal loadbalancer should refresh name resolution when some subchannel enters transient_failure or idle <nl> break subchannel connection and simulate load balancer refreshing name resolution <nl> break subchannel connection <nl> simulate receiving go-away so the subchannel transit to idle . <nl> simulate state transitions for each subchannel individually . <nl> simulate receiving go-away so ready subchannels transit to idle . <nl> no-op","currently each subchannel implicitly refreshes the name resolution when its connection is broken . that is , this feature is built into subchannel 's internal implementation . although it eliminates the burden of having lb implementations refreshing the resolver when connections to backends are broken , this is gives lb policies no chance to disable or override this refresh ( e.g. , in some complex load balancing hierarchy like xds , lb policies may embed a resolver inside for resolving backends so the refreshing resolution operation should be hooked to the resolver embedded in the lb policy instead of the",1617399970,"- subclasses of include remote address in insight if available . <nl> - adds buffered time , and the insight of real stream if it 's set . <nl> - insights outputs of substreams . <nl> - ~~ adds channel state . other information , like last error status , would need api changes to ~~ . <nl> example error message : . <nl> or .",0.9675356149673462
apache_pulsar/10557,"use message.getreaderschema in pulsar io sinks when possible <para-sep> autoconsumeschema is a special schema , that comes into play when the sink is going to handle any schema usually you see sink or sink in this case extract the schema from the message , this is the most accurate schema we have see <nl> get sink info <nl> wait that sink processed all records without errors","when you run a sink and you call record.getschema ( ) , it does not return an accurate representation of the schema in case of a schema update . <nl> for instance : <nl> - the topic starts with avro schema schema1 <nl> - the autoconsumeschema starts by populating the internal schemainfo with the definition of schema1 <nl> - the topic advances to avro schema schema2 <nl> - the autoconsumeschema still reports schemainfo for schema1 <nl> - record.getschema ( ) .getnativeschema ( ) reports the wrong schema definition . <nl> with this change we leverage message.getreaderschema ( ) api that",1620822405,"this is a last sub-task for , which would auto subscribe new topics , based on regex pattern topics changing subscription . <nl> - add to track topics change . <nl> - do auto subscribe/unsubscribe based on topics changes . <nl> - add test cases to verify .",0.9499815106391907
Graylog2_graylog2-server/10578,change requestfilter ordering . <nl> the shirorequestheadersbinder needs to run before the <nl> shiroauthenticationfilter . <nl> otherwise the x-graylog-no-session-extension header is <nl> not set to the threadcontext and thus a user session <nl> will be extended by periodical ui requests . <para-sep> ensure removal of request headers to avoid leaking them for the next request,the shirorequestheadersbinder needs to run before the shiroauthenticationfilter . <nl> otherwise the x-graylog-no-session-extension header is <nl> not set to the threadcontext and thus a user session <nl> will be extended by periodical ui requests .,1620230426,0. create a user ( web interface ) <nl> 0. create multiple access tokens for the new user ( web interface ) <nl> 0. delete the user ( web interface ) <nl> 0. verify the user and the access tokens are deleted from the mongo db .,0.8765240907669067
gocd_gocd/8644,"delete plugin settings on a successful migration of the plugin settings to cluster profile . <nl> * do not delete the plugin settings when the migrate-config call fails . <nl> * do not delete the plugin settings when the elastic agent plugin implements <nl> elastic agent extension v4 , which relies on plugin settings . <nl> * delete the plugin settings when the plugin successfully migrates the <nl> plugin settings to cluster profile and the plugin implements elastic <nl> agent extension v5 or above , which does not rely on plugin settings . <para-sep> all the plugins implementing elastic agent extension v5 , does not use plugin settings and hence delete them after successful migration","description : . <nl> * do not delete the plugin settings when the migrate-config call fails . <nl> * do not delete the plugin settings when the elastic agent plugin implements <nl> elastic agent extension v4 , which relies on plugin settings . <nl> * delete the plugin settings when the plugin successfully migrates the <nl> plugin settings to cluster profile and the plugin implements elastic <nl> agent extension v5 or above , which does not rely on plugin settings .",1602484971,- this is to update last-used time for the token in db . every minute it will dump the local cache to db when security is enabled . in case of security is not configured for the gocd server timer will do nothing .,0.9474630951881409
apache_druid/11208,"fix count and average sql aggregators on constant virtual columns <para-sep> use a set to get rid of dupes <nl> use 0-bit sum regardless of the type of the avg aggregator . <nl> if the filter or anywhere else defined a virtual column for us , re-use it","while looking into this issue , i noticed that did not include the required columns of the , but only of the delegate . this seemed a mistake to me so i have adjusted this so that it will now return the correct set of columns , and am using this , along with a new method on which can filter a list of columns to only include columns which are virtual so that we can continue to populate the virtual columns list . <nl> ~~i think we can rework to not require having this list of at all and",1620275277,this pr changes the joinable interface to return an optional set of correlated <nl> values for a column . <nl> this allows the joinfilteranalyzer to differentiate between the case where the <nl> column has no matching values and when the column could not find matching <nl> values chose not to distinguish between cases where correlated values could <nl> not be computed because of a config that has this behavior disabled or because <nl> of user error - like a column that could not be found . the reasoning was that <nl> the latter is likely an error and the non,0.9561364650726318
netty_netty/11230,add not null check to the return value of tox509certificates in opensslx509keymanagerfactory .,"motivation : . <nl> the return value of io.netty.handler.ssl.sslcontext.tox509certificates ( ) may be null , so the non-null check is required for the return value . <nl> modification : . <nl> should do the non-null check on the return value of io.netty.handler.ssl.sslcontext.tox509certificates ( ) in sslcontext and opensslx509keymanagerfactory , thanks . <nl> result : . <nl> added a non-null check for the return value of io.netty.handler.ssl.sslcontext.tox509certificates ( )",1620355751,"calling in the read completion handler before delivering the data to the pipeline causes the buffer to reallocate , copy and grow by 4k prematurely , since processing the data likely makes more space available for the next read without needing to reallocate capacity .",0.8100892305374146
hazelcast_hazelcast/18504,"refactor cacheable sql plans <para-sep> context that is passed to plans to check whether the plan is still valid . <nl> unique ids of resolved objects . * / <nl> current distribution of partitions . * / <nl> if some of objects used in the plan have changed , then the plan should be re-created . examples are index creation , map destroy , external object redefinition . <nl> if some of objects used in the plan have changed , then the plan should be re-created . examples are index creation , map destroy , external object redefinition . <nl> plans are created for specific partitions . if distribution changes , the plan can not be used anymore . <nl> id of an object used in the plan . <nl> key of the plan . * / <nl> time when the plan was used for the last time . * /",removed in favour of . <nl> integrated common methods into and moved related classes closer to it .,1617974308,"- current in-flight migration detection mechanism is racy . <nl> observed at the beginning of query execution can be the already updated . <nl> so , any change of may not be noticed . <nl> there 's no ordering between / and update of , because we can apply promotion commits and source migration commits in batches to increase availability . that 's why / and update of can be executed concurrently . <nl> instead of comparing and counting in-flight migrations , map service now uses two counters ; one for started migrations and one for completed migrations . we",0.9743667244911194
Alluxio_alluxio/13617,improve metrics description for journal metrics,this improves and clarifies metrics description for journal metrics .,1623270480,we recently added colon marks in yml file which broke the syntax . put them in quotes fixed it .,0.8526914119720459
Alluxio_alluxio/12466,"make a shared variable volatile <cm-sep> avoid waiting for server when reader is closing <para-sep> this is set by the grpc threads , and checked/read by the client . * / <nl> when a reader is closed , there is technically nothing the client requires from the server . however , the server does need to cleanup resources for a client close ( ) , including closing or canceling any temp blocks . therefore , we should wait for some amount of time for the server to finish cleanup , but it should not be very long ( since the client is finished with the read ) . also , if there is any error when waiting for the complete , it should be ignored since again , the client is completely finished with the read . <nl> wait a short time for the server to finish the close , and then let the client continue . <nl> ignore any errors <nl> waits until the specified file has the desired percentage in alluxio . <nl> ignore <nl> this marshaller is already closed , so release any resources and do not update the map <nl> close the marshaller <nl> no buffers should not exist , since the marshaller is already closed <nl> close the marshaller <nl> no buffers should not exist , since the marshaller is already closed","when a grpc reader is closing , there is no message that it is expecting from the server , however , it is currently waiting for some confirmation from the server . this can sometimes lead to an exception in the close ( ) phase of the reader , which is unnecessary , since the client is completely finished with reading . <nl> in this change , we avoid waiting long for the server when the reader is closing . if something does occur during the wait , we ignore it . this avoids any unnecessary timeouts or errors during",1604620894,"removes the deprecated synchronous eviction code path . <nl> previously , alluxio supported both synchronous and asynchronous eviction . synchronous eviction was more straightforward but ultimately less efficient because each client request would evict a small amount of data ( enough to satisfy the current request space call ) . asynchronous eviction allows the evictor to use more information and do a more efficient batch eviction .",0.9428070187568665
apache_beam/14164,"add runner determined sharding option for unbounded data to writefiles <para-sep> the record count and buffering duration to trigger flushing records to a tmp file . mainly used for writing unbounded data to avoid generating too many small files . <nl> currently manual sharding is required for writing unbounded data with a fixed number of shards or a predefined sharding function . this option allows the runners to get around that requirement and perform automatic sharding . intended to only be used by runners . <nl> and similar behavior in other runners . runners can choose to ignore this check and perform runner determined sharding for unbounded data by overriding the option . <nl> auto-sharding is achieved via groupintobatches.withshardedkey which shards , groups and at the same time batches the input records . the sharding behavior depends on runners . the batching is per window and we also emit the batches if there are a certain number of records buffered or they have been buffered for a certain time , controlled by file_triggering_record_count and buffering_duration respectively . todo ( ) : the implementation does n't currently work with session windows . <nl> write grouped elements to temp files . <nl> add dummy shard since it is required by writeshardsintotempfilesfn . it will be dropped after we generate the temp files . <nl> group temp file results by destinations again to gather all the results in the same window . this is needed since we do n't have shard idx associated with each temp file so have to rely on the indexing within a bundle . <nl> initialize watermark for timer to be triggered correctly . <nl> add 0 elements in the first window . <nl> add 0 more elements in the first window . <nl> add the remaining relements in the second window . <nl> flag to validate that the pipeline options are passed to the sink <nl> this means content will be checked only globally , that shards together contains written input and not content per shard","currently users are required to provide or for streaming writes . this pr adds an internal option to transform for runners to perform dynamic sharding for unbounded data . so if a runner supports it , users can also use for streaming processing . <nl> this pr reuses the existing in for unbounded data , i.e. , no new user visible option added . unless a runner overrides the new option added by the pr , users who try to use for unbounded data will get an error , so in other words the new option has not effect for",1615164983,follow this checklist to help us incorporate your contribution quickly and easily : .,0.9430753588676453
vespa-engine_vespa/18352,remove implicit testing over http/version in methods of httpserverconformancetest <cm-sep> reuse http client and executor . replace 'clientproxy ' with listen port . <cm-sep> execute each test http request once,reduces test runtime to ~0 seconds,1624292478,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9354128241539001
confluentinc_ksql/7243,"fix ( java client ) : allow java client to accept statements with more than one semicolon <para-sep> counts the number of sql statements in a string by 0. removing all of the sql strings and identifiers 0. splitting the remaining substrings by ' ; ' . the 0 argument in the split function call ensures that each ' ; ' will always have two partitions surrounding it , so that the number of partitions is the same whether or not the final ' ; ' has whitespace after it . 0. counting the partitions <nl> given <nl> when <nl> then",this pr updates the validator logic to ignore semicolons in strings when counting semicolons .,1615932198,"with this patch , we will print ' null ' instead .",0.9283008575439453
apache_flink/16191,extend pluginloader to allow closing classloader,"with this pr it will be possibly to load a plugin temporarily , for example within a single test that uses a minicluster .",1623999575,"- parser groupingkey from user 's config : k1=v1 , k2=v2 to map <nl> - use pushgateway java sdk to push with groupingkey <nl> - use pushgateway java sdk to delete with groupingkey * . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery",0.9326099753379822
runelite_runelite/13614,"update to 0-0-0 <cm-sep> use new report button offset <cm-sep> update chatbox sprite ids . <nl> these are all the wrong size , but they are n't horribly broken like this <cm-sep> rl-api : import gettoplevelinterfaceid <cm-sep> do n't attempt to draw a date when there is no report button . <nl> previously this would just silently ignore the screenshot if you were <nl> on the orb of oculus or fullscreen world map interfaces until you were <nl> back onto one of the normal tlis where the overlay is rendered .","requires ! 0 . <nl> this updates all of the interface styles chatbox buttons too , but it does n't resize them . they work relatively well at the wrong resolution , so this is fine for now",1621434736,"this is intended to make the tags feature more discoverable , as people keep requesting ' plugin categories ' . putting plugins into a singular category that will make sense for most users is impossible , as many plugins will can logically be placed into multiple categories . <nl> the category tag list is intended to be a short , curated , list of tags that are helpful to a user trying to find plugins . <nl> the icon for this list only shows up when the input is empty , otherwise it shows the existing clear button .",0.9041557312011719
OpenAPITools_openapi-generator/8387,fixes object inline enum defintion with refed enum item <para-sep> fakeapi | enum_test | post /fake/refs/enum-test | object contains enum properties and array properties containing enums inline_array_of_str_enum | | | * array_of_str_enum | arrayofenums | | <nl> enum_test | enumtest * | input object | <nl> 0 * | got object containing enums | - | <nl> * kwargs,"fixes object serialization when there is an inline array property which contains a refed enum <nl> the problem was that when we convert the object model to a dict , we were not correctly handling the list of modelsimple instances . <nl> my code update fixes that . <nl> tests : <nl> - test added showing instantiation of the model with the array property works <nl> - api serialization/deserialization test added .",1610128632,test scala akka petstore client in ci .,1.0
quarkusio_quarkus/17389,"runtime initialize amazon-services classes using j.u.random . <nl> ( cherry picked from commit sha ) <cm-sep> update aws-sdk to version . <nl> ( cherry picked from commit sha ) <cm-sep> fix case where rest client returns jax-rs response from a jax-rs endpoint . <nl> ( cherry picked from commit sha ) <cm-sep> workaround jpa-oracle failure when using mandrel . <nl> ( cherry picked from commit sha ) <cm-sep> honor generateresourcebuilditem while building uberjar . <nl> ( cherry picked from commit sha ) <cm-sep> resteasy hangs on null header . <nl> also fix resteasy reactive which would not hang but would <nl> fail with an npe . <nl> ( cherry picked from commit sha ) <cm-sep> handle class.getmethods ( ) returning multiple getters with just the return type differring . <nl> this can happen when getters are defined in an implement interface with <nl> a different return type ( a supertype ) ; in that case we get two getters <nl> for the same property in the array returned by class.getmethods ( ) . <nl> since the order of methods in that array is unspecified , in some cases <nl> it will work ( super method then overridden method = > we keep the <nl> overridden method ) , and in others it wo n't ( overridden method then <nl> super method = > we keep the super method ) . <nl> i was n't able to reproduce the problem in a unit test , but i know it <nl> happens with my jvm ( openjdk 0 ) for jaxbembeddable.getattributes ( ) , <nl> and it caused bytecoderecorder to fail . <nl> changing the loop to keep the most specific getter only fixes the <nl> problem . <nl> ( cherry picked from commit sha ) <cm-sep> add configuration reference to deploying to openshift . <nl> ( cherry picked from commit sha ) <cm-sep> use standardcharsets.utf_8 where appropriate . <nl> ( cherry picked from commit sha ) <cm-sep> bump xstream from version to version . <cm-sep> depend on keycloak version for the moment . <nl> ( cherry picked from commit sha ) <cm-sep> arc dev mode - fix business method invocations monitoring . <nl> ( cherry picked from commit sha ) <cm-sep> fix case of lost tccl in dev-mode when resteasy reactive reads the http body . <para-sep> in some cases the overridden methods from supertypes can also appear in the array","please do n't merge , i will merge it myself .",1621519292,"please do n't merge , i will merge it myself .",0.9862554669380188
apache_beam/13773,": add dlqprovider , a way of handling failures in a generic way . <nl> pub/sub lite users may not want to use pub/sub lite as a dlq location , as it is a pay-for-capacity system , and having the extra capacity around is not required . that being said , not allowing users to do so seems too restrictive . <nl> the genericdlq mechanism allows for registration of handlers for dead-letter events . these events are expected to be rare and ( usually ) triaged by a human , since if code could handle it directly , it would have . usually they imply misconfiguration of some kind . <para-sep> a generic failure of an sql transform . * / <nl> bytes containing the payload which has failed . * / <nl> information about the cause of the failure . * / <nl> helper to generate a dlq transform to write pcollection to an external system . * / <nl> a provider for generic dlq transforms that handle deserialization failures . * / <nl> returns an id that uniquely represents this dlq provider . * / <nl> generate a dlq output from the provided config value . * /","pub/sub lite users may not want to use pub/sub lite as a dlq location , as it is a pay-for-capacity system , and having the extra capacity around is not required . that being said , not allowing users to do so seems too restrictive . <nl> the genericdlq mechanism allows for registration of handlers for dead-letter events . these events are expected to be rare and ( usually ) triaged by a human , since if code could handle it directly , it would have . usually they imply misconfiguration of some kind",1611082207,"be sure to do all of the following to help us incorporate your contribution <nl> quickly and easily : . <nl> number , if there is one . <nl> individual contributor license agreement . <nl> the java directrunner needs to be well-defined with a payload in order to detect ( and provide ) runner-specified sharding .",0.9853606224060059
jenkinsci_jenkins/5153,add configurable jnlp root <cm-sep> add test that jnlp launch contains the alt url,"our use case , and i imagine a quite common one , is the jenkins controller and agents are all on the same firewalled network , inaccessible directly . a secure proxy permits http traffic to the controller and that url is what is advertised to users . the agents however can not connect through the secure proxy and there is n't any benefit to doing so even if it did because the agents can connect directly to the controller if they use the internal address , one that would not work outside the network . <nl> as pointed out",1609829331,"rfc : would this be useful ? <nl> i imagine it might help understand the need for certain translations . at the very least , it would show how many users use jenkins with a non-english language . <nl> data submitted looks like this : . <nl> { ' en-us , en ; q=version ' :0 , ' en-us , en ; q=version , de ; q=version ' :0 } . <nl> * add telemetry trial about user languages . <nl> - [ n/a ] jira issue is well described . <nl> * use the prefix if the change has",0.9675862193107605
keycloak_keycloak/7717,- allow batching writes to storage when running migration,"these changes aim to : . <nl> * allow setting whether migration changes should be done in batches <nl> * allow setting how many migration changes should be done in batch <nl> * possible useful to other scenarios where a large number of changes to storage is made . <nl> expected result : . <nl> * time to migrate should be drastically reduced . tests using the latest version migrate 1k realms in , whereas with these changes migration happens in . <nl> during migration , we should expect degradation due to the number of changes being made . by",1610543596,": return unauthorized when accessing bearer only in interactive mode . before that fix , instead of returning a 0 the application entered an infinite redirect loop .",0.9064698219299316
jenkinsci_jenkins/5033,jdk version / version+ functionstest # printthrowable ( ) <para-sep> format changed in version / version ( / / ),tested on adoptopenjdk version_272 and amazon coretto version .,1603698728,system.nanos ( ) returns a monotonically increasing value that is not related <nl> to wallclock time . use system.currenttimemillis ( ) instead . <nl> tested on both linux and windows slaves . all now report ' sensible ' clock differences of a few minutes/seconds .,0.8947893381118774
apache_beam/14658,implement externalworkerservice # stopworker to support loopback . <nl> thread based workers terminate automatically so externalworkerservice # stopworker can be no-op . override is still needed not to throw exception which will cause pipeline failure . <para-sep> thread based workers terminate automatically,thread based workers terminate automatically so externalworkerservice # stopworker can be no-op . override is still needed in order not to throw exception which will cause pipeline failure .,1619561482,"an it for mongodbio . <nl> i suggested different kubernetes scripts naming for mongo than for postgres scripts . the postgres ' naming is quite confusing to me - the ' local ' scripts are used everywhere right now , not only while running tests locally , so why call them ' local ' ? <nl> there is another thing that bothers me : the node port service kubernetes setup can be used only if the whole test ( including and methods ) is run in the same network , as the k8 cluster is ( to have direct access",0.9388523697853088
apache_kafka/10634,"init commit <para-sep> this function will return a map of topicpartitions and the highest committed offset seen so far this function will return a map of topicpartitions and the highest offset seen so far in the topic this function will return the time task idling started , if the task is not currently idling it will return empty",improve endoffsets for taskmetadata also add an int test for taskmetadata offset collections .,1620231950,"jira ticket <nl> jira ticket . <nl> the changes here are simple : <nl> • : a few checks to ensure that constructor parameters in the and classes are non-null and non-empty are fixed . the current logic erroneously ensures that they are either null or empty . <nl> • : a bug in how the connect framework instantiates objects for use by rest extensions ( specifically , incorrect order in arguments provided to a constructor ) is fixed . the current logic , while erroneous , should never have arisen in the past by rest extension developers , as",0.9562863111495972
confluentinc_ksql/6930,"attempt 0 <cm-sep> do not log data on json deserialization errors <para-sep> clear location in order to avoid logging data , for security reasons <nl> given : <nl> when :","jsonparseexceptions are automatically populated with location information to indicate where the parse exception occurred . however , we do n't want to log this from the ksqldb json deserializer as it may result in topic data being logged . this pr clears the location data to avoid this . <nl> here 's an example of what a stacktrace may look like prior to this pr : . <nl> and here 's what it looks like after this pr : . <nl> added unit test .",1612244459,fix issue with parsing sql files where there is trailing white space after command continuation character '\ ' .,0.8828089833259583
grpc_grpc-java/8041,xdsclient modified to have bootstrapinfo as a property which can be queried .,this pr is needed for further changes to eliminate the bootstrapper from tlscontextmanagrerimpl and related classes .,1617316358,"plumb authority into alts protocol negotiator and into altsclientoption so that client can perform server authority ( aka secure naming ) check , which is done by the handshaker service .",0.9683936834335327
hazelcast_hazelcast/18809,ignore some cdc tests on jdk 0 too ( not just 0 ),"there are some cdc tests that we ignore on jdk 0. they fail due to a jdk bug . apparently the same bug persists in jdk 0 too , so we should ignore these tests in that situation too . <nl> checklist : .",1622447617,"- fix metadataraftgrouptest snapshotting test : instead of blocking network communication completely , just drop append requests to force installing snapshot on follower . otherwise , we should handle various network split scenarios in the test . <nl> - reset known cp group leader when is received : is thrown when an invocation packet can not be sent to target . in that case , we should reset the known leader , because it might not be the leader anymore .",0.8564710021018982
Alluxio_alluxio/12650,"add ratis configuration <para-sep> the following configurations need to be changed when the single journal entry is unexpectedly big . <nl> this property defines the maximum allowed size of the concurrent journal flush requests . if the total size of the journal entries contained in the flush requests are bigger than the given threshold , ratis may error out as <nl> this property defines the maximum allowed size of the concurrent journal write io tasks . if the total size of the journal entries contained in the write io tasks are bigger than the given threshold , ratis may error out as",add ratis configuration so that users can change it when they have larger journal entries ( e.g . introduced by alluxio catalog service ) .,1608076415,"since the control path is tied to the channel , we can not close the channel ( commit blocks ) until the entire file is ready .",0.9147330522537231
Alluxio_alluxio/13709,fix typo and simplify the code in alluxiomasterrestservicehandler <para-sep> webui endpoints // todo ( william ) : dry up these endpoints <nl> ignore the exception <nl> ignore the exception,fix typo and simplify the code in alluxiomasterrestservicehandler . <nl> fix typo and simplify the code in alluxiomasterrestservicehandler . <nl> no .,1624875093,"when the file being async persisted is deleted from master , the worker heartbeat after the persist will crash due to the file not exist failure . this pr addresses the issue by logging the issues on master , but not returning exception to the heartbeat request .",0.885678768157959
netty_netty/11154,"clean code , including : <nl> 0. remove useless code <nl> 0. change io.netty.handler.codec.http.httpcontentencoder.state to volatile to ensure memory visibility","motivation : . <nl> clean code , including : <nl> 0. remove useless code <nl> 0. change io.netty.handler.codec.http.httpcontentencoder.state to volatile to ensure memory visibility . <nl> please review this pr , thanks . <nl> if there is no issue then describe the changes introduced by this pr .",1618308157,remove usage of atomicintegerfieldupdater in referencecountedopensslengine . <nl> motivation : . <nl> there is not need to use a cas as everything is synchronized anyway . we can simplify the code a bit by not using it . <nl> modifications : . <nl> - just remove the cas operation <nl> - change from int to boolean . <nl> result : . <nl> code cleanup,0.8104149103164673
gocd_gocd/8457,return urifordisplay instead of raw url <cm-sep> show only url for mercurial when branch is not defined on the materials spa <cm-sep> fix the issue of breaking vsm on panel header,"description : <nl> - mask password for urls on materials spa <nl> - fix issue where if branch was not defined for mercurial branch , was shown <nl> - fix the issue of broken link text on the panel header .",1597311001,description : <nl> - fix password shown as plain text <nl> - the scm api would not encrypt as secure variable if the value is passed instead of encrypted_value . they would get encrypted when a full config save happens . fixed that for all versions <nl> - fixed broken hover message and no usage found message,0.791906476020813
apache_incubator-pinot/6731,fix an issue with datetime column in rule engine <para-sep> create a map from col name to data type,previously it used to only work for time column . <nl> did n't want to duplicate all the unit tests - one for time column and one for datetime column - so i did n't include them in the pr . one unit test with datetime column should suffice .,1617152657,"previously , the method that fetches filter values drops the entire results if it encounters any errors when fetching the filter values for any one of the dimensions of the dataset . <nl> this fix allows the method to return partial results and hence the frontend could still show time series without being blocked .",0.9276454448699951
confluentinc_ksql/7132,add support for info ( wip ) <cm-sep> move server version utils to separate file <cm-sep> fail initialize if server version incompatible <cm-sep> validiate metadata initialized <cm-sep> back out partial progress on info <cm-sep> cleanup <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"two main changes in this pr : <nl> - check server version in and fail if the server version is incompatible <nl> - check whether has been called ( specifically , whether the metadata stream and table exist ) from each of , , and , and fail if not . <nl> also adds a helper method that will be used in , and cleans up a couple minor bugs . <nl> new unit tests added . existing integration tests continue to pass .",1614701434,"this pr adds some additional test coverage for the java client . the four new commits , in order : <nl> * add tests for tls mutual auth . cleans up existing tls test to avoid use of . <nl> more test coverage coming in a future pr . <nl> tests pass .",0.9618117809295654
grpc_grpc-java/7836,interop-testing : support rpc sleep behavior for xds test server,for testing xds timeout support . <nl> tested by running interop tests manually with and without metadata set .,1611362143,"embeddedchannel now runs all pending tasks when the channel is closed . <nl> this caused the http2connectionhandler to clear deframer references ( on <nl> channelinactive ) on errors when it previously did n't . now that the <nl> errors were handled more fully , it exposed bugs in tests .",0.8666744232177734
apache_incubator-pinot/6641,adding a check for multi-value column in star tree indexing config <para-sep> expected,adding a simple validation check for this . <nl> no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? <nl> no . <nl> does this pr otherwise need attention when creating release notes ? <nl> no,1614834959,"the gettimelinesviewinmonitoringwindow ( ) takes only the bucket time granularity from dataset configs . the function also has bucket time granularity from user . this design fails when the two config are not the same . this pull request is to resolve this issue . it takes both definitions of buckets , and apply the definition from function in default . but , it also compares the definition from dataset . if the function 's is smaller than the dataset 's , it applies the dataset 's instead . <nl> another part is to allow users to update function bucket",0.9204648733139038
hazelcast_hazelcast/18893,"config/config : add instantiation helper methods from jet <para-sep> creates a config which is loaded from a classpath resource . the system.properties are used for variable resolution in the configuration file <nl> creates a config which is loaded from a classpath resource . <nl> creates a config based on a the provided configuration file ( xml or yaml ) and uses the system.properties to resolve variables in the file . <nl> creates a config based on a the provided configuration file ( xml or yaml ) and uses the system.properties to resolve variables in the file . <nl> creates a config from the provided string ( xml or yaml content ) and uses the system.properties for variable resolution . <nl> creates a config from the provided string ( xml or yaml content ) . <nl> creates a config from the provided stream ( xml or yaml content ) and uses the system.properties for variable resolution . <nl> creates a config from the provided stream ( xml or yaml content ) . <nl> test for very long config string with length > 4k <nl> test for stream with > 4kb content <nl> wrap with bufferedinputstream ( which is not resettable ) , so that configstream behaviour kicks in .",restore non-deprecated static config constructors from jet .,1623421689,"* bytes send/received metrics for each are added as metrics and logged to diagnostics ( only total , not per-thread or per-pipeline ) . <nl> * bytes send/received are reported to management center . <nl> * stats are exposed in as it seems to be the most logic place for them at the moment . if more stats arise in future , a separate class might be introduced to handle all of them . <nl> note that this works only when advanced networking is enabled and an endpoint configuration is made for the specific protocol type ( member , client",0.9730084538459778
neo4j_neo4j/11528,update count store migration message to be ' migrating counts store ' . <nl> update message : <nl> ' migrating count rebuilding ' - > ' migrating counts store ',update message : <nl> ' migrating count rebuilding ' - > ' migrating counts store ',1523481820,some of our browser test cases started behaving flaky after we migrated browser tests to run on firefox .,0.8890565633773804
Alluxio_alluxio/12794,address race condition for async persist when the file to be persisted is updated ( delete + recreated ) . <para-sep> check if the size is the same to guard against a race condition where the alluxio file is mutated in between the persist command and execution,"fixes a race condition where if a file is scheduled for async persist changes in between submitting the async persist request and starting the async persist request , the wrong data will be written for the original file . <nl> i was able to reproduce this consistently with a unit test and adding a timing delay to the job service . <nl> not including the test because it would require a hook in the job service for timing delays , perhaps this is something we can add in the future when we have a framework for controlling timings between different",1612236338,"the serving thread is supposed to be responsive to interrupts such that this will never happen , but in case the thread does n't die after 0 minutes , we should stop the process and log the stack of the serving thread . <nl> the propertykey is added with since users should never need to see this configuration , but it could be useful for developer debugging purposes , or to avoid the in case it causes issues .",0.9300448894500732
OpenAPITools_openapi-generator/8472,add cors support to python-flask server generator <cm-sep> documentation update and cors support for other generators using the same base class,adds basic cors support to the server generated with the generator ( and the derived and ) . enabled with option ( same as similar option in other generators ) . disabled by default .,1611061811,"making api response headers case insensitive . <nl> okhttp 's headers ' class has only one method called ' tomultimap ' which returns headers as map . so , it is better handle it separately in apiresponse and apiexception classes separately . <nl> i will be raising separate pull requests for other libraries of java .",0.972857654094696
elastic_elasticsearch/74594,simplify get status <cm-sep> check memory usage before decoding async response <para-sep> reserve twice memory of the source length : one for the internal xcontent parser and one for the response <nl> check the authentication of the current user against the user that initiated the async task <nl> check if the result has expired <nl> get status response from index,this change makes sure the system has enough memory before decoding an async search response as a large response can lead to oom .,1624757503,"this commit lays the ground work for plugins supplying their own circuit breakers . <nl> it adds a new interface : . <nl> this interface provides methods for providing custom child circuitbreaker objects . there are also facilities for allowing dynamic settings for the custom breakers . <nl> with the refactor , circuit breakers are no longer replaced on setting changes . instead , the two mutable settings themselves are . plugins that want to use their custom circuit breaker should keep a reference of their constructed breaker .",0.966225802898407
vespa-engine_vespa/17914,"evaluate onnx models in model-evaluation with onnx rt <cm-sep> do n't add onnx models quite yet <para-sep> onnx models tied to a search definition or global . <nl> evaluate onnx models ( if not already evaluated ) and add the result back to the context . <nl> returns the set of onnx models that need to be evaluated on this context * / <nl> onnx models indexed by rank feature that calls them * / <nl> extract the feature used to evaluate the onnx model . e.g . onnxmodel ( name ) and add that as a bind target and argument . during evaluation , this will be evaluated before the rest of the expression and the result is added to the context . also extract the inputs to the model and add them as bind targets and arguments . <nl> load the model ( if not already loaded ) to extract inputs <nl> the prefix generated by model-integration/ .. /intermediateoperation * / <nl> a named onnx model that should be evaluated with onnxevaluator .","changes are mainly within to evaluate onnx models using the in . the now needs a , so the changes in injects this . for now , no onnx models are populated in the global rank profiles ( coming soon to a pr near you ) , so this is not fully wired in yet . <nl> there are tests both for rest api and the injected . conceptually , if a ranking expression contains and exists as a onnx model , the evaluates this first using onnx runtime , and adds the result to the context before evaluating the",1621504353,do not merge before implementation is ready .,0.9841660857200623
elastic_elasticsearch/72768,"validate that system indices are n't also hidden inidices <para-sep> checks that the request is n't trying to add the ' hidden ' setting to a system index <nl> requests that a cluster generates itself are permitted to have a difference in settings so that rolling upgrade scenarios still work . we check this via the request 's origin . <nl> visible for testing <nl> set up a system index upgrade service <nl> when we upgrade elasticsearch versions , existing indices may be newly defined as system indices . if such indices are set to ' hidden , ' we need to remove that setting . <nl> create an initial cluster state with a hidden index that matches the system index descriptor <nl> if a system index erroneously is set to hidden , we should remedy that situation . <nl> create an initial cluster state with a hidden index that matches the system index descriptor <nl> get a metadata upgrade task and execute it on the initial cluster state","although system indices will be mostly invisible to users in version , we use a different mechanism for this than what ' hidden indices ' use . by design , we should n't use both at once . when we create a system index descriptor or set the ' system ' property on an existing index , we need to validate that the index is n't hidden .",1620236528,"this commit adds a new metadata field mapper that validates , <nl> that a document has exactly a single timestamp value in the data stream timestamp field . <nl> the metadatacreateindexservice inserts a data stream timestamp field mapper whenever <nl> a new backing index of a data stream is created .",0.9742476940155029
Graylog2_graylog2-server/10292,"initialize es7 client and sniffer lazily . <nl> this change is avoiding eager initialization of the es7 client ( and <nl> sniffer ) in its provider class . instead , it is initializing a memoized <nl> supplier , which returns the same instance upon repeated invocation . <nl> ( cherry picked from commit sha )","this change is avoiding eager initialization of the es7 client ( and sniffer ) in its provider class . instead , it is initializing a memoized supplier , which returns the same instance upon repeated invocation . <nl> this avoids initializing the client and the sniffer unnecessarily when the es7 module is not in use . <nl> in a future improvement , we could safeguard against this by determining the es version earlier and include the es6/es7/ ... guice module only if the module is active . this is beyond the scope of this bugfix pr . <nl> the backport",1616160768,this change modifies the retrying semantics of bulk indexing to trigger retries also if the request failed on an http level ( is ) or in case of an which is not a in case of a repeated attempt .,0.9053570628166199
elastic_elasticsearch/74267,convert node shutdown system property feature flag to setting . <nl> this converts the system property feature flag ' to a regular <nl> non-dynamic node setting . this setting can only be set to 'true ' on a snapshot build of <nl> elasticsearch ( not a release build ) . <para-sep> node shutdown apis are operator only,this converts the system property feature flag ' to a regular <nl> non-dynamic node setting . this setting can only be set to 'true ' on a snapshot build of <nl> elasticsearch ( not a release build ) .,1623963105,"exceptions thrown by the various methods are <nl> logged as an by the and otherwise ignored . it 's <nl> preferable for implementations to log their own messages . <nl> this commit adjusts the implementation to log a message itself , and adds <nl> javadoc to clarify that other implementations should do the same .",0.9512947201728821
apache_pulsar/10530,support mock zookeeper with different session <para-sep> this constructor is never called,motivation <nl> support mock zookeeper with different session . <nl> modification <nl> wrap to support mock zookeeper with different session,1620661980,motivation . <nl> we added integration tests for kafka & cassandra sinks . we need test coverage on kafka sources . <nl> changes . <nl> - add and for testing sources <nl> - implement for testing kafka source,0.9752251505851746
vespa-engine_vespa/17307,add bfloat16 and int8 tensor cell types in java <para-sep> test bfloat16 and int8 when we have proper cell type resolving in place .,"this is primarily for serialization and deserialization . there might be some gaps in evaluation and tensor cell value type resolving , i 'll get to that in a follow-up .",1617874193,- stor-filestor.use_async_message_handling_on_schedule <nl> - stor-filestor.bucket_merge_chunk_size <nl> - stor-server.content_node_bucket_db_stripe_bits .,0.9555860161781311
vespa-engine_vespa/17385,allow jackson deserialization of model types <cm-sep> add type for ' 0 - conflict ' + extra constructors <cm-sep> expose restapi and objectmapper to handler implementation <cm-sep> create valid builder when uri has implicit port <cm-sep> convert remaining jax-rs resources to request handlers <cm-sep> rename class to match naming convention of other handlers,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618254047,this is not much in the way of functionality yet .,0.9873690605163574
Alluxio_alluxio/13068,add lrunondeterministiccacheevictor <cm-sep> add lrunondeterministiccacheevictortest <para-sep> lru with non-deterministic cache eviction policy . evict uniformly from the last mnumofcandidate of elements at the lru tail . <nl> todo ( zhenyu ) : is 0 the best default number ? <nl> required constructor .,"add a class lrunondeterministiccacheevictor . instead of evicting the tail element like lru , it evicts uniformly from the last n elements at the lru tail . <nl> a configurable parameter ' alluxio.user.client.cache.evictor.lru.nondeterministic.numofcandidate ' is exposed and the default value is 0 .",1615780285,"currently this class is only covered by integration tests , unit tests are needed .",0.9685595035552979
apache_druid/10950,fix union queries <cm-sep> add tests <para-sep> can only do union all of inputs that have compatible schemas ( or schema mappings ) and right side is a simple table scan,fixes a bug when the second input to is a join query and we try to cast to .,1614938430,"one downside of sql 's flexibility is that users tend to forget adding time filter when writing queries , which is usually very bad for timeseries data analysis and causes stability issue . <nl> since native query requires users to specify ' intervals ' , i think it 's reasonable to force sql users to specify __time filter in many cases adds a new option to support such needs . it defaults to false though so that the default behaviour is the same as before",0.9667244553565979
vespa-engine_vespa/18010,"log instead of throwing on identical redefinition of rank-expressions . <nl> redefinition to something else is still enforced . <para-sep> todo deploy logger should not be necessary , as redefinition is illegal , but legacy prevents enforcement starting now . <nl> todo throw instead , no later than vespa 0",redefinition to something else is still enforced .,1622119898,"first commit is part of a different pr , but conflicts shnomgflicst .",0.9016920328140259
apache_beam/14648,"spark postcommit test improvements - creating one jenkins job per gradle task for the spark streaming tests <cm-sep> format code using spotlessapply <cm-sep> add proto support to pubsub table provider <nl> adding proto tests for pubsubtableprovider <cm-sep> temporary changes for pubsubtableproviderit proto support <cm-sep> add proto support to pubsub table provider : added new class ( pubsubprotoobjectprovider ) to pubsubtableproviderit to test the pubsub protobuffer support changes . also , a slight modification to payload_messages.proto file was needed . <para-sep> prepare messages to send later","add proto support to pubsub table provider : added new class ( pubsubprotoobjectprovider ) to pubsubtableproviderit to test the pubsub protobuffer support changes . also , a slight modification to payload_messages.proto file was needed . <nl> thanks !",1619485249,"example implementation of repeated record conversion from bigquery to beam row through avro . sorry this is my first contribution so i am a bit new to this . i wanted to put this up as this worked on a test table with a repeated record that i tried on and maybe just put it on the radar ? <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9274541735649109
grpc_grpc-java/8056,"move classes having protobuf dependency in io.grpc.services into io.grpc.protobuf.services . create a forwarding class for healthstatusmanager to avoid breakages . others are mostly fine , as few people are using them . <cm-sep> migrate xds interop server 's usage for healthstatusmanager . <cm-sep> creata a forwarding class for healthcheckingloadbalancerutil to allow existing users migrate . <para-sep> todo ( zpencer ) : rename class to abstractbinarylog <nl> grpc is free to cache the interceptor , so the interceptor must be reusable across calls . todo ( zpencer ) : ensure the interceptor properly handles retries and hedging <nl> grpc is free to cache the interceptor , so the interceptor must be reusable across calls . todo ( zpencer ) : ensure the interceptor properly handles retries and hedging <nl> default impl : noop todo ( zpencer ) : make binarylogprovider provide a binarylog , and this method belongs there <nl> creating a named class makes debugging easier <nl> this shim interceptor should always be installed as a placeholder . <nl> copied from internal <nl> maximum buffer to be read is 0 kb . * / <nl> returns the byte array . * / <nl> copies the data from input stream to output stream . * / <nl> copied from guava com.google.common.io.bytestreams because its api is unstable ( beta ) <nl> avoid using 0 because proto3 long fields default to 0 when unset <nl> deprecated and will be removed in a future version of grpc . <nl> creates an instance . <nl> parsing the conf string may throw if it is blank or contains errors <nl> a class that accepts binary log messages . <nl> creates a binary log that writes to a temp file . warning : this implementation is not performance optimized , and rpcs will experience back pressure if disk io does not keep up . <nl> deprecated and will be removed in a future version of grpc . <nl> normally 'grpc- ' metadata keys are set from within grpc , and applications are not allowed to set them . this key is a special well known key that set from the application layer , but represents a com.google.rpc.status and is given special first class treatment . see statusproto.java <nl> todo ( zpencer ) : move proto related static helpers into this class <nl> not all transports have the concept of authority <nl> null on client side <nl> null","to separately manage services/classes with and without protobuf dependency in services package , we are moving classes with protobuf dependency into . this includes healthchecking , reflection , channelz , and binlogging . <nl> forwarding classes are created to avoid breaking existing users , while they are marked as deprecated to notify users to migrate .",1617762331,the dns name resolver will look up srv records by default if the grpclb artifact is in the classpath .,0.9080377221107483
apache_camel/5667,: base commit for huawei cloud iam component <cm-sep> : delete generated readme file <cm-sep> : update documentation <para-sep> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> generated by camel build tools - do not edit this file ! * / <nl> generated by camel build tools - do not edit this file ! <nl> manually maintained attributes <nl> since camel { since } * <nl> { component-header } * <nl> component options : start <nl> component options : end <nl> endpoint options : start <nl> endpoint options : end <nl> to securely manage users on huawei cloud <nl> checking for required operation <nl> checking for optional userid <nl> checking for optional groupid,huawei cloud 's identity and access management ( iam ) enables you to easily manage users and control their access to huawei cloud services and resources . <nl> this pr contains the camel component for integrating with existing users in the cloud . ( created via the huawei cloud web console ) .,1623690314,this adds azure eventhubs component .,0.9869450926780701
apache_shardingsphere/10482,add test unit for renew createuserstatementevent .,- remove users node in registry center node <nl> - remove userchangegevent .,1622016388,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9519385099411011
Alluxio_alluxio/13520,set invalid block logging to debug,i 've monitored excessive memory usage incurred by logging these two messages . below is a test in a test cluster with master heap of 12g ( -xmx=12g -xms=12g ) . <nl> i simulated registerworker rpcs where all the blocks are not present on the master . this can happen when a worker registers with blocks that have been removed while the worker lost heartbeat . each batch of test invokes 0 concurrent rpcs and records the average time taken . <nl> before the change - logging this message per block . rpcs took > 150s to finish on average,1622558156,fixing a race condition that prevented containers from being allocated to hosts . <nl> adding debug output to help the user track the attempts made to allocate containers .,0.8347687721252441
elastic_elasticsearch/74498,rework autofollowit.testautofollowsearchablesnapshotsfails <para-sep> create a repository and a snapshot of a 0 docs index on leader <nl> create a regular index on leader mount the snapshot on leader,"this test sometimes fails because it expects 0 indices to be followed ( the and the indices ) but not the mounted one . this looks wrong as the index is deleted soon after it is snapshotted , and this index only exist to create a snapshot that can be later mounted as an index in the leader cluster . <nl> this pull request changes the test so that the index , the repository and the snapshot are created at the beginning of the test . then the test creates the mounted index and the regular one and can now",1624461339,"today the keystore add command can only handle adding a single setting/value pair in a single invocation . this incurs the startup costs of the jvm many times , which in some environments can be expensive . this commit teaches the add keystore command to accept adding multiple settings in a single invocation .",0.8782781958580017
elastic_elasticsearch/74312,fix querying of indices without columns <para-sep> the following queries all return no rows in h2 <nl> since this is an unresolved star we do n't know whether it 's a path or an actual qualifier qualifier resolves to a non-struct field and can not be expanded,"adds support for querying indices without columns . previously , such queries failed .",1624026977,"this pull request is to enable the resthighlevelclient and lowlevelrestclient to automatically handle an elasticsearch response which has compressed content . compression can enabled within a node configuration with the following property : compression can be triggered by a request from a client . therefor you also need to provide additional information within the header of the request to elasticsearch if a client really wants to enable it . that is possible with the following requestoptions : . <nl> requestoptions.builder requestoptions = requestoptions.default.tobuilder ( ) <nl> .addheader ( ' accept-encoding ' , ' gzip ' ) . <nl> with these",0.9341515302658081
OpenAPITools_openapi-generator/8631,fix ocaml enum returntype in of_json.mustache,"enum return types seem to be incorrectly handled in api implementations for json swagger.txt . <nl> for operations returning enums , processing of return values is rendered as . <nl> where is an enum . it should however render to . <nl> the cause seems to be that neither nor is available for operations in : . <nl> this fix works for me , however i suppose that a solution could be substantially more elegant if i only was more with conversant codegen internals .",1612664141,- bugfix for models with parents ( embedded struct ) and to properly unmarshal .,0.926217794418335
elastic_elasticsearch/74283,"ilm mount snapshot step does need to set index.shard.check_on_startup . <nl> now the mount api overrides the index.shard.check_on_startup <nl> setting value to , there 's no need for mountsnapshotstep <nl> to set it explicitly .","now the mount api overrides the index.shard.check_on_startup <nl> setting value to , there 's no need for mountsnapshotstep <nl> to set it explicitly . <nl> this commit also fixes a failing test where some leftover code <nl> was overriding the setting value .",1624004182,"keystoreawarecommand attempted to deduce whether an error occurred <nl> because of a wrong password by checking the cause of the <nl> securityexception that keystorewrapper.decrypt ( ) throws . <nl> checking for aeadbadtagexception was wrong because that <nl> exception could be ( and usually is ) wrapped in an ioexception . <nl> this means that we would n't throw an appropriate error when running <nl> and <nl> when the user entered a wrong password . <nl> this commit addresses that issue , and since we are doing the check <nl> already in keystorewrapper , we can just return the message of",0.8865160942077637
Alluxio_alluxio/13455,"support bypass table when attach and sync db <para-sep> : the config file for the udb , you can specify bypass table by this option . return ufspath if set the key and value to be same when bypass path .","this pr supply a new option to describe detail information or concrete special behavior for the database . now , i add a json format file which contains , if tables are in it , they will be bypassed . <nl> bypass here means return the udb location directly to client , so that client can read data through ufs directly . <nl> this is an example of db config file . <nl> we can use the db config file when and . <nl> i create 0 table named and , now i bypass and , left in alluxio .",1621520800,"there are 0 components of this pr : . <nl> 0. throttle jobworker on high load of cpu <nl> 0. the task is no longer considered status.running until the task starts being processed . therefore , the parent plan is not considered status.running until one of its task starts being processed .",0.9425203204154968
elastic_elasticsearch/73756,"consolidate data stream alias logic . <nl> move data stream alias logic that was scattered in several places to the class . <cm-sep> adjust to 0.x reality <para-sep> returns the name of this data stream alias . returns the data streams that are referenced returns the write data stream this data stream alias is referring to . write requests targeting this instance will resolve the write index of the write data stream this alias is referring to . if the provided iswritedatastream is set to true then the provided data stream is also set as write data stream . if the provided iswritedatastream is set to false and the provided data stream is also the write data stream of this instance then the returned data stream alias instance 's write data stream is unset . the same instance is returned if the attempted addition of the provided data stream did n't change this instance . <nl> returns null if because of the removal of the provided data stream name a new instance would n't reference to any data stream . the same instance is returned if the attempted removal of the provided data stream did n't change this instance . <nl> the write data stream gets set to null in the returned instance if the write data stream no longer appears in the intersection . <nl> if this instance does n't have a write data stream then the write index of the other data stream becomes the write data stream of the returned instance . <nl> returns a new instance with potentially renamed data stream names and write data stream name . if a data stream name matches with the provided rename pattern then it is renamed according to the provided rename replacement . <nl> add to alias , a different instance is returned with as one of the data streams being referred to <nl> add to alias as write data stream , same as above but the returned instance also refers to as write data stream <nl> add as data stream , which is already referred to by this alias . the same instance is returned to signal a noop . <nl> add as non write data stream , which is already referred to by this alias . the same instance is returned to signal a noop . <nl> add as write data stream , which is already referred",move data stream alias logic that was scattered in several places to the class .,1622799202,this refactor for the deprecation plugin makes extending and adding more plugin settings deprecation checks simpler .,0.9752850532531738
apache_incubator-pinot/6694,remove unused variable in serverqueryexecutorv1impl and unnecessary check in threadtimer,"instead , if thread cpu timing is not enabled , return 0 . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1616089180,"* internally , we override this method , so moving the conditional into the method for backwards compatibility handling .",0.8364286422729492
apache_kafka/10675,"remove internal autodowngrade config , replace deprecation annotation on mockproducer <para-sep> eos-v2 assumes brokers are on version version+ and thus can understand the full set of consumer group metadata thus if we are using eos-v1 and ca n't make this assumption , we must downgrade the request to include only the group id metadata",removes this internal producer config which was only ever used to avoid a very minor amount of work to downgrade the consumer group metadata in the txn commit request . <nl> also replaces deprecation warning suppression with missing annotation on the mockproducer 's deprecated method .,1620775303,"turns out actually does apply the admin 's config internally , so we do n't need to worry about providing a timeout of our own . who knew",0.9479909539222717
elastic_elasticsearch/74106,"api keys are now cached on creation . <nl> the creation time hash computation now also uses the dedicated crypto <nl> thread pool , which was used only for authc time hash computation . <para-sep> clear the auth cache to force recompute the expensive hash which requires the crypto thread pool","the api key hashing result is now cached on the creation time of an api key , i.e . pre-warm the cache . previously it is cached when the api key is authenticated for the first time . since it is reasonable to assume that an api key will be used shortly after its creation , this change has following advantages : <nl> * it removes the need for expensive pbkdf2 hashing computation on authentication time and therefore reduces overall server load <nl> * it makes the first authentication faster . <nl> ~~currently , hashing on authentication time is performed",1623718885,"today a transport response uses the same wire format version as the <nl> corresponding request . this mostly works since we mostly know we are <nl> communicating with a node with a compatible version . tcp handshakes do n't have <nl> this guarantee since they use <nl> to let us handshake with older nodes . this results in the strange situation of <nl> a node of major version responding to a node of major version using a <nl> wire format of version . <nl> we put extra effort into the longer bwc requirements for successful responses , <nl> but we",0.9461760520935059
Graylog2_graylog2-server/10428,use consistent case for es cluster health status . <nl> the cluster health status on es6 was a lowercase string but on es7 is <nl> uppercase . this change transforms the status in es7 into a lowercase <nl> string . <cm-sep> make indexerclusterhealthsummary case independent .,"this pr makes makes two changes in the way we report es cluster health status and handle it in the web interface . <nl> first , it fixes an inconsistency in the returned case for the health status between elasticsearch versions . this is what the api returned before the changes , now it will use lower case in both cases : . <nl> es6 . <nl> es7 . <nl> additionally , it ensures the ui works in a case independent way , so the correct status is displayed regardless of the returned case . <nl> this pr needs to",1618326152,"when introducing the messageprocessor interface , the processing threads accidentally shared the instances ( and by induction the messagefilter instances as well ) . <nl> that posed no problem for most of the filters , because they do not rely on shared state , but the drools filter does and could skip messages ( because of drools itself returning early ) . <nl> this change uses a provider to get the orderedmessageprocessor instances explicitly and those do not get shared across threads .",0.8709256649017334
apache_beam/14659,propertly close executablestagecontext in dofnop # close . <nl> executablestagecontext needs to be closed when dofnop closes so that the wrapping default job bundle factory can be properly closed .,executablestagecontext needs to be closed when dofnop closes so that the wrapping default job bundle factory can be properly closed .,1619562944,"fix for potentially unclosed streams in apexyarnlauncher . <nl> using try-resources to handle closeable close issue <nl> removed redundant semicolons , string null assignment <nl> checkstyle passes . mvn clean verify passes .",0.8584150671958923
confluentinc_ksql/6845,add standard deviation udf <para-sep> uses the youngs-cramer algorithm to calculate standard deviation <nl> processing the first item,"this implementation uses the sample standard deviation calculation , later extensions can add support for population standard deviation .",1610139006,- <nl> - <nl> - . <nl> unit and integration tests are expected for any behavior changes._ .,0.962811291217804
elastic_elasticsearch/73335,"[ ml ] switch ml internal index templates to composable templates . <nl> legacy index templates are deprecated but ml was still using <nl> them for its hidden indices . <nl> this pr switches the legacy ml index templates to use the new <nl> composable index template framework . <nl> the composable index templates get installed once the master <nl> node is on a version that understands them . for templates <nl> that need to be up-to-date in mixed version clusters where the <nl> master might still be on a version that does n't understand <nl> composable index templates we still ship the legacy template <nl> too , and install this if required in the mixed version cluster . <nl> ( the notifications index template falls into this category . ) <nl> this makes a couple of places in the code a little messy , as <nl> the new style template definitions do n't contain a dummy _doc <nl> level ( where the type used to be ) , but the legacy template <nl> definitions do - hopefully we can tidy this up in master once <nl> version is released . <nl> there is one more change of note in this pr that is not <nl> strictly related to switching to composable templates , but <nl> which was shown up during the testing . we used to wait for <nl> all templates to be installed by the master node before running <nl> tests in mixed version clusters . i do not believe we should <nl> have been doing this , as other upgrade orchestration systems , <nl> e.g . cloud , will not be doing this . our production code needs <nl> to install templates and/or mappings before any operation that <nl> requires them if there 's a chance that the elected master wo n't <nl> have done this in time .","legacy index templates are deprecated but ml was still using <nl> them for its hidden indices . <nl> this pr switches the legacy ml index templates to use the new <nl> composable index template framework . <nl> the composable index templates get installed once the master <nl> node is on a version that understands them . for templates <nl> that need to be up-to-date in mixed version clusters where the <nl> master might still be on a version that does n't understand <nl> composable index templates we still ship the legacy template <nl> too , and install this if required",1621873545,this commit adds a dedicated threadpool for system index write <nl> operations . the dedicated resources for system index writes serves as <nl> a means to ensure that user activity does not block important system <nl> operations from occurring such as the management of users and roles .,0.9821677207946777
ballerina-platform_ballerina-lang/28791,make unused vars with inferred type incl . error a compilation error <cm-sep> fix now invalid var usage in tests <cm-sep> fix uninitialized var analysis for nested binding patterns <cm-sep> add tests <cm-sep> undo analysis for nested binding patterns <cm-sep> update tests <cm-sep> fix tests <cm-sep> remove io module usage in tests <para-sep> test usage of where the inferred type includes .,the following will now result in an error .,1613847817,the following changes are made with this pr : <nl> - is an open record <nl> - rest descriptor should also match to consider two open records equivalent <nl> - an open record and a closed record will not be equivalent <nl> - a closed record can be equivalent to an open record type . but not vice versa,0.9480885863304138
vespa-engine_vespa/18226,use lower case system name in tsdbqueryrewriter,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623432402,this reduces log spam on cd-controller .,0.6701769828796387
Alluxio_alluxio/12659,add unit test for failed tier move <para-sep> we are not evicting in the target tier so having no available space just means the tier is currently full . <nl> fill up the target dir <nl> consistency check : the block is still in its original location,"this change does 0 things : <nl> 0. when a tier mgmt task fails because the destination dir is full , it logs a warning instead of error <nl> 0. adds a unit test that verifies a failed tier move issued by a tier mgmt task fail consistently",1608194099,"when recursively listing from an object store , alluxio computes the prefixes from the object store results . however , the commonprefixes returned by the object store include the path separators . therefore , the alluxio processing should follow the same convention and include the path separators . further processing of the prefixes assume that the path separators are included .",0.8714712262153625
elastic_elasticsearch/73690,"make ilm aware of node shutdown . <nl> this commit makes ilm aware of different parts of the node shutdown lifecycle . it consists are two <nl> main parts , reacting to the state during execution , and signaling the status of shutdown from ilm . <nl> reacting to shutdown state <nl> ilm now considers nodes that are going to be shut down when deciding which node to assign for the <nl> shrink action . it uses the within the to <nl> not assign shards to a node that will be removed . if an index is already past this step and waiting <nl> for allocation , this commit adds an method to the <nl> so that an allocation that can not happen can be rewound and <nl> retried on another ( non-shutdown ) node . <nl> signaling shutdown status <nl> this commit introduces the which deals with classes . <nl> this class is used to signal shutdowns to plugins , and also to gather the status of a shutdown from <nl> these plugins . ilm implements this to signal if an index is in a step that is <nl> unsafe , such as the actual shrink step , so that shutdown will wait until after the allocation rules <nl> have been removed by ilm . <nl> this commit also hooks up the get shutdown api response to consider the statuses of its parts ( see <nl> ) when creating a response . <para-sep> these are ordered ( see # combine ( ... ) ) <nl> merges multiple statuses into a single , final , status for example , if called with not_started , in_progress , and stalled , the returned state is stalled . called with in_progress , in_progress , not_started , the returned state is in_progress . called with in_progress , not_started , complete , the returned state is in_progress called with complete , complete , complete , the returned state is complete called with an empty array , the returned state is complete <nl> max the status up to , but not including , ' complete ' <nl> either all the statuses were complete , or there were no statuses given <nl> whether the plugin is considered safe to shut down . this method is called when the status of a shutdown is retrieved via the api , and it is only called on the master node","this commit makes ilm aware of different parts of the node shutdown lifecycle . it consists are two <nl> main parts , reacting to the state during execution , and signaling the status of shutdown from ilm . <nl> reacting to shutdown state <nl> ilm now considers nodes that are going to be shut down when deciding which node to assign for the <nl> shrink action . it uses the within the to <nl> not assign shards to a node that will be removed . if an index is already past this step and waiting <nl> for allocation , this",1622653877,"this commit adds a new metadata field mapper that validates , <nl> that a document has exactly a single timestamp value in the data stream timestamp field . <nl> the metadatacreateindexservice inserts a data stream timestamp field mapper whenever <nl> a new backing index of a data stream is created .",0.9788786768913269
apache_pulsar/10366,fix transaction timeout tracker expired problem .,"so should add the timeout expired check . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that",1619369761,"the default value of the offload-deletion-lag is , this will cause an npe problem . <nl> add null check in the method . <nl> add unit test for method . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( yes ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : (",0.9225834012031555
grpc_grpc-java/8168,"implement rbac engine <para-sep> matcher for http request path . * / <nl> exact full path to be matched . <nl> path prefix to be matched . <nl> regular expression pattern of the path to be matched . <nl> whether case sensitivity is taken into account for matching . only valid for full path matching or prefix matching . <nl> provides a group of request matchers . a matcher evaluates an input and tells whether certain argument in the input matches a predefined matching pattern . <nl> matcher for http request headers . * / <nl> name of the header to be matched . <nl> matches exact header value . <nl> matches header value with the regular expression pattern . <nl> matches header value an integer value in the range . <nl> matches header presence . <nl> matches header value with the prefix . <nl> matches header value with the suffix . <nl> whether the matching semantics is inverted . e.g. , present & & ! inverted - > ! present <nl> the request header value should exactly match the specified value . * / <nl> the request header value should match the regular expression pattern . * / <nl> the request header value should be within the range . * / <nl> the request header value should exist . * / <nl> the request header value should have this prefix . * / <nl> the request header value should have this suffix . * / <nl> returns the matching result . * / <nl> represents an integer range . * / <nl> represents a fractional value . * / <nl> represents various ways to match a string . * / <nl> the input string has this prefix . <nl> the input string has this suffix . <nl> the input string matches the regular expression . <nl> the input string has this substring . <nl> if true , exact/prefix/suffix matching should be case insensitive . <nl> the input string should exactly matches the specified string . * / <nl> the input string should have the prefix . * / <nl> the input string should have the suffix . * / <nl> the input string should match this pattern . * / <nl> the input string should contain this substring . * / <nl> returns the matching result for this string . * / <nl> matcher to evaluate whether an ipv4","implement rbac engine and its helpers . <nl> next step : implemented consumer of the rbac engine , in server interceptors .",1620772295,"this pr contains all the changes in interface that i think are necessary for issues i encountered in its implementation . <nl> - method is no longer needed . constructor will take build the channel . the first rpc is sent only after a first watcher is registered . <nl> - methods need to take in the that was used for registering the watcher , so that we do not need to maintain another mapping from watcher to cluster name . <nl> with these data api defined , the xds resolver and lb policies should be able to proceed with",0.9619570374488831
neo4j_neo4j/11633,first draft at making the 0.x version of index entry hash work well with the values types . <cm-sep> try to make 0 bit string hashing faster . <cm-sep> make the 0-bit updatehash method on string values hash two code points at a time . <para-sep> note that we are basing the hash code on code points instead of char [ ] values . <nl> todo good enough ? or do subclasses need to implement each their own ?,"this variant is 0 to 0 times faster than the 0 variant , except for strings where it 's slightly slower ( 0 ns/op vs. 0 ns/op for 0 character strings ) due to the shortcuts the 0 variant can take there . the main motivation is , however , an astronomically reduced collision probability . especially for strings .",1524488704,"specifically in off-heap versions of primitive-collections and numberarray . <nl> unsafeutil provides means of knowing about aligned memory access constraint , <nl> but does n't automatically conforms access by it . need for aligned memory access <nl> is hardware dependent . <nl> currently the muninn page cache has some logic for this . other users of <nl> unsafeutil are the primitive-collections and numberarray . they have different <nl> constraints themselves than the page cache do and so they have been changed <nl> to conform to alignment constraints , but can get away with doing less adaptations <nl> than the page",0.9512608051300049
OpenAPITools_openapi-generator/8345,spring codegen - fix equals and hashcode methods for byte array and binary . <nl> - they should be compared using arrays.equals <nl> - they 're hash code generated using arrays.hashcode <para-sep> add imports for java.util.arrays,binary and byte arrays <nl> * should be compared using arrays.equals ( ... ) <nl> * their hash code generated using arrays.hashcode ( ... ) . <nl> spring codegen has been updated and the tests updated .,1609885743,- replace ' usenullforunknownenumvalue ' option with the nullable attribute,0.887732207775116
Graylog2_graylog2-server/10590,return default value for scaling factor if absent . <cm-sep> use if interpolation mode is absent .,"prior to this pr , when editing the ' messages over time ' widget of the ' sources ' dashboard , the user immediately ends up in a state where validation is failing due to missing and values . those are missing in the widget we generated in the migration in the first place . any further editing of the widget results in a valid widget . <nl> this pr is returning a default value ( ) for scaling in the backend if the factor is absent . in addition , when editing a widget with a line chart visualization",1620378955,"when no index is defined for the collection , a user <nl> visiting the system/overview page generates collscans on this <nl> collection , possibly leading to a performance degradation .",0.760992169380188
apache_ignite/9163,"cleanup <cm-sep> add ignitemarshallercacheseparatedirectorytest <cm-sep> wip ignitemarshallercacheseparatedirectorytest <cm-sep> fix shell.executesafe <cm-sep> restore old registermetadataforregisteredcaches behavior to fix java side , but break .net side <cm-sep> call registermetadataforregisteredcaches from platformprocessor <cm-sep> remove null assertion <cm-sep> use separate work dirs in queryentitymetadataregistrationtest <para-sep> register query entity meta .","* restore call in - this fixes java-side behavior , but breaks registration for platform types , because is not available at this point <nl> * call second time from only for platform types",1623261083,fix memory leak on unstable topology caused by partition reservation,0.964080274105072
OpenAPITools_openapi-generator/9299,add the dockerfile and updated the readme and others . <cm-sep> fixed the indent to follow the coding style guide .,"i add a dockerfile to the ruby-sinatra generator , and also update the readme.md file . <nl> to prepare these files , i needed to update the gemfile .",1618966663,"it does the same stuff as in the .travis.yml but just for gitlab ci : run nosetests . <nl> i see a but does n't use it , so i do n't know whether nosetests is the way to go here .",1.0000001192092896
OpenAPITools_openapi-generator/9268,add imports for inner items of arrays/maps in composedschemas <para-sep> without configuring providers <nl> configuring providers <nl> set configuration parameters here . <nl> configuring providers with an authentication service that manages your access tokens <nl> tslint : disable : no-unused-variable member-ordering * /,"for typescript at least , we need to import the inner items of complex types of the composed schemas . this pr adds it . <nl> there might be a better/cleaner way to do this , i 'm using the method to re-use existing algorithm and have the property and import them all . <nl> please advise if it should be done another way .",1618476660,visionmedia/superagent version is vulnerable to zip bomb attacks . <nl> refs : nvd - 0 . <nl> it has been fixed in v3.version . <nl> > - limit maximum response size . prevents zip bombs ( kornel ),0.8888238072395325
ballerina-platform_ballerina-lang/31405,fix modules getting removed during syntaxtreemodify,this was due to function selecting the first part of the molecule name and evaluates whether it exists in the code and decides whether or not to remove it .,1624452545,main function within a ballerina should be defined in a standard manner to execute . it only accepts one integer type argument and can return any number of arguments ( which are not usable though ) . here is the standard format .,0.8617798089981079
apache_beam/14016,"initial kafka byte restructuring <cm-sep> fix payload handling <cm-sep> fixes <cm-sep> tests <cm-sep> run spotless , add more tests <para-sep> csv is handled separately because multiple rows can be produced from a single message , which adds complexity to payload extraction . it remains here and as the default because it is the historical default , but it will not be extended to support attaching extended attributes to rows . <nl> a class which transforms kafka records with attributes to a nested table . * / <nl> suppress nullability warnings : producerrecord is supposed to accept null arguments . <nl> not nested schema ( no headers ) <nl> row payload without serializer <nl> bytes payload with serializer <nl> bad field in schema <nl> bad field type in schema <nl> schema requires headers , missing in message <nl> badrow can not be cast to schema","this modifies the kafka sql table provider to have a nested mode like pub/sub currently does , that exposes the headers and event timestamp from the record . it also allows the payload field in this mode to be bytes type , remaining unparsed in this case",1613677103,select from a pubsub topic and insert into a bigquery table . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9793605804443359
quarkusio_quarkus/17776,"also register customresource implementors fully for reflection . <nl> ( cherry picked from commit sha ) <cm-sep> simplescheduler - fix crontrigger # evaluate ( ) . <nl> ( cherry picked from commit sha ) <cm-sep> add resteasy extension to generated app in the amqp guide . <nl> ( cherry picked from commit sha ) <cm-sep> add artemis-mqtt-protocol dependency . <nl> ( cherry picked from commit sha ) <para-sep> register fully ( and not weakly ) for reflection watchers , informers and custom resources <nl> when the class has no subclasses and we were not able to determine the generic types , it 's likely that the class might be able to get deserialized <nl> milliseconds","please do n't merge , i will merge it myself .",1623173378,better reviewed commit per commit as they are all small fixes . <nl> so here are a set of fixes/improvements . <nl> could you have a look ?,0.911955714225769
prestodb_presto/16069,remove periodic check from memoryrevokingscheduler . <nl> it 's not needed since memory revocation is called on every reservation .,test plan - unit tests .,1620662276,"for others , we need to take care manually .",1.0
ballerina-platform_ballerina-lang/27011,propagate readonly-ness of cet to object-constr-expr analysis <cm-sep> defer semantic analysis of classes for object-constr-exprs to the type-checker <cm-sep> add tests <cm-sep> support implicitly isolated object-constructor-exprs <cm-sep> add tests <cm-sep> consider the union of readonly and isolated object for isolated expr types <cm-sep> refactor code <para-sep> this is a class defined for an object-constructor-expression ( oce ) . this will be analyzed when visiting the oce in the type checker . <nl> //// test object-constructor-expr with contextually expected type ////// <nl> //// test object-constructor-expr with contextually expected type //////,"this pr . <nl> - adds support for isolated object constructor expressions . isolatedness will no longer be inferred from the expected type for non-implicitly isolated object constructor expressions . <nl> - adds support for implicitly isolated object constructor expressions . <nl> the spec says . <nl> > an object field is isolated if it is declared as final and has a type-descriptor that is a subtype of readonly or isolated object { } , or if the object-constructor-expr is implicitly read-only . an object-constructor-expr is implicitly isolated if it is implicitly readonly or if every object field is isolated",1605769144,fix the following issues with immutable xml elements . <nl> - fixes attribute setting failing on initialization for immutable elements . <nl> - fixes the type of an immutable element 's attribute map not being marked immutable . <nl> - fixes children of an immutable element not being marked immutable .,0.970675528049469
OpenAPITools_openapi-generator/9519,adds getter + setter methods for isshortinteger in ijsonschemavalidationproperties <cm-sep> adds isshortinteger to codegenmodel <cm-sep> adds isshortinteger to codegenproperty <cm-sep> adds isshortinteger to codegenparameter <cm-sep> adds isshortinteger to codegenresponse,"this is not a breaking change with fallback because isinteger behaves the same . <nl> if one needs to differentiate between int32 and unbounded integers , one should use the template variables : <nl> - isshort <nl> - isunboundedinteger .",1621395164,i want to embed annotation when in kotlin-spring .,0.944988489151001
apache_camel/5529,added option to filter getall by path <cm-sep> fix in objectproducer because of failing test,the code adds the ability to modify the behavior of getall in the swift client by putting ' path ' =value in the header . <nl> the result is that a list of objects whose path starts with value are returned . <nl> if the ' path ' is not set it has the usual behavior .,1620398308,properties component should work with eclipse microprofile config,0.8862714171409607
apache_kafka/10679,global-topic-count-metric-and-test <cm-sep> add-global-partition-and-topic-metrics <cm-sep> comments-addressed <cm-sep> merge trunk <cm-sep> adding-offline-partition-and-replica-imbalance-metrics <cm-sep> global-topic-partition-counts <para-sep> a count of the total number of partitions in the cluster . <nl> a reference to the controller 's metrics registry .,"added globaltopiccount and globalpartitioncount metrics to the quorumcontrollermetrics . <nl> the metrics are calculated by counting records as they are replayed e.g . replay ( topicrecord ) , replay ( removetopicrecord ) . <nl> this was unit tested using mockcontrollermetrics .",1620842044,added supporting customized http response headers for kafka connect rest server .,0.957348108291626
apache_pulsar/11015,feat # add test for topiccountequallydividebundlesplitalgorithm . <para-sep> -- algorithm <nl> -- calculate the mock result <nl> -- do test,# # # modifications . <nl> add test for topiccountequallydividebundlesplitalgorithm .,1624350721,now we do n't have end to end test for tls authentication . <nl> - changed authtls.cc . <nl> from . <nl> to . <nl> to make it same as java auth plugin 's api . <nl> - add certification & key files for authentication <nl> - add tls authentication test for java client . <nl> - add tls authentication test for c++ client . <nl> we can test tls authentication plugin .,0.9250349402427673
vespa-engine_vespa/17390,"keep wanttorebuild flag until ready <cm-sep> extract constant <cm-sep> fix typo <para-sep> returns nodes that are candidates for upgrade * / <nl> trigger upgrade of candidates to given version * / <nl> readying host clears rebuild flag <nl> time budget has been spent , but we can not rebuild another host until the current one is done <nl> second host is rebuilt",rebuilding is unreliable and may result in the host becoming unavailable .,1618256161,we need to be able to override the applications override of the system level override of the system majorversion on the application level .,0.9617964029312134
apache_druid/10960,do n't fail on invalid views in informationschema,"this pr fixes an issue where information_schema queries would fail if an invalid view ( e.g. , view on a non-existent datasource ) is defined",1615245130,"though it and these others i have modified do seem to fail much less frequently than did , this should still help reduce flaking i think .",0.8786599040031433
elastic_elasticsearch/72674,"remove simplematchtofullname <cm-sep> some more unit tests <para-sep> check the ancestor of the field to find nested and object fields . runtime fields are excluded since they can override any path . todo find a way to do this that does not require an instanceof check <nl> we added this path on another field already <nl> checks if the parent field contains sub-fields <nl> no field type , it must be an object field <nl> returns all the mapped field types that match a pattern note that if a field is aliased and both its actual name and its alias match the pattern , the returned collection will contain the field type twice . <nl> no wildcards <nl> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field <nl> returns a set of field names that match a regex-like pattern all field names in the returned set are guaranteed to resolve to a field <nl> returns all the mapped field types that match a pattern note that if a field is aliased and both its actual name and its alias match the pattern , the returned collection will contain the field type twice .","mappinglookup has a method simplematchtofieldname that attempts <nl> to return all field names that match a given pattern ; if no patterns match , <nl> then it returns a single-valued collection containing just the pattern that <nl> was originally passed in . this is a fairly confusing semantic . <nl> this pr replaces simplematchtofullname with two new methods : <nl> * getmatchingfieldnames ( ) , which returns a set of all mapped field names <nl> that match a pattern . calling with a name returned by <nl> this method is guaranteed to return a non-null mappedfieldtype <nl> * getmatchingfieldtypes ,",1620124634,adds deleting multiple snapshots in one go without significantly changing the mechanics of snapshot deletes otherwise . <nl> this change does not yet allow mixing snapshot delete and abort . abort is still only allowed for a single snapshot delete by exact name .,0.974073052406311
apache_kafka/10232,make sure all rejoin groupa and reset state has a reason,0. create a reason string to be used for info log entry whenever we request re-join or reset generation state . <nl> 0. some minor cleanups .,1614581219,* add a normal windowed suppress with short windows and a short grace <nl> period <nl> * improve the smoke test so that it actually verifies the intended <nl> conditions .,0.933475136756897
confluentinc_ksql/7717,fixes slow streams shut down bug which made tests flaky,"the symptom of the flakiness was the failure : . <nl> after a lot of investigation , i noticed that was never being called in rare scenarios , causing the future to never complete . <nl> this was ultimately caused by an exception : . <nl> this pr avoids the cleanup if the does n't close correctly .",1624425082,"the api is a new method added in kafka version . if ksql runs on kafka version or lower , this api will return null causing a npe in ksql and denying any operation executed on a kafka version environment . <nl> to avoid the npe issue , ksql avoids enabling the topic validator instead . look at the which checks if the from the cluster is null . <nl> run local tests with kafka version . warning message is printed : . <nl> [ 0-0-0 0:0:0,0 ] warn the kafka broker has an authorization service enabled , but the",0.9157889485359192
apache_pulsar/10238,standalone support transaction . <para-sep> create default namespace <nl> create pulsar system namespace,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1618463104,and it follow the priority : args > conf > default,0.9095730781555176
apache_incubator-pinot/6754,add more logging for debugging segment reloading .,"add more logging to indicate the status of segment reloading . the segment reload involves multiple steps and conditions . we found it is hard to track the status for operation like segment reloading to populate derived columns . <nl> a good description should include pointers to an issue or design document , etc . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1617821024,user report anomalies to be exposed to ui <nl> add functionid to user report anomalies to let api fetch anomalies under function id .,0.8915783166885376
confluentinc_ksql/6803,"syntax changes <cm-sep> null handling <cm-sep> cleanup <cm-sep> historic plans <para-sep> maintain legacy name for backwards compatibility <nl> maintain legacy name for backwards compatibility <nl> maintain legacy name for backwards compatibility <nl> maintain legacy name for backwards compatibility <nl> new key column added , copy in to value schema : <nl> if partitioning by something other than an existing column , then a new key will have been synthesized . this new key must be appended to the value to make it available for stream processing , in the same way sourcebuilder appends the key and rowtime to the value : <nl> if partitioning by something other than an existing column , then a new key will have been synthesized . this new key must be appended to the value to make it available for stream processing dowmsteam in the topology . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> expect / when : <nl> then :","this pr adds support for partition by with multiple expressions , resulting in multiple key columns . there are no backwards compatibility concerns as the ksqldb syntax did not support this prior to this pr . <nl> docs will come in a separate pr . <nl> qtt .",1608276435,"prep pr for betting implicit field handling and structured key work . <nl> this pr extends the type to explicitly handling the implicit fields , i.e . and the key fields , i.e . <nl> - renamed - > <nl> - renamed - > <nl> - added and . <nl> - renamed - > <nl> - added ( to find across all fields . <nl> - renamed - > . <nl> a lot of this is not yet used . this is just prep work and i wanted the renames to happen outside of any pr that changed functionality .",0.9758642315864563
pentaho_pentaho-kettle/7823,"limitation with excel writer step - appending data to an existing xlsx document does not work when ' stream xlsx data ' is enabled . <cm-sep> remove unnecessary code <para-sep> ignore , by now , if it 's to use streaming ! in that case , one needs to initialize it later , after writing header/template , because sxssfworkbook ca n't read/rewrite existing data , only append . <nl> if it 's to use streaming , initialize it now as we already made all necessary initial calculations .","please , do n't forget to squash .",1610979973,- adding code to set the metastore object on transformations being executed via mdi . this is required to support making annotatestream step metadata-injectable .,0.8721057176589966
apache_kafka/10894,": restore must terminate for tx global topic <para-sep> records with key 1l , 2l , and 4l are written into record with key 3l is written into <nl> set the checkpointed offset to the commit marker of even if wo n't return any data for , we should still finish the restore <nl> we need to write aborted messages only after we init the to move the beyond the ` highwatermark we can not write committed messages because we want to test the case that poll ( ) returns no records cf . globalstatemanagerimpl # restorestate ( ) <nl> skip record because we wo n't read it ( cf checkpoint file above )","* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1623911575,"streamthreadstatestoreprovider # stores throws exception whenever taskid is not found , which is not correct behaviour in multi-threaded env where state store partitions are distributed among several streamtasks . <nl> final task task = tasks.get ( keytaskid ) ; <nl> if ( task == null ) { <nl> throw new invalidstatestoreexception ( <nl> string.format ( ' the specified partition % d for store % s does not exist . ' , <nl> storequeryparams.partition ( ) , <nl> storename ) ) ; <nl> } <nl> reproducible with kstream number of threads more then 0 . <nl> storequeryintegrationtest # streamsconfiguration . <nl>",0.9533388018608093
apache_beam/14034,"returning successes from fhirio executebundles . needed for healthcare <nl> solutions accuracy in logging what was written to the fhir store . <cm-sep> syncing with milenas change <cm-sep> undo formatting changes from google auto-formatter . <cm-sep> adding the tuple tag check for fhirio.write.result creation . <cm-sep> updating the contains tupletag check to use the pcollectiontuple .has ( ) <nl> method , casting tupletaglist - > collection creates an exception for <nl> some . <para-sep> the tag for successful writes to fhir store . * / <nl> the tag for the failed writes to fhir store . / the tag for the files that failed to fhir store . / the tag for temp files for import to fhir store . * / <nl> gets successful bodies from write .",adding a getsuccesses ( ) method to the fhirio.write.result - useful for the healthcare api users to know which bodies were successfully written to the store . <nl> i also made the check for tupletags consistent in fhirio.read.result and fhirio.search.result ( using the pcollectiontuple .has ( ) method ) since the cast from tupletaglist - > java.util.collection resulted in a classcastexception for me,1614014135,"motivation . <nl> - cleanup the code of on register process boundle descriptor . <nl> - correct the implementation of fn api , i.e. , would be better to cater to the asynchronous design principles of the beam api . <nl> changes <nl> - 0 : <nl> update the client side implementation of fn api to make sure registration is executed successfully before executing process_bundle . personally i think that the client side implementation of fn api should not assume that the implementation of registration in sdk harness is synchronous . the registration api itself is asynchronous and the client",0.9513491988182068
elastic_elasticsearch/74231,"this pr adds corresponding components in high level rest client for the new <nl> apis related to the service accounts feature . <para-sep> clears the service account token cache for the specified namespace , service-name and list of token names . see the docs for more . <nl> clears the service account token cache for the specified namespace , service-name and list of token names asynchronously . see the docs for more . <nl> get a service account , or list of service accounts synchronously . see the docs for more information . <nl> get a service account , or list of service accounts asynchronously . see the docs for more information . <nl> create a service account token . see the docs for more . <nl> asynchronously creates a service account token . see the docs for more . <nl> delete a service account token . see the docs for more . <nl> asynchronously deletes a service account token . see the docs for more . <nl> get credentials for a service account synchronously . see the docs for more information . <nl> get credentials for a service account asynchronously . see the docs for more information . <nl> the request used to clear the service account token cache .",this pr adds corresponding components in high level rest client for the new <nl> apis related to the service accounts feature .,1623929571,"getting the api key document form the security index is the most time consuing part <nl> of the api key authentication flow ( > 0 % if index is local and > 0 % if index is remote ) . <nl> this traffic is now avoided by caching added with this pr . <nl> additionally , we add a cache invalidator registry so that clearing of different caches will <nl> be managed in a single place ( requires follow-up prs ) .",0.9838043451309204
netty_netty/11204,"before throwing toolongframeexception , should call the skipbytes method to skip the bytes to be read .","motivation : . <nl> before throwing toolongframeexception , should call the skipbytes method to skip the bytes to be read . <nl> modification : <nl> this pr is to skip the bytes that need to be read in mqttdecoder , thanks .",1619577476,"remove ' content-length ' when decoding http/version message with both ' transfer-encoding : chunked ' and ' content-length ' . <nl> while it seems correct for netty to try to sanitize these types of <nl> messages , the spec explicitly mentions that the content-length header <nl> should be removed in this scenario . <nl> if a message is received with both a transfer-encoding and a <nl> content-length header field , the transfer-encoding overrides the <nl> content-length . such a message might indicate an attempt to <nl> perform request smuggling ( section version ) or response splitting <nl> ( section version",0.8124303817749023
apache_beam/13731,pubsub support writing beam datetime ( sql timestamp ) type <para-sep> extracts datetime from the jsonnode ( iso 0 format string ) if it is valid .,"see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1610437542,this pr refactors beam zetasql type translation code . <nl> after the refactor : <nl> zetasqlbeamtranslationutils.java contains utility methods for translation between zetasql and beam . <nl> zetasqlcalcitetranslationutils.java contains utility methods for translation between zetasql and calcite,0.9195535778999329
elastic_elasticsearch/74493,"deprecate bounding box query type parameter <para-sep> test [ warning : deprecated field used , this field is unused and will be removed entirely ]","this parameter is currently a non-op , therefore we are deprecating it .",1624458908,this will cause them to fail if you do n't have permission to execute <nl> expensive queries .,0.9101507067680359
elastic_elasticsearch/73017,"resolve associated indices for feature reset . <nl> when associated index patterns contained wildcards and <nl> action.destructive_requires_name was set to true , feature resets were <nl> failing . in order to avoid this , we want to resolve associated index <nl> names , then pass the concrete index names to the delete request . <nl> for normal system indices , the systemindexdescriptor provides a method <nl> that searches cluster metadata for indices that match the the system <nl> index pattern . this commit introduces an associatedindexdescriptor that <nl> provides the same mechanism . although we could use an <nl> indexnameexpressionresolver for the associated indices , it makes sense <nl> to me to keep things consistent across the various feature index patttern <nl> collections . <nl> this change has the effect of allowing the same regex-like syntax that <nl> system index patterns can use , rather than just wildcards , in associated <nl> index patterns . <cm-sep> add tests for associated index descriptors <cm-sep> make an indexdescriptor superclass . <nl> associated index descriptors need what is nearly a strict subset of the <nl> behavior of system index descriptors . it might make sense to create an <nl> indexdescriptor superclass and simply use that for associated indices . <nl> this will simplify code that resolves concrete indices from index <nl> patterns and cluster metadata . <para-sep> an ' associated index ' is an index that is related to or derived from a system index , but should not be considered a system index , usually because it is meant to be visible to users . however , if it goes out of sync with its related system indices , it may become unreliable or useless . hence , when taking a snapshot of a feature , we want the associated index to be included in the snapshot , and , likewise , we want an associated index to be restored when a feature snapshot is restored . <nl> a pattern , either with a wildcard or simple regex . * / <nl> a description of the index or indices * / <nl> create a descriptor for an index associated with a feature","when associated index patterns contained wildcards and was set to , feature resets were failing . in order to avoid this , we want to resolve associated index names , then pass the concrete index names to the delete request . <nl> for normal system indices , the provides a method that searches cluster metadata for indices that match the the system index pattern . this pr introduces a more general index descriptor class that provides the same mechanism . although we could find a way to use an for the associated indices , it makes sense to me to",1620855469,"plugin policy parsing is currently split , with different code executed <nl> for elasticsearch startup vs installing a plugin . this commit <nl> refactors the policy parsing to be utilized by both places . the main <nl> benefit is policy files in both places now handle permissions not only <nl> for a global grant , but also codebase specific grants .",0.9732727408409119
OpenAPITools_openapi-generator/9613,"minor improvements to wsdl-schema gen <cm-sep> better code format <para-sep> wsdl-schema ( beta ) <nl> strip umlauts etc . <nl> for xml compliant primitives , lowercase datatype of openapi <nl> prevent default= ' null ' in wsdl-tag if no default was specified for a param <nl> check if param has a minimum or maximum number or lenght <nl> if param is enum , uppercase 'basename ' to have a reference to wsdl simpletype <nl> check if model is a model with no properties used in the mustache template to ensure that no complextype is created if model is just a schema with an enum defined in the openapi specification <nl> lowercase basetypes if openapitype is string <nl> if string enum , uppercase 'name ' to have a reference to wsdl simpletype <nl> prevent default= ' null ' in wsdl-tag if no default was specified for a property <nl> check if model property has a minimum or maximum number or lenght <nl> just return the original string <nl> just return the original string <nl> delete temp folder",- renamed to <nl> - classified as ' schema ' generator <nl> - minor bug fix ( string comparison ) <nl> - better code format .,1622171274,this pr add the support of jackson in addition to gson for rest-assured .,0.8912656307220459
confluentinc_ksql/6795,"clarify single key unwrapping during schema inference ( minor ) <para-sep> until we support user-configuration of single key wrapping/unwrapping , we choose to have key schema inference always result in an unwrapped key",docs changes and a minor refactor to clarify that key schema inference always results in an unwrapped key today . also adds a qtt for multi-column key schema inference to confirm . <nl> new qtt passes .,1608161649,"ksql otherwise gets oom errors after doing high qps for half an hour , due to creating so many unique loggers . <nl> this is because both in the class and in the logger factory itself , they keep a concurrentmap of name - > logger to reuse loggers . after many , many queries , you eventually get ooms if you create a new one every pull query .",0.8537322282791138
elastic_elasticsearch/74257,"[ ml ] change close job so that it automatically stops the datafeed . <nl> previously it was a requirement of the close job api that if the <nl> job had an associated datafeed that that datafeed was stopped <nl> before the job could be closed . experience has shown that this <nl> is just a pedantic nuisance . if a user closes the job without <nl> first stopping the datafeed then it 's just a mistake , and they <nl> then have to make two further calls , to stop the datafeed and <nl> then attempt to close the job again . <nl> this pr changes the behaviour so that if you ask to close a job <nl> whose datafeed is running then the datafeed gets stopped first <nl> as part of the same call . datafeeds are stopped with the same <nl> level of force as the job close request specified . <para-sep> use lots of chunks to maximise the chance that we can close the job before the lookback completes <nl> it 's possible that the datafeed ran to completion before we force closed the job . ( we tried to avoid this by setting a small chunk size , but it 's not impossible . ) if the datafeed ran to completion then there could legitimately be a model snapshot even though we force closed the job , so we can not assert in that case . <nl> 0. if any of the jobs to be closed have running datafeeds , these are stopped first , using the same level of force as the close request 0. internally a task request is created for every open job , so there 0. no task is created for closing jobs but those will be waited on 0. collect n inner task results or failures and send 0 outer <nl> if there are failed jobs force close is true <nl> a datafeed with an end time will gracefully close its job when it stops even if it was force stopped . if we did n't do anything about this then it would turn requests to force close jobs into normal close requests for those datafeeds , which is undesirable - the caller specifically asked for the job to be closed forcefully , skipping the final state persistence to save time . therefore , before stopping the datafeeds in this","previously it was a requirement of the close job api that if the <nl> job had an associated datafeed that that datafeed was stopped <nl> before the job could be closed . experience has shown that this <nl> is just a pedantic nuisance . if a user closes the job without <nl> first stopping the datafeed then it 's just a mistake , and they <nl> then have to make two further calls , to stop the datafeed and <nl> then attempt to close the job again . <nl> this pr changes the behaviour so that if you ask to",1623947797,"deprecate settings : <nl> * in favor of <nl> * in favor of <nl> * in favor of . <nl> default to context cache . <nl> add , default to totally disable compilation rates . this setting is intended for integration tests .",0.9548397660255432
apache_druid/10839,"dd_protobuf_schema_registry <cm-sep> change licese <cm-sep> delete some annotation <cm-sep> nodify tests <cm-sep> delete extra exception <cm-sep> add licenses <para-sep> configure parser with desc file , and specify which file name to use <nl> configure parser with desc file , and specify which file name to use <nl> configure parser with desc file <nl> configure parser with non existent desc file <nl> for the backward compatibility , protomessagetype allows null when the desc file has only one message type . <nl> configure parser with desc file <nl> create binary of proto test event <nl> given <nl> when <nl> then <nl> given <nl> when <nl> given <nl> when <nl> given <nl> when <nl> given <nl> when <nl> then <nl> then <nl> then",confluent 's schema registry supports for deserializing protobuf now . so i add this feature to druid-protobuf-extension module . this module only work when user provide a .desc file in old version . now it can get schema from schema registry dynamically . <nl> this submission adds the io.confluent : kafka-schema-registry-client : version/io.confluent : kafka-protobuf-provider : version dependency to the druid-protobuf-extension module . <nl> old spec is : . <nl> new spec is : . <nl> and,1612325502,the benchmark report shows that the performance is improved by about 0 % with this pr . <nl> machine info : <nl> cpu : intel ( r ) xeon ( r ) gold 0 cpu @ versionghz <nl> disk : hdd <nl> command : java -djava.io.tmpdir=/data00/tmp_dir -jar benchmarks.jar indexmergewithtmpfilebenchmark,0.9779501557350159
Graylog2_graylog2-server/10392,url-encode template name so special characters are quoted . <cm-sep> quote special characters in index prefixes before creating regex .,"note : this pr requires a backport to . <nl> this pr is making a couple of changes to support the + character in index set prefixes . the required changes were : . <nl> - properly url encode in names when creating the index template <nl> - quote when creating the regular expression used to match indices against the prefix . <nl> when an index set is configured with a in the index set prefix , all kinds of issues show up , making it effectively unusable . indices are not identified to belong to this index set ,",1617895771,this pr adds some improvements to the events definition page : . <nl> - displays loading state when loading list of events definitions <nl> - uses pagination from the resource to display a paginated list <nl> - adds a filter component and implements filtering capabilities in the backend resource <nl> - displays information about scheduling and notifications in the list of event definitions .,0.9317896962165833
ballerina-platform_ballerina-lang/28989,"fix module prefix issues in errortypesymbol unions <cm-sep> modify the regex pattern to identify fully qualified module id <para-sep> it is assumed that if the owner is null , the error is defined within the current module .",> <nl> > * improved regex pattern : .,1614831701,"this will reduce the overhead of a task by removing the creation of a and a instances for each and every task . instead now we have a single instance , and we submit all the tasks as jobs .",0.9427919983863831
elastic_elasticsearch/73573,"create enrollment token . <nl> method to be called by the startup process while elasticsearch is in the <nl> enrollment mode to obtain an <nl> enrollment token used to enroll a new node to the cluster . <para-sep> setting for enabling enrollment process ; set-up by the es start-up script * / <nl> protected for testing <nl> tbd : awaiting enroll kibana api to be merged public string createkibanaenrollmenttoken ( string user , securestring password ) throws exception { return this.create ( user , password , kibanaenrollmentaction.name ) ; <nl> a simple http client for usage in command line tools . this client only uses internal jdk classes and does not rely on an external http libraries . <nl> timeout http ( s ) reads after 0 seconds . the default timeout for discovering a master is 30s , and we want to be longer than this , otherwise a querying a disconnected node will trigger as client side timeout rather than giving clear error details . <nl> general purpose http ( s ) call with json content-type and authorization header . ssl settings are read from the settings file , if any . <nl> if using ssl , need a custom service because it 's likely a self-signed certificate <nl> requires permission java.lang.runtimepermission ' setfactory ' ; <nl> add basic-auth header <nl> this throws ioexception if there is a network problem <nl> this ioexception is if the http response code is 'bad ' ( > = 0 ) <nl> we can not do custom name resolution here ... <nl> this sucks but a port can be specified with a value of 0 , we 'll never be able to connect to it so just default to what we know <nl> simple http response with status and response body as key value map .",method to be called by the startup process while elasticsearch is in the <nl> enrollment mode to obtain an <nl> enrollment token used to enroll a new node to the cluster or an enrollment <nl> token to configure kibana to communicate with a secured elasticsearch <nl> cluster .,1622493495,this commit adds a new geoshapeboundsaggregator to the spatial plugin and registers it with the geoshapevaluessourcetype . this enables geo_bounds aggregations on geo_shape fields,0.9728192090988159
apache_incubator-pinot/6538,"support date_trunc during ingestion <para-sep> helper methods and constructs for datetrunc function <nl> original comment from presto code <nl> copied from the presto timezonekey . it basically caches the joda chronologies corresponding to each of the timezones listed in the zone-index.properties the zone-index.properties is kept in sync with the presto zone index properties . <nl> load zone file todo parse file by hand since properties ignores duplicate entries <nl> normalize fixed offset time zones . <nl> in some zones systems , these will start with utc , gmt or ut . <nl> ( +/- ) 0:0 is utc <nl> if zoneid matches xxx : xx , it is likely +hh : mm , so just return it since only offset time zones will contain a character <nl> rewrite ( +/- ) h [ h ] to ( +/- ) hh:0 <nl> zone must start with a plus or minus sign <nl> flip sign for etc/gmt ( +/- ) h [ h ] <nl> extract the tens and ones characters for the hour <nl> do we have a valid hours offset time zone ? <nl> is this offset 0 ( e.g. , utc ) ? <nl> the sql compatible date_trunc function for epoch time . <nl> the sql compatible date_trunc function for epoch time . <nl> the sql compatible date_trunc function for epoch time . <nl> tests the arithmetic scalar transform functions <nl> tests the array scalar functions <nl> tests the pinot inbuilt transform functions <nl> round epoch millis to nearest 0 minutes <nl> round to 0 minutes , but keep in milliseconds : fri jan 0 0 0:0:0 becomes fri jan 0 0 0:0:0 <nl> toepochseconds ( with type conversion ) <nl> toepochseconds w/ rounding ( with type conversion ) <nl> toepochseconds w/ bucketing ( with underscore in function name ) <nl> toepochminutes <nl> toepochminutes w/ rounding <nl> toepochminutes w/ bucketing <nl> toepochhours <nl> toepochhours w/ rounding <nl> toepochhours w/ bucketing <nl> toepochdays <nl> toepochdays w/ rounding <nl> toepochdays w/ bucketing <nl> fromepochdays <nl> fromepochdays w/ bucketing <nl> fromepochhours <nl> fromepochhours w/ bucketing <nl> fromepochminutes <nl> fromepochminutes w/ bucketing <nl> fromepochseconds <nl> fromepochseconds w/ bucketing <nl> nested <nl> todatetime simple <nl> todatetime complex <nl> todatetime with timezone <nl> fromdatetime simple <nl> fromdatetime complex <nl> fromdatetime with timezone <nl> timezone_hour and timezone_minute <nl> convenience extraction functions <nl> sat may 0 0 0:0 : version utc <nl> sat may 0 0 0:0","date_trunc was only available during query time . adding it to scalar functions , so that it can be used during ingestion . <nl> all logic is simply moved from datetrunctransformfunction class to shared utils . no new logic has been introduced . <nl> also as part of this pr , split the inbuiltfunctionstest into test files of their own , per function group ( arithmetic , array , json , datetime ) , because that file was getting too long .",1612379055,"0. remove auxiliary email recipient from alertgrouper class . <nl> 0. add alertgrouprecipientprovider class , which provides the recipients depending on the given dimensions . <nl> tested with unit tests and local integration test ( i.e. , controller ) .",0.9689972996711731
confluentinc_ksql/6908,"select star table scans need keys in the intermediate row <cm-sep> fix test <para-sep> select * also requires keys , in case it 's not explicitly mentioned","with this change , we make sure to add keys if it 's a so that it 's now found for table scan .",1611797790,currently we require ksql server url to be specified when starting ksql cli . to keep the quick start and integration with confluent cli simple this pr will use as the default server url when the cli is called without any args . if there is args in starting the cli the server url should be specified .,0.7783510684967041
confluentinc_ksql/7366,"enable variable substitution for migrations tool <para-sep> given <nl> when <nl> then <nl> if validateonly is set to true , then this parses each of the commands but only executes define/undefine commands ( variables are needed for parsing insert into ... values , set/unset and define commands ) . if validateonly is set to false , then each command will execute after parsing . <nl> executes everything besides define/undefine commands <nl> checkstyle_rules.off : classdataabstractioncoupling checkstyle_rules.on : classdataabstractioncoupling <nl> splits the sql string into tokens ( uppercased keyowords , identifiers and strings ) <nl> determines if a statement is supported and the type of command it is based on a list of tokens . <nl> represents ksqldb define commands . <nl> represents ksqldb undefine commands . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","previously , the tool parsed each command , collected them and then executed them . because the variables are tracked in the java client , but set/unset/insert values do n't do variable substitution through the client , the flow was refactored to parse commands and then execute them one by one .",1618032521,"this allows us to make known backwards-compatible changes to ksql that would previously have caused an existing test to fail , e.g . changing the name of the internal topics . with this commit we can mark the old test as only valid up to the last version and create a new version of the test for , with a min version , to test versions going forward . <nl> e.g . <nl> 0. now accepts an optional . <nl> 0. , which is built from , now expects a <nl> 0. no longer takes the param , as it",0.9742271900177002
neo4j_neo4j/11910,"update io module test to junit 0. introduce common extensions . <nl> rewrite all , except parametrized tests , in junit 0 . <nl> introduce common test extensions . <nl> introduce inject annotation to inject test resources from custom extensions . <para-sep> another test that tries to squeeze out data race bugs . the idea is the following : we have a number of threads that are going to perform one of two operations on randomly chosen pages . the first operation is this : they are going to pin a random page , and then scan through it to find a record that is their own . a record has a thread-id and a counter , both 0-bit integers . if the record is not found , it will be added after all the other existing records on that page , if any . the last 0-bit word on a page is a sum of all the counters , and it will be updated . then it will verify that the sum matches the counters . the second operation is read-only , where only the verification is performed . the kicker is this : the threads will also keep track of which of their counters on what pages are at what value , by maintaining mirror counters in memory . the threads will continuously check if these stay in sync with the data on the page cache . if they go out of sync , then we have a data race bug where we either pin the wrong pages or somehow lose updates to the pages . this is somewhat similar to what the pagecachestresstest does . <nl> for debugging via the linear tracers : <nl> for debugging via linear tracers : <nl> similar to the test above , except the threads will have multiple page cursors opened at a time . <nl> it 's very important that even if all threads grab their maximum number of pages at the same time , there will still be free pages left in the cache . if we do n't keep this invariant , then there 's a chance that our test will run into live-locks , where a page fault will try to find a page to cooperatively evict , but all pages in cache are already taken . <nl> even if we block in pin , waiting to grab","rewrite all , except parametrized tests , in junit 0 . <nl> introduce common test extensions . <nl> introduce inject annotation to inject test resources from custom extensions .",1527780341,and also delete some unused test code .,0.9317064881324768
vespa-engine_vespa/18470,"add convenience function wrapping ' string.format ( locale.us , ... ) ' <cm-sep> string.format - > text.fmt",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> please take a look .,1624987512,"this moves serialization code from the public api package to own serializes package and replaces usage of guava with in . there is one usage in i could n't replace as that broke some test in that compared json as string , and i could n't even reproduce it locally .",0.8977345824241638
apache_flink/16242,fix upsert-kafka produce duplicates when enable object reuse,"fix upsert-kafka produce duplicates when enable object reuse . <nl> fix upsert-kafka produce duplicates when enable object reuse . <nl> - add tests in to verify the results if enable object reuse . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes /",1624363640,"currently , format only support deserialization , but not support serialization , which is not convenient for users to writing changelogs to an message queue . the serialization for could follow the json strcuture of debezium , but should consider currently flink ca n't combine and into a single message . this could encode and as and debezium messages . therefore , this could support serialization for format . <nl> - add which serialization schema from flink table/sql internal data structure to debezium json . <nl> - supports with creating encodingformat for . <nl> - add test cases for to",0.9358683824539185
confluentinc_ksql/7578,relax copartitioning requirement for fk joins <cm-sep> disallow fk joins on windowed tables in push queries,"two minor fixes in this pr : <nl> - do not require copartitioning for foreign key joins . <nl> - disallow foreign key joins on windowed tables , since it does n't make sense to extract a column/expression from the left source to match a windowed key from the right source . ksqldb does not support persistent queries on windowed tables so this is only relevant for push queries , so i 've added a corresponding rqtt . <nl> added tests . ( copartitioning tests will be enabled in a future pr . )",1621866063,this is to allow an upgrade to jackson version.x,0.8241687417030334
OpenAPITools_openapi-generator/8968,fix samples <cm-sep> build succcessful in android studio <cm-sep> fix deprecatation warnings <cm-sep> update dependencies <para-sep> body | pet * | pet object that needs to be added to the store | <nl> body | pet * | pet object that needs to be added to the store | <nl> body | order * | order placed for purchasing the pet | <nl> body | user * | created user object | <nl> body | list & lt ; user & gt ; * | list of user object | <nl> body | list & lt ; user & gt ; * | list of user object | <nl> body | user * | updated user object | <nl> the version of the openapi document : version the version of the openapi document : version the version of the openapi document : version the version of the openapi document : version the version of the openapi document : version <nl> verify the required parameter 'body ' is set,- update gradle wrapper to newer version <nl> - update dependencies to newer version <nl> - update samples <nl> - update build.gradle . <nl> tested locally with android studio .,1615711084,"when a parameter in with type is sent , the parameter name is hardcoded to but it should be set to the parameter name because it needs to be used in the mime header . as an example , if an api requires the following and the parameter name is set to in the spec , will still set to be hardcoded to . <nl> this issue is described in more detail here : . <nl> was select as the variable name to hold this info because it aligns with and the name is specifically associated with the file ,",0.8337823152542114
vespa-engine_vespa/18014,"remove duplicate option <cm-sep> add parameter for route , timeout and trace level <cm-sep> implement closeable for jsonstreamfeeder <cm-sep> improve and centralize validation of parameter combinations <cm-sep> add option for reading feed input from stdin <cm-sep> use jsonstreamfeeder to feed documents from cliclient <cm-sep> add verbose option <cm-sep> simplify using new methods on client builder <cm-sep> add benchmark mode to jsonstreamfeeder + cliclient wiring",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622126299,will do application in a separate pr .,0.983219563961029
apache_beam/13786,"add searchparameter class for fhirio.search <cm-sep> add fhirsearchparameter class as input for fhirio.search . <cm-sep> fixing up <para-sep> fhir search queries , represented by the fhirsearchparameter class . the outputs are results of each search , represented as a json array of fhir resources in string form , with pagination handled , and an optional input key . // search fhir resources using a simple query . map queries = new hashmap ( ) ; queries.put ( ' name ' , ' alice ' ) ; fhirsearchparameter searchparameter = fhirsearchparameter.of ( ' patient ' , queries ) ; pcollection > searchqueries = pipeline.apply ( create.of ( searchparameter ) .withcoder ( fhirsearchparametercoder.of ( stringutf8coder.of ( ) ) ) ) ; pcollection resources = searchresult.getresources ( ) ; // jsonarray of results // search fhir resources using an ' or ' query . map > listqueries = new hashmap ( ) ; listqueries.put ( ' name ' , arrays.aslist ( ' alice ' , ' bob ' ) ) ; fhirsearchparameter > listsearchparameter = fhirsearchparameter.of ( ' patient ' , ' alice-bob-search ' , listqueries ) ; pcollection > > listsearchqueries = pipeline.apply ( create.of ( listsearchparameter ) .withcoder ( fhirsearchparametercoder.of ( listcoder.of ( stringutf8coder.of ( ) ) ) ) ) ; fhirio.search.result listsearchresult = searchqueries.apply ( fhirio.searchresources ( options.getfhirstore ( ) ) ) ; pcollection > listresource = listsearchresult.getkeyedresources ( ) ; // kv <nl> gets resources with input searchparameter key . <nl> the key is used as a key for the search query , if there is source information to propagate through the pipeline . <nl> verify that none of the result resource sets are empty sets , using both getresources methods . <nl> verify that none of the result resource sets are empty sets , using both getresources methods .",create a fhirsearchparameter class to represent query information for fhirio.search,1611252098,"wire up the docker environmentfactory , and make the environment choice configurable . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .",0.9592316746711731
elastic_elasticsearch/73702,"since java 0 , the default value for illegal-access is deny . this means <nl> the latest release of elasticsearch , and all current integration tests , <nl> run with deny ( since we do n't explicitly set it in jvm options ) . yet <nl> tests run with illegal-access=warn , for legacy reasons . <nl> this commit explicitly sets tests to deny . this has the added benefit <nl> that any failures will be caught even when running tests with older <nl> jvms . <para-sep> todo : only open these for mockito when it is modularized","since java 0 , the default value for illegal-access is deny . this means <nl> the latest release of elasticsearch , and all current integration tests , <nl> run with deny ( since we do n't explicitly set it in jvm options ) . yet <nl> tests run with illegal-access=warn , for legacy reasons . <nl> this commit explicitly sets tests to deny . this has the added benefit <nl> that any failures will be caught even when running tests with older <nl> jvms .",1622675556,"the api name could cause issues in the client <nl> libs because is a reserved word in many languages . rename the <nl> api to avoid this , and rename the other apis for consistency .",0.7901343703269958
apache_pulsar/10716,support using autoproducebytesschema as the function output schema <para-sep> merge various schemas data to a topic . <nl> pojo for test multi-version schema . <nl> nothing to do,"currently , in function , we could n't use the as the output schema . <nl> support users use the as the value of configuration in function . such as . <nl> add a new integration test . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( yes ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no",1622046069,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( yes ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) . <nl> (",0.9795492887496948
ballerina-platform_ballerina-lang/30312,"add toml syntax tree modifier tests <cm-sep> add validations to the dependencies.toml . <para-sep> if name , org or version , one of the value is null , ignore dependency <nl> ignore exception and dependency diagnostic will be added by toml schema validator for the semver version error <nl> test dependenciestoml . <nl> invalid dependencies.toml file with dependencies missing org . [ ] name = ' foo1 ' version = ' version ' <nl> invalid dependencies.toml file with dependencies missing org value . [ ] org = name = ' foo1 ' version = ' version ' <nl> invalid dependencies.toml file with invalid org , name and version . [ ] org = ' ' name = ' ' version = ' 0 '","if validations fail for some dependency added to the file , diagnostic will be added and dependency will be ignored .",1620051974,are not getting rendered in the diagram atm . this is to fix it .,0.9749733805656433
apache_pulsar/10125,"inital commit <cm-sep> removed unused imports <para-sep> start local bookkeeper ensemble <nl> populate builtin connectors folder <nl> update cluster metadata <nl> setting up simple web server to test submitting function via url <nl> hacky parsing of prometheus text format . sould be good enough for unit tests <nl> example of lines are jvm_threads_current { cluster= ' standalone ' , } version or pulsar_subscriptions_count { cluster= ' standalone ' , namespace= ' sample/standalone/ns1 ' , topic= ' persistent : //sample/standalone/ns1/ ' } version 0 <nl> 0 setup producer <nl> 0 send messages and record the expected values after compaction <nl> duplicate keys will exist , the value of the new key will be retained <nl> 0 trigger compaction <nl> 0 setup sink <nl> 0 sink should only read compacted value，so we will only receive compacted messages <nl> 0 create producer、dlq consumer <nl> 0 setup sink <nl> 0 send message <nl> 0 all messages should enter dlq <nl> clean up <nl> create a producer that creates a topic at broker <nl> validate prometheus metrics empty <nl> get stats after producing <nl> delete functions <nl> make sure subscriptions are cleanup <nl> test pulsar source","refactor the existing pulsar function unit tests in order to improve maintainability and extension . <nl> broke the existing org.apache.pulsar.io.pulsarfunctione2etest class into smaller , more focused test classes . one for functions , one for sources , one for sinks , and one for batchsources . <nl> this change added tests and can be verified as follows : . <nl> - * added , , and . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api : no <nl> -",1617315662,the and are used for schema auto detection . currently it only supports avro . <nl> this pr is to support json . <nl> introduce generic schema and generic record for json schema .,0.9619728922843933
apache_pulsar/10573,support produce multiple schema by autoproducebytesschema,"currently , the schemahash only uses the schema data to distinguish different schemas , it 's not enough due to the primitive schemas all have empty schema data , and the json , avro schema will maintain the same schema data if they based on the same pojo . <nl> add a new field in schemahash . <nl> add a new unit test to produce multiple schemas messages by autoproducebytesschema in always_compatible mode . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no )",1620900784,handle heartbeat function if owner-worker is not available . <nl> function scheduling handles heartbeat function if owner-worker is not available .,0.8968111276626587
apache_shardingsphere/10848,optimize select group by having with calcite,changes proposed in this pull request : <nl> - optimize select group by having with calcite <nl> - delete and corresponding logic <nl> - fix queryresults loss when execute in,1623931611,"- add literal sql in xml driver file <nl> - remove sqlcaseid and sqlcaseloader <nl> - decouple with databasetypeenvironment , only init available database case . <nl> after refactor , integrate-test-case look like this .",0.9637594819068909
OpenAPITools_openapi-generator/8962,adds gethasrequiredvars + sethasrequiredvars to ijsonschemavalidationproperties <cm-sep> changes to gethasrequired and sethasrequired and implements in codegenmodel <cm-sep> updates codegenproperty <cm-sep> updates codegenparameter <cm-sep> updates codegenresponse <cm-sep> uses sethasrequired in model/prop/parameter/response <cm-sep> adds issue spec 0 <cm-sep> adds testhasrequiredinmodel <cm-sep> adds testhasrequiredinproperties <para-sep> all variables must be in the above sets <nl> all variables must be in the above sets <nl> all variables must be in the above sets,this is needed if one is generating classes for object schemas and one only wants to generate the class if required exists . <nl> one could almost do this with # requiredvars but that does n't work because using # requiredvars mean we move into the context of iterating over each var when we just need to know if there are required vars . <nl> hasrequired is tested in the below models : <nl> - codegenmodel <nl> - codegenproperty <nl> - codegenparameter <nl> - codegenresponse .,1615572540,"( details of the change , additional tests that have been done , reference to the issue for tracking , etc ) . <nl> the problem : <nl> api generation for c # , java and ruby creates a class based on the tag and then adds ' api ' after it . <nl> ideally though we have a class like ' study ' or ' study { { suffix } } ' not ' studyapi ' . <nl> i introduced a apinamesuffix parameter in order to add suffixes to the generated api class/file/document names . added the option '",0.9053916335105896
elastic_elasticsearch/72672,only wait for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade . <para-sep> cluster health does not wait for active shards per default <nl> explicitly wait for the primary shard ( although this might be default ),with this change transform only waits for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade .,1620122666,this commit updates the node stats version constants to reflect the fact <nl> that index pressure stats were backported to version . it also reenables bwc <nl> tests .,1.0
OpenAPITools_openapi-generator/8935,"add additional reserved words list for parameter name in powershell . <cm-sep> add missing check for parameter name starting with number . <para-sep> special variables <nl> sanitize and camelize parameter name pet_id = > petid <nl> for param name reserved word or word starting with number , append _","an additional reserved words list is added for parameter name in powershell . the initial reserved words list contains all reserved words provided by powershell . however for the parameter name , only the variables extracted in the new list ca n't be passed as names of a powershell advanced function parameter . with the additional reserved words list , keywords like filter do n't receive the additional prefix var when they 're parameter names .",1615302207,"adds an extra suffix to string returned by and if the suffix is resulting in a model or api file that ends in which is ignored by the go compiler . <nl> was rebuilt from scratch by , aside from which is useful . may be worthwhile to have that auto-added along with .",0.8945132493972778
crate_crate/11063,"fix max aggregation of version values . <nl> both and are positive numbers , not <nl> negative so is false . 🤦 . <nl> ( cherry picked from commit sha ) <cm-sep> ensure min/max values in max aggregation do n't result in results . <nl> ( cherry picked from commit sha )",mergify commands and options . <nl> you can also trigger mergify actions by commenting on this pull request : . <nl> - will re-evaluate the rules <nl> - will rebase this pr on its base branch <nl> - will merge the base branch into this pr <nl> - will backport this pr on branch . <nl> - look at your merge queues <nl> - generate the mergify configuration with the config editor .,1614162847,this reverts the initial fix which also changed the behavior to fully <nl> unnest multi dimensional arrays . <nl> that can break use cases and should n't be <nl> done as part of a hotfix . <nl> it instead fixes the return type to avoid a later <nl> on .,0.8382866382598877
OpenAPITools_openapi-generator/8462,"adds isnull to all schema classes <cm-sep> adds null model and property samples , adds models test of isnull <cm-sep> adds isnull tests for parameter and response also",adds isnull to codegenmodel codegenparameter codegenproperty codegenresponse <nl> this is different than nullable : true <nl> isnull should be set to true for schemas of type null like : .,1610903205,i want to embed annotation when in kotlin-spring .,0.9517644047737122
eclipse-openj9_openj9/11914,"change to use reflection.getclassaccessflags in mhs.checkclassaccess . <nl> using class.getmodifiers ( ) for an innerclass will return the source code <nl> level modifiers from the innerclass attribute , which may be different <nl> from the runtime class header . <nl> change to use reflection.getclassaccessflags will ensure the actual <nl> jvm romclass modifiers are used for access checks . <cm-sep> use .getmodifiers for arrayclass and primitiveclass . <nl> remove isprotected check on class modifiers . <para-sep> use reflection.getclassaccessflags to get the actual rom class modifiers instead of the attribute flags for innerclasses","using class.getmodifiers ( ) for an innerclass will return the source code <nl> level modifiers from the innerclass attribute , which may be different <nl> from the runtime class header . <nl> change to use reflection.getclassaccessflags will ensure the actual <nl> jvm romclass modifiers are used for access checks . <nl> use .getmodifiers for arrayclass and primitiveclass <nl> remove isprotected check on class modifiers .",1612817094,was a hack to enable the modifiers field to be <nl> final for jit purposes . it 's better to just do the isstatic <nl> check in the constructor once rather than making it part of the <nl> invoke/invokeexact sequence .,0.9013301730155945
apache_incubator-pinot/6385,cleanup tar.gz post upload complete . <para-sep> should clean up output segment on job completion .,"testing : <nl> verified the segment deletion by running pinot locally for jobtype and . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1608886109,* do n't purge segment unless there are records to be purged or modified,0.9079502820968628
ballerina-platform_ballerina-lang/27414,add a few readonly/isolated tests for classes with other qualifiers <cm-sep> add a negative isolated test for isolated service object inclusion <cm-sep> disallow non-readonly service access in isolated functions <para-sep> isolatedserviceobjecttype ;,a service reference can now be used within an function ( if the service is outside the function ) only if it refers to a variable and its type is a subtype of .,1607508543,"fix basic tuple , var ignore , byte value , float value , json value tests",0.8407377004623413
Alluxio_alluxio/12869,"add cost saving tables <cm-sep> add cost saving from saved metadata operations <para-sep> this class contains utilities to compute cloud cost savings . <nl> cost map is a map between ufs operations and their associated cost in dollars per operation . if it is a tiered storage solution , the top tier pricing is used . <nl> a map mapping getunderfstype to the cost map <nl> calculate the saved cost from the perufs operations saved map . <nl> intentionally left blank","this pr will export cost saving due to saved metadata operation per ufs , calculated from cloud vendor 's cost sheet .",1613602341,"now the cli and doctor cli will not show optional <nl> $ /bin/alluxio fsadmin doctor configuration <nl> server-side configuration errors ( those properties are required to be identical ) : <nl> key : key1 <nl> value : hdfs : //name2 : port2 ( masterhostname3 : masterport , masterhostname4 : masterport ) <nl> value : hdfs : //name1 : port1 ( masterhostname1 : masterport , masterhostname2 : masterport ) <nl> key : key2 <nl> value : errorvalue2 ( masterhostname1 : masterport , masterhostname3 : masterport ) <nl> value : errorvalue1 ( masterhostname4 : masterport , masterhostname2 : masterport ) . <nl>",0.9401213526725769
apache_pulsar/10642,transaction admin api get transaction coordinator status . <cm-sep> transaction admin api get transaction in buffer status . <cm-sep> fix some test <para-sep> get transaction in buffer stats .,"this is transaction buffer metrics . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment",1621436563,- add policy for namespace <nl> - add policy for namespace <nl> - add test case <nl> - update admin cli docs,0.9763597846031189
apache_druid/11019,"fix auto-compaction with segment granularity retrieve incomplete segments from timeline when interval overlap <cm-sep> fix auto-compaction with segment granularity retrieve incomplete segments from timeline when interval overlap <cm-sep> fix auto-compaction with segment granularity retrieve incomplete segments from timeline when interval overlap <para-sep> 0 segments across 0 days ( 0 total ) ... <nl> we wil have one segment with interval of 0-0-0/0-0-0 ( compacted with year ) <nl> 0 segments . 0 compacted year segment and 0 newly ingested day segments across 0 days we wil have one segment with interval of 0-0-0/0-0-0 ( compacted with year ) from the compaction earlier two segments with interval of 0-0-0/0-0-0 ( newly ingested with day ) and two segments with interval of 0-0-0/0-0-0 ( newly ingested with day ) <nl> this will submit a single compaction task for interval of 0-0-0/0-0-0 with month granularity <nl> we wil have one segment with interval of 0-0-0/0-0-0 ( compacted with year ) from before the compaction <nl> one segments with interval of 0-0-0/0-0-0 ( compacted with month ) and one segments with interval of 0-0-0/0-0-0 ( compacted with month ) <nl> partitionholder can only holds chunks of one partition space however , partition in the new timeline ( timelinewithconfiguredsegmentgranularity ) can be hold multiple partitions of the original timeline ( when the new segmentgranularity is larger than the original segmentgranularity ) . hence , we group all the segments of the original timeline into intervals bucket by the new configuredsegmentgranularity . we then convert each segment into a new partition space so that there is no duplicate partitionnum across all segments of each new interval . similarly , segment versions may be mixed in the same time chunk based on new segment granularity hence we create the new timeline with a temporary version , setting the fake version to all be the same for the same new time bucket . we need to save and store the originaltimeline so that we can use it to get the original shardspec and original version back ( when converting the segment back to return from this iterator ) . <nl> originaltimeline can be nullable if timeline was not modified <nl> we should get all segments in timeline back since skip offset is p0d . although the first iteration only covers the last hour of 0-0-0 ( 0-0-01t23:0:0/0-0-02t00:0:0 ) , the iterator will returns all segment as the umbrella","auto-compaction with segment granularity retrieve incomplete segments from timeline when interval overlap . <nl> auto-compaction with segment granularity retrieve incomplete segments from timeline when interval overlap . <nl> for example , if we have segments of year granularity from 0-0-0 to 0-0-0 and a segment of day granularity from 0-0-0 to 0-0-0. let 's then say that we set auto compaction with a segmentgranularity of month . auto-compaction will bucket all the existing segments into the new bucket using the configured segmentgranularity ( month in this example ) . when we iterate for segments to compact we will start at",1616299959,"the method is supposed to find all tasklockposses overlapping the given interval . it currently finds like below : . <nl> here , it 's calling to find the first entry to start searching . however , is a which is initialized with . as a result , if there 're two or more intervals of the same start but different end , returns the interval of the greatest end . <nl> if this error happens , the overlord prints or in its log . <nl> to fix this bug , i changed map to i also added some codes",0.950508177280426
apache_druid/11063,"enforce allow list for jdbc properties by default <para-sep> this config is for compatibility as enforcing allow list can break existing ingestion jobs or lookups . however , from the security point of view , this config should be always enabled in production to secure your cluster . as a result , this config is deprecated and will be removed in a future release .","this pr changes the default to enforce the allow list for jdbc connection properties . still remains as true by default because , at least the known security vulnerability can be exploitable only with mysql which druid will always enforce the allow list once it 's enabled regardless of",1617326447,"use case - <nl> in active directory environment , spnego token in the authorization header includes pac ( privilege access certificate ) information , which includes all security groups the user belongs to which in this case is the header to grow beyond 0 kb what druid can handle by default . <nl> changes - <nl> this patch adds new configuration and allows user to configure the max header size for druid jetty server . default value is 0 kb which is same as jetty default .",0.8294205069541931
ballerina-platform_ballerina-lang/27811,add support for type inclusion <para-sep> check if the inclusion function is overridden,> fixes a bug where errors are categorized as types .,1610442557,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9313039183616638
Graylog2_graylog2-server/10092,"creating integration test for . <cm-sep> correcting json path , adding safeguard if not present .","note : this pr should be backported to . <nl> prior to this change , the implementation for es7 was using the same json path as in es6 , although the structure of the response has changed . this , in combination with an overly relaxed parsing of the response lead to the method always returning 0 . <nl> the consequence of this is that any configured count-based rotation policy was never triggered , due to the threshold never being crossed . <nl> this pr is adding a test for the method , fixes the json path and makes sure",1613656613,this pr makes some improvements around how we handle the field type refresh interval for index sets : .,0.8983770608901978
ballerina-platform_ballerina-lang/27064,"rename packageloadrequest and response to resolutionrequest and response <cm-sep> add two more constructors to create from org , pkgname and version <cm-sep> remove confusing packagedesc constructor that uses string param types <cm-sep> refactor defaultpackageresolver to become a environment specific resolver . <nl> earlier it was used to be project environment specific . now it has become a sort of global resolver <nl> with this change , i 've removed the old langlib resolver as well <cm-sep> move ballerina dist repo impl to the internal/repository package <cm-sep> update packagedependency to include the scope <cm-sep> add an alogorithm to compare two semanticversions <cm-sep> add test cases to validate semantic version comparision logic <cm-sep> update the usages of resolutionresponse to use the scope property <cm-sep> add test cases to validate version conflict resolution logic <cm-sep> add ballerina-lang tests related to the project api <cm-sep> improve the package resolution logic to include test dependencies <cm-sep> add tests to verify packge resolution algorithem <para-sep> we do n't add the test dependencies to the balr file . <nl> represents the scope of the dependency . at the moment a package dependency can be a dependency for src and tests or tests only . <nl> these dependencies are available for both source and test sources . <nl> these dependencies are only available for test sources . <nl> if the requested module belongs to this package , continue . we do n't have to check whether this module exists , an error will be logged later in symbolenter . <nl> we do n't log errors for unresolved direct dependencies <nl> represents a dependency of a package which already resolved from a repository . <nl> versions can not be equal from this point onwards <nl> we 've eliminated initial versions now . <nl> defines the interface that will be used by the resolution logic to resolve packages from available repositories . <nl> todo we can use this call to send diagnostics if any <nl> package resolution is successful . <nl> failed to resolve the specified package . <nl> this class is responsible for creating the package dependency graph with no version conflicts . version conflict resolution logic is built into this graph build process . <nl> todo pass the diagnostic collector with the constructor . <nl> add the correct version of the dependent to the graph . <nl> add the correct version of the dependency to the graph .","with these changes , we can now persist dependencies in file .",1606099657,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9805302023887634
elastic_elasticsearch/73135,service accounts - add token source to metadata . <nl> service token of the same name can come from either a file or the <nl> security index . add the token source information to the authentication <nl> metadata to differentiate between them . this information is also <nl> serialised under token.type in the rest response back to users .,service token of the same name can come from either a file or the <nl> security index . add the token source information to the authentication <nl> metadata to differentiate between them . this information is also <nl> serialised under token.type in the rest response back to users .,1621232670,"this change was mainly triggered by the need for to pass during its constructor when creating . also , is carried around in some places where only a subset of it is needed . <nl> with this change we rather carry around the components that are strictly needed , in a couple of cases functions that provides , which helps clarifying the dependency between , and , as well as removing the need for mapperservice to pass to . <nl> some more details about the choices made : . <nl> - avoid carrying documentmapperparser around ( and expose it through",0.9626693725585938
OpenAPITools_openapi-generator/9426,"introduce fileparameter as an abstraction <cm-sep> update samples <para-sep> / / represents a file passed to the api as a parameter , allows using different backends for files / <nl> / / the filename / <nl> / / the content of the file / <nl> / / construct a fileparameter just from the contents , will extract the filename from a filestream / / the file content <nl> / / construct a fileparameter from name and content / / the filename / the file content <nl> / / implicit conversion of stream to file parameter . useful for backwards compatibility . / / stream to convert / fileparameter <nl> / / a container for generalized request inputs . this type allows consumers to extend the request functionality / by abstracting away from the default ( built-in ) request framework ( e.g . restsharp ) . / <nl> / / parameters to be bound to path parts of the request 's url / <nl> / / query parameters to be applied to the request . / keys may have 0 or more values associated . / <nl> / / header parameters to be applied to to the request . / keys may have 0 or more values associated . / <nl> / / form parameters to be sent along with the request . / <nl> / / file parameters to be sent along with the request . / <nl> / / cookies to be sent along with the request . / <nl> / / any data associated with a request body . / <nl> / / constructs a new instance of / <nl> binary | fileparameterfileparameter| none | binary | fileparameter * * | | <nl> file | fileparameter * fileparameter| file to upload | <nl> requiredfile | fileparameter * fileparameter| file to upload | <nl> openapi petstore this spec is mainly for testing petstore server and contains fake endpoints , models . please do not use this for any other purpose . <nl> / / represents a file passed to the api as a parameter , allows using different backends for files / <nl> / / the filename / <nl> / / the content of the file / <nl> / / construct a fileparameter just from the contents , will extract the filename from a filestream / / the file content <nl> / / construct a fileparameter from name and","this introduces a new class fileparameter as an abstraction to use in our apiclients . it contains an automatic implicit conversion for existing stream parameters so its backwards compatible to existing code . <nl> the reason for this is , that there are platforms that have file like parameters and we currently have no way to pass a filename into our api clients aside from filestreams . however for browser platforms there are no filestreams there are ibrowserfiles that do not map . so we need another abstraction . <nl> this could be further expanded to add content types to",1620391141,visionmedia/superagent version is vulnerable to zip bomb attacks . <nl> refs : nvd - 0 . <nl> it has been fixed in v3.version . <nl> > - limit maximum response size . prevents zip bombs ( kornel ),0.9099327325820923
confluentinc_ksql/7304,only list known connect worker properties when listing server props <para-sep> only list known connect worker properties to avoid showing potentially sensitive data in other configs <nl> given : <nl> when : <nl> then :,"when ksqldb runs with embedded connect via the config , if a user lists server properties with , the entire contents of the connect worker config file is displayed in the output , including any potentially sensitive configs . this is in contrast to sensitive ksqldb or streams configs which are properly sanitized ( displayed as ) in the properties listing output , including any/all udf-specific configs . this pr fixes the issue for the connect worker configs by only displaying known connect worker properties ( as specified by ) as we know these are safe to display . <nl>",1616772528,"the stream name and column names provided to the endpoint are both currently case-sensitive , meaning an attempted insert into a stream with name will fail if the stream actually has name in the metastore ( e.g. , if the stream were created with ) . the same holds for column names as well . this pr updates the endpoint to be case-insensitive by default , in order to be consistent with the rest of ksqldb . <nl> breaking change : stream name and column names provided to the endpoint are no longer case-sensitive . instead , they will be",0.9656139612197876
apache_shardingsphere/10414,optimize mysql create & alter and drop table route logic <para-sep> judge logic table is belong to sharding tables .,changes proposed in this pull request : <nl> - optimize mysql create & alter and drop table route logic,1621577288,"fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - refactoring : put antlrparsingengine into sqlparserfactory , and modify statement checking order . <nl> - add antlr postgresql dal parser .",0.9500551223754883
jenkinsci_jenkins/5105,"make fieldutils behave as it used to <para-sep> acgegi would silently fail to write to final fields fieldutils.writefield ( object , field , true ) only sets accessible on non public fields and then fails with illegalaccessexception ( even if you make the field accessible in the interim ! for backwards compatability we need to use a few steps","acegi fieldutils used to silently fail when you tried to set a field that was both and . <nl> whilst it seems silly to do that ( the code was obviously a no-op ) i observed a breakage in a plugin ( test code ) that was doing exactly that . seems like there is a possibility that some production code may exist that also was doing this that would now be broken , so make the code also silently fail for that case . <nl> * now silently fails to set fields again",1607537129,"however , in jenkins ' constructor , the call to jenkins # executereactor , which will execute the 'loading bundled plugins ' task that calls , happens a few lines before the call to installutil # proceedtonext , which will update to upgrade if it detects that an upgraded occurred , so the upgrade branch is never taken in . <nl> this pr instead checks the version numbers of the last running version and this version to decide if an upgrade occurred . <nl> * make sure detached plugins ( plugins which used to be part of jenkins itself )",0.9408661127090454
Alluxio_alluxio/13098,add blockworkerdatawriter <cm-sep> add workerblockwriter <para-sep> a data writer that issues from a client embedded in a worker to write data to the worker directly via internal communication channel . <nl> allocate enough space in the existing temporary block for the write . <nl> represents one session in the worker daemon .,extract the worker block write logics from grpc to . <nl> is shared by grpc and internal client .,1616105839,"a few caveats for this pr : <nl> - it turns out the major complexity of this pr is to figure out where to apply umask logic . after a few iterations , i finally put the umask logic into the method in class . the reason behind is that umask only matters for newly created files/directories , and is the critical path for those operations . <nl> - like linux , new files created in alluxio have default permission bits 0 and directories have 0. this is achieved by two different applyumask functions , one for file and one",0.9733797311782837
quarkusio_quarkus/16655,add configuration property to skip the elasticsearch version check . <nl> ... and thus allow starting hibernate search while the elasticsearch <nl> cluster is offline . <cm-sep> remove an unused constant <cm-sep> improve documentation of quarkus.hibernate-search-orm.schema-management.strategy <cm-sep> fix the level of headings in hibernate search documentation <cm-sep> document offline startup <para-sep> disable elasticsearch version checks on startup by setting the configuration property <nl> disable schema management on startup by setting the configuration property <nl> test that an application can be configured to start successfully even if the elasticsearch cluster is offline when the application starts .,"the configuration property has been around for quite some time , but we were n't exposing it in quarkus . <nl> i also took this opportunity to improve the documentation of .",1618922207,just testing that request scope is active for tests .,0.9526593685150146
keycloak_keycloak/7316,"correct ' does n't exists ' typos <para-sep> 0 ) the deployment has a keycloak.config.resolver and is n't valid ( does n't exist , is n't a resolver , ... ) : 0 ) the deployment has a keycloak.config.resolver and is n't valid ( does n't exist , is n't a resolver , ... ) : 0 ) the deployment has a keycloak.config.resolver and is n't valid ( does n't exist , is n't a resolver , ... ) : 0 ) the deployment has a keycloak.config.resolver and is n't valid ( does n't exist , is n't a resolver , ... ) : possibly remove keycloak groups , which do n't exist in ldap possibly remove keycloak groups , which do n't exist in ldap remove keycloak groups , which do n't exist in ldap <nl> map to track all ldap groups also exist in keycloak for the predecessor . result is the highest group , which does n't yet exist in ldap ( and hence requires sync to ldap ) parent does n't exist in ldap . let 's recursively go up . group mapping exists in ldap . for ldap_only mode , we can just delete it in ldap . for read_only we ca n't delete it - > throw error <nl> fallback to real username of the user just if attemptedusername does n't exist try to lookup current authsessionid from browser cookie . if does n't exist , use the same as current usersession this will remove usersession ' locally ' if it does n't exist on remotecache <nl> throw error if flow does n't exist to ensure we did not accidentally use different alias of non-existing flow when <nl> not possible to test file crl on undertow at this moment - jboss config dir does n't exist not possible to test file crl on undertow at this moment - jboss config dir does n't exist not possible to test file crl on undertow at this moment - jboss config dir does n't exist",trivial patch to correct a bunch of typos in source comments and debug output,1596276247,alternative way of exposing within . <nl> i 've also tacked on exposing of to allow overriding . _that_ was the main reason why i went through the effort of exposing in the first place ...,0.7602729797363281
jenkinsci_jenkins/5452,remove http response headers for the remoting-based cli,"i think these headers are unused now ; i could n't find a reference here or in remoting at least . <nl> is still advertised as , the port as . <nl> * stop sending http response headers related to the remoting-based cli ( removed in version )",1619717408,"plugins that may affect the view , eg via transientviewactionfactory <nl> that get installed _after_ a has been initally viewed <nl> will not be able to add anything to the view if the results <nl> of getactions ( ) are cached . <nl> * entry 0 : removed caching in views - plugins that affected the view , but are installed _after_ the initial rendering/viewing of the will not be called again and do not contribute to the . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8868029713630676
apache_flink/16079,bufferprovider is able to provide pure memorysegment in order to avoid extracting it from the bufferbuilder . <nl> ( cherry picked from commit sha ) <cm-sep> buffer is used inside of bufferbuilder for references counting . <nl> ( cherry picked from commit sha ) <cm-sep> recoveredchannelstatehandler requires the ownership of the input buffer . <nl> ( cherry picked from commit sha ) <cm-sep> clarification ownerships of the buffer for remote inputchannel # onbuffer in javadoc . <nl> ( cherry picked from commit sha ) <para-sep> handles the input buffer . this method is taking over the ownership of the buffer and is fully responsible for cleaning it up both on the happy path and in case of an error .,"this change added tests and can be verified as follows : . <nl> - added tests for bufferbuilder , inputchannelrecoveredstatehandler , resultsubpartitionrecoveredstatehandler . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that",1622808482,"fix computed column with escaped keyword can not work . <nl> fix a bug that computed column and escaped keyword can not work together . <nl> - add escape to field name in computed column . <nl> - add java doc to to remind others . <nl> this change is already covered by existing tests , such as ( please describe tests ) . <nl> - catalogtableitcase . testcomputedcolumnwithescapedkeywordfield ( ) . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any",0.8676971197128296
apache_incubator-pinot/6469,update segmentgenerationandpushtaskgenerator to set schemauri and tableconfiguri by default,segmentgenerationandpushtaskexecutor will fetch schema/tableconfig following the below priority . <nl> 0. used the schema/tableconfig set in the task config if there is any . <nl> 0. used the schemauri/tableconfiguri set in the task config to fetch the schema/tableconfig if there is any . <nl> 0. directly fetch the schema/tableconfig from the same cluster .,1611187839,"for datasets with epoch timestamps , the real dataset granularity and time unit granularity is usually different . by default , te onboard it as a five-minute granularity metric . this can be configured in dataset configs .",0.9536658525466919
neo4j_neo4j/11899,"move helper functions to runtime-util <cm-sep> port interpreted functions to call into static helper <cm-sep> port math functions to call into static helper <para-sep> this class contains static helper boolean methods used by the compiled expressions <nl> this class contains static helper methods for expressions interacting with the database <nl> data access <nl> this class contains static helper methods for the set of cypher functions <nl> this class contains static helper math methods used by the compiled expressions <nl> todo this is horrible spaghetti code , we should push most of this down to anyvalue <nl> list addition arrays are same as lists when it comes to addition <nl> string addition <nl> unfortunately string concatenation is not defined for temporal and spatial types , so we need to exclude them <nl> unfortunately string concatenation is not defined for temporal and spatial types , so we need to exclude them <nl> temporal values <nl> numbers <nl> temporal values <nl> temporal values","we recently introduced static helpers used by compiled expressions , we should also use these from the interpreted runtime in order to minimize code duplication . <nl> - move helpers to <nl> - port functions and math operations",1527714568,this is based on demands from product management to have more consistent naming of settings <nl> - change the security setting names to have a more consistent differentiation <nl> between authentication and authorization settings . <nl> - change the internal setting variable names to be more consistent with <nl> the real setting names . <nl> changelog : changed security setting names to have more consistent differentiation between authentication and authorization settings,0.7636866569519043
elastic_elasticsearch/73770,this commit adds a simple check that prevents to delete <nl> a repository that is required by an existing searchable <nl> snapshot index within the same cluster . <cm-sep> adjust version <para-sep> closes the given repository .,this commit adds a simple check that prevents to delete <nl> a repository that is required by an existing searchable <nl> snapshot index within the same cluster .,1622811897,this change revises an approach that generates an id using the ids of the <nl> segments of an index commit .,0.9784323573112488
apache_pulsar/10862,"added metadata cache test to simulate multi broker cache <cm-sep> fix create and delete ops on cache . <nl> 0. during create we should add a watch for the path in zookeeper . without this <nl> we will not be notified if the znode is changed on another brokers . <nl> 0. similarly when deleting , the cache should be invalidated . but we should n't add an <nl> entry to the cache . this could get added again on some other broker . in that <nl> case we need to go a fetch the entry from the zookeeper . adding an empty <nl> entry to the cache prevents that . <para-sep> in addition to caching the value , we need to add a watch on the path , so when/if it changes on any other node , we are notified and we can update the cache <nl> add on one cache and remove from another <nl> retry same order to rule out any stale state <nl> reverse the operations <nl> ensure that working on same cache continues to work . <nl> all time for changes to propagate to other caches <nl> all time for changes to propagate to other caches <nl> the entry should get removed from all caches","when doing operations on multiple brokers , the state is not always consistent . sometimes the operations do n't seem to get replicated to other brokers in the cluster . the queries from the brokers returns different results . <nl> 0. while creating a new object , we add the object to cache . however we are not adding a watch on the corresponding path in zookeeper . so when other brokers change/delete the object , the broker that added the object is not notified . with this change we will do a get ( ) , which will add",1623123468,"however , if proxy is also not in local n/w then it would also require to support hostname verification when it connects with broker . <nl> add option at proxy which forces proxy to do hostname verification when it connects to broker . <nl> proxy can support hostname verification when it connects to broker . <nl> after your change , what will change .",0.9472718834877014
grpc_grpc-java/7769,handle dns resolution refresh from downstream lb policies in cluster_resolver lb policy . <cm-sep> add ignore_reresolution field to prioritylb policy config 's per-priority config . <cm-sep> bypass reresolution requests from downstream lb policies if its config specifies so . <cm-sep> put ignore_reresolution=true for eds cluter 's priority config and ignore_reresolution=false for dns cluster 's . <cm-sep> fix prioritylbconfig usage in eds lb policy accordingly . <para-sep> wires re-resolution requests from downstream lb policies with dns resolver . <nl> config ( include load balancing policy/config ) for each priority in the cluster . <nl> generates the config to be used in the priority lb policy for a single priority . <nl> generates configs to be used in the priority lb policy for priorities in the cluster . <nl> config for each priority . <nl> load balancer for priority policy . a priority represents a logical entity within a cluster for load balancing purposes . list of priority names in order . config for each priority . <nl> simulate fallback to priority p1 .,"has the api that provides a way for lbs to send re-resolution requests to the ( dns ) resolver ( for async streaming resolvers like xds , refreshing is undefined ) . <nl> in , it supports resolving endpoint resources with a dns resolver . therefore , its refresh ( ) should be wired up correctly for its downstream lbs ( although currently none of them , including and will send re-resolution requests ) . <nl> in the context of aggregate cluster , is the aggregated place for discovering endpoints for multiple underlying clusters . endpoint load balancing for different",1609284694,"is appropriate for plumbing optional objects , especially useful for a long plumbing path where components in the middle may not care or see all objects in the container . it 's not the case for the on . both the default port and the proxy detector are guaranteed to be there and the plumbing path is very short . in this case , a first-class object is more appropriate and easier to use . <nl> we we also considering merging into the , to make match the api .",0.9679874777793884
trinodb_trino/8022,supports authentication using multiple ldap.user-bind-pattern value,"trino ldap authentication documents are described as shown below . <nl> > > the property can contain multiple patterns separated by a colon . each pattern will be checked in order until a login succeeds or all logins fail . <nl> but multiple ldap.user-bind-pattern values do not work as intended . <nl> only the first user-bind-pattern value tries to authenticate . <nl> to work properly , add additional accessdeniedexception and handle exceptions .",1621607383,"the new order is more reasonable . <nl> the method was added after last release , so it is a safe change to do <nl> now .",0.8142414689064026
apache_flink/15448,increased ttl for download cache entries <cm-sep> revert ' temporarily disable sqlclienthbaseitcase ' . <nl> this reverts commit sha .,i increased the timeout for download cache entries and reenabled test .,1617176578,"this pr is to bump up flink-shaded dependencies version to version , since the flink-shaded project has release version . <nl> - bump up flink-shaded dependencies version to version . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the",0.7776105403900146
apache_shardingsphere/10998,submit [ custom authority，schema can be assigned to proxy users ] to <nl> master <para-sep> build privileges . <nl> convert schemas . <nl> merge user schema to result .,authority enhance，sample： . <nl> when using root login from any host，you can use database test . <nl> when using user1 login from version，you can use database db_dal_admin . <nl> when using user1 login from any other host，you can use database test and db_dal_admin .,1624538801,"changes proposed in this pull request : <nl> - support sctl explain command , facilitate the users to locate problem",0.9749485850334167
apache_incubator-pinot/7061,change controller api to allow use specify column filter when query segment metadata,"this pr : <nl> * change controller api to allow use specify column filter when query segment metadata <nl> * fix a bug on controller api : we should url encode segment names <nl> * fix a bug on : we should put the full path of url as key to instead of ( which is a triple of scheme , host , port ) . otherwise , if we send multiple requests to the same server , will return as long as one of the request get returned . <nl> end-to-end test : . <nl> set up a cluster",1623791793,there are usecases where the service using the pinot client need to send the user defined headers to the http endpoint which seats behind load balancer . adding support for the same in the client,0.9551172256469727
jenkinsci_jenkins/5355,remove unused import <cm-sep> do not specify line endings,this fixes an unused import breaking ci . <nl> this also removes line ending specification since on different platform the checked out line ending can be different and our .gitattributes file specifies them to be .,1615548449,"adds system read permission support to global tool configuration . <nl> screenshot . <nl> when using the core-pr-tester ( ) , you can use script console to enable the new permission : . <nl> , allows users with system read permission to view the global tool configuration",0.735757052898407
prestodb_presto/15469,fix base column name not present error when dereference pushdown enabled <para-sep> self-join and table scan assignments,we 're seeing the error below when the dereference push down is enabled . <nl> ` java.lang.illegalargumentexception : nested column [ some_column_455.some_subfield ] 's base column some_column_455 is not present in table scan output <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitproject ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitproject ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.spi.plan.projectnode.accept ( projectnode.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitplan ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitproject ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitproject ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.spi.plan.projectnode.accept ( projectnode.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitplan ( hiveparquetdereferencepushdown.java:0 ) <nl> at com.facebook.presto.hive.rule.hiveparquetdereferencepushdown $ visitor.visitplan (,1606005573,there are a couple of places in optimizers that make wrong assumptions about column ordering .,0.6578747630119324
apache_flink/15513,fix less lines than requested returned by limitablebulkformat <para-sep> prepare file <nl> set limit <nl> configuration for small batches <nl> read <nl> check,"[ table runtime ] fix less lines than requested returned by limitablebulkformat . <nl> * fix less lines than requested returned by limitablebulkformat under certain conditions . <nl> - check null or not on result of before increase . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know",1617798312,"when the flink job failed before it was initialized , the method of could cause the for . therefore in , should add check whether is not null before each of closes . <nl> - add non-null check for before each of calls . <nl> - add test case in to verify the method whether cause the before calls method . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl>",0.9512670636177063
apache_incubator-pinot/6861,add broker tenant to request statistics,"this pr adds broker tenant to request statistics . <nl> since pql is deprecated , this pr only add for sql . let me know if i need to add for pql .",1619633734,"we are working on re-design the alert pipeline , removing the notified flag from anomaly results . one problem is that we need to distinguish anomalies from scheduled detection from others . users are not expect to receive any backfill anomalies in their alerts . to achieve that , a label should be applied to distinguish the difference . <nl> - add anomalyresultsource to distinguish the default anomaly detection from others . <nl> - update the anomaly result source in detection task runner",0.9364396929740906
elastic_elasticsearch/74408,"the securityindexmanager uses the name indexstate for both the inner <nl> class state and indexmetdata.state . the later is in fact a field of the <nl> former . this led to confusion when reading through the code . in <nl> addition , the names used for the inner class are inconsistent , there are <nl> places they are just called state . this pr changes to always use the <nl> name ' state ' for the inner class and ' indexstate ' for <nl> indexmetadata.state .","the securityindexmanager uses the name indexstate for both the inner <nl> class state and indexmetdata.state . the later is in fact a field of the <nl> former . this led to confusion when reading through the code . in <nl> addition , the names used for the inner class are inconsistent , there are <nl> places they are just called state . this pr changes to always use the <nl> name ' state ' for the inner class and ' indexstate ' for <nl> indexmetadata.state .",1624359627,"fixed a few remaining places where tier was still used , renamed to total <nl> like in most other places .",0.9177913665771484
Alluxio_alluxio/13107,"add replay statistics to raft journal . <nl> this change adds some new logging messages to the master while <nl> replaying the journal . specifically , it will now log the rate of <nl> journal entries applied to the state machine during the startup process . <nl> the average rate and amortized rate are logged along with the time <nl> elapsed since the last log message . <nl> additionally , there is a part of the message which attempts to estimate <nl> the remaining entries left as well as the remaining time . this part of <nl> the message can not use sequence numbers to estimate the rate because <nl> with raft , the last sequence number is non-trivial to retrieve before <nl> starting the replay . instead , we use the ratis ' commit index ' which <nl> represents batches of journal entries applied to the raft log . we are <nl> able to get the last commit index as well as track the most recently <nl> applied index which gives us the ability to provide the estimated time <nl> remaining . <nl> there is a case where an error occurs when retrieving the final commit <nl> index . in this case , the optional variable with the index will not be <nl> populated and the estimated time remaining statistics will not be <nl> calculated . <para-sep> class to abstract out progress logging for journal replay . <nl> could have been configurable . decided it is not really necessary . max time to wait before actually logging . * /","this change adds some new logging messages to the master while <nl> replaying the journal . specifically , it will now log the rate of <nl> journal entries applied to the state machine during the startup process . <nl> the number of entries in a particular interval are logged along with the <nl> current commit index and the expected entries remaining and estimated <nl> time left . <nl> in the embedded journal instead , we use the ratis ' commit index ' <nl> which represents batches of journal entries applied to the raft log . we are <nl> able to",1616304640,"0. in fuse openfile , a getstatus rpc is issued , but openfile will also issue a getstatus rpc internally , this redundant rcp is reduced in this pr . <nl> 0. when getting status of a file , or listing status of a directory , cache the status results so that future getstatus and liststatus calls do not need to issue rpcs to master . <nl> this pr introduces a new class to cache path metadata .",0.9804679155349731
apache_shardingsphere/10778,add test case for ruleconfigurationchecker <para-sep> database discovery rule configuration checker test . <nl> shadow rule configuration checker test .,changes proposed in this pull request : <nl> - add test case for databasediscoveryruleconfigurationchecker <nl> - add test case for shadowruleconfigurationchecker,1623460110,changes proposed in this pull request : .,0.9660297632217407
pentaho_pentaho-kettle/7795,"microsoft excel input mishandling empty strings and null values when using streaming <cm-sep> some sonar recommendations <para-sep> empty sheets have dimension with no range <nl> calculate the number of columns in the header row <nl> if the row has ended , break the inner while loop <nl> if the type of the cell is string , we continue <nl> if the type of the cell is string , we continue <nl> if ' t ' ended , this is a 'blank ' cell <nl> if ' is ' ended , this is a 'null ' cell <nl> most probably a 'null ' cell , but let 's make sure ... <nl> yes , it is a 'null ' cell ! <nl> we have parsed the header row <nl> do n't check the upper limit as not all rows may have been read ! if it 's found that the row does not exist , the exception will be thrown at the end of this method . <nl> there 're no more columns , no need to continue to read <nl> we 've read all document rows , let 's update the final count . <nl> and , as this was an invalid row to ask for , throw the proper exception ! <nl> we 're on the ' c ' cell tag <nl> read content as string <nl> if ' t ' ended , this is a 'blank ' cell <nl> if ' is ' ended , this is a 'null ' cell <nl> common code for the testreadblankandnullcells * tests . <nl> the full content of the file <nl> second cell is 'blank ' and third is 'null ' <nl> all cells have content <nl> second cell is 'blank ' <nl> all cells have content <nl> second cell is 'null ' <nl> all cells have content <nl> when it has an header , the first row wo n't show as content",…values when using streaming . <nl> please squash the commits .,1607701203,note : the key change we want to pick up here is the changes to subfloor.xml from steve . this should fix our build issues as we have the patched ivy jar .,0.9550898671150208
ballerina-platform_ballerina-lang/31248,add symbols for sizes in arraynode <cm-sep> add test cases for symbol at array length <cm-sep> optimize imports,> iteratively lookup symbols of array types node 's sizes list in the compiler api .,1623918052,"in this testcase , we are testing error message when client called unavailable service . but seems like when test case is running , service from another testcase is up and running in the same port . so testcase is hanging waiting for the server response . <nl> change the port from 0 to 0",0.8512423634529114
Alluxio_alluxio/13104,add resource loading fallback logic to extensionclassloader <para-sep> falls back to default class loader if not found in the url class loader,some extensions perform resource loading during initialization which can fail in the urlclassloader logic . this change adds a fallback logic to look for resource in the default class loader .,1616179310,currently in some integration tests we create a master replica from journal directory to check journal status . this can cause problems if the original master is not stopped when the new master is created . this change solves the issue by copying the journal to a separate directory and creating the new master based on the copy .,0.864141583442688
quarkusio_quarkus/17318,"handle class.getmethods ( ) returning multiple getters with just the return type differring . <nl> this can happen when getters are defined in an implement interface with <nl> a different return type ( a supertype ) ; in that case we get two getters <nl> for the same property in the array returned by class.getmethods ( ) . <nl> since the order of methods in that array is unspecified , in some cases <nl> it will work ( super method then overridden method = > we keep the <nl> overridden method ) , and in others it wo n't ( overridden method then <nl> super method = > we keep the super method ) . <nl> i was n't able to reproduce the problem in a unit test , but i know it <nl> happens with my jvm ( openjdk 0 ) for jaxbembeddable.getattributes ( ) , <nl> and it caused bytecoderecorder to fail . <nl> changing the loop to keep the most specific getter only fixes the <nl> problem . <nl> ( cherry picked from commit sha ) <para-sep> in some cases the overridden methods from supertypes can also appear in the array ( for some reason ) . we want the most specific methods .","please do n't merge , i will merge it myself .",1621338025,also adjust the various guides with the new datasource config .,0.8606747984886169
elastic_elasticsearch/73862,"add bigarrays to plugin # createcomponent ( ) <cm-sep> integrate circuit breaker in asynctaskindexservice <para-sep> sets the doc to use for updates when a script is not specified . the doc is provided in a bytes form . <nl> do not close the buffer or the xcontentbuilder until the indexrequest is completed ( i.e. , listener is notified ) ; otherwise , we underestimate the memory usage in case the circuit breaker does not use the real memory usage . <nl> do not close the buffer or the xcontentbuilder until the updaterequest is completed ( i.e. , listener is notified ) ; otherwise , we underestimate the memory usage in case the circuit breaker does not use the real memory usage .",this change integrates the circuit breaker in asynctaskindexservice to make sure that we wo n't hit oom when serializing a large response of an async search .,1623088962,adds a ' node ' field to the response from the following endpoints : . <nl> 0. open anomaly detection job <nl> 0. start datafeed <nl> 0. start data frame analytics job . <nl> if the job or datafeed is assigned to a node immediately then <nl> this field will return the id of that node . <nl> in the case where a job or datafeed is opened or started lazily <nl> the node field will contain an empty string . clients that want <nl> to test whether a job or datafeed was opened or started lazily <nl> can therefore,0.979510486125946
elastic_elasticsearch/73714,prevent deletion of repositories that are used by snapshot backed indices <para-sep> closes the given repository .,this commit adds a simple check that prevents to delete a repository that is required by an existing searchable snapshot index within the same cluster . <nl> note to reviewer : i labeled this pull request as an but one can argue that repository deletion not being forbidden is a bug . i 'm tempted to backport this change to 0.x as it is .,1622718320,"adds a setting that , when enabled , directs any currently running exporters in monitoring will treat any cluster alert definition as excluded from the list of allowed cluster alert watches . this is the first step to adding a migration path away from using cluster alerts configured by the monitoring plugin and toward those managed by the stack monitoring solutions on the new alerting feature .",0.97392338514328
jenkinsci_jenkins/5376,refactored multiple assertion tests into parameterized ones .,"problem : <nl> a test method with many individual assertions stops being executed on the first failed assertion , which prevents the remaining ones ' execution . in the refactored methods , the difference between the assertions lies in different arguments only . <nl> solution : <nl> parameterized tests make it possible to run a test multiple times , with different arguments , as individual and independent tests . this way , we were able to make 0 original tests become 0 independent ones . in this refactoring , no original assertion parameter was changed . <nl> n/a . <nl>",1616688831,note : jenkins currently ignores form validation errors for all fields when changing job configuration . so job configuration can be saved in an erroneous state . the errors are retained when the configure page is revisited .,0.9218713045120239
netty_netty/11420,logginghandler with hexdump constructor <para-sep> creates a new instance whose logger name is the fully qualified class name of the instance .,adding a constructor with hexdump enabled or disabled .,1624826240,this pull request is for ' master ' branch . <nl> i also sent another pull request for ' 0 ' branch . <nl> hope this pull request be added to netty version .,0.8197839856147766
elastic_elasticsearch/73355,"a sychronizedcollection needs to be manually synchronized when iterating <nl> through it , including stream . <nl> note : though this issue exists for both master and 0.x , the test was <nl> muted for a different reason in master . hence this pr does not remove <nl> the mute on master . it will remove the mute on 0.x when backporting .","a sychronizedcollection needs to be manually synchronized when iterating <nl> through it , including stream . <nl> note : though this issue exists for both master and 0.x , the test was <nl> muted for a different reason in master . hence this pr does not remove <nl> the mute on master . it will remove the mute on 0.x when backporting .",1621926202,"one of the plugin 's tests was failing on windows , due to a path being constructed like . this pr applies a workaround , and was tested on a windows 0 instance in gcp .",0.8422055244445801
apache_kafka/10510,"add unit test <para-sep> resign from leader , will restart in resigned state <nl> send vote request with higher epoch <nl> we will first transition to unattached and then grant vote and then transition to voted <nl> resign from candidate , will restart in candidate state <nl> send vote request with higher epoch <nl> we will first transition to unattached and then grant vote and then transition to voted <nl> beginning shutdown <nl> send vote request with higher epoch <nl> we will first transition to unattached and then grant vote and then transition to voted <nl> resign from leader , will restart in resigned state <nl> election timeout <nl> become candidate in a new epoch","more detailed description of your change <nl> as discussed in the jira , will transition to and grant vote , just add some unit tests to verify this transition . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1617949842,"the store 's registered callback could also be a restore listener , in which case it should be triggered along with the user specified global listener as well .",0.8948510885238647
jenkinsci_jenkins/5147,fixed spotbugs va_format_string_uses_newline <cm-sep> fixed spotbugs jua_dont_assert_instanceof_in_tests <cm-sep> fixed spotbugs dmi_random_used_only_once <cm-sep> removed superflous import,three minor spotbugs issues fixed involving only test code . so also just housekeeping . <nl> * internal : fixed minor spotbugs issues in test code,1609427324,"this is a small pr , which consist of three commits : <nl> * do not return null in a nonnull marked method <nl> * use equals at a string comparison and also mark method nonnull which is nonnull in base class . <nl> * minor internal bugfix in timezoneproperty forcurrentuser ( )",0.8430362343788147
apache_druid/11293,handle timestamps correctly when parsing protobuf <para-sep> timestamp spec to be used for parsing timestamp <nl> whether the spec has any fields to flat <nl> extracts the timestamp from the record . <nl> source : prototest.proto,timestamp in protobuf can be of types other than string such as . it 's best to fall back to the old logic of deserializing the timestamp via json than directly calling on object . the latter can return an unparseable string e.g . calling on will return,1621858784,"if an unhandled error occurs when curator is talking to zookeeper , _always_ exit the jvm in addition to stopping the lifecycle to prevent the process from being left in a zombie state ( note : previously , exiting the jvm was a configurable option disabled by default and would be triggered when the curator max connection retries was exceeded ) . <nl> with this change , boundedexponentialbackoffretrywithquit is no longer needed as when curator exceeds the configured retries , it triggers its unhandled error listeners . a new ' connectiontimeoutms ' curatorconfig setting is added mostly to facilitate testing",0.9656012654304504
OpenAPITools_openapi-generator/8910,changed virtualan version from version to version . update readme.md and description in springboot generator .,update readme.md and description in springboot generator .,1615038901,this pr fixes the errors in models .,1.0
apache_pulsar/10690,transaction admin api get transaction coordinator status . <cm-sep> fix some test <cm-sep> transaction admin api get transaction in pending ack stats . <cm-sep> fix some comment <cm-sep> fix some code style <cm-sep> fix some comment <cm-sep> fix some comments <cm-sep> fix some comment <cm-sep> fix transaction ack one topic with multi sub . <cm-sep> transaction admin api get transaction status . <para-sep> get transaction metadata . <nl> the txnid of this transaction . * / <nl> the status of this transaction . * / <nl> the open time of this transaction . * / <nl> the timeout of this transaction . * / <nl> the producedpartitions of this transaction . * / <nl> the ackedpartitions of this transaction . * /,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment : ( no ) .",1621868381,"add ability to examine specific message by position relative to earliest or latest message . <nl> so we can easily debug with topic without need to create subscription or fetch message by getting position ( legerid : entryid ) for that message first . <nl> add rest and cli command to get specific message from a topic position relative to earliest/latest message . <nl> exposed asyncreadentry , getfirstposition , getpositionaftern and getnumberofentries in persistenttopic to help implementing it .. . <nl> this change added tests and can be verified as follows : <nl> added unit test . <nl> - does",0.9783331751823425
ballerina-platform_ballerina-lang/28968,add conditional breakpoint support <para-sep> information about ballerina breakpoint ( properties ) .,this pr will add conditional breakpoint support for ballerina .,1614749451,- receiveactionnode <nl> - asyncsendactionnode <nl> - syncsendactionnode <nl> - forkstatementnode .,0.9725197553634644
apache_pulsar/10368,do n't return non-persistent topic when list tables by pulsar sql,"do n't return non-persistent topic when list tables by pulsar sql . <nl> new integration test added . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no )",1619371970,"motivation . <nl> when using the rest api to request to list all the non-persistent <nl> topics , it will show the persistent topics . <nl> modifications . <nl> - add a filter when before sending the response",0.9012125730514526
OpenAPITools_openapi-generator/9000,"aspnetcore fix file parameters . <cm-sep> update samples <para-sep> we need to postprocess the operations to add proper consumes tags and fix form file handling <nl> build a consumes string for the operation we can not iterate in the template as we need a ' , ' after each entry but the last <nl> in a multipart/form-data consuming context binary data is best handled by an iformfile <nl> change datatype of binary parameters to iformfile for formparams in multipart/form-data <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams <nl> input type formatter to allow model binding to streams",fix generation of operation parameters for fileupload . we can unfortunately not use on this type of parameter as they will then be treated as getting their individual properties from form . stream is also not a good fit in aspnetcore as iformfile is what we actually want .,1616073654,this pr stops descriptions and doc parts from beeing escaped by mustache and will pin poison to since poison does n't seems to work right now ( i have n't investigated anything ) .,0.9205812215805054
elastic_elasticsearch/74293,"restcontroller not using thread context directly from thread pool . <nl> at the moment thread context is passed via dispatchrequest but in some <nl> places thread context is fetched directly from thread pool <nl> this is not a problem in production , because thread pool is initialized <nl> with the same thread context as the one passed to dispatchrequest via <nl> abstracthttpservertransport . <nl> it might be harder to understand though and might cause problems in <nl> testing in smaller units .","at the moment thread context is passed via dispatchrequest but in some <nl> places thread context is fetched directly from thread pool <nl> this is not a problem in production , because thread pool is initialized <nl> with the same thread context as the one passed to dispatchrequest via <nl> abstracthttpservertransport . <nl> it might be harder to understand though and might cause problems in <nl> testing in smaller units .",1624014634,this change adds query parameter confirming that we accept tos of geoip database service provided by infra . <nl> it also changes integration test to use lower timeout when using local fixture .,0.9135774970054626
OpenAPITools_openapi-generator/9188,"use warning instead of throwing exceptions <para-sep> comment out below as we 're now showing warnings instead of throwing exceptions comment out below as we 're now showing warnings instead of throwing exceptions comment out below as we 're now showing warnings instead of throwing exceptions assert.assertthrows ( ( ) - > codegen.frommodel ( fmodelname , fsc ) ) ; comment out below as we 're now showing warnings instead of throwing exceptions assert.assertthrows ( ( ) - > codegen.frommodel ( fmodelname , fsc ) ) ;","currently , showing warnings instead of throwing exceptions in case the spec is not perfect . <nl> we 're already doing something similar in other part of the codegen , e.g .",1617703795,- replace ' usenullforunknownenumvalue ' option with the nullable attribute,0.8894089460372925
vespa-engine_vespa/17396,accept any os version by default <cm-sep> provision rhel 0 host if explicitly requested through flag,also added explicit handling of ' rhel7 ' in case we end up needing it .,1618302948,"it would be better if we could report _why_ the job was not triggered , but this at least makes me understand that nothing was really triggered",0.8228449821472168
vespa-engine_vespa/17506,function argument binding should be evaluated in parent context <cm-sep> cosmetic changes <cm-sep> more unit testing . <nl> * remove extra wiring that looks like it was added to work around <nl> evaluation happening with wrong bindings <para-sep> bound to a function argument ?,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618924816,"this will : <nl> * translate param to container endpoints and write them to the <nl> container endpoints cache , in addition to the existing rotations cache . <nl> * write param to container endpoints cache .",0.9333865642547607
elastic_elasticsearch/74494,"[ ml ] clear job size estimate cache when feature is reset <para-sep> call into the original listener to clean up the indices and then clear ml memory cache we do n't need to check anything as there are no tasks this is a quick path to downscale . simply return for scale down if delay is satisfied <nl> we never terminate the phaser <nl> if there are no registered parties or no unarrived parties then there is a flaw in the register/arrive/unregister logic in another method that uses the phaser <nl> we await all current refreshes to complete , this increments the ' current phase ' and prevents further interaction while we clear contents <nl> note : is incremented if cache is reset via the feature reset api <nl> phases above not equal to mean we 've been stopped , so do n't do any operations that involve external interaction","since the feature reset api clears out the indices , it follows that it also deletes the machine learning jobs . <nl> but , since the regular path of calling the delete job api is not followed , jobs that no longer exist could still have memory estimates cached on the master node . these would never get cleared out until after a master node changed . <nl> this commit causes feature reset to : <nl> - await for all refresh requests to finish ( of which there should usually be none as all assignments have been cancelled ) <nl>",1624460492,return a 0 http status code when attempting to delete a non existing data stream . <nl> however only return a 0 when targeting a data stream without any wildcards .,0.9532932639122009
grpc_grpc-java/7784,eliminate getters and builder for ldsupdate . <cm-sep> eliminate getters and builder for rdsupdate . <cm-sep> eliminate getters and builder for edsupdate .,"it 's common in xds for passing around configurations , which are ( effectively ) immutable . in most cases , those configuration instances are created by internal implementations and used internally as well . as configurations become complicated , getters and builders are verbose . they contribute to a significant amount of trivial code ( e.g. , adding one field requires adding one getter and one setter on builder ) . it would be extremely cumbersome to use getters and builder ( s ) for such cases . so to make data types consistent ( on xdsclient interface )",1609981858,"- add attributes to equivalentaddressgroup <nl> - replace resolvedserverinfogroup with equivalentaddressgroup <nl> - delete resolvedserverinfo , because attributes for individual addresses <nl> within an address group is not found to be useful . <nl> the result is a simpler api and reduction of boilderplates . <nl> as a related change , redefine the semantics of dnsnameresolver and <nl> roundrobinloadbalancer : . <nl> - before : dnsnameresolver returns all addresses in one address group . <nl> roundrobinloadbalancer ignores the grouping of addresses and <nl> round-robin on every single addresses . it does n't work well with the <nl> one-server-multiple-address setup ,",0.9674448370933533
apache_beam/14345,"add api key & token authentication in elasticsearchio <para-sep> if elasticsearch authentication is enabled , provide an api key . <nl> if elasticsearch authentication is enabled , provide a bearer token .","currently , only username/password authentication is supported in . this pr adds support for api key and bearer token authentication , respectively supported since version version and version of elasticsearch . <nl> this would allow users of this io to create tokens ( or api keys ) that expires , or with specific permissions",1616765495,"this change does two things : . <nl> 0. it modifies the way that the dataflow runner transmits combines to <nl> dataflow so that it can support combiner lifting . this is done by , when <nl> translating combinegroupedvalues transforms , encoding the id of the <nl> parent combine per key transform as a serialized fn . <nl> 0. this change also preemptively fixes an issue that occurs that would <nl> cause combinegroupedvalues with side inputs to get translated that way <nl> for combiner lifting , despite the parent transform being an anonymous <nl> composite transform , indicating that the",0.942958414554596
Alluxio_alluxio/12496,"implement concurrent ufs input stream cache <cm-sep> use ufs stream cache <para-sep> a map from the ufs file id to the metadata of the input streams . synchronization on this map before access . <nl> cache of the input streams , from the input stream id to the input stream . * / <nl> thread pool for asynchronously removing the expired input streams . * / <nl> constructs a new ufs input stream cache . <nl> a listener to the input stream removal . <nl> remove the key <nl> close the resource <nl> remove the value from the mapping <nl> releases an input stream . the input stream is closed if it 's already expired . <nl> for non-seekable input stream , close and return <nl> the cache no longer tracks this input stream <nl> the input stream expired , close it <nl> acquires an input stream . for seekable input streams , if there is an available input stream in the cache , reuse it and repositions the offset , otherwise the manager opens a new input stream . <nl> only seekable ufses are cachable/reusable , always return a new input stream <nl> explicit cache cleanup <nl> try to acquire an existing id from the stream id set . synchronized is required to be consistent between availableids ( ) and acquire ( id ) . <nl> find the next available input stream from the cache <nl> acquire it now while locked , so other threads can not take it <nl> for the cached ufs instream , seek ( outside of critical section ) to the requested position . <nl> no cached input stream is available , acquire a new id and open a new stream <nl> fall back to an uncached ufs creation . <nl> the metadata of the input streams associated with an under storage file that tracks which input streams are in-use or available . each input stream is identified by a unique id .","this version is very similar to the previous one , but is more concurrent , without global locks .",1605224612,"when listing status of a file , if the file is persisted and has no block cached in alluxio , and the ufs is not remote , then alluxio will ask ufs for the block locations of the file so that computation framework can leverage data locality . <nl> this pr caches the ufs locations so that further requests for the ufs locations do not need to send rpcs to ufs again .",0.9848983883857727
ballerina-platform_ballerina-lang/30782,update module.md files of the lang lib modules <cm-sep> fix documentation issues,fix documentation issues in lang lib modules,1621935811,this pr does not change any functionality .,0.8498488664627075
ballerina-platform_ballerina-lang/30539,improve method/remote method name collision diag,previous error : . <nl> now : .,1620898595,emit warning when deprecated child access is used . <nl> fixes # .,0.9274457097053528
elastic_elasticsearch/73710,remove parsedpoint from point field mappers <cm-sep> iter <para-sep> a base parser implementation for point formats * / <nl> geopoint parser implementation * / <nl> note that this parser is only used for formatting values . <nl> cartesianpoint parser implementation * / <nl> note that this parser is only used for formatting values .,this interface has been added to be able to share the same parser implementation between different field mappers . this makes the generic from the parser be different to the generic of the class which breaks the symmetry with the geo_shape implementation and makes it harder to work with . <nl> this change moves the abstraction to the parser in order to simplify the classes and makes it more in-line with shape implementations .,1622705770,"this change splits the ir nodes for variable/field accesses into two separate nodes , one for load and one for store . this removes the need for an assignment node as the store nodes replace it as the root . it also means all nodes simply have a write method instead of having separate methods for load and store to support the different types of bytecode required for this . this also means that compound assignment is no longer specialized on the assignment node which had to be overly coupled with the previous version of the variable/field accessor nodes .",0.9670091271400452
elastic_elasticsearch/74416,"[ ml ] closing an anomaly detection job now automatically stops its datafeed if necessary . <nl> previously it was a requirement of the close job api that if the <nl> job had an associated datafeed that that datafeed was stopped <nl> before the job could be closed . experience has shown that this <nl> is just a pedantic nuisance . if a user closes the job without <nl> first stopping the datafeed then it 's just a mistake , and they <nl> then have to make two further calls , to stop the datafeed and <nl> then attempt to close the job again . <nl> this pr changes the behaviour so that if you ask to close a job <nl> whose datafeed is running then the datafeed gets stopped first <nl> as part of the same call . datafeeds are stopped with the same <nl> level of force as the job close request specified . <para-sep> use lots of chunks to maximise the chance that we can close the job before the lookback completes <nl> it 's possible that the datafeed ran to completion before we force closed the job . ( we tried to avoid this by setting a small chunk size , but it 's not impossible . ) if the datafeed ran to completion then there could legitimately be a model snapshot even though we force closed the job , so we can not assert in that case . <nl> 0. if any of the jobs to be closed have running datafeeds , these are stopped first , using the same level of force as the close request 0. internally a task request is created for every open job , so there 0. no task is created for closing jobs but those will be waited on 0. collect n inner task results or failures and send 0 outer <nl> if there are failed jobs force close is true <nl> a datafeed with an end time will gracefully close its job when it stops even if it was force stopped . if we did n't do anything about this then it would turn requests to force close jobs into normal close requests for those datafeeds , which is undesirable - the caller specifically asked for the job to be closed forcefully , skipping the final state persistence to save time . therefore , before stopping the datafeeds","previously it was a requirement of the close job api that if the <nl> job had an associated datafeed that that datafeed was stopped <nl> before the job could be closed . experience has shown that this <nl> is just a pedantic nuisance . if a user closes the job without <nl> first stopping the datafeed then it 's just a mistake , and they <nl> then have to make two further calls , to stop the datafeed and <nl> then attempt to close the job again . <nl> this pr changes the behaviour so that if you ask to",1624363657,"deprecate settings : <nl> * in favor of <nl> * in favor of <nl> * in favor of . <nl> default to context cache . <nl> add , default to totally disable compilation rates . this setting is intended for integration tests .",0.9548898935317993
apache_beam/14069,"fix persubscriptionpartitionsdf to not rely on the presence of bundlefinalizer . <nl> this is currently not available in default dataflow and causes a hard error <para-sep> todo ( boyuanzz ) : when default dataflow can use finalizers , undo this . <nl> commit the next-to-deliver offset .",this is currently not available in default dataflow and causes a hard error,1614171618,"- introduces a new -- temprootkms flag , for use with tests that need a <nl> -- temproot with default key ( currently only select gcp tests ) . <nl> - simplifies gcskmskeyit 's kms key verification ( to notnull ) , since the <nl> bucket default key and -- dataflowkmskey do not match . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9221857190132141
apache_pulsar/10013,"add underreplicate state in the topic internal stats <para-sep> for the mock test , the default ensembles is [ ' version:0 ' , ' version:0 ' , ' version:0 ' ] the registed bookie id is version:0 <nl> integration tests for pulsar admin .","add underreplicate state in the topic internal stats . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no ) <nl> - anything that affects deployment : ( no",1616475859,allows the client to specify how long to wait for brokers to respond .,0.9634288549423218
apache_flink/15368,"<para-sep> returns a flag indicating if this fetcher is running . <nl> an exception wrapper to indicate an error has been thrown from the shard consumer . * / <nl> an exception to indicate the shard consumer has been cancelled . * / <nl> the record publisher has been cancelled . * / <nl> an exception wrapper to indicate the subscriber has been interrupted . * / <nl> throws error after 0 records <nl> sdkinterruptedexception will terminate the consumer , it will not retry and read only the first 0 records <nl> throws error after 0 records and there are 0 records available in the shard <nl> speed up test by reducing backoff time <nl> sdkclientexception will cause a retry , each retry will result in 0 more records being consumed the shard will consume all 0 records","this means consumer will poll kinesis without any delay , resulting in throttle . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : yes <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , kubernetes/yarn/mesos , zookeeper : no <nl> - the s3 file system connector : no . <nl> - does this",1616661780,"when the was introduced before , it forgot adding the checkpoint related metrics in the constructor . but it did not cause any problems , because only the actually worked before . <nl> after is replaced by as now , this bug is exposed and we will not see the checkpoint related metrics for the case of two inputs . <nl> the solution is to add these metrics while constructing the . <nl> add the related metrics while constructing the for two input cases . <nl> refactor the adding of related metrics for one input in order to reuse/unify the",0.9666104316711426
vespa-engine_vespa/17786,use abstractutf8array in interface and a more flexible implementation to reduce amount of copying .,use abstractutf8array in interface and a more flexible implementation to reduce amount of copying .,1620417998,"no longer return empty response with content-type , instead use ( only used by 0 endspoints ) . <nl> return better json responses for restart and deactivate application . <nl> in access logs i only found a few s , few requests from browsers and 0 % from , all of which should handle this change . ( current will return a for restart/deactivate , so that will be a json string , we can change that to just extract the message field later .",0.9399828314781189
apache_kafka/10580,fixed potential concurrency issue in connector creation,"concurrent requests to validate endpoint for the same connector type calls abstractherder : :getconnector to get the cached connector instances and if the connector has n't been cached yet then there is a race condition in the abstractherder : :getconnector method that potentially fails to detect that an instance of the connector has already been created and , as a result , can create another instance . <nl> existing tests are present with enough coverage so no new tests are added .",1619029426,it is best to use a growing thread pool for worker cleanups . this lets us ensure that we close workers as fast as possible and not get slowed down on blocking cleanups .,0.8496400117874146
elastic_elasticsearch/72810,"validate forced awareness allocation setting . <nl> today any setting under <nl> is accepted , but only those matching are actually <nl> valid . accepting other things means that we can not apply the resulting <nl> cluster state , which is disastrous . this commit adds settings validation <nl> to enforce the expected structure of these settings .","today any setting under <nl> is accepted , but only those matching are actually <nl> valid . accepting other things means that we can not apply the resulting <nl> cluster state , which is disastrous . this commit adds settings validation <nl> to enforce the expected structure of these settings .",1620306845,"there were a number of issues around data streams rolling over during <nl> a snapshot that are fixed in this pr : <nl> 0. if partial snapshots cause a data stream to not be fully snapshotted <nl> because an index gets concurrently deleted we must not add it to the <nl> resulting cluster state ( otherwise we trip assertions on either snapshot itself <nl> or a later restore , depending on whether or not the complete global state is <nl> snapshotted ) . <nl> 0. when a non-partial snapshot is running we must not allow a datastream rollover , <nl>",0.9340639710426331
runelite_runelite/13517,the inactive version of the crystal pickaxe does n't count as a pickaxe during charlie the tramp task to mine an iron ore . <nl> this should fix that by adding the inactive version as an item in the requirement collection for pickaxes .,the inactive version of the crystal pickaxe does n't count as a pickaxe during charlie the tramp task to mine an iron ore . <nl> this should fix that by adding the inactive version as an item in the requirement collection for pickaxes .,1619186077,shows crystal pickaxe as usable for the soul altar master clue step . <nl> i used the crystal pickaxe when doing this step and it worked,0.7954269647598267
vespa-engine_vespa/17808,add maven module for new feed client,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620660549,"initial version of the /system-flags/v1 api . access control , bindings and proper error handling will come in future pr .",0.9768356084823608
ballerina-platform_ballerina-lang/28636,replace with in function 's default worker <para-sep> peer-worker : = worker-name | function <nl> peer-worker : = worker-name | function,"with this change , ' default ' will no longer be a reserved keyword in the language .",1613329714,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9107248187065125
apache_druid/11227,"add auto clean up datasource metadata <cm-sep> add test <cm-sep> fix checkstyle <para-sep> remove datasource metadata created before the given timestamp and not in given excludedatasources set . <nl> return latest supervisors ( both active and terminated ) <nl> only return the latest terminated supervisors <nl> terminated supervisor will have it 's latest supervisorspec as noopsupervisorspec ( noopsupervisorspec is used as a tombstone marker ) <nl> terminated supervisor will have it 's latest supervisorspec as noopsupervisorspec ( noopsupervisorspec is used as a tombstone marker ) <nl> coordinatorduty for automatic deletion of datasource metadata from the datasource table in metadata storage . ( note : datasource metadata only exists for datasource created from supervisor ) . note that this class relies on the supervisorspec.getdatasources names to match with the 'datasource ' column of the datasource metadata table . <nl> datasource metadata only exists for datasource with supervisor to determine if datasource metadata is still active , we check if the supervisor for that particular datasource is still active or not <nl> we exclude removing datasource metadata with active supervisor <nl> try delete . datasource should not be deleted as it is in excluded set <nl> datasource should not be deleted <nl> try delete . datasource should be deleted as it is not in excluded set and created time older than given time <nl> datasource should be deleted <nl> do delete . datasource metadata should not be deleted . datasource is not active but it was created just now so it 's created timestamp will be later than the timestamp 0-0-01t00:0:00z <nl> datasource should not be deleted <nl> supervisor1 is terminated <nl> supervisor2 is still active <nl> get latest active should only return supervisor2 <nl> supervisor1 is terminated <nl> supervisor2 is still active <nl> get latest terminated should only return supervisor1",add feature to automatically remove datasource metadata based on retention period . <nl> this pr adds a similar auto cleanup based on duration ( time to retained ) but for the datasource metadata table to auto clean up datasource that is no longer active -- meaning that the datasource does not have active supervisor running ( note : datasource metadata only exists for datasource created from supervisor ) . <nl> this is useful when druid user has a high churn of task / datasource in a short amount of time causing the metadata store size to grow uncontrollably,1620630534,"this pr allows to directly rewrite filters on rhs join columns into filters on the equivalent lhs join columns , allowing these filters to be pushed down to base tables . <nl> to supports this two new methods are added to : <nl> - <nl> - . <nl> these methods are used to pass a map of column name rewrites to a filter , which the filter will use to return a copy of itself that operates on different columns . <nl> current restrictions on such rewrites : <nl> - only filters that reference a single column currently support such",0.9685158729553223
hazelcast_hazelcast/18673,"fix reconnect issue <para-sep> it might be the case that the connection was closed quickly enough that the planeindex was not set . instead look for the connection by remoteaddress and connectionid over all planes and remove it wherever found . <nl> when a member disappears and the other one ca n't connect to it <nl> then it eventually gets dropped from the cluster <nl> when a member disappears <nl> and connections to it do n't succeed ( they can be established , but immediately drop ) ( for example a tcp proxy might do this ) <nl> then it eventually gets dropped from the cluster <nl> ignore <nl> break it out of a potential accept call <nl> ignore","the root cause of this problem seems to be that , due to the proxy present , not being able to connect from one member to another does n't behave as expected . <nl> the expected behaviour is that a connection attempt is made , it fails , another one is made , it fails and after a certain number of attempts we give up and behave accordingly . <nl> what happens here instead is that a connection attempt is made , it succeeds connecting to the proxy , the proxy tries to connect to the other side , fails",1620888733,"getcacheentryrequest is used by mc to browse cache entries . currently , <nl> the entryprocessor it uses is not serializable and does n't work for <nl> keys on remote members , causing deserialization failure on the member <nl> when it tries to get the entry from another member . this commit makes <nl> both the entryprocessor used and its return type serializable .",0.9788455963134766
grpc_grpc-java/7960,turn lb state into transient_failure if an empty list of backend addresses is given . it applies to both the address list given by the balancer and fallback list given by the resolver whenever it is being used . <para-sep> populate backend servers to be used from the fallback backends . <nl> populate backend servers to be used based on the given list of addresses .,"there are two cases grpclb needs to handle an empty list of backend addresses : <nl> - the remote balancer gives an empty list . <nl> also , that change makes round_robin and pick_first diverge in terms of the behavior for receiving an empty list of backend addresses : round_robin buffers rpcs ( which could potentially hang forever as fallback timer had already been cancelled when receiving the response ) while pick_first fails rpcs immediately . <nl> - the fallback list given by the resolver , when it is used , turns out to be empty . <nl> - in",1615513472,"nothing is using this yet , but it will be used on both client and <nl> server .",0.9090324640274048
apache_kafka/10446,[ configentry.class ] add 'type ' to 'tostring ' and 'hashcode ',0. add and to <nl> 0. add and to <nl> 0. add and to <nl> 0. fix incorrect comparison of configentry # equal .,1617164822,"this is a minor fix of a regression introduced in the refactoring pr : in current trunk always return false , which would cause standby tasks to never be committed until closed . to go back to the old behavior we would return true when new data has been applied and offsets being updated .",0.888818085193634
grpc_grpc-java/8218,"server and channel builders for binderchannel . <nl> also adds 0 additional tests . <para-sep> basic tests for binder channel , covering some of the edge cases not exercised by abstracttransporttest . <nl> add two methods to the service . <nl> client-side transport tests for binder channel . like binderchannelsmoketest , this covers edge cases not exercised by abstracttransporttest , but in this case we 're dealing with rare ordering issues at the transport level , so we use a bindertransport.binderclienttransport directly , rather than a channel . <nl> this should n't throw an exception . <nl> without the fix , this loops forever . <nl> send a transaction to the no-longer present call id . it should be silently ignored . <nl> wait until we receive the first message . <nl> wait until the server actually provides all messages and completes the call . <nl> now we should be able to receive all messages on a single message producer . <nl> wait until we receive the first message . <nl> now cancel the stream , forcing it to close . <nl> the message producer should n't throw an exception if we drain it now . <nl> builder for a grpc channel which communicates with an android bound service . <nl> creates a channel builder that will bind to a remote android service . the underlying android binding will be torn down when the channel becomes idle . you the caller are responsible for managing the lifecycle of any channels built by the resulting builder . they will not be shut down automatically . <nl> always fails . <nl> always fails . <nl> specifies certain optional aspects of the underlying android service binding . * / <nl> provides a custom scheduled executor service . this is an optional parameter . if the user has not provided a scheduled executor service when the channel is built , the builder will use a static cached thread pool . <nl> optional . a default implementation will be used if no custom executor is provided . <nl> provides a custom security policy . this is optional . if the user has not provided a security policy , this channel will only communicate with the same application uid . <nl> sets the policy for inbound parcelable objects . * / <nl> creates new binder transports . * / <nl> builder for a server that services","with these builders , binderchannel should now be actually usable . <nl> this also includes more tests for which cover some special cases .",1622135167,temporary implementation until merged with xdsclient,0.9887308478355408
apache_shardingsphere/10382,support postgresql analyze & load statement <para-sep> analyze table statement context . <nl> postgresql load statement .,changes proposed in this pull request : <nl> - support postgresql analyze & load statement <nl> - add some rewrite test case for analyze statement,1621407377,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - add proxy meta data <nl> - fix some problems <nl> -,0.9690828323364258
apache_kafka/10705,"; merge raftclient and metalogmanager interfaces and remove shim <cm-sep> move reader iteration to event handler <para-sep> handle metadata snapshots <nl> loading snapshot on the broker is currently not supported . <nl> visible for testing . it 's useful to execute events synchronously in order to make tests deterministic . this object is responsible for closing the reader . <nl> the batch of records to the raft client . they will be written out asynchronously . <nl> if the controller is active , the records were already replayed , so we do n't need to do it here . <nl> complete any events in the purgatory that were waiting for this offset . <nl> delete all the in-memory snapshots that we no longer need . if we are writing a new snapshot , then we need to keep that around ; otherwise , we should delete up to the current committed offset . <nl> if the controller is a standby , replay the records that were created by the active controller . <nl> optionally return a snapshot reader if the offset if less than the first batch . <nl> load the snapshot if needed <nl> shutdown the log manager . even though the api suggests a non-blocking shutdown , this method always returns a completed future . this means that shutdown is a blocking operation . <nl> if this node is becoming the leader , then we can fire as soon as the listener has caught up to the start of the leader epoch . this guarantees that the state machine has seen the full committed state before it becomes leader and begins writing to the log . <nl> called on any change to leadership . this includes both when a leader is elected and when a leader steps down or fails . if this node is not the leader , then this method will be called as soon as possible . in this case the leader may or may not be known for the current epoch . subsequent calls to this method will expose a monotonically increasing epoch . once a leader is known for a given epoch it will remain the leader for that epoch . in other words , the implementation of method should expect this method will be called at most twice for each epoch . once if the epoch changed but the leader is not","this patch removes the temporary shim layer we added to bridge the interface differences between and . <nl> 0. reverse dependency between : raft and : metadata modules . <nl> 0. consolidate and apis into single api <nl> 0. move into : metadata <nl> 0. update listeners to use which takes disk reads out of the raft io thread <nl> 0. delete , , and <nl> 0. remove code for loading snapshots on the controller .",1621108495,subtask jira <nl> main changes of this pr <nl> * deprecate old consumer.internal.partitionassignor and add public consumer.consumerpartitionassignor with all ootb assignors migrated to new interface <nl> * refactor assignor 's assignment/subscription related classes for easier to evolve api <nl> * removed version number from classes as it is only needed for serialization/deserialization . <nl> other previously-discussed cleanup included in this pr : <nl> * remove assignment.error added in pt 0 <nl> * remove consumercoordinator # adjustassignment added in pt 0,0.9722965955734253
netty_netty/11267,"provide a way to pass through a certain upgrade request . <nl> motivation : . <nl> a user might want to handle a certain http upgrade request differently <nl> than what does by default . for example , a <nl> user could let handle http/0 upgrades but <nl> not websocket upgrades . <nl> modifications : . <nl> - added so a user can <nl> tell to pass the request as it is to the <nl> next handler . <nl> result : . <nl> - a user can handle a certain upgrade request specially . <para-sep> not handling an upgrade request yet . check if we received a new upgrade request . <nl> the upgrade request should not be passed to the next handler without any processing . <nl> no response should be written because we 're just passing through .","motivation : . <nl> a user might want to handle a certain http upgrade request differently <nl> than what does by default . for example , a <nl> user could let handle http/0 upgrades but <nl> not websocket upgrades . <nl> modifications : . <nl> - added so a user can <nl> tell to pass the request as it is to the <nl> next handler . <nl> result : . <nl> - a user can handle a certain upgrade request specially .",1621300900,motivation : . <nl> result : . <nl> the empty buffer is correctly handled in deflate encoder/decoder .,0.9483564496040344
OpenAPITools_openapi-generator/9733,: set ' anytype ' to . <nl> would not be translated to the json value type . <nl> this fixes that .,would not be translated to the json value type . <nl> this fixes that .,1623249633,"this pr only removes typemapping for ' list ' . all other custom mappings ( e.g . ' uuid ' ) still remain . while i believe they must not be there also , i 'm being conservative to minimize the impact .",0.9272456169128418
elastic_elasticsearch/72668,only wait for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade . <para-sep> cluster health does not wait for active shards per default <nl> explicitly wait for the primary shard ( although this might be default ),with this change transform only waits for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade .,1620122224,this commit updates the node stats version constants to reflect the fact <nl> that index pressure stats were backported to version . it also reenables bwc <nl> tests .,1.0
elastic_elasticsearch/73029,the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,the delete token response now returns status code 0 instead of 0 <nl> when the token does not exist .,1620886640,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.9336521625518799
apache_flink/15380,"ensure to dispose state backend in statebackendtestbase # testkeygroupedinternalpriorityqueue finally <cm-sep> refactor statebackendtestbase to ensure created keyed state backend could be disposed finally <para-sep> cast because our test serializer is not typed to testpojo <nl> make sure that we are in fact using the kryoserializer <nl> we will be expecting expectedkryotestexception to be thrown , because the exceptionthrowingtestserializer should be used <nl> backends that eagerly serializes ( such as rocksdb ) will fail here <nl> backends that lazily serializes ( such as memory state backend ) will fail here <nl> cast because our test serializer is not typed to testpojo <nl> make sure that we are in fact using the kryoserializer <nl> we will be expecting expectedkryotestexception to be thrown , because the exceptionthrowingtestserializer should be used <nl> backends that eagerly serializes ( such as rocksdb ) will fail here <nl> backends that lazily serializes ( such as memory state backend ) will fail here <nl> we will be expecting expectedkryotestexception to be thrown , because the exceptionthrowingtestserializer should be used <nl> backends that eagerly serializes ( such as rocksdb ) will fail here <nl> backends that lazily serializes ( such as memory state backend ) will fail here <nl> we will be expecting expectedkryotestexception to be thrown , because the exceptionthrowingtestserializer should be used <nl> backends that eagerly serializes ( such as rocksdb ) will fail here <nl> backends that lazily serializes ( such as memory state backend ) will fail here <nl> ============== create snapshot - no kryo registration or specific / default serializers ============== make some more modifications <nl> ====================================== restore snapshot ====================================== <nl> this is only available after the backend initialized the serializer <nl> some modifications to the state <nl> draw a snapshot <nl> make some more modifications <nl> draw another snapshot <nl> validate the original state <nl> this is only available after the backend initialized the serializer <nl> 0 ) test that valuestate # value ( ) before and after kvstate # getserializedvalue ( byte [ ] ) return the same value . <nl> set some key and namespace <nl> query another key and namespace <nl> the state should not have changed ! <nl> re-set values <nl> 0 ) test two threads concurrently using valuestate # value ( ) and kvstate # getserializedvalue ( byte [ ] ) . <nl> some modifications to the state <nl> run both threads for max 100ms <nl> wait for","this change includes two commits : <nl> to fix . <nl> to stabilize all state backend tests . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",1616732781,"add a row delimiter parameter to the constructor <nl> # # verifying this change . <nl> pr adds a new test . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects",0.9094002842903137
apache_kafka/10814,"; add transaction tool from <para-sep> get the name of this command ( e.g . ) . <nl> specify the arguments needed for this command . <nl> execute the command logic . <nl> if a transaction was started by a new producerid and became hanging before the initial commit/abort , then the coordinator epoch will be 0 as seen in the output . in this case , we conservatively use a coordinator epoch of 0 , which is less than or equal to any possible leader epoch . <nl> assert expected headers <nl> add a little time so that we can see a positive transaction duration in the output","this includes all of the logic for describing transactional state and for aborting transactions . the only thing that is left out is the implementation , which will be left for a subsequent patch .",1622769586,"summary of changes : . <nl> currently , in sslfactory.java , when the keystore is created null ( caused by passing an empty config value to ssl.keystore.location ) , the default sun keymanager is used ignoring the 'ssl.keymanager.algorithm ' provided . <nl> i included changes to fetch keymanager from the keymanagerfactory based on the provided keymanager algorithm , populated by 'ssl.keymanager.algorithm ' if the keystore is found empty",0.9805181622505188
apache_druid/11172,"add a way to retrieve bytes directly via dimensiondictionaryselector . <nl> the idea is that certain operations ( like count distinct on strings ) will <nl> be faster if they are able to run directly on bytes instead of on <nl> java strings decoded by ' lookupname ' . <para-sep> returns the value for a particular dictionary id as a java string . <nl> if is n't faster , it 's better to throw an exception rather than delegate to ' lookupname ' and do the conversion . callers should check ' supportslookupnameutf8 ' to make sure they 're calling the fastest method . <nl> duplicate the first buffer since we are reading the dictionary twice . <nl> returns the value for a particular dictionary id as bytes . the returned buffer is in big-endian order . it is not reused , so callers may modify the position , limit , byte order , etc of the buffer . the returned buffer points to the original data , so callers must take care not to use it outside the valid lifetime of this column . <nl> an objectstrategy that returns a big-endian bytebuffer pointing to the original data . the returned bytebuffer is a fresh read-only instance , so it is ok for callers to modify its position , limit , etc . however , it does point to the original data , so callers must take care not to use it if the original data may have been freed . <nl> this method does n't have javadocs and i 'm not sure if it is ok to modify the ' val ' argument . copy defensively . <nl> duplicate the first buffer since we are reading the dictionary twice . <nl> different buffer on different calls ; enables callers to safely modify position , limit as promised in the javadocs .","the idea is that certain operations ( like count distinct on strings ) will <nl> be faster if they are able to run directly on bytes instead of on <nl> java strings decoded by ' lookupname ' . <nl> i 'm looking into modifying the cardinality and datasketch hll build <nl> aggregators to use lookupnameutf8 instead of lookupname in a <nl> follow-on patch , and it is able to speed them up quite a bit .",1619551906,initializing a is not cheap ; it includes parsing an expression . the should be reused in stream indexing rather than recreating it for every stream chunk . batch ingestion does n't have this issue since it decorates an with a which is a reader for the entire input data . <nl> also fixed json serde of,0.9724867343902588
jenkinsci_jenkins/5483,remove usages of deprecated ( in java 0 and above ),"the documentation for includes the following warning : . <nl> > note that this method propagates any exception thrown by the nullary constructor , including a checked exception . use of this method effectively bypasses the compile-time exception checking that would otherwise be performed by the compiler . the method avoids this problem by wrapping any exception thrown by the constructor in a ( checked ) . <nl> for this reason , the method has been deprecated in java 0 and above . <nl> we should always prefer to calling directly . the latter sequence of calls is inferred to",1620791831,"corrected a misspelled class name ; and introduced a new overload of that does not make you remember to use a -block . considered having it take but this throws which is inconvenient ; lets that be parameterized but i settled on simple by comparing the following jdk 0 λ snippets : . <nl> vs. the more readable and natural . <nl> ( i remember seeing some proposal for that would be better than for this case , but can not find it now . can not find anything more suitable in either , and anyway we could not yet",0.9250414967536926
Alluxio_alluxio/13132,"add journal space monitor . <nl> this new monitor tracks disk utilization of a disks when alluxio is <nl> is configured to use the embedded journal . the monitor logs messages <nl> when available disk space falls below a configurable percentage . the <nl> disk utilization metrics are exposed in the logs when the threshold is <nl> reached , but can also now be found as metrics as well as in the alluxio <nl> master 's web interface . <nl> implementation details : <nl> the monitor is implemented as a heartbeat thread in the <nl> defaultmetamaster . it gets disk utilization by using the command <nl> that is by default included with nearly all linux distributions , including <nl> within bare containers such as alpine , ubuntu , and centos . the command <nl> and arguments used are all posix-compatible , so this should be portable <nl> but for now is limited to linux . <nl> for metrics , the actual disk values are not retrieved on every call to <nl> the metrics endpoint but rather thye are only updated on the configured <nl> heartbeat interval . <para-sep> a class representing the state of a physical device .","this new monitor tracks utilization of disks when alluxio is <nl> is configured to use the embedded journal . the monitor logs messages <nl> when available disk space falls below a configurable percentage . the <nl> disk utilization metrics are exposed in the logs when the threshold is <nl> reached , but can also now be found as metrics as well as in the alluxio <nl> master 's web interface . <nl> implementation details : <nl> the monitor is implemented as a heartbeat thread in the <nl> defaultmetamaster . it gets disk utilization by using the command <nl> that is",1616884558,"master address lookup does some retries of its own , but not as long as the retries needed to survive master failover . this can cause the worker to die if it starts while a master failover is happening . we address this by adding a retry around the worker 's initial request for an id from the master . <nl> there is also a bigger issue where would call outside the retry loop . if getting the address throws an error , we would n't retry . does some retries of its own , but not nearly as long",0.9800676107406616
vespa-engine_vespa/18163,warn instead of failing on validation errors in manual zones . <nl> the purpose of validation overrides is to protect production from <nl> destructive changes by requiring a confirmation for such changes . <nl> this is unnecessary in manuall deployed environments . <para-sep> todo : remove this class after june 0,the purpose of validation overrides is to protect production from <nl> destructive changes by requiring a confirmation for such changes . <nl> this is unnecessary in manuall deployed environments .,1623145984,"this should fix most of the issues with . <nl> this pr simplifies/makes tests more accurate by using to perform application activation ( thereby always setting last deploy time ) . this makes it possible to simplify the actual maintainers by always using last deploy time , f.ex . in . this should also fix a minor bug where an operator has performed a change , but the redeployment failed - in that case it would not be retried until picked it up . <nl> the rest is just logging a nicer stack trace on transient errors . <nl> what",0.8835302591323853
grpc_grpc-java/8030,"fix lifecycle mismatch issue for most recently updated route configurations when the currently in-usse resources are revoked . the route configuration to be used should always be updated when receiving resource update , even if the update revokes the in-use resource . <cm-sep> enhance tests to have better coverage for multiple resource updates . <para-sep> clusters ( with reference counts ) to which new/existing requests can be/are routed . <nl> populate all clusters to which requests can be routed to through the virtual host . <nl> updates channel 's load balancing config whenever the set of selectable clusters changes . <nl> discovery state for routeconfiguration resource . one instance for each listener resource update . <nl> two new service config updates triggered : - with load balancing config being able to select cluster1 and cluster2 - with load balancing config being able to select cluster2 only <nl> no name resolution result until new rds resource update is received . do not use stale config <nl> simulate management server adds back the previously used rds resource . <nl> should never be subscribing to more than one lds and rds resource at any point of time .","xdsnameresolver is stateful in terms of received xds configurations ( e.g. , routes , httpmaxstreamduration , clusters being exposed in service config ) . the full suite of configurations should always be updated whenever receiving new resource updates , including updates that revoke currently in-use resources . reference counts for currently in-use clusters should also be cleaned up properly . otherwise , re-receiving ( after being revoked ) the same resource can be treated as if the configuration never changed . <nl> in short , all of xdsnameresolver 's states should always be consistent with the most recent xds update",1617130915,"the ' active ' list and corresponding circular index used by 's picker is currently refreshed via a call to after _any_ change to a subchannel 's state or the resolved address groups , regardless of whether that change actually results in a change to the contents of the list . <nl> in fact it appears that the _majority_ of picker refreshes may be no-ops - for example any time a new eag is discovered while there are already active subchannels , its new subchannel is added in state followed by an immediate picker refresh which will be unnecessary because",0.9806458353996277
apache_camel/5504,"add support to set the index time <para-sep> time this even occurred . by default , the time will be when this event hits the splunk server . <nl> time this even occurred . by default , the time will be when this event hits the splunk server . the option is a : & lt ; code & gt ; java.lang.long & lt ; /code & gt ; type . group : producer <nl> time this even occurred . by default , the time will be when this event hits the splunk server . the option will be converted to a & lt ; code & gt ; java.lang.long & lt ; /code & gt ; type . group : producer",add new option in the splunk-hec component in order to set the time the event occurred rather than defaulting the time to the index time .,1620169961,added support of socks proxy to telegram component by adding proxytype query parameter . <nl> proxytype supported values are : <nl> - http <nl> - socks4 <nl> - socks5 . <nl> because of asynchttpclient use there is a clear distinguish between socks versions now unlike in .version version .,0.9550750851631165
vespa-engine_vespa/18220,log load balancer state transitions <cm-sep> test that service supports node/cluster type when activating <para-sep> always store load balancer so that loadbalancerexpirer can expire partially provisioned load balancers <nl> signal that load balancer is not ready yet,take 0. merge can wait until monday .,1623418924,this avoids creating an excessive number of connections <nl> to search clusters when the application ( incorrectly ) creates <nl> many local provider chains to the same search cluster .,0.972793459892273
elastic_elasticsearch/73051,fix deprecation logs throttling for deprecated routes . <nl> so far when a deprecated route was executed it only emitted deprecation <nl> warning once . all subsequent deprecated routes ( even when path and <nl> method were different ) we throttled because the key was the same - <nl> deprecated_route . <nl> this commit suffixes the deprecation key with path and method . <cm-sep> throttling test,so far when a deprecated route was executed it only emitted deprecation <nl> warning once . all subsequent deprecated routes ( even when path and <nl> method were different ) were throttled because the key was the same - <nl> deprecated_route . <nl> this commit suffixes the deprecation key with path and method .,1620913487,this moves the execution of the action before the <nl> action in the and phases for a more efficient <nl> data migration ( ie . mounting it as a searchable snapshot directly on the <nl> target tier ) .,0.9522799849510193
Alluxio_alluxio/12982,correct java doc and remove unused import in cosnunderfilesystemfactory and ozoneunderfilesystemfactory,add import statement to make link in java doc workable,1614738181,this change updates the scalability and performance tuning docs per the new version grpc changes .,0.7497087717056274
trinodb_trino/7621,remove unsed supportsmetadatadelete in hivemetadata . <nl> this is a legacy method that is only used with table layouts . <cm-sep> use acid semantics for whole partition deletes . <nl> use a row level delete instead of dropping partitions when <nl> running a delete that exactly matches entire partitions . <para-sep> verify all partitions exist <nl> run delete and verify row count <nl> verify all partitions still exist,use a row level delete instead of dropping partitions when running a delete that exactly matches entire partitions .,1618610370,operation timing is based on and <nl> and there is no guarantee the <nl> measured elapsed time is positive .,0.791293203830719
Alluxio_alluxio/13426,change tier block store to dependency injection for testing,modify tierblockstore to take dependencies as parameter to avoid get internal fied in tierblockstoretest,1621058455,"in addition , excludes the conflicting mortbay jetty dependencies when running with the minidfs cluster . this only affects test code .",0.9085801839828491
ballerina-platform_ballerina-lang/30258,send access token if available in all central commands . <para-sep> set newly retrieved access token <nl> read the access token generated for the cli . <nl> the access token can be specified as an environment variable or in 'settings.toml ' . first we would check if the access token was specified as an environment variable . if not we would read it from 'settings.toml ',# # purpose <nl> > $ title .,1619706287,load stdlib from balo at compile time,0.9597362279891968
apache_flink/15752,"refactor joinconditionwithfullfilters from an inner class in abstractstreamingjoinoperator to a common utility class . <para-sep> utility to take null filters into consideration when apply join condition . * / <nl> should filter null keys . * / <nl> no keys need to filter null . * / <nl> filter null to all keys . * / <nl> key is always binaryrowdata <nl> find null present , return false directly <nl> test condition","this pull request aims to refactor joinconditionwithfullfilters from an inner class in abstractstreamingjoinoperator to a common utility class . <nl> - update related joinoperators : abstractstreamingjoinoperator , streamingjoinoperator , streamingsemiantijoinoperator . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and",1619359952,"# # what is the purpose of the change . <nl> in , we can not remove all for tableschema , because schema ( it is a descriptor ) is not same to tableschema . schema contains time attribute , so we need keep them in properties . <nl> remove per key for tableschema in . <nl> add test . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> -",0.9266835451126099
apache_kafka/10824,"sessionwindows close after gap plus grace <para-sep> dummy record to advance stream time = 0 , 0 for gap time plus 0 to place outside window <nl> dummy record to advance stream time = 0 , 0 for gap time plus 0 to place at edge of window <nl> dummy record to advance stream time = 0 , 0 for gap time plus 0 to place outside window",session windows should be closed only after reaches .,1622858977,the and use relatively strict timeouts of 0 seconds to check the intermediate state of the tests . the test failures observed in these two tests were not about the final output but asserting the embedded broker sent messages within the given timeframe . <nl> i ran the existing streams test suite .,0.8378354907035828
apache_shardingsphere/10762,optimize select statement that in same datasource route logic <para-sep> judge whether all tables are in same data source or not .,changes proposed in this pull request : <nl> - optimize select statement that in same datasource route logic,1623401135,changes proposed in this pull request : <nl> - load shardingmetadataloader metadata for different data sources concurrently,0.8973392248153687
OpenAPITools_openapi-generator/8346,"added javadoc + meta-data about request/response + abstract class . <para-sep> { { ^description } } gets or sets { { { name } } } { { /description } } { { # description } } { { { description } } } { { /description } } <nl> this is the default behavior . stateful : if a specific endpoint is called more than once from multiple sessions , its state is retained properly . for example , if you want to keep a class property that counts the number of requests or the last time a request was received . note : stateful flavor is more performant than stateless . <nl> returns the default base path to access this server . <nl> request parameters : <nl> ' { { { basename } } } ' <nl> - required : { { { required } } } <nl> response headers : [ { { # responseheaders } } { { { . } } } { { ^-last } } , { { /-last } } { { /responseheaders } } ] <nl> consumes : { { { consumes } } } <nl> responses : <nl> { { # isdefault } } default { { /isdefault } } { { ^isdefault } } { { { code } } } ( { { # is1xx } } informative { { /is1xx } } { { # is2xx } } success { { /is2xx } } { { # is3xx } } redirection { { /is3xx } } { { # is4xx } } client error { { /is4xx } } { { # is5xx } } server error { { /is5xx } } ) { { /isdefault } } { { # message } } : { { { message } } } { { /message } } <nl> { { { appname } } } { { { appdescription } } } { { # version } } openapi document version : { { { version } } } { { /version } } { { # infoemail } } maintained by : { { { infoemail } } } { { /infoemail } } auto-generated file , do not modify ! <nl> { { { description } } } { { /description } } <nl> minimum : { { { minimum } } } { {","this pr brings the undertow server template up-to-date by adding the following : . <nl> - make the main class and methods abstract ; this ensures that implementations do not miss an endpoint by mistake . <nl> - added possibility to set a different base path if needed . <nl> - added javadoc for the endpoints , including description , notes , expects/returns and consumes/produces . <nl> - properly links to other pojos from the documentation . <nl> - added licensing header to all files . <nl> - fixed a couple of indentation errors in classes . <nl> - allows",1609890441,this looks for all used schema to compute the unused one .,0.9445393681526184
hazelcast_hazelcast/18921,"preliminary changes <para-sep> returns maximum execution time for the job in milliseconds . <nl> sets the maximum execution time for the job in milliseconds . if the execution time ( counted from the time job is submitted ) , exceeds this value , the job is forcefully cancelled . <nl> start and wait for the job to start running <nl> kill old master and wait for the cluster to reconfigure <nl> wait for the job to be restarted and cancelled due to timeout","now if a param is specified in a job config , a delayed task is created on job start that will cancel the job forcefully , this task is cancelled upon the job completion . <nl> currently only and -statements create a job as part of their execution , therefore support is added only for those statements . additionally support for would be added separately as that is mostly centered around sql fe extension , rather than sql be/jet itself .",1623853266,nodes confirm who their master is at regular intervals . master removes nodes if they have not recently confirmed . <nl> master sends out a member list at regular intervals to ensure everyone is in sync . <nl> unit tests for situations seen in a production system included .,0.9510430693626404
elastic_elasticsearch/72726,"clean up node shutdown metadata in test cleanup . <nl> this commit ensures that node shutdown metadata is cleaned up between <nl> tests , as it causes unrelated tests to fail if a test leaves node <nl> shutdown metadata in place . <para-sep> if any nodes are registered for shutdown , removes their metadata .","this commit ensures that node shutdown metadata is cleaned up between <nl> tests , as it causes unrelated tests to fail if a test leaves node <nl> shutdown metadata in place .",1620165254,"removing error messages for missing , unreadable or blocked config files that are no longer used because the reloader fails before running the config classes .",0.895763635635376
neo4j_neo4j/11673,disable restriction on open maps as arguments to point function <para-sep> todo : we might consider removing this code if the pointbuilder.allowopenmaps=true remains default <nl> we can un-ignore this if/when we re-enable strict map checks in pointfunction.scala,this fixes a behaviour regression from version where point function was previously allowed to take maps of arbitrary values .,1525075711,unify hazelcast configuration among core and edges .,0.7775858044624329
OpenAPITools_openapi-generator/9367,minor wording change <cm-sep> remove samples <para-sep> kotlin-server-deprecated ( deprecated ) <nl> constructs an instance of .,- update code comment <nl> - mark generator as deprecated <nl> - minor wording change <nl> - remove samples ( not required for deprecated generator ) .,1619657453,minor improvement to the java vertx web server generator . <nl> - mark as beta <nl> - minor change to default output directory <nl> - update template creator .,0.9273231029510498
ballerina-platform_ballerina-lang/27038,add annotation support to resource path parameter <cm-sep> restrict resource-path-rest-param to be last param <para-sep> validate resource path elements and create a stnodelist <nl> resource-path-parameter : = ' [ ' type-descriptor [ ... ] param-name ' ] ' <nl> resource-path-segment can not follow a resource-path-rest-param,- add annotation support to resource path parameter <nl> - restrict resource-path-rest-param to the last parameter .,1605866971,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9590129256248474
keycloak_keycloak/8106,"fix 'java.lang.noclassdeffounderror : could not initialize class org.jboss.marshalling.river.rivermarshaller ' <nl> error for : . <nl> * org.keycloak.testsuite.crossdc.lastsessionrefreshcrossdctest and <nl> * org.keycloak.testsuite.crossdc.sessionexpirationcrossdctest . <nl> tests , when running cross-dc tests with jdk 0 . <cm-sep> adaptively add the default modular jvm options <nl> to the ' javavmarguments ' to start the cache server container with , <nl> if the jvm used to run the cache server is modular ( jdk 0+ ) . <para-sep> original config of the cache server container as a map <nl> start cache server with default modular jvm options set if jdk is modular ( jdk 0+ ) <nl> when jvm used to launch the cache server container is modular , add the default modular jvm options to the configuration of the cache server container if these are n't present there yet . see the definition of the 'default.modular.jvm.options ' property for details . <nl> since next time the cache server container might get started using a non-modular jvm again , do n't store the default modular jvm options into the cache server container 's configuration permanently ( not to need to remove them again later ) . rather , instead of that , retrieve the original cache server container 's configuration as a map , add the default modular jvm options there , and one-time way start the cache server using this custom temporary configuration . <nl> finally start the cache server container : - either using the original container config ( case of a non-modular jvm ) , - or using the updated container config ( case of a modular jvm )","adaptively add the default modular jvm options <nl> to the ' javavmarguments ' to start the cache server container with , <nl> if the jvm used to run the cache server is modular ( jdk 0+ ) <nl> signed-off-by : jan lieskovsky . <nl> fixes issues / errors like : . <nl> when running cross-dc tests on hosts having both jdk 0 & jdk 0 installed ( e.g . recent fedora or .0 systems ) . <nl> fix 'java.lang.noclassdeffounderror : could not initialize class org.jboss.marshalling.river.rivermarshaller ' <nl> error for : <nl> * org.keycloak.testsuite.crossdc.lastsessionrefreshcrossdctest and <nl> * org.keycloak.testsuite.crossdc.sessionexpirationcrossdctest <nl> tests ,",1622131942,"pr includes two commits as i first added to add theme selector spi , then added which leverages theme selector spi to add support for overriding themes per client or client template .",0.8925920128822327
ballerina-platform_ballerina-lang/30682,use intersection effective type to compute intersection <cm-sep> add tests,"we need to improve the intersection computation to propagate attributes ( read-onlyness , size if fixed , etc . ) from the original type .",1621443191,private fields and methods are not allowed in an abstract object .,0.929574728012085
ballerina-platform_ballerina-lang/30362,"add minor fix for conditional breakpoints <cm-sep> enable tests <para-sep> as we are disabling all the breakpoint requests before evaluating the user 's conditional expression , need to re-enable all the breakpoints before continuing the remote vm execution .",- adds minor fix related to conditional breakpoints support .,1620204458,when field access done with error lifting .,0.8318789005279541
vespa-engine_vespa/18395,add logging of most important config parameters <cm-sep> remove debug logging,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624537375,"tested manually , works great . will add tests against docker daemon in separate commit as i need to get it working on linux first .",0.8455507755279541
confluentinc_ksql/7053,unit tests for newmigrationcommand <cm-sep> more dm_exit cleanup <cm-sep> unit tests for initializemigrationcommand <para-sep> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,as the title says . also fixes a minor bug with handling of migrations directories with trailing slashes . <nl> : ) .,1613777951,"currently , if a streams producer encounters an error while trying to publish a record , the streams thread will shut down , preventing further processing of records . this pr adds the ability to instead log the error and continue processing . a new config controls this behavior , and defaults to ( i.e. , the current behavior ) . <nl> regardless of the value of the flag , any producer error messages are logged as a new type of record processing message , , containing the error message . ( we choose not to include the record that",0.9619330763816833
elastic_elasticsearch/73861,"the recent upgrade of the azure sdk has caused a few test failures that <nl> have been difficult to debug and do not yet have a fix . we need to wait <nl> for a fix for that issue , so this reverts commit <nl> sha . <para-sep> we have to rewrite the service classes to make them public to avoid granting the permission ' java.lang.reflect.reflectpermission ' ' newproxyinpackage ' to this plugin . <nl> eclipse ca n't pick up the shadow dependency so we point it at something so it can compile things .","the recent upgrade of the azure sdk has caused a few test failures that <nl> have been difficult to debug and do not yet have a fix . we need to wait <nl> for a fix for that issue , so this reverts commit <nl> sha .",1623088699,"this change adds an extra piece of information , <nl> limits.total_ml_memory , to the ml info response . <nl> this returns the total amount of memory that ml <nl> is permitted to use for native processes across <nl> all ml nodes in the cluster . some of this may <nl> already be in use ; the value returned is total , <nl> not available ml memory .",0.8960719108581543
Graylog2_graylog2-server/10183,"support ipinfo database files in geoip lookup data adapter . <nl> add support for the standard location and asn ipinfo database files . <para-sep> small abstraction layer for the different location databases from maxmind and ipinfo to make them usable in a single lookup data adapter until we create separate adapters for the different databases . <nl> ipinfo asn response : { ' name ' : ' cloudflare , inc. ' , ' route ' : ' version/0 ' , ' type ' : ' hosting ' , ' asn ' : ' as13335 ' , ' domain ' : ' cloudflare.com ' } <nl> the ipinfo databases use a different database type identifier and a different data format than the maxmind databases . <nl> ipinfo standard location response : { ' country ' : ' de ' , ' lng ' : ' version ' , ' city ' : ' tostedt ' , ' timezone ' : ' europe/berlin ' , ' region ' : ' lower saxony ' , ' lat ' : ' version ' , ' geoname_id ' : ' 0 ' } <nl> values can be null so we can not use an immutablemap here <nl> values can be null so we can not use an immutablemap here <nl> this test will possibly get flaky when the entry for version changes ! <nl> this test will possibly get flaky when the entry for version changes !",add support for the standard location and asn ipinfo database files .,1614690231,"this pr will add contentpackable interface to export a eventdefintion and its config <nl> to a content pack entity . and add a nativeentityconverter to export a eventdefintionentity <nl> to its nativeentity ( eventdefintion ) . <nl> this pr , also , adds a eventdefintionfacade . <nl> - exported and imported a eventdefintion via content pack .",0.9800412058830261
apache_pulsar/10713,fix inconsistent behavior <cm-sep> add unit test,"if there is no data , in concurrentopenlongpairrangeset , the above two methods will return null . <nl> nosuchelementexception will be thrown in defaultrangeset , which is the default behavior of guava range . <nl> when i was using this interface , it was very troublesome to deal with abnormal scenarios . i needed to determine whether it was null and add try-catch , so it is better to make the behavior of the current implementation class consistent . <nl> either throw an exception or return null , i chose to return null .",1622017998,"currently , if we pass an invalid source configuration to instantiate we will get no log even there is an exception thrown . and after called , the background thread may still alive unless we caught an if returns . so i would like to add a flag to indicate if the connector is stopped . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9295922517776489
vespa-engine_vespa/17085,"increase the minimum time before first cluster state broadcast <para-sep> mintimebeforefirstsystemstatebroadcast is the minimum time the cc will wait for the storage nodes and distributors being down in slobrok and/or getnodestate , before being allowed to broadcast a cluster state . we therefore force a longer timeout depending on related settings .","this pr will <nl> - designate the master cc as in ' moratorium ' until it has broadcast its first cluster state <nl> - deny the safe setting of node states in moratorium <nl> - increase the time to the first cluster state broadcast as described below . <nl> the first cluster state broadcast by a new cc will increase from 0 to 0 seconds , by default . the time from start to the first broadcast can be increased with config , but not decreased below either of the following two config settings : <nl> - <nl> - .",1616187348,"add support for serializing and compressing once , instead of once per backend node .",0.9519563317298889
jenkinsci_jenkins/5456,migrate some tests from hudsontestcase to jenkinsrule,"was deprecated in favor of on june 0 , 0 , yet 0 tests in this repository continue to use it . this pr does not migrate all of them , but it does take care of 0 pieces of low-hanging fruit .",1619897314,"* a created on the master does not set the flag . so why would we do so on the remote side ? that merely produces a flurry of packets . we expect that code flushes a stream when it is done with it . <nl> * conversely , on the agent side produces a which produces a which uses to forward stdout/stderr of the process . yet as far as i can tell , this never flushed its sink unless you pass the flag ( which no code in core does ) , meaning the tail end of log",0.952636182308197
crate_crate/10772,"do not cancel recovery for copy on broken node . <cm-sep> cancel recoveries even if all shards assigned . <cm-sep> remove allocationservice.reroute ( clusterstate , string , boolean ) .",see commit messages for details . <nl> these are out of order patches missing from the es-backports list and motivated <nl> by flaky allocation related tests .,1605279316,see the individual commits for details .,0.844662070274353
elastic_elasticsearch/72835,deprecate single-tier allocation filtering settings . <nl> settings are now deprecated in <nl> favor of using .,settings are now deprecated in <nl> favor of using .,1620335290,the main changes are : <nl> 0. add to the default properties of geoip processor . <nl> 0. add a yaml test for the code change . <nl> 0. update the geoip processor doc .,0.8865366578102112
ballerina-platform_ballerina-lang/30559,"support config variables with enum types with toml <cm-sep> support config variables with enum types via cli <cm-sep> add unit tests for config enum types <cm-sep> add integration tests for configurable union types <para-sep> todo : move the enum check to provider impl , once runtime support configuring union types . <nl> enum value given with toml <nl> enum value given with cli <nl> invalid config enum value <nl> not supported union type <nl> build and push config lib project .",example . <nl> toml . <nl> cli .,1620969991,times for 2b operations : . <nl> value | operation | before ( ms ) | after ( ms ) <nl> -- | -- | -- | -- <nl> record | create | 0 | 0 <nl> | | get | 0 | 0 <nl> | | set | 0 | 0 <nl> | map | create | 0 | 0 <nl> | | get | 0 | 0 <nl> | | set | 0 | 0 . <nl> sample code used : .,0.9779248237609863
jenkinsci_jenkins/5367,"check if agent before master , fix remoting classloading <nl> error","also tested running a freestyle build on the controller and there were no issues . <nl> , fix a classloading issue while executing processtree.get ( )",1616172453,"not enough information is exposed about the build executor when a job is started via the jenkins cli jar . <nl> change the clicause to extend the useridcause class because it provides us with more information : namely , the userid and username properties .",0.8335390090942383
apache_druid/11316,* fix bug <cm-sep> * simplify class loading <cm-sep> * fix example configs for integration tests <para-sep> must be called only when the hadoopy classloader is the current classloader,"this fixes a bug which caused hadoop based ingestion tasks to fail whenever the deep storage directory has a character that is not permitted in hdfs . this caused by the deep storage segment file path being returned without the scheme ( s3 , gcs , etc ) . hadoop client uses the scheme to determine the filesystem class implementation to use when performing file operations . if no scheme is set , it default to hdfs file . fixed the issue by returning the full uri of the segment file , which includes the scheme",1622251699,but i would like to suppose that there may be rare possibility someone has a dependency on this field . the restful should be the priority option to retrieve segment metadata,0.8884961605072021
apache_pulsar/10304,"improve shutdown ( daemon=false , uncaught exception handler ) <cm-sep> improve logging <cm-sep> fix logging for broker shutdown <cm-sep> print the stacktrace for uncaught exceptions <cm-sep> add logging for pulsarservice shutdown completion",by default log4j2 registers a shutdown hook which stops log4j2 logging before the broker shutdown has completed . this makes it hard to diagnose issues in broker shutdown . <nl> this pr will also help to diagnose that issue . <nl> - add more logging to shutdown <nl> - pass option to broker and standalone startup <nl> - initiate log4j2 shutdown manually by calling before the jvm exits <nl> - remove outdated code to flush logback logger before shutdown <nl> - print the stacktraces for uncaught exceptions in the broker,1619002071,"added bookkeeperclientminnumracksperwritequorum and bookkeeperclientenforceminnumracksperwritequorum to be able to configure rack and region aware bookie selection policy more precisely . <nl> we wanted to store copy of each pulsar message in all that azs . after configuring rack aware bookie selection policy , we found that messages are usually stored only in 0 azs . after digging , we 've found that it 's caused by default bookeeper client minnumracksperwritequorum=0 setting . we 've added bookkeeperclientminnumracksperwritequorum and also bookkeeperclientenforceminnumracksperwritequorum to be able to configure this behaviour . <nl> added bookkeeperclientminnumracksperwritequorum and bookkeeperclientenforceminnumracksperwritequorum configuration option , modified tests , config files and",0.9384075999259949
OpenAPITools_openapi-generator/9136,"fix inner enum integer without format <cm-sep> add line break , update samples <cm-sep> remove line break <cm-sep> add line break <para-sep> enumintegeronly | int * | | <nl> / defines enumintegeronly / <nl> / / enum number_2 for value : 0 / <nl> / / enum number_minus_2 for value : 0 / <nl> / / gets or sets enumintegeronly / <nl> / <nl> / enumintegeronly . <nl> enumintegeronly | int * | | <nl> / defines enumintegeronly / <nl> / / enum number_2 for value : 0 / <nl> / / enum number_minus_2 for value : 0 / <nl> / / gets or sets enumintegeronly / <nl> / <nl> / enumintegeronly . <nl> enumintegeronly | int * | | <nl> / defines enumintegeronly / <nl> / / enum number_2 for value : 0 / <nl> / / enum number_minus_2 for value : 0 / <nl> / / gets or sets enumintegeronly / <nl> / <nl> / enumintegeronly . <nl> enumintegeronly | int * | | <nl> / / test inner enum integer / <nl> / defines enumintegeronly / <nl> / / enum number_2 for value : 0 / <nl> / / enum number_minus_2 for value : 0 / <nl> / / gets or sets enumintegeronly / <nl> / <nl> / enumintegeronly . <nl> enumintegeronly | int * | | <nl> / defines enumintegeronly / <nl> / / enum number_2 for value : 0 / <nl> / / enum number_minus_2 for value : 0 / <nl> / / gets or sets enumintegeronly / <nl> / <nl> / enumintegeronly . <nl> enumintegeronly | enumintegeronlyenum * | | <nl> gets or sets enumintegeronly <nl> get enumintegeronly <nl> enumintegeronly | enumintegeronlyenum * | | <nl> gets or sets enumintegeronly <nl> get enumintegeronly",- fix enum of type without format ( e.g . int32 ) <nl> - better code format <nl> - added a test .,1617096395,this pr adds test cases to confirm the issue is fixed : ) .,0.9679203629493713
apache_kafka/10496,"move noopsnapshotwriter to main . <nl> move noopsnapshotwriter and noopsnapshotwriterbuilder out of the test <nl> directory and into the main directory , until we implement the kraft <nl> integration . <para-sep> the no-op snapshot writer which does nothing . todo : this will be moved to the test/ directory once we have the kraft implementation of the snapshot writer .","move noopsnapshotwriter and noopsnapshotwriterbuilder out of the test <nl> directory and into the main directory , until we implement the kraft <nl> integration .",1617763620,"remove duplcated code , use common function in utils instead .",0.7686522603034973
Alluxio_alluxio/12665,authorization + listallmybuckets for s3 rest api <cm-sep> remove log <cm-sep> fix checkstyle <cm-sep> fix list buckets to be more correct,"the existing implementation is not v1 or v2 , so this pr implements the v1 api . v2 will come in a later pr .",1608320340,"a few caveats for this pr : <nl> - it turns out the major complexity of this pr is to figure out where to apply umask logic . after a few iterations , i finally put the umask logic into the method in class . the reason behind is that umask only matters for newly created files/directories , and is the critical path for those operations . <nl> - like linux , new files created in alluxio have default permission bits 0 and directories have 0. this is achieved by two different applyumask functions , one for file and one",0.9370272755622864
apache_flink/16161,fix the issue that compactfilewriter wo n't emit endcheckpoint with long.max_value checkpointid even though the inputs end . <para-sep> * / <nl> assert emit inputfile <nl> assert emit endcheckpoint <nl> end input <nl> assert emit endcheckpoint with long.max_value lastly,"this pull request is to fix the issue that compactfilewriter wo n't emit endcheckpoint with long.max_value checkpointid even though the inputs end . <nl> - delete method notifycheckpointcomplete and override method commituptocheckpoint in compactfilewriter <nl> - in method commituptocheckpoint fo compactfilewriter , it call super . commituptocheckpoint and emit endcheckpoint . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the",1623740716,"( please pick either of the following options ) <nl> this change is a trivial work without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing , yarn/mesos , zookeeper :",0.9252091646194458
confluentinc_ksql/6965,"clarifications and more details to klip 0 <para-sep> release target * : version | <nl> a new java api for java developers <nl> command to export existing streams , tables , queries , and custom types to a migration file","as the title says . notable updates and clarifications include : <nl> - how we want to handle potential race conditions <nl> - more details around configs <nl> - clarifying that version numbers need not be consecutive <nl> - a few fixes , such as the fact that is inclusive not exclusive . <nl> see inline comments for more . <nl> docs-only change ( plus a minor update to the migrations tool skeleton , which has yet to be released ) .",1612764749,also minor other doc fixes i encountered while making this patch . <nl> note : i wo n't merge this until i have the embedded connect pr merged ( which is about to come out ) .,0.7675608992576599
elastic_elasticsearch/74432,remove use of spanboostquery <cm-sep> bar boosts on field masking span queries,"spanboostquery will be removed in lucene version . it is currently a no-op anyway , <nl> unless it appears at the top level of a span query tree , in which case it is <nl> equivalent to a standard boostquery . this commit removes references to <nl> spanboostquery from elasticsearch spanquerybuilders , replacing it with <nl> boostquery where appropriate . <nl> it also adds a new , breaking , check to to ensure that <nl> its inner query does not have a boost set on it , bringing it into line with all <nl> other span queries that wrap inner",1624370993,"some callers of only call on it , which is already available on . this commit moves these callers to call directly . <nl> also , the remaining getmapperservice usages in tests can now be removed or replaced .",0.9416489005088806
elastic_elasticsearch/74280,avoid use the same token name in different tests,the name is used in both and . there are times when the two tests are not fully isolated . this leads to test failure because indexing of the service token document must be an . this pr fixes the failure by using a different token name in .,1624001829,the ranges in http headers are using inclusive values for start and end of the range . <nl> the math we used was off in so far that start equals end for the range resulted in length <nl> instead of the correct value of .,0.8708374500274658
crate_crate/11267,"merge pluginloader mechanisms . <nl> this removes the crate specific and instead uses the es <nl> mechanism to load the jmx-monitoring , lang-js , and functions extensions . <nl> used a custom plugin loader mechanism . the idea was that <nl> we 'd distinguish between cratedb plugins and es plugins . but with the <nl> integration of the es code into there is no longer a strong <nl> case for having two loaders . instead the es plugin loading mechanism * is <nl> the * cratedb plugin loading mechanism . <nl> it also looks as if our extension loading mechanism could n't include <nl> additional dependencies which becomes a problem when trying to move from <nl> and directives in the gradle configuration to <nl> , or .","this removes the crate specific and instead uses the es <nl> mechanism to load the jmx-monitoring , lang-js , and functions extensions . <nl> used a custom plugin loader mechanism . the idea was that <nl> we 'd distinguish between cratedb plugins and es plugins . but with the <nl> integration of the es code into there is no longer a strong <nl> case for having two loaders . instead the es plugin loading mechanism * is <nl> the * cratedb plugin loading mechanism . <nl> it also looks as if our extension loading mechanism could n't include <nl> additional",1618394913,running the tests with <nl> uncovered the leak .,0.8280407190322876
ballerina-platform_ballerina-lang/27325,validate service path against listener type <cm-sep> revert previous commit on spec issue 0 <cm-sep> add service ctor as a service attach point,previously only service-decl was considered for service attach point . <nl> fixes # .,1606995806,this pr fixes and enables objectequivalencynegative test case .,0.8501238226890564
jenkinsci_jenkins/5029,"queue ( mainly ) style consistency . <nl> - removal of null check , while annotation + ecosystem search proves it 's never occurring <nl> - small code style <nl> - cleanup of tab vs spaces <para-sep> returns whether the new item should be scheduled . an action should return true if the associated task is 'different enough ' to warrant a separate execution . <nl> returns whether the new item should be scheduled .","- removal of null check , while annotation + ecosystem search proves it 's never occurring <nl> - small code style <nl> - cleanup of tab vs spaces . <nl> ( tip : review the pr with ' whitespace changes ignored ' ) . <nl> 🤷‍♂️ the class is so messy , i tried to keep the changes as small as possible , but there are so many stuff not consistent . <nl> no ticket . <nl> * n/a . <nl> n/a . <nl> - [ n/a ] ( if applicable ) jira issue is well described <nl> - [",1603557565,the logic relied on the monitor being triggered to show more decimals . <nl> the monitor threshold can be set to something other than 1gb . <nl> therefore check the available space instead of the triggered status .,0.8824588060379028
apache_kafka/10764,make sure all fiedls of o.p.k.s.a.action are not null,the kafka plugin needs to take something from field but it does not know whether the field is nullable ( or users need to add null check ) . i check all usages and i do n't observe any null case .,1622008516,"test uses 100ms as and checks that a second reauthentication does n't occur within the hard-coded 0 second minimum interval . but since the interval is small , we can not guarantee that the time between the two checks is not higher than 0 second . change the test to use mocktime so that we can control the time .",0.8657911419868469
confluentinc_ksql/7181,"fix the cache max bytes buffering check . <nl> this patch fixes our validation of cache.max.bytes.buffering . we validate based <nl> on the set of live queries in the engine context . however , we were n't popullating <nl> this set for sandboxes . this is fixed in this change by introducing a sandbox type <nl> for transient query metadata , and filling in the live queries set with sandboxed <nl> query metadatas <para-sep> no-op <nl> given : <nl> when : <nl> then : <nl> when : <nl> then :","this patch fixes our validation of cache.max.bytes.buffering . we validate based <nl> on the set of live queries in the engine context . however , we were n't populating <nl> this set for sandboxes . this is fixed in this change by introducing a sandbox type <nl> for transient query metadata , and filling in the live queries set with sandboxed <nl> query metadatas",1615278139,"adds a plugin that can be used to limit memory across all rocksdb instances and configure the number of threads . <nl> example usage ( add these lines to the server properties file ) : . <nl> in order to configure the total memory and number of threads , checks whether the implements a static method and calls it if so . a drawback to this approach is that the can only be used when the ksql server is started , and not via a statement afterwards . an alternative to having a static method could be to configure the",0.9860803484916687
confluentinc_ksql/7405,exclude stream threads . <nl> ( cherry picked from commit sha ) <para-sep> when <nl> then,"( cherry picked from commit sha ) . <nl> streams no longer sets the java thread uncaught exception handler and instead uses their own . the issue is once a thread has been replaced it throws the exception to finish killing the thread . ksql however sets the java thread uncaught exception handler globally , this calls system.exit ( 0 ) , perviously the streams handler would override this so the stream threads would be excluded but now that is not the case . <nl> we ignore the calls for the stream threads . <nl> unit and integration tests are",1618945433,this patch changes this default to 0 . <nl> unit and integration tests are expected for any behavior changes._ <nl> created and added relevant unit tests <nl> # # # reviewer checklist .,0.9519827365875244
apache_pulsar/10824,"fix consumer stuck issue due to reuse entry wrapper . <nl> 0. add wrapperoffset to make sure get the correct batch size from the metadata <nl> 0. fix the issue that using ( batch count / avgbatchsizepermsg ) to calculate messages for the consumer <nl> it should be ( messages / avgbatchsizepermsg ) <cm-sep> fix comment of the test <cm-sep> fix comment of the test <para-sep> the test case is to simulate dispatch batches with different batch size to the consumer . 0. the consumer has 0 available permits 0. the producer send batches with different batch size according the batch average size dispatching , the broker will dispatch all the batches to the consumer","0. add wrapperoffset to make sure get the correct batch size from the metadata <nl> 0. fix the issue that using ( batch count / avgbatchsizepermsg ) to calculate messages for the consumer <nl> it should be ( messages / avgbatchsizepermsg ) . <nl> * the test case is to simulate dispatch batches with different batch size to the consumer . <nl> * 0. the consumer has 0 available permits <nl> * 0. the producer send batches with different batch size <nl> * <nl> * according the batch average size dispatching , the broker will dispatch all the batches to",1622783144,"this code is to enable non-persistent subscriptions to continue to consume， based on the id of the first message in the client 's receiverqueue when reconnection is triggered . <nl> but it 's not considered the case that there is no messageid for the first connection . therefore , we need to determine whether the messageid is null . <nl> unit test : nondurablesubscriptiontest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api : (",0.9782293438911438
confluentinc_ksql/7268,fix npe when backing a record that has null key/values <para-sep> given <nl> when <nl> then <nl> given <nl> when <nl> then,unit and integration tests are expected for any behavior changes._ .,1616426814,"with this patch , we will print ' null ' instead .",0.8988428711891174
confluentinc_ksql/6927,support timestamp protobuf serde <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> this case is just a string . <nl> given : <nl> when : <nl> then :,this pr adds an extra step before registering protobuf schemas that resolves dependencies .,1612218542,"ensures all commands written to the command topic can be deserialized before writing them . <nl> a non-deserializable command causes the command runner thread to die . <nl> even restarting the server wo n't help as the server will stop when it hits the non-deserializable command again . <nl> this adds some level of protection . <nl> ( i know i 'd previously been against this , but ... meh ... maybe i was wrong ; ) ) . <nl> submitting a statement to the server which the server finds it ca n't deserialize now results in an error and",0.9455247521400452
apache_pulsar/10811,autoconsumeschema decode data with null schema version . <cm-sep> add license header . <para-sep> autoconsumeschema test .,"currently , the autoconsumeschema decode messages which has a null schema version will cause the npe problem . <nl> check the schema version , if the schema version is null , fallback uses the bytes schema to decode . <nl> test decode message data which has a null schema version . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of",1622717702,"upgrade sparkstreamingpulsarreceiver.java use pulsar-client and add spark example . <nl> 0. upgrade sparkstreamingpulsarreceiver.java use pulsar-client , remove pulsar-x pom <nl> 0. add simple spark example . <nl> - [ ✔️ ] make sure that the change passes the ci checks - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding the documentation",0.9634211659431458
jenkinsci_jenkins/5324,"update commons-beanutils to version , adapt stapler <para-sep> ignore <nl> ignore <nl> this test suite contains tests related to commons beanutils use in stapler . beanutils version and newer no longer support the 'class ' attribute due to potential abuse in some applications processing untrusted input . <nl> this jelly page , standalone , does can not resolve the 'my ' tag library <nl> with a groovy wrapper defining the tag library so it can be resolved by class name , it works <nl> we 're called from statictaglibrary , and assumed to be dynatag ( also , taglibrary # gettag is needed , no returning null ! ) <nl> groovy with dynatag works <nl> groovy without dynatag fails -- this seems to be mostly the st.include case that would fail without workaround <nl> this case would fail without the compatibility code : 'class ' attribute set in a groovy view <nl> this case would fail without the compatibility code : 'class ' attribute set in a groovy view","the upside is we 're doing more than just shutting up scanners , the downside is that we 're doing more than just shutting up scanners 😅 . <nl> the fix in stapler may be incomplete ( it assumes the only custom tag with attribute is which seems very optimistic ) , so it probably makes sense to add an escape hatch just in case . <nl> * update commons-beanutils library to version . <nl> * update stapler to version to make the commons-beanutils update work",1614775438,"currently , simply lists all jobs associated with particular view . i propose to traverse all subviews that might be associated . this situation occurs when implements as well . <nl> this change is apparent when nested view plugin is used . a top level view appears empty prior this change while after this change it lists all the jobs transitively contained in the view .",0.9429685473442078
apache_druid/10968,"fix sql issue for group by queries with time filter that gets optimized to false <cm-sep> short circuit always false in combineandsimplifybounds <para-sep> null , the ' universal timestamp ' of nothing <nl> we might sometimes come into here with just a false from optimizing impossible conditions <nl> all and/or filters have at least 0 child <nl> short circuit if can never be true <nl> this gets optimized into 'false '",this results in an unfriendly . <nl> instead of returning empty results . <nl> i also added some additional short circuits for always false conditions in based on observations in debugger while testing this issue,1615285431,"if using the graphite-emitter and , the graphite-emitter currently generates an error for every request log event : allows the graphite-emitter to optionally forward requestlogevents to other emitters instead of generating an error message",0.9321759343147278
elastic_elasticsearch/73762,retry ilm force merge step on shard failures . <nl> this makes the forcemerge step inspect the response of the forcemerge <nl> operation and retry if there are any failed shards . <para-sep> let 's report it as a failure and retry,this makes the forcemerge step inspect the response of the forcemerge <nl> operation and retry if there are any failed shards .,1622808230,"when a search phase fails , we release the context of all successful shards .",0.9518680572509766
apache_druid/11233,"fix jdbc array handling , split handling for some array and multi value operator , split and add more tests <para-sep> we do n't want to stringify arrays for jdbc ever because avatica needs to handle this <nl> these methods can not be mixed ; you must call exactly one . <nl> on the backend , these functions are identical , so these classes only override the signature information . <nl> no instantiation <nl> note : since this function produces an array <nl> use number.class for exact numeric types since json transport might switch longs to integers <nl> use number.class for exact numeric types since json transport might switch longs to integers <nl> the protobuf jdbc handler prefers lists ( it actually ca n't handle java arrays as sql arrays , only java lists ) the json handler could handle this just fine , but it handles lists as sql arrays as well so just convert here if needed <nl> tests for array functions and array types <nl> test some query stuffs , sort of limited since no native array column types so either need to use constructor or array aggregator <nl> without expression output type inference to prevent this , the automatic translation will try to turn this into this error message will get better in the future . the error without translation would be : org.apache.druid.java.util.common.re : unhandled array constructor element type [ string_array ] <nl> array constructor turns decimals into ints for some reason , this needs fixed in the future also , yes these outputs are strange sometimes , arrays are in a partial state of existence so end up a bit stringy for now this is because virtual column selectors are coercing values back to stringish so that multi-valued string dimensions can be grouped on . <nl> these report as strings even though they are not , someday this will not be so <nl> when not stringifying arrays , some things are still stringified , because they are inferred to be typed as strings the planner context which controls stringification of arrays does not apply to multi-valued string columns , which will still always be stringified to ultimately adhere to the varchar type as array support increases in the engine this will likely change since using explict array functions should probably kick it into an array <nl> these report as strings even though they are","this pr also splits up the sql array functions ( prefixed ) from multi value string functions ( prefix ) to allow for subtly different return type reporting and handling ( the primary difference being that functions which return arrays will typically report their output type as instead of an ) . i 've also homogenized the type signatures of these functions to make sure all of the and functions are consistent within the family ( some of the array_ methods were missing handling actual array typed inputs heh ) . <nl> to go along with this split , i",1620727472,"this commit adds the ability to change some master parameters dynamically . thus , you can enter a web console and change these parameters while the master is running . these parameters include : <nl> 0. millistowaitbeforedeleting - time to wait before dropping a segment from a server . <nl> 0. mergebyteslimit - the maximum number of bytes allowed during a segment merge . <nl> 0. mergesegmentslimit - the maximum number of segments that can be merged together . <nl> 0. maxsegmentstomove - the max number of segments the master moves on each run . <nl> the web console interface",0.9619431495666504
jenkinsci_jenkins/5192,"support 'min ' and 'max ' values in the tag . <nl> add the validator for whose clazz is 'number ' , 'number-required ' , 'non-negative-number-required ' , 'positive-number ' , 'positive-number-required ' <para-sep> tests for lib/number.jelly . <nl> simulate human to type string into the , then trigger the onchange event , thus error messages will show . <nl> add a validator for number fields which contains 'min ' , 'max ' attribute <nl> find the validation-error-area","add the validator for whose clazz is 'number ' , 'number-required ' , 'non-negative-number-required ' , 'positive-number ' , 'positive-number-required ' . see demo . <nl> * support 'min ' and 'max ' values in the whose clazz is 'number ' , 'number-required ' , 'non-negative-number-required ' , 'positive-number ' , 'positive-number-required ' .",1611159379,demonstrates some basics of data binding and xstream persistence .,0.9550103545188904
keycloak_keycloak/7940,": make get requests for localization texts public , to display the admin ui correctly , even if the role view-realm is missing .","make get requests for localization texts public , to display the admin ui correctly , even if the role view-realm is missing .",1618560850,": return unauthorized when accessing bearer only in interactive mode . before that fix , instead of returning a 0 the application entered an infinite redirect loop .",0.9192219376564026
apache_camel/5682,"respect the user 's intention to send content-type header without appended charset : <nl> ' application/edifact ' <cm-sep> as2 server : currently there is no means to specify custom mdn template <nl> mdn template from configuration is ignored . <para-sep> mdn response is to be sent anyway , so empty or null value will be treated as if the user does n't know how to compose their own template and/or is satisfied with default one .","currently there is no means to specify custom mdn template . here i mean that i can call the corresponding setter , but the specified template is n't passed deeper and i still get hardcoded template default_mdn_message_template from the class responsemdn - i can see it from my testing . <nl> my changes allow tp pick up the template from the class as2configuration along with many other settings .",1623866327,"~~pulsar messages are currently acknowledged immediately upon consumption . this could lead to lost messages if the application crashes or does not finish its unit of work . in such situations , it may be desirable to leave these messages unacknowledged so that they can be redelivered to another consumer.~~ [ correction march 0 , 0 -- this is not correct . pulsar messages are acknowledged after successful processing of the route , not immediately after consumption from the topic . exceptions or errors on the route will correctly cause the message to remain unacknowledged . ] <nl> allow manual",0.9027538299560547
vespa-engine_vespa/18097,use proton metrics for memory and disk utilization . <nl> since these metrics are use for block decisins they should also be <nl> used for autoscaling . <para-sep> memory util <nl> disk util <nl> query rate write rate <nl> the names of this metric as emitted from its source . a map of the values of these names which were present in the response will be provided to computefinal to decide on a single value . computes the final metric value * /,since these metrics are use for block decisins they should also be <nl> used for autoscaling .,1622664559,* makes it possible to run inside container <nl> * adds host 's hostname to node-repo <nl> * updates 's and,0.9467114806175232
elastic_elasticsearch/73225,the get aliases api should not return entries for data streams with no aliases . <nl> the get alias api should take into account the aliases parameter when <nl> returning aliases that refer to data streams and do n't return entries <nl> for data streams that do n't have any aliases pointing to it . <para-sep> return all all data streams with aliases <nl> filter by alias name <nl> filter by data stream :,the get alias api should take into account the aliases parameter when <nl> returning aliases that refer to data streams and do n't return entries <nl> for data streams that do n't have any aliases pointing to it .,1621412040,"this took me a bit of time so i 'll try to describe what happened . the test failed twice this year ( 0 , 0 ) with a ' resource not exception ' indicating that a task was not correctly created ( the task is a reindexing task ) . <nl> the elasticsearch logs show the following warning messages for both builds failures : <nl> > warn ] [ o.e.t.loggingtasklistener ] 0 failed with exception <nl> > org.elasticsearch.index.mapper.mapperexception : the parameter ca n't be updated for the object mapping . <nl> it indicates that the index was already created",0.9034115076065063
neo4j_neo4j/11668,"increase the swapper id space from 0 bit to 0 bit . <nl> this means that the page cache can now have roughly 0 million files mapped , instead of the version it could handle before . <cm-sep> extract a few constants in pagelist . <cm-sep> reformat pagelist . <cm-sep> try making pagelist.isboundto faster . <para-sep> bytesuse 8sequence lock word . 8pointer to the memory page . 8last modified transaction id . 8page binding . the first 0 bits ( 0 bytes ) are the file page id . the following ( low order ) 0 bits ( 0 bytes and 0 bits ) are the swapper id . the last ( lowest order ) 0 bits are the page usage counter . <nl> the high 0 bytes of the page binding are the file page id . the 0 following lower bits are the swapper id . and the last 0 low bits are the usage counter . <nl> use compareandswaplong to only actually store the updated count if nothing else changed in this word-line . the word-line is shared with the file page id , and the swapper id . those fields are updated under guard of the exclusive lock , but we might race with that here , and in that case we would never want a usage counter update to clobber a page binding update . <nl> see about why we use .","this means that the page cache can now have roughly 0 million files mapped , instead of the version it could handle before . <nl> this is important as we have more and more indexes that are backed by the page cache . <nl> i 'm not sure if we should target this to version or version .",1524832592,previously the port would remain bound until the jvm was terminated .,0.9516770839691162
apache_flink/15450,revert ' temporarily disable streamingkafkaitcase ' . <nl> this reverts commit sha . <cm-sep> add timeout to streamingkafkaitcase,reenable streamingkafkaitcase with added timeout .,1617180859,"fixes an instability in the where the shutdown of the dispatcher caused a slot allocation to fail , resulting in the job failing , reaching a terminal state and afterwards being removed from zookeeper . <nl> we now prevent the job from reaching a terminal state by enabling a fixed-delay restart strategy . should the allocation fail the jm will retry until the jm itself is being shut down . on shutdown the jm will suspend the job , allowing it to be recovered by other dispatchers . <nl> i verified the fix by re-running the test until i ran",0.8569827675819397
vespa-engine_vespa/17922,remove version from help page <cm-sep> remove wip unit test,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621516785,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8523834347724915
vespa-engine_vespa/18223,send empty sentinel config as an empty config . <nl> not as an empty payload . the sentinel will stop services not in the service <nl> array so the result should remain the same .,not as an empty payload . the sentinel will stop services not in the service <nl> array so the result should remain the same .,1623424582,"there is some discrepancy between the list of applications we actually consider when listing versions and computing confidence , and my expectations/what we should do : <nl> the last one should have confidence : high by now , and we should n't show versions with no deployments ( unless when the infradstructure is upgraded and no applications ) . <nl> not sure if it 's caused by not filtering out pr 's , but it 's not wrong .",0.8456224799156189
quarkusio_quarkus/18182,"implement support for ndjson streaming in vertex-web <para-sep> the method returns a multi that needs to be written as server-sent event . we subscribe to this multi and write the provided items ( one by one ) in the http response . on completion , we ' end ' the response if the method returned null , we fail if the provided item is null we fail if the multi is empty , and the method return a multi , we reply with a 0 - no content ( as regular ) if the produced item is a string or buffer , the response.write method is used to write the events in the response if the produced item is an object , the item is mapped to json and included in the section of the event .","i noticed vertx reactive routes support sse but not ndjson ( usually is the one that is used by spring webflux ) . spring webflus was returning before but they are now switching to , this is why i am using that content type . <nl> if this integration is wanted i will polish and write test , otherwise i 'll not waste more time on it , please let me know . <nl> p.s . i did not touch the other supports but the the sse one has a minor bug imho , the function always applies the header",1624800676,"please do n't merge , i will merge it myself .",0.9821164608001709
confluentinc_ksql/7271,enable variable substitution for query-stream and ksql endpoints <para-sep> given <nl> when <nl> then <nl> when <nl> then <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : maybe need to retry as populating agg table is async <nl> then : <nl> given : when : <nl> then :,"for , is a map of initial variable values that can be modified with and statements . <nl> this is a prerequisite for enabling variable substitutions in the java client .",1616453630,"this allows us to make known backwards-compatible changes to ksql that would previously have caused an existing test to fail , e.g . changing the name of the internal topics . with this commit we can mark the old test as only valid up to the last version and create a new version of the test for , with a min version , to test versions going forward . <nl> e.g . <nl> 0. now accepts an optional . <nl> 0. , which is built from , now expects a <nl> 0. no longer takes the param , as it",0.9664636850357056
elastic_elasticsearch/73582,"extend version barrier to all upgrades . <nl> today when upgrading to the next major version we have a so-called <nl> _major version barrier_ : once the cluster comprises nodes of the new <nl> major version then nodes of the previous major version are prevented <nl> from joining the cluster . this means we can be certain that <nl> will never decrease , so <nl> we can implement upgrade logic that relies on the cluster remaining in <nl> its wholly-upgraded state . <nl> this commit generalises this behaviour to apply to all upgrades , so that <nl> we can be certain that will <nl> never decrease in a running cluster . <para-sep> > <nl> > > <nl> note : the notable-breaking-changes tagged regions are re-used in the installation and upgrade guide <nl> tag : :notable-breaking-changes [ ] <nl> details * + <nl> impact * + <nl> end : :notable-breaking-changes [ ] <nl> if the cluster is not fully-formed then the min version is not meaningful <nl> ensures that the joining node 's version is equal or higher to the minclusternodeversion . this is needed to ensure that if the master is already fully operating under the new version , it does n't go back to mixed","today when upgrading to the next major version we have a so-called <nl> _major version barrier_ : once the cluster comprises nodes of the new <nl> major version then nodes of the previous major version are prevented <nl> from joining the cluster . this means we can be certain that <nl> will never decrease , so <nl> we can implement upgrade logic that relies on the cluster remaining in <nl> its wholly-upgraded state . <nl> this commit generalises this behaviour to apply to all upgrades , so that <nl> we can be certain that will <nl> never decrease in a",1622535309,today we document the use of to specify the <nl> addresses of a network interface but do not spell out which parts of <nl> this syntax should be taken literally and which are part of the <nl> placeholder for the interface name . if you get it wrong then the <nl> exception message is confusing too since it uses the results of <nl> which contains much more than just the <nl> name of the interface . <nl> this commit clarifies the docs and the exception message .,0.9205955266952515
elastic_elasticsearch/74260,"disable optimization if we are n't sure its faster . <nl> this disables the filter-by-filter aggregation optimization used by <nl> , , , and aggregations unless <nl> we 're sure that its faster than the ' native ' implementation . mostly this <nl> is when the top level query is empty or we can merge it into the filter <nl> generated by the agg rewrite process . <nl> now that we have hard and fast rules we can drop the cost estimation <nl> framework without too much fear . so we remove it in this change . it <nl> stomps a bunch of complexity . sadly , without the cost estimation stuff <nl> we have to add a separate mechanism for blocking the optimization <nl> against runtime fields for which it 'd be kind of garbage . for that i <nl> added another rule preventing the filter-by-filter aggregation from <nl> running against the queries made by runtime fields . its not fool-proof , <nl> but we have control over what queries we pass as a filter so its not <nl> wide open . <nl> i spent a lot of time working on an alternative to this that preserved <nl> that fancy filter-by-filter collection mechanism and was much more kind <nl> to the query cache . it detected cases where going full filter-by-filter <nl> was bad and grouped those filters together to collect in one pass with a <nl> funny oring collector . it worked . and , if we were super concerned with <nl> the performance of the aggregation it 'd be the way to go . but <nl> it was very complex and it was actually slower than using the native <nl> aggregation for things like and . it was <nl> glorious . but it was wrong for us . too complex and optimized the wrong <nl> things . <nl> so here we are . hopefully this is a fairly simple solution to a sneaky <nl> problem . <para-sep> we know that runtime fields are n't fast to query at all but we expect all other sorts of queries are at least as fast as the native aggregator . <nl> for now any complex union kicks us out of filter by filter mode . its possible that this de-optimizes many ' filters ' aggregations but likely correct when ' range ' , ' date_histogram ' , or ' terms","this disables the filter-by-filter aggregation optimization used by <nl> , , , and aggregations unless <nl> we 're sure that its faster than the ' native ' implementation . mostly this <nl> is when the top level query is empty or we can merge it into the filter <nl> generated by the agg rewrite process . <nl> now that we have hard and fast rules we can drop the cost estimation <nl> framework without too much fear . so we remove it in this change . it <nl> stomps a bunch of complexity . sadly , without the cost estimation",1623958995,the backport required modifications to handle the possibility of multiple mapping types .,0.9711751937866211
apache_pulsar/10420,fix kinesis sink can not retry to send messages . <para-sep> kpl-thread captures publish-failure . fail the publish on main pulsar-io-thread to maintain the ordering,"# # # motivation . <nl> currently , when the kinesis sink connector fails to send a message , it will not retry . in this case , if is enabled , it will lead to subsequent messages can not be sent like the following : <nl> > 0:0 : version [ crm/messaging-service/messaging-service- ] warn org.apache.pulsar.io.kinesis.kinesissink - skip acking message to retain ordering with previous failed message prod_extapi.reply.message-optional . <nl> * add retry logic for the kinesis sink connector . when sending a message fails , it will retry to send . <nl> * disconnect the network <nl> * send",1619606523,"fix break changes in namespace offload policy and rabbitmq sink . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> - the schema : ( no ) <nl> - the default values of configurations : ( no ) <nl> - the wire protocol : ( no ) <nl> - the rest endpoints : ( no ) <nl> - the admin cli options : ( no ) <nl> - anything that affects deployment :",0.9574806690216064
apache_pulsar/11051,"add authoritative flag for topic policy to avoid redirect loop . <nl> 0. add authoritative flag for topic policy to avoid redirect loop <nl> 0. prevent set topic policy on a non-existing topic <nl> 0. prevent set topic policy on a partition of a partitioned topic <nl> 0. redirect to the broker which is owner of the for a partitioned topic when setting topic policy <nl> 0. do n't remove policy cache when the topic removed from the broker , <nl> this will lead to the topic come back , but ca n't find the topic policy , <nl> since the namespace does not removed from the broker , we will not read from <nl> the system topic again . for this case we already handled when the broker does not <nl> provide service for that namespace , the topic policy cache under the namespace will be removed .","0. add authoritative flag for topic policy to avoid redirect loop <nl> 0. prevent set topic policy on a non-existing topic <nl> 0. prevent set topic policy on a partition of a partitioned topic <nl> 0. redirect to the broker which is the owner of the for a partitioned topic when setting topic policy <nl> 0. do n't remove policy cache when the topic removed from the broker , <nl> this will lead to the topic come back , but ca n't find the topic policy , <nl> since the namespace does not remove from the broker , we will",1624464688,"according to , we need to support builder for topicsconsumer . <nl> - add in consumerbuilder <nl> - add test for the builder .",0.9246200919151306
apache_druid/11232,"add auto cleanup <para-sep> for cases where the task method does not throw an exception but still needs retrying , the method can throw this retryableexception so that the retryutils can then retry the task <nl> coordinatorduty for automatic deletion of compaction configurations from the config table in metadata storage . note that this will delete compaction configuration for inactive datasources ( datasource with no used and unused segments ) immediately . <nl> if current compaction config is empty then there is nothing to do <nl> get all active datasources note that we get all active datasources after getting compaction config to prevent race condition if new datasource and config are added . <nl> calculate number of compaction configs to remove for logging <nl> do database insert without swap if the current config is empty as this means the config may be null in the database <nl> failed but is retryable <nl> failed and not retryable <nl> set current compaction config to an empty compaction config <nl> verify and assert <nl> the updated config should only contains one compaction config for the active datasource <nl> should delete 0 config <nl> return fail result with retryableexception the first three call to updated set <nl> return success ok on the fourth call to set updated config <nl> verify and assert <nl> should delete 0 config <nl> should call watch ( to refresh current compaction config ) four times due to retryableexception when failed <nl> should call set ( to try set new updated compaction config ) four times due to retryableexception when failed <nl> should call retrievealldatasourcenames four times due to retryableexception when failed",add feature to automatically remove compaction configurations for inactive datasources . <nl> this pr adds a similar auto cleanup but for the compaction configurations ( which are stored in the druid config table ) to auto clean up compaction configs belonging to datasource that is no longer active -- meaning that the datasource has no used/unused segments . <nl> this is useful when druid user has a high churn of task / datasource in a short amount of time causing the metadata store size to grow uncontrollably,1620713322,"this pr adds long and float implementations of dimensionhandler/dimensionindexer/dimensionmerger , allowing ingestion of long/float typed dimensions . <nl> this also changes the type parameter in the interfaces above to , removing the restriction that the individual fields of row keys during ingestion must be arrays ( to allow for single numeric values in the keys , since long/floats do n't support multivalue rows )",0.9645623564720154
jenkinsci_jenkins/5110,"resolve all core caused illegal reflective access warnings <para-sep> all reflection method initialisation is delayed until first use so that we do n't access the methods if we do n't need to . <nl> pick the last one , which is the one closest to the leaf of the classloader tree .","there 's still illegal reflective access warnings on startup that require library upgrades ( or xstream might need core / plugin tweaks ) : <nl> * guice to version ( only in beta atm ) <nl> * groovy to 0.x <nl> * some xstream ones only triggered in certain circumstances , have n't managed to trigger it in a debugger atm 😢 . <nl> xstream .",1607858195,"rather than catching or providing partial implementation classes , now that we are on java 0 we can add methods . <nl> for now , focusing mainly on methods which were added into existing s and so for which we had special tricks to preserve compatibility , or for which there was already an class pairing . there are plenty of other cases where a method would be sensible and could be added in the future , such as . <nl> none required .",0.9633516073226929
quarkusio_quarkus/17731,"ensure that a non-indexed leaf does n't break generic type resolution . <nl> this can happen if say some interface extends a jdk interface and there <nl> is no reason the type resolution should fail because of it . <nl> ( cherry picked from commit sha ) <cm-sep> catch the proper exception when resolving k8s watcher generic types . <nl> ( cherry picked from commit sha ) <cm-sep> create quarkusdeploymentonlyclasspath instead of detached configuration for the deployment only dependencies . <nl> ( cherry picked from commit sha ) <cm-sep> do n't write error response when it 's already been written . <cm-sep> make vertxinputstream # available not fail on large content-type . <nl> an inputstream can not read over 2gb of memory , but as <nl> is only an estimate , there is no good reason for that specific <nl> method to fail if content-type indicated a larger payload . <nl> whether or not the processing fails or how it proceeds , should <nl> be up to consumer of the stream and will likely have to do with <nl> how is implemented . <cm-sep> bump gradle jandex plugin version in test and doc . <nl> ( cherry picked from commit sha ) <cm-sep> pass max frame size to vertxserverwebsocketcontainer . <nl> ( cherry picked from commit sha ) <cm-sep> correctly propagate dispatchtoworker to websockets . <nl> also use the executor included in the container info even if the code <nl> was working ok . <nl> ( cherry picked from commit sha ) <cm-sep> use version version in the generated projects . <para-sep> keep compatibility with what clients already expect <nl> no un-indexed classes means that there were no problems traversing the class and interface hierarchies <nl> map any returned type parameters to our type arguments on the way down <nl> map any returned type parameters to our type arguments on the way down","please do n't merge , i will merge it myself .",1623075842,"a couple minor optimisations in vertxhttprequest based on profiling data . <nl> also , removed some unused fields .",0.9459364414215088
vespa-engine_vespa/18314,log which tenants we move to none plan <cm-sep> join in stream statement,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1624012572,"i discovered two errors with current implementation . <nl> 0. we have a special hardcoded applicationinstancereference for the config server that did not fit the assumption made in the id conversion to applicationid <nl> 0. the cluster controller path to set all nodes in a cluster in maintenance was wrong . <nl> both have been tested in the dev environment . the clustercontroller path was tested with : . <nl> { <nl> ' wasmodified ' : true , <nl> ' reason ' : ' ok ' <nl> } .",0.9007474184036255
confluentinc_ksql/6797,"bound the size of the shared buffer cache used by queries . <nl> bound the total size of the shared buffer cache used by queries . the <nl> bound is controlled by 0 configs , one for controlling the limit for <nl> persistent queries , the other for transient queries . today , this limit <nl> is implemented by accounting the full limit for each query against the <nl> total bound . in the future we may implement by using a shared cache . <para-sep> hack to get at default config value <nl> validate that a given physical plan can be executed by the underlying runtime . ensures that a given physical plan can be executed by the underlying runtime . it 's important to decouple this from query execution , so that a query can be planned and validated , then committed ( e.g . to a log of queries to be executed ) with the expectation that it should always be able to execute . <nl> given : <nl> when/then : <nl> given : <nl> when/then ( no throw ) <nl> given : <nl> when/then ( no throw ) <nl> given : <nl> when/then : <nl> given : <nl> when/then ( no throw ) <nl> given : <nl> when/then :","bound the total size of the shared buffer cache used by queries . the <nl> bound is controlled by 0 configs , one for controlling the limit for <nl> persistent queries , the other for transient queries . today , this limit <nl> is implemented by accounting the full limit for each query against the <nl> total bound . in the future we may implement by using a shared cache .",1608225679,"this pr explicitly adds the ssl config names to the ksql configuration , extends the prefix to allow ssl overrides specific to the sr to be supplied , and then wires this all up to configure the used by the sr client . <nl> for example , where the same ssl configuration is needed from the schema registry as for the kafka brokers , then config like this can be used : . <nl> where sr requires different configuration , it also supports overrides : . <nl> still to do ... .",0.9835407733917236
elastic_elasticsearch/73267,"introduce an async querying mode for sql . <nl> this adds an async query mode to sql . <nl> it ( re ) uses the same request and response async-specific eql object <nl> parameters . <nl> also similar to eql , the running search task can have its state <nl> monitored and canceled and its results stored and deleted , with <nl> intermediary responses not supported ( the entire result is available <nl> once search finished ) . <nl> the initial query and subsequent pagination/scrolling requests will both <nl> be started in the async mode . <para-sep> internal class for temporary storage of eql search results <nl> update the expiration time of the ( partial ) response . <nl> this method is called when the task is finished successfully before unregistering the task and storing the results <nl> this method is called when the task failed before unregistering the task and storing the results <nl> return currently available partial or the final results <nl> exposes sql async action names for the rbac engine <nl> service for managing eql requests <nl> wrapper for eqlsearchrequest that creates an async version of eqlsearchtask <nl> if we did n't start operation for any reason , we need to clean up the task that we have created <nl> this is will performed in case of timeout <nl> this will be performed at the end of normal execution <nl> we finished before timeout <nl> we finished after timeout - saving results <nl> we finished before timeout <nl> we finished after timeout - saving exception <nl> we should only unregister after the result is saved <nl> adds a self-unregistering listener to a task . it works as a normal listener except it retrieves a partial response and unregister itself from the task if timeout occurs . <nl> timeout was triggered <nl> a response for * ql search status request <nl> get status from the stored ql search response <nl> returns the id of the eql search status request . <nl> this could be either because eql search has n't finished yet , or if it finished and some shards have failed or timed out . <nl> returns a timestamp when the eql search task started , in milliseconds since epoch . <nl> returns a timestamp when the eql search will be expired , in milliseconds since epoch . <nl> for a completed eql search returns the completion","this adds an async query mode to sql . <nl> it ( re ) uses the same request and response async-specific eql object <nl> parameters . <nl> also similar to eql , the running search task can have its state <nl> monitored and canceled and its results stored and deleted , with <nl> intermediary responses not supported ( the entire result is available <nl> once search finished ) . <nl> the initial query and subsequent pagination/scrolling requests will both <nl> be started in the async mode .",1621506563,"the action toggles on the new setting that informs the cluster to tear down any previously created cluster alerts , and after that is accepted , the action immediately attempts a best-effort refresh of cluster alert resources in order to force their removal in case collection is disabled or delayed . <nl> since resources are controlled lazily by the existing monitoring exporters , extra care was taken to ensure that any in-flight resource management operations do not race against any resource actions taken by the migration action . resource installation code was updated with callbacks to report any errors instead",0.9852818250656128
elastic_elasticsearch/73456,fix bug with concurrent snapshot and index delete . <nl> fix state machine bug that fixes the incorrect assumption a finished snapshot delete <nl> could only start shard snapshots when in fact it can also move snapshots to a <nl> completed state . <para-sep> create and delete a snapshot of the given name and for the given single index in a loop until the index is removed from the cluster at which point donelistener is resolved,fix state machine bug that fixes the incorrect assumption a finished snapshot delete <nl> could only start shard snapshots when in fact it can also move snapshots to a <nl> completed state .,1622105077,"we were caching serialized in the newest <nl> metadata format . this lead to a confusing situation where <nl> numeric shard generations would be cached in <nl> that were not written to the repository because the repository <nl> or cluster did not yet support . <nl> in the case where shard generations are not actually supported yet , <nl> these cached numeric generations are not safe and there 's multiple <nl> scenarios where they would be incorrect , leading to the repository <nl> trying to read shard level metadata from index-n that do n't exist . <nl> this commit makes",0.9538641571998596
elastic_elasticsearch/74618,"shard level request cache is now generally supported for queries with dls <nl> and/or fls . the request cache is now enabled following the same rule as a <nl> regular search w/o dls/fls except following few scenarios where the request <nl> cache will still be disabled : <nl> 0. dls query uses a stored script <nl> 0. the search targets any remote indices <nl> 0. the cluster has any nodes older than v7.version . <nl> it is worth noting that the caching behaviour is overall safety over <nl> efficiency . this means two functional equivalent set of dls or fls permissions <nl> can possibly result into different cache entries . we consider this a better <nl> tradeoff due to higher priorities for correctness and security . <para-sep> allows plugins to register a cache differentiator which contributes to the cachekey computation for the request cache . this helps differentiate between queries that are otherwise identical . <nl> sortedset because orders are important when they get serialised for request cache key <nl> todo : should we apply the same logic here as fieldpermissions # limitfieldpermissions , i.e . treat limited-by as queries if original queries is null ? <nl> constructor that enables field-level security based on include/exclude rules . exclude rules have precedence over include rules . * / <nl> sortedset because orders are important when building the request cachekey <nl> interface in es security for objects that can contribute to a cache-key <nl> the overall same grant/except sets but are come from either : 0. just the definition 0. just the limited-by definition 0. both the cache key should differentiate between them <nl> just definition <nl> mixed definition <nl> another mixed definition <nl> just limited by <nl> just limited by is the same as definition because limitfieldpermissions uses limited-by definition if the original permission is match all <nl> create the index with a date field and 0 primary shard with no replica <nl> a doc in the past 0 min <nl> a doc in the future 0 min <nl> first search should only get 0 doc in the past <nl> cache should not be used since dls query uses stored script <nl> search first with power client , it should see all docs <nl> search with the limited client and it should see only one doc ( i.e . it wo n't use cache entry for power client ) <nl> execute",shard level request cache is now generally supported for queries with dls <nl> and/or fls . the request cache is now enabled following the same rule as a <nl> regular search w/o dls/fls except following few scenarios where the request <nl> cache will still be disabled : <nl> 0. dls query uses a stored script <nl> 0. the search targets any remote indices <nl> 0. the cluster has any nodes older than v7.version . <nl> it is worth noting that the caching behaviour is overall safety over <nl> efficiency . this means two functional equivalent set of dls or fls,1624878532,"the action toggles on the new setting that informs the cluster to tear down any previously created cluster alerts , and after that is accepted , the action immediately attempts a best-effort refresh of cluster alert resources in order to force their removal in case collection is disabled or delayed . <nl> since resources are controlled lazily by the existing monitoring exporters , extra care was taken to ensure that any in-flight resource management operations do not race against any resource actions taken by the migration action . resource installation code was updated with callbacks to report any errors instead",0.9907535314559937
apache_druid/10948,"add it <cm-sep> add it <para-sep> load and verify initial data <nl> compaction with perfect roll up . rolls with ' x ' , ' h ' ( for the first and second columns respectively ) should be roll up <nl> verify compacted data compacted data only have one segments . first segment have the following rows : the ordering of the columns will be ' dimb ' , ' dima ' , ' dimc ' ( this is the same as the ordering in the initial ingestion task ) <nl> load and verify initial data <nl> compaction with perfect roll up . rolls with ' x ' , ' h ' ( for the first and second columns respectively ) should be roll up <nl> verify compacted data compacted data only have one segments . first segment have the following rows : the ordering of the columns will be ' dima ' , ' dimb ' , ' dimc ' <nl> load and verify initial data <nl> compaction with perfect roll up . rolls with ' x ' , ' h ' ( for the first and second columns respectively ) should be roll up <nl> verify compacted data compacted data only have one segments . first segment have the following rows : the ordering of the columns will be ' dimc ' , ' dimb ' , ' dima ' <nl> first segments have the following rows : <nl> second segments have the following rows : <nl> third segments have the following rows : <nl> fourth segments have the following rows : <nl> check if there is a valid dimension ordering in the ingestionspec to fall back on <nl> remove all dimensions that does not exist within the indexes from the candidate <nl> sanity check that there is no extra/missing columns <nl> sanity check that all indexes dimension ordering is the same as the ordering in candidate <nl> this value does not matter <nl> valid ordering as although second index has gap , it is still same ordering <nl> no valid ordering as no index as all three dimensions <nl> no valid ordering as ordering is not the same in all indexes <nl> no valid ordering as no index as all three dimensions <nl> no valid ordering as ordering is not the same in all indexes <nl> no valid ordering as no index has all three dimensions <nl>","if ingested data has sparse columns , the ingested data with forceguaranteedrollup=true can result in imperfect rollup and final dimension ordering can be different from dimensionspec ordering in the ingestionspec . <nl> when does this problem happens : . <nl> this can happens when we have sparse columns in the input data and a dimensionsspec with dimension ordering that is not lexicographic . note that this isn ’ t limited to compaction but can also occurs in initial batch ingestion of data ( index task ) . <nl> root cause : . <nl> this bug occurs when all the dimensions",1614931172,"sometimes it 's hard to validate if different versions of druid generate the same data for a segment . for example , if null-handling changes then segment sizes and dimension offsets in metadata can be different between two segments . i added a cli tool that utilizes to validate segments which can be used as following : . <nl> where and are directories that consist of segment files ( version.bin , etc ) . <nl> while doing this , i found bugs in that could lead incorrect validation . the first is to throw dimension value lengths not equal exception",0.9798637628555298
jenkinsci_jenkins/5398,fix java11 telemetry test broken after end of its sendings,"this fixes the test error because of java11 telemetry has reached its end , so the sendings do n't take place anynmore . the test was not taking this into account , now it is . <nl> no entry required",1617790802,add headers x-hudson-job and x-hudson-result to e-mail notification for filtering purposes .,0.88936448097229
apache_pulsar/10612,setup intial namespaces with metadatastore <para-sep> create specified tenant <nl> create specified namespace <nl> missing arguments <nl> invalid namespace,"refactor the initial namespaces setup command to use the new api . <nl> explain here the context , and why you 're making that change . what is the problem you 're trying to solve . <nl> describe the modifications you 've done . <nl> this change is already covered by existing tests , such as * * . <nl> ( or ) . <nl> this change added tests and can be verified as follows : <nl> - added unit tests for the command . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does",1621262417,- and fixed deprecated method in unit test . ( use intead of ) .,0.9271933436393738
ballerina-platform_ballerina-lang/26864,fix simpleconstantaccessinbalotest <cm-sep> fix mapconstantequalityindifferentbalotest <cm-sep> fix closedrecordtypereferencetest,- simpleconstantaccessinbalotest <nl> - mapconstantequalityindifferentbalotest <nl> - closedrecordtypereferencetest .,1605090899,language server test cases were fixed separately .,0.8160896301269531
apache_druid/11009,auto-compaction with segment granularity should skip segments that already have the configured segmentgranularity <cm-sep> auto-compaction with segment granularity should skip segments that already have the configured segmentgranularity <cm-sep> auto-compaction with segment granularity should skip segments that already have the configured segmentgranularity <para-sep> 0 segments across 0 days ( 0 total ) ... <nl> compacted without segmentgranularity in auto compaction config <nl> segments were compacted and already has day granularity since it was initially ingested with day granularity . now set auto compaction with day granularity in the granularityspec <nl> should be no new compaction task as segmentgranularity is already day <nl> 0 segments across 0 days ( 0 total ) ... <nl> compacted without segmentgranularity in auto compaction config <nl> segments were compacted and already has day granularity since it was initially ingested with day granularity . now set auto compaction with day granularity in the granularityspec <nl> there should be new compaction tasks since segmentgranularity changed from day to year <nl> only checks for segmentgranularity as auto compaction currently only supports segmentgranularity <nl> candidate segments were all compacted without segment granularity set . we need to check if all segments have the same segment granularity as the configured segment granularity . <nl> month of feb month of jan <nl> same indexspec as what is set in the auto compaction config <nl> same partitionsspec as what is set in the auto compaction config <nl> create segments that were compacted ( compactionstate ! = null ) and have segmentgranularity=day <nl> auto compaction config sets segmentgranularity=day <nl> same indexspec as what is set in the auto compaction config <nl> same partitionsspec as what is set in the auto compaction config <nl> create segments that were compacted ( compactionstate ! = null ) and have segmentgranularity=day <nl> auto compaction config sets segmentgranularity=day <nl> same indexspec as what is set in the auto compaction config <nl> same partitionsspec as what is set in the auto compaction config <nl> create segments that were compacted ( compactionstate ! = null ) and have segmentgranularity=day <nl> auto compaction config sets segmentgranularity=year <nl> we should get all segments in timeline back since skip offset is p0d . <nl> no more <nl> same indexspec as what is set in the auto compaction config <nl> same partitionsspec as what is set in the auto compaction config <nl> create segments that were compacted ( compactionstate ! = null ) and have,"auto-compaction with segment granularity should skip segments that already have the configured segmentgranularity . <nl> auto-compaction now supports setting segmentgranularity . however , it currently submits compaction tasks unnecessary for segments that was compacted ( lastcompactionstate ! = null ) but lastcompactionstate.getgranularityspec ( ) == null ( i.e . compacted when the auto compaction spec does not set segmentgranularity ) and the segments ' segmentgranularity is already the same as the segmentgranularity configured in the auto compaction spec . this change will make auto compaction checks the existing segments ' segmentgranularity and determine if compaction is needed or not even",1616030210,"this pr adds a new dimfilter that provides a convenient syntax for range filtering on long millisecond timestamp columns . <nl> the new intervaldimfilter accepts an array of iso 0 intervals , converts them into startmillis/endmillis ranges . <nl> its tofilter ( ) method converts the intervaldimfilter to an or of boundfilters from those millisecond ranges . <nl> the pr also adds a test/docs demonstrating a basic retention analysis example , using the new time interval filter .",0.9751059412956238
apache_druid/11058,"add a planner rule to handle empty tables <para-sep> the resources found in the plannercontext can be less than the datasources in the query plan , because the query planner can eliminate empty tables by replacing them with inlinedatasource of empty rows . <nl> this rule is used when the query directly reads in-memory tuples . for example , is reduced to . this rule will be used for this case as well . <nl> can not vectorize inline datasource <nl> skip vectorization since otherwise the ' context ' will change for each subtest . <nl> hashjoinsegmentstorageadapter is not vectorizable <nl> hashjoinsegmentstorageadapter is not vectorizable <nl> milliseconds of timestamps as if they were in utc . this looks strange but intentional because they are what calcite gives us . see druidlogicalvaluesrule.getvaluefromliteral ( ) and calcites.calcitedatetimeliteraltojoda . <nl> hashjoinsegmentstorageadapter is not vectorizable","this pr adds a new planner rule , , that can interpret logical tuples into . this can be useful when you have a query that calcite can reduce empty tables into empty tuples . for example , given a query of , calcite can reduce this query to . <nl> before this pr , druid used calcite to execute simple queries without the from clause , such as . after this pr , druid will be able to execute those queries using regular druid query engine with . <nl> druid sql now uses the druid query engine to process",1617231456,added a new method in the for computing result-level cache keys . <nl> made havingspec cacheable and implemented for subclasses <nl> added unit tests for,0.9557744860649109
apache_druid/11084,add docs <para-sep> remove audit logs created older than the given timestamp . <nl> do delete <nl> verify the delete <nl> do delete <nl> verify that entry was not delete <nl> binding for set of indexing service coordinator ddty <nl> binding for set of metadata store management coordinator ddty,add feature to automatically remove audit logs based on retention period . <nl> this pr adds a similar auto cleanup based on duration ( time to retained ) but for the audit table ( using the coordinator duty instead of overlordhelper ) . <nl> this is useful when druid user has a high churn of task / datasource in a short amount of time causing the metadata store size to grow uncontrollably,1617925856,this pr adds a table to the pool of system tables . this would allow to query the supervisors via druidsql,0.971615731716156
elastic_elasticsearch/72555,service accounts - audit logging for service token name <cm-sep> service accounts - audit for security config change . <nl> add security_config_change auditing for create and delete index-based <nl> service account tokens . <para-sep> clear log <nl> clear log,add security_config_change auditing for create and delete index-based <nl> service account tokens .,1619789280,"we recently rewrote the code to encapsulate the rollover into a single <nl> cluster state . this is great , but we can do a bit better when there are concurrent rollover requests <nl> that occur , specifically , we should meet both of the following criteria : . <nl> - multiple concurrent unconditional rollovers should generate multiple rollovers without any concurrent <nl> modification exceptions . <nl> - multiple concurrent rollovers with conditions should roll over exactly once , assuming the <nl> condition is met only once . <nl> this commit changes the code to reach these goals . it",0.960801362991333
apache_camel/5514,: fixed property placeholder not working in marshal/unmarshal ( ref ) . <cm-sep> fix concurrent bug with multiple attachments,the fix is remove attachments after iteration avoiding concurrentmodificationexception . <nl> i added a test to cover multiple attachments scenario .,1620235234,"this prevents propagation of headers when consuming from kafka or producing back to kafka . the values of these headers are populated by the from values specific to a consumed kafka record , such as the timestamp or topic , and do not make sense once going to the scope of a new produced kafka record which has its own values for topic and timestamp .",0.9440445303916931
apache_shardingsphere/10830,update aesencryptalgorithm.java . <nl> improvement base64 encode decode performance . totally increase almost over 0 %,improvement base64 encode decode performance . totally increase almost over 0 % . <nl> fixes apache base64 encode decode low performance issue .,1623815761,changes proposed in this pull request : <nl> - remove some space line <nl> - change get class name method <nl> -,0.8373517990112305
Alluxio_alluxio/12845,use java 0 new time implementation <cm-sep> format,"can return incorrect time , and inodesyncstream can return negative elapsed time for a sync job . <nl> this changes time calculation to use java 0 new time implementation for precision and thread safety .",1613103436,web ui might fail to load if anything given under prefix is required to load the under file system . <nl> this fix makes the web ui to use which takes properties with prefix when initializing the ufs . <nl> will port to version branch once approved .,0.8914251327514648
apache_beam/14644,add support for parquetio sink to pass an avro model to avroparquetwriter,"extend the parquetio sink builder to accept an avro data model that can then be passed to the avroparquetwriter . <nl> this is needed to better specify the genericdata model in case is needed to read/write avro genericrecord . avroparquetwriter set by default the specificdata model , which could create inconsistencies when reading genericrecords with a genericdata model",1619429517,"adds for overriding the query planner specified in pipelineoptions . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9328159093856812
apache_pulsar/10619,converted bundle split into an http async operation,"the bundle split operation should not keep the jetty thread blocked while the split is being done , to avoid having a deadlock when broker is trying to make other calls to http service .",1621295574,"if there has a partitioned topic with too many partitions , users need to get all partition and unload them one by one . we need to support unload all partition of a partitioned topic .",0.9558152556419373
apache_kafka/10631,try removing hamcrest <cm-sep> updating test <cm-sep> clean up,"we currently use imports to check the outputs of the , but with the new gradle updates , the proper hamcrest imports are no longer included in the test jar . <nl> this is a bit of a workaround to remove the hamcrest usage so we can get system tests up and running again . potential follow-up could be to update the way we create the test-jar to pull in the proper dependencies .",1620170466,do n't throw topologybuilderexception during runtime .,0.9022486209869385
apache_pulsar/10691,avoid making copies of internal maps when iterating,"in several places in the code when iterating over the custom hashmaps , we are taking over a copy of the map . this was done every time the iteration could end up modifying the map , since there was a non-reentrant mutex taken during the iteration . any modification would lead to a deadlock .",1621884072,"is a serializable class because clientconfig is used in storm and spark adapter to pass client configuration and storm serializes and deserializes spout and bolt while executing them in topology . now , after making transient variable storm always deserializes it as null and authentication fails . also is a serializable class so , any auth-implementation must be serializable .",0.893309473991394
apache_kafka/10749,"acl authentication , host field support ip network segment <cm-sep> : use uncheckedioexception when wrapping ioexception <cm-sep> restore the variation of without the main branch <para-sep> when there is only a single voter , become candidate immediately <nl> create the snapshot directory if it does n't exists",the raft module may not be fully consistent on this but in general in that module we have decided to not throw the checked ioexception . we have been avoiding checked ioexception exceptions by wrapping them in runtimeexception . the raft module should instead wrap ioexception in uncheckedioexception . this change should be limited to the raft module .,1621839732,"this is a general change and is re-requisite to allow streams benchmark test with different streams tests . for the streams benchmark itself i will have a separate pr for switching configs . details : . <nl> 0. create a ' streams.properties ' file under persistent_root before all the streams test . for now it will only contain a single config of state.dir pointing to persistent_root . <nl> 0. for all the system test related code , replace the main function parameter of state.dir with propsfilename , then inside the function load the props from the file and apply overrides",0.9452126026153564
elastic_elasticsearch/74506,"[ ml ] ensure progress is complete by the time dfa job stops . <nl> the reason this may happen is that we persist progress asynchronously <nl> except for when we 're marking the task complete . when we mark the task <nl> complete , we make another try to persist complete progress . however , <nl> we skip persistence if the existing progress document is the same . <nl> those previous fire-and-forget index requests may end up processed <nl> in a different order resulting into overwriting a latter progress <nl> document . <nl> this commit fixes this by making the progress persist calls at <nl> the end of each step wait for the index request to complete . in <nl> addition , we abort persisting state if the task has been cancelled . <para-sep> we persist progress at the end of each step to ensure we do not have to repeat the step in case the node goes down without getting a chance to persist progress .","the reason this may happen is that we persist progress asynchronously <nl> except for when we 're marking the task complete . when we mark the task <nl> complete , we make another try to persist complete progress . however , <nl> we skip persistence if the existing progress document is the same . <nl> those previous fire-and-forget index requests may end up processed <nl> in a different order resulting into overwriting a latter progress <nl> document . <nl> this commit fixes this by making the progress persist calls at <nl> the end of each step wait for the index",1624465910,"this works now because all mappedfieldtype <nl> constructors have either a specified analyzer , or a default , to pass to <nl> textsearchinfo . to ensure that this continues to be the case , this <nl> commit adds a null check to textsearchinfo 's analyzer parameters .",0.9111771583557129
trinodb_trino/7728,"rename tests to reveal difference . <nl> and do not really describe what they <nl> are supposed to be covering . <cm-sep> improve formatting of an exception message <cm-sep> group related test assertions together . <nl> most of the test code covering required partition filter was just <nl> repeated setup code , with very slight differences . the differences did <nl> not make reading easier though . the commit removes the duplication . <para-sep> no partition filter <nl> partition filter that gets removed by planner <nl> equality partition filter <nl> is not null partition filter <nl> predicate involving a cast ( likely unwrapped ) <nl> partition predicate in outer query only <nl> analyze <nl> join on partition column allowing filter inference for the other table <nl> join on non-partition column","most of the test code covering required partition filter was just <nl> repeated setup code , with very slight differences . the differences did <nl> not make reading easier though . the commit removes the duplication .",1619209616,"allow presto to correctly read from exernal hive tables that use to sotre null in an alternate format . <nl> this works with , , and formats . there are no tests for the latter two ( because they ca n't be easily embedded in the tests because they are binary file formats and presto ca n't insert data into external hive tables ) .",0.9023315906524658
apache_pulsar/10601,"fix getting partition metadata of a nonexistent topic returns 0 <para-sep> the topic may be a non-partitioned topic , so check if it exists here . however , when checkallowautocreation is true , the client will create the topic if it does n't exist . in this case , means the automatically created topic is a non-partitioned topic so we should n't check if the topic exists . <nl> todo : there 're some gaps between non-persistent topics and persistent topics , so some checks will be skipped for non-persistent topics . after the gaps were filled , we can remove this check . <nl> todo : for non-persistent topics getlist will return 0 <nl> todo : for non-persistent topics , deletesubscription might throw notfoundexception <nl> todo : for non-persistent topics , deletesubscription wo n't fail <nl> todo : for non-persistent topics , getsubscriptions will return a empty set <nl> todo : for non-persistent topics , deletesubscription might throw notfoundexception <nl> todo : for non-persistent topics , getsubscriptions will return a empty set <nl> todo : for non-persistent topics , the subscription does n't exist <nl> todo : for non-persistent topics , the subscription does n't exist <nl> todo : for non-persistent topics , skilallmessages will cause 0 internal error <nl> todo : for non-persistent topics , deletesubscription might throw notfoundexception <nl> todo : for non-persistent topics getlist will return 0","the reason is when tries to get partition metadata , the query param is false , so the topic existence check will never be performed . <nl> - check if the topic exists when the partition 's metadata is 0 and is false . see comments for detail explanations . <nl> - change the current tests to make sure the check works . <nl> this change is already covered by existing tests , such as adminapitest # partitionedtopics .",1621176753,enable messaging tests to integration tests .,0.9611226320266724
apache_druid/10754,"properly handle child matchers that return the original mask . <nl> this happens when a child matcher is literally true ( for example , <nl> booleanvectorvaluematcher ) . in this case , orfilter would throw this <nl> exception from its call to removeall while processing the next filter : . <nl> java.lang.illegalstateexception : 'other ' must be a different instance from 'this ' . <nl> also update the javadocs for vectorvaluematcher to call out that the <nl> returned object may be the same as the input mask . <para-sep> ' other ' can not be the same instance as this object . does not modify ' mask ' . <nl> initialize retval = currentmatch , the rows matched by the first matcher . we 'll add more as we loop over the rest of the matchers . <nl> basematchers [ i ] matched every remaining row . short-circuit out .","this happens when a child matcher is literally true ( for example , <nl> booleanvectorvaluematcher ) . in this case , orfilter would throw this <nl> exception from its call to removeall while processing the next filter : . <nl> java.lang.illegalstateexception : 'other ' must be a different instance from 'this ' . <nl> also update the javadocs for vectorvaluematcher to call out that the <nl> returned object may be the same as the input mask .",1610576316,"this pr adds a new dimfilter that provides a convenient syntax for range filtering on long millisecond timestamp columns . <nl> the new intervaldimfilter accepts an array of iso 0 intervals , converts them into startmillis/endmillis ranges . <nl> its tofilter ( ) method converts the intervaldimfilter to an or of boundfilters from those millisecond ranges . <nl> the pr also adds a test/docs demonstrating a basic retention analysis example , using the new time interval filter .",0.9424352049827576
vespa-engine_vespa/17917,add cli interface of vespa-feed-client <para-sep> parses command line arguments <nl> main method for cli interface,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621511010,"i have not connected this to any build mechanism yet . also , while it built successfully in its previous location , i have n't tested it for building here yet .",0.9915913343429565
apache_shardingsphere/10372,support mysql create udf statement execute <para-sep> mysql create loadable function statement .,changes proposed in this pull request : <nl> - support mysql create udf statement execute,1621307951,changes proposed in this pull request : <nl> - add drop_role and set_default_role.xml <nl> - add setdefaultrole role in mysqlstatement.g4,0.9257667064666748
OpenAPITools_openapi-generator/9251,"overhaul pistache templates <para-sep> / helper function to handle unexpected exceptions during parameter parsing and validation . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during processing of the request in handler functions . / may be overriden to return custom error formats . / <nl> / <nl> / / validate a string against the full-date definition of rfc 0 , section version . / <nl> / / validate a string against the date-time definition of rfc 0 , section version . / <nl> / / determine if the given vector only has unique elements . t must provide the == operator . / <nl> compare every element of vec to every other element of vec . this is n't an elegant way to do this , since it 's o ( n^0 ) , but it 's the best solution working only with the == operator . this could be greatly improved if our models provided a valid hash and/or the < operator <nl> / / validate the current data in the model . throws a validationexception on failure . / <nl> / / validate the current data in the model . returns false on error and writes an error / message into the given stringstream . / <nl> helper overload for validate . used when one model stores another model and calls it 's validate . <nl> / / helper function to handle unexpected exceptions during parameter parsing and validation . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during processing of the request in handler functions . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during parameter parsing and validation . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during processing of the request in handler functions . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during parameter parsing and validation . / may be overriden to return custom error formats . / <nl> / / helper function to handle unexpected exceptions during processing of the request in handler functions . / may be overriden to return","this pr includes a variety of smaller changes , as well as implementing model validation for the pistache c++ server . <nl> - generate arrays with as s. the current implementation used a type called which did not exist and caused build issues . <nl> - implement the operator ( and ) for model classes . this is needed for checking if an array only has unique elements . <nl> - change get functions for array type . they now just return a vector , instead of a const reference to the vector . this copies the underlying vector ,",1618313607,"this pr only removes typemapping for ' list ' . all other custom mappings ( e.g . ' uuid ' ) still remain . while i believe they must not be there also , i 'm being conservative to minimize the impact .",0.9272456169128418
vespa-engine_vespa/17612,"change the way we switch connection when the current one is not working . <nl> consider only healthy sources ( if there are any ) when switching to <nl> a new one fue to failures . <nl> also log when connecting to a source <para-sep> sets the current jrtconnection instance by randomly choosing from the available sources and returns the result . <nl> todo : exposes implementation , try to remove",consider only healthy sources ( if there are any ) when switching to <nl> a new one due to failures . <nl> also log when connecting to a source .,1619511074,acl scheduler will be removed in next pr,0.9665095806121826
vespa-engine_vespa/17969,do n't create test driver twice,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621947845,"no longer return empty response with content-type , instead use ( only used by 0 endspoints ) . <nl> return better json responses for restart and deactivate application . <nl> in access logs i only found a few s , few requests from browsers and 0 % from , all of which should handle this change . ( current will return a for restart/deactivate , so that will be a json string , we can change that to just extract the message field later .",0.9013497233390808
confluentinc_ksql/6790,improve error messages on invalid group bys <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when / then :,"tl ; dr this pr improves error messages on invalid statements involving group bys . <nl> the long version : currently , in the logical planner when we build aggregate nodes , validation is split across the logic for building the aggregate schema ( ) and for performing the aggregate analysis ( ) . the former throws a nice error message if the statement contains a function call that doesn ’ t exist . the latter throws a nice error message if the group by expressions contain window bounds ( since does n't support that today ) . however ,",1608154057,"some applications need to have nullable fields in their output avro schema so this pr will use type for output avro schema where the type consists of two types , and the actual type of the field . <nl> by default the types are nullable now .",0.9521501660346985
apache_incubator-pinot/6507,"add access controll for rest endpoints of controller <para-sep> note : this method is only used fore read access . it 's being deprecated and its usage will be replaced by method with accesstype.read . <nl> return whether the client has permission to the given table <nl> return whether the client has permission to access the epdpoints with are not table level <nl> utility class to simplify access control validation . this class is simple wrapper around accesscontrol class . <nl> validate permission for the given access type against the given table <nl> validate permission for the given access type for a non-table level endpoint <nl> validate permission for the given access type against the given table <nl> different access types used in access control of the rest endpoints <nl> annotation to be used on top of rest endpoints . <nl> a container filter class responsible for automatic authentication of rest endpoints . <nl> check if authentication is required <nl> perform authentication : note that table name is extracted from ' path parameters ' or ' query parameters ' if it 's defined as one of the followings : - ' tablename ' , - ' tablenamewithtype ' , or - ' schemaname ' if table name is not available , it means the endpoint is not a table-level endpoint . <nl> validate permission","- if an endpoint requires authentication , it can be simply annotated with annotation with parameter . this will trigger automatic authentication . <nl> - authentication happens in a container filter - - which automatically gets called before execution of each endpoint . <nl> - checks if annotation is available on the requested endpoint . if available , then it calls object to perform actual authentication . <nl> - the described approach works just fine for the endpoints that are not table level . in other words , they do n't require table name for authentication . <nl> - for",1611964522,created joint table for storing dependencies . used jpa annotations as well as a joint table entity ( emailfunctiondependency ) . updated emailreportjob to retrieve anomalies by function ids . added anomalyresult endpoints to retrieve by function .,0.9722285866737366
Alluxio_alluxio/13675,"cherry-pick without resolving conflict <para-sep> when we pin a file with default min replication ( zero ) , we bump the min replication to one in addition to setting pinned flag , and adjust the max replication if it is smaller than min replication . <nl> when we unpin a file , set the min replication to zero too . <nl> pinning status has changed , therefore we change the medium list with it .",0. added more comprehensive testing <nl> 0. correct client side file info <nl> 0. have the pinning status of a directory propagated to the files .,1624293009,"we should never call mkdirs with because ufs does not know about the ancestor inode permission in alluxio namespace . instead , all the missing ancestor directories in ufs should be created from top to the bottom , with the corresponding permission in inode . <nl> currently there are two places where we set to true , one is persist command , the other one is rename with creating missing dst partent directories in ufs .",0.9525299072265625
vespa-engine_vespa/17105,assess if impact is greater than upgrade policy . consider config and proxy node types <para-sep> add config nodes and parents <nl> add routing nodes and parents,consider config and proxy node types . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616432140,separated out the capacity checking part of the maintainer for reuse in an endpoint . <nl> made an endpoint to explain why the capacity checker got to the conclusions it did .,0.9753316044807434
jenkinsci_jenkins/5283,remove broken upgrade wizard <para-sep> put here the different changes that are enforced after an update . <nl> disable the legacy system of api token only if the new system was not installed in such case it means there was already an upgrade before and potentially the admin has re-enabled the features <nl> has the setup wizard been completed ? <nl> create an admin user by default with a difficult password <nl> no longer persisted,"upgrade wizard has n't functioned since version , since the initial upgrade it was serialised to disk and was never recalculated , also broke it as well . <nl> the ui for the wizard is completely broken and does n't look worth saving . <nl> none",1613117341,"as discussed in jenkins security advisory 0-0-0 these services are vulnerable to / 0. the security release disables these protocols but they should be completely removed to finish the clean up . <nl> i can post in the user and dev lists to see if anyone objects to this removal . <nl> * remove network discovery services ( udp and dns ) . <nl> network discovery features , dns multicast and udp broadcast , were previously disabled and discouraged because of various problems including jenkins security advisory 0-0-0. they have now been removed . there is no replacement . <nl>",0.9788954257965088
apache_incubator-pinot/6530,update dimtablesegmentassignment to include both offline and realtime servers . <para-sep> returns the server instances in the cluster for the given tenant .,we want dimension tables to be distributed to realtime servers as well as offline servers to enable ' realtime fact table to dimension table joins ' .,1612306645,"0. store the message and stack trace of the exceptions that are induced during task execution . <nl> 0. if more than 0 % of dimension exploration or 0 % of merged anomaly updates fail , the task becomes failed instead of complete . the error message will be logged in te 's db . <nl> tested on local anomaly detection .",0.9310603141784668
apache_incubator-pinot/7086,"optimize basesinglesegmentconversionexecutor by skipping task if crc not match <para-sep> if the segmentzkmetadata is null , it is likely that the segment has been deleted , return 0 as crc in this case , so that task can terminate early when verify crc . if we throw exception , helix will keep retrying this forever and task status would be left unchanged without proper cleanup .","without this logic , minion will start the task blindly and fail when uploading new segment , which will make minion do unnecessary works and increase the waiting time of other tasks .",1624492180,"there are two issues : . <nl> * when a new byte column is added to the schema , our current code does not update the with the length of default value in local metadata during the reload , which makes the assertion failed like below : . <nl> * when fetching the column metadata from schema , the current code does not convert the byte array of default in schema to make the comparison with the one in local metadata . <nl> this pr fixes these bugs and unit test added .",0.8993757963180542
Alluxio_alluxio/12658,change to journal large table partitions separately <para-sep> next available id : 0 <nl> next available id : 0 <nl> separate the possible big table entry into multiple smaller table partitions entry <nl> should not reach here <nl> add a list of partitions . <nl> add partitions to the current table .,"when a table has thousands of partitions , the journal entry size can be bigger than 30mb ( an example journal entry with about 0 partitions takes 31mb disk space ) . <nl> alluxio embedded journal raft library - ratis currently hard-coded the largest journal entry as 30mb which means that all journal entries bigger than 30mb is not allowed in the read path . <nl> this pr change from journaling a table with a single big entry to multiple smaller entries by journaling table partitions in different entries . <nl> table entries in backup files created before this change",1608169230,"- change in cli , a new option is added to show the source of a configuration in the following two cases : . <nl> - change in configuration tab of webui : add a new column to show the source of each configuration property .",0.9573211669921875
apache_pulsar/10386,fix primary schema upload for always_compatible strategy . <para-sep> bytes [ ] schema and bytebuffer schema does not upload schema info to the schema registry <nl> try to upload the schema again .,"currently , if using the always_compatible strategy and primitive schemas , only the first primary schema can upload to the schema registry , the root cause if we are checking the hash of the schema data , if the hash equals to the existing hash , the new schema will be skipped and return the existing schema . <nl> this will not express the real schema since the primary schema has empty schema data but different schema types . so this pr removed the hash comparison when put a schema to the schema storage . <nl> currently , we are",1619445741,- broker lookup gives npe when it could n't find any available broker and it should be handle with correct error-msg . <nl> handle npe when lookup does n't find available broker .,0.8975083827972412
vespa-engine_vespa/17822,"type resolving for constants . <nl> * wire in constants named directly in type resolving <nl> * add unit test that would fail without this wiring <cm-sep> also add rank properties for ' constant ( foo ) ' . <nl> * constanttensortransformer was trying to handle both ' foo ' and ' constant ( foo ) ' , <nl> but the latter would lookup ' constant ' not ' foo ' in the map . <nl> * add unit test for this variation also . <para-sep> the name of a constant feature ?",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner . <nl> the alternative is to deprecate this completely and remove various unit tests ( and .sd parsing ) .,1620740362,- and allow building an endpoint from url <nl> - i think this is a public api ( ? ) but the abi spec is empty - not sure what is missing <nl> - adding a method should not cause a problem afaik,0.9337443709373474
grpc_grpc-java/7790,"make the timing restriction of subchannel creation stricter . throw at subchannel creation if the channel is being shutting down and the delayed transport is terminated ( aka , all retry calls has been finished ) . <para-sep> no new subchannel should be created after load balancer has been shutdown .","throw for subchannel creation if the channel is being shutting down and the delayed transport is terminated ( aka , all retry calls has been finished ) . <nl> this enforces a tighter timing restriction on load balancer implementations to ensure no subchannel should be created after the balancer itself has been shut down . a load balancer implementation may not always check its state before creating new subchannels . they can be out of sync when the subchannel creation is queued and executed later . we had run into exceptions below in xds where priorityloadbalancer enqueues addresses propagation to",1610069518,"preparing to support server side keepalive . <nl> for the convience on server side , not to use ping callback to cancle shutdownfuture any more , instead , regard as ping ack and cancel shutdownfuture in it .",0.8675256967544556
elastic_elasticsearch/74557,increase default api key auth cache size to 25k . <nl> this pr increases default size of the api key auth cache from 10k to 25k <nl> to cover the majority of expected deployment sizes . also add trace and warning <nl> loggings on eviction for the api key auth cache to help identify potential cache <nl> thrashing issues . <para-sep> package private for test <nl> fill the cache <nl> wait for the entry to expire <nl> cache a new entry <nl> fill the cache <nl> prepare the warning logging to trigger <nl> ensure the counter is updated <nl> will not log warning again for the next eviction because of throttling,this pr increases default size of the api key auth cache from 10k to 25k <nl> to cover the majority of expected deployment sizes . also add trace and warning <nl> loggings on eviction for the api key auth cache to help identify potential cache <nl> thrashing issues .,1624537410,"today a transport response uses the same wire format version as the <nl> corresponding request . this mostly works since we mostly know we are <nl> communicating with a node with a compatible version . tcp handshakes do n't have <nl> this guarantee since they use <nl> to let us handshake with older nodes . this results in the strange situation of <nl> a node of major version responding to a node of major version using a <nl> wire format of version . <nl> we put extra effort into the longer bwc requirements for successful responses , <nl> but we",0.9612118005752563
Alluxio_alluxio/13533,"when alluxio use hdfs client to read ec files , the client will use the contextclassloader to initialize codecregistry which will load rawerasurecoderfactory . the classloader of hdfs configuration should be the same with codecregistry , otherwise we will get the error java.lang.noclassdeffounderror : could not initialize class org.apache.hadoop.io.erasurecode.codecregistry . <para-sep> the minimum hdfs production version required for ec . * * / <nl> name of the class for the hdfs ec codec registry . * * / <nl> when hdfs version is version or later , initialize hdfs ec codecregistry here to ensure rawerasurecoderfactory implementations are loaded by the same classloader of hdfsconf .","when alluxio use hdfs client to read ec files , the client will use the contextclassloader to initialize codecregistry which will load rawerasurecoderfactory . the classloader of hdfs configuration should be the same with codecregistry , otherwise we will get the error java.lang.noclassdeffounderror : could not initialize class org.apache.hadoop.io.erasurecode.codecregistry .",1622629352,example output for user log : .,0.8986470699310303
apache_kafka/10646,"consolidate the global state stores <para-sep> todo ( ) : we should not trigger user 's exception handler for illegal-argument but always fail-crash ; in this case we would not need to immediately close the state store before throwing <nl> register the store first , so that if later an exception is thrown then eventually while we call on the state manager this state store would be closed as well <nl> todo ( ) : we should not trigger user 's exception handler for illegal-argument but always fail-crash ; in this case we would not need to immediately close the state store before throwing <nl> register the store first , so that if later an exception is thrown then eventually while we call on the state manager this state store would be closed as well","0. when register state stores , add the store to globalstatestores before calling any blocking calls that may throw errors , so that upon closing we would close the stores as well . <nl> 0. remove the other list as a local field , and call topology.globalstatestores when needed to get the list .",1620365723,"in the unit test for jdk 0 , we spotted a case where a global stream thread startup would stall if it fails immediately upon the first poll . the reason is that function only checks whether the thread is not running , as it needs to block until it finishes the initialization . however , if the thread transits to immediately , the call would block forever . <nl> use the failed unit test to verify it works .",0.915192186832428
apache_beam/14554,"samza portable runner support . <nl> update samza runner to work with . <nl> 0. portable runner <nl> 0. jobserverdriver <nl> 0. defaultjobbundlefactory . <nl> in portability framework <para-sep> to support -- output_executable_path where bundles the input pipeline along with all artifacts , etc . required to run the pipeline into a jar that can be executed later . <nl> driver program that starts a job server for the samza runner . * / <nl> samza runner-specific configuration for the jobserver . * / <nl> todo : expose the filesystem related options . <nl> register standard file systems . <nl> assumes it is safe to release the backing environment asynchronously . <nl> this map should only ever have a single element , as each job will have its own classloader and therefore its own instance of samzaexecutablestagecontextfactory . this code supports multiple jobinfos in order to provide a sensible implementation of factory.get ( jobinfo ) , which in theory could be called with different jobinfos . <nl> always release environment asynchronously .","update samza runner with : . <nl> 0. samzajobserverdriver to extend jobserverdriver to support artifact staging , logging services etc . <nl> 0. dofnop to get job bundle factory from samzaexecutablestagecontextfactory <nl> 0. add samzaexecutablestagecontextfactory to use defaultjobbundlefactory to support starting docker container as workers automatically",1618522146,"this adds support for to read raw lines without any sort of csv format involved . the rabbit hole went a bit deep . <nl> - you use to read csv and set e.g . to do what you used to do with . <nl> - because the new options for are disjoint from the old ones , i added a backwards compatibility . <nl> - i added end-to-end tests of reading and writing these variations . <nl> - i deleted tests that did n't seem to add any value . <nl> - that showed a bug where we have",0.9759969711303711
neo4j_neo4j/11906,"counts raft replication events . more precisely counts : <nl> new replication , nbr of attempts , successful and failed . <nl> also logs number of attempts if more than 0 <cm-sep> remove unused lifecycle interface from raftreplicator <para-sep> blocking at least until the send has succeeded or failed before retrying <nl> given","counts raft replication events . more precisely counts : <nl> new replication , nbr of attempts , successful and failed . <nl> also logs number of attempts if more than 0",1527773045,during store upgrade in case if transaction logs are missing upgrade transaction checksum will be set to predefined constant value <nl> ( since we ca n't get find real value in the logs ) . <nl> in ha setup upgraded store will be copied by slaves and update pullers will try to fetch updates starting from upgrade transaction id . <nl> master should be able to recognise that specific upgrade transaction id and use checksum that was assign to it during upgrade .,0.9726646542549133
vespa-engine_vespa/17224,add logging of reportentry <cm-sep> present more errors to the user <para-sep> return failure to enforce getting the test report from the caller . <nl> likely this is something wrong with the provided test bundle . create a test report and present in the console to enable tenants to act on it .,* remove irrelevant ' test plan execution started ' messages <nl> * log reportentry from tests <nl> * include errors when test bundle fails to start,1617021290,"add connector configuration that will transform the connector to a <nl> health check proxy for to a different connector , e.g proxying http - > <nl> https . this is a required feature to support http-only load balancer <nl> health checks when the container is intended to be running in a <nl> https-only environment .",0.957300066947937
neo4j_neo4j/11715,normalize nanos to be between 0 and 1s <para-sep> normalize nanos to be between 0 and nanos_per_,normalize nanoseconds to be between 0 and 999_999_999 instead of between -999_999_999 and 999_999_999 .,1525419574,"where the count was stored as unsigned short , but retrieved as <nl> signed short in some places , which may have it seen as negative .",0.8913107514381409
hazelcast_hazelcast/18537,fix failures in splitbraintest . <nl> the reason was that some instances were created with a custom config and <nl> some with a default config and they had different partition count .,"these nightly tests were consistently failing , but issue was n't reported . <nl> the reason was that some instances were created with a custom config and <nl> some with a default config and they had different partition count .",1618483229,"- fixes hazelcasttestsupport.assertjoinable , expects milliseconds timeout , not nanoseconds . <nl> - threadleaktestutils initializes logger factory . log4j2 creates its own shutdown hook threads , by initializing logger initially we force them to be created beforehand . this is required to be able to detect thread leaks . <nl> - add explicit thread names to test connection managers .",0.8896799683570862
jenkinsci_jenkins/5095,"update maskingclassloader.java . <nl> using the correct replace method <nl> modified the replace ( ) with character parameter for optimization <cm-sep> update lineendingconversion.java . <nl> using the correct replace method <nl> modified the replace ( string , string ) to replace ( char , char ) for optimization <cm-sep> update icon.java . <nl> using the correct replace method <nl> modified the replace ( ) with character parameter for optimization",using the correct replace method <nl> modified the replace ( ) with character parameter for optimization,1606987182,"* rfe ( internal ) , prevent occasional serialization of remoting classes to a wrong channel",0.8245223760604858
vespa-engine_vespa/17263,"sort and group deps based on scope . <cm-sep> move componentgraph.provider from container-di to component . <nl> - it was the only publicapi class in container-di , and is widely <nl> used in the same way as e.g . abstractcomponent from the <nl> component module . <cm-sep> update abi specs after moving provider from di- > component <cm-sep> remove unnnecessary deps and maven config from metrics pom . <cm-sep> remove deps to container-di for modules that only used provider . <cm-sep> add config definitions from container-di . <cm-sep> add java source from container-di . <cm-sep> remove unnecessary plugin configuration . <cm-sep> remove duplicate test deps . <cm-sep> add test config defs from container-di . <cm-sep> remove all dependencies to container-di <cm-sep> do not build or install the container-di module . <cm-sep> remove container-di from code-map . <cm-sep> remove the container-di module . <cm-sep> remove container-di from enforcer . <cm-sep> allow container-disc to embed the 'component ' artifact . <nl> .. to allow deploying it as part of container-disc , instead of a <nl> separate bundle . <cm-sep> fix incorrect method name . <cm-sep> package component and container-core as jar , not container-plugin . <nl> - component is now embedded in container-disc , and container-core <nl> always was . <cm-sep> do not install the component module . <nl> - the jar is now embedded in the container-disc bundle . <para-sep> provides a component of the parameter type t. if ( and only if ) dependency injection does not have a component of type t , it will request one from the provider providing type t. providers are useful in these situations : some code is needed to create the component instance in question . the component creates resources that must be deconstructed . a fallback component should be provided in case the application ( or system ) does not provide a component instance . <nl> specifies how a component should be instantiated from a bundle . immutable <nl> must only be used when classid ! = null , otherwise the id must be handled as a componentspecification ( since converting a spec string to a componentid and then to a componentspecification causes loss of information ) . <nl> todo : these are the same for now because they are in the same bundle . <nl> return a new instance of the specification with bundle name altered","this easter egg contains : <nl> * move to the module , to reduce dependencies on container-di+core . <nl> * merge container-di into container-core <nl> * embed in the container-disc bundle , to reduce installed packages . <nl> after merging this , builders must run to avoid failure in when building vespa ..",1617401556,should not be merged until after pending protocol version change has passed entirely through our pipelines and upgrade documentation is in place .,0.9233766794204712
netty_netty/11191,"motivation : . <nl> when create a websocketserverprotocolconfig to check uri path starts from '/ ' , <nl> only '/ ' or '//subpath ' can be passed by the checker , but '/subpath ' should be <nl> passed as well . <nl> modifications : . <nl> in treat '/ ' a special case . <nl> result : <nl> '/subpath ' can be passed","motivation : . <nl> when create a websocketserverprotocolconfig to check uri path starts from '/ ' , <nl> only '/ ' or '//subpath ' can be passed by the checker , but '/subpath ' should be <nl> passed as well . <nl> modifications : . <nl> in treat '/ ' a special case . <nl> result : <nl> '/subpath ' can be passed .",1619196409,"motivation : . <nl> if the encoded value of a form element happens to exactly hit the chunk limit ( 0 bytes ) , the post request encoder will throw a nullpointerexception . <nl> modification : . <nl> catch the null case and return . <nl> result : .",0.9132189750671387
apache_kafka/10630,stop logging raw record contents above trace level in workersourcetask,accidental logging of record contents is a security risk as they may contain sensitive information such as pii . this downgrades the level of log messages in the class that contain raw record contents to level in order to make that scenario less likely . <nl> as these changes are trivial no tests are added .,1620144608,"the documentation for max.block.ms said it affected only send ( ) <nl> and partitionsfor ( ) , but it actually also affects inittransactions ( ) , <nl> aborttransaction ( ) and committransaction ( ) . so rework the <nl> documentation to cover these methods too .",0.8562332391738892
apache_druid/10956,logs more info when delete segments & & add deletesegments-related ut <cm-sep> revert msic.xml <para-sep> published segments to metadatastorage <nl> check segments published <nl> remove segments in metadatastorage <nl> check segments removed,logs more info for metadata deletion in overlord : <nl> 0. this would help users to more clearly understand what delete actions have been done by the kill task including metadata and data . <nl> 0. this would help in debugging metadata related issues . <nl> p.s . <nl> kill task is divided into two stages : <nl> 0. overlord deletes meta infos . <nl> 0. peon deletes deepstorage files . <nl> so that we can only add meta-related logs in overlord,1615186146,"all dimension positions other than the first index ( which has the value of the last column ) , will have null values instead . <nl> prior to this fix the added test would fail with",0.9368205666542053
confluentinc_ksql/7576,fix bugs in fk n-way joins,"without this fix , we fail with a because downstream operators fall back to default bytearrayserde as no is set . <nl> all but two n-way join qqt test pass now , but as long as qtt is not fixed , we can not enable them yet . one test fails with missing result columns ( we need to fix forward in a follow up pr ) .",1621784263,"this is only a partial fix because it means any new queries running this code will not hit the problem , it does n't fix existing queries . to do that , we will follow up this commit with one that preemptively registers the schema of the original topic into the subject of the changelog topic . <nl> note : this pr is split into two commits because it requires rewriting almost all historical plans that used tables . also , if someone can take a look at and let me know if this fixes a bug or if it",0.92866450548172
jenkinsci_jenkins/5121,- fix null safety for plugin categories <para-sep> checks whether a plugin has a desired category <nl> todo : cache it in a hashset for performance improvements <nl> get categories stream for further search .,not all update centers support categories . hopefully handling of these issues becomes more automatic once spotbugs is fully cleaned up for normal level . <nl> * prevent nullpointerexception in plugin manager when using an update center without support for plugin categories,1608026815,"proposed changelog entries : . <nl> if you have the authorize project plugin installed and configured , its configuration will now be treated as final with respect to the behavior of job/build checks from build other projects and build after other projects are built . formerly , if a per-project configurable build authorization was enabled globally but some projects did not specify an authorization , the two aforementioned checks would automatically fall back to checking as anonymous ( typically denying build permission ) . to restore the former behavior , explicitly configure a project default build authorization to be run",0.933131754398346
Graylog2_graylog2-server/10799,fix for the semantic change : no_limit was 0 pre 0.x and is now 0,"this changed in the background to for other functionality in version . <nl> for the legacy-api , this pr changes the semantics back . <nl> /search/universal/absolute * <nl> /search/universal/keyword * <nl> /search/universal/relative * .",1623078065,"the pr also changes how we add handlers to the promises in the sidecar stores , to ensure that an error in the backend will not call handlers added to the action promise .",0.8392418622970581
jenkinsci_jenkins/5391,"bring back support for stapler.jelly.trace <para-sep> this method seems unused in the ecosystem , only grails-plugin was using it but it 's blacklisted now","this system property helps undertanding where the jelly fragments are coming from by adding comments around the fragments . <nl> there are two reasons for the failure . <nl> 0 ) ❌ firstchild 🚸 <nl> the firstchild javascript method is not expected to return a commentnode in our js . can return element , textnode or commentnode , while can only return element . <nl> from the core code i checked , the element seems to be the only one really desired , but i can be wrong . <nl> 0 ) ❌ flush 🚽 <nl> ⚠️ more complicated to",1617621615,- also now aware of concurrent builds .,0.9542105793952942
elastic_elasticsearch/73843,"nested objects are implemented via a nested class directly on object mappers , <nl> even though nested and non-nested objects have quite different semantics . in <nl> addition , most call-sites that need to get an object mapper in fact need a nested <nl> object mapper . to make it clearer that nested and object mappers are different <nl> beasts with different implementations and different requirements , we should <nl> split them into different classes . <para-sep> todo stop nestedobjectmapper extending objectmapper ?","nested objects are implemented via a nested class directly on object mappers , <nl> even though nested and non-nested objects have quite different semantics . in <nl> addition , most call-sites that need to get an object mapper in fact need a nested <nl> object mapper . to make it clearer that nested and object mappers are different <nl> beasts with different implementations and different requirements , we should <nl> split them into different classes .",1623074964,"this drop the ' top level ' pipeline aggregators from the aggregation <nl> result tree which should save a little memory and a few serialization <nl> bytes . perhaps more imporantly , this provides a mechanism by which we <nl> can remove all pipelines from the aggregation result tree . this will <nl> save quite a bit of space when pipelines are deep in the tree . <nl> sadly , doing this is n't simple because of backwards compatibility . nodes <nl> before version need those pipelines . we provide them by setting passing <nl> a into the root of",0.97602379322052
ballerina-platform_ballerina-lang/30076,add tests for invalid cyclic record type inclusion <para-sep> personone ; <nl> employee ; <nl> persontwo ; <nl> personone ; <nl> employee ; <nl> persontwo ;,allows the following type test .,1618830168,same visibility is enforced for interface method and it 's implementation in non-abstract objects . <nl> visibility modifiers are allowed for object-outer functions .,0.9574572443962097
neo4j_neo4j/11703,move all index to atomic files . <nl> index ids will for the time being always be an empty set in prepare <nl> store copy request .,index ids will for the time being always be an empty set in prepare <nl> store copy request .,1525340092,by using the same mechanisms to figure that out as neo4j <nl> does otherwise .,0.90392005443573
runelite_runelite/13171,add item identification for logs and planks <para-sep> logs <nl> planks,i added item identification for logs and planks . let me know if i need to change something . thanks,1612708950,"the itemidentification plugin supports items that are hard to tell apart , such as seeds and herbs . i 've added potions as well , since many potions are difficult to tell apart for colorblind individuals . <nl> i 've added short and medium identification to all of the most commonly commonly used potions and all unfinished potions . i have not added identification to skill potions , barbarian mixes , or some one-off potions like blamish oil . although adding them later would be trivial . <nl> potions ( normal vision ) . <nl> potions ( deuteranopia vision )",0.9262118339538574
OpenAPITools_openapi-generator/8609,"mark java-vert as deprecated <cm-sep> update , clean up samples <para-sep> java-vertx ( deprecated )",- mark java-vertx as deprecated <nl> - recommend java-vertx-web instead .,1612412389,,0.0
vespa-engine_vespa/17725,inline variable <cm-sep> remove unnecessary interface and package exports,is not a component ( maybe it was in the past ? ),1620119797,"there should be no functional changes here , just refactoring .",0.9276925921440125
apache_druid/10830,allow only http and https protocols for the http inputsource <cm-sep> rename,this pr adds new configurations for allowed protocols for http and hdfs inputsources and firehoses . these inputsources and firehoses can accept only the uris that have the allowed protocols and fail otherwise . <nl> - : allowed protocols that hdfs inputsource and hdfs firehose can use . <nl> - : allowed protocols that http inputsource and http firehose can use . <nl> this pr changes the existing behavior that users can use any protocols with these inputsources and firehoses,1612231396,kafkaindextask support for a minimummessagetime parameter and changes to kafkasupervisor to utilize this parameter . allows users to specify a threshold for how old messages can be until they are dropped ; this helps to prevent segment allocation conflicts when running a realtime and batch pipeline concurrently .,0.9710620045661926
Graylog2_graylog2-server/10391,"add path check <cm-sep> return after aux file check <para-sep> if the allowedauxiliarypathchecker is enabled ( one or more paths provided to the allowed_auxiliary_paths server configuration property ) , then this error path will also be triggered for cases where the file does not exist . this is unavoidable , since the allowedauxiliarypathchecker tries to resolve symbolic links and relative paths , which can not be done if the file does not exist . therefore this error message also indicates the possibility that the file does not exist . <nl> intentionally return here , because in the cloud context , we should not perform the following checks to report to the user whether or not a file exists .","tested in the ui to verify that when values are specified , the ui will not attempt to perform validation for file paths that are outside of the specified permitted directories . <nl> also tested that when values are not specified , that the file existence and readability checks are performed normally as expected .",1617893534,"prior to this change , time ranges per search type were either overwritten by the global override time range ( if present ) or ' derived ' from the search type/query 's time range . this led to offset time ranges being overwritten by the global override time range and therefore breaking trending . <nl> this change is now taking the global override time range into account when ' deriving ' a time range . that means the offset time range checks if a global override time range is present and uses it as reference . if it is absent",0.9426453113555908
gocd_gocd/8654,introduce an internal secret configs endpoint which contains all the auto complete information,description : <nl> - introduce an internal secret configs api which contains the secret configs configured along with any auto-complete suggestions required <nl> - updated the secret config spa to use the same .,1602666563,description : introduced scm api v3 . <nl> - deprecated v1 and v2 <nl> - add an usages api for a given scm material . <nl> response .,0.9906971454620361
quarkusio_quarkus/17418,update to maven version . <nl> ( cherry picked from commit sha ),"please do n't merge , i will merge it myself .",1621620631,"fixes for incorrect checks - comparing incompatible types for equality . <nl> - classifier is optional , equality check needs to reflect that <nl> - capability is enum , not string .",0.7428058385848999
elastic_elasticsearch/72995,"this commit upgrades the azure sdk to version and jackson to version . the <nl> jackson upgrade must happen at the same time due to azure depending on <nl> this new version of jackson . <para-sep> even though we do n't use it , we need to force static init of the default resolver which reads /etc/hosts so it does n't init later <nl> needed by netty dns resolver",this commit upgrades the azure sdk to version and jackson to version . the <nl> jackson upgrade must happen at the same time due to azure depending on <nl> this new version of jackson .,1620835669,"this change adds an extra piece of information , <nl> limits.total_ml_memory , to the ml info response . <nl> this returns the total amount of memory that ml <nl> is permitted to use for native processes across <nl> all ml nodes in the cluster . some of this may <nl> already be in use ; the value returned is total , <nl> not available ml memory .",0.9135358929634094
elastic_elasticsearch/72671,only wait for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade . <para-sep> cluster health does not wait for active shards per default <nl> explicitly wait for the primary shard ( although this might be default ),with this change transform only waits for 0 active shard ( primary ) as waiting for all can block during <nl> rolling upgrade .,1620122466,this commit updates the node stats version constants to reflect the fact <nl> that index pressure stats were backported to version . it also reenables bwc <nl> tests .,1.0
jenkinsci_jenkins/5174,bump commons-fileupload from version- to version . <nl> bumps commons-fileupload from version- to version . <cm-sep> work around <para-sep> todo remove this workaround after is resolved .,"jenkins core uses a fork of commons fileupload version ( which was released upstream on february 0 , 0 ) . two changes were made to the jenkins fork : . <nl> as of 0 , the latest upstream release ( version ) contains all the changes present in the fork ; therefore , the fork is no longer necessary . furthermore , it prevents us from receiving upstream fixes . <nl> upgrade to the latest upstream release , commons fileupload version . <nl> all testing was done with or with remote debugging enabled to verify that all relevant code",1610594550,while investigating an issue stumbled upon this double call of use the cached value of the first instead of calling it twice to prevent double checks of acls . <nl> improve performance of list views when listing items,0.8804164528846741
elastic_elasticsearch/73308,"speed up maps.copymapwithaddedentry to speed up its . <nl> this method is taking about 0 % of cpu time with internal cluster tests <nl> for me . 0 % of that were coming from the slow immutability assertion , <nl> the rest was due to the slow way we were building up the new map . <nl> the cpu time slowness likely translates into outright test slowness , <nl> because this was mainly hit through adding transport handlers when starting <nl> nodes ( which happens on the main test thread ) . <nl> fixed both to save a few % of test runtime . <para-sep> map classes that are known to be immutable , used to speed up immutability check in # assertimmutablemap <nl> check in the known immutable classes map first , most of the time we do n't need to actually do the put and throw which is slow to the point of visibly slowing down internal cluster tests without this short-cut","this method is taking about 0 % of cpu time with internal cluster tests <nl> for me . 0 % of that were coming from the slow immutability assertion , <nl> the rest was due to the slow way we were building up the new map . <nl> the cpu time slowness likely translates into outright test slowness , <nl> because this was mainly hit through adding transport handlers ( calling this method for each added transport handler + in some other random places when starting nodes ( which happens on the main test thread ) . <nl> fixed both",1621631756,"exceptions thrown by the various methods are <nl> logged as an by the and otherwise ignored . it 's <nl> preferable for implementations to log their own messages . <nl> this commit adjusts the implementation to log a message itself , and adds <nl> javadoc to clarify that other implementations should do the same .",0.9361509084701538
ballerina-platform_ballerina-lang/27244,"add response status line , header and entity body validation configs <cm-sep> add integration test cases <para-sep> set response validation limits . <nl> test case for services with inbound response limit configurations .",> change inbound request header length validation error status code to .,1606642682,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9663218855857849
vespa-engine_vespa/17126,"retrieve path suffix with ' * ' <cm-sep> add getter for restapi instance <cm-sep> create copy of default objectmapper instance . <nl> objectmapper is mutable/configurable , and is exposed through various getters in restapi . <cm-sep> convert stateresource as request handler <para-sep> a web service to discover and proxy vespa service state info . <nl> if it points to a port and host not part of the application , rewriting will not occur , so this is kind of safe <nl> nop",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616509479,"with this you can just trigger the next ( zonedeployment ) step returned , as they are returned in order and test and staging are always included when appropriate .",0.9783445596694946
apache_kafka/10722,update java doc for deprecated methods,update deprecated methods : <nl> 0 . <nl> 0. .,1621394857,"close ( long , timeunit ) was deprecated and replaced with close ( duration ) ;",0.7998915910720825
apache_camel/5578,: add https to existing exclusion <cm-sep> update fileutiltest.java,add https to the exclusion for path compating .,1621242726,"the pattern stops colon search after the first colon , so the sanitizeuri method will hide the complete password part .",0.9084972143173218
apache_shardingsphere/10541,prepare configurationproperties for evaluate <cm-sep> add show-process-list-enabled <para-sep> whether enable show process list .,changes proposed in this pull request : <nl> - add switch in <nl> - prepare for to fetch <nl> - enable,1622272316,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9343329071998596
apache_druid/11014,"enable multiple distinct count <para-sep> see countrequiredmergebuffernumwithoutsubtotal ( ) for explanation <nl> this should be 0 because the broker needs 0 buffers and the queryable node needs one . <nl> this should be 0 because the broker needs 0 buffers and the queryable node needs one . <nl> 0 for subtotal and 0 for groupbyqueryrunnerfactory # mergerunners <nl> 0 needed by subtotal and 0 for groupbyqueryrunnerfactory # mergerunners <nl> 0 for subtotal , 0 for nested group by and 0 for groupbyqueryrunnerfactory # mergerunners <nl> 0 for subtotal , 0 for nested group by and 0 for groupbyqueryrunnerfactory # mergerunners <nl> reset the walker and conglomerate with required number of merge buffers . default value is 0 .","running queries with multiple exact distinct aggregations require us to enable a calcite rule which is currently not enabled . instead rule is used which plans queries with multiple distinct aggregations as a join query with a join condition of type . however , druid supports only equality conditions in joins . rule , on the other hand , uses grouping aggregator , to run the queries with distinct aggregations . that aggregator was added recently . <nl> with enabled , query planning completes just fine however , after planning , the query execution fails . this is due to",1616139849,maxsegmentsinqueue parameter added to coordinatordinamicconfig and used in loadrule to improve segments loading and replication speed . adjusting this config parameter might be useful if there are ' slow ' nodes in the cluster to prevent huge backlog in loading queue for such nodes . it could be more important to load segment to not optimal ( in sense of balancerstrategy ) server than waiting for a long time until backlog is processed . <nl> default value does not change behavior .,0.9476127028465271
jenkinsci_jenkins/5457,ensure there are no unused imports with spotless rather than checkstyle,"in this pr we disable the checkstyle check and replace it with the spotless check . the spotless goal runs in the phase by default and fails like this if there are any violations : . <nl> note that the last line contains a helpful suggestion to run , which automatically fixes all violations . the developer can then commit the result and quickly move on .",1619904296,"adds system read permission support to global tool configuration . <nl> screenshot . <nl> when using the core-pr-tester ( ) , you can use script console to enable the new permission : . <nl> , allows users with system read permission to view the global tool configuration",0.735757052898407
apache_beam/14942,add main method to externalworkerservice . <nl> 0. add main method to externalworkerservice to support launching worker pool from java sdk container . <para-sep> worker pool entry point . the worker pool exposes an rpc service that is used with external environment to start and stop the sdk workers . it needs to be known up-front and matches the running job . <nl> wait to keep externalworkerservice running,0. add main method to externalworkerservice to support launching worker pool from java sdk container .,1622765387,follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9149273633956909
apache_pulsar/10995,"java client : keyvalueschema with autoconsume component - make it work if the topic is still not initialized <para-sep> this consumer is the same as 'c3 ' consumer below , but it subscribes to the topic before that the producer writes messages and set the schema so the consumer starts on a non existing topic ( that will be autocreated ) without a schema in fact a keyvalue schema with a autoconsumeschema component is to be treated like an autoconsumeschema because it downloads automatically the schema when needed <nl> verify that the consumer did not set a schema on the topic <nl> verify c0 <nl> verify c1 <nl> verify c2 <nl> verify c3 <nl> verify c3before <nl> verify c4 <nl> verify c3before <nl> it may happen that the schema is not loaded but we need it , for instance in order to call getschemainfo ( ) we can not call this method in getschemainfo . <nl> schemaless topic","when you use keyvalueschema together with schema.auto_consume ( ) for the key or for the value , currently ( pulsar version ) the ' consumerbuilder.subscribe ( ) ' method fails because in this case the keyvalueschema requires to fetch the schema , because one of the bk components uses autoconsumeschema , but the schema is not set on the topic . <nl> - add some special handling in the subscribe code path in order to deal with keyvalueschema , the same way we are doing for autoconsumeschema <nl> - add special handling in messageimpl in order to support schema versioning",1624259668,"currently , pulsar support delete inactive topic which has no active producers and no subscriptions . this pull request is support to delete inactive topics that all subscriptions of the topic are caught up and no active producers/consumer . <nl> expose inactive topic delete mode in broker.conf , future more we can support namespace level configuration for the inactive topic delete mode . <nl> new unit tests added for each inactive topic delete mode . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no",0.9622937440872192
elastic_elasticsearch/72860,cleanup blobpath class . <nl> there should be a singleton for the empty version of this . <nl> all the copying to or use as an iterator make <nl> no sense either when we can just use the list outright .,there should be a singleton for the empty version of this . <nl> all the copying to or use as an iterator make <nl> no sense either when we can just use the list outright .,1620504930,"just a cleanup i found when working on the recovery logic : . <nl> a class with 0 fields does not need a builder , especially <nl> when in many cases the builder result is just equivalent to the <nl> singleton to begin with . <nl> removed the builder and simplified related code accordingly .",0.9371092915534973
grpc_grpc-java/7796,"first commit of binder transport code . <nl> this just adds the servicebinding class , an internal util . <cm-sep> copyright <para-sep> only flags suitable for use with grpc/binderchannel are available to manipulate here . the javadoc for each setter discusses each supported flag 's semantics at the grpc layer . <nl> a set of default flags suitable for most applications . <nl> * / <nl> * / <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> if false , rpcs will not succeed until the remote service comes into existence for some other reason ( if ever ) . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> this flag has no additional meaning at the grpc layer . see the android docs for more . <nl> * / <nl> callbacks from this class . methods will be called at most once , and always on the application 's main thread . <nl> we 're now bound to the service . only called once , and only if the binding succeeded . * / <nl> we 've disconnected from ( or failed to bind to ) the service . this will only be called once , after which no other calls will be made ( but see note on threading above ) . <nl> attempt to bind with the remote service . <nl> unbind from the remote service if connected . <nl> manages an android binding that 's restricted to at most one connection to the remote service . a note on synchronization & locking in this class . clients of this class are likely to manage their own internal state via synchronization . in order to avoid deadlocks , we must","this first commit just adds a simple servicebinding class , an internal util .",1610382589,"this adds utility methods for attaching a protobuf object to a grpc on the server-side and retrieving it on the client-side . <nl> the design document for mapping from grpc to suggests that the data should be regarded as a first-class member of the grpc api . since can not depend on protobuf , an alternative approach to that chosen for this pr is to introduce a class with member variables , , that maps 0-0 with . this would allow attaching as a member variable in grpc . <nl> however , we would still have to jump through a",0.9876846671104431
apache_kafka/10599,; add api to abort transactions <para-sep> forcefully abort a transaction which is open on a topic partition . <nl> forcefully abort a transaction which is open on a topic partition . this will send a request to the partition leader in order to abort the transaction . this requires administrative privileges . <nl> we need a sleep here because the client will attempt to backoff after the disconnect,"the api needs to be sent to partition leaders , so we are able to reuse , which was introduced when support for was added .",1619470552,"summary of changes : . <nl> currently , in sslfactory.java , when the keystore is created null ( caused by passing an empty config value to ssl.keystore.location ) , the default sun keymanager is used ignoring the 'ssl.keymanager.algorithm ' provided . <nl> i included changes to fetch keymanager from the keymanagerfactory based on the provided keymanager algorithm , populated by 'ssl.keymanager.algorithm ' if the keystore is found empty",0.9745661020278931
hazelcast_hazelcast/18502,"use configfactory to create the default config instances . <nl> currently , we use default constructor to create config , clientconfig <nl> and clientfailoverconfig when parsing the spring application-context . <nl> with these changes , we introduce a factory class to create these config <nl> instances . the factory class uses 'supplier 's to create the config <nl> instances . these suppliers can be changed to provide a pre-configured <nl> instance instead of the default one . <nl> the motivation to use factory methods is that some of the tests stuck <nl> at creating the client , the default connection timeout for the client <nl> is infinite . instead of changing each and every config xml file , we <nl> want to pre-configure the client ( and member for smallinstancesconfig ) <nl> and add a finite value for the connection timeout in the tests . <para-sep> contains config factory classes .","currently , we use default constructor to create config , clientconfig <nl> and clientfailoverconfig when parsing the spring application-context . <nl> with these changes , we introduce a factory class to create these config <nl> instances . the factory class uses 'supplier 's to create the config <nl> instances . these suppliers can be changed to provide a pre-configured <nl> instance instead of the default one . <nl> the motivation to use factory methods is that some of the tests stuck <nl> at creating the client , the default connection timeout for the client <nl> is infinite . instead of",1617954634,a new test is added as well .,0.9424216747283936
apache_flink/15863,"fix npe on bundle close when task failover after a failed task open <para-sep> simulate a failover after a failed task open ( e.g. , stuck on initializing ) expect no exception happens <nl> simulate a failover after a failed task open , expect no exception happens <nl> simulate a failover after a failed task open , expect no exception happens <nl> window aggregate put window properties at the end of aggs <nl> simulate a failover after a failed task open , expect no exception happens <nl> processing time window does n't support two-phase , so add a single two-phase test . <nl> window aggregate put window properties at the end of aggs <nl> simulate a failover after a failed task open , expect no exception happens <nl> simulate a failover after a failed task open , expect no exception happens","fix npe on bundle close when task failover after a failed task open and add case for current sql harness tests . <nl> - add null check on finishbundle for abstractmapbundleoperator <nl> - add close without open case for current sql harness tests . <nl> this change added tests and can be verified as follows : . <nl> - extended harnesstest for close without open . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no )",1620453412,"downgrades/silences various logging messages to debug to make the logs less noisy , modifies some messages to improve clarify , and even adds a few .",0.8590238690376282
quarkusio_quarkus/16761,allow to add extra codestarts in createproject <nl> this is needed for code.quarkus.io,this is needed for code.quarkus.io and have been wrongly removed ( by me ) in a previous pr . <nl> this also fix a bug in .,1619183633,this enables the usage of <nl> native-image -h : +reportexceptionstacktraces . <nl> > -h : ±reportexceptionstacktraces show exception stack traces for exceptions during image building. ) . default : - ( disabled ) . <nl> this enables <nl> in the maven mojo <nl> and the corresponding option of the gradle plugin .,0.9278224110603333
hazelcast_hazelcast/18857,"extract sqlconsole into separate class <cm-sep> use jline line reader in clientconsoleapp <cm-sep> add client console command to hazelcastcommandline <cm-sep> add clear and history command to client console app . <nl> also , removed ' whoami ' command which was not working . <para-sep> ctrl+d , and kill signals result in exit <nl> ctrl+c cancels the not-yet-submitted command <nl> remove the ' history ' command from the history <nl> starts the hazelcast console application . <nl> this main function should only be used for test runs <nl> ctrl+d , and kill signals result in exit <nl> ctrl+c cancels the not-yet-submitted query <nl> remove the ' history ' command from the history <nl> if it 's a result with an update count , just print it <nl> this is a result with rows . print the header and rows , watch for concurrent cancellation <nl> bottom line after all the rows <nl> the query failed to execute <nl> if a one line comment , a multiline comment or a quote is not started before , check if the character we 're on is a quote character <nl> start a quote block <nl> in a quote block <nl> end the block ; arg could be empty , but that 's fine <nl> enter the multiline comment block <nl> in a multiline comment block <nl> end the multiline block <nl> enter the one line comment block <nl> in a one line comment <nl> end the one line comment block <nl> not in a quote or comment block <nl> these eoferror exceptions are captured in linereader 's readline ( ) method and it points out that the command being written to console is not finalized and command wo n't be read","this pr adds a new command to <nl> to start the . <nl> also , i replaced the line reader of client console app with jline reader <nl> to add clear terminal , history like functionalities to this application <nl> and made some cleanup on commands which was not working . <nl> additionally , i extracted to a separate class from . <nl> checklist : .",1623169550,"apparently , these two classes are introduced to help integration <nl> via jet and never used later . see related pr : . <nl> these classes expose internals to api , and do n't have any practical usage <nl> at the moment . <nl> see imports of hazelcastclientfactory , these classes should not be imported <nl> by a user class . <nl> note : these two classes are never documented as feature publicly .",0.9699131846427917
apache_incubator-pinot/6693,make resizetimems metric as a gauge instead of a meter,"resizetimems should not be meter , since meter has counters , whereas gauge has the absolute values . this pr moves resizetimems metric to gauge and set the unit as ' milliseconds ' . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1616007022,currently pinot does n't need this to differentiate online/offline tables .,0.8123170733451843
apache_druid/11025,"auto-compaction can run indefinitely when segmentgranularity is changed from coarser to finer . <cm-sep> add option to drop segments after ingestion <cm-sep> fix checkstyle <para-sep> segment1 does not exist , hence will fail to drop <nl> all the hour segments got dropped even if we do not have all minutes segments fully covering the 0 hours interval . in fact , we only have 0 minutes of data out of the 0 hours interval . <nl> this creates hour segments with intervals of - 0-0-01t00:0:0/0-0-01t01:0:0 - 0-0-01t01:0:0/0-0-01t02:0:0 - 0-0-01t02:0:0/0-0-01t03:0:0 <nl> segments that did not belong in the compaction interval are expected unchanged <nl> new segments that was compacted are expected . however , old segments of the compacted interval should be drop regardless of the new segments fully overshadow the old segments or not . hence , we do not expect old segments of the 0-0-01t01:0:0/0-0-01t02:0:0 interval post-compaction full compaction with null segmentgranularity meaning that the original segmentgrnaularity is perserved for the intervals , 0-0-01t00:0 : versionz/0-0-01t01:0 : versionz and 0-0-01t02:0 : versionz/0-0-01t03:0 : versionz the original segmentgranularity is hour from the initial ingestion . for the interval , 0-0-01t01:0 : versionz/0-0-01t01:0 : versionz , the original segmentgranularity is minute from the partial compaction done earlier . <nl> ingest data with year segment granularity <nl> ingest data with overwrite and minute segment granularity <nl> used segments after overwrite will contain 0 old segment with year segmentgranularity ( from first ingestion ) and 0 new segments with minute segmentgranularity ( from second ingestion ) <nl> ingest data with year segment granularity <nl> ingest data with overwrite and minute segment granularity <nl> used segments after overwrite will contain 0 old segment with year segmentgranularity ( from first ingestion ) and 0 new segments with minute segmentgranularity ( from second ingestion ) <nl> ingest data with year segment granularity <nl> ingest data with overwrite and minute segment granularity <nl> used segments after overwrite and drop will contain only the 0 new segments with minute segmentgranularity ( from second ingestion ) <nl> ingest data with year segment granularity <nl> ingest data with overwrite and minute segment granularity <nl> used segments after overwrite will contain 0 old segment with year segmentgranularity ( from first ingestion ) and 0 new segments with minute segmentgranularity ( from second ingestion ) <nl> the earlier segment with year granularity will be dropped post-compaction hence , we will only have","add an option for ingestion task to drop ( mark unused ) segments that are of the interval in the ingestionspec . <nl> this pr adds a new option called in the for batch parallel task and batch simple task . this config default value is ( which is the same as the current behavior ) and is not required . if this config is set to ( and is and interval in granularityspec is given ) , then the ingestion task would transactionally drop ( mark unused ) all existing segments that are fully contain by the intervals in",1616565258,"this pr is to allow for auto compaction to use the parallel indexing task . this will be useful when there are too many or large segments in a single time chunk . <nl> - parallel indexing task has a new configuration , , in the tuningconfig to allow for operators to give a hint to control the amount of data that each first phase sub task reads . is the only available option for now which is used only for . <nl> - compaction task now uses . <nl> - auto compaction tuning config now supports and",0.9838190078735352
confluentinc_ksql/7718,implement serde for date <para-sep> return epoch days <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,"date gets serialized to an integer number of days since 0-0-0 , and deserialized to .",1624433410,"for unwrapped single fields it was registering them as a union , i.e . optional . for example , for a unwrapped single field the avro schema was being registered as : . <nl> while this is strictly true , as the value can be null , this would be inconsistent with the schemas ksql would register for a normal row , which would just be an avro record , _not_ a union of and the record type . likewise , the stock confluent avro serializer would also register the same record schema . <nl> so this pr makes a",0.966705858707428
hazelcast_hazelcast/18791,"add partitionassignment to processor context . <nl> the assignment is n't cheap to obtain and it 's useful for processors <nl> dealing with hz data structures . <para-sep> returns the slice of partitions for this processor . <nl> returns the partition assignment used by this job . this is the assignment partitioned edges will use and the assignment processors dealing with hazelcast data structures should use . <nl> the returned list can be empty . <nl> sets the partition assignment . <nl> address in partition table does n't exist in member list , it has just joined the cluster . <nl> if the object count is smaller than processor count , an empty array is put for the rest of the processors . <nl> count == 0 <nl> count == 0",the assignment is n't cheap to obtain and it 's useful for processors <nl> dealing with hz data structures or for sql processors .,1622127171,"this feature is needed for jet sql to implement joins . the actual partition id set will contain local partitions , but we do n't want to use , because after migration we want to continue working with some remote partitions , until the job is restarted . also , there 's no ...",0.9428378939628601
apache_druid/11006,"fix kinesis lag metrics bug and modify current ut <cm-sep> done <cm-sep> revert misc.xml <para-sep> if no more new data after offsettouse , it means there is no lag for now . so report lag points as 0l .",if empty it means there is no more new data for current stream . so just return 0l here,1615963013,"i 'm hoping this can go in because it would be super handy . <nl> adds and which are described in the docs . <nl> the is defaulting to 0 to facilitate not delaying unit tests that may start a jetty server , and to make the default behavior match legacy behavior of not waiting .",0.9245229363441467
elastic_elasticsearch/73297,"add keep_values gap policy . <nl> adds a new keep_values gap policy that works like skip , except if the metric <nl> calculated on an empty bucket provides a non-null non-nan value , this value is <nl> used for the bucket . <para-sep> serial diff ignores these values and replaces them with null <nl> ' keep_values ' : for empty buckets the values provided by the metrics will still be used if they are available","adds a new keep_values gap policy that works like skip , except if the metric <nl> calculated on an empty bucket provides a non-null non-nan value , this value is <nl> used for the bucket .",1621541224,this commit cancels proxy requests and its descendant requests when the proxy channel closes . this change is also required to support cross-clusters task cancellation .,0.9415248036384583
elastic_elasticsearch/73930,resurrect the removed _xpack/license endpoints <cm-sep> add specs for yamlrestcompattest,adds back the routes when using rest compatibility for a request .,1623185125,this change aims to fix our setup in ci so that we can run 0.x in <nl> fips 0 mode . the major issue that we have in 0.x and did not <nl> have in master is that we ca n't use the diagnostic trust manager <nl> in fips mode in java 0 with sunjsse in fips approved mode as it <nl> explicitly disallows the wrapping of x509trustmanager . <nl> this change introduces a runtime check in sslservice that overrides <nl> the configuration value of xpack.security.ssl.diagnose.trust and <nl> disables the diagnostic trust manager when we are running in java 0,0.8880909085273743
apache_shardingsphere/10833,fix column index out of range exception when execute subquery select,changes proposed in this pull request : <nl> - fix column index out of range exception when execute subquery select <nl> - refactor logic of containssubquery,1623828680,changes proposed in this pull request : <nl> - refactor for readability . <nl> - add delay time information for real-time sync task progress . <nl> - change job id from string to int .,0.9553282260894775
elastic_elasticsearch/73266,"data stream aliases and action request 's includedatastreams flag . <nl> when data stream aliases are resolved then the includedatastreams flag of an action request should be taken into account , <nl> so that data stream aliases are n't resolved to backing indices for apis that do n't support data streams .","when data stream aliases are resolved then the includedatastreams flag of an action request should be taken into account , <nl> so that data stream aliases are n't resolved to backing indices for apis that do n't support data streams . <nl> ( marking as non-issue , because this is a bug in unreleased code )",1621501595,"this adds validation to make sure alias operations ( add , remove , remove index ) <nl> do n't target data streams or the backing indices .",0.9446696639060974
OpenAPITools_openapi-generator/9108,remove duplicated supportingfiles <cm-sep> modify examples - remove duplicated supportingfiles,"- remove duplicated declaration <nl> - . <nl> ※ before correction <nl> after generation , in . <nl> execute commands . <nl> log .",1616862546,"this removes the mimetypes module , because : <nl> - it does n't really add any value ( it used to when we used to initialise structs but they 're not just s ) <nl> - it 's possible to get collisions in the identifiers .",0.9587274789810181
Alluxio_alluxio/13466,"allow distributed load to read from another worker and always read to local worker . <nl> the earlier change can potentially cause undesired load balance among workers . <nl> because it always respects the alluxio configuration instead of localfirst . <nl> also it always loads from the ufs instead of potentially from another worker when <nl> it is already in alluxio memory . ( e.g . when replication checker runs load ) <para-sep> when the data to load is persisted , simply use local worker to load from ufs ( e.g . distributed load ) or from a remote worker ( e.g . setreplication )",the earlier change can potentially cause undesired load balance among workers . <nl> because it always respects the alluxio configuration instead of localfirst . <nl> also it always loads from the ufs instead of potentially from another worker when <nl> it is already in alluxio memory . ( e.g . when replication checker runs load ),1621629802,backup to root ufs by default and modify the docs,0.892020046710968
apache_beam/14078,"provide setcoder , withcoder methods in parquetio.parse and parquetio.parsefiles to provide explicit coder . <para-sep> * / <nl> * / <nl> use explicitly provided coder","provide setcoder , withcoder methods in parquetio.parse and parquetio.parsefiles to provide explicit coder",1614230240,allows specifying dlq where the messages would go when they can not be parsed . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .,0.9512490630149841
hazelcast_hazelcast/18510,"implementation of sql position function . <nl> * adds support for position ( substring in string ) function <para-sep> test with start argument , slide the search index to right . valid start indices are between 0 and 0 . <nl> repeated string <nl> sql index starts from 0 <nl> sql not found is 0 <nl> if any argument is null , the function will return null . <nl> in this case the argument is not given , then search it from the beginning . <nl> in this case the argument is given but it is null , then return null . <nl> valid argument is between [ 0 , text.length ( ) ] . invalid argument will return 0 ( not_found ) . <nl> convert sql index to java index for passing as argument to function . convert back the result when it returns .",* adds support for position ( substring in string [ from position ] ) function . <nl> checklist : .,1618220643,the new implementation keeps a clone of the old/existing value and uses that for replace/delete operations . this takes care of the user modifying existing value in-place .,0.9628486037254333
confluentinc_ksql/7517,"build physical plan for fk table-table joins <cm-sep> adding tests <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> then : <nl> given : <nl> when : <nl> then : <nl> this is actually a pk-pk join and the logical planner would not compile a fk-join plan for this case atm however , from a physical plan pov this should still work , so we would like to keep this test it might be possible to actually change the logical planner to compile a pk-pk join as fk-join if input tables are not co-partitioned ( instead of throwing an error an rejecting the query ) , ie , if key-format or partition-count do not match -- it 's an open question if it would be a good idea to do this though <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> this is actually a pk-pk join and the logical planner would not compile a fk-join plan for this case atm however , from a physical plan pov this should still work , so we would like to keep this test it might be possible to actually change the logical planner to compile a pk-pk join as fk-join if input tables are not co-partitioned ( instead of throwing an error an rejecting the query ) , ie , if key-format or partition-count do not match -- it 's an open question if it would be a good idea to do this though <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :",later we need to extend qtt tests when we actually use this code ( that is currently ' deal code ' ) .,1620856421,"( note : the feature is currently disabled behind the 'allow any key column name ' feature flag ) . <nl> this change fixes an issue with our repartition semantics . <nl> old style query semantics for partition by are broken : . <nl> s1 : rowkey = > b , c ( meaning s1 has a schema with rowkey as the key column , and b and c as value columns - types are n't important ) . <nl> s2 : rowkey = > b , c . <nl> as you can see the schema of s2 is still",0.9847536683082581
netty_netty/11246,"add defaulthostsfileentriesresolver # addresses to provide all hosts file 's entries for a hostname . <nl> motivation : <nl> defaulthostsfileentriesresolver should provide all hosts file 's entries for a hostname when <nl> dnsnameresolver # resolveall as opposed to the current implementation where only the first <nl> entry is taken into consideration . <nl> modification : <nl> - add defaulthostsfileentriesresolver # addresses to provide all hosts file 's entries for a hostname <nl> - add hostsfileentriesprovider to provide all hosts file 's entries for a hostname and to keep <nl> backwards compatibility for hostsfileentries and hostsfileparser <nl> - dnsnameresolver # resolveall uses the new defaulthostsfileentriesresolver # addresses <nl> - blockhound configuration : replace hostsfileparser # parse with hostsfileentriesprovider $ parserimpl # parse <nl> as the latter does the parsing <nl> - add junit tests . <para-sep> checks whether the given hostname is the localhost/host ( computer ) name on windows os . windows os removed the localhost/host ( computer ) name information from the hosts file in the later versions and such hostname can not be resolved from hosts file . <nl> our current implementation does not support reloading the hosts file , so use a fairly large ttl ( 0 day , i.e . 0 seconds ) . <nl> empty instance . <nl> a container of hosts file entries <nl> performs the parsing operation using the provided reader of hosts file format . <nl> the ipv4 entries . <nl> the ipv6 entries . <nl> remove comment <nl> skip empty lines <nl> split <nl> a valid line should be [ ip , hostname , alias * ] <nl> skip invalid line <nl> skip invalid ip <nl> loop over hostname and aliases <nl> the produced mappings contain only the first entry per hostname .",motivation : . <nl> should provide all hosts file 's entries for a hostname when <nl> as opposed to the current implementation where only the first <nl> entry is taken into consideration . <nl> modification : . <nl> - add to provide all hosts file 's entries for a hostname <nl> - add to provide all hosts file 's entries for a hostname and to keep <nl> backwards compatibility for and <nl> - uses the new <nl> - configuration : replace with <nl> as the latter does the parsing <nl> - add junit tests .,1620757527,this pull request contains <nl> - oio sctp transport . <nl> - oioeventloop interrupt method change ( please review ),0.9647884368896484
Alluxio_alluxio/12520,add configuration for ratis retry cache expiry time,"add a configuration for ratis retry cache expiry time . this affects the size of the ratis server retry cache , which can consume a lot of memory if there is a high volume of journal writes in a short period of time .",1605641529,modified the user logging directory to prevent errors from occurring when the user running a command is different from the alluxio installation user .,0.9274705052375793
apache_camel/5526,: upgrade flatpack to version in order to compile in java 0 and 0 <cm-sep> : upgrade flatpack to version in order to compile in java 0 and 0,"this upgrades to flatpack version that fixes the compilation issues in jdk 0 and 17ea . however , since version is not yet released to maven , please do not merge this pr . this should be fixed once the maintainer of the flatpack project releases version to maven central .",1620376365,this is related to . <nl> camel-archetype-api-component <nl> - add test dependency to fix build failures <nl> in generated test sources <nl> - remove deprecated property ( ) <nl> - the generated component was broken due to a missing argument in <nl> constuctor of the propertieshelper class due to a change in the <nl> apimethodpropertieshelper parent class . <nl> camel-archetype-component and camel-archetype-dataformat <nl> - fix missing plugin version warning for <nl> by adding a new property .,0.8240026235580444
apache_incubator-pinot/6434,pass configuration properties for decoder through to schema registry client <cm-sep> pass configuration properties for decoder through to schema registry client,"no <nl> no . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1610466539,"when users trigger replay , the system should respond the job id right away . however , the system wait for long until the detection jobs finish . this is cause by the bug when using thread . originally , it uses run ( ) , which triggers the run ( ) in the runnable instead of triggering in a thread . the correct one should be start ( ) , which generates a thread and triggers the run ( ) in the runnable .",0.7597229480743408
apache_incubator-pinot/6826,using correct placeholder for dimension table data manager,this patch uses correct placeholders for the dimension table data manager .,1619012444,"this pr is mainly setting up the data flow for advanced dimension analysis table in rca and includes : <nl> - ember data wiring : model/adapter/serializer for <nl> - query caching service for dimensions <nl> - component for ( parses data from several rca objects , including as the user changes the selected metric or analysis window ) <nl> - removing call to , which is not needed in . <nl> testing : <nl> - added initial integration test for dimensions component . skipping for now until i can work out why its not getting mirage data . <nl> 0",1.0
jenkinsci_jenkins/5063,"admin monitors popup is now loaded through an api <cm-sep> fixes form submission inside the popup . <nl> - wraps it in an l : ajax template so that proper variables are set <nl> - applies the csrf crumbs to the forms after the popup is constructed <cm-sep> handle authorization and empty state <para-sep> used by api <nl> applies all initialization code to the elements within the popup among other things , this sets the csrf crumb to the forms within","this pr aims to make loading the list of administrative monitors asynchronous and to not affect page load . this also has the benefit of fixing keyboard navigation through the page header . <nl> no notable changes to show in screenshots , except the empty state . <nl> screenshot of empty state . <nl> this should almost never be shown ( for example , user gets permissions to read monitors removed and tries to load them before reloading the page ) . <nl> * load the administrative monitors popup on demand to reduce page load time . <nl> * fixes",1605802582,"rfc : would this be useful ? <nl> i imagine it might help understand the need for certain translations . at the very least , it would show how many users use jenkins with a non-english language . <nl> data submitted looks like this : . <nl> { ' en-us , en ; q=version ' :0 , ' en-us , en ; q=version , de ; q=version ' :0 } . <nl> * add telemetry trial about user languages . <nl> - [ n/a ] jira issue is well described . <nl> * use the prefix if the change has",0.9815686941146851
hazelcast_hazelcast/18983,"add serializers <cm-sep> move old util reader/writers to portableutil for back compatibility <nl> since year field is different ( int replacing short ) we can not use the <nl> old reader/writers <cm-sep> generate compatibility binary <cm-sep> fix checkstyle <para-sep> a short used here for backward compatibility , other places use an int <nl> a short used here for backward compatibility , other places use an int","adds default serializers for localdate , localtime , localdatetime , offsetdatetime classes . this is necessary for non-java clients to use these classes . currently , for sql , non-java clients send and receive strings with explicit casts . also , map operations are not possible due to the lack of default serializers . <nl> in portable serialization , we used short for the year field . we can not change it here due to backward compatibility . <nl> note that the client protocol will also be changed for sql to support the 0-0,0,0 range for year , like default",1624872148,"it adds a check for imap permission for maps involved in the query execution . <nl> implementations details : <nl> 0. the existing is removed <nl> 0. when the plan is created , a list of required permissions is collected ( ) . for imdg these are permissions for observed maps . jet sql will have its own logic in its implementation <nl> 0. when a query is being executed in the secure context , the collected permissions are checked ( , ) <nl> 0. the sql security context is created for both a client invocation ( ) and an",0.9648395776748657
apache_druid/10962,"fix streaming ingestion fails and halt if it encounters empty rows <para-sep> input is empty <nl> expect a parseexception on the following call on iterator <nl> the 2nd line is ill-formed , so the parse of this text chunk aborts","fix streaming ingestion fails if it encounters empty rows ( regression ) . <nl> this is because when the task try to parse an empty row , it does not result in a parseexception but resulted in java.util.nosuchelementexception instead . hence , the task will fail and will not be able to move pass the empty row even with maxparseexceptions set",1615253751,"this also plumbs compressionutils 's ' zip ' function through <nl> writeatomically , so the code for handling atomic local filesystem <nl> writes is all done in the same place .",0.9113759994506836
apache_pulsar/10364,"motivation . <nl> sometimes , the superuser is not only needed the client <nl> role but also needs some data in the authentication data <nl> to check whether the role is the superuser . <para-sep> test super role is null but the auth datasource contains superuser","motivation . <nl> sometimes , the superuser is not only needed the client <nl> role but also needs some data in the authentication data <nl> to check whether the role is the superuser .",1619352759,there is a race condition when the topic creation is triggered by multiple producers at the same with a schema definition . <nl> 0. the topic is created correctly and then each producers tries to add the schema <nl> 0. one single operation will first create the z-node entry for schema registry ( that points to no schema ) and then will add the schema <nl> 0. other producers might happen to see the z-node but content will be invalid ( ledgerid=0 ) . <nl> do the operation before * the topic is visible . that will ensure the whole,0.9145938754081726
ballerina-platform_ballerina-lang/29362,preserve the original types of a union type <cm-sep> fix union compile-time tostring ( ) and fix tests <cm-sep> fix union runtime tostring ( ) and fix tests <cm-sep> add original union members to the bir and fix tests <cm-sep> add module info to union type string representation <cm-sep> add flags to runtime union type and allow checking for enum <para-sep> this logic is added to prevent duplicate recursive calls to tostring <nl> improve readability of cyclic union types <nl> this logic is added to prevent duplicate recursive calls to tostring <nl> bala tests for the union type .,"this pr also cleans up some buniontype constructors . <nl> this pr also fixes issues with immutable union ( cyclic ) types . if an immutable union type is created for a mutable union type with a name , a new type def is added for the immutable union type too - similar to records and objects .",1616382743,"- to fix the compiler and cpu level issues due to the latest language changes . <nl> - fixes to stream test cases to align with the latest language changes <nl> - add initial implementation of patterns in streaming for logical patterns . <nl> logical patterns match events that arrive in temporal order and correlate them with logical relationships such as and , or and not . this pr contains the implementation of ' or ' along with a test case . with this , users can define streaming queries containing logical patterns with relationships made using ' or '",0.9847406148910522
apache_camel/5766,"use getjmscorrelationid instead of ... asbytes . <nl> when determining jms correlation id , use getjmscorrelationid instead of getjmscorrelationidasbytes <cm-sep> update replymanagersupport . <nl> replace getjmscorrelationidasbytes with getjmscorrelationid in replymanagersupport.onmessage <para-sep> gets the jmscorrelationid from the message . <nl> ignore","this pr replaces calls with . using to determine correlation id is not compatible with artemis jms client as the artemis implementation of only returns a correlation id from if the correlation id is a byte array , otherwise it returns null . because camel sets the correlation id explicitly as a string , the correlation id retrieved from was always null .",1624996158,"] make sure there is a [ jira issue filed for the change ( usually before you start working on it ) . trivial changes like typos do not require a jira issue . your pull request should address just this issue , without pulling in other changes . <nl> [ ] each commit in the pull request should have a meaningful subject line and body . <nl> [ ] if you 're unsure , you can format the pull request title like , where you replace with the appropriate jira issue . <nl> [ ] write a pull request",0.8715226650238037
hazelcast_hazelcast/18900,- bigint-to-timestamp sql function <cm-sep> - removed variable unit support for negative timestamps <cm-sep> - timestamp with tz to bigint function,"adds support for function , which takes arbitrary and returns its epoch millisecond value in a . <nl> example query : . <nl> example result : . <nl> note that by default interprets values as in seconds .",1623675195,"* introduces configurable entry task scheduler to reduce dead time between replica sync retries . configure granularity in number of slots per second with system property ( default is 0 slots/second - > 100ms between attempting to schedule a replica sync retry ) <nl> * replica sync retry delay is now configurable with system property ( default is same as previously , 500ms ) . <nl> * is no longer retried in the face of a .",0.9696235656738281
vespa-engine_vespa/17443,delegate to ssl before alpn <cm-sep> enable http/0 in unit tests for proxy protocol,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618485342,"i do n't think there is any need to call orchestrator if there are no active nodes , but there could be some corner case here i have n't thought through .",0.8460661172866821
Alluxio_alluxio/12811,do not have the probalisticreviewer unnecessarily reject <para-sep> try allocating from given location . skip the review because the location is forced . <nl> try allocating from given location . this may be rejected by the review logic .,many calls to tieredblockstore.allocatespace comes from tieredblockstore.requestspace either through . <nl> ' shortcircuitblockwritehandler - > defaultblockworker ' or <nl> ' underfilesystemblockreader ' . <nl> ( block expansion ) . <nl> all usages of this has forcelocation true and evictionallowed true . <nl> the code instead probabilistically evicted more things in the first tier leading to more churn .,1612554178,contains some documentation updates and bug fixes .,0.8640775680541992
apache_flink/16027,"close file of partition when partition is committable to fix the issue that although partition has committed , the file in this partition is unready . <para-sep> partition commit predicate . <nl> return the partition . * / <nl> return the creation time of the partition . * / <nl> return the current process time . * / <nl> returns the current event-time watermark . * / <nl> partition commit predicate by partition time and watermark , if 'watermark ' > 'partition-time ' + 'delay ' , the partition is committable . <nl> the time zone used to parse the long watermark value to timestamp . * / <nl> returns the watermark has passed the partition time or not , if true means it 's time to commit the partition . <nl> here we do n't parse the long watermark to timestamp and then comparision , but parse the partition timestamp to epoch mills to avoid daylight saving time issue <nl> partition commit trigger by partition time and watermark . <nl> partition commit trigger by creation time and processing time service , if 'current processing time ' > 'partition creation time ' + 'delay ' , the partition is committable . <nl> partition commit trigger by creation time and processing time service . <nl> when partition keys and partition commit policy exist , the partition commit trigger is enabled <nl> close in-progress part file when partition is committable . * / <nl> if partition is committable , close in-progress part file in this partition <nl> the rolling policy is not to roll file by filesize and roll file after one day , it can ensure the file can be closed only when the partition is committable in this test . <nl> commit delay is 0 second with process-time trigger <nl> assert files are n't committed in { 0 , 0 } partitions <nl> first retry <nl> simulate waiting for 0 seconds , now partition { 0 } is committable <nl> only file in partition { 0 } should be committed assert files are committed <nl> simulate waiting for 0 seconds again , now partition { 0 } is committable <nl> second retry <nl> assert files in all partition have been committed <nl> the rolling policy is not to roll file by filesize and roll file after one day , it can ensure the file can be closed only when the","this pull request is to fix the issue that although partition has committed , the file in this partition is still unready . <nl> this change added tests and can be verified as follows : <nl> - added tests to assert close and commit inprogress-file if the partition is committable in streamingfilewritertest # testcommitfilewhenpartitioniscommittablebyprocesstime and streamingfilewritertest # testcommitfilewhenpartitioniscommittablebypartitiontime . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record",1622442614,"this pr adds support for partition related operations to catalog apis . <nl> - adds partition related apis in both readablecatalog and readablewritablecatalog <nl> - implemented them in genericinmemorycatalog . <nl> this change added tests and can be verified as follows : . <nl> - added corresponding unit tests in genericinmemorycatalogtest . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code",0.9806446433067322
confluentinc_ksql/7587,"adds scalable push query routing <cm-sep> remove thread pool and adds some tests <cm-sep> fixes lint errors <cm-sep> fixes various tests <para-sep> does a scalable push query returning a handle which can be used to stop the connections . <nl> connects to all of the hosts provided . <nl> add skip forward flag to properties <nl> subscriber for handling remote data . <nl> subscriber for handling local data . <nl> if anything calls the error callback . all results are closed . <nl> routing options given to scalable push queries . <nl> if we should avoid skipping forwarding the request because it 's already been forwarded . <nl> forced shutdown ? <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> consuming the rows as they stream in rather than aggregating them all in one list . the method itself blocks until the query is complete . send query request to remote ksql server . first , this is run asynchronously and second , when a response is received , a publisher is returned which publishes results asynchronously as they become available . <nl> given : <nl> when : <nl> then : <nl> when : <nl> then : <nl> the old api returns rows in a strange format - it looks like a json array but it is n't . there are newlines separating the elements which are illegal in json and there can be an extra comma after the last element there can also be random newlines in the response <nl> insert a random newline for good measure - the server can actually do this <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then : <nl> when : <nl> then :","at the moment , it attempts to determine the set of hosts at start time to connect to and just sticks with them . a followup change will fail the query if there 's a rebalance . <nl> does everything async , meaning that it uses the vertx context and completablefutures to handle everything , so it does n't require a thread pool . <nl> this also introduces a http2 client to since this is required to issue http2 requests , which this now does for the requests between cluster instances .",1621988959,"part of the work to introduce primitive , then structured , keys . <nl> keys are currently assumed to be kafka serialized strings . when we introduce a way to specify a there must be a way to declare the key is a kafka serialized string if we 're to maintain backwards compatibility . also , many companies using kafka serialized ints or longs as keys . <nl> this pr brings a new format , which will use the appropriate standards kafka serde classes to deserialize a primitive key or value , e.g . <nl> will handle the case where",0.9846845269203186
apache_incubator-pinot/6928,add complex-type support to avro-to-pinot schema inference,add complex-type support to avro-to-pinot schema inference . now users can use the command like the following to infer pinot schema from avro schema with complex-structure .,1621111245,this part handles the change in the controller side fsm to handle the incident reported by the <nl> server . <nl> the protocol now has a new message element ( reason for stopping consumption ) that is printed in the <nl> log message on the controller . <nl> added tests for the new condition .,0.9765759706497192
apache_pulsar/10026,allow websocket to consume and pass message to client without decryption,"websocket proxy should default pass encrypted message to client without decrypting and let client app handles it . so , add default decryption action as : . i will create a separate pr to support decryption at websocket proxy in specific scenario where user wants websocket to handle message decryption .",1616550861,one of the security-recommendation report has listed system internal info in error-response which should be fixed . <nl> url : <nl> error-response : .,0.9105852842330933
Alluxio_alluxio/13160,"fix the issue <cm-sep> before solve conflicts <cm-sep> resolve conflicts <para-sep> map for holding the async releasing entries for proper umount <nl> remove earlier to try best effort to avoid write ( ) - async release ( ) - getattr ( ) without waiting for file completed and return 0 bytes file size error <nl> release operation is async , we will try our best efforts to close all opened file in/out stream before umounting the fuse <nl> waiting for in progress async release to finish <nl> todo ( lu ) consider the case that client application may not call release ( ) for all open ( ) or create ( ) . force closing those operations .","in , a special logic is added to wait for the writing file to completed before getting file size information . <nl> can happen in any cases . when it 's in - - process , we do n't want it to block waiting file completed . when it 's written by other threads or it 's in - - , we do want it to block waiting file completed . <nl> this pr introducing new concurrent hash maps for the releasing entries to fulfill the logics and logics ( ) .",1617291052,"we need to consider tags in the uniqueness of our metrics , otherwise we may incorrectly override metrics ( usually to 0 ) leading to inaccurate numbers .",0.9461778998374939
Alluxio_alluxio/13616,"add javadoc links to filesystem api doc <para-sep> this policy maps the blockid to several deterministic alluxio workers . the number of workers a block can be mapped to can be passed through the constructor . the default is 0. it skips the workers that do not have enough capacity to hold the block . concurrently , the replication level for the block would get close to 0 as each worker reads note that the hash function relies on the number of workers in the cluster , so if the number of workers changes , the workers chosen by the policy for a given block will likely change . a policy that returns the local worker first , and if the local worker does n't exist or have enough availability , will select the nearest worker from the active workers list with sufficient availability . <nl> open the file for reading <nl> read data <nl> close file relinquishing the lock <nl> * <nl> if no worker meets availability criteria , will randomly select a worker from the list of all workers . <nl> if no worker meets availability criteria , will randomly select a worker from the list of all workers . <nl> if no worker meets availability criteria , will randomly select a worker from the list of all workers . <nl> if no worker meets availability criteria , will randomly select a worker from the list of all workers . <nl> if no value is set , will randomly select a worker from the list of all workers .","this pr adjusts/adds javadoc links , adjusts some wording , and changed the ordering of sections for clarity in the filesystem api doc . <nl> clarification on the filesystem api doc . <nl> adjusted the public doc for the filesystem api .",1623265143,move ttl modification to a and remove some unnecessary code,0.8720209002494812
grpc_grpc-java/7922,"add nextlong ( ) for generating a random long . <cm-sep> implement hash value generation for individual rpcs , based on the route-level hashpolicy that the request is routed to . <cm-sep> apply the hack of exposing content-type header to hashing , eliminated the unncessary hack for hiding the grpc-previous-rpc-attempts header . <para-sep> index ascii headers by key , multi-value headers are concatenated for matching purposes . <nl> special hack for exposing headers : ' content-type ' . <nl> rotating the old value prevents duplicate hash rules from cancelling each other out and preserves all of the entropy . <nl> if the policy is a terminal policy and a hash has been generated , ignore the rest of the hash policies . <nl> virtualhost-level configuration for request routing . <nl> first call , with header ' custom-key ' : ' custom-value ' . <nl> second call , with header ' custom-key ' : ' custom-val ' , ' another-key ' : ' another-value ' . <nl> third call , with header ' custom-key ' : ' value ' . <nl> first call , with header ' custom-key ' : ' value1 ' . <nl> second call , with no custom header . <nl> a different resolver/channel . <nl> third call , with no custom header .",generate a hash value for each rpc based on the hashpolicies configured for the route that the rpc is routed to .,1614302814,"make sure the config for grpclb is passed to the , which will support two child policies -- ' round_robin ' ( default ) and ' pick_first ' . <nl> previously the presence of balancer addresses would dictate ' grpclb ' policy , despite of the service config . service config will now take precedence instead . <nl> implement config parsing logic in . the more appropriate config error handling is upcoming .",0.9583829641342163
elastic_elasticsearch/73689,"service to migrate indices and ilm policies to data tiers . <nl> this adds a service that migrates the indices and ilm policies away from <nl> custom node attribute allocation routing to data tiers . <para-sep> represents an ordered list of data tiers from frozen to hot ( or slow to fast ) <nl> based on the provided target tier it will return a comma separated list of preferred tiers . ie . <nl> we cache the currently executing ilm phase in the index metadata so the ilm execution for managed indices is not irrecoverably interrupted by a concurrent update policy that , say , would remove the current execution phase altogether . this contains class contains a series of methods that help manage the cached ilm phase . <nl> rereads the phase json for the given index , returning a new cluster state . <nl> rereads the phase json for the given index , and updates the provided metadata . <nl> ensure that we have the minimum amount of metadata necessary to check for cache phase refresh . this includes : - an execution state - existing phase definition json - a current step key - a current phase in the step key - not currently in the error step <nl> for the given new policy , returns a new cluster with all updateable indices ' phase json refreshed . <nl> for the given new policy , update the provided metadata to reflect the refreshed phase json for all updateable indices . returns true if any indices were updated and false otherwise . <nl> no need to update anything if the policies are identical in contents <nl> returns 'true ' if the index 's cached phase json can be safely reread , 'false ' otherwise . <nl> the index is on a step that does n't exist in the new policy , we ca n't safely re-read the json <nl> the new and old phase have the same stepkeys for this current phase , so we can refresh the definition because we know it wo n't change the execution flow . <nl> if there is an error parsing or if the phase definition is missing the required information , returns null . <nl> check that no other execution state changes have been made <nl> check that the phase definition has been refreshed <nl> success case , it can be","this adds a service that migrates the indices and ilm policies away from <nl> custom node attribute allocation routing to data tiers . <nl> the operates on the <nl> and performs a few operations : <nl> 0. removes the ( optionally ) provided index template if it exists ( note that it will <nl> only look for legacy templates . if a composable template with the provided name <nl> exists it will not be deleted ) . <nl> 0. iterates through the existing ilm policies and inspects the actions that <nl> configure any ( require , include , exclude )",1622652605,"* create new data-stream xpack module . <nl> * move timestampfieldmapper to the new module , <nl> this results in storing a composable index template <nl> with data stream definition only to work with default <nl> distribution . this way data streams can only be used <nl> with default distribution , since a data stream can <nl> currently only be created if a matching composable index <nl> template exists with a data stream definition . <nl> * renamed meta field mapper <nl> to meta field mapper . <nl> * add logic to put composable index template api <nl> to fail",0.9583310484886169
elastic_elasticsearch/74507,"fix error in fieldcapabilitiesresponse serialization . <nl> in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version . <para-sep> check that failure serialization between different minor versions after version works <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> check that failure serialization to minor versions before version works without serializing the failures part <nl> only match size of failure list and indices , most exceptions do n't support 'equals ' <nl> minimum version set to version because the nested fieldcapabilities had another serialization change there","in version version we added failure serialization to the api . <nl> fieldcapabilitiesresponse currently has a bug here where the failures list is <nl> serialized based on version.current , which is different on different releases , <nl> but instead it should be serialized/deserialized for all nodes where the version <nl> is on or above version .",1624468273,this commit restores the filtering of empty fields during the <nl> xcontent serialization of searchhit .,0.9451592564582825
apache_shardingsphere/10713,fix create user password parse error,changes proposed in this pull request : <nl> - fix create user password parse error ( include quote ),1623142949,changes proposed in this pull request : <nl> 0. filter out incorrect table which with only alias . <nl> 0. modify ut .,0.9129363894462585
elastic_elasticsearch/73707,reduce memory when update response of async search <para-sep> todo : integrate with circuit breaker <nl> todo : integrate with circuit breaker <nl> todo : integrate with the circuit breaker,this change tries to write an async response directly to xcontent in base64 to avoid using multiple buffers .,1622686705,"today will wait <nl> indefinitely for the master to process the pending cluster health task , <nl> ignoring the specified timeout . this could take a very long time if the master <nl> is overloaded . this commit fixes this by adding a timeout to the pending <nl> cluster health task .",0.9515858888626099
apache_druid/10936,"migrate bitmap benchmarks to jmh <para-sep> sorted by an order of increasing density <nl> sorted by an order of decreasing density <nl> bitmaps usually have a short circuit to early return an empty bitmap if it finds no intersection during an and operation . we want to let them iterate all bitmaps instead , so add some bits that will be set for all bitmaps we create .","bitmap operation benchmarks are currently written using junit . this pr rewrites them using jmh . also added a new benchmark , , to see if the bitmap order impacts on performance",1614711439,"allows the router to be configured to proxy requests to the active coordinator or overlord . this is different from the current inactive- > active http redirect behavior which has a number of shortcomings and does not work well with some deployment architectures . <nl> the default behavior is for the management proxy to be disabled . see router.md for more information on the routing behavior . <nl> supports tls and security . authentication gets checked on the router ( as well as destination ) , and authorization is checked on the destination ( similar to how the query forwarding",0.9763867259025574
confluentinc_ksql/7145,"add error reason to metadata stream/table <cm-sep> implement info command ( wip ) <cm-sep> move migration into util <cm-sep> rename migration to migrationfile <cm-sep> move versioninfo to separate file <cm-sep> add additional fields to migration version info <cm-sep> progress implementing info <cm-sep> add version into migration version info <cm-sep> switch to map <cm-sep> implement table printing <cm-sep> print current version <cm-sep> clean up integ test <cm-sep> more test coverage <cm-sep> format timestamp when printing <para-sep> issue a single , multi-key pull query <nl> issue multiple , single-key pull queries <nl> format header <nl> format divider <nl> format version info rows <nl> format footer <nl> given : when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> verify current <nl> this is needed to make sure that the table is fully done being created . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :","this pr implements the command . the command does two things : prints the current migration version , and prints a table with information about the different available migration versions . <nl> as part of implementing , this pr also adds a new column ( ) to the migrations metadata stream and table , and contains some minor refactors such as renaming to , renaming to and moving it into its own file , and cleaning up some test code . the refactors are in the first few commits and can be reviewed separately if that 's easier . <nl>",1614763797,"* 0. switch the default so that by default we unwrap single values . <nl> in addition , when adding the new compatibility breaking config many existing tests qtt tests failed , as the actual output form had changed , ( single fields where no longer being wrapped ) . changing the tests to not expect the output to be wrapped worked for the latest version of the tests , but failed for previous version , ( i.e . those listed in dir ) , as they have their persisted config restored . <nl> rather than add a property to",0.9844895601272583
apache_pulsar/10876,always let system topic transaction_buffer_snapshot be auto created <para-sep> the set of all local topic names declared above .,"from the linked issue : . <nl> > while testing the versionrc2 i found that if you start a pulsar broker with transactioncoordinatorenabled=true and allowautotopiccreation=false the broker does not work . <nl> the topic is a system topic , and it should be auto created as needed . <nl> 0. updated the logic in the method to ensure that is considered a system topic . <nl> 0. updated the logic in to take a and then check for equality in stead of check . that could have technically led to unexpected behavior if the topic name was something like or",1623260574,"- provide a flag in , defaults to <nl> - when is disabled and the specified subscription ( ) on the topic does not exist when trying to subscribe via a consumer , the server should reject the request directly by in <nl> - create the subscription on the coordination topic if it does not exist when init",0.9311769008636475
apache_incubator-pinot/6927,"normalize lhs and rhs numerical types for > , > = , < , and < = operators . <para-sep> numerical expressions of form ' column literal ' , where operator can be '= ' , ' ! = ' , ' > ' , ' > = ' , ' -3e9 ' gets rewritten to ' where true ' because int values are always greater than -3e9 . 0 ) where ' intcolumn1 = version and intcolumn2 = intcolumn3 ' 0 ) where ' intcolumn1 ! = version or intcolumn2 = 0 ' ( 0 is out of bounds for integer column ) todo : add support for between , in , and not in operators . recursively traverse the expression tree to find an operator node that can be rewritten . <nl> rewrite expressions of form ' column > literal ' , ' column > = literal ' , ' column < literal ' , and ' column < = literal ' to ensure that rhs literal is the same datatype as lhs column . <nl> get column data type . <nl> no rewrites needed since short and int conversion to numeric column types ( int , long , float , and double ) is lossless and will be implicitly handled on the server side . <nl> literal value is greater than the bounds of int . > and > = expressions will always be false because an int column can never have a value greater than integer.max_value . < and < = expressions will always be true , because an int column will always have values greater than or equal to integer.min_value and less than or equal to integer.max_value . <nl> literal value is less than the bounds of int . > and > = expressions will always be true because an int column will always have a value greater than or equal to integer.min_value . < and < = expressions will always be false , because an int column will never have values less than integer.min_value . <nl> long literal value falls within the bounds of int column , server will successfully convert the literal value when needed . <nl> since we are converting a long value to float , float value will never be out of bounds ( i.e -infinity or +infinity ) . <nl> rewrite range operator <nl> rewrite range literal <nl> long to","future prs will extend numerical type conversion to include other operators ( in , not_int , and having clause ) . <nl> queries with predicates that compare a column expression of one numerical type ( int for example ) with a literal of another numerical type ( double for example ) will fail to evaluate on the server side : . <nl> this happens because we currently do n't support upcasting and downcasting of numerical predicates with different data types . to solve this problem , we rewrite the predicate on the broker side to an equivalent predicate whose literal",1621103548,refactor segmentstatuscheckerintegrationtests to controllerperiodictaskintegrationtest . this will include the integration tests for all controllerperiodictasks . the setup and teardown will be shared across all tests . <nl> add integration test for realtimesegmentrelocation controller periodic task .,0.9607813358306885
apache_druid/11259,fix sql planner bug with inner offset causing loop <para-sep> timeseries can not handle offsets .,"this is because the timeseries query construction during planning was only checking that offset was not present if there was at least one grouping dimension ( when it should 've always been checking this ) , so simply moving this check outside of an 'if ' statement resolves the issue",1621042233,"all dimension positions other than the first index ( which has the value of the last column ) , will have null values instead . <nl> prior to this fix the added test would fail with",0.9019412994384766
apache_shardingsphere/10956,fix booting error with oracle 11g . <nl> booting error with oracle 11g <para-sep> condition 0 : oracle version > = version withoutexistedtables . condition 0 : version > oracle version > = version withoutexistedtables . condition 0 : oracle version = version withexistedtables . condition 0 : version > oracle version > = version withexistedtables . condition 0 : oracle version < version withexistedtables .,booting error with oracle 11g . <nl> changes proposed in this pull request : <nl> - fix booting error with oracle 11g,1624510417,"improve netty backend performance , support multi query results of mysql connections .",0.9142727255821228
jenkinsci_jenkins/5049,convert sshd module to a plugin,". <nl> - ~~ [ ] for dependency updates : links to external changelogs and , if possible , full diffs~~",1604841742,"* update jna from version to version to fix issue with shared library loading on aix when using openjdk . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.8562730550765991
Alluxio_alluxio/13208,update docs with latest docgen run .,docs were out of sync . this pr is just to bring things back in line so that future commits can include their doc changes .,1617990778,"when the file being async persisted is deleted from master , the worker heartbeat after the persist will crash due to the file not exist failure . this pr addresses the issue by logging the issues on master , but not returning exception to the heartbeat request .",0.8361993432044983
confluentinc_ksql/7615,use connect default precision for avro decimals if not specified <cm-sep> historic plans <para-sep> when : <nl> then :,"this pr does _not_ change how ksqldb generates output schemas -- the precision is still always written into the schema explicitly , even if the default of 0 was used . <nl> added unit + integration tests .",1622557499,this patch adds a condition to check for zero decimal values and calculates their precision correctly .,0.9147965312004089
Graylog2_graylog2-server/10156,enable csv export for all exportable widgets . <cm-sep> use in test . <cm-sep> use in other tests . <para-sep> eslint-disable-next-line class-methods-use-this <nl> eslint-disable-next-line class-methods-use-this,"prior to this change , exporting capability was hard-coded to the message table . this change is now making it possible for all widgets , whose property is . this allows us to gradually implement exporting capabilities for other widgets as well .",1614255530,"even when ' root-user ' was listed under in the configuration file , the root user would still be shown on the frontend and used at some places in the code . having the root-user linger even though it ca n't really be used is confusing . <nl> the root user will now be hidden in the frontend and it has been made clearer in the api that the root user might not exist ( by making the return value optional ) . <nl> setting the root user 's password in the config is not required anymore when the user",0.913348913192749
vespa-engine_vespa/17818,add utility class containing vespa version <cm-sep> extend closeable <cm-sep> construct underlying apache httpclient5 builder,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620732981,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.961586058139801
quarkusio_quarkus/17478,"use vert.x spi for opentelemetry integration . <para-sep> jaeger spanexporter support . jaeger spanexporter support is enabled by default . <nl> the jaeger endpoint to connect to . defaults to if unset . <nl> the maximum amount of time to wait for the collector to process exported spans before an exception is thrown . a value of will disable the timeout : the exporter will continue waiting until either exported spans are processed , or the connection fails , or is closed for some other reason . <nl> only create the jaegergrpcspanexporter if an endpoint was set in runtime config <nl> create batchspanprocessor for jaeger and install into lateboundbatchspanprocessor <nl> find all known spanexporters and spanprocessors <nl> should not be reached : dump what was injected if it somehow passed <nl> should not be reached : dump what was injected if it somehow passed <nl> opentelemetry support . opentelemetry support is enabled by default . <nl> build / static runtime config for tracer * / <nl> static init * / <nl> static init * / <nl> set tracer provider if present <nl> add propagators . //todo need a way to handle this with config <nl> static init * / <nl> runtime init * / <nl> not allowed <nl> support for tracing with opentelemetry . support for tracing will be enabled if opentelemetry support is enabled and either this value is true , or this value is unset . <nl> build / static runtime config for span exporters * / <nl> build / static runtime config for span exporters * / <nl> static init * / <nl> static init * / <nl> define service resource <nl> find all spanexporter instances <nl> find all spanprocessor instances <nl> register shutdown tasks <nl> runtime init * / <nl> create new span <nl> add attributes <nl> builder.setattribute ( semanticattributes.http_url , ( ( clientrequestcontextimpl ) requestcontext ) .getinvocation ( ) .getactualtarget ( ) .geturi ( ) . ) <nl> todo is this ok as we do n't have an exception to call recordexception ( ) with ? <nl> tracingoptions overrides <nl> vertxtracerfactory overrides <nl> vertxtracer overrides <nl> retrieve any incoming span <nl> create new span <nl> todo - figure out how to handle span name in a better way . <nl> add attributes <nl> smallrye reactive messaging with kafka is responsible for creating spans for outgoing messages . in this spi call there is no way",- implement vert.x tracing spis for opentelemetry <nl> - update opentelemetry to version <nl> - update package names to reflect the usual naming pattern <nl> - implement opentelemetry context storage backed by vert.x context,1622041684,"please do n't merge , i will merge it myself .",0.9801917672157288
apache_pulsar/10614,fixed issues in pulsar-client shading configuration <para-sep> return the maximum for a given buffer to be encrypted or decrypted . this is meant to allow to pre-allocate a buffer with enough space to be passed as,"there are few issues in the dependencies exposed by and modules : <nl> 0. protobuf is exposed as a dependency , being pulled by , even though it 's not used anymore . <nl> 0. must not be included in the shaded jar , instead it needs to stay as a transitive dependency of the shaded jar <nl> 0. some depedendencies were not being included in the shaded jar",1621269216,"currently the logic for determining if a role is a super user is not pluggable . thus , users have to specify who is a super using the the configuration of a broker which is hard coded . <nl> making the logic of determining if a role is a super user pluggable while allow users more flexibility in setting super users which can be a dynamic list of users held in an external source . <nl> made the mechanism of determining super users pluggable",0.9674134850502014
apache_incubator-pinot/6306,some geo function improvements <cm-sep> relax check on stcontain <para-sep> sets the geometry to geography . <nl> sets to geometry . <nl> creates a point .,"instead of , we can now use . <nl> - support creation from literal such as <nl> - swapped latitude , longitude for calculation for geography . <nl> , etc . <nl> does this pr otherwise need attention when creating release notes ? things to consider : <nl> - the signature of is changed to take an optional third parameter . 0 ( default ) means geometry , 0 means geography <nl> - in is changed to for geography .",1606890619,"in the previous pr support was added for computing the number of rows per chunk based on the metadata ( variable width column value max length ) . <nl> in this pr , the writer tracks the chunk offsets in the file header using long instead of int . the writer version has been bumped to protect compatibility . backward compatibility test has also been added . <nl> there could be cases where text column value is several hundred thousands of characters . in our particular case around 0 % values ( of the total rows in a segment )",0.9567475318908691
Graylog2_graylog2-server/10766,fix handling of null timerange when retrieving field types .,"this pr is fixing an issue with the hook being used to retrieve field types for widgets in case where the widget has no custom time range . in these cases a of is passed , resulting in a 0 being returned by the backend and no field types being shown in the widget edit form . <nl> this pr is doing two things to improve this : . <nl> - filter out the prop from the request if it is <nl> - accept values for and in the backend .",1622555701,"the pr also changes how we add handlers to the promises in the sidecar stores , to ensure that an error in the backend will not call handlers added to the action promise .",0.8425225019454956
gocd_gocd/8464,"* add a safety check around config parial hash generation . <nl> the hash generation function serializes config entity into xml and then <nl> computes hex . there is a possibility of plugin providing a structurally <nl> invalid config which can fail during serializing into xml . hence , <nl> add a try/catch safety net to avoid failures while serializing . <para-sep> hashes.digestpartial method is responsible to serialize domain config entity into xml and then compute hex in case of a deserialization bug , a plugin may return an invalid config which might fail during serializing into xml hence , in case of a serialization error , return null has hash it is safe to return null on a structurally invalid config , as once a the config is fixed , a hash will be computed . <nl> handles null","description : . <nl> * add a safety check around config partial hash generation . <nl> the hash generation function serializes config entity into xml and then <nl> computes hex . there is a possibility of plugin providing a structurally <nl> invalid config which can fail during serializing into xml . hence , <nl> add a try/catch safety net to avoid failures while serializing .",1597414832,* show errors occurred due to invalid config merge . <nl> * show errors occurred due to invalid config repo material .,0.9374694228172302
ballerina-platform_ballerina-lang/27933,"refactor qualifier rules in error handler <cm-sep> add a test case for top level function keyword recovery . <cm-sep> refactor func qualifier rules in error handler <para-sep> assume we only reach here for transactional-expr <nl> fall through <nl> ideally , optimal solution should not be an insert action on qualifiers . therefore , qualifier ctxs are pointed to the end of qualifier parsing token to exit early .",for example : <nl> assume lookahead_limit = 0 and entry point to the error handler is a qualifier starting context . <nl> in old approach : <nl> 0 qualifier case : we traverse 0 + 2x1 + 2x1x1 + 2x1x1x1 + 2x1x1x1x1 = 0 alternative qualifier paths . <nl> 0 qualifier case : we traverse 0 + 4x3 + 4x3x3 + 4x3x3x3 + 4x3x3x3x3 = 0 alternative qualifier paths . <nl> in new approach : <nl> 0 qualifier case : we traverse 0 alternative qualifier paths . <nl> 0 qualifier case : we traverse 0 alternative qualifier paths .,1610999047,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9527923464775085
confluentinc_ksql/6749,add back dummy mapvalues at table source for sr-enabled joins <cm-sep> delete old plans <cm-sep> add new plans,"the previous pr removed the forced materialization at table sources for sources used in joins with sr-integrated key formats , as it 's known that these sources will be repartitioned prior to the join . as part of doing so , the previous pr also removed the dummy call at such table sources , as it 's a no-op . <nl> qtt .",1607546974,"the still fails occasionally on jenkins . the problem is that there are no logs for the run since the log files are not accessible on jenkins . this patch adds a logging configuration to redirect the logs to stdout . <nl> another notable thing from recent failures is only some of the expected outputs are printed . there is a point in the code where we abort reading from the server if the response stream contains a non-null error . if we get a spurious error , then it would explain the test failures . so this patch adds",0.7423510551452637
apache_incubator-pinot/6964,fixed genericrow compare for different _fieldtovaluemap size <para-sep> place different data throughout the nested collections to ensure we 're checking deep equality <nl> todo : comparison of sets of arbitrary objects is not specifically supported since isequalset uses isequalignoreorder which requires sorting . <nl> an effective copy of arrays.deepequals but using equalityutils.isequal for element comparison rather than .equals .,"genericrow.comparemap will now return false if the maps are different sizes . <nl> i 'm fairly new to this project , so i do not believe this affects upgrades , but i am also not sure where genericrow equality checks are done or how important they are . <nl> no . <nl> does this pr fix a zero-downtime upgrade introduced earlier ? no . <nl> does this pr otherwise need attention when creating release notes ? no <nl> # # release notes .",1621896175,"review comment : added logic to set a minimum of 0 k rows if the target number of rows computes to be too small . <nl> this avoids corner cases where incoming stream has issues and we consume too small number of rows . <nl> changed updateflushthreshold method to be synchronized since multiple partitions could be calling invoking the same method <nl> in the same instance of the object , and we need to serialize them in order for the ratio to be correct . <nl> changed the threshold updater to accept input from partitions other than patition 0 if",0.9453497529029846
elastic_elasticsearch/74125,"treat writtenby as an opaque string . <nl> today is a , but sent over the <nl> wire as a . it 's included in every file chunk sent during <nl> recovery , but parsing it uses a few times , which <nl> is nontrivial , representing > 0 % of the time it takes to deserialize a <nl> . moreover the value is n't actually used for <nl> anything so the parsing is wasted work . <nl> with this commit we treat this field as an opaque string , avoiding the <nl> unnecessary parsing effort . we do n't remove it because it appears in <nl> e.g . a snapshot repository , where it may be useful for debugging . <para-sep> returns a string representation of the lucene version this file has been written by or null if unknown","today is a , but sent over the <nl> wire as a . it 's included in every file chunk sent during <nl> recovery , but parsing it uses a few times , which <nl> is nontrivial , representing > 0 % of the time it takes to deserialize a <nl> . moreover the value is n't actually used for <nl> anything so the parsing is wasted work . <nl> with this commit we treat this field as an opaque string , avoiding the <nl> unnecessary parsing effort . we do n't remove it because it appears in <nl> e.g",1623761246,few things that prevent us from supporting cross-clusters tasks cancellation : . <nl> this does n't hold for a cross-clusters task as the parent task does not belong to the remote cluster . <nl> 0. ban action is n't registered on proxy nodes . <nl> 0. banned parent markers are removed when a node with the parent task leaves the cluster . this issue is similar to the first issue . <nl> ~this commit tries to address the third issue by periodically ( every 0 minutes ) sending heartbeats for banned parent markers and removing markers that have n't received,0.9489067196846008
apache_incubator-pinot/6873,expose info about json index on column <cm-sep> expose information about star tree index <para-sep> get the json object containing star tree index details for a segment . <nl> helper to loop over star trees of a segment to create a map containing star tree details .,this pr exposes information about json index and star tree index in the segment metadata api . <nl> sample response :,1619983388,"* currently , it is not easy to get all the tables of a certain tenant . you have to start by getting the instances and manually finding the tables on those instances . <nl> * this api will look at table config in zk and gather the tables that are tagged with the particular tenant .",0.9607517123222351
elastic_elasticsearch/72984,"speed up geotile aggregation over geo_shape field <para-sep> min values are included , max values are excluded <nl> for every level we go down , we half each dimension . the total number of splits is equal to 0 < < ( levelend - levelstart ) <nl> the start value of a dimension is calculated by multiplying the value of that dimension at the start level by the number of splits . choose the max value with respect to the bounding box . <nl> the end value of a dimension is calculated by adding to the start value the number of splits . choose the min value with respect to the bounding box . <nl> do the same for the x dimension taking into account that the bounding box might cross the dateline . <nl> for every level we go down , we half each dimension . the total number of splits is equal to 0 < < ( levelend - levelstart ) <nl> the start value of a dimension is calculated by multiplying the value of that dimension at the start level by the number of splits <nl> the end value of a dimension is calculated by adding to the start value the number of splits","when a tile is inside a geometry , we use recursion to add all the tiles at the aggregation precision . for geotile aggregation we can do better by computing the range of tiles that needs to be added . then we just need to do a simple iteration to add the corresponding tiles . some rough measurement shows speed ups of around ~0 % .",1620825977,"we generate a circular reference exception in translog in version in the following scenario : . <nl> - the first hits ' too many open files ' exception when it 's copying a checkpoint file . we will set the tragic exception and close the translog . <nl> - the second hits alreadyclosedexception as the current writer is closed . we will suppress the ace to the current tragic exception . unfortunately , this leads to a circular reference as ace already suppresses the tragic exception . <nl> other factors that help to manifest this bug : . <nl> -",0.9305921792984009
apache_flink/15298,add show views test in cliclientitcase,"this is just do some code clean before unify the parser . move the show views test from the cliclienttest into cliclientitcase . it also removes some usesless codes . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - does this pull request introduce a new feature ? ( yes / no ) <nl> - if yes , how is the feature documented ? ( not applicable / docs / javadocs / not documented )",1616235794,"fs connector should use format options style . like : . <nl> - filesystemformatfactory implements factory <nl> - update formats . <nl> this change is already covered by existing tests . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : ( yes ) <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects deployment or recovery : jobmanager ( and its components ) , checkpointing ,",0.9465516209602356
Alluxio_alluxio/13241,split read and write timeouts .,"in certain environments , the read and write timeout may not make sense to be equal . for example , it may be desirable to fail fast on reads and retry while allowing for a long timeout on writes because retries can not be attempted .",1618526388,makes specific constants for ufs ops through the worker instead of using constants intended for other purposes .,0.8741291165351868
vespa-engine_vespa/17897,rename 'connectioninfo ' to 'connectioninfos ' <cm-sep> ensure sslengine instances are purged on connection closed <para-sep> extra mapping as callbacks in sslhandshakelistener only provides sslengine ( no connection reference ) as argument,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1621420722,register servlet during request dispatch . the write listener was previously registered on the first write from a . this pr fixes the issues resulting in and corrupted jetty buffers .,0.9239629507064819
apache_pulsar/10093,"time based backlog quota . <cm-sep> fix style .. <para-sep> handle exceeded size backlog by using policies set in the zookeeper for given topic . <nl> drop the backlog on the topic . <nl> if enabled precise time based backlog quota check , will expire message based on the timebasequota <nl> set the reduction factor to 0 % . the aim is to drop down the backlog to 0 % of the quota limit . <nl> if disabled precise time based backlog quota check , will try to remove whole ledger from cursor 's backlog <nl> timestamp only > 0 if ledger has been closed <nl> skip whole ledger for the slowest cursor","add istimebacklogexceeded in persistenttopic to check whether time based backlog quota has exceeded for given topic . <nl> - does this pull request introduce a new feature ? ( yes / no ) <nl> - if yes , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation , explain why ? <nl> - if a feature is not documented yet in this pr , please create a followup issue for adding the documentation",1617148021,"in our use case we require using java client with pattern subscription to read from a set of non-persistent topics . unfortunately , right now this feature does n't work . after researching the cause for this i have found out that under the hood the client is requesting a list of topics by namespace from the server and then filters them out by pattern and subscribes to them . the method in pulsar broker namespaceservice class that is responsible for searching for required topics only uses ledgers , thus returning only persistent topics to the client . the goal",0.9604008197784424
elastic_elasticsearch/73649,[ 0.x ] delete mounted indices after in searchable snapshots yaml tests <cm-sep> revert ' [ 0.x ] delete mounted indices after in searchable snapshots yaml tests ' . <nl> this reverts commit sha . <cm-sep> add wipesearchablesnapshotsindices <cm-sep> adjust version <cm-sep> of course <cm-sep> found the culprit <cm-sep> ifs <para-sep> returns whether to preserve searchable snapshots indices . defaults to not preserving them . only runs at all if xpack is installed on the cluster being tested . <nl> clean up searchable snapshots indices before deleting snapshots and repositories <nl> retrieves all indices with a type of store equals to ' snapshot ',"this commit adds some clean up logic to esresttestcase so that searchable snapshots indices are deleted after test case executions , before the snapshot and repositories are wipe out .",1622621449,"as requestoptions add requestconfig , users can set some request config per request , e.g sockettimeout . <nl> without requestconfig , sockettimeout can only set in restclient init . <nl> as different kind of request maybe have different request options , users can set requestconfig optional .",0.9284743070602417
elastic_elasticsearch/74630,make allows remote indices a request property <para-sep> determines whether the request can contain indices on a remote cluster .,"some requests can reference index names on a remote cluster , yet most do n't . <nl> when ( locally ) authorizing requests that can not reference remote indices , the security code takes a ( cached ) shortcut to first check if the request is authorized for any index , before doing the in-detail authorization on the actual indices . <nl> this pr moves the ' allows remote indices ' property to the indices request away from security code , with the goal that it 's useful to non-security code as well ( rather than duplicating it in the",1624888726,"pipeline aggregations like , , and <nl> only operate on buckets that have multiple buckets . <nl> this adds support for those aggregations to , , <nl> , and . <nl> this all happened because we used a marker interface to mark compatible <nl> aggs , and it was fairly easy to forget <nl> to implement the interface . <nl> this replaces the marker interface with an abstract method in <nl> , which makes you return , <nl> , or . the aggregations can check for . at <nl> this point and amount to about the same thing , but",0.8705289363861084
elastic_elasticsearch/73562,"move vector til implementation to its own module <para-sep> uses internal java api : sun.misc.unsafe <nl> redistributions in binary form must reproduce the above <nl> neither the name of google inc. nor the names of its <nl> rest test for _mvt end point . the test only check that the structure of the vector tiles is sound in respect to the number of layers returned and the number of features abd tags in each layer . <nl> desc order , polygon should be the first hit <nl> asc order , polygon should be the last hit <nl> to be overriden by tests <nl> todo : not sure what is the difference between extent and tile size ? <nl> mvt tile geometry to mvt features <nl> todo : handle degenerated rectangles ? <nl> utility functions to transforms wgs84 coordinates into spherical mercator . <nl> no instances <nl> gets the jts envelope for z/x/y/ tile in spherical mercator projection . <nl> transforms wgs84 longitude to a spherical mercator longitude <nl> transforms wgs84 latitude to a spherical mercator latitude <nl> it is just much more efficient for those shapes . <nl> 0 <nl> 0 <nl> 0 <nl> close <nl> main class handling a call to the _mvt api . <nl> mime type as defined by the mapbox vector tile specification <nl> this will allow to cancel the search request if the http channel is closed <nl> even if there is no hits , we return a tile with the meta layer <nl> todo : should we expose the total number of buckets on internalgeotilegrid ? <nl> todo : i wonder if we can leverage field and format so what we get in the result is already the mvt commands . <nl> todo : see comment on field formats . <nl> add geometry <nl> todo : it should be the centroid of the data ? <nl> add count as key value pair <nl> transforms a rest request in a vector tile request <nl> todo : should it be searchservice.default_size ? <nl> todo : should it be 0 , no aggs by default ? <nl> specific for vector tiles <nl> this should validate that z/x/y is a valid combination <nl> todo : validation <nl> top term and percentile should be supported <nl> should not have pipeline aggregations <nl> utility methods for vector tiles . <nl> no instances <nl> creates a vector layer builder with the",this pr moves all new vector tile code into its own pack module called vector-tile . i am removing lots of unused code which was developed as part of the original prototype so the code is looking more similar to the final version . in particular i have removed all the aggregations implementations as we are not using them . <nl> in addition i added a couple of nice things : . <nl> * the api now handles cancellation which it turned to be a big performance booster . <nl> * the api supports defining a sort field . <nl>,1622470131,"the deprecation indexing code was writing to a regular data stream , and it is not yet possible to hide a data stream or prefix it with a period . this functionality we be re-added once it is possible to mark a data stream as hidden , and also to not rely on the standard logs template since that can be disabled .",0.9693613052368164
elastic_elasticsearch/72843,".snapshot-blob-cache index is created today with a data tier <nl> preference set to data_cold , data_warm , data_hot . this does <nl> not works well with autoscaling and clusters that only have <nl> a hot and a frozen tier : in such cases autoscaling adds a <nl> cold tier just to host this system index . <nl> this commit changes the tier preference to data_content , data_hot . <cm-sep> adjust version <para-sep> prefer to allocate to the data content tier and then the hot tier .","snapshot-blob-cache index is created today with a data tier <nl> preference set to data_cold , data_warm , data_hot . this does <nl> not works well with autoscaling and clusters that only have <nl> a hot and a frozen tier : in such cases autoscaling adds a <nl> cold tier just to host this system index . <nl> this commit changes the tier preference to data_content , data_hot .",1620375656,"0. we passed for the map which is n't nullable any longer <nl> when creating , fixed by just passing an empty map <nl> like the handling did in the past . <nl> 0. the removal of a failed state snapshot from the cluster state tried <nl> removing it from the finalization loop ( the set of repository names that are <nl> currently finalizing ) . this will trip an assertion since the snapshot failed <nl> before its repository was put into the set . i made the logic ignore the set <nl> in case we remove a failed state",0.8881648778915405
apache_incubator-pinot/6711,set thread cpu time in setexecutionstatistics ( ),"this pr remove a todo : put thread cpu time setting logic in . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1616465254,add missing init ( ) for anomalydetectioninputcontextbuilder,0.8469571471214294
apache_incubator-pinot/6204,add upsert metadata metric of the primary key counts per partition metadata manager <para-sep> sets the value of a table partition gauge . <nl> upsert metrics <nl> update metrics <nl> update metrics <nl> update metrics,add upsert metadata metric of the primary key counts per partition metadata manager .,1603843357,"a server config is added to control the code path to upload metadata files or not . by default , it is true .",0.9420294761657715
elastic_elasticsearch/73963,"expose community id processor in painless <para-sep> should never happen , must be available in all jdks",adds two methods to painless that exposes the functionality of the community id processor .,1623258649,make serializing a little faster ( worth it since for large repos we could be parsing multiple mbs of data here ) and split up/document the code for it a little as well given how massive this method has gotten at this point . <nl> mainly motivated by the fact that upcoming work will add further information to which will be less painful to understand with slightly more understandable serialization logic .,0.9712718725204468
apache_shardingsphere/10736,refactor postgresql proxy <cm-sep> fix empty sql cause npe <cm-sep> fix empty sql parsing error <cm-sep> fix checkstyle <cm-sep> fix postgresqlcomdescribeexecutortest <cm-sep> refactor postgresql proxy protocol <cm-sep> fix no data packet may be missing <cm-sep> fix get optional class mistake <cm-sep> fix sql command not found <cm-sep> fix postgresql frontend test cases <cm-sep> add postgresqlnodatapackettest <cm-sep> replace threadlocal with connectioncontextregistry <cm-sep> fix checkstyle <cm-sep> fix test case <para-sep> no data packet for postgresql .,"changes proposed in this pull request : <nl> - add and corresponding registry . <nl> - , , command executors will pending until executing command executor . <nl> - return packet at the right time .",1623231555,changes proposed in this pull request : <nl> - extract mysql subquery in select clause <nl> - extract mysql subquery in from clause <nl> - extract mysql subquery in where clause,0.982276439666748
Alluxio_alluxio/12710,add logging and add folder feature <cm-sep> add test <cm-sep> checkstyle <para-sep> need to create a folder <nl> helper interface to add to request methods that needs logging for debugging . <nl> helper class for adding logs to request methods for debugging purposes .,"when the key ends with a separator , it means a directory should be added",1610478489,added dependency viewing feature to ui .,0.9521756172180176
ballerina-platform_ballerina-lang/30904,avoid setting closure for all onfail var refs <cm-sep> add breakable mode <cm-sep> support jumping to end and outside a block stmt <cm-sep> improve on fail tests <para-sep> we need to create a new variable for the expression as well . this is needed because integer ranges can be added as the expression so we can not get the symbol in such cases . <nl> get the symbol of the variable ( collection ) . <nl> rewrite the block . <nl> supported types : not_breakable - do not transfer control flow break_within_block - transfer control flow to the end of current block statement break_to_outer_block - transfer control flow to the immediate outer block statement,> introduce breakable mode to identify whether to change control flow to the end or outside the current block statement .,1622526207,move workerdatachannels to stackframe … <nl> when a default worker fails while a worker wait for an action we need to notify the waiting worker <nl> when popping the stackframe . this is not possible when we do such notifications from the strand <nl> callback signal . hence wd channels are moved to stackframe .,0.9575532674789429
apache_druid/11081,fix nested groupby got empty result when using virtual column,"we have a sql like this : . <nl> expected result is 0 , but got empty result ! <nl> in order to reproduce this problem , we explain the above sql and add the following unit test into nestedquerypushdowntest.java according to the explained plan ( not the same but has the same pattern ) : . <nl> then we debug the above test . <nl> the dimfilter from the outer query will be used to filter out result rows of inner query ( in method rowbasedgrouperhelper.getresultrowpredicate ( ) ) . however , virtual column 'v0 ' does not exist",1617892307,"all dimension positions other than the first index ( which has the value of the last column ) , will have null values instead . <nl> prior to this fix the added test would fail with",0.9283172488212585
Alluxio_alluxio/13115,reduce default inode cache size . <para-sep> 0 bytes per inode cache key and * 0 for the existence of edge cache and some leeway,each inode cache entry takes up about 0 ~ 0 bytes . so a 0 million default max size is already 0 ~ version gb when full . <nl> this is also not accounting for the edgecache which has the same default max size as inode cache and while smaller than inode cache in average . is n't that much smaller .,1616538579,adding some additional diagnostic messages in tests to understand it better .,0.8288614153862
apache_pulsar/10765,pulsar-perf : print total number of messages,"# # # motivation . <nl> when you run pulsar-perf manually or even in some automated job , it is very useful to see the progress , in terms of number of messages produced/consumed , this way you have a feedback about the progress of the execution . <nl> add the total number of produced and consumed messages",1622541019,we need to break it immediately after having tried all the addresses . <nl> this is currently making tests to fail all the times on master .,0.9229446649551392
grpc_grpc-java/7987,import envoy router.proto <cm-sep> pretty print http filters,"interop test logs showed that router filter in v3 can not be printed , and router filter as well as fault filter in v2 can not be printed . imported protos and added proto descriptors to .",1616047112,"the way of generating self-signed keys and certificates in tls example does not work , since the generated certificates does not contain subject alternative names . <nl> for maintainability , we do not provide a separate set of certs here . we recommend users to use our test certs for running the tls example .",0.7891474366188049
ballerina-platform_ballerina-lang/30365,fix shell unicode not identifying issue <para-sep> convert unicode character to ballerina unicode format .,issue occurred due to java unicode type is different from the ballerina unicode type . added a function to convert unicode types .,1620207857,"now , bvm errors will be logged to a file in the current user dir . if ballerina does n't have permission to write the log file there , it will write the log to the folder of the os . the log file is now called . the dir and bre/conf ` dir of the distribution are also removed with this pr .",0.940281867980957
eclipse-openj9_openj9/11708,"change to use reflection.getclassaccessflags in mhs.checkclassaccess . <nl> using class.getmodifiers ( ) for an innerclass will return the source code <nl> level modifiers from the innerclass attribute , which may be different <nl> from the runtime class header . <nl> change to use reflection.getclassaccessflags will ensure the actual <nl> jvm romclass modifiers are used for access checks . <para-sep> use reflection.getclassaccessflags to get the actual rom class modifiers instead of the attribute flags for innerclasses","using class.getmodifiers ( ) for an innerclass will return the source code <nl> level modifiers from the innerclass attribute , which may be different <nl> from the runtime class header . <nl> change to use reflection.getclassaccessflags will ensure the actual <nl> jvm romclass modifiers are used for access checks .",1611158388,was a hack to enable the modifiers field to be <nl> final for jit purposes . it 's better to just do the isstatic <nl> check in the constructor once rather than making it part of the <nl> invoke/invokeexact sequence .,0.9013301134109497
vespa-engine_vespa/18172,rename 'jsonstreamfeeder ' to 'jsonfeeder ' <cm-sep> rename 'feed ' to 'feedmany ' <cm-sep> split out parser and dispatch of operations to separate class <cm-sep> make client mock mark async operations as completed <cm-sep> make feedmany async + introduce callback for each operation result,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623231292,this pr fixed the issue where we did not add a changed session to session cache when there was already an item in the cache . this led to application being loaded twice and performance issues .,0.9796687364578247
apache_flink/16309,fix ziputils to handle properly for softlinks <para-sep> the content of the file is the target path of the symlink <nl> the permission of the target file will be set to be the same as the symlink todo : support setting the permission without following links <nl> this may happens when the target file of the symlink is still not extracted <nl> * /,"# # what is the purpose of the change . <nl> this pull request fixes ziputils to handle properly for softlinks . <nl> - fix ziputils <nl> - added test cases ziputilstest . <nl> - added tests ziputilstest . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api , i.e. , is any changed class annotated with : ( no ) <nl> - the serializers : ( no ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( no ) <nl> - anything that",1624882621,"after we introduce region failover , pending checkpoints would be aborted when task failed . however , previous implementation would come across a bug leading to periodical checkpoint is invalid . <nl> previously , when checkpoint coordinator trigger a checkpoint and the size of pending checkpoints is larger than ( default 0 ) , it would just assign the to null . however , the pending checkpoints would then possibly be aborted due to region failover , which lead to no pending checkpoints and no . in the end , the periodical checkpoint mechanism would become not valid anymore .",0.9534507989883423
quarkusio_quarkus/17345,avoid expensive copying into hashset <cm-sep> use small lists as most resources will resolve without ambiguity,"spotted via profiling , two low hanging fruits . <nl> i have a couple more optimisations in the pipeline but they are less trivial and will actually need tests - when i have more time .",1621413867,so using the pgiterator is no longer needed in the guide .,0.8021555542945862
Graylog2_graylog2-server/10280,"simple first version with a stripped down interface for the dto and lax requirements on the web side for discussion <cm-sep> summaries for dashboards and searches ( viewdto ) <para-sep> a short , one sentence description of the view <nl> a longer description of the view , probably including markup text","in places where only a subset and not all object 's attributes is needed , only summaries of searches and dashboards are loaded and transferred between backend and frontend . <nl> also , a new viewsummaryservice i introduced and injected into the dashboardresource and searchresource . <nl> the requirements for view on the frontend-side have been loosened so that missing fields that had been required in the past are no longer necessary . <nl> feature branches ) and documents with those fields exist in the db , loading those documents fail after switching to a different branch that does not",1616068420,"this pr is inlining the required code parts into the package of that migration to make it independent , and remove the original / classes .",0.9738210439682007
apache_pulsar/10182,issue 0 : transactions : broker side nullpointerexception in case of enabletransactioncoordinator=false,this change is a trivial rework / code cleanup without any test coverage .,1617965830,"when i use oracle jdk version，the broker metrics will export as follow : . <nl> and then prometheus will failed when parsing . <nl> the reason is when using to collect jvm info , it returns jvm vendor with , and in the pulsar source code , it adds in both sides , so it comming with , and prometheus parse failed .",0.9005119204521179
apache_druid/11040,"add avro stream input format <para-sep> your schema goes here , for example <nl> your schema goes here , for example <nl> your id - > schema map goes here , for example <nl> prepare data <nl> encode schema id <nl> encode data <nl> write avro datum to bytes <nl> prepare data <nl> encode schema id <nl> encode data <nl> write avro datum to bytes","because of deprecated of parsespec , i develop avrostreaminputformat for new interface , which supports stream ingestion for data encoded by avro",1616920373,add sql inputsource support for ingesting events from rdbms using parallel indexing,0.9855411052703857
ballerina-platform_ballerina-lang/29111,add path fixes for ballerina file code coverage <para-sep> modify classes in coveragebuilder to reflect ballerina source root . <nl> normalize package name and class name for classes generated for bal files <nl> normalize source file package name <nl> get package instance and traverse through all the modules <nl> escape special characters before using in regex <nl> capture file paths with the format ' orgname/packagename/xxxx/file-name ' and replace with ' /file-name ' <nl> capture remaining file paths with the format ' orgname/packagename/file-name ' and replace with ' ' <nl> represents a coverage class containing normalized package and class names to reflect ballerina source root . <nl> packagename normalization is not done for non-ballerina classes and normalizedpackagename is null . <nl> test class to test report using a ballerina project . <nl> validate package names in xml file <nl> validate package names in xml file per module <nl> add the tests only module ( bar.tests ) to the package name list <nl> validate class names in xml file per module <nl> validate class names in class elements for a given module . <nl> get the expected class elements per each package element in covergae xml . <nl> validate package names in package element per module . <nl> copy the report.dtd file to the coverage xml path for validation . <nl> validates actual package names against the expected package names . <nl> validate xml file <nl> validate actual class names against the expected class names .,add path fixes for ballerina file code coverage to support seamless integration to external tools . <nl> tested for the following cases : . <nl> - package with only default module <nl> - package with a single module <nl> - package with multiple modules <nl> - package with hierarchical module names .,1615395866,this pr ; <nl> - adds native code to ballerina file builder <nl> - implements ballerinaannotation and generate annotated ballerina files from annotated native code <nl> - removes libsrc directory <nl> - merges native code defined in ballerina with automatically generated bal files,0.9835313558578491
apache_flink/16055,removed unused method in localinputchannel <cm-sep> remove unused constructor in testtaskstatemanager <cm-sep> rename triggercheckpoint to better reflect a difference compared to other similarly named methods <para-sep> math.max (,"this pr is fixing a bug of being not set in of and . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects deployment or recovery : jobmanager ( and its",1622640242,"thank you very much for contributing to apache flink - we are happy that you want to help us improve flink . to help the community review your contribution in the best possible way , please go through the checklist below , which will get the contribution into a shape in which it can be best reviewed . <nl> please understand that we do not do this to make contributions to flink a hassle . in order to uphold a high standard of quality for code contributions , while at the same time managing a large number of contributions ,",0.9281352758407593
apache_pulsar/10467,fix publish callback 's entry data is null during ledger rollover <para-sep> will be released in,"however , when a ledger is full and the rollover is triggered , the method will be triggered in and the argument is null . <nl> - extend the lifetime of when is called in , and pass the to , after that , release the . <nl> - make current test cover the ledger rollover case . <nl> this change is already covered by existing tests , such as managedledgertest # asyncaddentrywithouterror .",1619959086,since we mocked classlayout.parseclass ( ) because we need to exclude org.openjdk.jol for license issues . lets come up with another way to estimate class size,0.862721860408783
gocd_gocd/8919,"remove warning logs while checking file status as the cruise-config , jetty and aes_cipher files need to be present for the server to get started . <nl> - also removed the syncing of the des cipher as the same is no longer required","description : <nl> - remove warning logs while checking file status as the cruise-config , jetty and aes_cipher files need to be present for the server to get started . <nl> - also removed the syncing of the des cipher as the same is no longer required .",1609134414,* delete all the old code ( including controllers/views/js/specs ) <nl> * there 's a new entrypoint ' shim ' on the old pipelines page . this shim <nl> is responsible for exporting a helper function that assists in loading <nl> the ' show template ' modal from the old pipeline edit page . this is the <nl> ' lens ' icon in the sidebar when viewing a pipeline associated with a <nl> template .,0.8595985770225525
apache_shardingsphere/10561,"add global rule changed listener factory , add globalrulechangedlistenerfactory to governance doc . <para-sep> global rule changed listener factory .",- add global rule changed listener factory <nl> - add globalrulechangedlistenerfactory desc to governance doc .,1622427537,changes proposed in this pull request : <nl> - add case test for governancetransactioncontexts,0.8889500498771667
hazelcast_hazelcast/18516,fix nomandatorydependencydeclared tests . <nl> - add javax.annotation and javax.jms to the whitelist ( oss side ),this pr adds ~~and ~~ to the whitelist . <nl> checklist : .,1618305283,testing hazelcaststarter with 0.x instances in some tests is broken <nl> due to incompatible changes in version as expected .,0.6325278282165527
grpc_grpc-java/7957,add a flag to interop clients to allow statically configuring grpclb,"this is needed as a pre-req for internal issue b/0 ( in order to use a more recent grpc-java in those tests , we need to configure an explicit grpclb service config ) .",1615408995,added and tested accessing peer attributes map from the handshaker result,0.9038962125778198
vespa-engine_vespa/17993,wire in system.in <cm-sep> sort lines <para-sep> todo add description to each option,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622042167,"today , you get 0 bad request when activation fails due to a conflict . using 0 seems correct and will also gives us the possibility to retry deployment if we want to avoid deployment failures in this scenario . <nl> doc will be updated in another pr .",0.9184247255325317
apache_kafka/10267,do n't update connection idle time for muted connections <cm-sep> clarifying comment in test <para-sep> advance mock time in increments to verify that muted sockets with buffered data dont have their idle time updated additional calls to poll ( ) should not update the channel last idle time <nl> buffered requests should be processed after channel is unmuted,"will always call for channels with buffered data . will always update connection last idle time , even if the channel is muted and we do n't actually read from the channel . <nl> there is an existing unit test that fails to catch this behavior because the object used in the test is updated in a large enough increment to expire a connection between calls to . after updating the test to advance time in smaller increments , the test fails without the selector change .",1614902939,otherwise the join-group would not be resend and we 'd just fall into the endless loop .,0.8897035717964172
apache_flink/15297,add the error info of the exception,"so , i ca n't quickly locate the problem machine when the exception occurs . <nl> this change is a trivial rework / code cleanup without any test coverage . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do",1616230803,"add new entry to list of sensitive configuration parameters , so that the datadog api key is not leaked into logs . <nl> - added to list of sensitive keys . <nl> this change added a new test and can be verified by starting a flink cluster with config key and observing in the log file that the sensitive value is not printed . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no",0.8213619589805603
elastic_elasticsearch/73964,this change tries to write an async response directly to xcontent in <nl> base64 to avoid using multiple buffers . <para-sep> todo : integrate with circuit breaker <nl> todo : integrate with circuit breaker <nl> todo : integrate with the circuit breaker,this change tries to write an async response directly to xcontent in <nl> base64 to avoid using multiple buffers .,1623260252,( cherry picked from commit sha ) <nl> signed-off-by : andrei dan .,0.9508169293403625
elastic_elasticsearch/74188,"[ ml ] remove the undocumented ' delimited ' format for post_data . <nl> the data_description of anomaly detection jobs used to accept <nl> delimited data , although this was never documented . <nl> this change removes the delimited option from the data_description , <nl> and the associated functionality in post_data that handled it . <nl> this is not a breaking change because it 's removing functionality <nl> that officially never existed . however , just in case somebody <nl> was using it it is only removed from version and higher , so that at <nl> least they wo n't find out during a patch install . <para-sep> data must either be in json or smile format ( and only json is publicly documented ) . <nl> delimited used to be an option , although it was never documented . we silently convert it to xcontent now . <nl> works with either xcontent , xcontent , etc . the old value delimited is tolerated as it may have been persisted , but is silently converted to xcontent as it was never documented . any other values throw an exception . <nl> older nodes may serialise delimited on the wire , which will cause an exception . we just silently convert to xcontent like we do when parsing . <nl> the strict parser needs to tolerate this field as it 's documented , but there 's only one value so we do n't need to store it <nl> fielddelimiter <nl> quotecharacter <nl> fielddelimiter quotecharacter <nl> if a configured field is missing from the input <nl> must see in the input datadescriptions timefield is missing <nl> nulls are replaced with empty strings to match the way the c++ process treats them ( which , for historical interest , was originally shaped by the fact that csv can not distinguish empty string and null ) . <nl> old undocumented option silently modified to the only current valid option <nl> old undocumented option silently modified to the only current valid option","the data_description of anomaly detection jobs used to accept <nl> delimited data , although this was never documented . <nl> this change removes the delimited option from the data_description , <nl> and the associated functionality in post_data that handled it . <nl> this is not a breaking change because it 's removing functionality <nl> that officially never existed . however , just in case somebody <nl> was using it it is only removed from version and higher , so that at <nl> least they wo n't find out during a patch install .",1623856106,"this commit cuts over all metadata field mappers to parametrized format . several <nl> of these mappers are non-configurable , and we add a new <nl> that simplifies parsing and building of these mapper types .",0.9773997664451599
ballerina-platform_ballerina-lang/28435,"refactor for project api source root fix <cm-sep> migrate thread reference usages into its proxy implementation <cm-sep> resolve dependency issue <cm-sep> add minor improvements <cm-sep> sync with master <cm-sep> add more improvements <cm-sep> sync with master <cm-sep> fix regression issue related to test sources debugging <cm-sep> fix child variable order for indexed compound variable types <cm-sep> preserve child variable order <cm-sep> complete variable paging implementation <cm-sep> fix order preservation of named child variables <cm-sep> update tests <cm-sep> add paging support for json and map variable types <cm-sep> fix child variable size calculation <cm-sep> enhance child variable loading for map variables <cm-sep> improve json variable implementation <cm-sep> resolve merge conflicts <nl> # conflicts : <nl> # misc/debug-adapter/modules/debug-adapter-core/src/main/java/org/ballerinalang/debugadapter/jdieventprocessor.java <para-sep> debug control flow instructions supported by the ballerina debugger . <nl> context holder for debug execution state related information . <nl> if the last instruction is step-in and there are no valid source information in the top-most stack frame , that means that the debugger has stepped into an unsupported source ( i.e . lang library , standard library , imported module from central ) . todo - enable and refactor accordingly after adding support for external module debugging support . if ( ! isvalidframe ( balframes.get ( 0 ) ) & & lastinstruction == debuginstruction.step_in ) { sendoutput ( ' trying to step into an unsupported source ! rolling back into the previous state .. ' , onsole ) ; stepout ( activethread.uniqueid ( ) ) ; return completablefuture.completedfuture ( stacktraceresponse ) ; } <nl> adds ballerina source information . <nl> handles indexed variables . <nl> handles map-type indexed variables . <nl> handles list-type indexed variables . <nl> handles named variables . <nl> returns a map of all currently running threads in the remote vm , against their unique id . <nl> filter thread references which are suspended , whose thread status is running , and which represents an active ballerina strand . <nl> validates whether the given dap thread reference represents a ballerina strand . <nl> todo - refactor to use thread proxy implementation <nl> validates whether the given dap stack frame represents a ballerina call stack frame . <nl> todo - refactor to use stack frame proxy implementation <nl> validates a given ballerina stack frame for for its source information . <nl> clears previous state information and prepares for the given debug instruction type execution . <nl> clears state information","- arrays <nl> - json <nl> - maps <nl> - xml <nl> - tables <nl> - tuples . <nl> with this feature , ballerina variables which contains a large number of child variables will be shown in a paged view , as shown below . <nl> along with the paging support , this pr also introduces following improvements to debugger variable representation . <nl> - preserve child variable order in the debug view for ballerina ordered variable types ( i.e . arrays , tables ) <nl> - optimize map and json child variable loading mechanism .",1612364438,"with this pr a new parameter is of type ' type ' is added to sql select and call actions . the type of struct needs to passed as an argument when the returned datatable is iterated via structs . with this change , the restriction of having the struct field name which is similar to the db column name is removed . this will give the user more flexibility in writing code which involves complex queries where column name is complex . <nl> ex1 : . <nl> ex2 :",0.9854532480239868
quarkusio_quarkus/18209,revert ' fix broken liquibase version in native mode ' . <nl> this reverts commit sha . <cm-sep> revert ' bump to liquibase version ' . <nl> this reverts commit sha .,"since the upgrade to liquibase version , we have some errors with their license stuff . given we do n't have the sources and things are obfuscated , it 's not exactly easy to know what 's going on so for now , let 's go back to version . <nl> for the record : . <nl> note that graalvm recommends to make runtime initialized but it 's not as easy as it seems as this class is used in a ton of clinits across the codebase . <nl> and for now , i must admit i do n't want",1624894949,let 's see what ci has to say as i ca n't build the main integration tests on my laptop anymore .,0.8541746139526367
vespa-engine_vespa/17380,"sort and group deps based on scope . <cm-sep> move componentgraph.provider from container-di to component . <nl> - it was the only publicapi class in container-di , and is widely <nl> used in the same way as e.g . abstractcomponent from the <nl> component module . <cm-sep> update abi specs after moving provider from di- > component <cm-sep> remove unnnecessary deps and maven config from metrics pom . <cm-sep> remove deps to container-di for modules that only used provider . <cm-sep> add config definitions from container-di . <cm-sep> add java source from container-di . <cm-sep> remove unnecessary plugin configuration . <cm-sep> remove duplicate test deps . <cm-sep> add test config defs from container-di . <cm-sep> remove all dependencies to container-di <cm-sep> do not build or install the container-di module . <cm-sep> remove container-di from code-map . <cm-sep> remove the container-di module . <cm-sep> remove container-di from enforcer . <cm-sep> allow container-disc to embed the 'component ' artifact . <nl> .. to allow deploying it as part of container-disc , instead of a <nl> separate bundle . <cm-sep> fix incorrect method name . <cm-sep> embed 'component ' in the container-disc bundle . <nl> - do not install the component module anymore . <para-sep> provides a component of the parameter type t. if ( and only if ) dependency injection does not have a component of type t , it will request one from the provider providing type t. providers are useful in these situations : some code is needed to create the component instance in question . the component creates resources that must be deconstructed . a fallback component should be provided in case the application ( or system ) does not provide a component instance . <nl> specifies how a component should be instantiated from a bundle . immutable <nl> must only be used when classid ! = null , otherwise the id must be handled as a componentspecification ( since converting a spec string to a componentid and then to a componentspecification causes loss of information ) . <nl> todo : these are the same for now because they are in the same bundle . <nl> return a new instance of the specification with bundle name altered","again , i remind that builders must re-run bootstrap.sh to avoid failure in container-disc when building vespa ..",1618237958,should not be merged until after pending protocol version change has passed entirely through our pipelines and upgrade documentation is in place .,0.9233767986297607
apache_kafka/10362,"use self-managed mode instead of and nozk <para-sep> if is set to , the server acts as a self-managed broker . if is set to , the server acts as a self-managed controller . if is set to , the server acts as both a self-managed broker and a self-managed controller . if is not set at all then we are assumed to be in zookeeper mode . as mentioned earlier , you ca n't currently transition back and forth between zk mode and self-managed mode without reformatting . <nl> support for certain security features : configuring an authorizer , setting up scram , delegation tokens , and so forth support for transactions and exactly-once semantics support for adding partitions to existing topics support for partition reassignment support for some configurations , like enabling unclean leader election by default or dynamically changing broker endpoints support for ' jbod ' modes support for controller metrics <nl> in integration tests . we can remove this after the self-managed controller a self-managed kafka broker . a self-managed kafka controller . self-managed mode configs / self-managed mode configs / self-managed mode configs * / <nl> self-managed mode configs . note that these configs are defined as internal . we will make them public in the version release . this class implements the self-managed mode server ( aka ) which relies on a note that this server is a work in progress and we are releasing it as early access in version . note that we allow the use of self-managed mode controller apis when forwarding is enabled <nl> ensure that apis needed for the self-managed mode ( aka ) self-managed mode configs <nl> quorumcontroller implements the main logic of the self-managed controller ( aka ) .",is not particularly descriptive . i also tweaked the readme text a bit . <nl> tested that the readme for self-managed still works after these changes .,1616164950,this is just a minor typo in the javadoc .,1.0
hazelcast_hazelcast/18570,"implementation of sql extract function <para-sep> datetime <nl> todo : add timestamp_with_local_time_zone support to the parser <nl> intercept date , time , timestamp types to return ( offset , local ) ( date , time ) instead of calendar class <nl> this function is called for check ( ) function to calculate adjustment of the actual value . the reason is that extract function casts its argument to timestamptz to run its logic .","adds support for function . <nl> the function computes date parts from the source field . <nl> example : . <nl> supported types for argument : <nl> - date <nl> - time <nl> - timestamp <nl> - timestamp with time zone . <nl> supported enumeration for argument : <nl> - millennium . <nl> the first millennium starts at 0-0-0 0:0:0 , the second century starts at 0-0-0 0:0:0 etc . <nl> - century . <nl> the first century starts at 0-0-0 0:0:0 , the second century starts at 0-0-0 0:0:0 etc . <nl> - decade . <nl> year divided by",1618918793,* adds new client operations for mc purposes : <nl> - <nl> * a bounded queue was added into member 's to limit consumed when mc is not connected . known restriction : when mc is not connected newer events will be ignored when the queue is full .,0.987946093082428
apache_druid/10892,avoid expensive findentry call in segment metadata query <para-sep> versionedintervaltimeline # addall implementation is much more efficient than calling versionedintervaltimeline # add in a loop when there are lot of segments to be added for same interval and version . <nl> there is one test for a scenario where a single interval has large number of segments . <nl> mock scheduler to return same sequence as argument,"this pr fixes two performance issues in the timeline conversion , observed when an interval has a large number of segments . for such an interval , <nl> - reading the timeline entries from the original timeline . is an expensive operation since it involves a deep copy of the chunk . and on top of that , a deep copy is done for every segment in the interval which significantly amplifies the performance overhead o ( n * n ) <nl> - adding the entries to the new timeline . this involves an call which too is o (",1613475791,the endpoint in and use the api to get overshadowed segments without building the every time . <nl> renamed to . <nl> this pr does not address the mutability of and getting rid of interning in,0.9777395129203796
apache_druid/10762,"fix cardinality estimation <para-sep> for cardinality estimation , we want to consider unique rows instead of unique hash buckets and therefore we do not use partition dimensions in computing the group key","this pr changes the logic to compute total number of output rows when automatically calculating numshards . currently , we estimate the unique number of hash buckets as the cardinality . instead , we would always consider the unique number of rows irrespective of the partition dimensions",1610608828,"this pr fixes an 'off by 0 ' issue in for the scenario that when faced with multi-value dimension rows with 0 elements , and attempting to aggregate on , the grouper would initialize incorrectly into a state where it 's value was , meaning evaluates to false , but is called without checking resulting in something like : . <nl> also fixes an issue in to return instead of assuming the delegate has a next after initialized . this is no longer an issue since the delegate in this case is now getting initialized correctly , but still seems",0.9592783451080322
jenkinsci_jenkins/5301,"clean up interrupts , try-with-resources , lambdas . <cm-sep> use lambdas . <cm-sep> use method reference . <cm-sep> use try-with-resources . <para-sep> we should just propagate this , no point trying to log <nl> safe to ignore and continue for this one <nl> save for later",i figured i 'd try to clean up some things while i was browsing some source files . <nl> * ensure that updates the configuration only when all views are successfully set,1614025659,minor test code cleanup <nl> * simplified asserts <nl> * use try with resources instead of try finally <nl> * minor improvements on stream api calls <nl> * removed some redundancies . <nl> * n/a .,0.9206233620643616
apache_incubator-pinot/6725,"explicitly enable lead controller resource <para-sep> explicitly set resource_enabled to true , so that the lead controller resource is always enabled . this is to help keep the behavior consistent in all clusters for better maintenance . todo : remove the logic of handling this config in both controller and server in the next official release .","the purpose of this feature is to logically separate per-table functionality in all clusters . <nl> after enabling lead controller resource , the controller host listed under znode only denotes the helix lead controller in the cluster . <nl> the lead pinot controller for each of the tables can be found by the following apis : <nl> get the leaders for all the tables in the cluster <nl> get /leader/tables . <nl> given a table name , return the partition id and lead controller instance id <nl> get /leader/tables/ { tablename } . <nl> the config is to be removed",1617039461,* move logic for tagging events as ' baseline ' from backend to frontend . <nl> * display baseline event in light color . <nl> * tweak/fix labels and formatting of events,0.860720694065094
trinodb_trino/7959,merge pushpredicateintotablescan with simplifyoptimizer invocations . <nl> the invocations can be run together .,the invocations can be run together .,1621338043,"allow presto to correctly read from exernal hive tables that use to sotre null in an alternate format . <nl> this works with , , and formats . there are no tests for the latter two ( because they ca n't be easily embedded in the tests because they are binary file formats and presto ca n't insert data into external hive tables ) .",0.8125935196876526
Alluxio_alluxio/13387,do not include secondary master by default in localalluxiocluster,the goal of this pr is to make tests faster/less flaky .,1620689495,"the root cause for the deadlock was . <nl> makes calls into , and , but and both call synchronously while holding -level locks . this leads to an issue where and each try to grab a lock on the other .",0.901501476764679
grpc_grpc-java/7944,simplify clientxdsclienttestbase by reusing test resources <para-sep> lds test resources . <nl> rds test resources . <nl> cds test resources . <nl> eds test resources . <nl> locality with 0 endpoints <nl> locality with 0-weight endpoint <nl> add another watcher . <nl> initial lds response . <nl> updated lds response . <nl> initial lds response . <nl> empty lds response deletes the listener . <nl> both lds resources were requested . <nl> ldsresourcewatcher called with listenervhosts . <nl> watcher1 called with listenertwo . <nl> watcher2 called with listenertwo . <nl> unknown rds resource . <nl> add another watcher . <nl> initial rds response . <nl> updated rds response . <nl> both rds resources were requested . <nl> initial cds response . <nl> updated cds response . <nl> initial cds response . <nl> empty cds response deletes the cluster . <nl> add another watcher . <nl> initial eds response . <nl> updated eds response . <nl> both eds resources were requested .,"in preparation for ads parsing changes , i was reading through clientxdsclienttestbase and ended up refactoring some pieces to make it easier to add upcoming resource metadata capture . <nl> - the same resources used in different places moved to private fields to make it easier to know when a different resource is used in tests on purpose <nl> - added some constants to make assertions for the same values easier to read/conceptualize <nl> - added helpers for single-resource , , etc , to skip single-element collection so it 's a bit easier to read <nl> - re-ordered arguments of",1614993051,"these are dangling code in grpclb 's tests . grpclb 's implementation does not use attributes any more . leaving this in its test does not make any sense . <nl> todo : eliminate usage in xds 's . it turns out not to be a simple cleanup there , some logic needs to be rewritten .",0.8891114592552185
apache_incubator-pinot/6331,add a controller endpoint to return table creation time <cm-sep> make exception generic to catch npe on null values of tabletypestr <para-sep> container object for metadata info / stats of pinot tables,"for now only table creation time is in the tablestats object . later on , more info can be added to this object . <nl> for one of our clusters , some admin tools need to delete the tables two weeks after the creation time . therefore the table creation time api is exposed in this pr . <nl> here is the zooinspector snapshot for the same table which verifies the creation time returned by the endpoint : .",1607393763,"there are certain usecases , where we need greater customization than the in built support . for instance , a usecase might interpret an increase in the metric as a bad thing , and hence want increases to be shown as red and decreases as blue . <nl> in our heatmap , we use the value of the metric as the cell size . however , this may not work best in case of derived metrics . we are adding config driven support to determine which expression should be applied in case of cell size . <nl> adding collection aliases",0.9689961075782776
jenkinsci_jenkins/5037,urlencode item names in url during rename,", fix redirects when renaming jobs with non-latin characters or spaces",1603975464,"[ fix ] make reversebuildtrigger # getupstreamprojects null-safe . <nl> * entry 0 : issue , human-readable text <nl> * .. . <nl> * use the prefix if the change has no user-visible impact ( api , test frameworks , etc . )",0.9033061861991882
apache_flink/16245,changelog & table modes no longer use max_column_width for all columns <cm-sep> first working version <cm-sep> fixed some deprecation issues <cm-sep> updates documentation <cm-sep> cleanup <para-sep> execution options <nl> display options,"in the linked ticked we discussed allowing the user to set the max width as unlimited , but on second thought i find is hard to implement since the resulting data may not be materialized = > we do not know the maximum width required by the data . i suggest we do not implement this as part of this ticket . <nl> * aligned the column width strategy across all modes <nl> in tableau mode , the column width is computed by and depends on the column type ( e.g . 0 for a date ) . <nl> in",1624389000,"# # what is the purpose of the change . <nl> now hiveoptions is used for globalconfiguration.loadconfiguration ( ) . <nl> it is not natural for table , we should use configuration from tablefactory to enable table config . <nl> modify to read config from . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> -",0.953101634979248
vespa-engine_vespa/18023,throw exception if resource-limits is specified,"please review only , can not be merged until no customers in hosted specify in services.xml",1622203991,i suggest reviewing each commit in order . the purpose of this is to tie the state/v1/health response of the container to the vip status : whenever the container decides that it is not fit to receive traffic it should also respond that it 's in bad health .,0.9391267895698547
apache_pulsar/10489,"add onfilter for interceptor <para-sep> the interception of web processing , as same as . so in this method , we must call to continue the chain . <nl> just continue the chain by default . <nl> no init necessary . <nl> no state to clean up . <nl> init filter <nl> ' application/json ' should be intercepted","since the interceptor obtains references to request and response , and many properties of these objects can not be modified , so we can only read but not modify them . <nl> therefore , we must wrap request and response . however , the attributes we want to modify are different . some people want to change the header , and some people want to modify the queryparam . this requires very high flexibility of httpwrapper . <nl> at least for now it is not supported .",1620282680,"in that case , connection should be closed and client should be able to connect with other broker to get the request served . <nl> eg : sometimes broker is not able to create zk-session and it keeps failing to authenticate client-request so , client should be redirected to other broker by closing client-side connection on broker 's . <nl> add in to disable keep-alive after . <nl> should close the connection on",0.9620896577835083
apache_incubator-pinot/6288,"use sorted index based filtering <nl> only for sorted column with dictionary <para-sep> currently sorted index based filtering is supported only for dictionary encoded columns . the on-disk segment metadata will indicate if the column is sorted or not regardless of whether it is raw or dictionary encoded . here when creating the filter operator , we need to make sure that sort filter operator is used only if the column is sorted and has dictionary . <nl> test with sorted column without dictionary filteroperatorutils code should correctly create scan operator for int_col_raw else this test will fail <nl> test with sorted column without dictionary filteroperatorutils code should correctly create scan operator for int_col_raw else this test will fail <nl> test with sorted column without dictionary filteroperatorutils code should correctly create scan operator for int_col_raw else this test will fail","currently we build sorted index only if the column is dictionary encoded . however , when we write in on-disk segment metadata , we write on the basis of pre-index stats collector . so , for a sorted column without dictionary , segment metadata will still indicate column as sorted . <nl> during query processing , when we create filter operator , we check the data source metadata to see if the column is sorted and create sorted index based filter operator . however , using this operator for any sorted raw column will lead to the following error stack",1606290309,"optimize some of the hot paths in query parsing : <nl> - avoid doing replaceall if it would do nothing ( eg . for string <nl> literals , we use replaceall to replace double quoted quotes , for <nl> things such as ' o ' reilly ' ) <nl> - use a hashset instead of a treeset for items in an in clause , avoids <nl> having to rebalance the tree many times if the items in the in clause <nl> are in sorted order",0.914128303527832
vespa-engine_vespa/17539,"define notification <cm-sep> store notifications in zk <cm-sep> expose notifications in /applications/v4/ <cm-sep> remove notifications when deleting tenant/application/instance <cm-sep> raise log level on some errors <cm-sep> add notifications on application package warnings and deployment failures <cm-sep> allow filtering notifications by production <para-sep> for direct deployments use the full application id , but otherwise use just the tenant and application as the source since it 's the same application , so it should have the same warnings","we want to expose to the users certain warnings/errors in a prominent view in the console . these include warnings about usage of deprecated features ( returned by the configserver on deploy , ) , or when a cluster uses too much of resource ( s ) ( ) . <nl> this pr adds , which stores notifications in zk , similar to audit log . but by storing the source and the type of notification , we can remove or update it periodically , avoiding duplicates and stale warnings . <nl> the rest api allows getting notifications on tenant/application/instance",1619076866,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9878025054931641
hazelcast_hazelcast/18793,disable multicast setinterface calls in solaris,disable multicast setinterface calls in solaris .,1622131575,- updates with correct current/previous cluster version constants . <nl> - updates version xsd usages .,0.9265862703323364
vespa-engine_vespa/17029,"inhibit zookeeper connections until our local slobrok mirror is ready . <nl> otherwise , if there are transient slobrok issues during cc startup and <nl> we end up winning the election , we risk publishing a cluster state where <nl> the entire cluster appears down ( since we do not have any knowledge of <nl> slobrok node mapping state ) . this will adversely affect availability for <nl> all the obvious reasons . <para-sep> we defer zookeeper connections until our local slobrok mirror is ready . otherwise we risk winning an election without having any clue about the state of the nodes in the cluster , causing us to spuriously publish cluster down-states . <nl> returns whether the lookup instance has been able to bootstrap itself with information about nodes . calling updatecluster ( ) _before_ isready has returned true may not provide any useful data .","otherwise , if there are transient slobrok issues during cc startup and <nl> we end up winning the election , we risk publishing a cluster state where <nl> the entire cluster appears down ( since we do not have any knowledge of <nl> slobrok node mapping state ) . this will adversely affect availability for <nl> all the obvious reasons .",1616066132,"this augments today 's per-visitor timeout , which should not be used <nl> implicitly for setting the session timeout .",0.9102890491485596
elastic_elasticsearch/72736,"fix watcher http connection config for longevity . <nl> watcher uses a connection pool for outgoing http traffic , which means <nl> that some http connections may live for a long time , possibly in an idle <nl> state . such connections may be silently torn down by a remote device , so <nl> that when we re-use them we encounter a or similar <nl> error . <nl> this commit introduces a setting allowing users to set a finite expiry <nl> time on these connections , and also enables tcp keepalives on them by <nl> default so that a remote teardown will be actively detected sooner .","watcher uses a connection pool for outgoing http traffic , which means <nl> that some http connections may live for a long time , possibly in an idle <nl> state . such connections may be silently torn down by a remote device , so <nl> that when we re-use them we encounter a or similar <nl> error . <nl> this commit introduces a setting allowing users to set a finite expiry <nl> time on these connections , and also enables tcp keepalives on them by <nl> default so that a remote teardown will be actively detected sooner .",1620200697,eagerly creates the first backing index when a data stream is created .,0.9603768587112427
vespa-engine_vespa/17554,"add fine-grained logging . re-read vcmr before writing . add test <cm-sep> increase maintainer frequency <para-sep> read the vcmr again , in case the source status has been updated","- add some fine-grained logging <nl> - add test to verify that updated source status is indeed stored in zk <nl> - increase maintainer frequency , 0 hours is too rare <nl> - update approval status <nl> - re-read vcmr from zk before writing assessment . could be keeping old data in memory while fetches updates",1619113488,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9269700050354004
Alluxio_alluxio/13028,"cleanup worker <cm-sep> combine abstractreadhandler and blockreadhandler <para-sep> 0. the channel is closed if there is any exception during the data read/write . threading model : only two threads are involved at a given point of time : grpc event thread , data reader thread . 0. the grpc event thread accepts the read request , handles write callbacks . if any exception occurs ( e.g . failed to read from stream or respond to stream ) or the read request is cancelled by the client , the grpc event thread notifies the data reader thread . 0. the data reader thread keeps reading from the file and writes to buffer . before reading a new data chunk , it checks whether there are notifications ( e.g . cancel , error ) , if there is , handle them properly . <nl> * / <nl> a serializing executor for sending responses . * / <nl> this is only created in the grpc event thread when a read request is received . using ' volatile ' because we want any value change of this variable to be visible across both grpc and i/o threads , meanwhile no atomicity of operation is assumed ; <nl> expected state : context equals null as this handler is new for request . otherwise , notify the client an illegal state . note that , we reset the context before validation msg as validation may require to update error in context . <nl> handles any exception which should abort the client 's read request .","- remove unnecessary class hierarchy : e.g. , , , , <nl> - simplify calls",1615243438,"this pr decouples the journal api from its ufs implementation . in particular , it creates , , , and interfaces and hides the ufs implementation behind these interfaces . <nl> in the context of the journal api , we no longer talk about files , directories , and paths . we talk about checkpoints , completed logs , and the current log . the api uses uris to identify these objects and provides methods for working with these objects .",0.9649957418441772
apache_druid/10736,"fix potential deadlock in batch ingestion <para-sep> the given intervals are first converted to align with segment granularity . this is because , when an overwriting task finds a version for a given input row , it expects the interval associated to each version to be equal or larger than the time bucket where the input row falls in . see parallelindexsupervisortask.findversion ( ) . <nl> condense intervals to avoid creating too many locks . <nl> task futures available from the taskrunner <nl> attain futures for all active tasks ( assuming they are ready to run ) . copy tasks list , as notifystatus may modify it . <nl> task should be running , so run it . <nl> task.isready ( ) can internally lock intervals or segments . we should release them if the task is not ready . <nl> kill tasks that should n't be running <nl> this test verifies releasing all locks of a task when it is not ready to run yet . these apis should be used only to emulate a certain deadlock scenario . all normal tasks should use taskqueue apis . <nl> task1 emulates a case when there is a task that was issued before task2 and acquired locks conflicting to task2 . <nl> manually get locks for task1 . task2 can not be ready because of task1 . <nl> task3 can run because task2 is still blocked by task1 . <nl> shut down task1 and task3 and release their locks . <nl> now task2 should run .","is called which is called in the overlord to check if the task is ready for execution . since the overlord only checks the result of but does nothing with locks by itself , locking individual interval can lead to deadlock . imagine that there are two tasks that want to work on overlapping intervals . one task could lock some of intervals but failed for others for some reason . later , another task could lock those intervals where the first task failed to lock . now they would wait for each other to release locks they possess .",1610049732,initializing a is not cheap ; it includes parsing an expression . the should be reused in stream indexing rather than recreating it for every stream chunk . batch ingestion does n't have this issue since it decorates an with a which is a reader for the entire input data . <nl> also fixed json serde of,0.9847931265830994
vespa-engine_vespa/17626,"switch connection only when the current one is failing . <nl> subscribers set error on a connection if it fails , so when having <nl> many subscribers we should not switch unless the current connection <nl> is having errors <para-sep> preconditions : 0. the current connection is unhealthy and should not be selected when switching 0. there is more than 0 source . <nl> should change connection , not getting first connection as new <nl> should change connection , not getting second connection as new <nl> fail a few more times with old connection , as will happen when there are multiple subscribers connection should not change <nl> should change connection , not getting third connection as new <nl> should change connection , not getting current connection as new","subscribers set error on a connection if it fails , so when having <nl> many subscribers we should not switch unless the current connection <nl> is having errors .",1619591353,- move ntokenvalidator from controller-server to vespa-athenz <nl> - remodel zmskeystore as athenztruststore <nl> - use file-backed truststore on controller ( replaces download of public keys ) <nl> - remove zmsclient.getpublickey/getpublickeys .,0.9810805320739746
elastic_elasticsearch/73614,"osstats must be lenient with bad data from older nodes <para-sep> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here . <nl> if we have a node in the cluster without the bug fix for negative memory values , we need to coerce negative values to 0 here .","we 've had a series of bug fixes for cases where an osprobe gives negative values , most often just 0 , to the osstats class . we added assertions to catch cases where we were initializing osstats with bad values . unfortunately , these fixes turned to not be backwards-compatible . in this commit , we simply coerce bad values to 0 when data is coming from nodes that do n't have the relevant bug fixes .",1622558469,"today you can mount a snapshot of a searchable snapshot index , but the <nl> shard fails to allocate since the underlying snapshot is devoid of <nl> content . doing this is a mistake , you probably meant to restore the <nl> index instead , so this commit rejects it earlier with a more helpful <nl> message .",0.8699483275413513
apache_pulsar/10859,refactor refactor some method to java8 . <cm-sep> fixed checkstyle <para-sep> ensure the vip status is only visible when the broker is fully initialized,refactor some method to java8 .,1623106755,optimize the usage of pulsar-perf subcommands .,0.8735005259513855
apache_shardingsphere/10481,"refactor subscribe authoritychangedevent , add test unit . <cm-sep> add test unit for renew createuserstatementevent .","-refactor renew authoritychangedevent , add test unit .",1622016061,changes proposed in this pull request : <nl> - support heart beat for sharding jdbc with yaml .,0.9733917713165283
apache_kafka/10666,throw if still shutting down and add test,"currently only throw an illegalstateexception if the state is running or rebalancing , however the application could be in the process of shutting down in which case streamthreads may still be running . we should also throw if the state is pending_error or pending_shutdown",1620710689,"0. in activetasks.suspend , we should also close all restoring tasks as well . closing restoring tasks would not require as in , since the topology is not initialized yet , instead only state stores are initialized . so we only need to call . <nl> 0. unit tests updated accordingly .",0.9273025989532471
Graylog2_graylog2-server/10687,"make all wildcardpermission case sensitive . <nl> when introducing the new permissions system in version <nl> we started using object instead of string permissions . <nl> we did not notice that wildcardpermissions are by default case insensitive . <nl> for most cases that did n't make a difference , <nl> but returning the self-editing permissions to a user with a <nl> non-lowercase name would change from something like . <nl> to . <nl> which would break the frontend permission checks <nl> for these cases . <nl> - > introduce a new casesensitivewildcardpermission class <nl> that changes this default . <para-sep> use case sensitive permission resolver <nl> use case sensitive permission resolver","when introducing the new permissions system in version <nl> we started using object instead of string permissions . <nl> we did not notice that wildcardpermissions are by default case insensitive . <nl> for most cases that did n't make a difference , <nl> but returning the self-editing permissions to a user with a <nl> non-lowercase name would change from something like . <nl> to . <nl> which would break the frontend permission checks <nl> for these cases . <nl> - > introduce a new class <nl> that changes this default .",1621619554,"created , edited and deleted a content pack with collectors .",0.8869467973709106
Alluxio_alluxio/12653,add option to allow mounting partitions with diff location prefix than table location <cm-sep> lint fix <para-sep> : specify the udb options for the hive udb . the options <nl> : whether to mount partitions that do not share <nl> a map from default property key 's string name to the key . * / <nl> create a alluxio.table.under.hive.property instance . <nl> udb property builder .,"this pr aims to add an hive udb option in command , to allow mounting partitions in hive tables that do n't share the same location prefix with that of the table .",1608081021,added apis for intercepting grpc client and server with custom data serialization/deserialization . <nl> also made the worker send read response asynchronously to improve throughput for single read request .,0.9804211854934692
ballerina-platform_ballerina-lang/28010,make fielddescriptors ( ) in field symbols return a map <cm-sep> fix fielddescriptors ( ) usages in lang server <cm-sep> fix fielddescriptors ( ) usages in docerina and data mapper <cm-sep> fix fielddescriptors ( ) usages in tests <para-sep> get the symbols of the fields of the class . the mapping is a set of field name and field symbol pairs . the returned map is ordered . the order in which the fields were specified in the source code is preserved when iterating the entries of the map . <nl> get the symbols of the fields of the object type . the mapping is a set of field name and field symbol pairs . the returned map is ordered . the order in which the fields were specified in the source code is preserved when iterating the entries of the map . <nl> get the symbols of the methods of the object type . the mapping is a set of method name and method symbol pairs . the returned map is ordered . the order in which the fields were specified in the source code is preserved when iterating the entries of the map . <nl> get the symbols of the fields of the record type . the mapping is a set of field name and field symbol pairs . the returned map is ordered . the order in which the fields were specified in the source code is preserved when iterating the entries of the map .,this is because a common use case is to lookup fields in the aforementioned types by name and previously the user had to loop through the fields list and filter to get the relevant field symbol . the map used for this is a so that the original order is preserved when iterating .,1611137638,"* move metrics user api to ballerina-builtin . <nl> * update metrics user api to work with new syntax changes . <nl> * fix metrics unit tests . <nl> all metrics tests were passed . <nl> yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes .",0.9673235416412354
vespa-engine_vespa/18249,add javadoc <para-sep> / adds http request header to all client requests . * / adds http request header to all client requests . value can be dynamically updated during a feed . overrides default retry strategy .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623675336,* use hostname of localhost if host not found and equal to localhost <nl> instead of hardcoded name for tests .,0.8712108731269836
ballerina-platform_ballerina-lang/29630,restrict never completion for stream type <cm-sep> improve type checking to restrict never <cm-sep> refactor stream tests to restrict never <cm-sep> revert removing type params <para-sep> setting nil type the completion type if not resolved <nl> test the negative assignability of stream and stream <nl> nevernumbergenerator nevernumgen = new ( ) ; stream nevernumstream = new ( nevernumgen ) ; record { | int value ; | } ? nevernum1 = nevernumstream.next ( ) ; record { | int value ; | } ? nevernum2 = nevernumstream.next ( ) ; record { | int value ; | } ? nevernum3 = nevernumstream.next ( ) ; testpassed = testpassed & & ( nevernum3 == ( ) ) ; <nl> todo will revisit during unbounded stream implementation testpassed = testpassed & & ( emptystream4.next ( ) === ( ) ) ; testpassed = testpassed & & ( emptystream6.next ( ) === ( ) ) ; testpassed = testpassed & & ( emptystream9.next ( ) === ( ) ) ; <nl> test the assignability of stream and stream,so that and is assignable to . and is equivalent to .,1616750247,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9386304616928101
quarkusio_quarkus/18264,"allow openapi filters to run on request rather than on startup ( with config ) . allows for more dynamic document creation . <cm-sep> update smallrye openapi to version <nl> signed-off-by : phillip kruger <para-sep> do not run the filter only at startup , but every time the document is requested ( dynamic ) . <nl> filter that count version <nl> first time should be version <nl> second time should be version <nl> third time should be version <nl> holds instances of the openapi document <nl> generate the document once on creation . <nl> generate the document on every request .","this also adds a configuration ( ) that if set to true ( default false ) will run the filter <nl> on every openapi document request ( rather just on startup ) . this allows for dynamic schema generation . <nl> this is needed by the code.quarkus.io rest api , that use a filter to populate the available platform versions in the schema document . this will allow the document to update when a new version is released .",1625050072,"please do n't merge it , i will merge it myself .",0.966992199420929
vespa-engine_vespa/17560,allow rank profiles representing models to have declared inputs <cm-sep> add input parameters to rank profile . <nl> * also : try to resolve type of output expressions <cm-sep> use actual dimension names <cm-sep> update with now-resolved correct type <cm-sep> fix typo <cm-sep> rename inputparameter - > inputfeature <para-sep> use for rank profiles representing a model evaluation ; it will assume that a input is provided with the declared type ( for the purpose of type resolving ) . * / <nl> add input features <nl> xxx should we resolve type here ?,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1619166165,this is the baseline cluster state + per bucket space states .,0.9583909511566162
elastic_elasticsearch/73844,"dismax query tests to not rely on order . <nl> this commit updates some of the multi match and query string unit tests to not rely on order when checking dismax query subclauses . <nl> this is somehow related to how fields are returned from fieldtypelookup # getmatchingfieldsnames , which though returns a set hence we ca n't rely on its ordering .","this commit updates some of the multi match and query string unit tests to not rely on order when checking dismax query subclauses . <nl> this is somehow related to how fields are returned from fieldtypelookup # getmatchingfieldsnames , which though returns a set hence we ca n't rely on its ordering .",1623075076,"this commit moves the keystore cli into its own project , so that the <nl> test dependencies can be isolated from the rest of server .",0.9137207865715027
apache_druid/11157,"array_agg sql aggregator function <cm-sep> add javadoc <para-sep> convert a boolean back into native expression type <nl> convert a boolean into a long expression type examine java type to find most appropriate expression type <nl> maxbytes must be a literal <nl> yo , ca n't group on array types right now so expect failure","use of within the expression is not currently supported , and the ordering of results within the output array may vary depending on processing order.| <nl> ||collects all distinct values of into an array , including null values , with in bytes limit on aggregation size ( default of 0 bytes ) per aggregate . use of within the expression is not currently supported , and the ordering of results within the output array may vary depending on processing order.| . <nl> since this is an expression aggregator , it is unlikely to be the most optimal way to provide",1619170361,"this pr updates calcite to version . <nl> the web console relies on the subquery order by being respected ( it can wrap queries made in the query view with an outer query that has a limit ) , so this patch adds an internal query context flag that wraps a query with a limit-only logicalsort if specified",0.9560791254043579
OpenAPITools_openapi-generator/8718,use a valid php type for maps,"this pull request aligns the map types to native array types . <nl> it does this in two steps to show the impact of the change . <nl> 0. it maps to the native array type . <nl> 0. it adjusts the syntax to match that expected by psalm , phpdoc , and ide 's that parse phpdoc .",1613452863,"this pr includes a few different fixes : . <nl> - add missing import , serializer for <nl> - remove bad import <nl> - use raw strings for those that contain variable name . this should eliminate potential issue with variables like . <nl> - use instead of to avoid potential conflict with op params . <nl> these fixes are required when i try to generate for kubernetes api ( example json here ) .",0.8690571188926697
hazelcast_hazelcast/18872,use light jobs for sql statements <para-sep> submits a new light job with a default config . <nl> submits a job defined in the core api with a default config . <nl> removed from the cluster . enabled by default . by default it 's disabled . it 's disabled by default .,"use the new light job feature for running sql statements . also enables for light jobs , but documents and verifies , which settings are not applicable to light jobs ( most are n't ) . we needed this to pass dynamic parameters to queries , but it 's a better design in general : also can be used by light jobs . <nl> also fix joining of a light job which was n't implemented at all by mistake : )",1623249330,"i have cleared all the code about synchronizing mapstore loadall among cluster members . <nl> it was too complicated , and have concurrency problems , may easily cause deadlocks . <nl> so currently all nodes tries to loadall and operations do not wait load all . <nl> if this improvement needed , it should be carefully redesigned .",0.9759942293167114
runelite_runelite/12936,loot tracking bird nests is granular,"~~this modifies the current bird nest loot tracking to improve the wiki data sets . currently , the system combines all types of bird nests and it is tracked under ' bird nest ' .~~ . <nl> ~~changes made : ~~ <nl> ~~- wyson nests - > bird nest ( wyson ) ~~ <nl> ~~- regular nests ( miscellania , birdhouses , woodcutting ) - bird nest ( seed ) ~~ <nl> ~~- ring nests - > bird nest ( ring ) ~~ <nl> ~~- egg nests- > bird nest ( egg ) ~~ <nl> ~~- empty nests - >",1607990414,added two agility shortcuts that were not added in trollheim .,1.0000001192092896
apache_druid/11311,"fix bug <cm-sep> add test <cm-sep> fix it <cm-sep> fix checkstyle <para-sep> happens when current database entry is the same as this value . note that the current database entry ( in array of bytes ) have to be exactly the same as the array of bytes of this value for update to succeed . if null , then the insert will not consider the current database entry . note that this field intentionally uses byte array to be resilient across serde of existing data retrieved from the database ( instead of java object which may have additional fields added as a result of serde ) <nl> verify that compaction config already exist . this config was inserted manually into the database using sql script . this auto compaction configuration payload is from druid version <nl> now submit a new auto compaction configuration <nl> wait for compaction config to persist <nl> verify that compaction was successfully updated <nl> should call convertbytetoconfig and lookup ( to refresh current compaction config ) four times due to retryableexception when failed","fix bug 0 bad gateway thrown when we edit/delete any auto compaction config created version or before . <nl> this issue will only happen if user has one or more auto compaction configuration created in a version before latest ( version or earlier ) then upgrade to latest ( version or later ) . if this was the case , once user upgraded to version or later , <nl> - the user will not be able to add , edited or deleted any auto-compaction configuration ( for both old datasource created prior to upgrade and new datasources created after the",1622106732,"in case message at the offset being fetched is not present anymore at kafka brokers . <nl> in the next supervisor run , supervisor will start new tasks for these partitions with start offset fetched from kafka .",0.9783622622489929
ballerina-platform_ballerina-lang/28322,fix tostring representation for optional field access <cm-sep> fix unavailable field access on nilable mappings,also fixes the string representation for optional field access .,1612111255,"with this pr , i 've improved the logic which checks the similarity of types as well as assignability of types . i 've also fixed two class of issue with this pr and appropriate test case have been included .",0.9616032242774963
ballerina-platform_ballerina-lang/26966,"update projectloader api to accept a project environment builder <cm-sep> delay desuar and birgen until codegen is invoked . <nl> this is done to support language server use cases . we need to figure out a better way to improve this later <cm-sep> introduce a method a load a project from a given path <cm-sep> update semantic api test cases with the compilation state change <cm-sep> add a statement comment to explain what 's going on <para-sep> perform the rest of the compilation phases before generating platform-specific code <nl> serialize the bir model <nl> skip the code generation phase if there are diagnostics <nl> we check whether the particular module compilation state equal to the typecheck phase here . if the states do not match , then this is a illegal state exception .",i had to delay the desugar and bir gen phases in order to do this .,1605573713,"this pr brings slight changes to how trace logs are used following the introduction of the config api . now , to enable http trace logs , users need to set the flag . <nl> this also introduces log level configuring to ballerina user level logging through the config api . there are several aspects to this : log api config vs. package level configs and vs. dynamic parameters . <nl> if we consider dynamic parameters , log level can be set to the entire log api through the flag . to set the log level to a specific package",0.9462937712669373
Alluxio_alluxio/12785,disable remote client <cm-sep> add a flag and fix some tests <cm-sep> fix checkstyles <para-sep> todo ( feng ) : remove this test when remote journal write is deprecated <nl> create a counting master implementation that counts how many journal entries it processed . <nl> using a large entry count for catching transition while in-progress . <nl> suspend follower journal system . <nl> catch up follower journal to a large index to be able to transition while in progress . <nl> create entries in parallel on the leader journal context . these will be replicated to follower journal context . <nl> wait until advancing starts . <nl> gain primacy in follower journal and validate it catches up . <nl> ca n't use countingmaster because raft stops applying entries for primary journals . using journalsystem # getcurrentsequences ( ) api instead . <nl> follower should no longer be suspended after becoming primary .,"existing alluxio master with embedded journal will attempt to write to the quorum even after it stepped down in various failure situation , journaling a bunch of inconsistent master states as a result . even though the new master has a catchup process to wait for these journal entries before serving request , there is a chance for the old leader to send it after the period ends and corrupt the journal . <nl> this change updates the journal writer to only write to local raft server by default . this should prevent any remote write request from an old",1612207788,port to version from master branch . <nl> this fix changed the api so we hides values of mount options that are <nl> credentials .,0.9431480765342712
elastic_elasticsearch/74279,today a searchable snapshot index inherits the <nl> index.shard.check_on_startup index setting from <nl> the snapshot it is mounted from .,today a searchable snapshot index inherits the <nl> index.shard.check_on_startup index setting from <nl> the snapshot it is mounted from .,1624001091,"the ml system indices now use the special functionality for <nl> applying the correct mappings on first use . this replaces <nl> the index templates that used to do this job , but were <nl> vulnerable to tampering . <nl> a number of other changes have had to be made to utilise <nl> the system index functionality : . <nl> 0. all fields previously missed out of mappings have been <nl> added to the system index mappings , with the types that <nl> would have been assigned dynamically in previous <nl> versions . this is necessary because dynamic mappings <nl>",0.950501561164856
confluentinc_ksql/6876,"fix how the buffer limit check evaluates streams config . <nl> the buffer limit check first creates a dummy streams config to get the current <nl> max bytes buffering value . to do this it creates a map of the streams props and <nl> creates the config ( with dummy values for all the required fields ) . however <nl> sometimes those fields are already provided and immutablemap does n't like <nl> overwrites in the builder . so , use a plain old hashmap","the buffer limit check first creates a dummy streams config to get the current <nl> max bytes buffering value . to do this it creates a map of the streams props and <nl> creates the config ( with dummy values for all the required fields ) . however <nl> sometimes those fields are already provided and immutablemap does n't like <nl> overwrites in the builder . so , use a plain old hashmap .",1611126303,"this patch passes along the auth header that is used to the connect client so that we can forward it to the connect cluster when making requests . <nl> in another shell , run . <nl> we now can create the connector . i was lazy and did n't actually successfully create the connector because that means adding more roles to more topics and jazz like that , but we can see that the auth header passes along well .",0.9212585091590881
crate_crate/11411,remove one reference constructor overload . <nl> it only set the default for and there are n't <nl> enough call-sites to warrant another overload . <cm-sep> fix columnstoredisabled parameter names . <nl> the value was passed to a function where the <nl> parameter was called .,the value was passed to a function where the <nl> parameter was called .,1621954689,"cherry-pick of sha has failed : . <nl> to fixup this pull request , you can check out it locally .",0.7883356213569641
hazelcast_hazelcast/18886,sql dml cleanups + tests <para-sep> if some table <nl> sort <nl> dml rules <nl> we need to feed primary keys to the delete processor so that it can directly delete the records . therefore we use the primary key for the select list .,removed usage from - returns instead of . <nl> handled from unknown table case and added tests . <nl> simplified couple of rules .,1623405198,"the current sqlresult can represent two options : it 's either a row set <nl> or an update count . the type is determined by calling . <nl> this pr aligns it with the jdbc api : . <nl> - we eliminate the method . instead , the <nl> method returns 0 in case the result represents a row set . <nl> - we ensure that a result with update count does n't have negative count . <nl> we also remove from the responses and rename <nl> to .",0.9379808902740479
elastic_elasticsearch/74065,tidy up deprecation code . <nl> removed unused code and made fields immutable .,removed unused code and made fields immutable .,1623673209,"we have various ways of copying between two streams and handling thread-local <nl> buffers and stream copying throughout the code-base . this commit unifies a number of spots and <nl> removes buffer allocations in many spots . <nl> i do not think that increasing the thread local buffer size from 1k to 8k is a problem in the affected spots : <nl> first off , we almost always will do string reading and writing on the same thread <nl> if we do one of the two operations on it so in most cases it 's only a 6k increase to",0.9106519222259521
elastic_elasticsearch/73685,ensurenowarnings method should assert that there is no other warnings <nl> than the allowed ' predefined ' warnings in filteredwarnings ( ) method .,ensurenowarnings method should assert that there is no other warnings <nl> than the allowed ' predefined ' warnings in filteredwarnings ( ) method .,1622650315,"if the recovery source is on an old node ( before version ) , then the recovery target wo n't have the safe commit after phase1 because the recovery source does not send the global checkpoint in the clean_files step . and if the recovery fails and retries , then the recovery stage wo n't transition properly . if a sync_id is used in peer recovery , then the clean_files step wo n't be executed to move the stage to translog . <nl> i think we should do it as this issue can occur in version . ( requires a",0.8679396510124207
vespa-engine_vespa/17023,rewrite zkmetricupdater to support zk with vespa mtls,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616058027,"just refactoring , no functional changes",0.9201868772506714
apache_shardingsphere/10655,fix create table rewrite error with encrypt,changes proposed in this pull request : <nl> - fix create table rewrite error with encrypt <nl> - add rewrite test case,1622795350,fixes # issuse_id . <nl> changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9568066000938416
hazelcast_hazelcast/18528,clear jmx metrics when starting tests looking at them <cm-sep> clear jmx metrics when starting tests looking at them,fix brittle tests by cleaning up garbage before they start .,1618402751,* added creation time to executor jmx bean <nl> * annotated creationtime field with probe . <nl> enhancement that allow mc correctly handle situation when user requests executor metrics since its creation .,0.8734931945800781
neo4j_neo4j/11721,fix bug when computing the difference in seconds of two equal dates . <nl> that would crash before . <cm-sep> configuration option to set the default time zone for temporal values .,a ) fixes a bug when the duration between two equal dates was computed . <nl> b ) enables to configure the default time zone for temporal values . <nl> changelog : adds the configuration option to configure a default time zone affecting the creation of all temporal values .,1525440330,"each transaction executes in a context , meaning that the services needed . <nl> during the transaction and during commit will remain the same throughout <nl> the lifecycle of the transaction , even if there 's a role switch . <nl> this solves a class of bugs caused by transactions spanning more than one <nl> version of a service , for example a lockmanager instance .",0.9521808624267578
quarkusio_quarkus/16845,"switch to using s01.oss.sonatype.org everywhere . <nl> it used to not work for snapshots but our authorization to push to <nl> oss.sonatype.org has been revoked so hopefully it 's working now . <nl> ( cherry picked from commit sha ) <cm-sep> bump kubernetes-client-bom from version to version . <cm-sep> jacoco fixes . <nl> - note in docs that you ca n't use both plugin and extension <nl> - make sure only actual dependencies are taken into account <nl> - if an error occurs print out an error report . <nl> ( cherry picked from commit sha ) <cm-sep> fix loading an overlapping workspace . <nl> ( cherry picked from commit sha ) <cm-sep> fix minor typos in the oidc docs . <nl> ( cherry picked from commit sha ) <cm-sep> downgrade keycloak image to version as we have problems with the version image . <nl> ( cherry picked from commit sha ) <cm-sep> bump dokka-maven-plugin to remove jcenter repository <para-sep> this could happen in case of an overlapping workspace layout , see localworkspacediscoverytest.loadoverlappingworkspacelayout ( ) <nl> should be an overlapping workspace layout <nl> ignore","please do n't merge , i will merge it myself .",1619543275,i just reordered the commits and rebased . <nl> let 's see what ci has to say .,0.9287005662918091
elastic_elasticsearch/73960,"today , writing a writable value to xcontent in base64 format performs <nl> these steps : ( 0 ) create a bytesstreamoutput , ( 0 ) write writable to that <nl> output , ( 0 ) encode a copy of bytes from that output stream , ( 0 ) create a <nl> string from the encoded bytes , ( 0 ) write the encoded string to xcontent . <nl> these steps allocate/use memory 0 times than writing the encode chars <nl> directly to the output of xcontent . <nl> this api would help reduce memory usage when storing a large response <nl> of an async search . <para-sep> this api can be used to generate xcontent directly without the intermediate results to reduce memory usage . note that this method supports only json . <nl> we need to close the output stream that is wrapped by a base64 encoder to flush the outstanding buffer of the encoder , but we must not close the underlying output stream of the xcontentbuilder . <nl> write a field whose value is written directly to the output stream . as the content is copied as is , the writer must a valid xcontent value ( e.g. , string is properly escaped and quoted )","today , writing a writable value to xcontent in base64 format performs <nl> these steps : ( 0 ) create a bytesstreamoutput , ( 0 ) write writable to that <nl> output , ( 0 ) encode a copy of bytes from that output stream , ( 0 ) create a <nl> string from the encoded bytes , ( 0 ) write the encoded string to xcontent . <nl> these steps allocate/use memory 0 times than writing the encode chars <nl> directly to the output of xcontent . <nl> this api would help reduce memory usage when storing a large",1623252656,"the secure_settings_password was never taken into consideration in <nl> the reloadsecuresettings api . this commit fixes that and adds <nl> necessary rest layer testing . doing so , it also . <nl> - allows testclusters to have a password protected keystore <nl> so that it can be set for tests . <nl> - adds a parameter to the run task so that elastisearch can <nl> be run with a password protected keystore from source .",0.967426598072052
apache_pulsar/10653,"transaction admin api get coordinator internal stats . <para-sep> get managed ledger internal stats <nl> get transaction coordinator internal stats . <nl> get transaction coordinator internal stats . <nl> managedledger internal statistics . <nl> messages published since this broker loaded this managedledger . * / <nl> the total number of entries being tracked . * / <nl> the total storage size of all messages ( in bytes ) . * / <nl> the count of messages written to the ledger that is currently open for writing . * / <nl> the size of messages written to the ledger that is currently open for writing ( in bytes ) . * / <nl> the time when the last ledger is created . * / <nl> the time when the last ledger failed . * / <nl> the number of cursors that are ' caught up ' and waiting for a new message to be published . * / <nl> the number of messages that complete ( asynchronous ) write requests . * / <nl> the ledgerid : entryid of the last message that is written successfully . if the entryid is 0 , then the ledger is open , yet no entries are written . * / <nl> the state of this ledger for writing . the state ledgeropened means that a ledger is open for saving published messages . * / <nl> the ordered list of all ledgers for this topic holding messages . * / <nl> the list of all cursors on this topic . each subscription in the topic stats has a cursor . * / <nl> ledger information . <nl> pulsar cursor statistics . <nl> transaction coordinator internal stats . <nl> the transaction log stats * / <nl> transaction log stats . <nl> the managed ledger name * / <nl> the manage ledger internal stats * /","does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl> anything that affects deployment : ( no ) .",1621503916,"if the topic has relatively low traffic , the de-duplication cursor will not move . this can cause messages that are not able to be deleted based on the retention policy . we should add a policy to take de-duplication snapshots based on time .",0.9773196578025818
apache_incubator-pinot/7052,"add groupby query option <para-sep> in query option , if a positive min trim size is given , we use it to override the server settings . otherwise check if a simple boolean option is given and use default trim size . <nl> testcase4 : low limit + low server trim size + query option size <nl> testcase5 : low limit + low server trim size + query option enable","this pr adds query options for groupby in-segment trim . two options are added : segmentmintrimsize and segmentenabletrim . <nl> if segmentmintrimsize is set to be positive in the query option , it will override the server config and trigger the trim based on the given number . if segmentenabletrim is set to be true in the query option , it will override the server config and trigger the trim based on the default trim size ( 0 ) . <nl> example : <nl> mintrimsize in server config : 0 <nl> query : ' select metric_0 , max ( metric_1",1623438744,this pr adds a thread pool to run preview tasks for the dashboard . it adds the following limits to prevent excessive server usage . <nl> 0. the number of preview task running at the same time <nl> 0. the timeout for a preview task,0.9521812200546265
elastic_elasticsearch/74415,"[ ml ] abort opening job if close is requested during reset . <nl> this commit checks if the job has been requested to close after <nl> the reset action completes as part of allocating the job to a new node . <nl> this ensures we do not proceed to start the job process even though <nl> the job had been requested to close . <para-sep> due to 0 reasons . the first is because the job went into the failed as it is cleaned up already . the third is that the kill has been received before the process has even started . in all cases , we still need to remove the task from the taskmanager ( which is what the kill would do )","while the job is opening it is possible that the kill process action is called . <nl> if the kill process action is received before the job process has started , <nl> we currently start the process anyway . the process will eventually timeout <nl> to connect to anything and will exit . however , it may cause an unexpected <nl> failure if the job is opened again as it wo n't be able to launch a process as <nl> one would already exist . <nl> this commit ensures the reports when <nl> the kill process action has been called",1624363122,"if node does n't support maxprimaryshardsize then serialize maxprimaryshardsize as maxsize . <nl> this should fix a problematic situation if an older node does n't support maxprimaryshardsize <nl> and this is the only condition specified then the older node ends up with a instance without <nl> any conditions . this could lead to upgrade failures , new nodes not able to start because <nl> local cluster state ca n't be read .",0.889889121055603
hazelcast_hazelcast/18866,add offset support for sql queries,adds offset support for sql queries . <nl> checklist : .,1623230826,"- hazelcasttransactionobject now implements spring 's <nl> smarttransactionobject , exposing the boolean field isrollbackonly <nl> - make hazelcasttransactionmanager override dosetrollbackonly so that if <nl> a transaction is participating in another one , and there is a rollback , <nl> we force the participant to be rollback-only <nl> - add tests that verify that in the middle of persisting objects through several beans , even when one exception is thrown after some of the objects have been persisted , the <nl> transaction gets fully rolled back , leaving behind an empty map .",0.9267690181732178
runelite_runelite/13254,add soul wars imbued slayer helmets to slayer item set <cm-sep> add soul wars imbued slayer helmets to emote and skill sets <cm-sep> add soul wars imbues,"adds items imbued via soul wars to slayer plugin , clues , and itemmapping .",1614066752,"there are a number of things wrong with the way we do it now <nl> 0 ) there are up to 0 models in each , so we have to have a method for each of them . both models must be from the same objectcomposition , but have different rotations . <nl> 0 ) gets offset by <nl> 0 ) is not the 0-0 ' jau ' rotation , but the 0-0 type rotation <nl> 0 ) the rotation is baked into the model , and does not need to be accounted for by",0.7467595934867859
apache_beam/14233,"returning successes from fhirio executebundles . needed for healthcare <nl> solutions accuracy in logging what was written to the fhir store . <cm-sep> syncing with milenas change <cm-sep> undo formatting changes from google auto-formatter . <cm-sep> adding the tuple tag check for fhirio.write.result creation . <cm-sep> updating the contains tupletag check to use the pcollectiontuple .has ( ) <nl> method , casting tupletaglist - > collection creates an exception for <nl> some . <cm-sep> fix build <cm-sep> running spotless apply <cm-sep> adding lro counters to import/export/deidentify <para-sep> increments success and failure counters for an lro . to be used after the lro has completed . this function leverages the fact that the lro metadata is always of the format : ' counter ' : { ' success ' : ' 0 ' , ' failure ' : ' 0 ' }",adding counters for the success/failure counters that are output in the operation metadata after an lro completes . we increment the counters after the operation is complete since we already wait on them . <nl> tested that this change works properly for import but i do n't have tests for the other lros,1615823615,"added ' timemonitors ' and collect read , write and run time . some minor refactoring included ( in ioitmetrics.java class ) . <nl> thank you for your contribution ! follow this checklist to help us incorporate your contribution quickly and easily : . <nl> see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs .",0.9429386258125305
elastic_elasticsearch/74272,"ensures that high level rest client is running against a verified <nl> elasticsearch . when the first request is send on hlrc , a request to the <nl> info endpoint is made first to verify the product identification and <nl> version . <cm-sep> fix java 0 compatibility <para-sep> to be called using performclientrequest and performclientrequestasync to ensure version compatibility check do not access directly but through getversionvalidationfuture ( ) * / <nl> create a future that tracks cancellation of this method 's result and forwards cancellation to the actual llrc request . <nl> raise the flag by completing the future <nl> send the request after we have done the version compatibility check . note that if it has already happened , the listener will be called immediately on the same thread with no asynchronous scheduling overhead . <nl> send the request and propagate cancellation <nl> forward cancellation to the actual request ( no need to check parameters as the only way for cancellationforwarder to be completed is by being cancelled ) . <nl> version validation was n't successful , fail the request with the validation result . <nl> propagate validation request failure . this will be transient since clears the validation future if the request fails , leading to retries at the next hlrc request ( see comments below ) . <nl> unlikely to happen <nl> returns a future that asynchronously validates the elasticsearch product version . its result is an optional string : if empty then validation was successful , if present it contains the validation error . api requests should be chained to this future and check the validation result before going further . further client requests reuse its result . if the version check request fails ( e.g . this allows retries to happen while avoiding a busy retry loop ( llrc retries on the node pool still happen ) . <nl> re-check in synchronized block <nl> asynchronously call the info endpoint and complete the future with the version validation result . <nl> these status codes are nominal in the context of product version verification <nl> fail the requests ( this one and the ones waiting for it ) and clear the future so that we retry the next time the client executes a request . <nl> validates that the response info ( ) is a compatible elasticsearch version . <nl> let requests go through if the","ensures that high level rest client is running against a verified <nl> elasticsearch . when the first request is sent on hlrc , a request to the <nl> info endpoint is made first to verify the product identification and <nl> version .",1623967376,adds a minimum version request parameter to searchrequest . the minimum version helps failing a request if any shards involved in the search do not meet the compatibility requirements ( all shards need to have a version equal or later than the minimum version provided ) .,0.9736526608467102
apache_druid/11190,"add overlord api /lockedintervals . skip compaction for locked intervals <para-sep> gets a list of intervals locked by higher priority tasks for each datasource . here , segment locks are being treated the same as time chunk locks i.e . a task with a segment lock is assumed to lock a whole interval and not just the corresponding segment . <nl> take a lock and populate the maps <nl> if this datasource is not requested , do not proceed <nl> do not proceed if the lock is revoked <nl> do not proceed if the lock has a priority strictly less than the minimum <nl> gets a list of intervals locked by higher priority tasks for each datasource . <nl> build the response <nl> acquire locks for task1 <nl> acquire locks for task2 <nl> verify the locked intervals <nl> acquire lock for a low priority task <nl> acquire lock for a low priority task <nl> acquire lock for a low priority task <nl> revoke the lowprioritytask <nl> verify the locked intervals <nl> create a task and add it to the taskqueue <nl> acquire a lock for the task <nl> verify that locks are removed on calling shutdown <nl> contains utility methods for compaction . <nl> no instantiation <nl> integration test to verify behaviour when there is a lock contention between compaction tasks and on-going stream ingestion tasks . <nl> start supervisor <nl> generate data for minutes 0 , 0 and 0 <nl> wait for data to be ingested for all the minutes <nl> wait for the segments to be loaded and interval locks to be released <nl> 0 segments for each minute , total 0 <nl> generate more data for minute2 so that it gets locked <nl> trigger auto compaction <nl> wait for segments to be loaded <nl> verify that minute1 and minute3 have been compacted <nl> trigger auto compaction again <nl> verify that all the segments are now compacted <nl> retries until the segment count is as expected . <nl> verifies that the given intervals have been compacted . <nl> generates data points for the specified interval . <nl> retries until segments have been loaded . <nl> retries until the specified intervals are locked for the current datasource . if no interval has been specified , retries until no interval is locked <nl> checks if a test should be skipped based on whether transaction is enabled or not . <nl>","compaction tasks , both auto and manual , try to acquire locks on the datasource intervals which they need to compact . if a higher priority ingestion task is in progress for an overlapping interval , the compaction task waits until it can acquire a lock . this can lead to the following potential issues : <nl> - due to poor configuration of , compaction can get stuck for long periods of time . <nl> - once the lock is released by the ingestion task , it is possible that some new segments are published ( and/or removed ) .",1620057445,"several bugs are found in the overshadowablemanager . it could happen in various cases , but it was essentially the contract of the of the atomicupdategroup was not respected properly . i updated its javadoc as below to make it more clear : . <nl> the main bug fixes have been fixed in and . <nl> in , it should consider the following cases : . <nl> 0 ) the latest standby group should be visible if there is no full group . <nl> 0 ) if an overshadowed group becomes full , it could be promoted to visible if",0.9773021340370178
apache_kafka/10370,remove duplicate word from kafkaraftclient <para-sep> revoking redundant connectors/tasks if the workers have duplicate assignments loop over the candidate workers as many times as it takes a class that provides necessary apis to bridge feature apis provided by the admin client with,as the title.here is a duplicate definition about 'the ' ?,1616339327,existing javadoc fails to mention that endoffsets returns zero for empty topicpartitions . just added that important little tidbit to save developers ' time .,0.8916077613830566
apache_kafka/10704,"wip <cm-sep> : fix concurrentmodificationexception in abstractconfig <para-sep> configs for which values have been requested , used to detect unused configs . this set must be concurrent modifiable and iterable . it will be modified when directly accessed or as a result of recordingmap access .",recently we have noticed multiple instances where kafkaproducers have failed to constructer due to the following exception : . <nl> this is due to the fact that below is a synchronized set . is being modified while removeall is being called . this is due to the use of recordingmap in the sender thread ( see below ) . switching to a concurrenthashset avoids this issue as it support concurrent iteration .,1621094730,"securitytest.test_client_ssl_endpoint_validation_failure is failing because it greps for 'sslhandshakeexception in the consumer and producer log files . with the fix for , the test uses the verifiableconsumer instead of the consoleconsumer , which does not log the exception stack trace to the service log . this patch catches exceptions in the verifiableconsumer and logs them in order to fix the test . tested by running the test locally .",0.8690049648284912
ballerina-platform_ballerina-lang/30342,fix the test bypass caused by exit codes <cm-sep> fix the test cases with the latest formatting changes <cm-sep> fix node level formatting when generating bindings <para-sep> retrieve two new line minutiaes as a minutiae list .,* re-enable some of the test cases bypassed with the addition of exit codes .,1620132948,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.9103320240974426
apache_pulsar/11094,fix inputs to return a list of topic,add the list of topic in field .,1624611306,allowability to specify sub position in pulsar functions . <nl> - add params <nl> - add test case .,0.9208665490150452
grpc_grpc-java/7887,fix wrong server field in lookup request again <para-sep> handled by the following null check,need strip the port part from the authority .,1612993417,"using as the delay for netty 's can cause ( ) deadlines for scheduled tasks to wrap into negative values , which is unspecified behavior . recent versions of netty are guarding against overflows , but not all versions of grpc-java are using a recent <nl> enough netty . <nl> when connections are gracefully closed , netty 's sets up a timeout task forcing resources to be freed after a grace period . when deadlines for these tasks wrap into negative values , a race was observed in production systems ( with grpc-java < = version ) causing netty <nl>",0.8977919220924377
apache_beam/14098,re-raise underlying exception for invocationtargetexception <para-sep> if underlying exception is unchecked re-raise it as-is,"see .test-infra/jenkins/readme for trigger phrase , status and link of all jenkins jobs . <nl> see ci.md for more information about github actions ci .",1614292012,this pr updates snowflake jdbc and adds ' application=beam ' string to url when building snowflake jdbc connection,0.9240162372589111
elastic_elasticsearch/72694,"extract index setting and analyzers from mappinglookup <cm-sep> extract parsedocument from mappinglookup . <nl> mappinglookup became capable of parsing documents because we needed the search execution context to expose the ability to parse a document that did not depend on a mutable document mapper ( only the percolator uses this feature ) . <nl> in hindsight , parsing documents is quite a specific usecase that does not quite fit in mappinglookup . also , it introduces the need for mappinglookup to hold indexsettings , indexanalyzers and documentparser only for that purpose . <nl> instead , we can expose the documentparser by making it public and make its parse method accept a mappinglookup instance . <para-sep> note that we are not doing anything with dynamic mapping updates , hence fields that are not mapped but are present in the sample doc are not accessible from the script through doc [ 'field ' ] . this is a problem especially for indices that have no mappings , as no fields will be accessible , neither through doc nor _source ( if there are no mappings there are no metadata fields ) . <nl> a parser for documents <nl> parse a document","mappinglookup became capable of parsing documents because we needed the search execution context to expose the ability to parse a document that did not depend on a mutable document mapper ( only the percolator uses this feature ) . <nl> in hindsight , parsing documents is quite a specific usecase that does not quite fit in mappinglookup . also , it introduces the need for mappinglookup to hold indexsettings , indexanalyzers and documentparser only for that purpose . <nl> instead , we can expose the documentparser by making it public and make its parse method accept a mappinglookup instance .",1620136506,"if shards are relocated to new nodes , then searches with a point in time will fail , although a pit keeps search contexts open . this commit solves this problem by reducing info used by searchsharditerator and always including the matching nodes when resolving a point in time .",0.9675235748291016
vespa-engine_vespa/17986,"set status failed when we do not get a deployment when bootstrapping applications . <nl> if we for some reason do n't get a deployment the deployment of the <nl> app should be retried <para-sep> for some reason a deployment is not present , which should not be possible when bootstrapping",set status failed when we do not get a deployment when bootstrapping applications . <nl> if we for some reason does not return a deployment we should retry .,1622028132,"please review and merge . only the first commit is interesting , and is a non-functional change to make safe deconstruction easier . the remaining commits are just minor improvements .",0.941143810749054
vespa-engine_vespa/17778,success with no content is allowed on failure,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620397585,"this is for the compressed tensor constants we discussed . <nl> until it is supported in the backend , this will just fail to reload in proton , but i think that 's ok as it is undocumented . <nl> i 'll create a ticket for proton support .",0.8991833925247192
elastic_elasticsearch/74265,"[ ml ] add datafeed field to the job config <para-sep> accessing here causes an npe in tests as a datafeedconfig parser is referenced in the job parser <nl> each of these writables are version aware <nl> this reads a boolean from the stream , if true , it sends the stream to the method <nl> each of these writables are version aware <nl> this writes a boolean to the stream , if true , it sends the stream to the method <nl> todo in v8.version move this out so that it will be included when is <nl> this is used for parsing . if the datafeed_config exists and its indices options are , we set them to these options <nl> can only test with a single agg as the xcontent order gets randomized by test base class and then the actual xcontent is n't the same and test fail . testing with a single agg is ok as we do n't have special list writeable / xcontent logic <nl> when we are writing for internal storage , we do not include the datafeed config <nl> use newer state from cluster service as the job creation may have created shared indexes <nl> there can not be more than one datafeed per job <nl> check for duplicate jobs <nl> merge cluster state and index jobs",this is a quality of life improvement for typical users . almost all anomaly detection jobs receive their input data through a datafeed . <nl> the datafeed config can now be supplied and is available in the field in the job config for creation and getting jobs .,1623960054,fixed storage autoscaling to also calculate a capacity in the case where <nl> the policy governs no nodes currently ( 0-0 case ) .,0.9812436699867249
apache_pulsar/10156,"exposing prometheus metrics for pulsar function local run mode <para-sep> validate prometheus metrics <nl> validate prometheus metrics <nl> hacky parsing of prometheus text format . sould be good enough for unit tests <nl> example of lines are jvm_threads_current { cluster= ' standalone ' , } version or pulsar_subscriptions_count { cluster= ' standalone ' , namespace= ' sample/standalone/ns1 ' , topic= ' persistent : //sample/standalone/ns1/ ' } version 0 <nl> collector registry for prometheus metrics <nl> starting metrics server <nl> add the jmx exporter for functionality similar to the kafka connect jmx metrics <nl> add the default exports from io.prometheus.client.hotspot.defaultexports","# # # motivation . <nl> currently , metrics are not exposes with running functions/sources/sinks in local run mode . <nl> expose metrics in prometheus format but running a metrics server and allow users to specify the port the metrics server will start on - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding",1617759301,while deploying proxy/websocket we need a mechanism to add/remove host from the vip . <nl> add rest api which checks the existence of and we can add/remove host in vip based on the file availability .,0.9635714292526245
apache_pulsar/10107,implement schema # object prototype <cm-sep> add support for keyvalue <cm-sep> implement schema # object prototype <cm-sep> reduce code duplication <cm-sep> cleanup <cm-sep> fix imports <cm-sep> add primitiverecord in order to support primitive types in schema.auto_consume <cm-sep> implement pulsarobject <cm-sep> implement pulsarobject <cm-sep> rename pulsarobject to genericobject <cm-sep> restore <cm-sep> clean up <cm-sep> restore fields <cm-sep> rename primiverecord to genericobjectwrapper <cm-sep> address sijie 's comments <cm-sep> rebase on top of genericobject patch,basically with this patch we are supporting keyvalue on message.getvalue ( ) when using autoconsumeschema . <nl> modifications : <nl> - enhance keyvalue handling in messageimpl.java <nl> - add a test case about reading a keyvalue payload with schema.auto_consume ( ),1617202028,"currently , the transaction metadata handlers start with pulsar client start , but the handlers connect with the broker asynchronously , if the client restart , the metadata handler may not be available . <nl> add the connection future for the metadata handler . <nl> this change added tests and can be verified as follows : . <nl> - org.apache.pulsar.client.impl.transactionendtoendtest # txnmetadatahandlerrecovertest . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no ) <nl> -",0.9345126748085022
pentaho_pentaho-kettle/7923,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) <para-sep> fileobject.isreadable wrongly returns true in windows file system even if not readable <nl> fileobject.isreadable wrongly returns true in windows file system even if not readable,backport of - problems in delete files and get subfolder names steps when using s3 ( version suite ) .,1617984156,adding new pdi client type ' other ' with a configurable client id,0.8271980881690979
elastic_elasticsearch/73516,"make datastreamssnapshotsit resilient to failures because of local time . <nl> backing index names contain a date component . <nl> instead of defining what the expected backing index names are before creating the data streams , <nl> resolve these expected backing index names after the data streams are created . <nl> this way we avoid failures that can occur around midnight ( local time ) , where the expected <nl> names are created before midnight and the data streams are created after midnight . <para-sep> resolve backing index names after data streams have been created : ( these names have a date component , and running around midnight could lead to test failures otherwise ) <nl> will be used in some tests , to test renaming while restoring a snapshot :","backing index names contain a date component . <nl> instead of defining what the expected backing index names are before creating the data streams , <nl> resolve these expected backing index names after the data streams are created . <nl> this way we avoid failures that can occur around midnight ( local time ) , where the expected <nl> names are created before midnight and the data streams are created after midnight .",1622192056,adds support for the unsigned_long type to data frame analytics . <nl> this type is handled in the same way as the long type . values <nl> sent to the ml native processes are converted to floats and <nl> hence will lose accuracy when outside the range where a float <nl> can uniquely represent long values .,0.846022367477417
apache_kafka/10621,"fix a couple trogdor issues . <cm-sep> fix whitespace issues . <para-sep> ' messagesperwindow ' : 0 , if is less than or equal to 0 , will not throttle at all and will return immediately . <nl> calculate the default values . <nl> run unthrottled if messagesperwindow is not positive . <nl> distribution centered around with a deviation of . ' messagesperwindowaverage ' : 0 , ' messagesperwindowdeviation ' : 0 , <nl> calculate the default values . <nl> calculate the first window . <nl> this class behaves identically to timestampconstantpayloadgenerator , except the message size follows a gaussian distribution . this should be used in conjunction with timestamprecordprocessor in the consumer to measure true end-to-end latency of a system . - the average size in bytes of each message . - the standard deviation to use when calculating message size . - the number of messages to keep at the same size . here is an example spec : { ' type ' : ' gaussiantimestampconstant ' , ' messagesizeaverage ' : 0 , ' messagesizedeviation ' : 0 , ' messagesuntilsizechange ' : 0 } this will generate messages on a gaussian distribution with an average size each 0-bytes . the message sizes will have a standard deviation of 0 bytes , and the size will only change every 0 messages . the distribution of messages will be as follows : the average size of the messages are 0 bytes . ~0 % of the messages are between 0 and 0 bytes ~0 % of the messages are between 0 and 0 bytes ~0 % of the messages are between 0 and 0 bytes <nl> make the random number generator deterministic for unit tests . <nl> calculate the next message size based on a gaussian distribution . <nl> generate the byte array before the timestamp generation . <nl> do the timestamp generation as the very last task . <nl> a payloadgenerator which generates a timestamped constant payload . the timestamp used for this class is in milliseconds since epoch , encoded directly to the first several bytes of the payload . this should be used in conjunction with timestamprecordprocessor in the consumer to measure true end-to-end latency of a system . - the size in bytes of each message . here is an example spec : { ' type ' : ' timestampconstant ' , ' size","* changes the new throughput generators to track messages per window instead of making per-second calculations which can have rounding errors . also , one of these had a calculation error which prompted this change in the first place . <nl> * fixes a couple typos . <nl> * fixes an error where certain json fields were not exposed , causing the workloads to not behave as intended . <nl> * fixes a bug where we use not in a loop , which exits too quickly . <nl> * adds additional constant payload generators . <nl> * fixes problems with",1619811520,"with the improvement of 0 , we are now offering developers a better experience on writing their customized eos apps with group subscription , instead of manual assignments . with the demo , user should be able to get started more quickly on writing their own eos app , and understand the processing logic much better .",0.9540009498596191
Alluxio_alluxio/12813,cleanup counters in local client cache <para-sep> errors when adding pages due to insufficient space made after eviction . * /,two improvements : <nl> 0. added new counter ' client.cacheputinsufficientspaceerrors ' indicating the failed put due to insufficient space made after eviction attempts . <nl> 0. remove unnecessary cleanup which may artificially bump error counters <nl> 0. remove unnecessary directory cleanup which has potential race condition to fail put unnecessarily,1612559999,this pr makes fixes various minor issues : <nl> - removes duplicate call to stop the worker metrics system <nl> - uses the proper api ( as opposed to sleeping in a loop ) to wait for the data server executor groups to shutdown ; this speeds up integration tests from 0:0 to 0:0 on my machine <nl> - replaces unnecessary qualifiers with,0.9416905045509338
Alluxio_alluxio/12628,add support for handling 'remove_table ' journal entry <para-sep> drop a table to create a 'remove_table ' entry,"the pr aims to fix the bug that when alluxio master is restarted , it fails to recognize the journal entry during journal replaying , and stuck there forever .",1607718116,it 's expected to get invalid ufs capability for object storage .,0.8658631443977356
grpc_grpc-java/8163,"do not eagerly parse headers , only do it when matchers need to check headers , and only parse headers with key bytes equal . <para-sep> first call , with header ' custom-key ' : ' custom-value ' . <nl> second call , with header ' custom-key ' : ' custom-val ' .","in normal cases , we only have a few header matchers but the number of headers can be completely up to the application . indexing headers eagerly parses all headers , even for those with no matcher matching the key . we should only parse header values for those with key matching the header matcher ( aka , only call metadata.get ( ) with key that has some matcher looking for ) .",1620723447,"this is part one of handling service config , and also enabled grpclb to work . i manually tested this with some complex dns data , but i dont have many unit tests because we dont have a dummy dns server . <nl> handling or the srv records logs failures and tries to keep going . <nl> this can be enabled by setting to true .",0.9640458226203918
Graylog2_graylog2-server/9922,"retry read timeouts for elasticsearch . <nl> before this change , the retry strategy used for es requests did not <nl> retry for instances of , raised in case of read <nl> timeouts . this resulted in exceptions being raised when individual nodes <nl> were not responding and node discovery was not used . this was e.g . being <nl> noticable when performing searches and 0 of 0 nodes was failing , so <nl> every 3rd search request was timing out and returning an error instead <nl> of being retried and successful and just taking longer . <nl> this change is adding this class to the exceptions being retried , so any <nl> request that goes out to a node which is not responding on time is <nl> retried .","before this change , the retry strategy used for es requests did not retry for instances of , raised in case of read timeouts . this resulted in exceptions being raised when individual nodes were not responding and node discovery was not used . this was e.g . being noticable when performing searches and 0 of 0 nodes was failing , so every 3rd search request was timing out and returning an error instead of being retried and successful and just taking longer . <nl> this change is adding this class to the exceptions being retried , so any request",1610977193,returns an empty string if none found .,0.9089917540550232
apache_druid/11144,make sure changing coordinator config is protected against concurrent updates <para-sep> set the config and add audit entry <nl> set the config and add audit entry <nl> do database insert without swap if the current config is empty as this means the config may be null in the database <nl> do database insert without swap if the current config is empty as this means the config may be null in the database <nl> do database insert without swap if the current config is empty as this means the config may be null in the database,"make sure updating auto compaction config is protected against race condition . <nl> the auto compaction config ( ) contains all the compaction configs for multiple datasources within the same payload . when we do update on auto coordinator config , we first do a read to get the current value and apply the change . the read and write does not have any lock to prevent concurrent update . <nl> for example , let ’ s say we currently have current value for compaction config : { datasource x } and we have concurrent deletecompactionconfig and addorupdatecompactionconfig calls happening",1619043198,"example config : . <nl> the example defines 0 lanes , ' ten ' , ' twenty ' , and ' fifty ' , which if the query context contains that lane name will be allowed to use up to 0 % , 0 % , or 0 % of the total capacity",0.9802548289299011
confluentinc_ksql/7491,"split building of join nodes into two steps <cm-sep> remove repartiton in case of foreign key joins <cm-sep> de-dup code <cm-sep> add feature flag <cm-sep> fixes and wire in feature flag <para-sep> we do not need to repartition for foreign key joins , as fk joins do not have co-partitioning requirements <nl> it is always safe to build the repartition node - this operation will be a no-op if a repartition is not required . if the source is a table , and a repartition is needed , then an exception will be thrown <nl> we do not need to repartition for foreign key joins , as fk joins do not have co-partitioning requirements","this pr refactors the logic in the logical planner for building join source nodes to first build a raw source node ( either a joinnode or a datasourcenode ) and then to add potential prejoinrepartition or prejoinproject nodes only after the join has been validated , since part of the validation is detecting whether the join is a foreign key join or not , and we do not want to add pre-join repartition nodes in the case of foreign key joins . this pr also adds a feature flag for foreign key joins while the feature is still under development",1620678817,"slows heartbeating which was making ssl handshakes timeout . <nl> also , adds a new ephemeral port picker . this is useful for picking a port at random to avoid teardown/setup issues that can cause flakiness .",0.8927062749862671
apache_kafka/10610,replace deprecated class.newinstance ( ) to class.getdeclaredconstructor ( ) .newinstance ( ),> the call <nl> clazz.newinstance ( ) <nl> can be replaced by <nl> clazz.getdeclaredconstructor ( ) .newinstance ( ) <nl> .,1619685914,": rename the field of incrementalalterconfigsresponse to match alterconfigs . <nl> this patch changes the name of the field of incrementalalterconfigsresponse to . this makes it consistent with alterconfigsresponse , which has a differently-named but structurally-identical field .",0.8305952548980713
apache_druid/10901,"add integration tests for ldap extension <cm-sep> * refactor <para-sep> this group can only be run individually using -dgroups=ldap-security since it requires specific test data setup . <nl> initial setup is done now , run the system schema response content tests <nl> curr_size on historicals changes because cluster state is not isolated across different integration tests , zero it out for consistent test results <nl> check that we can access a datasource-permission restricted resource on the broker <nl> check that we can access a state-permission restricted resource on the broker <nl> create a new user+role that can only read 'auth_test ' <nl> create a new user+role that can only read 'auth_test ' + state read access <nl> create a new user+role with only state read access <nl> ensure that auth_test segments are loaded completely , we use them for testing system schema tables <nl> check that admin access works on all nodes <nl> as admin <nl> check that we can access a datasource-permission restricted resource on the broker <nl> as user that can only read auth_test <nl> check that we can access a state-permission restricted resource on the broker <nl> as user that can read auth_test and state <nl> as user that can only read state <nl> as user that can only read state <nl> check that we are allowed to access unsecured path without credentials . <nl> create a role that can only read 'auth_test ' <nl> create a new role that can only read 'auth_test ' + state read access <nl> create a new role with only state read access <nl> create a role that can read /status","modeled heavily after the existing . added new test group as we need specific common druid properties to be set in order configure druid to use ldap auth z/n . <nl> * running the osixia/docker-openldap docker image as an ldap server for the tests <nl> * users and groups are preloaded into the ldap server , as defined in <nl> * refactored common functionality between and into base class",1613701729,"join-related datasource types : . <nl> 0 ) add ' join ' , ' lookup ' , and ' inline ' datasources . <nl> 0 ) add ' getchildren ' and ' withchildren ' methods to datasource , which will be used <nl> in the future for query rewriting ( e.g . inlining of subqueries ) . <nl> datasource analysis functionality : . <nl> 0 ) add datasourceanalysis class , which breaks down datasources into three components : <nl> outer queries , a base datasource ( left-most of the highest level left-leaning join <nl> tree ) , and other joined-in",0.9569659233093262
OpenAPITools_openapi-generator/8787,use files.createtempfile <para-sep> files.createtempfile requires the prefix to be at least three characters long,- use files.createtempfile instead to avoid potential security issues .,1613981762,- replace ' usenullforunknownenumvalue ' option with the nullable attribute,0.8070248961448669
elastic_elasticsearch/73834,"revert recent dynamicfieldtype changes . <nl> we recently introduced support for static fields as part of dynamicfieldtype , as well as for dynamic runtime fields . we were thinking we would use this to emit multiple field from a single runtime script , but as we made progress on that task , we realized that we do n't need any dynamic behaviour and we are taking a much simpler and static approach . <para-sep> this will override concrete fields with runtime fields that have the same name","we recently introduced support for static fields as part of dynamicfieldtype , as well as for dynamic runtime fields . we were thinking we would use this to emit multiple field from a single runtime script , but as we made progress on that task , we realized that we do n't need any dynamic behaviour and we are taking a much simpler and static approach .",1623069606,"instead of doing our own checks against rest status , shard counts , and shard failures , this commit changes all our extractor search requests to set . <nl> - scrolls are automatically cleared when a search failure occurs with set . <nl> - code error handling is simplified .",0.953665018081665
netty_netty/11224,"update bytetomessagedecoder.java . <nl> motivation : <nl> after the if case , outsize must be 0 , so seems redundant . <nl> workaround : <nl> delete <nl> modification : <nl> update bytetomessagedecoder # calldecode . <nl> result : <nl> clearer than before","motivation : <nl> after the if case , outsize must be 0 , so seems redundant . <nl> workaround : <nl> delete <nl> modification : <nl> update bytetomessagedecoder # calldecode . <nl> result : <nl> clearer than before",1620224738,motivation . <nl> modification . <nl> just use alloc ( ) .heapbuffer ( ... ) for the allocation . <nl> result . <nl> no possibility of ' missing ' array allocations when bytebuf # copy is used .,0.8457361459732056
apache_incubator-pinot/6893,"fix flaky test case . <cm-sep> fix flakey test case . <para-sep> to avoid flakyness , set timeoutms to 0 msec . for some test runs , it can take up to 0 msec to mark request as failed .","for some test runs , it can take up to 0 msec to mark request as failed .",1620414504,change default time zone to pacific time zone in anomaly detection . previously it was using utc as the default time zone and does not take daylight savings time into consideration .,0.8208563923835754
netty_netty/11269,fail the build if we ca n't load the openssl library . <nl> motivation : . <nl> we should better fail the build if we ca n't load the openssl library to ensure we not introduce a regression at some point related to native library loading . <nl> modifications : . <nl> remove usages of assumetrue and let the tests fail if we cant load the native lib . <nl> result : . <nl> ensure we not regress,motivation : . <nl> we should better fail the build if we ca n't load the openssl library to ensure we not introduce a regression at some point related to native library loading . <nl> modifications : . <nl> remove usages of assumetrue and let the tests fail if we cant load the native lib . <nl> result : . <nl> ensure we not regress .,1621319046,"missed a lot of these last time , sorry about it being split across multiple pull requests",0.9038527607917786
elastic_elasticsearch/73143,adjusts wire-compat and re-enables bwc tests,adjusts wire-compat and re-enables bwc tests,1621247817,version nodes never speak to nodes before version so these version guards are <nl> unnecessary .,0.9748989939689636
ballerina-platform_ballerina-lang/29966,"fix non-ballerina files handling . <nl> ballerina.toml ) . <cm-sep> add integration tests <para-sep> loads the target ballerina source project instance using the project api , from the file path of the open/active editor instance in the client ( plugin ) side . <nl> following is a temp fix to distinguish bala and build projects . <nl> test class for debugger engaging in debug launch mode . <nl> test for debug engage","ballerina.toml , dependencies.toml ) . <nl> - adds integration tests to cover the related scenarios .",1618132889,extract from the spec . <nl> fixes # .,0.9543939828872681
vespa-engine_vespa/17823,extract concurrent identity hashmap into separate class <para-sep> separate janitor threadpool for tasks that can not be executed on the jdisc default threadpool due to risk of deadlock .,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620743073,- cache imported models <nl> - include specific error information when some output could not be imported,0.9752822518348694
runelite_runelite/13237,adds a menu entry swap option for the fossil island rowboat . swaps the travel option with dive .,adds a menu entry swap option for the fossil island rowboat . swaps the travel option with dive .,1613752880,add contract for farming guildmaster to menu entry swapper .,0.923424482345581
runelite_runelite/13177,idle notification will now trigger after the following actions : <nl> - filling buckets of slime <nl> - emptying bone crusher bin <nl> - griding the bones ( last animation played if the player has no container for the crushed bones ) <para-sep> ectofuntus animations,idle notifier will now trigger after the following animations : <nl> - filling buckets of slime <nl> - emptying bone crusher bin <nl> - grinding the bones ( last animation played if the player has no container for the crushed bones ) .,1612743809,"i do not own these items , but these should be the animations for them .",0.9608739614486694
Graylog2_graylog2-server/10244,"add permitted location where csv lookups are permitted from . <nl> change is being applied to master first , then will be ported to .0 after <para-sep> optional allowed paths for graylog data files . if provided , certain operations in graylog will only be permitted if the data file ( s ) are located in the specified paths . all subdirectories of indicated paths are allowed by default . this provides an additional layer of security , and allows administrators to control where in the file system graylog users can select files from . it protects against the potential inspection of arbitrary files in the file system from the graylog user interface .","if provided , certain operations in graylog will only be permitted if the data file ( s ) are located in the <nl> specified paths . all subdirectories of indicated paths are allowed by default . this provides an additional layer of security , and allows administrators to control where in the file system graylog users can select files from . it protects against the potential inspection of arbitrary files in the file system from the graylog user interface . <nl> the first usage ( as implemented in this pr ) is within the csv file lookup adapter . <nl>",1615471164,"up until now , it 's possible to create grok patterns with the same name , but different patterns . <nl> this change set ensures that there are no duplicate grok patterns by removing them in a migration and adding a unique index on the ' name ' field of the ' grok_patterns ' mongodb collection .",0.9743435382843018
apache_incubator-pinot/6465,add controller validation for dimension table storage quota . <cm-sep> fix conflict issues . <cm-sep> add some useful logging . <para-sep> dim tables must adhere to cluster level storage size limits <nl> set a default storage quota <nl> set a default storage quota and keep the rps value <nl> controller assigns default quota if none provided <nl> controller throws exception if quote exceed configured max value <nl> successful creation with proper quota,"in current implementation , dimension tables are fully loaded into heap memory , so this change is to prevent users from accidentally loading very large tables and disrupting the server . <nl> changes include : <nl> - new controller config key : ' controller.dimtable.maxsize ' <nl> - default value if no config is provided : default_dim_table_max_size = ' 200m ' <nl> - validation and enforcement logic in table creation flow ( ) , such that the default max value is applied if no storage config exists for dimension tables . <nl> note : i looked into enforcing this constraint in",1611094681,"this pull request removes dependency on collectionconfig , collectionschema and dashboardconfig . it uses the metricconfig , datasetconfig and dahsboardconfig tables generated by the script which migrated datasets into database . <nl> tested that the dashboard works with these changes . the detectionscheduler and workers have also been tested <nl> todo : test alert , monitor and merge",0.9453914761543274
apache_incubator-pinot/6580,add the isolation level config to kafka ingestion to support kafka transactions <para-sep> push the records from the given avro files into a kafka stream . <nl> initiate transaction . <nl> the first transaction of kafka messages are aborted <nl> the second transaction of kafka messages are committed <nl> set the transaction state replication factor,[ ] yes ( please label this pr as release-notes and complete the section on release notes ) <nl> setting it to will ingest transactionally committed messages in kafka stream only .,1613323115,the performance metrics need to be stored as a by-product of each detection . later this will be read by the model evaluators to monitor the detection models . this pr creates the table and adds the necessary boilerplate codes for storing the evaluation metrics . the pr also adds the mape calculation and collects the metric .,0.9802683591842651
apache_pulsar/10115,support auto generate html page for pulsar client cli tool,"* add auto script for pulsar-client <nl> * add drop-menu for pulsar-client - does this pull request introduce a new feature ? ( yes / no ) , how is the feature documented ? ( not applicable / docs / javadocs / not documented ) <nl> - if a feature is not applicable for documentation a feature is not documented yet please create a followup issue for adding the documentation",1617275936,"due to race condition on , dispatcher tries to access which is empty and it is getting below exception so , dispatcher is not able to read entries . <nl> with this fix , dispatcher will atomically fetches replay-messages without accessing .",0.8316521644592285
vespa-engine_vespa/17194,revert ' remove blockingqueuerequestlog ' . <nl> this reverts commit sha . <cm-sep> use blockingqueuerequestlog,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616747954,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9174164533615112
apache_beam/14254,fix nullability issues with beamzetasqlcalcrel . <nl> remove a misimplemented optimization that leads to failed null checks in beamzetasqlcalcrel . <nl> also fix nullability of this class in general . <nl> caused by : java.lang.nullpointerexception : null future <nl> org.apache.beam.sdk.extensions.sql.zetasql.autovalue_beamzetasqlcalcrel_timestampedfuture . ( autovalue_beamzetasqlcalcrel_timestampedfuture.java:0 ) <nl> org.apache.beam.sdk.extensions.sql.zetasql.beamzetasqlcalcrel $ timestampedfuture.create ( beamzetasqlcalcrel.java:0 ) <nl> org.apache.beam.sdk.extensions.sql.zetasql.beamzetasqlcalcrel $ timestampedfuture.access $ 0 ( beamzetasqlcalcrel.java:0 ) <nl> org.apache.beam.sdk.extensions.sql.zetasql.beamzetasqlcalcrel $ calcfn.processelement ( beamzetasqlcalcrel.java:0 ) <para-sep> exp can not be reused and is transient so needs to be reinitialized . * /,remove a misimplemented optimization that leads to failed null checks in beamzetasqlcalcrel . <nl> also fix nullability of this class in general . <nl> error seen during run :,1615916815,this pr adds another load test ( for pardo ) and moves cross test functionality to a common loadtest class . <nl> follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9474960565567017
elastic_elasticsearch/73806,"remove parsedpoint from point field mappers <cm-sep> iter <cm-sep> iter <cm-sep> introduce formatsfactory and remove formats from parser <cm-sep> iter <cm-sep> remove geometryformat interface <cm-sep> iter <cm-sep> iter <cm-sep> iter <para-sep> output formatters supported by geo fields . <nl> returns a formatter by name <nl> an utility class with to read geometries from a xcontentparser or generic object . <nl> supported formats to read/write json geometries . <nl> serializes the geometry into its json representation <nl> parser json representation of a geometry <nl> returns a geometry parser format object that can parse and then serialize the object back to the same format . <nl> gets the formatter . if the method return null , then the format is unsupported and an error is thrown . <nl> only used in test <nl> output formatters supported by cartesian fields . <nl> returns a formatter by name",this pr makes a distinction between the formats that can be provided at ingestion time and formats that can be retrieved by the fields api . we currently support the same formats in both cases but this does not need to be true . a few words about the difference between those two formats : . <nl> * parsing formats : parsing formats always dealt with xcontent object and ca read and write to them . an important part of our parsing capabilities is that users do not need to specify the format so we need to guess in the,1622962963,"this drop the ' top level ' pipeline aggregators from the aggregation <nl> result tree which should save a little memory and a few serialization <nl> bytes . perhaps more imporantly , this provides a mechanism by which we <nl> can remove all pipelines from the aggregation result tree . this will <nl> save quite a bit of space when pipelines are deep in the tree . <nl> sadly , doing this is n't simple because of backwards compatibility . nodes <nl> before version need those pipelines . we provide them by setting passing <nl> a into the root of",0.9809598326683044
ballerina-platform_ballerina-lang/29182,"replace intersection check with generic check <cm-sep> fix record intersection validation <cm-sep> fix and enable test <cm-sep> add more tests <para-sep> bassertutil.validateerror ( negativeresult , i++ , ' incompatible types : ' ( string|int ) ' will not be matched to 'float ' ' , 0 , 0 ) ; bassertutil.validateerror ( negativeresult , i++ , ' incompatible types : 'any ' will not be matched to 'error ' ' , 0 , 0 ) ;",this pr also changes the intersection check for the type test ' will not match ' error to use the generic intersection logic and enables some disabled tests .,1615632596,code will be generated as below . <nl> this also fixes the printing garbage values when instruction does n't have positions in bir emitter .,0.9578253626823425
Graylog2_graylog2-server/10400,"eliminate redundancy ; start adding tests <cm-sep> unit tests passing <para-sep> netty 's sslcontextbuilder chokes on some pkcs8 key file formats . so we need to pass a private key and keycertchain instead of the corresponding files . <nl> build a password-encrypted pkcs8 private key and write it to a pem file in the temp directory . caller is responsible for ensuring that the temp directory is writable . the file will be deleted when the vm exits . <nl> construct object to create the pkcs8 object from the private key and encryptor <nl> write pkcs8 to file <nl> obtain a private key from a pks8 pem file , which is optionally password-protected . <nl> be sure to specify charset for reader - do n't use plain filereader <nl> read a pkcs5 v2.0 encrypted private key in pkcs8 format <nl> read a pkcs5 v1.0 encrypted private key in pkcs8 format","when a password is provided for a tls-enabled input with self-signed cert , use that password to encrypt the key file . <nl> if a password is provided , we now use it to encrypt the generated key . <nl> this led to a failure when accessing such an input , since the code tried to decrypt the key whenever a password was available . <nl> tested that a tls input with self-signed cert can process messages , both with and without password .",1617957470,since both are bound to streams i decided to put them into the stream entity for now . <nl> i also fixed the following smaller issues : . <nl> - avoid nullpointerexception for stream rule fileds <nl> - fix javadoc comment .,0.9755450487136841
apache_kafka/10317,": add setup method to internal topics . <nl> for , we need a way to setup internal topics without <nl> validating them . this pr adds a setup method to the <nl> internaltopicmanager for that purpose . <para-sep> sets up internal topics . either the given topic are all created or the method fails with an exception . <nl> attempt to create it again with replication 0","for , we need a way to setup internal topics without <nl> validating them . this pr adds a setup method to the <nl> internaltopicmanager for that purpose .",1615810794,"this is part 0 of suppression . <nl> in an effort to control the scope of the review , this pr is just the tests for buffered suppression .",0.9805242419242859
apache_druid/11164,"add feature to automatically remove rules based on retention period <cm-sep> add feature to automatically remove rules based on retention period <para-sep> remove rules for non-existence datasource ( datasource with no segment ) created older than the given timestamp . <nl> note that the method removerulesforemptydatasourcesolderthan depends on the version field to be a timestamp <nl> note that this delete sql depends on the version field to be a timestamp . hence , this method depends on overriderule method to set version to timestamp when the rule entry is created <nl> note that this query could be expensive when the segments table is large however , since currently this query is run very infrequent ( by default once a day by the killrules coordinator duty ) and the inner query on segment table is a read ( no locking ) , it is keep this way . <nl> verify that rule was added <nl> now delete rules <nl> verify that rule was deleted <nl> verify that rule was added <nl> this will not delete the rule as the rule was created just now so it will have the created timestamp later than the timestamp 0-0-01t00:0:00z <nl> verify that rule was not deleted <nl> verify that rule was added <nl> add segment metadata to segment table so that the datasource is considered active <nl> this will not delete the rule as the datasource has segment in the segment metadata table <nl> verify that rule was not deleted <nl> create the default rule <nl> verify the default rule <nl> delete everything <nl> verify the default rule was not deleted",add feature to automatically remove rules based on retention period . <nl> this pr adds a similar auto cleanup based on duration ( time to retained ) but for the rules table to auto clean up rules of inactive datasource ( datasource with no used and unused segments ) . <nl> this is useful when druid user has a high churn of task / datasource in a short amount of time causing the metadata store size to grow uncontrollably,1619498186,this strategy can be enabled by setting to,0.9781961441040039
apache_druid/10955,suppress logging for some exceptions to reduce excessive stack trace messages . <para-sep> supress stack trace logging for some specific exceptions to reduce excessive stack trace messages when waiting druid nodes to start up <nl> log message only <nl> log stack trace for unknown exception <nl> log stack trace for unknown exception,"this pr improves it to reduce excessive stack trace messages when waiting druid nodes to start up . <nl> when running it , druid nodes are started up in k8s environment , and it test cases will wait for druid nodes to start up by checking their http endpoint '/status/health ' periodically . <nl> in some cases , nodes in k8s environment take some time to start up , and this causes the periodical check mentioned above outputs a lot of disturbing and very long stack trace messages shown as below . <nl> this kind of exception during this phase",1615184567,verified with .version on a dev environment .,0.8881264328956604
ballerina-platform_ballerina-lang/27605,"re-enable listener balo test <cm-sep> allow listener decl to use listener|error <para-sep> module init should fail if listener is a error value . <nl> if listener contain errors we need to cast this to a listener type so that , attached function invocation call is generated in birgen . casting to the first listener type should be fine as actual method invocation is based on the value rather than the type . <nl> validate listener attachment based on attach-point of the service decl and second param of listener . <nl> path literal is provided , listener does not accept path literal <nl> absolute path is provided , listener does not accept abs path <nl> there should be at least one listener compatible type and all the member types , except error type should be listener compatible .",note : scenario where the listener init returning error is not tested in this pr .,1608540184,when merged this pr will add group based scheduling via strand annotation .,0.9770025610923767
elastic_elasticsearch/73874,fix hlrc doc link for point in time api <para-sep> end : :open-point-in-time-routing <nl> >,the pit 's docs in hlrc was n't linked properly .,1623118250,re-enabled and fixed test to work when persisting metadata in lucene .,0.9048701524734497
apache_pulsar/10062,"support generate document automatically for pulsar-client <para-sep> ikey is an internal interface and can not be accessed directly , so the type needs to be erased and force cast to a subclass",add command that can generate document automatically for pulsar-client .,1616927477,do not merge . <nl> the proxy does not currently proxy admin requests . <nl> add a proxy servlet to proxy admin requests to the pulsar cluster .,0.9820737242698669
trinodb_trino/7796,make the intention of max pivot+0 test clearer . <nl> it can apparently escape noticing that <nl> should be read together with <nl> as they work in tandem . this commits squashes them <nl> together and adds explanatory comment .,it can apparently escape noticing that <nl> should be read together with <nl> as they work in tandem . this commits squashes them <nl> together and adds explanatory comment .,1619646064,"before this change , column aliases were assigned to leftmost <nl> columns of the with-query . that was incorrect in case when <nl> there were any hidden columns preceding any of the visible columns . <nl> the hidden columns should be skipped when assigning aliases , <nl> and not considered in the resulting scope .",0.7128920555114746
apache_druid/10900,"add query granularity to compaction task <cm-sep> fix checkstyle <cm-sep> fix checkstyle <para-sep> if granularityspec is not null , then set segmentgranularity . otherwise , creates new granularityspec and set segmentgranularity <nl> day segmentgranularity <nl> hour segmentgranularity <nl> day querygranularity <nl> day segmentgranularity and day querygranularity <nl> 0 segments across 0 days <nl> querygranularity was second , now we will change it to hour <nl> the original 0 segments should be compacted into 0 new segments <nl> 0 segments across 0 days <nl> the original 0 segments should be compacted into 0 new segment <nl> 0 segments across 0 days <nl> for the new granularityspec map <nl> for the deprecated segment granularity field",add query granularity to compaction task . <nl> add query granularity to compaction task . note that query granularity is still not supported in auto compaction . <nl> this pr also creates a new class to use instead of when passing query granularity and segment granularity into compaction task . this allows the null value ( value not given by the user ) to represent using the original current query granularity and segment granularity ( this is the existing behavior for compaction task ) . note that the compaction task ultimately still converts to a when creating the index ingestion,1613694181,"- expressionobjectselector able to read from string columns , and able to <nl> return strings . <nl> - expressionvirtualcolumn able to offer string ( and long for that matter ) <nl> as its native type . <nl> - expressionpostaggregator able to return strings . <nl> - groupby , topn : allow post-aggregators to accept dimensions as inputs , <nl> making expressionpostaggregator more useful . <nl> - topn : use dimextractiontopnalgorithm for string columns that do not <nl> have dictionaries , allowing it to work with string-type expression <nl> virtual columns . <nl> - adjusts null handling to better match the",0.9784578084945679
prestodb_presto/15534,make abstracttestxqueries classes abstract <para-sep> we use this instead of checksuccess in airlift so we can propagate the error message and so that we throw a prestoexception rather than an illegalargumentexception .,"checksuccess wrapped exceptions in an illegalargumentexception , which <nl> meant the actual error was buried in the stacktrace . getfuturevalue <nl> wrapped the source exception in a runtime exception , but only included <nl> the error stacktrace and not the stack to the getfuturevalue call . <nl> without the other stack trace , you do n't know where in the operator <nl> execution spill failed , which can make debugging harder . <nl> test plan - ran tests with max spilled bytes set to 1b and looked at the <nl> errors .",1608150535,this also changes the unit tests to work correctly when the timezone is set to that of the hive installation .,0.9353727102279663
confluentinc_ksql/7585,"qualified select * now works in n-way join with repartition <cm-sep> historic plans <cm-sep> 0-way join <cm-sep> historic plans <para-sep> else , empty .","the reason for both bugs is because the current logic in for finding data source names says ' if the current node is a joinnode , inspect its children , else use the current node ' . this is incorrect because . <nl> 0. the current node might be neither a joinnode nor a node corresponding to a single data source -- it might be a prejoinrepartitionnode attached to a joinnode . in this case , the current logic says to use the current node but the current node is not associated with any data source . as a result",1621952197,"if the request contains a connection : close header , it appears jetty sends back a response without content-length set . vert.x does n't like this as it expects content-length to be set for all non chunked responses . <nl> this works around the issue by adding transfer-encoding : chunked if jetty omits this . <nl> note that the ksql cli does n't seem to send connection : close so this issue only seems to affect the reproducer .",0.9260115027427673
OpenAPITools_openapi-generator/9170,"add addresponseheaders option <para-sep> option to include headers in the response <nl> responsewithheaders return a implresponse struct filled , including headers <nl> responsewithheaders return a implresponse struct filled , including headers","this pull request is intended to provide the capability to specify headers to include in the response . <nl> this is needed , for example , to allow a rest api to redirect the client to a new url ( using the location header ) . <nl> also added an option ' addresponseheaders ' to make this change backward-compatible .",1617596398,this pr updates the asp.net server generator to support asp.net core version .,0.9450528621673584
quarkusio_quarkus/17201,"improve continuous testing status message . <nl> the message is now the same for passed/failed ( but <nl> a different color ) . it show total passed/failed , and <nl> the results of the last run .","the message is now the same for passed/failed ( but <nl> a different color ) . it show total passed/failed , and <nl> the results of the last run .",1620892736,"i did n't have the time to think about using the generated doc , considering there are a lot of additional info in there . we might need some doc generation tweaks . <nl> we can do that in version but we need to fix the config properties to be consistent with the quarkus way of doing things .",0.9350876808166504
neo4j_neo4j/11614,explicitly release lock before test completion,this pr adds an explicit before awaiting spawned thread to exit so that the lock is released and thread completion occurs sooner .,1524150169,remove expectation of lucene label scan store to be included into set of <nl> lucene indexes that we expect to have snapshots for . <nl> check snapshots validity based on segments file as an indicator what <nl> index commit was used for particular index snapshot .,0.8383296728134155
apache_incubator-pinot/6560,use minion data directory as tmp directory for segmentgenerationandpushtask,"this will fix the issue that the current pinot segment generation task may fail due to any reason . the leftover segment intermediate data wo n't be clean up and eventually will fill up the disk . <nl> minion data directory is always cleaned up once the minion instance got restarted . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1612861308,"add frequency as query parameter for endpoint that update anomaly detection function , make time series retrieve endpoints do not roll-up . <nl> anomaly detection can work on 'dimension exploration ' - for a given dimension , run parallel anomaly detection for all categories in this dimension . <nl> for example if we set anomaly detection for 'page views ' and explore on 'country ' dimension , and there are ten distinct countries , we are going to do <nl> 0 parallel detection , treat each country as a independent metric . <nl> if the rollup flag is 'true '",0.8733504414558411
apache_pulsar/10683,optimize gettopicpolicies : skip unnecessarily thrown exception,"it is better to return null than to create an exception , catch it , then return null . the modified code will no longer throw an unnecessary exception . <nl> this pr updates the to check a config to return null instead of throwing an exception . additionally , this pr reduces some code duplication by simplifying the two methods and removing an unnecessary parameter . <nl> this change is a trivial rework of the methods . passing tests should be sufficient verification . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does",1621750489,"the handler for the on broker side is processing the request in sync mode . this is used when periodically fetching the list of topics from regex consumers . <nl> most of the time this is not an issue since the list of topics is locally cached in the zk children cache . though when there is an eviction ( eg . we discard all cached entries after 5mins ) , we 're forced to do a blocking call . <nl> this call will block the io thread for extended amount of time , impacting other topics as well .",0.9585753679275513
vespa-engine_vespa/17082,"inhibit zookeeper connections until our local slobrok mirror is ready . <nl> otherwise , if there are transient slobrok issues during cc startup and <nl> we end up winning the election , we risk publishing a cluster state where <nl> the entire cluster appears down ( since we do not have any knowledge of <nl> slobrok node mapping state ) . this will adversely affect availability for <nl> all the obvious reasons . <cm-sep> do n't allow short-circuiting election phase if only one node configured if using zk <cm-sep> use local leader state for decisions rather than election handler . <nl> avoids potentially publishing cluster states _before_ we have triggered <nl> our own leadership election edge handling code . could happen if code <nl> called prior to the election edge logic checked the election handler <nl> state and erroneously thought we had performed the prerequisite actions <nl> we 're supposed to do when assuming leadership ( such as reading back <nl> current state from zk ) . <cm-sep> make sure to reset any election shortcuts if we go from ! zk - > zk <para-sep> use ismaster instead of election handler state , as ismaster is set _after_ we have completed a leadership event edge , so we know we have read from zookeeper . <nl> reset any shortcuts taken by non-zk election logic . <nl> returns whether the lookup instance has been able to bootstrap itself with information about nodes . calling updatecluster ( ) _before_ isready has returned true may not provide any useful data .","this strictly orders leadership edges to happen after zk is connected . <nl> * be consistent in what election state the core logic consults . instead of ( mostly ) checking the election handler , check our local state instead . the latter depends on the former , but will only be set _after_ we have fully processed the leadership edge . this strictly orders any state publishes to happen after we 've read back from zk , transitively after zk connection establishment , transitively after slobrok reports itself as ready . note that there 's still some auxiliary code",1616170595,fixes two edge cases when the cached cluster state has no available distributors : <nl> * avoid division by zero in <nl> * ensure policy context is set when is thrown,0.9369257092475891
apache_pulsar/10520,get durable subscription without handling startmessagerollbackdurationsec <cm-sep> fix,motivation <nl> handle startmessagerollbackdurationsec when get durable subscription,1620547197,"currently , the pulsar sql could n't support avroschema use the as the field type . for example , use the pojo class as below . <nl> error log . <nl> when the presto field record type is , check the record type is , , or others , and to process the field record by the type . <nl> this change added tests and can be verified as follows : . <nl> added unit test for getting bytes from type field record . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it",0.9330223202705383
elastic_elasticsearch/74712,"<para-sep> should never happen , must be available in all jdks",adds two methods to painless that exposes the functionality of the community id processor .,1624987455,changes the output format of preview regarding deduced mappings and enhances it to return all the details about auto-index creation . this allows the user to customize the index creation . using hlrc you can create a index request from the output of the response .,0.9701964855194092
apache_beam/13646,"cleanup code , shorten - > <para-sep> readablefile } , which allows more flexible usage . <nl> returns a model object created using provided modelclass or null . * /",* simplify and cleanup code related to avroio and parquetio . <nl> * update code to use beamschema for parquetio,1609766844,follow this checklist to help us incorporate your contribution quickly and easily : .,0.9279927015304565
vespa-engine_vespa/18106,define feature flag for requiring connectivity check before startup <cm-sep> add api for new feature flag <cm-sep> wire api for new feature flag <cm-sep> wire feature flag into sentinel config producer <cm-sep> make flag tunable per zone / application,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1622727622,"i do n't think we need/want this cache , i 'd like to try running without it in a zone for a while .",0.9317689538002014
neo4j_neo4j/11470,raft-synchronous snapshot download . <nl> blocks the raft while downloading the snapshot . <cm-sep> wait for complete download in core life start . <nl> previously we would wait just for the snapshot to have been installed <nl> and potentially double-start local database .,"cl [ version , version ]",1522956418,cl : ability to configure import input data buffer size using,0.9263374209403992
apache_shardingsphere/10757,fix failed unit test for metadatarefresherfactory <cm-sep> add final modifier for altertablestatementfederaterefresher <para-sep> remove . <nl> shardingsphere federate refresher for alter table statement .,changes proposed in this pull request : . <nl> - create altertablestatementfederaterefresher <nl> - add ut and fix failed unit test for metadatarefresherfactory <nl> - add final modifier for altertablestatementfederaterefresher,1623378286,- fix get data source for shadow <nl> - add shadow insert values token generator <nl> - add remove shadow column token generator <nl> - add the executeupdate,0.9824914336204529
vespa-engine_vespa/18404,"do n't swallow exception when unable to find file references in use . <nl> also keep 0 unused file references at all times <para-sep> removes unused file references older than a configured time , but always keeps a certain number of file references even when they are unused .",also keep up to 0 unused file references at all times .,1624612136,"remove misleading prefix of some deploy messages . <nl> parent-host-not-ready : <nl> 0/0 hosts for vespa.album-recommendation.default-t have completed <nl> provisioning and bootstrapping , still waiting for <nl> h33908.staging.aws-us-c.vespa-external-cd.aws.oath.cloud . <nl> load-balancer-not-ready : <nl> failed to ( re ) configure load balancer for cluster in application , <nl> targeting : reals . the operation will be retried on next deployment . <nl> out-of-capacity one of : <nl> could not satisfy request for 0 nodes with ... <nl> not enough capacity to start 0 r4.xlarge instances ... <nl> no host flavor matches [ vcpu : 0 , memory : ... ] ,",0.9039361476898193
elastic_elasticsearch/73079,"improve error when handling unexpected wildcards . <nl> security actively prevents wildcards ( as well as empty indices <nl> and explicit '_all ' ) from being sent to actions that do n't support <nl> replacing their index names . for example . <nl> get /a * /_doc/0 . <nl> this is so that we do n't end up in a situation where an action <nl> resolves wildcards in a non-security aware way . <nl> the error message that was returned in these cases was not meaningful <nl> to clients , and has been a regular source of confusion . <nl> this commit changes the error messages that are returned in this case .","security actively prevents wildcards ( as well as empty indices <nl> and explicit '_all ' ) from being sent to actions that do n't support <nl> replacing their index names . for example . <nl> get /a * /_doc/0 . <nl> this is so that we do n't end up in a situation where an action <nl> resolves wildcards in a non-security aware way . <nl> the error message that was returned in these cases was not meaningful <nl> to clients , and has been a regular source of confusion . <nl> this commit changes the error messages that are",1620980628,few things that prevent us from supporting cross-clusters tasks cancellation : . <nl> this does n't hold for a cross-clusters task as the parent task does not belong to the remote cluster . <nl> 0. ban action is n't registered on proxy nodes . <nl> 0. banned parent markers are removed when a node with the parent task leaves the cluster . this issue is similar to the first issue . <nl> ~this commit tries to address the third issue by periodically ( every 0 minutes ) sending heartbeats for banned parent markers and removing markers that have n't received,0.9528780579566956
crate_crate/10788,avoid counting votes from master-ineligible nodes .,bringing the coordination layer up2date . <nl> the commits are n't listed in es-backports because we had n't included the coordination in the git log statement that we use to generate the list . <nl> i 've kept the newly introduced undocumented for now .,1605780373,the index also exists for object columns . so we can always <nl> use for queries . <nl> this significantly improves the performance : . <nl> q : select min ( obj [ ' x ' ] ) from tbl where obj is not null <nl> c : 0 <nl> | version | mean ± stdev | min | median | q3 | max | <nl> | v1 | version ± version | version | version | version | version | <nl> | v2 | version ± version | version | version | version | version | <nl> mean :,0.8939782381057739
elastic_elasticsearch/72718,correct logging statements . <cm-sep> make buildshardfailures and buildsearchresponse private . <cm-sep> avoid closing releasable twice .,* use correct phase name in logging statements . <nl> * make buildshardfailures and buildsearchresponse private . <nl> * avoid closing releasables twice .,1620154844,"migrate async search to use an auto-created system index . this does change the behaviour of - previously , it would ensure the index existed before carrying out any operation , whereas now the index is only created when a document is created . for any other operation , the wrapped will be allowed to bubble up .",0.9253794550895691
apache_kafka/10729,: remove deprecated methods under stores . <nl> removes deprecated methods since version <nl> moves needed implementation from deprecated method <nl> to the right new one .,removes deprecated methods since version <nl> moves needed implementation from deprecated method to the right new one .,1621426163,"0. let to call on underlying bytes store directly , using the more restricted range . <nl> 0. fix the conservative upper range for multi-key range in session schema . <nl> 0. minor : removed unnecessary private wrappedsessionstorebytesiterator class as it is only used in unit test . <nl> 0. minor : removed unnecessary schema # init function by using the direct bytes-to-binary function .",0.9330396056175232
apache_kafka/10302,"move defaultpartitiongrouper <para-sep> groups partitions by the partition id . join operations requires that topics of the joining entities are copartitoned , i.e. , being partitioned by the same key and having the same number of partitions . copartitioning is ensured by having the same number of partitions on joined topics , and by using the serialization and producer 's default partitioner . <nl> generate tasks with the assigned topic partitions .","* more detailed description of your change , <nl> if necessary . the pr title and pr message become <nl> the squashed commit message , so use a separate <nl> comment to ping reviewers . * . <nl> * summary of testing strategy ( including rationale ) <nl> for the feature or bug fix . unit and/or integration <nl> tests are expected for any behaviour change and <nl> system tests should be considered for larger changes . * .",1615441275,"in this pr , i have eliminated the facility in api and it 's implementation to be able to optionally send a request to the controller . this feature was not seen to be particularly useful , and besides it also poses some hindrance to post world where no client would be able to access the controller directly . <nl> test plan : . <nl> rely on existing unit & integration tests .",0.9338717460632324
ballerina-platform_ballerina-lang/28952,"fix create variable 's name gen issues <cm-sep> remove semi-colon from function call insert text <para-sep> in some scenarios the compiler sends the symbol name as empty string . hence add the check <nl> covers 0 and 0 <nl> covers 0 and 0 <nl> generic completion provider for match statement related contexts such as match node and pattern clauses . <nl> error keyword suggestion is covered by the module completion items <nl> also , should include the enum members as well . since currently both are same , this is fine <nl> enum context tests .",0. add the completion support for the match statement context .,1614681968,- make parent context available for model builders <nl> - add support for allof composite types <nl> - add codegen supprot for any parameter type <nl> - throw error if swagger definition is not readable . <nl> generated dog object will look like below .,0.9779665470123291
grpc_grpc-java/7782,interop-testing : rename xdstestclient secure_mode argument <cm-sep> * interop : add channelz support to xds interop test client and server . <nl> * add reflection . <cm-sep> add channelz to xds interop test server running in non-secure mode,backport of xds security support for xdstestserver and xdstestclient .,1609904149,"embeddedchannel now runs all pending tasks when the channel is closed . <nl> this caused the http2connectionhandler to clear deframer references ( on <nl> channelinactive ) on errors when it previously did n't . now that the <nl> errors were handled more fully , it exposed bugs in tests .",0.8469352722167969
apache_shardingsphere/10270,support postgresql pattern matching operator parse,changes proposed in this pull request : . <nl> - support postgresql pattern matching operator parse,1620381638,changes proposed in this pull request : <nl> - modify getsubquerywheresegments method to make subquery in subqueryroutetest work well,0.9502223134040833
neo4j_neo4j/11702,"support temporal arithmetics in compiled runtime <cm-sep> change temporalarithmeticacceptance to be compiled-friendly . <nl> now the temporalarithmetic tests are also successfully run by the <nl> compiled runtime . we have to store the values in properties first , <nl> because any query that has a udf does not go to compiled runtime . <cm-sep> add tests to expose compiler runtime accessor problem <cm-sep> add tests to expose compiler runtime accessor problem 0 <para-sep> unfortunately string concatenation is not defined for temporal and spatial types , so we need to exclude them <nl> unfortunately string concatenation is not defined for temporal and spatial types , so we need to exclude them <nl> temporal values <nl> temporal values <nl> temporal values <nl> temporal values <nl> temporal and spatial types should only ever reach the compiled runtime as neo values <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then","the new temporal types define arithmetics for operators : <nl> and ( temporalvalue , durationvalue ) <nl> and ( durationvalue with number ) . <nl> the new temporal and spatial types also define map-like field accessors .",1525340008,"whenever a plan can be run by the compiled runtime test fails so that we can <nl> explicitly run the test with all runtimes . in the process of converting tests <nl> two bugs were discovered : <nl> - , , and was not handling correctly in all cases <nl> - was not handling array and list comparisons <nl> correctly",0.8409140110015869
apache_shardingsphere/10889,"<para-sep> utility for sql node converter . <nl> convert order by items . <nl> abstract limit sql node converter . <nl> binary operation expression converter . <nl> column of order by converter . <nl> column projection converter . <nl> column converter . <nl> todo <nl> todo expression has not been parsed now . <nl> expression converter entry . <nl> todo <nl> group by converter . <nl> having converter . <nl> join converter . <nl> list expression converter . <nl> order by converter . <nl> pagination value converter . <nl> projection converter . <nl> todo other projection <nl> simple table converter . <nl> subquery converter . <nl> todo <nl> convert from clause . <nl> where converter . <nl> binary sql operator . <nl> get binary operator . <nl> convert string to binarysqloperator . <nl> testcase of converting shardingshphere ast to calcite ast . after converting phrase finished , the next phrase is comparing the converted result with the result of calcite parser . <nl> todo outer join is not supported by parser of shardingsphere",- add some testcase for sqlnodeconverter .,1624202336,changes proposed in this pull request : <nl> - <nl> - <nl> -,0.9870936274528503
ballerina-platform_ballerina-lang/28960,remove blangcompilerexception with a warning for invalid settings . <nl> this fix will remove blangcompilerexception and display a warning <nl> when 'settings.toml ' is having syntax erros . <para-sep> validate settings.toml file <nl> ignore 'settings.toml ' parsing errors <nl> ignore 'settings.toml ' parsing errors <nl> ignore 'settings.toml ' reading and parsing errors,when pushing a package error will be shown .,1614699930,this pr provides swagger to ballerina support for this extension . this pr also include several minor fixes for bal-swagger code generator . <nl> - add support for x-multi path extension <nl> - update default codegen server bindings <nl> - add inverse support for equals helper <nl> - update errors after httpconnectorerror changes,0.9331471920013428
ballerina-platform_ballerina-lang/27807,enable a simple integration test in the lang repo <para-sep> generate ballerina bindings for a simple scenario and build the project .,* fixes a syntax change in user-defined errors in the bindings template .,1610435085,this pr fixes/enables the following test cases . <nl> - typeunificationtest <nl> - constrainedjsontest <nl> - constrainedmaptest <nl> - mapaccessexprtest <nl> - enabled ballerina http/grpc/ws related unit test cases . <nl> it also updates incompatible types conversion message to use proper sentence .,0.8484863042831421
apache_incubator-pinot/6911,initialize server tls early <para-sep> install default ssl context if necessary ( even if not force-enabled everywhere ),this pr initializes tls defaults even without any further settings for segment uploader .,1620931765,"currently you can specify a readerconfig when creating segments using pinot-admin.sh , but this argument is not available when creating segments using the hadoop jar command . i added code so that you can specify a readerconfig filepath in job.properties . not sure why the spacing ended up off within getreaderconfig . <nl> it may be a good idea to also allow job.properties to specify the expected file format . the current way that hadoop segmentcreation reads file formats gives problems e.g . when uploading a .tsv file ; this pr now allows reading files with any delimiter , but",0.9236332178115845
elastic_elasticsearch/73718,deprecation <cm-sep> tests <para-sep> details * +,indexing and search slow log level setting is deprecated in 7x as it is removed in master .,1622725661,we implicitly only supported the prime256v1 ( aka secp256r1 ) <nl> curve for the ec keys we read as pem files to be used in any <nl> ssl context . we would not fail when trying to read a key <nl> pair using a different curve but we would silently assume <nl> that it was using which would lead to strange <nl> tls handshake issues if the curve was actually another one . <nl> this commit fixes that behavior in that it <nl> supports parsing ec keys that use any of the named curves <nl> defined in rfc5915 and rfc5480,0.9383842349052429
vespa-engine_vespa/17688,do not process metrics we dont care about,"this is a bit ugly , but the issue is that returns 0 even if it 's not valid . what happened before was that for each metrics block we would aggregate a bunch of 0s , so the end result did n't change . but with my feed blocked metric we now get metric that cluster-controller ( which does not report this metric for itself , only on behalf of content nodes ) has feed limit 0 and util 0 .",1619787603,"up until now every lookup of a flag on zookeeperflagsource would hit zookeeper . <nl> flags are ideal for caching : changes seldom , little data , clients should handle <nl> short-lived inconsistencies at the time it is changed ( flag-flips must be reversible ) . <nl> this pr will make the backing flagsdbimpl cache the /flags/v1 zk directory and <nl> completes the optimization of configserverflagsource .",0.9205350875854492
hazelcast_hazelcast/18663,"support for order by queries <para-sep> comparison of row values : - compare the rows according to field collations starting from left to right . - if one of the field comparison returns the non-zero value , then return it . - otherwise , the rows are equal according to field collations , then return 0 . <nl> for each collation : - get collation index and use it to fetch values from the rows . - get direction ( ascending , descending ) and null direction ( nulls first , nulls last ) . if no null direction is given , then it will be inferred from the direction . since null is sorted as the +inf , ascending implies null last whereas descending implies nulls first . - comparison of field values : - if both of them are null , then return 0 . - otherwise , if one of them is null , then return : - null direction value if lhs is null . - or negative null direction if rhs is null . - if none of them is null , then : - if direction is ascending , then return the comparison result . - if direction is descending , return the negation of comparison result . <nl> use 0-phase sort for maximum parallelism first , construct processors for local sorting <nl> then , combine the locally sorted inputs while preserving the ordering",add support for order by . <nl> checklist : .,1620724980,"changed the 'non-space-string ' xsd type to collapse all <nl> whitespace , and made sure that all enumerated types <nl> extend from this type ( some were extending xs : string ) .",0.9563277959823608
apache_druid/11074,"fix tests for java 0 and above . <nl> * javascript scripting support was removed in jdk 0 : skip tests for <nl> those versions without the javascript script engine <nl> * fix flaky http client tests with jdk 0 <cm-sep> cms is not longer available in jdk15 , use g1gc instead <para-sep> skip tests for newer jdks without javascript support <nl> skip tests for newer jdks without javascript support","* javascript script engine support was removed in jdk 0 : skip those tests for jdks without it <nl> * fix flaky http client tests with java 0 <nl> * switch from cms to g1gc in integration tests , since cms is no longer available in jdk 0",1617752254,"should be immutable , but is exposed by and can be modified .",0.904927670955658
vespa-engine_vespa/18388,different log level for different errors,"this is hopefully enough . it 's also possible to keep older errors per request , and return these when a request is cancelled , but that seems too messy , and these requests _were_ cancelled , in the end ...",1624467153,setup a container running on the same host as logserver when <nl> using a dedicated host in hosted vespa . this container will be used <nl> for running a handler that can retrieve logs from logserver archive .,0.9562743306159973
elastic_elasticsearch/73576,add cluster health change in disassociatedeadnodes,"today we log if the cluster health changes when shards start or fail but do not <nl> log the health change associated with a node leaving the cluster , even though a <nl> node departure often means that a number of shards have just become unassigned . <nl> this omission can make it harder to determine the timeline of events when <nl> analysing the logs . with this commit we now log a change in cluster health <nl> caused by a node leaving the cluster .",1622518290,only transient format is supported for now .,0.935990571975708
apache_flink/15696,"hivetablesink should copy the record when converting rowdata to row . <para-sep> this is the inverse of creating the normal output . in case of object reuse , we need to copy in the broadcast output . because user 's operator may change the record passed to it .","hivetablesink should copy the record when converting rowdata to row . <nl> fix the classcastexception issue when inserting into hive . <nl> - copy the record when converting rowdata to row in hivetablesink <nl> - add test case . <nl> existing and added test cases . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class annotated with : no <nl> - the serializers : no <nl> - the runtime per-record code paths ( performance sensitive ) : no <nl> - anything that affects",1618985699,"# # what is the purpose of the change . <nl> bug when use jdbc sink with float type . <nl> in flink <nl> - sql , we regard float as java float . <nl> - but in jdbc , real type is java float , float/double are java double . <nl> we have dealt with data very well in jdbcutils , but mismatch in jdbctypeutil to match java float to jdbc float . <nl> - dependencies ( does it add or upgrade a dependency ) : no <nl> - the public api , i.e. , is any changed class",0.9375425577163696
elastic_elasticsearch/73804,"allow build xcontent directly from writable <para-sep> this api can be used to generate xcontent directly without the intermediate results to reduce memory usage . note that this method supports only json . <nl> we need to close the output stream that is wrapped by a base64 encoder to flush the outstanding buffer of the encoder , but we must not close the underlying output stream of the xcontentbuilder . <nl> write a field whose value is written directly to the output stream . as the content is copied as is , the writer must a valid xcontent value ( e.g. , string is properly escaped and quoted )","today , writing a writable value to xcontent in base64 format performs these steps : ( 0 ) create a bytesstreamoutput , ( 0 ) write writable to that output , ( 0 ) encode a copy of bytes from that output stream , ( 0 ) create a string from the encoded bytes , ( 0 ) write the encoded string to xcontent . these steps allocate/use memory 0 times than writing the encode chars directly to the output of xcontent . <nl> this api would help reduce memory usage when storing a large response of an async search",1622946614,system indices can be snapshotted and are therefore potential candidates <nl> to be mounted as searchable snapshot indices . as of today nothing <nl> prevents a snapshot to be mounted under an index name starting with . <nl> this commit introduces a changes to prevent snapshots to be mounted <nl> as a system index .,0.9673599004745483
apache_pulsar/10466,fix the possible memory leak of topicpolicy <para-sep> change persistent : //tenant/namespace/xxx- to persistent : //tenant/namespace/xxx <nl> clean cache and listeners in topicpolicies and so on . <nl> no-op,"now only the value of the listeners is deleted , the key is not deleted , and the cache is not deleted as well .",1619939402,"currently implementation only increase redelivery count when consumer call redeliver un-ack messages , since a consumer disconnect also let messages redeliver to other consumers in shared subscription mode , but the redelivery count does not increase . <nl> 0. when consumer send redelivery un-ack message request or consumer disconnect , add the position to redelivery message tracker . <nl> 0. when send messages to consumer will check if the tracker contains this message , if yes , increase redelivery count , otherwise use 0 as redelivery count . <nl> added unit test for this change . <nl> if was chosen",0.9424983263015747
Alluxio_alluxio/12480,expose mount id in mount table listing <cm-sep> add support for loading options from ufs for io tests,previously any ufs with credentials would need the credentials resupplied when running speed test . <nl> this change removes that hassle for the user .,1604971493,"this pr : <nl> 0. adds to and implement it in . <nl> 0. when calling from alluxio master , if acl is supported and enabled in under file system , loads the acl to alluxio inode tree . <nl> this pr extends the to include acl entries , so when creating an inode in , the acl entries retrieved from ufs are set into the inode 's acl . <nl> another design option is to extend the to include acl entries , then create inode without acl , after the creation is completed , use to set the acl",0.9774138927459717
elastic_elasticsearch/73764,add sentiment analysis task <cm-sep> results are xcontent fragments and have to be nested in an object for the api response <cm-sep> fixes <para-sep> nothing to validate <nl> bytesreference.bytes closes the builder,adds the sequence classification ( sentiment analysis ) task which given some input text returns a and . these values are softmax normalised . <nl> implement and so need to be wrapped in start and end objects in the api response . this change is required to be consistent but it means the ner and fill mask responses have changed to <nl> and rather than just returning the array .,1622808250,"similar to what the moving function aggregation does , except merging windows of percentiles <nl> sketches together instead of cumulatively merging final metrics .",0.9911378026008606
pentaho_pentaho-kettle/7677,backport of - pdi vfs connections are attached to every ktr even if it does not use them <cm-sep> backport of - disabling the blind copy of embedded metastore to the local metastore <cm-sep> backport of - disabling the blind copy of embedded metastore to the local metastore <cm-sep> backport of - setting the metastore without copying all the embedded connection to local metastore <cm-sep> backport of - setting the metastore when user connect or disconnect from repository,"backports of , , , to address security issues around vfs connections in pdi , raised in",1599585052,- when running pan/kitchen with an invalid repo it raises a java npe .,0.8630156517028809
Graylog2_graylog2-server/9971,"adding test to check if indexing retries for invalid alias targets . <cm-sep> adding indexing listener to bulk indexing to improve tests . <cm-sep> suppressing specific warnings . <cm-sep> introducing . <cm-sep> retrying bulk indexing upon . <cm-sep> relaxing es exception regex . <cm-sep> throw specific exception if parsed exception indices invalid write target . <cm-sep> fixing error parsing for ess6 , extracting target for exception . <para-sep> checking is always if at least one item fails . instead , we are checking the response code to to determine if the result failed in general .","prior to this pr , if one of the write targets in a bulk indexing request is an alias with zero or multiple targets , indexing failed and messages were silently dropped . this results in an error type being returned from es different to the ones we handled before . before this we had : . <nl> - requests failing completely : due to general errors ( e.g . networking errors ) , indicated by an being thrown and no response being returned <nl> - requests failing partially ( one or all individual bulk items failing ) : due",1611667258,"if we try to bulk index a batch of messages that exceeds the <nl> elastic search setting . ( default 100mb ) <nl> elastic will respond with an http 0 entity too large error . <nl> in this case we retry the request by splitting the message batch <nl> in half . <nl> when responding with an http 0 error , the server is allowed to close the connection <nl> immediately . this means that our http client ( jest ) will simply report <nl> an ioexception ( broken pipe ) instead of the actual error . <nl> this can",0.9748354554176331
quarkusio_quarkus/17450,support vert.x context switching . <nl> - updated to latest jboss threads <nl> - provide default context switcher to run the task without any context switch <nl> - add context switcher when vert.x core is present to use the context from the existing thread and set it onto the new execution thread <para-sep> only do context handling if it 's non null,- updated to latest jboss threads <nl> - provide default context switcher to run the task without any context switch <nl> - add context switcher when vert.x core is present to use the context from the existing thread and set it onto the new execution thread,1621945027,"to use the from within kubernetes , some rbac configuration is required . <nl> at minimum the role needs to be granted to the pod . <nl> this pull request introduces a new build item for extensions to be able to express their rbac requirements . kubernetesprocessor has been updated to read those items and generate the manifests accordingly .",0.9488567113876343
Alluxio_alluxio/13424,add a test option to accept running test name .,"provide an option to help debug a specific test when running runufstests <nl> for example , we can pass to focus test only and .",1621057688,"i found that the previous approach would always take over one second for the first rpc , while the low-level api would take less than 0 milliseconds .",0.8678763508796692
elastic_elasticsearch/73533,"we recently streamlined support for dynamic field lookups in fieldtypelookup . that is now used by the flattened field mapper . we would also like to use it for runtime fields , hence this commit adds support for dynamic runtime fields . <nl> this will be useful to support emitting multiple fields from a single runtime field script , as the sub-fields will be dynamically emitted . <para-sep> this will override concrete fields with runtime fields that have the same name","we recently streamlined support for dynamic field lookups in fieldtypelookup . that is now used by the flattened field mapper . we would also like to use it for runtime fields , hence this commit adds support for dynamic runtime fields . <nl> this will be useful to support emitting multiple fields from a single runtime field script , as the sub-fields will be dynamically emitted .",1622215379,this fixes two issues : . <nl> - results persister would retry actions even if they are not intermittent . an example of an persistent failure is a doc mapping problem . <nl> - data frame analytics would continue to retry to persist results even after the job is stopped .,0.9586331248283386
ballerina-platform_ballerina-lang/29604,replace valid imports with dummy values in parser tests <cm-sep> enable parsertestrunner <para-sep> this is an import declaration node import foobar/bar ; // this is a commentimport foobar/qux ; //this is the second importfunction add ( ) returns int { int x = a ; int y = b ; int z = a + b ; return z ; },"are replaced with , <nl> ` <nl> # # check list .",1616668433,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.862129807472229
ballerina-platform_ballerina-lang/29173,fix extracting bala twice issue . <para-sep> todo : need to refactor this fix,# # purpose <nl> > $ title .,1615546531,"with this fix , two json objects with different key-value pair ordering but the same key-value pairs are <nl> considered as equal .",0.9168503284454346
hazelcast_hazelcast/18884,"use instance factory to create instances in tests . <nl> this test was failing due to the interference with other tests . so , <nl> used the test instance factory while creating instances to avoid the <nl> interference between tests .","was failing due to the interference <nl> with other tests . so , i used the test instance factory while creating instances <nl> to avoid the interference between tests . <nl> see this kind of warning logs in the test failure , which are not related to the test : . <nl> here , it was interfering with . <nl> note : was marked as serial but <nl> is not . marking <nl> as serial would probably solve this problem , but i chose a different way . <nl> checklist : .",1623402832,fix for findbugs failures : . <nl> < < < findbugs-maven-plugin : version : check ( default ) < : findbugs @ hazelcast-client < < < .,0.8419796824455261
elastic_elasticsearch/74435,[ rest api compatibility ] ignore use_field_mapping option for docvalue . <nl> the value itself is ignored ( replaced with null ) as it is a default <nl> behaviour to use field mapping format .,the value itself is ignored ( replaced with null ) as it is a default <nl> behaviour to use field mapping format .,1624371765,add debug logging of the autoscaling capacity api reponse .,0.9177536964416504
Alluxio_alluxio/12745,add jni-fuse stackfs for testing <cm-sep> update stackfs descriptions <para-sep> stack fs implements the fuse callbacks defined by jni-fuse without interactions with alluxio clients/servers . stack fs mounts a local filesystem path to another local filesystem path . all the operations target the stack fs mount point will be directly trigger on the local filesystem mounted path without complex added logics . this class is mainly added for testing purposes to understand the performance overhead introduced by jni-fuse and provides an upper-bound performance data for alluxio jni-fuse implementations .,add stackfs which tests the performance overhead of jni-fuse without alluxio interactions .,1611185126,add support for authentication using keystone v3 credentials .,0.9768439531326294
apache_shardingsphere/10381,add sql definition for selectsubquery <cm-sep> add selectsubquery clause definition,please check it . i 'll change them based on your feedback . <nl> changes proposed in this pull request : <nl> - added sql definition for select statement 's subquery clause . <nl> - added test cases for the newly added rules .,1621358553,changes proposed in this pull request : <nl> - fix yaml meta data marshal,0.9637064933776855
apache_druid/10761,"add offsetfetchperiod to kinesis ingestion doc <cm-sep> remove jackson dependencies from extensions <cm-sep> use fixed delay for lag collection <cm-sep> metrics reset after finishing processing <cm-sep> comments <cm-sep> broaden the list of exceptions to retry for <para-sep> checks whether an exception can be retried or not . <nl> always retry on client exceptions caused by ioexception <nl> a special check carried forwarded from previous implementation . <nl> this will retry for 5xx errors . <nl> we let the firedepartmentmetrics know that all messages have been read . this way , some metrics such as high message gap need not be reported <nl> lag is collected with fixed delay instead of fixed rate as lag collection can involve calling external services and with fixed delay , a cooling buffer is guaranteed between successive calls","this pr fixes the following bugs <nl> - add offsetfetchperiod to the kinesis ingestion doc <nl> - when druid.extensions.useextensionclassloaderfirst is set to true , services fail to start due to duplicate jackson-databind dependencies in extensions . <nl> - publish the lag with a fixed delay instead of a fixed-rate so that there is enough cooling period between successive requests <nl> - when tasks start publishing segments , the reported message gap increases even though there are no messages being read . added a method to mark that processing is completed . <nl> - fix the retry mechanism in kinesis connector",1610608594,- fixes bug where a single worker can get blacklisted with enough failures <nl> - fixes bug where pending tasks do n't get assigned when worker is removed from blacklist <nl> - fixes concurrent modification exception while iterating through blacklisted nodes <nl> - fixes npe if task has n't been assigned to a worker <nl> - adds additional logging <nl> - changes default worker selection strategy to equaldistribution,0.9789058566093445
OpenAPITools_openapi-generator/8842,remove redundant operations <cm-sep> use logger correctly with object placeholders,"0. removed some redundant operations from blocks , unnecessary casts , object creation and a few more . <nl> 0. fixed use of loggers in defaultcodegen to use object placeholders which are faster , decrease object allocation in string pool and adds nullsafety in loggers",1614280692,- decommission ' packagepath ' <nl> - users will need to use -o ( -- output ) to control the destination folder instead to make it consistent with other generators <nl> - add new option ' packagename ' .,0.9267160296440125
elastic_elasticsearch/73178,deprecate shared and index data path settings . <nl> this commit adds deprecation warnings for use of the path.shared_data <nl> setting as well as the index setting index.data_path . <para-sep> details * + <nl> impact * + <nl> note : this must be done with an explicit check here because the deprecation property on a path setting will cause es to fail to start since logging is not yet initialized on first read of the setting,this commit adds deprecation warnings for use of the path.shared_data <nl> setting as well as the index setting index.data_path .,1621278022,this setting was recently deprecated in favor of node.remote_cluster_client . this commit adds this setting to the deprecation info api .,0.957423210144043
apache_incubator-pinot/6153,add more validation for upsert config <para-sep> no startree index <nl> non-existing column used as primary key <nl> valid primary key,- validate primary key columns <nl> - validate startree index not in use,1602990733,check alert 's lasttaskruntime . if there is no success run within 0 days then disable it .,0.9231023192405701
apache_pulsar/10525,fix transaction buffer delete marker problem .,"does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( no ) <nl> anything that affects deployment : ( no ) .",1620614027,on race condition when in namespace-policy gets changed multiple times subsequently ( repl-cluster added then removed ) : replication producer could n't close successfully . <nl> broker should not try to startreplicator again on newproducer-creation as it flips the state of replicator . <nl> it will avoid flipping up replicator 's state wrongly and replicator 's producer can be closed on replicator removal .,0.9155031442642212
elastic_elasticsearch/73634,expose uri parts processor in painless,adds a new method to painless that exposes the functionality of the uri parts processor .,1622577249,add matchboolprefix static method in query builders .,0.9605104327201843
ballerina-platform_ballerina-lang/28728,"fix signature of xml with param name empty <cm-sep> fix record to have rest signature only if exclusive <cm-sep> fix array type signature to contain size <para-sep> if the array is of fixed size , the signature should reflect that . <nl> treating every record typedesc as exclusive record typedescs .","fix xml , array and record type symbol signatures .",1613595566,"with this fix , two json objects with different key-value pair ordering but the same key-value pairs are <nl> considered as equal .",0.9164955019950867
apache_shardingsphere/11000,add oracle sql - associate statistics <para-sep> oracle associate statistics statement . <nl> assert actual index segment is correct with expected index . <nl> associate statistics statement assert . <nl> assert associate statistics statement is correct with expected parser result . <nl> associate statistics statement test case .,changes proposed in this pull request : <nl> - add oracle sql - associate statistics <nl> - add corresponding test cases .,1624541995,"changes proposed in this pull request : <nl> - write/read instance state to/from registry center <nl> - initialize cluster state module , define the state api",0.9828546643257141
elastic_elasticsearch/73165,allow null search strings ( matches all ) . <cm-sep> remove unnecessary skip,allow null search strings ( matches all ) .,1621263856,"currently if we shortcircuit a message the breaker release is null since <nl> there is nothing to be broken . however , the tcptransportchannel <nl> infrastructure still expects it . this commit resolves this issue be <nl> returning a no-op breaker release .",0.8515704274177551
apache_pulsar/10470,fixed npe from pulsar client if we attempt to close the resource when conf.getserviceurl is blank,pulsarclientimpl throws npe if we attempt to close the resource when conf.getserviceurl is blank . <nl> added a null check before accessing the resource . <nl> this change is a trivial rework / code cleanup without any test coverage .,1620025998,currently the information_schema that presto provides by default is not working for the pulsar presto connector,0.8891242146492004
Graylog2_graylog2-server/10897,parse new error messages for ingestion error during flood stage as retriable . <cm-sep> bumping es version for integration tests . <cm-sep> adjusting to changed error message for missing alias target . <cm-sep> bumping version used in tests from to .,"between es version and version , the error messages returned by the server for these case : . <nl> - a message can not be ingested to an index because the index/cluster is in flood stage <nl> - a message can not be ingested to an alias , because the alias is missing a target . <nl> have changed . therefore our error checking code does not identify these cases as being retriable , resulting in message loss . <nl> this pr addresses these cases and adds the changed error messages in addition to the previous ones in order to",1624261865,"this change introduces the new boolean configuration option , which allows the user to enable/disable the compression of requests going to the indexer ( elasticsearch ) nodes . this helps to significantly reduce the traffic sent over the wire , especially for bulk indexing requests .",0.8901805281639099
ballerina-platform_ballerina-lang/29982,fix issue with complement of integer literals <cm-sep> add unit tests for unary expression,fix the following issues with this pr . <nl> 0. issue with the complement of integer literals . <nl> 0. using the operator with an integer literal .,1618479631,when duplicate column name is found the latter occurrences are appended with table name .,0.8998662829399109
apache_druid/11115,"vectorized versions of hllsketch aggregators . <nl> also includes some minor changes to the theta sketch vector aggregator : . <nl> - cosmetic changes to make the hll and theta implementations look <nl> more similar . <nl> - extends the theta sql tests to run in vectorized mode . <para-sep> we initialize by copying a prebuilt empty hllsketch image . <nl> noinspection resultofobjectallocationignored ( hllsketch writes to ' emptysketch ' as a side effect of construction ) <nl> copy prebuilt empty sketch object . <nl> add an hllsketch for this chunk to our sketchcache . <nl> retrieves the sketch at a particular position . <nl> clean up resources used by this helper . <nl> in very rare cases sketches can exceed given memory , request on-heap memory and move there . we need to identify such sketches and reuse the same objects as opposed to wrapping new memory regions . <nl> we initialize by copying a prebuilt empty union image . <nl> noinspection resultofobjectallocationignored ( union writes to ' emptyunion ' as a side effect of construction ) <nl> copy prebuilt empty union object . not necessary to cache a union wrapper around the initialized memory , because : - it is cheap to reconstruct by re-wrapping the memory in ' aggregate ' and ' get ' . - unlike the hllsketch objects used by hllsketchbuildbufferaggregator , our union objects never exceed the max size and therefore do not need to be potentially moved in-heap . <nl> nothing to close . <nl> ca n't vectorize due to concat expression . <nl> ca n't vectorize due to outer query , which runs on an inline datasource . <nl> can not vectorize due to substring . <nl> uppercase <nl> lowercase ; also , filtered <nl> on extractionfn <nl> on expression <nl> on native theta sketch column <nl> on native theta sketch column <nl> ca n't vectorize due to outer query ( it operates on an inlined data source , which can not be vectorized ) .",also includes some minor changes to the theta sketch vector aggregator : . <nl> - cosmetic changes to make the hll and theta implementations look <nl> more similar . <nl> - extends the theta sql tests to run in vectorized mode .,1618436135,"- can handle non-rolled-up input ( by grouping input rows using an additional mr stage ) <nl> - can select its own partitioning dimension , if none is supplied <nl> - can detect and avoid oversized shards due to bad dimension value distribution <nl> - shares input parsing code with indexgeneratorjob",0.9843339323997498
elastic_elasticsearch/73753,ignore 0-not found error when cleaning up resources after tests,"we 're doing some clean up logic to delete indices , data streams , auto-follow patterns or searchable snapshot indices in some test classes after a test case is executed . today we either fail or log a warning if the clean up failed but i think we should simply ignore the 0 - not found response exception , like we do in other places for regular indices . <nl> note that this change applies only : <nl> - when cleaning up searchable snapshots indices in <nl> - when cleaning up indices , data streams and auto-follow pattern in",1622795285,this change ensures auditing does n't throw when such an api key is used for authentication .,0.9139781594276428
elastic_elasticsearch/73139,so far when a deprecated route was executed it only emitted deprecation <nl> warning once . all subsequent deprecated routes ( even when path and <nl> method were different ) were throttled because the key was the same - <nl> deprecated_route . <nl> this commit suffixes the deprecation key with path and method .,so far when a deprecated route was executed it only emitted deprecation <nl> warning once . all subsequent deprecated routes ( even when path and <nl> method were different ) were throttled because the key was the same - <nl> deprecated_route . <nl> this commit suffixes the deprecation key with path and method .,1621238907,just what it says on the tin . wiring a new agg up to the registry .,0.9448158740997314
hazelcast_hazelcast/18600,add null check to clientexceptionfactory . <nl> clientexceptionfactory becomes null when clientengine is <nl> noopclientengine ( clientengine can be noopclientengine according to <nl> network config ) .,clientexceptionfactory becomes null when clientengine is <nl> noopclientengine ( clientengine can be noopclientengine according to <nl> network config ) . <nl> checklist : .,1619503774,"this gives users a better guidance when the aws module is missing . <nl> there is also a small behaviour change : the original code would throw <nl> . the new code throws - this <nl> is a subclass of so it should not cause compatibility <nl> issues . <nl> for a comparison , here is the original stacktrace : . <nl> and here is a new one :",0.8651865720748901
elastic_elasticsearch/74536,remove bounding box query type parameter <para-sep> details * + <nl> impact * +,the parameter has been deprecates in version as it is a no-op .,1624514046,"in xpack the license state contains methods to determine whether a <nl> particular feature is allowed to be used . the one exception is <nl> allowsrealmtypes ( ) which returns an enum of the types of realms allowed . <nl> this change converts the enum values to boolean methods . there are 0 <nl> notable changes : none is removed as we always fall back to basic license <nl> behavior , and native is not needed because it would always return true <nl> since we should always have a basic license .",0.9566354155540466
elastic_elasticsearch/74017,move custom checkstyle rule implementations to build-conventions project <cm-sep> update git ignore <cm-sep> intellij likes to add a line break here i guess,"since we bumped the target runtime version for to java 0 , we 've broken our intellij checkstyle integration . since intellij uses java 0 as it 's runtime we ca n't compile the checkstyle rules with java 0. this pr moves the rule implementations into which uses java 0 as the target version . we 've also committed the checkstyle ide configuration file into source control so that this no longer has to be manually configured by developers .",1623341529,"testhealthonmasterfailover could timeout on some of the health requests <nl> in the case where an index is added , since the recovery leads to <nl> extended test run time .",0.894582211971283
elastic_elasticsearch/74025,"[ ml ] adds new running_state field to datafeed stats <para-sep> is the datafeed a ' realtime ' datafeed , meaning it was started without an end_time <nl> has the reading historical data has finished and are we now running on ' real-time ' data <nl> indicates if the datafeed is configured to run in real time <nl> indicates if the datafeed has processed all historical data available at the start time and is now processing ' real-time ' data .",adds the new field to the high level rest client .,1623349590,"this changes adds a new qa test that runs a smoke test on a node that <nl> has been configured with one realm of each type . <nl> not all of the realms work , because some of them would depend on <nl> external fixtures ( ldap , saml , etc ) and this particularly test suite <nl> is intended to be as stable as possible and have no external <nl> dependencies . <nl> the primary purpose of this test is to catch any issues that prevent <nl> a node from starting with particular realms configured ( e.g . security",0.9778503179550171
ballerina-platform_ballerina-lang/31102,fix simple string to json conversion,note : with this fix the shell print 0 pairs of double quotes .,1623332241,"include a link to a markdown file or google doc if the feature write-up is too long to paste here . <nl> if no doc impact , enter “ n/a ” plus brief explanation of why there ’ s no doc impact . <nl> if there is no impact on certification exams , type “ n/a ” and explain why . <nl> yes/no <nl> - ran findsecuritybugs plugin and verified report ? yes/no <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes/no .",0.93629390001297
elastic_elasticsearch/73124,"fix typo in rectangle ( ) error message . <nl> line 0 said : 'max y can not be less than min x ' , while this should be 'min y '","line 0 said : 'max y can not be less than min x ' , while this should be 'min y '",1621031987,"the rest api uses ' thread_pool ' as the name of the thread pool metric . <nl> if we use this name internally when we serialize nodes stats and info <nl> requests , we wo n't need to do any fancy logic to check for and switch <nl> out ' threadpool ' , which was the previous internal name .",1.0
apache_kafka/10266,": add validation method for internal topics . <nl> for , we need a way to validate internal topics before <nl> we create them . this pr adds a validation method to the <nl> internaltopicmanager for that purpose . <para-sep> validates the internal topics passed . the validation of the internal topics verifies if the topics : - are missing on the brokers - have the expected number of partitions - have configured a clean-up policy that avoids data loss","for , we need a way to validate internal topics before <nl> we create them . this pr adds a validation method to the <nl> internaltopicmanager for that purpose .",1614891131,"this is part 0 of suppression . <nl> in an effort to control the scope of the review , this pr is just the tests for buffered suppression .",0.9682455062866211
jenkinsci_jenkins/5474,"add admin monitor recommending java 0 for controller <para-sep> depending on whether the user said ' yes ' or ' no ' , send him to the right place .",", recommend running on java 0",1620547578,"i 'm looking into modernizing stapler . this is related to stephen 's work from last year that aimed to make stapler more declarative . first however i 'd like to gather some information about how stapler is used ' in the wild ' to determine the impact in terms of changes required to fully adapt to any potential changes i 'm looking into . for that reason , this trial collect anonymized dispatch information similar to , but without the actual string values etc . ( i.e . this does not collect user data ) . <nl> sample payload",0.9638903737068176
ballerina-platform_ballerina-lang/27930,remove logging of log messages <cm-sep> move logging of error message to trace span tag <cm-sep> update logging api to events <para-sep> do nothing <nl> adding error message to trace span <nl> adding specific error code to trace span,"moreover , the errors returned from a function were added as logs to the span . this is not required as this is an error of the function itself and it can be added as a tag to the span . <nl> refactor adding error messages which were added to logs as well into trace tags .",1610988833,"yes <nl> - ran findsecuritybugs plugin and verified report ? yes <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? yes",0.961449921131134
apache_kafka/10334,"fix basehashtable sizing . <nl> the array backing basehashtable is intended to be sized as a power of <nl> two . due to a bug , the initial array size was calculated incorrectly <nl> in some cases . <nl> also make the maximum array size the largest possible 0-bit power of <nl> two . previously it was a smaller size but this was due to a typo . <para-sep> the minimum number of slots we can have in the hash table . <nl> calculate the capacity we should provision , given the expected size . our capacity must always be a power of 0 , and never less than 0 or more than max_capacity . we use 0-bit numbers here to avoid overflow concerns .","the array backing basehashtable is intended to be sized as a power of <nl> two . due to a bug , the initial array size was calculated incorrectly <nl> in some cases . <nl> also make the maximum array size the largest possible 0-bit power of <nl> two . previously it was a smaller size , but this was due to a typo .",1615930382,"while processing connection set up timeouts , we are iterating through the connecting nodes to process timeouts and we disconnect within the loop , removing the entry from the set in the loop that it iterating over the set . that raises an exception . the current unit test did not catch this because it was using only one node .",0.8927212953567505
ballerina-platform_ballerina-lang/27265,"move utils from test to main <para-sep> ballerina debug point ( breakpoint/debug hit point ) representation used for integration test scenarios . <nl> timer task implementation to capture breakpoints from server stop events . <nl> if the debug hit is observed , cancels the timer task . <nl> if the debuggee program execution is already finished , cancels the timer task immediately . <nl> holds all the notifications/responses coming from the debug adapter server . <nl> test util class for all debugger integration test cases . <nl> copy all the test resources to a temp dir . <nl> initialize test debug session . <nl> initialize test debug session . <nl> else , tries to initiate the socket connection . <nl> sends ' configuration done ' notification to the debug server . <nl> sends ' configuration done ' notification to the debug server . <nl> can be used to add a new test breakpoint on-the-fly . <nl> sends ' setbreakpoints ( ) ' requests per source file . <nl> can be used to remove an already added test breakpoint on-the-fly . <nl> resumes the execution of the debuggee program . <nl> waits for a debug hit within a given time . <nl> can be used to fetch variable values when a debug hit is occurred . <nl> can be used to fetch stack frames when a debug hit is occurred . <nl> can be used to get child variables from parent variable . <nl> can be used to assert variable name , value and type . <nl> can be used to assert any expression evaluation result . <nl> can be used to evaluate any given evaluation failure , against its expected error message . <nl> can be used to assert stack frame name , line and source . <nl> can be used to evaluate any given expression , when a debug hit is occurred . <nl> terminates the debug session . <nl> program resume options . <nl> debug variable scope types . <nl> util class for debug related operations . <nl> finds an available port . <nl> ballerina command options to be run in debug mode . <nl> util class for file operations . <nl> recursively copy a directory from a source to destination . <nl> returns the content of a given file as a string . <nl> idebugprotocolclient implementation . <nl> debugger adaptor protocol based client request handler implementation .",we have moved the debugger utils classes from to . by doing this we would be able to pack the util classes inside the jar and these utils classes can be used in .,1606802773,pr introduces <nl> - server connector connection as a param in resource signature . <nl> - respond native function to send back the response to the caller .,0.9176993370056152
crate_crate/11388,"remove eager global ordinals property . <nl> we never set/used this property and removed logic related to it in other <nl> places . <cm-sep> remove unused options from textfieldmapper . <nl> these options can not be set or changed via sql statements , so we can <nl> remove them and all the related logic .","these options can not be set or changed via sql statements , so we can remove <nl> them and all the related logic .",1621331193,"uncleanliness : if the data folder does not exist during startup ( which is the default after download , unpack and start ) , it will ge crated with the initial cluster.name , which is ' elasticsearch ' at this time . the finally used cluster.name will get set not before the plugin is loaded . <nl> solution : pass -des.cluster.name= ' crate ' in the start-script .",0.944800615310669
jenkinsci_jenkins/5154,log if no class paths was found for plugin . <nl> this will make it easier to debug jenkins startup errors when an <nl> incorrect/corrupt jpi archive has been loaded .,"we ran into a situation where one of the plugin jpi archives was incorrect and did n't contain any valid classpaths . it took us a while to figure out that the classes from the jpi was n't added to the class path . the log entry added in this change would have helped us a lot to spot the error quicker , and i believe that others in similar situations would benefit from it as well . <nl> no jira issue available for this minor logging improvement . <nl> n/a",1609851609,"windows does n't allow deleting directories that have a file open inside of them , so this test is invalid on windows .",0.8550465106964111
Alluxio_alluxio/13409,"fixes <cm-sep> remove unnecessary code <para-sep> remove both ends of ' / ' character in the path as well as bucket name add ' / ' at end to show it 's a folder ( or else , aws cli crashes with index out of bounds ) <nl> prefix object .","both s3browser and aws command line are particular about the output of these files in different ways . fortunately , s3 api is very visible about it and can tell what it 's doing . the cli on the other hand will just throw cryptic errors at you until you trial & error it out . <nl> the two important changes here are : . <nl> 0. each entry of commonprefixes has its own <nl> 0. add a ' / ' at the end of each common prefix .",1620949397,- replace individual members in in favor of storing and using directly . <nl> - add getprimaryindex in multiprocesscluster for determining primary master .,0.8986660242080688
grpc_grpc-java/7810,separate bootstapper into interface + implmentation . <cm-sep> refactor tests for bootstrapper implementation . <cm-sep> fix usages for creating bootstrapper instances . <cm-sep> add test for using bootstrap filepath via system property . <para-sep> reads the content of the file with the given path in the file system . <nl> * / <nl> todo ( chengyuanzhang ) : require at least one server uri . <nl> * /,"split bootstrapper into bootstrapper interface and bootstrapperimpl . bootstrapper 's implementation is getting complicated , the way how its code is organized gets bad for readability and testing . also , having the singleton instance on bootstrapper itself does not provide any benefit . the singleton is already making use of a single bootstrapper instance . we would still want bootstrapper mockable as using a real instance in its consumer 's tests is cumbersome . so we make bootstrapper as an interface and implement a separate concrete implementation bootstrapperimpl . this is quite similar to nameresolver and dnsnameresolver .",1610679968,"in the latest design , the lb config for eds policy started to diverge for the full xds flow and for eds only flow ( internal . legacy ? ) <nl> this changes separates the usage of lb configs for these two code paths : . <nl> for full xds flow ( received from cds lb policy ) : . <nl> for eds only flow ( received from remote resolver ) : . <nl> since the eds only flow ( ) also delegates load balancing logic to , it converts to by setting field to target authority .",0.9496696591377258
netty_netty/11284,add builds for windows . <nl> motivation : . <nl> let 's also build on windows during pr validation . <nl> modifications : . <nl> add build on windows during pr . <nl> result : . <nl> validate that all also pass on windows <para-sep> failing on windows atm <nl> failing on windows atm <nl> not works on windows atm .,motivation : . <nl> let 's also build on windows during pr validation . <nl> modifications : . <nl> add build on windows during pr . <nl> result : . <nl> validate that all also pass on windows,1621436786,motivation : . <nl> sha introduced the possibility to use recvmmsg ( ... ) but did not correctly handle ipv6 mapped ip4 addresses to make it consistent with other transports . <nl> modifications : . <nl> - correctly handle ipv6 mapped ipv4 addresses by only copy over the relevant bytes <nl> - small improvement on how to detect ipv6 mapped ipv4 addresses by using memcmp and not byte by byte compare <nl> - adjust test to cover this bug . <nl> result : . <nl> correctly handle ipv6 mapped ipv4 addresses,0.9058576226234436
jenkinsci_jenkins/5453,suppressed spotbugs of type predictable_random on not security relevant randoms,suppressed spotbugs of type on not security relevant randoms and deleted an unused random . <nl> * n/a,1619777539,"various tests which have prevented us from having a stable build since nov 0 , which is intolerable . exempting this test where it just looks like all hell broke loose , not the fault of the test .",0.884329080581665
apache_pulsar/10564,fix transaction buffer cache problem .,"when topic init and have n't add consumer in , the of this sub is null . this time tc endtp will return ' nullpointerexception ' the tc will not retry this op . <nl> fix transaction buffer client lookup error in order to make transaction end buffer op can retry . <nl> fix tp redeliver message throw nullpointerexception problem . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no )",1620885733,topicpatternsubscription is not supported on proxy . <nl> - add gettopicsofnamespace support at the proxy <nl> - add a unit test to proxytest to cover regex subscription . <nl> regex subscription is supported at the proxy .,0.9489137530326843
confluentinc_ksql/7064,utility functions for retrieving migration files and finding the current version,* adds functions in title .,1614031792,"unfortunately , the external library was missing functionality : the ability to generate string fields using iterators . <nl> this pr updates to a new version of the avro-random-generator , to which string iteration have been added , and adds a test to detect any similar future errors .",0.9532226324081421
Graylog2_graylog2-server/10605,"lookup tables - purge key should purge it from all cluster members . <nl> - added an api to manage cache purging on the cluster-wide level <nl> - migrated the client to the newly introduced api . <para-sep> the primary objective of this api is to provide facilities for managing lookup tables on the cluster level . originally was introduced to perform cluster-wide cache purging . <nl> an http client interface for the lookup table api . is intended to be used in cluster-wide operations , e.g . cache purging . <nl> note : must not be called directly by clients . <nl> the new method properly handles the case of response and provides detailed report per each node api call . <nl> the new method properly handles the case of response and provides detailed report per each node api call . <nl> this method concurrently performs an api call on all active nodes . <nl> this wrapper is intended to provide additional server error information if something went wrong beyond the actual api http call . <nl> mind backward compatibility with existing plugins . <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then <nl> given <nl> when <nl> then","to make cluster-wide lookup table cache purging possible a new api endpoint was introduced in scope of this pr . the fe was adjusted accordingly , however error handling could be improved . <nl> manually verified : <nl> - unauthorized access to the new api endpoint <nl> - cache purging in multi-server environment . <nl> unit tests : <nl> - covered with unit tests . <nl> an example of response with successful api calls : . <nl> an example of response with failed api calls : . <nl> an example of response with server error : .",1620665976,"- exported , imported and installed an content pack containing a notification .",0.9824370741844177
apache_incubator-pinot/6455,cleanup dictionary and forward index loading in segmentpreprocessor <para-sep> returns the forward index reader for the given column . <nl> returns the dictionary for the given column .,move the dictionary and forward index loading logic into the loaderutils class,1611021840,this change is mainly about switching to the scheduled query executor <nl> to allow us to use custom query scheduling algorithms . current implementation <nl> will use fcfs as the only supported algorithm . this commit has following <nl> important changes : . <nl> 0. switch to scheduled query executor that processes queries on different <nl> executor service freeing up netty threads quickly . freeing up netty is less beneficial <nl> right now but we can potentially lower threads and support async queries from broker in future . <nl> 0. query worker threads are moved from tabledatamanager control to query,0.9724428057670593
elastic_elasticsearch/73639,"fix error when fetching values for parent id join field . <nl> the parent id join field is an internal field that links child documents to <nl> their parent . although it 's internal , we include it when listing all field <nl> types . this means a search with can attempt to fetch values from <nl> the parent id field and fail . <nl> this pr applies a simple fix to return an empty result instead of failing . <para-sep> although this is an internal field , we return it in the list of all field types . so we provide an empty value fetcher here of throwing an error . <nl> the parent join id is an internal field type and we do n't return any values for it .","the parent id join field is an internal field that links child documents to <nl> their parent . although it 's internal , we include it when listing all field <nl> types . this means a search with can attempt to fetch values <nl> from the parent id field and fail . <nl> this pr applies a simple fix to return an empty result instead of failing .",1622585443,"this pushes generating the description string for the values source into the values source config , and does better handling of the various cases of where the config got the values from .",0.9444255232810974
apache_kafka/10584,"prevent handling metadata requests with topic ids set or topics set to null . <para-sep> the response does not allow null , so convert to empty string if necessary <nl> version 0 adds topicid and allows name field to be null . however , this functionality was not implemented on the server . versions 0 and 0 should not use the topicid field or set topic name to null . <nl> construct invalid metadatarequesttopics . we will build each one separately and ensure the error is thrown . <nl> if version is 0 or 0 , the invalid topic metadata should return an error <nl> topic ids are not supported for versions 0 and 0. topic names can not be null in these versions . <nl> construct invalid metadatarequesttopics . we will try each one separately and ensure the error is thrown . <nl> if version is 0 or 0 , the invalid topic metadata should return an error",we prevent handling metadatarequests where the topic name is null ( to prevent npe ) as well as prevent requests that set topic ids since this functionality has not yet been implemented . <nl> should also cherry-pick these changes to version for the next release . <nl> added tests to ensure the error is thrown .,1619060071,"when the connect worker forwards a rest api request to the leader , it might get back a that suggests the worker should forward the request to a different worker . this can happen when the leader changes , and the worker that receives the original request forwards the request to the worker that it thinks is the current leader , but that worker is not the current leader . in this case . in most cases , the worker that received the forwarded request includes the url of the current leader , but it is possible ( albeit rare",0.904837429523468
apache_shardingsphere/10701,add test for localtransactionmanager <cm-sep> fix by comments <cm-sep> fix code style <cm-sep> fix test case <cm-sep> fix test case <cm-sep> add test for localtransactionmanager <cm-sep> fix by comments <cm-sep> fix code style <cm-sep> fix test case <cm-sep> fix test case <cm-sep> fix test case,changes proposed in this pull request : . <nl> - add test for localtransactionmanager,1623055507,changes proposed in this pull request : <nl> - add case test for governancetransactioncontexts,0.9813652634620667
Graylog2_graylog2-server/10544,"cleaning up tests , adding test case for issue . <cm-sep> do not quote index match pattern . <para-sep> use a special match pattern and wildcard to match restored indices like","note : this needs to be backported to . <nl> this works fine unless is defined . the index match pattern can contain special characters and regex terms deliberately , which must not be quoted . the index match pattern is currently used by archiving , which lead to it not being able to identify indices belonging to the restored archives index set . <nl> this pr is removing quoting for the index match pattern . any usage of the index match pattern must ensure that all special characters are quoted properly . <nl> in a future pr i would",1620050416,"up until now , trying to generate a field chart on a non-numeric value failed , as the server did only try to calculate statistical aggregations for the field and that is not possible . anyway , we could still calculate the total and cardinality functions for those fields , as we do in the statistics analyzer . <nl> this pr changes how we treat non-numeric field charts , enabling users to generate graphs for cardinality and total . it is as well possible to stack them to other field charts , and add them to dashboards , just as",0.8530442714691162
apache_beam/13733,add hash functions in beam sql,. <nl> zeta sql has already suported hash function . so comment out the hash function line to use in beam sql . <nl> please check it,1610463630,these are cherry-picks of and opn the version branch . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .,0.7221236824989319
apache_pulsar/10091,fixed equals for the clientconfigurationdata ( found while fixing tests in pulsar-adapters repo ) <cm-sep> added test/repro,found this while fixing a test in pulsar-adapters repo . <nl> two effectively equal configs were not equal : . <nl> this results in creating new pulsarclient for effectively the same config . <nl> reuse authenticationdisabled.instance as default instead of creating new one . <nl> this change added unittests . <nl> no . <nl> - does this pull request introduce a new feature ? no,1617128019,motivation . <nl> nullpointerexception was thrown when function worker is running as part of broker and metrics collection kicks in <nl> before worker service completes initialization . <nl> changes . <nl> only generate functions when worker service is ready .,0.8951611518859863
apache_kafka/10469,: fix using random payload in producerperformance incorrectly,"in producerperformance , random payload always same . it has a great impact when use the compression.type option .",1617457207,check whether cache is null before retrieving from cache .,0.8282298445701599
elastic_elasticsearch/73737,breaking change for single data node setting . <nl> this commit ensures the only valid value for the setting is true and <nl> adds deprecations if the setting is set . the setting will be removed <nl> in a future release . <para-sep> details * + <nl> impact * + <nl> get deprecation warnings .,this commit ensures the only valid value for the setting is true and <nl> adds deprecations if the setting is set . the setting will be removed <nl> in a future release .,1622747296,"migrate the and system indices to use the auto-create infrastructure . the watcher history indices are left alone . <nl> as part of this work , a now inspects its mappings to determine whether it has any dynamic mappings . this influences how strict elasticsearch is with enforcing the descriptor 's mappings , since es can not know in advanced what all the mappings will be . <nl> this pr also fixes the so that it does n't fall over when attempting to inspect the state of an index that has n't been created yet .",0.9507676362991333
ballerina-platform_ballerina-lang/29719,refactor and fix the function type symbol creation logic <cm-sep> deprecate parameters ( ) and introduce params ( ) as the alternative <cm-sep> migrate usages of parameters ( ) to params ( ),"this also addresses a couple of other issues as well , which hindered the introduction of this method . <nl> if it is the typedesc , this will return empty .",1617115800,now there are child buckets with values in both internal and external syntax tree nodes . but the public api does not expose those null values due to the usage of optional .,0.9543036222457886
apache_kafka/10856,small optimizations and removal of unused code in streams . <nl> remove unused methods in internal classes <nl> mark fields that can be final as final <nl> remove unneeded generic type annotation <nl> convert single use fields to local final variables <nl> use method reference in lambdas when it 's more readable,remove unused methods in internal classes <nl> mark fields that can be final as final <nl> remove unneeded generic type annotation <nl> convert single use fields to local final variables <nl> use method reference in lambdas when it 's more readable .,1623254807,"turns out actually does apply the admin 's config internally , so we do n't need to worry about providing a timeout of our own . who knew",0.9307000041007996
elastic_elasticsearch/72926,"[ ml ] revert model snapshot now waits for annotations index . <nl> reverting a model snapshot with the delete_intervening_results <nl> option deletes system-generated annotations that are more recent <nl> than the model snapshot . doing this relies on the annotations <nl> index being available , so the revert model snapshot action now <nl> waits for this . <nl> this problem is more likely to be seen in recent releases , as we <nl> now revert to the most recent model snapshot when a job relocates <nl> from one node to another , so we are more likely to be reverting <nl> a model snapshot at a time when there has been cluster disruption <nl> and this could also be causing the annotations index to be <nl> temporarily unavailable . <para-sep> results views , so needs to exist when there might be ml results to view . this method also waits for the index to be ready to search before it returns . <nl> create the .ml- index with correct mappings if it does not already exist . this index is read and written by the ui <nl> 0. revert the state <nl> 0. ensure the annotations index mappings are up to date","reverting a model snapshot with the delete_intervening_results <nl> option deletes system-generated annotations that are more recent <nl> than the model snapshot . doing this relies on the annotations <nl> index being available , so the revert model snapshot action now <nl> waits for this . <nl> this problem is more likely to be seen in recent releases , as we <nl> now revert to the most recent model snapshot when a job relocates <nl> from one node to another , so we are more likely to be reverting <nl> a model snapshot at a time when there has been cluster",1620739160,"it is possible that snapshot upgrader execution path continues before the old <nl> model state is fully read by the native process . <nl> to prevent this , a flush request is made after the state is loaded . this is to verify that the all the state <nl> has been read by the native process . this allows the task to fail if reading the state fails and prevents some <nl> strange race conditions .",0.9328516721725464
Graylog2_graylog2-server/10057,now the single job runs through the complete set of indices . <para-sep> reverse order to archive oldest index first,"if applied , this commit will open one job for every set of indices to be archived instead of opening one job for every single index in the set of indices . <nl> this change was made because the creation of jobs for each index in the set of indices was faster than the first job took to finish , resulting in it blocking the next jobs in queue from executing . now the single job runs through the complete set of indices . <nl> the run ( ) method of archivecreatejob now takes a list of indices which it",1613140074,"even when ' root-user ' was listed under in the configuration file , the root user would still be shown on the frontend and used at some places in the code . having the root-user linger even though it ca n't really be used is confusing . <nl> the root user will now be hidden in the frontend and it has been made clearer in the api that the root user might not exist ( by making the return value optional ) . <nl> setting the root user 's password in the config is not required anymore when the user",0.9218252897262573
elastic_elasticsearch/72710,rework reruntestresultprocessor to handle aborted tests and handle root descriptors reliable <para-sep> required as we rely on junit4 rules <nl> track reaper jar as a test input using runtime classpath normalization strategy <nl> testfinishevent finishevent ( string parentid ) { def event = mock ( testfinishevent ) _ * event.getparentid ( ) > > parentid event },also introducing the option to have unit tests in build tools written in spock,1620145248,there is a small chance that the file deletion will run <nl> on the searchable snapshot thread pool and not on the test <nl> thread now that the cache is non-blocking in which case <nl> we fail the assertion unless we wait for that thread .,0.8745219111442566
ballerina-platform_ballerina-lang/31014,fix isolated inference for function accessing isolated var <cm-sep> add tests,the methods in the following service will now be inferred as isolated .,1623046502,"fix basic tuple , var ignore , byte value , float value , json value tests",0.8555221557617188
netty_netty/11300,"modify list to map of pooled redis message in fixedredismessagepool . <nl> motivation : . <nl> for easy to get pooled message , add two type enum indicate redis message . <nl> use an enum as the key to easy get pooled message . <nl> modifications : . <nl> modify pooled collections from list to map in fixedredismessagepool , <nl> use an enum as the key to easy get pooled message . <nl> result : . <nl> users can get pooled message from map by enum instead of the whole string","motivation : . <nl> for easy to get pooled message , add two type enum indicate redis message . <nl> use an enum as the key to easy get pooled message . <nl> modifications : . <nl> modify pooled collections from list to map in fixedredismessagepool , <nl> use an enum as the key to easy get pooled message . <nl> result : . <nl> users can get pooled message from map by enum instead of the whole string",1621939250,may drop data if stream closed while auto read is off . <nl> motivation : <nl> http2multiplexcodec queues data internally if data is delivered from the <nl> parent channel but the child channel did not request data . if the parent <nl> channel notifies of a stream closure it is possible data in the queue <nl> will be discarded before closing the channel . <nl> http2multiplexcodec interacts with recvbytebufallocator to control the <nl> child channel 's demand for read . however it currently only ever reads a <nl> maximum of one time per loop . this can thrash the read,0.9688830971717834
gocd_gocd/8538,"introduce stage overview on pipeline activity page . <para-sep> for a user with no operate permission , the add comment feature is not available , making the stage overview mis-positioned , hence , position stage overview a little above for read only users .",description : . <nl> show stage overview on pipeline activity page .,1599644857,"this change allows config-repo users to set secure environment variables to empty strings . <nl> technically the following definition is not correct because empty string should have been encrypted with cipher text and look something like . <nl> there is one reasonable use case to allow above definitions - when user actually does not want to store secret in the config-repo , but rather provide it at runtime when triggering pipeline with overridden <nl> environment variables . <nl> above screenshot from following pipeline : . <nl> when sees that is an empty string , it will be encrypted using current",0.8677210211753845
apache_beam/14507,"change kafka table provider properties structure . <nl> this is an intentionally breaking change in the kafka beam sql table . currently , using the kafka table provider is impossible with a single reference identifier ( location ) , and the location field goes entirely unused . this change repurposes the currently unused location field to be . <nl> this is a breaking change because previously , users could have had location set to any string they wanted , including those without the / structure , since this field was entirely unused . <nl> this change also changes ' bootstrap.servers ' which is a comma-separated string in the properties to ' bootstrap_servers ' which uses a proper array , and makes both the ' topics ' and ' bootstrap_servers ' parameters optional ( previously , they were actually required , although the documentation said otherwise ) . <nl> also update beam documentation to reflect new kafka , pubsub and pubsublite semantics added in this and previous prs . <para-sep> kafka beam sql tables now ascribe meaning to the location field ; previously <nl> type kafka // optional . one broker host : port pair to bootstrap with and a topic . // only one topic overall may be provided for writing . location 'my.company.url.com:0/topic1 ' // extra bootstrap_servers and topics can be provided explicitly . these will be merged // with the server and topic in location . tblproperties ' { ' bootstrap_servers ' : [ ' version:0 ' , ' version:0 ' ] , ' topics ' : [ ' topic2 ' , ' topic3 ' ] } ' <nl> pub/sub supports generic payload handling . <nl> for writing <nl> for reading <nl> : : id of the google cloud project : the pub/sub lite topic name . : the pub/sub lite subscription name . : the location for this pub/sub lite topic os subscription . : : optional . the key which contains the event <nl> : optional , supports <nl> : optional . allows you to specify the payload format . <nl> pub/sub lite supports generic payload handling . <nl> : a url with the initial bootstrap broker to use and the initial <nl> : optional . allows you to specify additional <nl> : optional . allows you to specify additional topics , which are <nl> kafka supports all generic payload handling <nl> : avro an avro","this is an intentionally breaking change in the kafka beam sql table . currently , using the kafka table provider is impossible with a single reference identifier ( location ) , and the location field goes entirely unused . this change repurposes the currently unused location field to be . <nl> this is a breaking change because previously , users could have had location set to any string they wanted , including those without the / structure , since this field was entirely unused . <nl> this change also changes ' bootstrap.servers ' which is a comma-separated string in the",1618106883,"runner code generally only has access to the root pipeline and s while walking the pipeline to perform translation . this change adds a new message which is embedded in the of serialized s. doing so avoids the extra pipeline munging necessary to access to proper set of subtransforms . <nl> it also means that subtransforms are _not_ added directly to transforms . this effectively makes executable stages native transforms , which they should be as far as the runner is concerned . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .",0.9676728248596191
apache_druid/10929,"add avro + schema registry integration test <para-sep> given <nl> when <nl> given <nl> when <nl> the values here should be kept in sync with the values used in the docker-compose files used to bring up the integration-test clusters . integration-tests/docker/docker-compose.base.yml defines most of the hostnames , ports , and addresses , but some might live in the overrides as well .","this container only runs when the integration test group is run . <nl> i also adjusted the parse method to distinguish failures to get the avro schema from the registry from actual parse exceptions , since it seems like failure to get the schema would cause no messages to ever be parsable",1614571679,"extends , but sets to true , and to false , though it might actually be cacheable ... still need to think about that . direct queries to these segments will be performed on historicals as being a it will fail the checks to run locally on the broker , but if wired up to a that supplies an , can be used as part of a join clause and be run directly with the query instead of requiring a subquery join with an . <nl> examples to illustrate the implications/behavior , assuming is bound to :",0.9746395945549011
apache_beam/14642,"remove blank line that javadoc does n't like . <nl> the blank line in the example in the ' reading from jdbc datasource ' causes javadoc to terminate prematurely . while this is probably a bug in javadoc , it causes the documentation to be missing everything after that spot -- including the rather important ' how to write to a jdbc datasource ' section .. if you take out this line the javadoc builds correctly . this bug was not in version but was in version","the blank line in the example in the ' reading from jdbc datasource ' causes javadoc to terminate prematurely . while this is probably a bug in javadoc , it causes the documentation to be missing everything after that spot -- including the rather important ' how to write to a jdbc datasource ' section .. if you take out this line the javadoc builds correctly . this bug was not in version but was in version . <nl> i removed the blank line ; this allows the doc to build correctly . <nl> thank you for your contribution !",1619408770,update dependencies in readme . include 'supported versions ' section in javadoc .,0.8570975065231323
quarkusio_quarkus/17503,"revert ' resteasy reactive : allow , test and document httpserverresponse injection ' . <nl> this reverts commit sha .",this removes safer annotations because some vscode/eclipse implementations are even more broken than javac .,1622126581,a couple small optimisations in the orm bootstrap,0.9272116422653198
vespa-engine_vespa/17589,"reapply ' lesters/resolve cell types for rename and slice ' . <nl> this reverts commit sha . <cm-sep> allow rename of non-existing dimension ( with warning ) for now <para-sep> throw new illegalargumentexception ( ' bad rename , dimension ' +oldname+ ' not found ' ) ; <nl> allowed ( with warning ) for now : <nl> checkrenamefails ( ' tensor ( ) ' , mkl ( ' a ' ) , mkl ( ' b ' ) ) ;",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1619419589,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9394941329956055
grpc_grpc-java/8151,"populate the hostname used for dns reslution from cluster resource . <cm-sep> propagate dns hostname discovered by cds to cluster_resolver lb policy via its config . <cm-sep> use dns hostname received from discovermechanism in the lb config for logical_dns clusters to resolve endpoints . <para-sep> hostname for resolving endpoints via dns . only valid for logical_dns clusters . <nl> corresponding dns name to be used if upstream endpoints of the cluster is resolvable via dns . only valid for logical_dns cluster . <nl> private , use cdsupdate.forlogicaldns ( ) instead .",this change includes : . <nl> - parse the _single_ endpoint address from the embedded resource in cds responses as the dns hostname for logical_dns cluster and include it in cdsupdate being notified to the cds lb policy . <nl> - propagate the dns hostname to the cluster_resolver lb policy via its lb config ( discoverymechanism for logical_dns cluster ) . <nl> - cluster_resolver lb policy takes the dns hostname from the discoverymechanism for logical_dns cluster and use it as the name for dns resolution .,1620342802,the fake clock lets us advance the clock deterministically and avoid <nl> in unit tests .,0.959636926651001
apache_kafka/10537,": change timeorderedkeyschema combined key to ( time-key-seq ) <cm-sep> : removes duplicated records using deleterange ( ) internally <para-sep> end of key is exclusive , so we increment it by 0 byte to make keyto inclusive <nl> deletes keys entries in the range [ 'from ' , 'to ' ] , including 'from ' and excluding 'to ' . <nl> string format is happening in wrapping stores . so formatted message is thrown from wrapping stores . <nl> delete all duplicates for the specified key and timestamp <nl> string format is happening in wrapping stores . so formatted message is thrown from wrapping stores . <nl> string format is happening in wrapping stores . so formatted message is thrown from wrapping stores . <nl> remove all duplicated records with the provided key in the specified timestamp . <nl> given a record key and a time , construct a segmented key to search when performing prefixed queries . <nl> key into a schema combined of ( time , key , seq ) . since key is variable length while time/seq is fixed length , when formatting in this order , varying time range query would be very inefficient since we 'd need to be very conservative in picking the from / to boundaries ; however for now we do not expect any varying time range access at all , only fixed time range only . <nl> key and time range queries are not supported . <nl> add some records <nl> delete some records <nl> only non-deleted records should appear in the all ( ) iterator <nl> add some records in different order <nl> add duplicates <nl> only non-deleted records should appear in the all ( ) iterator <nl> a new all ( ) iterator after a previous all ( ) iterator was closed should return all elements .","this pr changes the composite key from - > to allow deletion of duplicated time-key records using the rocksdb api . it also removes all duplicates when is called . currently , the was a no-op , which was causing problems because there was no way to delete any keys when duplicates are allowed . <nl> the rocksdb deletes a range of keys from ( inclusive ) to ( exclusive ) . to make inclusive , i incremented the end key by one when calling the .",1618429780,"i 've tried various ways to fix it completely and i ended up having to add a single-point query to the public readonlysessionstore api for the exact needed semantics . it is used for flushing to read the old values ( otherwise the wrong old values will be sent downstreams , hence it is a correctness issue ) and also for getting the value for value-getters ( it is for perf only ) .",0.9623761773109436
Alluxio_alluxio/13109,"stop master process upon demotion . <nl> - the code changes here are relatively simple . when the <nl> faulttolerantalluxiomasterprocess changes state from primary to <nl> secondary , then instead of switching states and continuing operation , we <nl> should trigger the jvm to exit instead . <nl> the reasoning behind this change is that the implementation to clean up <nl> between state changes is not sound and leaves additional resources <nl> hanging around which accumulate if enough state changes occur . <nl> defaulting to this behavior places the restart responsibility elsewhere , <nl> but guarantees a clean slate and no resource leaks upon startup . <nl> this is implemented with little change by simply placing a call to <nl> stop ( ) once the primary selector changes to the secondary state <nl> within the ftamp . a simple new test is added to verify this behavior . <nl> additional considerations may want to be taken into account now that <nl> this is the default behavior . we may want to consider additional <nl> recommended guidelines for process supervision on bare metal machines <nl> using systemd . k8s deployments should not be affected as the default <nl> behavior is usually to restart the pod anyway .","the code changes here are relatively simple . when the <nl> faulttolerantalluxiomasterprocess changes state from primary to <nl> secondary , then instead of switching states and continuing operation , we <nl> should trigger the jvm to exit instead . <nl> the reasoning behind this change is that the implementation to clean up <nl> between state changes is not sound and leaves additional resources <nl> hanging around which accumulate if enough state changes occur . <nl> defaulting to this behavior places the restart responsibility elsewhere , <nl> but guarantees a clean slate and no resource leaks upon startup . <nl> this",1616387570,todo : add integration tests .,0.9641993641853333
netty_netty/11414,combinedchannelduplexhandler.removeoutboundhandler ( ) cause connect ( ... ) to not pass the correct parameters . <nl> motivation : . <nl> due a bug we did not pass the correct remote and localaddress to the next handler if the outbound portion of the combinedchannelduplexhandler was removed . <nl> modifications : . <nl> - call the correct connect ( ... ) method <nl> - refactor tests to test that the parameters are correctly passed on <nl> - remvoe some code duplication in the tests . <nl> result : . <nl> combinedchannelduplexhandler correctly pass parameters on,combinedchannelduplexhandler.removeoutboundhandler ( ) cause connect ( ... ) to not pass the correct parameters . <nl> motivation : . <nl> due a bug we did not pass the correct remote and localaddress to the next handler if the outbound portion of the combinedchannelduplexhandler was removed . <nl> modifications : . <nl> - call the correct connect ( ... ) method <nl> - refactor tests to test that the parameters are correctly passed on <nl> - remvoe some code duplication in the tests . <nl> result : . <nl> combinedchannelduplexhandler correctly pass parameters on,1624526971,this pull request contains <nl> - oio sctp transport . <nl> - oioeventloop interrupt method change ( please review ),0.8465738892555237
grpc_grpc-java/8275,"update androidcomponentaddress to include a binding intent . <nl> by considering this intent 's action , data , type , identity and categories <nl> we align grpc/binder 's addressing with android 's natural equivalence <nl> relation for ' cached ' ibinders . <cm-sep> update binderserverbuilder to accept any androidcomponentaddress and add binderserverbuildertest <para-sep> see bound services overview for more . <nl> creates a server builder that will listen for bindings to the specified address . <nl> always fails .","by considering the binding intent 's action , data , type , identity and categories we align grpc/binder 's addressing with android 's natural equivalence relation for ' cached ' ibinders .",1624054144,"this aligns with shutdownnow ( ) , which is already accepting a status . <nl> the status will be propagated to application when rpcs failed because <nl> of transport shutdown , which will become useful information for debug .",0.9576206207275391
vespa-engine_vespa/17213,add new method queryparameters.getstringlist ( ) <cm-sep> convert hostsuspensionresource to request handler,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1616778113,will do application in a separate pr .,0.980365514755249
Alluxio_alluxio/12743,fix backup lock acquisition <para-sep> deactivate interrupter if lock acquisition was not successful .,this pr disables the interruption threads once we give up on the back up process . previous behavior causes all future rpcs to fail because it is not able to obtain shared state lock . <nl> this pr also updates the default value for alluxio.master.lost.worker.file.detection.interval to 5mins from 10secs .,1611161128,"this fix intends to set the correct underfs_address for gcs , swift , glusterfs in addition to the previously hard coded hdfs , s3 and oss .",0.9000279307365417
neo4j_neo4j/11572,"updates test w/ regards to expected exception <para-sep> guarded by instantiatecloselock <nl> instantiate from factory . do this under lock so that we coordinate with any concurrent call to close . concurrent calls to instantiating parts wo n't contend with each other since there 's only a single writer at a time anyway . <nl> guarded by instantiatecloselock <nl> select the path corresponding to the given valuegroup . creates the path if needed , <nl> instantiate from factory . do this under lock so that we coordinate with any concurrent call to close . concurrent calls to instantiating parts wo n't contend with each other since there 's only a single writer at a time anyway . <nl> given <nl> this exception is ok since it may have been closed <nl> when <nl> then <nl> good <nl> given <nl> this exception is ok since it may have been closed <nl> when <nl> then <nl> good","with one-to-one native indexes like number or string , <nl> updates or interactions after call to close ( ) is prohibited <nl> and coordinated inside gbptree . with the spatial/temporal index <nl> structure , which has lazy instantiation of sub-indexes <nl> there was no such coordination . this meant that a call to close ( ) <nl> could race with an instantiation of one or more sub-indexes . <nl> this in turn would result in opened sub-indexes ( gbptree instances ) <nl> that would never get closed . <nl> contractually this is very good to tighten up so that they",1523912432,if writer reach a tree node with a valid successor it means that the <nl> tree is not consistent in one out of three ways : <nl> 0. tree state point to a root that is outdated ( has a successor ) <nl> 0. child pointer in parent does not point to latest successor of child . <nl> 0. sibling pointer does not point to latest successor of sibling .,0.9579954743385315
apache_pulsar/10689,fix transaction ack one topic with multi sub .,"fix it . <nl> this is transaction component status . <nl> does this pull request potentially affect one of the following parts : <nl> if yes was chosen , please highlight the changes . <nl> dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> the public api : ( no ) <nl> the schema : ( no ) <nl> the default values of configurations : ( no ) <nl> the wire protocol : ( no ) <nl> the rest endpoints : ( no ) <nl> the admin cli options : ( yes ) <nl>",1621867491,"bug fix . <nl> ' unackedmessagetracker ' will call ' consumerbase.redeliverunacknowledgedmessages ' . there will be 0 steps here : <nl> 0 ) filter out the messages that need to enter the dlq <nl> 0 ) the remaining messages will be re-delivered via redeliverunacknowledgedmessages request . <nl> the problem appeared in the second step , when all messages were filtered out in the first step . if the messageidslist received by the broker is empty , it will trigger the reposting of all unackedmessages under this consumer . <nl> other consumers will consume messages that exceed maxredeliverycount again , and",0.9198482036590576
quarkusio_quarkus/17451,add constraintverifier infomation to optaplanner documentation . <nl> ( cherry picked from commit sha ) <cm-sep> add changestreamdocument mongo class for reflection . <para-sep> container element constraints <nl> do nothing,"please do n't merge , i will merge it myself .",1621948421,"please do n't merge , i will merge it myself .",0.9385554790496826
netty_netty/11245,update selfsignedcertificate.java <para-sep> change all asterisk to ' x ' for file name safety .,"motivation : . <nl> creates a certificate and private key files and store them in a temporary directory . however , if the certificate uses a wildcard hostname that uses asterisk , e.g . , it 'll throw an error because is not a valid character in the file system . <nl> modification : <nl> replace the asterisk with ' x ' .",1620749417,motivation : . <nl> data flowing in from the decoder flows out in sequence，whether decoder removed or not . <nl> modification : . <nl> fire data in out and clear out when hander removed <nl> before call method handlerremoved ( ctx ) . <nl> result : .,0.8842282295227051
pentaho_pentaho-kettle/7829,"kitchen/pan client does not release the control when the specified ' directory ' does not have read/write permission . <para-sep> the options : <nl> parse the options ... <nl> if the old style of logging name is filled in , and the new one is not overwrite the new by the old <nl> : this throws an exception if the given log file is not accessible <nl> /////////////////////////////////////////////////////////////////////////////////////////////////// this is where the action starts . print the options before we start processing when running in debug or rowlevel <nl> ///////////////////////////////////////////////////////////////////////////////////////////////////",kitchen/pan client does not release the control when the specified ' directory ' does not have read/write permission .,1611662973,also i backported a fix for incorrect test .,0.76087486743927
apache_pulsar/10593,initial commit <para-sep> test where the discoverytriggererclassname is null <nl> test where the class name does not implement the batchsourcetriggerer interface <nl> test where the class name provided does n't exist,"this fix provides an alternative means of providing these configuration vaules . <nl> modified org.apache.pulsar.admin.cli.cmdsources and created associated unit tests . <nl> ( please pick either of the following options ) . <nl> this change added tests and can be verified as follows : . <nl> - added unit tests that submit batchsource class from the command line using the switch <nl> # # # does this pull request potentially affect one of the following parts : . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency )",1621035743,"to simplify deployment , it will be good to run bookie along with broker . so people do n't have to run separate bookkeeper cluster . it is good for small-size or midsize deployments . <nl> add options in pulsarbrokerstarter to allow run bookie together with broker . <nl> pulsarbrokerstarter command 's old behaviour will not change ; user now could add new options to start bookie or bookie auto recovery together with broker .",0.970937967300415
ballerina-platform_ballerina-lang/28863,fix generated node in array tables <cm-sep> cleanup toml transformer,this pr also cleans tomltransformer by getting rid of instanceof checks and unnecessary exception throwing .,1614147515,now there are child buckets with values in both internal and external syntax tree nodes . but the public api does not expose those null values due to the usage of optional .,0.9306085109710693
vespa-engine_vespa/17502,deduplicate <cm-sep> always use fallback mechanism in detector connection factory <para-sep> note : detector connection factory with single alternative will fallback to next protocol in connection factory list,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1618921215,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.8474228978157043
elastic_elasticsearch/73515,add _meta field to ilm policy,the main changes of this pr are : <nl> 0. add an optional field to ilm policy . <nl> 0. add some test code about the change . <nl> 0. update the doc of .,1622191868,"add tracking for multipart and resumable uploads for googlecloudstorage . <nl> for resumable uploads only the last request is taken into account for <nl> billing , so that 's the only request that 's tracked .",0.9471688866615295
OpenAPITools_openapi-generator/8681,added enumclassprefix option to go-gin-server . <nl> modified : docs/generators/go-gin-server.md <nl> modified : modules/openapi-generator/src/main/java/org/openapitools/codegen/languages/goginservercodegen.java <nl> modified : modules/openapi-generator/src/main/resources/go-gin-server/model.mustache <para-sep> list of { { { classname } } },added enumclassprefix option for go-gin-server target . this option already exists in go-server . <nl> fixed a bug in the model.mustache where name is used in the type declaration and classname is used in the definition . <nl> generated code before : . <nl> generated code after : .,1613058813,added ' enumclassprefix ' option for go server generation . ported existing functionality already made available in the go client generation so that the constant terms for enum values can be prefixed with the enum name itself . this is useful when you have multiple enum definitions that have some values that are shared between the enum sets .,0.9547067284584045
apache_incubator-pinot/6238,[ te ] uncomment travis cron check,this pr is achieve following items : . <nl> - remove from module <nl> - switch from to to reflect detection and alert components in and <nl> - remove from exclusion in the of,1604528539,"an earlier commit disabled the feature to override pre-loaded classes with new ones for a protocol . <nl> added back that feature , and added a test for it .",0.9341559410095215
elastic_elasticsearch/73889,"we recently introduced support for static fields as part of dynamicfieldtype , as well as for dynamic runtime fields . we were thinking we would use this to emit multiple field from a single runtime script , but as we made progress on that task , we realized that we do n't need any dynamic behaviour and we are taking a much simpler and static approach . <para-sep> this will override concrete fields with runtime fields that have the same name","we recently introduced support for static fields as part of dynamicfieldtype , as well as for dynamic runtime fields . we were thinking we would use this to emit multiple field from a single runtime script , but as we made progress on that task , we realized that we do n't need any dynamic behaviour and we are taking a much simpler and static approach .",1623145472,"instead of doing our own checks against rest status , shard counts , and shard failures , this commit changes all our extractor search requests to set . <nl> - scrolls are automatically cleared when a search failure occurs with set . <nl> - code error handling is simplified .",0.9539101719856262
apache_pulsar/10341,catch topic policy not hit exception in handlesubscribe,"the reason is that it does n't catch exception in gettopicpolicies , which will lead to subscribe failed .",1619170251,"it is useful to be able to control message flow from the client but still use messagelistener to be notified when new messages arrive . currently you have to use consumer.receive ( ) and receiverqueuesize which requires polling , which is inefficient for thousands of consumers . the c++ client has consumer.pausemessagelistener ( ) and resumemessagelistener ( ) . <nl> added consumer.pause ( ) and consumer.resume ( ) . when paused the consumer does not send requests for more messages to the broker . this works when using messagelistener and consumer.receive ( ) which is why i did n't use",0.9285182356834412
OpenAPITools_openapi-generator/8594,"fix date types usages <para-sep> enumheaderstringarray | kotlin.collections.list & lt ; kotlin.string & gt ; | header parameter enum test ( string array ) | enum : > , $ ] enumheaderstring | kotlin.string| header parameter enum test ( string ) | [ default to -efg ] [ enum : _abc , -efg , ( xyz ) ] enumquerystringarray | [ kotlin.collections.list & lt ; kotlin.string & gt ; | query parameter enum test ( string array ) | enum : > , $ ] enumquerystring | kotlin.string| query parameter enum test ( string ) | [ default to -efg ] [ enum : _abc , -efg , ( xyz ) ] enumformstringarray | [ kotlin.collections.list & lt ; kotlin.string & gt ; | form parameter enum test ( string array ) | [ default to $ ] [ enum : > , $ ] enumformstring | kotlin.string| form parameter enum test ( string ) | [ default to -efg ] [ enum : _abc , -efg , ( xyz ) ] <nl> pipe | kotlin.collections.list & lt ; kotlin.string & gt ; | | ioutil | kotlin.collections.list & lt ; kotlin.string & gt ; | | http | kotlin.collections.list & lt ; kotlin.string & gt ; | | url | kotlin.collections.list & lt ; kotlin.string & gt ; | | context | kotlin.collections.list & lt ; kotlin.string & gt ; | | decimal | java.math.bigdecimal | | & # x60 ; 123list & # x60 ; | kotlin.string * | | <nl> status | kotlin.collections.list & lt ; kotlin.string & gt ; * | status values that need to be considered for filter | [ enum : available , pending , sold ] <nl> tags | kotlin.collections.list & lt ; kotlin.string & gt ; * | tags to filter by | <nl> dollarspecialpropertyname | kotlin.long * | | <nl> user | kotlin.collections.list & lt ; user & gt ; * | list of user object | <nl> user | kotlin.collections.list & lt ; user & gt ; * | list of user object |","has some issues related to date types . <nl> the first one is that in the it defines as which is correct . <nl> but then in it defines as which is incorrect and does n't match with the <nl> it should define as in the . <nl> the second one is that it defines as in the and in the , which is wrong , it should be . <nl> this can cause bugs because the servers and the clients can ( and most probably are ) in different timezones . <nl> this is already fixed in and but",1612200195,make map to to make it useful in yard comment .,0.9140118956565857
elastic_elasticsearch/74473,rename token classification to ner <cm-sep> set class labels in the config <para-sep> checks labels are valid entity tags and none are duplicated <nl> create and validate the nlp processor <nl> validate the task input string . <nl> the second score is usually the positive score so put that first so it comes first in the results doc,"is a new array field in the task config , it must have the same length as the number of output classes . <nl> for example , given a sentiment analysis task the output labels can be change from the defaults ( 'positive ' , 'negative ' ) : . <nl> and the output is . <nl> the order of the labels is important , the first maps to class 0 the second class 0 etc . <nl> the change also renames the task type to .",1624440189,the endpoint now includes the name of the parent data stream for any backing indices .,0.9812533259391785
elastic_elasticsearch/73319,deprecate realm names with a leading underscore <para-sep> details * + <nl> impact * + <nl> ensure at least one realm has invalid name,deprecation warning is now issued if any realm is configured with a name <nl> prefixed with an underscore . this applies to all realms regardless <nl> whether they are enabled or not .,1621855605,"with this change , the recommend way of disabling file/native realm is to explicitly set to , e.g . : <nl> this pr ensures that a warning is generated whenever file and/or native realm is implicitly disabled . <nl> this change also brings a question about the parameter . currently , the parameter is mandatory in version and gets a warning message if it is missing in 0.x . however , it makes sense to not specify the parameter if the realm is disabled . so i also updated the parameter related code to do just that .",0.9734759330749512
Alluxio_alluxio/13198,reduce unnecessary prefetching and listing of subdirectories in metadata sync <para-sep> initialize sync children to true if it is a liststatus call on a directory <nl> load metadata for dira with 'always ' <nl> the file should already be loaded <nl> load metadata for dira with 'always ' <nl> the file should not already be loaded,"previously , when we only list one level of directory , we still add the children to the workqueue and prefetch children 's children from ufs . that is not necessary . <nl> this fixes that issue .",1617904483,"ttlaction needs to check for null in defaultfilesystemmaster . <nl> the setattribute function should only change the ttlaction if it 's specifically set within the options . otherwise , we should avoid the set . setting the ttlaction with a null param results in the ttl action being set to delete . if the default is free , then a user may be inadvertently setting the action to delete by calling setattribute . <nl> a test is added which fails before this fix .",0.9300041198730469
vespa-engine_vespa/17019,"add growth headroom test <cm-sep> average query rate over measurement window <cm-sep> adjust growth rate by average rate over window <cm-sep> cleanup <cm-sep> advance time <cm-sep> normalize to rate in measurement window <para-sep> the max query growth rate we can predict from this time-series as a fraction of the average traffic in the window <nl> the current query rate , averaged over the same window we average utilization over , as a fraction of the peak rate in this timeseries <nl> returns the average query rate in the given window , or empty if there are no measurements in it * / <nl> returns the average query rate in the given window , or empty if there are no measurements in it * / <nl> no current traffic share : ideal load is low but capped <nl> almost no current traffic share : ideal load is low but capped <nl> no current traffic : ideal load is low but capped",just making predictions more resilient to noisy data . next i 'll need to refactor .,1616012038,last commit is the new one .,0.9534268975257874
pentaho_pentaho-kettle/7921,problems in delete files and get subfolder names steps when using s3 <para-sep> fileobject.isreadable wrongly returns true in windows file system even if not readable <nl> fileobject.isreadable wrongly returns true in windows file system even if not readable,problems in delete files and get subfolder names steps when using s3 .,1617902632,"provide the capability to suppress result data from a transformation running on a remote slave . first commit provides this ability via named parameters for back-porting , second commit adds a gui checkbox .",0.8481081128120422
elastic_elasticsearch/74315,"[ ml ] optimize inference step when training_percent is 0 . <nl> in data frame analytics , when the analysis supports inference <nl> and is set to , there is no need to <nl> load the model in memory only to realize there are no documents <nl> to run inference on . <nl> this commit optimizes the inference step in this scenario . <para-sep> no need to run inference at all so let us skip loading the model in memory .","in data frame analytics , when the analysis supports inference , <nl> is set to , and there are no test docs <nl> ( i.e . docs missing a value for their dependent variable ) , <nl> there is no need to load the model in memory only to realize <nl> there are no documents to run inference on . <nl> this commit optimizes the inference step in this scenario .",1624027485,reenabled and fixed test that verifies that we properly cleanup after <nl> 6x leftover data .,0.9267731308937073
elastic_elasticsearch/73984,deprecate querystring and replace it with query_string <cm-sep> add tests,"both saml complete logout and saml invalidate session apis use a camelcase request parameter , , while the convention is to use snake_case parameters . this pr deprecates and replaces it with . it is an error to if a request specifies both of them .",1623305845,the name is now required when creating or granting api keys .,0.9150147438049316
confluentinc_ksql/7010,"init changes , need to move restart logic <para-sep> math.max ( ) prevents overflow if now is long.max_value ( found just in tests ) <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> given : <nl> then :",unit and integration tests are expected for any behavior changes._ .,1613500855,"there 's a recent change gone into that split it into an abstract base class and a derived class , with another derived class in the testing framework . <nl> a much better pattern is to ' favour composition over inheritance ' . i 've updated the classes to use composition and dependency injection to achieve the same ends . <nl> suitable tests added / changed / moved .",0.9723190069198608
apache_druid/10746,"tidy up query error codes <para-sep> an abstract class for all query exceptions that should return a bad request status code ( 0 ) . <nl> this exception is for queryresource and sqlresource to surface when a query is cast away after it hits a resource limit . it is currently used in 0 places : when the query is rejected by queryscheduler . <nl> this method sets hostname unlike constructors because this can be called in historicals while those constructors are only used in brokers . <nl> the resource limitations set by druid cluster operators are typically less flexible than the parameters of a user query , so when a user query requires too many resources , the likely remedy is that the user query should be modified to use fewer resources , or to reduce query volume . <nl> todo : nettyhttpclient should check the actual cause of the failure and set it in the future properly . <nl> errorcode should not be null now , but maybe could be null in the past .. <nl> note : this switch clause is to restore the 'type ' information of queryexceptions which is lost during json serialization . this is not a good way to restore the correct exception type . rather , queryexception should store its type when it is serialized , so that we can know the exact type when it is deserialized . <nl> the below is the list of exceptions that can be thrown in historicals and propagated to the broker . <nl> this class is for any exceptions that should return a bad request status code ( 0 ) . <nl> we ca n't collapse catch clauses since sqlplanningexception has type-sensitive constructors . <nl> an exception for sql query planning failures .","druid querying system returns an http status code on query failures . currently , most of query failures return an internal error ( 0 ) which could be misleading in some cases . this pr is to tidy up this and return a proper status code . here is a list of query errors , their current status codes , and proposed changes . <nl> likely an internal error | 0 | <nl> relconversionexception from calcite | conversion from sql to druid failed | 0 | <nl> cannotbuildqueryexception | failed to create a druid native query from druidrel . likely",1610440862,"this pr adds a new method to the interface , which should be noted in the release notes .",0.9853783845901489
jenkinsci_jenkins/5107,remove traces from jquery-detached from core,this pr removes some dependencies that cause a _web-inf/lib/jquery-.version-core-assets.jar_ to be included on the a compiled jenkins _war_ . <nl> no issues when manually testing so far . <nl> * remove unused jquery dependencies,1607692469,"this fixes a test to check an empty map using a proper method rather than relying on its tostring representation . <nl> no jira nor changelog entry , trivial improvement . <nl> ~~- [ ] jira issue is well described~~ <nl> ~~- [ ] changelog entry appropriate for the audience affected by the change ( users or developer , depending on the change ) . <nl> ~~- [ ] appropriate autotests or explanation to why this change has no tests~~ <nl> ~~- [ ] for dependency updates : links to external changelogs and , if possible , full diffs~~ .",0.8275880217552185
apache_flink/15288,ignore outdated slot allocation confirmations <para-sep> register task executor <nl> triggers the allocation of a slot <nl> clear requirements immediately to ensure the slot will not get re-allocated to the same job <nl> when the slot is freed it will be re-assigned to this second job <nl> acknowledge the first allocation this should fail if the acknowledgement is not ignored <nl> sanity check that the acknowledge was really ignored,"the accounts for the possibility of slot allocation confirmations coming in after the slot has already been freed or fully allocated ( e.g. , through a slotreport ) by checking whether there is still a pending request for that slot . <nl> however , this only works properly if the slot was allocated . <nl> if the slot was freed in the mean time then it could 've already been re-assigned to another job , which result in an illegalstateexception once the confirmation arrives because a transition from pending - > allocation is not allowed if the jobids are not",1616157245,"invoking rpc endpoint with message in order to properly handle possible user code specific exceptions . <nl> added it test : . <nl> - dependencies ( does it add or upgrade a dependency ) : ( yes / no ) <nl> - the public api , i.e. , is any changed class annotated with : ( yes / no ) <nl> - the serializers : ( yes / no / do n't know ) <nl> - the runtime per-record code paths ( performance sensitive ) : ( yes / no / do n't know ) <nl> - anything that affects",0.9294511675834656
confluentinc_ksql/7542,replace deprecated usages of sslcontextfactory .,"the previous fix is better in theory , but it can be merged only after the changes have been merged ( so it also breaks ci right now ) . <nl> - this is not a problem on and above , so this change needs to land solely here . we should merge it up with . i actually do n't have the permissions to do that , so i 'll have to ask the reviewers to help me with this .",1621290878,commiting the 'ratings ' example dataset used for workshop content so we do n't lose it,0.9099813103675842
apache_incubator-pinot/6382,"compatibility test for segment operations upload and delete <cm-sep> compatibility test for segment operations upload and delete <para-sep> uploads the segment , and verifies that the segments appear in externalview <nl> create segment file , compress to targz , upload the files to controller and verify segment upload . <nl> generate the segment ( s ) and then compress to targz file . supports generation of segment files for one input data file . <nl> upload the targz segment file to the controller . <nl> verify given table and segment name in the controller are in the state matching the parameter . <nl> deletes the segment for the given segment name and table name . <nl> verify given table name and segment name deleted from the controller . <nl> retrieve external view for the given table name . <nl> retrieve the number of segments for offline which are in state matching the parameter . <nl> retrieve the number of segments for both offline irrespective of the state .","0 . _upload_ : operation requires the below input and performs segment generation , compress to tar.gz file and then upload to controller . also , does the validation check for segment uploaded to the controller and whether it is in online state . <nl> > - inputdatafilename <nl> > - schemafilename <nl> > - tableconfigfilename <nl> > - recordreaderconfigfilename <nl> > - segmentname <nl> 0 . _delete_ : operation requires the below input and deletes segment . also , does the validation check for the segment deletion . <nl> > - tableconfigfilename <nl> > - segmentname . <nl> _note",1608851365,reusing the code path from offline side entirely,0.980693519115448
apache_beam/14322,support pcollectionlist in passert <para-sep> test that we throw an error for false assertion on flattened . * / <nl> test that we throw an error for false assertion on list with one matcher . * / <nl> test that we throw an error for false assertion on list with multiple matchers . * /,* added method that runs an assertion on the flattened contents of the . <nl> * added method that could run an assertion on each in the using one or multiple matchers,1616579815,- first_value <nl> - last_value . <nl> it uses a java optional class as a holder for the combine function,0.9533426761627197
netty_netty/11165,use threadlocalrandom instead of math.random ( ),motivation : . <nl> threadlocalrandom does n't cause contention . also generates only 0 random bytes while math.random ( ) generates 0 bytes . <nl> modification : . <nl> replaced with . <nl> result : . <nl> no possible contention when random numbers for websockets .,1618655798,"motivation : <nl> we can use instead of manually checking . also , there was a missing javadoc for , . <nl> modification : <nl> used for checking . <nl> added missing javadoc . <nl> result : <nl> more readable code .",0.8377473950386047
ballerina-platform_ballerina-lang/30678,"make optional in . <nl> with this we introduce separate node named futuretypedescriptornode . <cm-sep> rename to . <nl> with future-type-desc being extracted to a separate node , <nl> parameterizedtypedescriptornode is only used for map-type-desc . <para-sep> | defaultable-params [ , rest-param ] <nl> check whether the given token is a parameterized type keyword . <nl> parse map type descriptor . map-type-descriptor : = type-parameter <nl> parse parameterized type descriptor . parameterized-type-descriptor : = & nbsp ; | & nbsp ; | & nbsp ; | <nl> this is a generated internal syntax tree node . <nl> this is a generated syntax tree node . <nl> this is a generated tree node modifier utility . <nl> test parsing map and future types . valid source test <nl> recovery tests","- used to represent , , and type descriptors . <nl> ( syntaxkind is used to distinguish among 0 cases ) .",1621426180,"in the long run , package cache implementation will be based on this and also composer should be able <nl> to use the same package cache with the initialized language server instance",0.9723783135414124
hazelcast_hazelcast/18602,make file table functions implement hazelcastfunction <para-sep> remove the branch when map/map_value_constructor gets proper support <nl> 0 ( hdr ) + 0 ( arbitrary content ) . * / <nl> map converter .,"refactored so it extends - unified operand & return type checking for table functions , extracted common logic and simplified . <nl> introduced & to support operand checks . <nl> this is a prerequisite for dynamic parameters in file table functions .",1619515662,"this pr deletes code <nl> that was already added to mc code from imdg code . <nl> * managementcenterservice is moved from imdg to mc code ( renamed to <nl> mcclient ) <nl> * dtos used on client side while executing mc operations are moved to mc <nl> code <nl> * mc related tests except scriptingprotectiontest are moved to mc code <nl> ( this test is mostly concerned about whether member rejects script <nl> execution client operation on server side , so it makes sense to keep it <nl> in imdg . )",0.9766445159912109
apache_pulsar/10369,added more unit tests to the javainstancetest class,"adding some more unit tests for the javainstance class , and doing a sanity check to see if a simple pr is able to build successfully in the oss environment . <nl> added more unit tests for the javainstancetest class , that 's it , nothing else . <nl> this change is the addition of new unit tests to an existing test class . <nl> - does this pull request introduce a new feature ? ( no ) <nl> - if yes , how is the feature documented ? ( not applicable ) <nl> - if a feature is not",1619372530,"override resources only if the quantities have been specified in cmdline . <nl> describe the modifications you 've done . <nl> after your change , what will change .",0.9651605486869812
Graylog2_graylog2-server/10098,"use custom timeout when optimizing index for es7 . <cm-sep> actually return value , use correct import . <cm-sep> validating config setting to make sure it can be safely casted to int . <cm-sep> actually use 0 days as maximum . <para-sep> this constraint is related to the duration ( in milliseconds ) being casted to integer at some point .","prior to this change , the force merge request which is used during the index optimization job did not supply a timeout for es7 . this leads to the default timeout ( 60s ) being used , which is too short in most cases . <nl> this pr is supplying the configured timeout to the request .",1613724707,"right now we can not handle a path prefix for the web interface assets , because of the way they are bundled . the config parameter allows one , so we need to explicitly check for it and raise an error when it is set to prevent undefined/unexpected behavior .",0.9319478273391724
vespa-engine_vespa/17748,"billing api v2 draft - tenat api done , accountant not started <cm-sep> inject clock into billingapihandlerv2 . <nl> - injects the clock instance to make tests with date output work <nl> - rename invoice - > bill in the api path <cm-sep> accountant methods for billingapihandlerv2 . <nl> - create the accountant methods to preview and create bills <nl> - make sure classes take a clock through constructor to help with testing <nl> - update path groups for accountant view",i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1620214902,i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,0.9842930436134338
confluentinc_ksql/7284,add 'show connector plugins ' syntax <para-sep> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then : <nl> list all of the connector plugins available in this connect cluster . <nl> given : <nl> when : <nl> then : <nl> given : <nl> when : <nl> then :,add new syntax that displays the all available connector plugins from connect . <nl> unit and integration tests are expected for any behavior changes._ <nl> added unit tests <nl> verified manually in cli .,1616539373,"( note : the feature is currently disabled behind the 'allow any key column name ' feature flag ) . <nl> this change fixes an issue with our repartition semantics . <nl> old style query semantics for partition by are broken : . <nl> s1 : rowkey = > b , c ( meaning s1 has a schema with rowkey as the key column , and b and c as value columns - types are n't important ) . <nl> s2 : rowkey = > b , c . <nl> as you can see the schema of s2 is still",0.9848394989967346
Alluxio_alluxio/12770,make delegated backup suspend more resiliant <cm-sep> improve comment <para-sep> locks the state exclusively . <nl> suspend journals on current follower for every lock attempt . <nl> timeout for when suspend request is not followed by a backup request .,"currently delegated backup would timeout on suspend when the primary master takes long time to acquire exclusive lock during busy hours . this change adds a function in state lock manager to allow suspend of journal before every retry of lock , which should greatly improve the chance of keeping secondary master ready during the locking stage .",1611860229,"calling incurs some costs , such as querying ufs for available space . also , this gets call on each heartbeat which can be very frequent . instead , do this on a best effort basis periodically .",0.9477427005767822
apache_beam/14803,"prefetch subsequent pages over the fnapi . <nl> we still want to be lazy when the object is created , as we do n't <nl> know if we 'll want to iterate over it at all , but once we 've <nl> started iterating in most cases we 'll want to read the entire <nl> iterable and it makes sense to issue the state requests concurrent <nl> to processing the current page . <para-sep> this iterator will only request a chunk on first access . subsiquently it eagerly pre-fetches one future chunks at a time . <nl> no more is read than necessary . <nl> subsequent pages are pre-fetched , so after accessing the second page , the third should be requested .","we still want to be lazy when the object is created , as we do n't <nl> know if we 'll want to iterate over it at all , but once we 've <nl> started iterating in most cases we 'll want to read the entire <nl> iterable and it makes sense to issue the state requests concurrent <nl> to processing the current page",1620865889,maintain a mapping from bundle id to active bundle processor,0.903069257736206
elastic_elasticsearch/73098,ensure valid random service token name . <nl> the random token name is a base64 uuid . it can sometimes vilolate the <nl> validation rules . the base64 uuid is now hashed with sha256 to ensure <nl> the name is always valid .,the random token name is a base64 uuid . it can sometimes vilolate the <nl> validation rules . the base64 uuid is now prefixed with a string <nl> to ensure the name is always valid .,1620998363,"we had a few classes written in java but mistakenly placed in the groovy source set . although this works , it implicitly enabled groovy joint-compilation which is considerably slower due to the need to generate java stubs from groovy source files . this pr moves those files into as intended as well as removes which was no longer being used .",0.7651639580726624
apache_kafka/10458,": remove deprecated config value for client config . <nl> the config has been deprecated since kafka version ( released ~0 year before <nl> version ) , but it was the default before it got deprecated . as such , it 's <nl> reasonably unlikely that people would have set it explicitly . <nl> given the confusing name even though it 's _not_ the default , i <nl> think we should remove it in version .","the config has been deprecated since kafka version ( released ~0 year before <nl> version ) , but it was the default before it got deprecated . as such , it 's <nl> reasonably unlikely that people would have set it explicitly . <nl> given the confusing name even though it 's _not_ the default , i <nl> think we should remove it in version . <nl> also remove ( not public api ) , which unlocks <nl> a number of code simplications .",1617281111,"since currently not all refactorings on streams metrics <nl> proposed in has yet been implemented , this commit <nl> hides the built-in metrics version config from the user . <nl> thus , the user can not switch to the refactored streams metrics .",0.9468913674354553
apache_beam/13722,disable classloader check for mode . <nl> i was surprised that does not seem to respect the user-provided <nl> flink configuration . this pr makes respect the user-provided <nl> flink configuration when it creates a local environment .,"i was surprised that does not seem to respect the user-provided <nl> flink configuration ( ) . <nl> this pr makes respect the user-provided <nl> flink configuration when it creates a local stream environment . <nl> for batch , simply modify the default configuration . <nl> the difference is because batch exposes its configuration publicly , while does not",1610395511,description here . <nl> follow this checklist to help us incorporate your contribution quickly and easily : .,0.8961689472198486
runelite_runelite/13635,"scripts/skilltabbuilder : fix unbalanced stack <cm-sep> update cs2 opcodes <cm-sep> rl-client : update cs2 overlay opcodes <cm-sep> rl-client : cleanup cs2 overlays <cm-sep> use scriptprefired <cm-sep> use less callbacks in script overlays . <nl> all of these separate callbacks are error prone to update and hard to <nl> test <para-sep> builds a line in the chatbox when there is no username : prefix , such as a game or system message <nl> builds a line in the chatbox when there is a username : prefix <nl> builds a line in the chatbox when it from a clan","this should mostly have no side effects , with the exception of that timestamps now are given for all messages .",1621996978,"let me know if this code style is too ugly , i felt dumb using a switch for a boolean . i also removed a switch with a single case and instead used if .",0.9461791515350342
apache_kafka/10878,; owned partitions in the subscription must be sorted,"the group coordinator compares the provided subscription with the store subscription based on their bytes representation . so if the subscribed partitions are not in the same order , the group coordinator would consider that they are different and rebalance the group .",1623684751,"allow even distribution of lost/new tasks when more than one worker joins the group at the same time . <nl> issue description : <nl> existing issue 0 description : when more than one worker joins the consumer group the incremental co operative assignor revokes and re assigns atmost average number of tasks per worker . <nl> issue : this results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks . <nl> fix : as part of task assignment calculation following a deployment , the reassignment of",0.9190350770950317
vespa-engine_vespa/17463,"no longer allow suspension if in maintenance . <nl> if a storage node falls out of slobrok , it will change from up to maintenance <nl> after 60s , then after further 30s go to down . avoid allowing suspension in the <nl> 30s grace period just because it is maintenance mode . <cm-sep> disallow > 0 group to suspend . <nl> if there is more than one group , disallow suspending a node if there is a node <nl> in another group that has a user wanted state ! = up . <nl> if there is 0 group , disallow suspending more than 0 node . <para-sep> returns true if the group contains more than one ( leaf ) group . * / <nl> returns a disallow-result if there is another node ( in another group , if hierarchical ) that has a wanted state ! = up . we disallow more than 0 suspended node/group at a time . <nl> have found a node that is suspended , halt the visiting <nl> return a disallow-result if there is another node with a wanted state <nl> returns a disallow-result , if there is a node in the group with wanted state ! = up . * / <nl> nodes 0-0 , storage node 0 being in maintenance with ' orchestrator ' description . <nl> nodes 0-0 , storage node 0 being in maintenance with ' orchestrator ' description . <nl> nodes 0-0 , distributor 0 being in maintenance with ' orchestrator ' description . 0 groups : nodes 0-0 is group 0 , 0-0 is group 0 . <nl> denied for node 0 in group 0 , since distributor 0 in group 0 is down <nl> even node 0 of group 0 is not permitted , as node 0 is not considered suspended since only the distributor has been set down . <nl> nodes 0-0 , storage node 0 being in maintenance with ' orchestrator ' description . 0 groups : nodes 0-0 is group 0 , 0-0 is group 0 . <nl> denied for node 0 in group 0 , since node 0 in group 0 is in maintenance <nl> permitted for node 0 in group 0 , since node 0 is already in maintenance with description orchestrator , and it is in the same group <nl> make a hierarchicalgroupvisiting with the given number of nodes , with","* if there is more than one group , disallow suspending a node if there is a node in another group that has a user wanted state ! = up . <nl> * if there is 0 group , disallow suspending more than 0 node . <nl> in addition , we no longer allow suspension if a node is already in maintenance , as maintenance is used with grace period exactly to defer downing of node .",1618569050,"this adds some basic constraints for zip file extraction that should deal with <nl> the most common security issues , e.g . resource starvation and path traversals . <nl> i verified that all deployed application packages work with this change . <nl> this also has the added benefit of not extracting/copying files the controller <nl> does n't care about ( e.g . large bundles ) , which reduces the amount of garbage <nl> generated on each deploy .",0.9736151695251465
confluentinc_ksql/7195,"throw on unsupported statement type <cm-sep> positive unit tests <cm-sep> fix case-sensitivity on insert values <cm-sep> throw on missing semicolon , catch error on invalid parse <cm-sep> minor cleanup <cm-sep> validate config file present in create <cm-sep> minor touchups","this pr contains various minor improvements/fixes to the migrations tool : <nl> - the tool now throws if an unsupported statement type ( , , , , , , , , ) is encountered when applying a migration <nl> - the tool now throws if a migration file contains un-parsed statements at the end ( i.e. , missing semicolon ) , rather than silently ignoring such statements <nl> - fixes case-sensitivity of commands , so we can now insert into case-sensitive streams and streams with case-sensitive field names <nl> - adds a bunch of unit tests , both for negative",1615409520,"treats them as being just inbound ) <nl> as used by other sql providers . <nl> uses can set to true , ( either through server properties or session properties , to switch the implementation back to legacy mode , i.e . and error handling that throws a lot of exceptions . <nl> because i 've extended the description of , i 've also improved the formatting of the output of the in the cli , so that long descriptions are correctly split across lines and properly indented . new output looks like : .",0.973587691783905
netty_netty/11422,migrate codec-http2 to junit5 . <nl> motivation : . <nl> we should update to use junit5 in all modules . <nl> modifications : . <nl> adjust codec-http2 tests to use junit5 . <nl> result : . <para-sep> verify that the event was absorbed and not propagated to the observer .,motivation : . <nl> we should update to use junit5 in all modules . <nl> modifications : . <nl> adjust codec-http2 tests to use junit5 . <nl> result : .,1624965407,"improvement of traffic handler by using timer from netty instead of executor . <nl> no more threads creation per handler , so less resources .",0.9143669605255127
apache_beam/14691,"add patchresources to fhirio . <nl> the google cloud fhir service does n't support neither patch nor <nl> conditional patch within bundles , so it requires it 's own connector . <para-sep> the type patch resources . * / <nl> represents the input parameters for a single fhir patch request . * / <nl> shard input into batches to improve worker performance . <nl> the type write fhir fn . * / <nl> initialize healthcare client . <nl> creates a fhirsearchparameter to represent a fhir search request .","the google cloud fhir service does n't support neither patch nor conditional patch within bundles , so it requires its own connector",1619732608,follow this checklist to help us incorporate your contribution quickly and easily : . <nl> it will help us expedite review of your pull request if you tag someone ( e.g . ) to look at it .,0.9882597923278809
jenkinsci_jenkins/5359,ensure that plugins are sorted by name <cm-sep> remove incorrect comment,noticed this when looking at the code . <nl> available plugins should be sorted by name if popularity is equal,1615825290,"we have fixed the regression introduced in jenkins22750 , and i have correspondingly written a unit test to demonstrate that the job in fact gets queued on the master .",0.8750823736190796
apache_pulsar/10744,"new backoff by java reflact <cm-sep> add backoff in pulsar io core <para-sep> all variables are in timeunit millis by default . <nl> check for mandatory stop <nl> randomly decrease the timeout up to 0 % to avoid simultaneous retries if current < 0 then current/0 < 0 and we get an exception from random saying ' bound must be positive ' <nl> if the current time is less than the time at which next retry should occur , we should backoff","currently , the class in the project pulsar client impl , the kinesis sink connector want to use this class , the dependency is needed , but this will increase the connector size , so we could add a new class in the function io-core , then the class could be reused by other connectors . <nl> add the class in the project function io-core . <nl> if was chosen , please highlight the changes . <nl> - dependencies ( does it add or upgrade a dependency ) : ( no ) <nl> - the public api : ( no",1622401305,motivation . <nl> we added integration tests for kafka & cassandra sinks . we need test coverage on kafka sources . <nl> changes . <nl> - add and for testing sources <nl> - implement for testing kafka source,0.960959255695343
elastic_elasticsearch/74256,increment request before serializing it in outboundhandler . <nl> if there are outside ways by which a request can be decremented ( e.g . <nl> due to cancelling a recovery concurrently ) we may run into a situation where <nl> we try to send a request . we have to avoid this by incrementing <nl> a request before serializing and decrementing after it returns to make sure we <nl> do n't corrupt the request bytes while they 're being serialized <nl> or sent over the wire .,if there are outside ways by which a request can be decremented ( e.g . <nl> due to cancelling a recovery concurrently ) we may run into a situation where <nl> we try to send a request . we have to avoid this by incrementing <nl> a request before serializing and decrementing after it returns to make sure we <nl> do n't corrupt the request bytes while they 're being serialized <nl> or sent over the wire .,1623947248,re-enabled transportmonitoringmigratealertsactiontests # testlocalalertsremoval and transportmonitoringmigratealertsactiontests # testrepeatedlocalalertsremoval on 0.x branch .,0.9301573634147644
vespa-engine_vespa/17053,reduce initial time to sleep when redeploying fails <cm-sep> rename variable,"we have backoff , so this is just to reduce the initial sleep time , things will work the same , but e.g . tests will redeploy faster",1616136379,keep old until it is not used anymore,0.8483906984329224
vespa-engine_vespa/18275,"add 0 examples . <nl> the two more complex examples are copied from vespa-http-client documentation . <para-sep> sample feeder demonstrating how to programmatically feed to a vespa cluster . <nl> feed all operations from a stream . <nl> simple streaming feeder implementation which will send operations to a vespa endpoint . other threads communicate with the feeder by adding new operations on the blockingqueue <nl> constructor <nl> shutdown this feeder , waits until operations on queue is drained",the two more complex examples are copied from vespa-http-client documentation . <nl> i confirm that this contribution is made under the terms of the license found in the root directory of this repository 's source tree and that i have the authority necessary to make this contribution on behalf of its copyright owner .,1623762635,add code that returns a routing later as load balancers .,0.9802377223968506
Alluxio_alluxio/12649,add rais logging <para-sep> add the error logging here since the actual flush error may be overwritten by the future meaningless ratis.protocol.alreadyclosedexception,"add the debug logging since the actual flush failure will be overwritten by the last meaningless failure like or . <nl> the actual flush failure will sometimes give us helpful information or annoying meaningless logs , that 's why i mark it as debug for now . will be better to have an exception duplication-checking and only log the no-duplicate exceptions . and also link the exception to meaningful configuration suggestions .",1608067850,"we are able to reproduce the problem of complaining frame size smaller than the default limit . as a result , we increase the frame size and add the support of customizing this value .",0.8747130632400513
OpenAPITools_openapi-generator/8717,"add aspnet core version support <para-sep> .rsuser .suo .user .userosscache .sln.docstates <nl> .userprefs <nl> .visualstate.xml <nl> _i.c _p.c _h.h .ilk .meta .obj .iobj .pch .pdb .ipdb .pgc .pgd .rsp .sbr .tlb .tli .tlh .tmp .tmp_proj _wpftmp.csproj .log .vspscc .vssscc <nl> .pidb .svclog .scc <nl> .aps .ncb .opendb .opensdf .sdf .cachefile .vc.db .vc.vc.opendb <nl> .psess .vsp .vspx .sap <nl> .e2e <nl> .gpstate <nl> [ rr ] e [ ss ] harper .dotsettings.user <nl> .dotcover <nl> .coverage .coveragexml <nl> .mm . * <nl> [ pp ] ublish.xml .azurepubxml <nl> .pubxml .publishproj <nl> .nupkg <nl> .snupkg <nl> / [ pp ] ackages/ <nl> .nuget.props .nuget.targets <nl> .build.csdef <nl> .appx .appxbundle .appxupload <nl> [ cc ] ache <nl> ~ .dbmdl .dbproj.schemaview .jfm .pfx .publishsettings <nl> .rptproj.bak <nl> .mdf .ldf .ndf <nl> .rdl.data .bim.layout .bim_ * .settings .rptproj.rsuser - [ bb ] ackup.rdl - [ bb ] ackup ( ) .rdl - [ bb ] ackup ( ) .rdl <nl> .ghostdoc.xml <nl> .plg <nl> .opt <nl> .vbw <nl> /.htmlclient/generatedartifacts /.desktopclient/generatedartifacts /.desktopclient/modelmanifest.xml /.server/generatedartifacts /.server/modelmanifest.xml <nl> .pyc <nl> .tss <nl> .jmconfig <nl> .btp.cs .btm.cs .odx.cs .xsd.cs <nl> .binlog <nl> .nvuser <nl> / / model state validation attribute / <nl> / / called before the action method is invoked / / <nl> / / a requirement that an apikey must be present . / <nl> / / get the list of api keys / <nl> / / get the policy name , / <nl> / / create a new instance of the class . / / / <nl> / / enforce that an api key is present . / <nl> / <nl> openapi petstore this is a sample server petstore server . for this sample , you can use the api key to test the authorization filters . <nl> / / / <nl> / / add a new pet to the store / / pet object that needs to be added to the store / successful operation / invalid input <nl> todo : uncomment the next line to return response 0 or use other options such as return this.notfound ( ) , return this.badrequest ( .. ) , ... return statuscode ( 0 , default ( pet ) ) ; todo : uncomment the next line to return response 0 or use other options such as return this.notfound ( ) , return this.badrequest ( .. ) , ... return statuscode ( 0 ) ; <nl> todo : change",add asp.net core version support .,1613446496,add support for angular 0 <nl> fix api.module.ts to generate . <nl> instead of .,0.9074464440345764
ballerina-platform_ballerina-lang/30600,"enable testballerinatomlwithinvalidorgnameversion on windows . <para-sep> text range including minutiae , if we get a node that includes newline minutiae , its text range will be different . i.e windows will have an extra 0 length due to \r\n .","# # purpose <nl> > enable on windows , by changing textrange value for windows platform .",1621226538,"at the project level ' ballerina test ' is issued but outputs as no tests found in all of the modules . <nl> n/a <nl> - ran findsecuritybugs plugin and verified report ? n/a <nl> - confirmed that this pr does n't commit any keys , passwords , tokens , usernames , or other secrets ? n/a .",0.8319148421287537
apache_incubator-pinot/7074,"adding support for config files in compat tests . <nl> pinot installation administrators can now specify configuration files to run the <nl> tests as per their environment . <nl> changed the java files to get the ports as declared in the config files . <nl> cleaned up the scripts to use variables for ports . <nl> updated the scripts to compile with java 0 ( so that it can be run on desktops <nl> with one java environment for older and newer release ) <para-sep> todo support https , perhaps based on configuration",pinot installation administrators can now specify configuration files to run the <nl> tests as per their environment . <nl> changed the java files to get the ports as declared in the config files . <nl> cleaned up the scripts to use variables for ports . <nl> updated the scripts to compile with java 0 ( so that it can be run on desktops <nl> with one java environment for older and newer release ) .,1624061226,removed allocation of memory for virtual columns in consuming segments . <nl> removed the getrecord ( ) interface from indexsegment since it is not used anywhere . <nl> restricted it to a method within mutablesegmentimpl ( needed to build completed <nl> segments from consuming segments ) . <nl> verified that segment metadata did not have virtual columns before and after my change . <nl> verified that we can still execute the following queries : . <nl> select distinctcount ( $ segmentname ) from mytable <nl> select count ( * ) from mytable group by $ segmentname top 0 <nl> select,0.9328226447105408
elastic_elasticsearch/72612,"we recently replaced some usages of documentmapper with mappinglookup in the search layer , as document mapper is mutable which can cause issues . in order to do that , mappinglookup grew and became quite similar to documentmapper in what it does and holds . <nl> in many cases it makes sense to use mappinglookup instead of documentmapper , and we may even be able to remove documentmapper entirely in favour of mappinglookup in the long run . <nl> this commit replaces some of its straight-forward usages . <cm-sep> more <para-sep> todo this throws npe when called against an empty index with no provided mappings : documentmapper is null and the corresponding empty mappinglookup does not have a documentparser set <nl> returns the mapping source that this lookup originated from","we recently replaced some usages of documentmapper with mappinglookup in the search layer , as document mapper is mutable which can cause issues . in order to do that , mappinglookup grew and became quite similar to documentmapper in what it does and holds . <nl> it turns out that possibly documentmapper does not even need to be mutable ( to be verified ) but in many cases we should be using mappinglookup instead of documentmapper , and we should even be able to remove documentmapper entirely in favour of mappinglookup in the long run . <nl> this commit replaces",1620032105,"guava was removed from elasticsearch many years ago , but remnants of it <nl> remain due to transitive dependencies . when a dependency pulls guava <nl> into the compile classpath , devs can inadvertently begin using methods <nl> from guava without realizing it . this commit moves guava to a runtime <nl> dependency in the modules that it is needed . <nl> note that one special case is the html sanitizer in watcher . the third <nl> party dep uses guava in the policyfactory class signature . however , only <nl> calling a method on the policyfactory actually causes the",0.971122682094574
Alluxio_alluxio/12901,"report error if any of the sync paths faled in syncmetadata <para-sep> there should not be any failed or outstanding jobs <nl> this is a timing based test and may become flaky . the goal is to simulate a user interrupted liststatus call . in this case , the user 's liststatus should have synced the first level directory but have not completed the second level directory sync . thus resulting in a partial sync . <nl> make large nested directories/files in ufs","before this change , if any path was successfully synced , we return success from syncmetadata . <nl> after this change , we only return success if there was no failures and all paths have been synced without interruption . <nl> this also fixes an issue where an interrupted syncmetadata is considered synced by the file system master and will not be synced again until sync interval passes .",1614026214,"files containing strings in the blacklist will not be persisted . this can be useful for alluxio to avoid persisting results too early for workloads like hive or mapreduce as they typically create temp results first into temp directories , before the entire directory was renamed ( as commit ) .",0.9097124338150024
Graylog2_graylog2-server/10247,also drain input buffer in buffer synchronizer,"when the server shuts down , it drains the process buffer and the output buffer and only then continues with the shutdown sequence . <nl> this change adds the input buffer to the list of buffers to be drained and waited upon during server shutdown . <nl> when elasticsearch is down , we skip buffer draining , because we do n't want to wait for the process and output buffers to be empty ( which would n't happen ) . this made a small refactoring of the buffer synchronizer necessary so that we can still wait for the input buffer",1615547954,this pr introduces support for optional stream ids for saved searches <nl> which are constrained to one stream .,0.9612189531326294
apache_incubator-pinot/6186,"added recursive functions validation check for group by . <nl> the current validation rule for select-inside-groupby currently only consider exact match and alias function . <nl> there are many cases where composite functions are used in select-groupby too e.g . ' select concat ( foo , bar , '- ' ) , count ( * ) ... group by foo , bar ' is a valid query . <para-sep> check recursively if an expression contains any reference not appearing in the group by clause . <nl> return early for literal , aggregate and if we have an exact match <nl> function expression <nl> for alias function , check the actual value <nl> expression is invalid if any of its children is invalid <nl> nested functions in group by","there are many cases where composite functions are used in select-groupby too e.g . is a valid query . <nl> if you have a series of commits adding or enabling a feature , then <nl> add this section only in final commit that marks the feature completed . <nl> refer to earlier release notes to see examples of text .",1603524538,this pr supports embedded parsing in pinotdataandqueryanonymizer .,0.9137706756591797
confluentinc_ksql/7137,followups and fixes <cm-sep> add ability to apply specific migration version ( wip ) <cm-sep> throw on multiple migration files with same version <cm-sep> finish implementation <para-sep> throw on multiple matches <nl> extra migration to ensure only the first is applied <nl> extra migration to ensure only the first two are applied <nl> given : <nl> when : <nl> then :,adds a new option to for applying a specific migration version . <nl> added unit tests .,1614723792,"ensures all commands written to the command topic can be deserialized before writing them . <nl> a non-deserializable command causes the command runner thread to die . <nl> even restarting the server wo n't help as the server will stop when it hits the non-deserializable command again . <nl> this adds some level of protection . <nl> ( i know i 'd previously been against this , but ... meh ... maybe i was wrong ; ) ) . <nl> submitting a statement to the server which the server finds it ca n't deserialize now results in an error and",0.9517133235931396
ballerina-platform_ballerina-lang/30533,assign position when creating type-def node <cm-sep> revert ' fix npe at positionutil.withinrange ( ) for null nodeposition ',"with pr : 0 , we changed the to include a null-check . but , this change can be driven to anonymous errors in the future . therefore , this pr will revert the changes done earlier and fix the original issue .",1620887951,* add the bindgen command to ballerina help page . <nl> * fix a bug in the java class to ballerina object mapping template .,0.8176538944244385
